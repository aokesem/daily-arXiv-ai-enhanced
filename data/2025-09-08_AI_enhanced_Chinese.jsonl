{"id": "2509.04505", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.04505", "abs": "https://arxiv.org/abs/2509.04505", "authors": ["Somtochukwu Azie", "Yiping Meng"], "title": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management", "comment": "16 Pages", "summary": "The integration of Artificial Intelligence (AI) into construction project\nmanagement (CPM) is accelerating, with Large Language Models (LLMs) emerging as\naccessible decision-support tools. This study aims to critically evaluate the\nethical viability and reliability of LLMs when applied to the ethically\nsensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods\nresearch design was employed, involving the quantitative performance testing of\ntwo leading LLMs against twelve real-world ethical scenarios using a novel\nEthical Decision Support Assessment Checklist (EDSAC), and qualitative analysis\nof semi-structured interviews with 12 industry experts to capture professional\nperceptions. The findings reveal that while LLMs demonstrate adequate\nperformance in structured domains such as legal compliance, they exhibit\nsignificant deficiencies in handling contextual nuance, ensuring\naccountability, and providing transparent reasoning. Stakeholders expressed\nconsiderable reservations regarding the autonomous use of AI for ethical\njudgments, strongly advocating for robust human-in-the-loop oversight. To our\nknowledge, this is one of the first studies to empirically test the ethical\nreasoning of LLMs within the construction domain. It introduces the EDSAC\nframework as a replicable methodology and provides actionable recommendations,\nemphasising that LLMs are currently best positioned as decision-support aids\nrather than autonomous ethical agents.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86LLMs\u5728CPM\u4e2d\u7684\u9053\u5fb7\u53ef\u884c\u6027\u548c\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u7ed3\u6784\u5316\u9886\u57df\u8868\u73b0\u826f\u597d\u4f46\u5728\u5904\u7406\u60c5\u5883\u5dee\u522b\u548c\u63d0\u4f9b\u900f\u660e\u63a8\u7406\u65b9\u9762\u5b58\u5728\u7f3a\u9677\u3002\u5229\u76ca\u76f8\u5173\u8005\u4e3b\u5f20\u5bf9AI\u7684\u81ea\u4e3b\u4f7f\u7528\u8fdb\u884c\u76d1\u7763\u3002\u7814\u7a76\u5f3a\u8c03LLMs\u76ee\u524d\u9002\u5408\u4f5c\u4e3a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLMs\u5e94\u7528\u4e8eCPM\u4e2d\u9053\u5fb7\u654f\u611f\u3001\u9ad8\u98ce\u9669\u51b3\u7b56\u80cc\u666f\u7684\u9053\u5fb7\u53ef\u884c\u6027\u548c\u53ef\u9760\u6027\uff0c\u4ee5\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002\u7814\u7a76\u7ed3\u8bba\u5c06\u4e3a\u5efa\u7b51\u9886\u57df\u7684\u51b3\u7b56\u8005\u548c\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u5173\u4e8eLLMs\u5728\u4f26\u7406\u63a8\u7406\u65b9\u9762\u7684\u5b9e\u8bc1\u6570\u636e\u548c\u5efa\u8bae\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u8bbe\u8ba1\uff0c\u5b9e\u65bd\u5b9a\u91cf\u6027\u80fd\u6d4b\u8bd5\u548c\u5b9a\u6027\u5206\u6790\u3002\u4f7f\u7528\u65b0\u578b\u9053\u5fb7\u51b3\u7b56\u652f\u6301\u8bc4\u4f30\u6e05\u5355\uff08EDSAC\uff09\u8bc4\u4f30LLMs\u5728\u5341\u4e8c\u4e2a\u73b0\u5b9e\u4e16\u754c\u9053\u5fb7\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002\u5bf912\u4f4d\u884c\u4e1a\u4e13\u5bb6\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u4ee5\u6355\u6349\u4e13\u4e1a\u8ba4\u77e5\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u7ed3\u6784\u5316\u9886\u57df\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u60c5\u5883\u7ec6\u5fae\u5dee\u522b\u3001\u786e\u4fdd\u95ee\u8d23\u5236\u548c\u63d0\u4f9b\u900f\u660e\u63a8\u7406\u65b9\u9762\u5b58\u5728\u7f3a\u9677\u3002\u5229\u76ca\u76f8\u5173\u8005\u5f3a\u70c8\u4e3b\u5f20\u5bf9AI\u7684\u81ea\u4e3b\u4f7f\u7528\u8fdb\u884c\u76d1\u7763\u3002\u7814\u7a76\u5f15\u5165\u4e86EDSAC\u6846\u67b6\u4f5c\u4e3a\u4e00\u79cd\u53ef\u590d\u5236\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u5f3a\u8c03LLMs\u76ee\u524d\u6700\u9002\u7528\u4e8e\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5728\u5efa\u7b51\u9879\u76ee\u7ba1\u7406\uff08CPM\uff09\u4e2d\u7684\u6574\u5408\u6b63\u5728\u52a0\u901f\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u53ef\u8bbf\u95ee\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u5d2d\u9732\u5934\u89d2\u3002\u7814\u7a76\u65e8\u5728\u6279\u5224\u6027\u8bc4\u4f30\u5c06LLM\u5e94\u7528\u4e8eCPM\u4e2d\u56fa\u6709\u7684\u9053\u5fb7\u654f\u611f\u3001\u9ad8\u98ce\u9669\u51b3\u7b56\u80cc\u666f\u65f6\u7684\u9053\u5fb7\u53ef\u884c\u6027\u548c\u53ef\u9760\u6027\u3002\u7814\u7a76\u91c7\u7528\u4e86\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u8bbe\u8ba1\uff0c\u6d89\u53ca\u4f7f\u7528\u65b0\u578b\u9053\u5fb7\u51b3\u7b56\u652f\u6301\u8bc4\u4f30\u6e05\u5355\uff08EDSAC\uff09\u5bf9\u4e24\u79cd\u4e3b\u8981LLMs\u5728\u5341\u4e8c\u4e2a\u73b0\u5b9e\u4e16\u754c\u9053\u5fb7\u573a\u666f\u4e0b\u7684\u5b9a\u91cf\u6027\u80fd\u6d4b\u8bd5\uff0c\u5e76\u5bf912\u4f4d\u884c\u4e1a\u4e13\u5bb6\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u7684\u5b9a\u6027\u5206\u6790\uff0c\u4ee5\u6355\u6349\u4e13\u4e1a\u8ba4\u77e5\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136LLMs\u5728\u7ed3\u6784\u5316\u9886\u57df\uff08\u5982\u6cd5\u5f8b\u5408\u89c4\uff09\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u60c5\u5883\u7ec6\u5fae\u5dee\u522b\u3001\u786e\u4fdd\u95ee\u8d23\u5236\u548c\u63d0\u4f9b\u900f\u660e\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002\u5229\u76ca\u76f8\u5173\u8005\u5bf9\u4e8e\u5c06AI\u81ea\u4e3b\u7528\u4e8e\u4f26\u7406\u5224\u65ad\u8868\u793a\u76f8\u5f53\u4fdd\u7559\uff0c\u5f3a\u70c8\u4e3b\u5f20\u5f3a\u5927\u7684\u4eba\u7c7b\u76d1\u7763\u3002\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u7b2c\u4e00\u9879\u5728\u5efa\u7b51\u9886\u57df\u5185\u5bf9LLMs\u7684\u9053\u5fb7\u63a8\u7406\u8fdb\u884c\u5b9e\u8bc1\u6d4b\u8bd5\u7684\u7814\u7a76\u4e4b\u4e00\u3002\u5b83\u5c06EDSAC\u6846\u67b6\u4f5c\u4e3a\u53ef\u590d\u5236\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\uff0c\u5f3a\u8c03\u76ee\u524dLLMs\u6700\u9002\u7528\u4e8e\u51b3\u7b56\u652f\u6301\u5de5\u5177\u800c\u975e\u81ea\u4e3b\u9053\u5fb7\u4ee3\u7406\u7684\u7acb\u573a\u3002"}}
{"id": "2509.04642", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.04642", "abs": "https://arxiv.org/abs/2509.04642", "authors": ["Wenxiao Wang", "Priyatham Kattakinda", "Soheil Feizi"], "title": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents", "comment": "Technical Report by RELAI.ai", "summary": "Building reliable LLM agents requires decisions at two levels: the graph\n(which modules exist and how information flows) and the configuration of each\nnode (models, prompts, tools, control knobs). Most existing optimizers tune\nconfigurations while holding the graph fixed, leaving structural failure modes\nunaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for\nLLM agents that jointly searches over graphs and configurations to maximize\nagent quality, subject to explicit rollout/token budgets. Beyond numeric\nmetrics, Maestro leverages reflective textual feedback from traces to\nprioritize edits, improving sample efficiency and targeting specific failure\nmodes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses\nleading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,\n4.9%, and 4.86%, respectively; even when restricted to prompt-only\noptimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these\nresults with far fewer rollouts than GEPA. We further show large gains on two\napplications (interviewer & RAG agents), highlighting that joint graph &\nconfiguration search addresses structural failure modes that prompt tuning\nalone cannot fix.", "AI": {"tldr": "Maestro is a framework-agnostic optimizer for LLM agents that searches over graphs and configurations, outperforming existing prompt optimizers by improving sample efficiency and addressing structural failure modes. It consistently surpasses leading prompt optimizers on benchmarks and achieves significant improvements in applications like interviewer & RAG agents.", "motivation": "Existing optimizers focus on tuning configurations while ignoring structural failure modes, leading to suboptimal performance of LLM agents. Maestro aims to maximize agent quality by considering both graph structures and node configurations.", "method": "Introducing Maestro, a holistic optimizer for LLM agents that jointly searches over graphs and configurations, leveraging reflective textual feedback for prioritizing edits.", "result": "Maestro consistently surpasses MIPROv2, GEPA, and GEPA+Merge prompt optimizers on IFBench and HotpotQA benchmarks, achieving an average improvement of 12%, 4.9%, and 4.86%, respectively. Even in prompt-only optimization, Maestro leads by 9.65%, 2.37%, and 2.41%. It requires fewer rollouts compared to GEPA and shows significant gains in interviewer & RAG agent applications.", "conclusion": "Maestro outperforms leading prompt optimizers in optimizing LLM agents by simultaneously searching over graphs and configurations, improving sample efficiency and addressing structural failure modes."}}
{"id": "2509.04646", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.04646", "abs": "https://arxiv.org/abs/2509.04646", "authors": ["Philippe J. Giabbanelli", "Ameeta Agrawal"], "title": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization", "comment": "Accepted at the AAAI 2025 Fall Symposium Series. November 6-8, 2025,\n  Arlington, VA, USA", "summary": "Modeling & Simulation (M&S) approaches such as agent-based models hold\nsignificant potential to support decision-making activities in health, with\nrecent examples including the adoption of vaccines, and a vast literature on\nhealthy eating behaviors and physical activity behaviors. These models are\npotentially usable by different stakeholder groups, as they support\npolicy-makers to estimate the consequences of potential interventions and they\ncan guide individuals in making healthy choices in complex environments.\nHowever, this potential may not be fully realized because of the models'\ncomplexity, which makes them inaccessible to the stakeholders who could benefit\nthe most. While Large Language Models (LLMs) can translate simulation outputs\nand the design of models into text, current approaches typically rely on\none-size-fits-all summaries that fail to reflect the varied informational needs\nand stylistic preferences of clinicians, policymakers, patients, caregivers,\nand health advocates. This limitation stems from a fundamental gap: we lack a\nsystematic understanding of what these stakeholders need from explanations and\nhow to tailor them accordingly. To address this gap, we present a step-by-step\nframework to identify stakeholder needs and guide LLMs in generating tailored\nexplanations of health simulations. Our procedure uses a mixed-methods design\nby first eliciting the explanation needs and stylistic preferences of diverse\nhealth stakeholders, then optimizing the ability of LLMs to generate tailored\noutputs (e.g., via controllable attribute tuning), and then evaluating through\na comprehensive range of metrics to further improve the tailored generation of\nsummaries.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5b9a\u5236\u7684\u5065\u5eb7\u6a21\u62df\u89e3\u91ca\u3002\u901a\u8fc7\u9010\u6b65\u6846\u67b6\u548c\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\uff0c\u6210\u529f\u8bc6\u522b\u4e86\u5065\u5eb7\u5229\u76ca\u76f8\u5173\u8005\u7684\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u4f18\u5316LLMs\u7684\u80fd\u529b\u751f\u6210\u4e86\u5b9a\u5236\u8f93\u51fa\uff0c\u6700\u7ec8\u8fdb\u4e00\u6b65\u6539\u8fdb\u4e86\u751f\u6210\u7684\u6458\u8981\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u73b0\u6709\u7684M&S\u65b9\u6cd5\u5728\u652f\u6301\u51b3\u7b56\u6d3b\u52a8\u4e2d\u5177\u6709\u6f5c\u5728\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u5065\u5eb7\u9886\u57df\u3002\u7136\u800c\uff0c\u7531\u4e8e\u8fd9\u4e9b\u6a21\u578b\u7684\u590d\u6742\u6027\uff0c\u8fd9\u79cd\u6f5c\u529b\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u5b9e\u73b0\uff0c\u56e0\u4e3a\u8fd9\u4f7f\u5f97\u8fd9\u4e9b\u6a21\u578b\u5bf9\u6700\u6709\u5229\u76ca\u7684\u5229\u76ca\u76f8\u5173\u8005\u4e0d\u53ef\u53ca\u3002\u53e6\u5916\uff0c\u5f53\u524d\u7684LLMs\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u4e00\u63fd\u5b50\u6458\u8981\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e34\u5e8a\u533b\u751f\uff0c\u653f\u7b56\u5236\u5b9a\u8005\uff0c\u60a3\u8005\uff0c\u7167\u6599\u8005\u548c\u5065\u5eb7\u5021\u5bfc\u8005\u7684\u591a\u6837\u5316\u4fe1\u606f\u9700\u6c42\u548c\u98ce\u683c\u504f\u597d\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u77e5\u8bc6\u7a7a\u767d\uff0c\u4ee5\u63d0\u4f9b\u66f4\u597d\u5730\u6ee1\u8db3\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u9700\u6c42\u7684\u89e3\u91ca\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\uff0c\u901a\u8fc7\u9010\u6b65\u6846\u67b6\u6765\u8bc6\u522b\u5065\u5eb7\u5229\u76ca\u76f8\u5173\u8005\u7684\u9700\u6c42\uff0c\u6307\u5bfcLLMs\u751f\u6210\u5b9a\u5236\u7684\u89e3\u91ca\u3002\u9996\u5148\u5f15\u51fa\u4e86\u5065\u5eb7\u5229\u76ca\u76f8\u5173\u8005\u7684\u89e3\u91ca\u9700\u6c42\u548c\u98ce\u683c\u504f\u597d\uff0c\u7136\u540e\u901a\u8fc7\u4f18\u5316LLMs\u7684\u80fd\u529b\uff0c\u5e76\u4f7f\u7528\u53ef\u63a7\u5c5e\u6027\u8c03\u6574\u6765\u751f\u6210\u5b9a\u5236\u8f93\u51fa\uff0c\u6700\u540e\u901a\u8fc7\u5168\u9762\u7684\u5ea6\u91cf\u8bc4\u4f30\u6765\u6539\u8fdb\u751f\u6210\u7684\u6458\u8981\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u9010\u6b65\u6846\u67b6\u548c\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\uff0c\u6210\u529f\u8bc6\u522b\u4e86\u5065\u5eb7\u5229\u76ca\u76f8\u5173\u8005\u7684\u9700\u6c42\uff0c\u5e76\u6307\u5bfcLLMs\u751f\u6210\u4e86\u5b9a\u5236\u7684\u5065\u5eb7\u6a21\u62df\u89e3\u91ca\u3002\u901a\u8fc7\u4f18\u5316\u548c\u8bc4\u4f30\uff0c\u8fdb\u4e00\u6b65\u6539\u8fdb\u4e86\u751f\u6210\u7684\u6458\u8981\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9010\u6b65\u6846\u67b6\uff0c\u65e8\u5728\u8bc6\u522b\u5229\u76ca\u76f8\u5173\u8005\u7684\u9700\u6c42\u5e76\u6307\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u5b9a\u5236\u7684\u5065\u5eb7\u6a21\u62df\u89e3\u91ca\u3002\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\uff0c\u9996\u5148\u5f15\u51fa\u4e86\u4e0d\u540c\u5065\u5eb7\u5229\u76ca\u76f8\u5173\u8005\u7684\u89e3\u91ca\u9700\u6c42\u548c\u98ce\u683c\u504f\u597d\uff0c\u7136\u540e\u901a\u8fc7\u4f18\u5316LLMs\u7684\u80fd\u529b\u6765\u751f\u6210\u5b9a\u5236\u8f93\u51fa\uff08\u4f8b\u5982\u901a\u8fc7\u53ef\u63a7\u5c5e\u6027\u8c03\u6574\uff09\uff0c\u6700\u540e\u901a\u8fc7\u5168\u9762\u7684\u5ea6\u91cf\u8bc4\u4f30\u6765\u8fdb\u4e00\u6b65\u6539\u8fdb\u6458\u8981\u7684\u5b9a\u5236\u751f\u6210\u3002"}}
{"id": "2509.04676", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.04676", "abs": "https://arxiv.org/abs/2509.04676", "authors": ["Sasha Mitts"], "title": "An Approach to Grounding AI Model Evaluations in Human-derived Criteria", "comment": "4 figures, 6 pages, presented at CHI 2025 Workshop on Human-AI\n  Interaction for Augmented Reasoning", "summary": "In the rapidly evolving field of artificial intelligence (AI), traditional\nbenchmarks can fall short in attempting to capture the nuanced capabilities of\nAI models. We focus on the case of physical world modeling and propose a novel\napproach to augment existing benchmarks with human-derived evaluation criteria,\naiming to enhance the interpretability and applicability of model behaviors.\nGrounding our study in the Perception Test and OpenEQA benchmarks, we conducted\nin-depth interviews and large-scale surveys to identify key cognitive skills,\nsuch as Prioritization, Memorizing, Discerning, and Contextualizing, that are\ncritical for both AI and human reasoning. Our findings reveal that participants\nperceive AI as lacking in interpretive and empathetic skills yet hold high\nexpectations for AI performance. By integrating insights from our findings into\nbenchmark design, we offer a framework for developing more human-aligned means\nof defining and measuring progress. This work underscores the importance of\nuser-centered evaluation in AI development, providing actionable guidelines for\nresearchers and practitioners aiming to align AI capabilities with human\ncognitive processes. Our approach both enhances current benchmarking practices\nand sets the stage for future advancements in AI model evaluation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u4eba\u7c7b\u884d\u751f\u7684\u8bc4\u4f30\u6807\u51c6\u6765\u589e\u5f3a\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u7528\u6027\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u53c2\u4e0e\u8005\u8ba4\u4e3a\u4eba\u5de5\u667a\u80fd\u5728\u89e3\u91ca\u80fd\u529b\u548c\u60c5\u611f\u7406\u89e3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4f46\u5bf9\u5176\u6027\u80fd\u5bc4\u4e88\u9ad8\u671f\u671b\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u7528\u6237\u4e2d\u5fc3\u7684\u8bc4\u4f30\u5728\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u8bc4\u4f30\u7684\u672a\u6765\u8fdb\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u672c\u7814\u7a76\u9488\u5bf9\u4eba\u5de5\u667a\u80fd\u5728\u6a21\u578b\u884c\u4e3a\u65b9\u9762\u5b58\u5728\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u7528\u6027\u95ee\u9898\uff0c\u4ee5\u7269\u7406\u4e16\u754c\u5efa\u6a21\u6848\u4f8b\u4e3a\u91cd\u70b9\uff0c\u65e8\u5728\u901a\u8fc7\u4eba\u7c7b\u884d\u751f\u7684\u8bc4\u4f30\u6807\u51c6\u589e\u5f3a\u6a21\u578b\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u7528\u6027\u3002\u53c2\u4e0e\u8005\u8ba4\u4e3a\u4eba\u5de5\u667a\u80fd\u5728\u89e3\u91ca\u80fd\u529b\u548c\u79fb\u60c5\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4f46\u5bf9\u5176\u6027\u80fd\u5bc4\u4e88\u539a\u671b\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u6df1\u5165\u8bbf\u8c08\u548c\u5927\u89c4\u6a21\u8c03\u67e5\uff0c\u4ece\u611f\u77e5\u6d4b\u8bd5\u548cOpenEQA\u57fa\u51c6\u51fa\u53d1\uff0c\u8bc6\u522b\u51fa\u5bf9\u4eba\u5de5\u667a\u80fd\u548c\u4eba\u7c7b\u63a8\u7406\u90fd\u81f3\u5173\u91cd\u8981\u7684\u5173\u952e\u8ba4\u77e5\u6280\u80fd\uff0c\u5982\u4f18\u5148\u7ea7\u5236\u5b9a\u3001\u8bb0\u5fc6\u3001\u8fa8\u522b\u548c\u60c5\u5883\u5316\u7b49\u3002\u5c06\u6240\u5f97\u7ed3\u8bba\u6574\u5408\u5230\u57fa\u51c6\u8bbe\u8ba1\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u53d1\u66f4\u7b26\u5408\u4eba\u7c7b\u9700\u6c42\u7684\u5b9a\u4e49\u548c\u8861\u91cf\u8fdb\u5c55\u7684\u65b9\u5f0f\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u53c2\u4e0e\u8005\u8ba4\u4e3a\u4eba\u5de5\u667a\u80fd\u5728\u89e3\u91ca\u80fd\u529b\u548c\u60c5\u611f\u7406\u89e3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4f46\u5bf9\u5176\u6027\u80fd\u5bc4\u4e88\u8f83\u9ad8\u671f\u671b\u3002\u901a\u8fc7\u878d\u5408\u7814\u7a76\u53d1\u73b0\u7684\u89c1\u89e3\u5230\u57fa\u51c6\u8bbe\u8ba1\u4e2d\uff0c\u4e3a\u5236\u5b9a\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u7684\u5b9a\u4e49\u548c\u8861\u91cf\u8fdb\u5c55\u7684\u6846\u67b6\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u6574\u5408\u4eba\u7c7b\u884d\u751f\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u65b9\u6cd5\u6765\u589e\u5f3a\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u7528\u6027\uff0c\u5f3a\u8c03\u4e86\u7528\u6237\u4e2d\u5fc3\u7684\u8bc4\u4f30\u5728\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u589e\u5f3a\u4e86\u5f53\u524d\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\uff0c\u8fd8\u4e3a\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u8bc4\u4f30\u7684\u672a\u6765\u8fdb\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.04731", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO", "68T05, 90C40, 91A26, 68T42, 93E35", "I.2.11; I.2.6; I.2.8; I.2.9; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.04731", "abs": "https://arxiv.org/abs/2509.04731", "authors": ["Brennen Hill"], "title": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning", "comment": null, "summary": "The convergence of Language models, Agent models, and World models represents\na critical frontier for artificial intelligence. While recent progress has\nfocused on scaling Language and Agent models, the development of sophisticated,\nexplicit World Models remains a key bottleneck, particularly for complex,\nlong-horizon multi-agent tasks. In domains such as robotic soccer, agents\ntrained via standard reinforcement learning in high-fidelity but\nstructurally-flat simulators often fail due to intractable exploration spaces\nand sparse rewards. This position paper argues that the next frontier in\ndeveloping capable agents lies in creating environments that possess an\nexplicit, hierarchical World Model. We contend that this is best achieved\nthrough hierarchical scaffolding, where complex goals are decomposed into\nstructured, manageable subgoals. Drawing evidence from a systematic review of\n2024 research in multi-agent soccer, we identify a clear and decisive trend\ntowards integrating symbolic and hierarchical methods with multi-agent\nreinforcement learning (MARL). These approaches implicitly or explicitly\nconstruct a task-based world model to guide agent learning. We then propose a\nparadigm shift: leveraging Large Language Models to dynamically generate this\nhierarchical scaffold, effectively using language to structure the World Model\non the fly. This language-driven world model provides an intrinsic curriculum,\ndense and meaningful learning signals, and a framework for compositional\nlearning, enabling Agent Models to acquire sophisticated, strategic behaviors\nwith far greater sample efficiency. By building environments with explicit,\nlanguage-configurable task layers, we can bridge the gap between low-level\nreactive behaviors and high-level strategic team play, creating a powerful and\ngeneralizable framework for training the next generation of intelligent agents.", "AI": {"tldr": "\u672c\u6587\u9610\u8ff0\u4e86\u8bed\u8a00\u6a21\u578b\u3001Agent\u6a21\u578b\u548c\u4e16\u754c\u6a21\u578b\u7684\u878d\u5408\u5bf9\u4eba\u5de5\u667a\u80fd\u7684\u91cd\u8981\u6027\uff0c\u5f3a\u8c03\u4e86\u5177\u6709\u5206\u5c42\u4e16\u754c\u6a21\u578b\u7684\u73af\u5883\u5bf9\u57f9\u517b\u667a\u80fdAgent\u7684\u5173\u952e\u6027\u3002\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u548c\u5206\u5c42\u65b9\u6cd5\u4e0e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u53ef\u4ee5\u6784\u5efa\u4efb\u52a1\u4e3a\u57fa\u7840\u7684\u4e16\u754c\u6a21\u578b\u6765\u6307\u5bfcAgent\u5b66\u4e60\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u751f\u6210\u5206\u5c42\u811a\u624b\u67b6\uff0c\u4f7f\u5f97Agent\u6a21\u578b\u80fd\u591f\u4ee5\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\u83b7\u5f97\u590d\u6742\u7684\u6218\u7565\u884c\u4e3a\u3002", "motivation": "\u8bba\u6587\u6307\u51fa\u4e86\u53d1\u5c55\u5177\u6709\u660e\u786e\u7684\u3001\u5206\u5c42\u4e16\u754c\u6a21\u578b\u7684\u73af\u5883\u5bf9\u4e8e\u5f00\u53d1\u80fd\u529b\u5f3a\u5927\u7684Agent\u7684\u91cd\u8981\u6027\u3002\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5728\u7ed3\u6784\u5e73\u5766\u7684\u6a21\u62df\u5668\u4e2d\u5f80\u5f80\u7531\u4e8e\u63a2\u7d22\u7a7a\u95f4\u8fc7\u5927\u548c\u5956\u52b1\u7a00\u758f\u800c\u5931\u8d25\u3002\u4f5c\u8005\u8ba4\u4e3a\u4e0b\u4e00\u4e2a\u53d1\u5c55\u524d\u6cbf\u5728\u4e8e\u521b\u5efa\u5177\u6709\u663e\u5f0f\u3001\u5206\u5c42\u4e16\u754c\u6a21\u578b\u7684\u73af\u5883\uff0c\u901a\u8fc7\u5206\u89e3\u590d\u6742\u76ee\u6807\u4e3a\u7ed3\u6784\u5316\u5b50\u76ee\u6807\u5b9e\u73b0\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u5ba1\u96052024\u5e74\u7684\u591a\u667a\u80fd\u4f53\u8db3\u7403\u7814\u7a76\uff0c\u8bc6\u522b\u51fa\u4e00\u79cd\u660e\u663e\u548c\u51b3\u5b9a\u6027\u7684\u8d8b\u52bf\uff0c\u5373\u5c06\u7b26\u53f7\u548c\u5206\u5c42\u65b9\u6cd5\u4e0e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u3002\u8fd9\u4e9b\u65b9\u6cd5\u9690\u5f0f\u6216\u663e\u5f0f\u6784\u5efa\u4e86\u57fa\u4e8e\u4efb\u52a1\u7684\u4e16\u754c\u6a21\u578b\u4ee5\u6307\u5bfcAgent\u5b66\u4e60\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5373\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u52a8\u6001\u751f\u6210\u8fd9\u79cd\u5206\u5c42\u811a\u624b\u67b6\uff0c\u6709\u6548\u5229\u7528\u8bed\u8a00\u6765\u5b9e\u65f6\u6784\u5efa\u4e16\u754c\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u548c\u5206\u5c42\u65b9\u6cd5\u4e0e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u53ef\u4ee5\u6784\u5efa\u4efb\u52a1\u4e3a\u57fa\u7840\u7684\u4e16\u754c\u6a21\u578b\u6765\u6307\u5bfcAgent\u5b66\u4e60\u3002\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u751f\u6210\u5206\u5c42\u811a\u624b\u67b6\u7684\u65b0\u8303\u5f0f\uff0c\u4f7f\u5f97Agent\u6a21\u578b\u80fd\u591f\u4ee5\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\u83b7\u5f97\u590d\u6742\u7684\u6218\u7565\u884c\u4e3a\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u53d1\u5c55\u5177\u6709\u660e\u786e\u5206\u5c42\u4e16\u754c\u6a21\u578b\u7684\u73af\u5883\u5bf9\u57f9\u517b\u80fd\u529b\u5f3a\u5927\u7684\u667a\u80fdAgent\u7684\u91cd\u8981\u6027\u3002\u901a\u8fc7\u5c06\u590d\u6742\u76ee\u6807\u5206\u89e3\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u7ba1\u7406\u7684\u5b50\u76ee\u6807\uff0c\u53ef\u4ee5\u5b9e\u73b0\u521b\u5efa\u5177\u6709\u5206\u5c42\u4e16\u754c\u6a21\u578b\u7684\u73af\u5883\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5373\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u751f\u6210\u8fd9\u79cd\u5c42\u6b21\u5316\u811a\u624b\u67b6\uff0c\u4ece\u800c\u6709\u6548\u5229\u7528\u8bed\u8a00\u6765\u5b9e\u65f6\u6784\u5efa\u4e16\u754c\u6a21\u578b\u3002\u901a\u8fc7\u521b\u5efa\u5177\u6709\u660e\u786e\u7684\u3001\u53ef\u914d\u7f6e\u8bed\u8a00\u4efb\u52a1\u5c42\u7684\u73af\u5883\uff0c\u53ef\u4ee5\u586b\u8865\u4f4e\u5c42\u53cd\u5e94\u884c\u4e3a\u548c\u9ad8\u5c42\u6218\u7565\u56e2\u961f\u534f\u4f5c\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u8bad\u7ec3\u4e0b\u4e00\u4ee3\u667a\u80fdAgent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u4e14\u901a\u7528\u7684\u6846\u67b6\u3002"}}
{"id": "2509.04791", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04791", "abs": "https://arxiv.org/abs/2509.04791", "authors": ["Yuan Sui", "Yanming Zhang", "Yi Liao", "Yu Gu", "Guohua Tang", "Zhongqian Sun", "Wei Yang", "Bryan Hooi"], "title": "What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking", "comment": "arXiv admin note: text overlap with arXiv:2508.21365", "summary": "Large language models (LLMs) excel at processing information reactively but\nlack the ability to systemically explore hypothetical futures. They cannot ask,\n\"what if we take this action? how will it affect the final outcome\" and\nforecast its potential consequences before acting. This critical gap limits\ntheir utility in dynamic, high-stakes scenarios like strategic planning, risk\nassessment, and real-time decision making. To bridge this gap, we propose\nWiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.\nOur approach integrates What-If Analysis (WIA), a systematic approach for\nevaluating hypothetical scenarios by changing input variables. By leveraging\nenvironmental feedback via reinforcement learning, WiA-LLM moves beyond\nreactive thinking. It dynamically simulates the outcomes of each potential\naction, enabling the model to anticipate future states rather than merely react\nto the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a\ncomplex multiplayer game environment characterized by rapid state changes and\nintricate interactions. The game's real-time state changes require precise\nmulti-step consequence prediction, making it an ideal testbed for our approach.\nExperimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy\nin forecasting game-state changes (up to two times gain over baselines). The\nmodel shows particularly significant gains in high-difficulty scenarios where\naccurate foresight is critical. To our knowledge, this is the first work to\nformally explore and integrate what-if analysis capabilities within LLMs.\nWiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,\nproviding a scalable framework for robust decision-making in dynamic\nenvironments with broad implications for strategic applications.", "AI": {"tldr": "WiA-LLM integrates What-If Analysis (WIA) into Large Language Models (LLMs) to enable proactive thinking, anticipate future outcomes, and make informed decisions. Experimental validation in a multiplayer game environment shows a remarkable 74.2% accuracy in forecasting game-state changes, surpassing baselines by up to two times. This work is the first to formally explore and integrate what-if analysis capabilities within LLMs, paving the way for proactive reasoning and robust decision-making in dynamic environments.", "motivation": "Large language models excel at reactive processing but lack the ability to explore hypothetical futures and anticipate consequences before acting, limiting their utility in dynamic and high-stakes scenarios. The motivation behind this work is to bridge this critical gap by introducing proactive thinking capabilities to LLMs through WiA-LLM, enabling them to make informed decisions in challenging and rapidly changing environments such as strategic planning, risk assessment, and real-time decision-making.", "method": "The paper proposes WiA-LLM, a paradigm that integrates What-If Analysis (WIA) to empower LLMs with proactive thinking abilities. WiA-LLM leverages environmental feedback through reinforcement learning to simulate potential outcomes of actions and anticipate future states. The approach is validated in a multiplayer game environment that requires accurate multi-step consequence prediction, demonstrating remarkable forecasting accuracy of 74.2% in game-state changes, surpassing baselines by up to two times.", "result": "Experimental results show that WiA-LLM achieves a significant 74.2% accuracy in forecasting game-state changes, particularly excelling in high-difficulty scenarios. The model's proactive reasoning capabilities through What-If Analysis demonstrate a fundamental advance in LLMs, offering a scalable framework for robust decision-making in dynamic environments.", "conclusion": "WiA-LLM introduces proactive thinking capabilities to Large Language Models (LLMs) through What-If Analysis (WiA), enabling them to anticipate future outcomes and make informed decisions. Experimental results in a multiplayer game environment demonstrate significant improvements in forecasting game-state changes, especially in high-difficulty scenarios. This work represents the first formal exploration and integration of what-if analysis within LLMs, paving the way for proactive reasoning and robust decision-making in dynamic environments."}}
{"id": "2509.04809", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.04809", "abs": "https://arxiv.org/abs/2509.04809", "authors": ["Haechang Kim", "Hao Chen", "Can Li", "Jong Min Lee"], "title": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models", "comment": "31 pages total", "summary": "Explainable Reinforcement Learning (XRL) has emerged as a promising approach\nin improving the transparency of Reinforcement Learning (RL) agents. However,\nthere remains a gap between complex RL policies and domain experts, due to the\nlimited comprehensibility of XRL results and isolated coverage of current XRL\napproaches that leave users uncertain about which tools to employ. To address\nthese challenges, we introduce TalkToAgent, a multi-agent Large Language Models\n(LLM) framework that delivers interactive, natural language explanations for RL\npolicies. The architecture with five specialized LLM agents (Coordinator,\nExplainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically\nmap user queries to relevant XRL tools and clarify an agent's actions in terms\nof either key state variables, expected outcomes, or counterfactual\nexplanations. Moreover, our approach extends previous counterfactual\nexplanations by deriving alternative scenarios from qualitative behavioral\ndescriptions, or even new rule-based policies. We validated TalkToAgent on\nquadruple-tank process control problem, a well-known nonlinear control\nbenchmark. Results demonstrated that TalkToAgent successfully mapped user\nqueries into XRL tasks with high accuracy, and coder-debugger interactions\nminimized failures in counterfactual generation. Furthermore, qualitative\nevaluation confirmed that TalkToAgent effectively interpreted agent's actions\nand contextualized their meaning within the problem domain.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u4e86TalkToAgent\uff0c\u65e8\u5728\u63d0\u4f9bRL\u7b56\u7565\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002\u901a\u8fc7\u4e94\u4e2a\u4e13\u95e8\u7684LLM\u4ee3\u7406\uff0cTalkToAgent\u80fd\u591f\u4ea4\u4e92\u6027\u5730\u89e3\u91caRL\u7b56\u7565\uff0c\u5e76\u6210\u529f\u5c06\u7528\u6237\u67e5\u8be2\u6620\u5c04\u5230XRL\u4efb\u52a1\u3002\u9a8c\u8bc1\u7ed3\u679c\u8868\u660e\uff0cTalkToAgent\u5728\u89e3\u91ca\u4ee3\u7406\u884c\u4e3a\u65b9\u9762\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u6709\u6548\u5c06\u5176\u610f\u4e49\u653e\u7f6e\u4e8e\u95ee\u9898\u9886\u57df\u5185\u3002", "motivation": "XRL\u5728\u63d0\u9ad8RL\u4ee3\u7406\u900f\u660e\u5ea6\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u590d\u6742RL\u653f\u7b56\u4e0e\u9886\u57df\u4e13\u5bb6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u73b0\u6709XRL\u65b9\u6cd5\u7684\u53ef\u7406\u89e3\u6027\u6709\u9650\u4e14\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u7528\u6237\u4e0d\u786e\u5b9a\u4f7f\u7528\u54ea\u4e9b\u5de5\u5177\u3002", "method": "\u5f15\u5165\u4e86TalkToAgent\uff0c\u4e00\u4e2a\u5305\u542b\u4e94\u4e2a\u4e13\u95e8\u7684LLM\u4ee3\u7406\uff08\u534f\u8c03\u5458\u3001\u89e3\u91ca\u5668\u3001\u7f16\u7801\u5668\u3001\u8bc4\u4f30\u5668\u548c\u8c03\u8bd5\u5668\uff09\u7684\u67b6\u6784\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u6027\u5730\u4e3aRL\u7b56\u7565\u63d0\u4f9b\u89e3\u91ca\u3002", "result": "\u901a\u8fc7\u5728\u56db\u91cd\u7f50\u8fc7\u7a0b\u63a7\u5236\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793aTalkToAgent\u6210\u529f\u5c06\u7528\u6237\u67e5\u8be2\u6620\u5c04\u5230XRL\u4efb\u52a1\uff0c\u5e76\u6700\u5927\u9650\u5ea6\u51cf\u5c11\u4e86\u53cd\u4e8b\u5b9e\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5931\u8d25\u3002\u5b9a\u6027\u8bc4\u4f30\u8bc1\u5b9e\uff0cTalkToAgent\u6709\u6548\u5730\u89e3\u91ca\u4e86\u4ee3\u7406\u7684\u884c\u4e3a\u5e76\u5c06\u5176\u610f\u4e49\u7f6e\u4e8e\u95ee\u9898\u9886\u57df\u5185\u3002", "conclusion": "TalkToAgent\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u4f9bRL\u7b56\u7565\u7684\u4e92\u52a8\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cTalkToAgent\u6210\u529f\u5c06\u7528\u6237\u67e5\u8be2\u6620\u5c04\u5230XRL\u4efb\u52a1\uff0c\u9ad8\u51c6\u786e\u5ea6\u5730\u6267\u884c\u4e86\u8fd9\u4e00\u4efb\u52a1\uff0c\u5e76\u6700\u5927\u9650\u5ea6\u51cf\u5c11\u4e86\u53cd\u4e8b\u5b9e\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5931\u8d25\u3002\u5b9a\u6027\u8bc4\u4ef7\u8bc1\u5b9e\uff0cTalkToAgent\u6709\u6548\u5730\u89e3\u91ca\u4e86\u4ee3\u7406\u7684\u884c\u4e3a\u5e76\u5c06\u5176\u610f\u4e49\u7f6e\u4e8e\u95ee\u9898\u9886\u57df\u5185\u3002"}}
{"id": "2509.04847", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04847", "abs": "https://arxiv.org/abs/2509.04847", "authors": ["Mukul Singh", "Arjun Radhakrishna", "Sumit Gulwani"], "title": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory", "comment": "9 pages", "summary": "Language models are increasingly deployed in interactive online environments,\nfrom personal chat assistants to domain-specific agents, raising questions\nabout their cooperative and competitive behavior in multi-party settings. While\nprior work has examined language model decision-making in isolated or\nshort-term game-theoretic contexts, these studies often neglect long-horizon\ninteractions, human-model collaboration, and the evolution of behavioral\npatterns over time. In this paper, we investigate the dynamics of language\nmodel behavior in the iterated prisoner's dilemma (IPD), a classical framework\nfor studying cooperation and conflict. We pit model-based agents against a\nsuite of 240 well-established classical strategies in an Axelrod-style\ntournament and find that language models achieve performance on par with, and\nin some cases exceeding, the best-known classical strategies. Behavioral\nanalysis reveals that language models exhibit key properties associated with\nstrong cooperative strategies - niceness, provocability, and generosity while\nalso demonstrating rapid adaptability to changes in opponent strategy mid-game.\nIn controlled \"strategy switch\" experiments, language models detect and respond\nto shifts within only a few rounds, rivaling or surpassing human adaptability.\nThese results provide the first systematic characterization of long-term\ncooperative behaviors in language model agents, offering a foundation for\nfuture research into their role in more complex, mixed human-AI social\nenvironments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u8fed\u4ee3\u56da\u5f92\u56f0\u5883\u4e2d\u7684\u884c\u4e3a\u52a8\u6001\uff0c\u53d1\u73b0\u5b83\u4eec\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u5408\u4f5c\u7b56\u7565\u7279\u6027\uff0c\u5bf9\u5bf9\u624b\u7b56\u7565\u7684\u53d8\u5316\u5177\u6709\u5feb\u901f\u9002\u5e94\u80fd\u529b\uff0c\u751a\u81f3\u8d85\u8d8a\u4eba\u7c7b\u7684\u9002\u5e94\u6027\u3002\u901a\u8fc7\u4e0e\u7ecf\u5178\u7b56\u7565\u5bf9\u6297\u5b9e\u9a8c\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u53ef\u4ee5\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u6700\u4f73\u7ecf\u5178\u7b56\u7565\u7684\u6c34\u5e73\u3002\u7ed3\u679c\u4e3a\u672a\u6765\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u66f4\u590d\u6742\u793e\u4f1a\u73af\u5883\u4e2d\u7684\u89d2\u8272\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u5ffd\u7565\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u4e92\u52a8\u3001\u4eba-\u6a21\u578b\u5408\u4f5c\u548c\u884c\u4e3a\u6a21\u5f0f\u6f14\u53d8\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528\uff0c\u672c\u6587\u9488\u5bf9\u6b64\u5c55\u5f00\u63a2\u7a76\u3002\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u8fed\u4ee3\u56da\u5f92\u56f0\u5883\u4e2d\u7684\u884c\u4e3a\u52a8\u6001\u53ef\u4ee5\u63ed\u793a\u5b83\u4eec\u5728\u5408\u4f5c\u4e0e\u51b2\u7a81\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5176\u5728\u66f4\u590d\u6742\u3001\u6df7\u5408\u4eba\u5de5\u667a\u80fd\u793e\u4f1a\u73af\u5883\u4e2d\u7684\u89d2\u8272\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5728\u8fed\u4ee3\u56da\u5f92\u56f0\u5883\u4e2d\u4e0e240\u4e2a\u7ecf\u5178\u7b56\u7565\u8fdb\u884c\u5bf9\u6297\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u4e0e\u6700\u4f73\u7ecf\u5178\u7b56\u7565\u76f8\u5f53\u751a\u81f3\u8d85\u8fc7\u7684\u6027\u80fd\u3002\u5bf9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u884c\u4e3a\u5206\u6790\uff0c\u63ed\u793a\u51fa\u5176\u8868\u73b0\u51fa\u5f3a\u5927\u5408\u4f5c\u7b56\u7565\u7684\u5173\u952e\u7279\u6027\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u5bf9\u5bf9\u624b\u7b56\u7565\u53d8\u5316\u7684\u5feb\u901f\u9002\u5e94\u80fd\u529b\u3002\u5728\u201c\u7b56\u7565\u5207\u6362\u201d\u5b9e\u9a8c\u4e2d\uff0c\u8bed\u8a00\u6a21\u578b\u80fd\u5728\u51e0\u8f6e\u5185\u63a2\u6d4b\u548c\u56de\u5e94\u5bf9\u624b\u7b56\u7565\u53d8\u5316\uff0c\u4e0e\u751a\u81f3\u8d85\u8d8a\u4eba\u7c7b\u7684\u9002\u5e94\u6027\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u5728\u8fed\u4ee3\u56da\u5f92\u56f0\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u4e0e\u7ecf\u5178\u7b56\u7565\u76f8\u5f53\u751a\u81f3\u9886\u5148\u7684\u6027\u80fd\u3002\u884c\u4e3a\u5206\u6790\u8868\u660e\uff0c\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u5f3a\u5927\u5408\u4f5c\u7b56\u7565\u7684\u7279\u6027\uff0c\u8fd8\u5c55\u73b0\u51fa\u5bf9\u5bf9\u624b\u7b56\u7565\u53d8\u5316\u7684\u5feb\u901f\u9002\u5e94\u80fd\u529b\u3002\u5728\u201c\u7b56\u7565\u5207\u6362\u201d\u5b9e\u9a8c\u4e2d\uff0c\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u63a2\u6d4b\u548c\u56de\u5e94\u5bf9\u624b\u7b56\u7565\u53d8\u5316\u7684\u80fd\u529b\uff0c\u4e0e\u4eba\u7c7b\u7684\u9002\u5e94\u6027\u76f8\u5ab2\u7f8e\u751a\u81f3\u66f4\u80dc\u4e00\u7b79\u3002", "conclusion": "\u672c\u6587\u8c03\u67e5\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u8fed\u4ee3\u56da\u5f92\u56f0\u5883\u4e2d\u7684\u884c\u4e3a\u52a8\u6001\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u4e0e\u5f3a\u5927\u5408\u4f5c\u7b56\u7565\u76f8\u5173\u7684\u5173\u952e\u7279\u6027\uff0c\u540c\u65f6\u5bf9\u5bf9\u624b\u7b56\u7565\u7684\u53d8\u5316\u8868\u73b0\u51fa\u8fc5\u901f\u7684\u9002\u5e94\u80fd\u529b\u3002\u8bed\u8a00\u6a21\u578b\u5728\u63a7\u5236\u7684\u201c\u7b56\u7565\u5207\u6362\u201d\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u63a2\u6d4b\u548c\u56de\u5e94\u5bf9\u624b\u7b56\u7565\u53d8\u5316\u7684\u80fd\u529b\uff0c\u8fdc\u8d85\u4eba\u7c7b\u7684\u9002\u5e94\u6027\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u957f\u671f\u5408\u4f5c\u884c\u4e3a\u65b9\u9762\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7279\u5f81\uff0c\u4e3a\u672a\u6765\u63a2\u8ba8\u5b83\u4eec\u5728\u66f4\u590d\u6742\u7684\u6df7\u5408\u4eba\u5de5\u667a\u80fd\u793e\u4f1a\u73af\u5883\u4e2d\u7684\u89d2\u8272\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.04871", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04871", "abs": "https://arxiv.org/abs/2509.04871", "authors": ["Krittanon Kaewtawee", "Wachiravit Modecrua", "Krittin Pachtrachai", "Touchapon Kraisingkorn"], "title": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets for Telesales", "comment": "10 pages, 4 figures", "summary": "Recent advances in language and speech modelling have made it possible to\nbuild autonomous voice assistants that understand and generate human dialogue\nin real time. These systems are increasingly being deployed in domains such as\ncustomer service and healthcare care, where they can automate repetitive tasks,\nreduce operational costs, and provide constant support around the clock. In\nthis paper, we present a general methodology for cloning a conversational voice\nAI agent from a corpus of call recordings. Although the case study described in\nthis paper uses telesales data to illustrate the approach, the underlying\nprocess generalizes to any domain where call transcripts are available. Our\nsystem listens to customers over the telephone, responds with a synthetic\nvoice, and follows a structured playbook learned from top performing human\nagents. We describe the domain selection, knowledge extraction, and prompt\nengineering used to construct the agent, integrating automatic speech\nrecognition, a large language model based dialogue manager, and text to speech\nsynthesis into a streaming inference pipeline. The cloned agent is evaluated\nagainst human agents on a rubric of 22 criteria covering introduction, product\ncommunication, sales drive, objection handling, and closing. Blind tests show\nthat the AI agent approaches human performance in routine aspects of the call\nwhile underperforming in persuasion and objection handling. We analyze these\nshortcomings and refine the prompt accordingly. The paper concludes with design\nlessons and avenues for future research, including large scale simulation and\nautomated evaluation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u5982\u4f55\u4ece\u7535\u8bdd\u8bb0\u5f55\u8bed\u6599\u5e93\u4e2d\u514b\u9686\u5bf9\u8bdd\u5f0f\u8bed\u97f3AI\u4ee3\u7406\u7684\u65b9\u6cd5\uff0c\u8ba8\u8bba\u4e86\u7cfb\u7edf\u6784\u5efa\u8fc7\u7a0b\u548c\u8bc4\u4f30\u7ed3\u679c\u3002\u7814\u7a76\u53d1\u73b0AI\u4ee3\u7406\u5728\u4f8b\u884c\u901a\u8bdd\u65b9\u9762\u63a5\u8fd1\u4eba\u7c7b\u8868\u73b0\uff0c\u4f46\u5728\u4e00\u4e9b\u5173\u952e\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u6848\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u548c\u8bed\u97f3\u5efa\u6a21\u7684\u8fdb\u5c55\u4f7f\u5f97\u6784\u5efa\u80fd\u591f\u5b9e\u65f6\u7406\u89e3\u548c\u751f\u6210\u4eba\u7c7b\u5bf9\u8bdd\u7684\u81ea\u4e3b\u8bed\u97f3\u52a9\u624b\u6210\u4e3a\u53ef\u80fd\u3002\u8fd9\u4e9b\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u90e8\u7f72\u5728\u5ba2\u6237\u670d\u52a1\u548c\u533b\u7597\u4fdd\u5065\u7b49\u9886\u57df\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u91cd\u590d\u4efb\u52a1\u3001\u964d\u4f4e\u8fd0\u8425\u6210\u672c\uff0c\u5e76\u63d0\u4f9b\u5168\u5929\u5019\u7684\u6301\u7eed\u652f\u6301\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4ece\u7535\u8bdd\u8bb0\u5f55\u8bed\u6599\u5e93\u4e2d\u514b\u9686\u5bf9\u8bdd\u5f0f\u8bed\u97f3AI\u4ee3\u7406\u7684\u4e00\u822c\u65b9\u6cd5\u3002\u7cfb\u7edf\u901a\u8fc7\u76d1\u542c\u7535\u8bdd\u5ba2\u6237\u3001\u4f7f\u7528\u5408\u6210\u8bed\u97f3\u56de\u5e94\u5e76\u9075\u5faa\u4ece\u8868\u73b0\u4f18\u8d8a\u7684\u4eba\u7c7b\u4ee3\u7406\u5b66\u4e60\u800c\u6765\u7684\u7ed3\u6784\u5316\u6307\u5bfc\u3002\u63cf\u8ff0\u4e86\u57df\u9009\u62e9\u3001\u77e5\u8bc6\u63d0\u53d6\u548c\u63d0\u793a\u5de5\u7a0b\u7b49\u6784\u5efa\u4ee3\u7406\u7684\u65b9\u6cd5\uff0c\u5e76\u6574\u5408\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u3001\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u7ba1\u7406\u5668\u4ee5\u53ca\u6587\u672c\u8f6c\u8bed\u97f3\u5408\u6210\u6210\u4e3a\u6d41\u5f0f\u63a8\u7406\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7\u572822\u9879\u6807\u51c6\u8986\u76d6\u4ecb\u7ecd\u3001\u4ea7\u54c1\u6c9f\u901a\u3001\u9500\u552e\u52a8\u529b\u3001\u5f02\u8bae\u5904\u7406\u548c\u7ed3\u675f\u7b49\u65b9\u9762\u5bf9\u514b\u9686\u4ee3\u7406\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aAI\u4ee3\u7406\u5728\u901a\u8bdd\u7684\u4f8b\u884c\u65b9\u9762\u63a5\u8fd1\u4eba\u7c7b\u8868\u73b0\uff0c\u4f46\u5728\u8bf4\u670d\u529b\u548c\u5f02\u8bae\u5904\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u4e0d\u8db3\u4e4b\u5904\u5e76\u76f8\u5e94\u8c03\u6574\u63d0\u793a\uff0c\u4e0d\u65ad\u6539\u8fdbAI\u4ee3\u7406\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4ece\u901a\u8bdd\u8bb0\u5f55\u8bed\u6599\u5e93\u4e2d\u514b\u9686\u5bf9\u8bdd\u5f0f\u8bed\u97f3AI\u4ee3\u7406\u7684\u4e00\u822c\u65b9\u6cd5\u8bba\u3002\u901a\u8fc7\u5bf9\u7535\u8bdd\u8bb0\u5f55\u8fdb\u884c\u76d1\u542c\u3001\u4f7f\u7528\u5408\u6210\u8bed\u97f3\u8fdb\u884c\u56de\u5e94\uff0c\u5e76\u9075\u5faa\u4ece\u8868\u73b0\u4f18\u8d8a\u7684\u4eba\u7c7b\u4ee3\u7406\u5b66\u4e60\u800c\u6765\u7684\u7ed3\u6784\u5316\u6307\u5bfc\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u65e5\u5e38\u901a\u8bdd\u7684\u65b9\u65b9\u9762\u9762\uff0cAI\u4ee3\u7406\u63a5\u8fd1\u4eba\u7c7b\u8868\u73b0\uff0c\u4f46\u5728\u8bf4\u670d\u529b\u548c\u5f02\u8bae\u5904\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u4e0d\u8db3\u4e4b\u5904\u5e76\u76f8\u5e94\u8c03\u6574\u63d0\u793a\uff0c\u8bba\u6587\u5f97\u51fa\u8bbe\u8ba1\u7ecf\u9a8c\u6559\u8bad\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u5927\u89c4\u6a21\u6a21\u62df\u548c\u81ea\u52a8\u8bc4\u4f30\u3002"}}
{"id": "2509.04876", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04876", "abs": "https://arxiv.org/abs/2509.04876", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Xiaofei Sun", "Keze Wang"], "title": "OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration", "comment": "Accepted at EMNLP 2025 (Long Paper)", "summary": "This paper introduces OSC (Orchestrating Cognitive Synergy), a\nknowledge-aware adaptive collaboration framework designed to enhance cognitive\nsynergy in multi-agent systems with large language models. While prior work has\nadvanced agent selection and result aggregation, efficient linguistic\ninteractions for deep collaboration among expert agents remain a critical\nbottleneck. OSC addresses this gap as a pivotal intermediate layer between\nselection and aggregation, introducing Collaborator Knowledge Models (CKM) to\nenable each agent to dynamically perceive its collaborators' cognitive states.\nThrough real-time cognitive gap analysis, agents adaptively adjust\ncommunication behaviors, including content focus, detail level, and expression\nstyle, using learned strategies. Experiments on complex reasoning and\nproblem-solving benchmarks demonstrate that OSC significantly improves task\nperformance and communication efficiency, transforming \"parallel-working\nindividuals'' into a \"deeply collaborative cognitive team.'' This framework not\nonly optimizes multi-agent collaboration but also offers new insights into LLM\nagent interaction behaviors.", "AI": {"tldr": "OSC\u662f\u4e00\u79cd\u77e5\u8bc6\u611f\u77e5\u81ea\u9002\u5e94\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165CKM\u5b9e\u73b0Agent\u4e4b\u95f4\u7684\u8ba4\u77e5\u534f\u540c\u3002\u5b9e\u9a8c\u8bc1\u660eOSC\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\uff0c\u5c06\u4e2a\u4f53\u8f6c\u53d8\u4e3a\u6df1\u5ea6\u534f\u4f5c\u8ba4\u77e5\u56e2\u961f\uff0c\u4e3aLLM\u4ee3\u7406\u7684\u4e92\u52a8\u884c\u4e3a\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u867d\u7136\u63a8\u8fdb\u4e86Agent\u9009\u62e9\u548c\u7ed3\u679c\u805a\u5408\uff0c\u4f46\u5728\u4e13\u5bb6Agent\u4e4b\u95f4\u8fdb\u884c\u9ad8\u6548\u7684\u8bed\u8a00\u4ea4\u4e92\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u74f6\u9888\u3002OSC\u4f5c\u4e3a\u9009\u62e9\u548c\u805a\u5408\u4e4b\u95f4\u7684\u5173\u952e\u4e2d\u95f4\u5c42\uff0c\u586b\u8865\u4e86\u8fd9\u4e00\u7f3a\u53e3\uff0c\u4e3a\u5b9e\u73b0\u6df1\u5ea6\u534f\u4f5c\u5f15\u5165\u4e86Collaborator Knowledge Models\uff08CKM\uff09\u3002", "method": "\u4ecb\u7ecd\u4e86OSC\u6846\u67b6\uff0c\u5f15\u5165Collaborator Knowledge Models\uff08CKM\uff09\uff0c\u4f7f\u6bcf\u4e2aAgent\u80fd\u591f\u52a8\u6001\u611f\u77e5\u5176\u534f\u4f5c\u8005\u7684\u8ba4\u77e5\u72b6\u6001\u3002\u901a\u8fc7\u5b9e\u65f6\u8ba4\u77e5\u5dee\u8ddd\u5206\u6790\uff0cAgent\u53ef\u4ee5\u81ea\u9002\u5e94\u6027\u5730\u8c03\u6574\u901a\u4fe1\u884c\u4e3a\uff0c\u5305\u62ec\u5185\u5bb9\u7126\u70b9\u3001\u8be6\u7ec6\u7ea7\u522b\u548c\u8868\u8fbe\u98ce\u683c\uff0c\u4ee5\u589e\u5f3a\u6df1\u5ea6\u534f\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eOSC\u6846\u67b6\u663e\u8457\u6539\u5584\u4e86\u4efb\u52a1\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\uff0c\u5c06\u4e2a\u4f53\u8f6c\u53d8\u4e3a\u6df1\u5ea6\u534f\u4f5c\u8ba4\u77e5\u56e2\u961f\u3002", "conclusion": "OSC\uff08Orchestrating Cognitive Synergy\uff09\u662f\u4e00\u79cd\u77e5\u8bc6\u611f\u77e5\u81ea\u9002\u5e94\u534f\u4f5c\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3a\u5177\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591aAgent\u7cfb\u7edf\u4e2d\u7684\u8ba4\u77e5\u534f\u540c\u3002\u5b9e\u9a8c\u8bc1\u660eOSC\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\uff0c\u4f7f\u201c\u5e76\u884c\u5de5\u4f5c\u7684\u4e2a\u4f53\u201d\u8f6c\u53d8\u4e3a\u201c\u6df1\u5ea6\u534f\u4f5c\u8ba4\u77e5\u56e2\u961f\u201d\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u4f18\u5316\u4e86\u591aAgent\u534f\u4f5c\uff0c\u8fd8\u4e3aLLM\u4ee3\u7406\u7684\u4e92\u52a8\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.04908", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.04908", "abs": "https://arxiv.org/abs/2509.04908", "authors": ["Hongyi Jing", "Jiafu Chen", "Chen Rao", "Ziqiang Dang", "Jiajie Teng", "Tianyi Chu", "Juncheng Mo", "Shuo Fang", "Huaizhong Lin", "Rui Lv", "Chenguang Ma", "Lei Zhao"], "title": "SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing", "comment": null, "summary": "The existing Multimodal Large Language Models (MLLMs) for GUI perception have\nmade great progress. However, the following challenges still exist in prior\nmethods: 1) They model discrete coordinates based on text autoregressive\nmechanism, which results in lower grounding accuracy and slower inference\nspeed. 2) They can only locate predefined sets of elements and are not capable\nof parsing the entire interface, which hampers the broad application and\nsupport for downstream tasks. To address the above issues, we propose\nSparkUI-Parser, a novel end-to-end framework where higher localization\nprecision and fine-grained parsing capability of the entire interface are\nsimultaneously achieved. Specifically, instead of using probability-based\ndiscrete modeling, we perform continuous modeling of coordinates based on a\npre-trained Multimodal Large Language Model (MLLM) with an additional token\nrouter and coordinate decoder. This effectively mitigates the limitations\ninherent in the discrete output characteristics and the token-by-token\ngeneration process of MLLMs, consequently boosting both the accuracy and the\ninference speed. To further enhance robustness, a rejection mechanism based on\na modified Hungarian matching algorithm is introduced, which empowers the model\nto identify and reject non-existent elements, thereby reducing false positives.\nMoreover, we present ScreenParse, a rigorously constructed benchmark to\nsystematically assess structural perception capabilities of GUI models across\ndiverse scenarios. Extensive experiments demonstrate that our approach\nconsistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,\nCAGUI-Grounding and ScreenParse benchmarks. The resources are available at\nhttps://github.com/antgroup/SparkUI-Parser.", "AI": {"tldr": "\u63d0\u51fa\u4e86SparkUI-Parser\uff0c\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u8fde\u7eed\u5750\u6807\u5efa\u6a21\u548c\u62d2\u7edd\u673a\u5236\u63d0\u9ad8GUI\u611f\u77e5\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u901f\u5ea6\u3002\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u8d44\u6e90\u53ef\u5728GitHub\u83b7\u53d6\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728GUI\u611f\u77e5\u65b9\u9762\u53d6\u5f97\u4e86\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u6311\u6218\uff0c\u5982\u4f4e\u5b9a\u4f4d\u7cbe\u5ea6\u3001\u8f83\u6162\u7684\u63a8\u7406\u901f\u5ea6\u548c\u65e0\u6cd5\u89e3\u6790\u6574\u4e2a\u754c\u9762\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u901f\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684Multimodal Large Language Model (MLLM)\u8fdb\u884c\u8fde\u7eed\u5750\u6807\u5efa\u6a21\uff0c\u914d\u5907\u989d\u5916\u7684\u4ee4\u724c\u8def\u7531\u5668\u548c\u5750\u6807\u89e3\u7801\u5668\uff0c\u6709\u6548\u5730\u7f13\u89e3\u4e86\u79bb\u6563\u8f93\u51fa\u7279\u6027\u548cMLLM\u9010\u4ee4\u724c\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5c40\u9650\u6027\u3002\u540c\u65f6\u5f15\u5165\u57fa\u4e8e\u4fee\u6539\u540e\u7684\u5308\u7259\u5229\u5339\u914d\u7b97\u6cd5\u7684\u62d2\u7edd\u673a\u5236\uff0c\u8bc6\u522b\u548c\u62d2\u7edd\u4e0d\u5b58\u5728\u7684\u5143\u7d20\uff0c\u51cf\u5c11\u8bef\u62a5\u3002\u63d0\u51fa\u4e86\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30GUI\u6a21\u578b\u7ed3\u6784\u611f\u77e5\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5ScreenParse\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cSparkUI-Parser\u65b9\u6cd5\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002\u8d44\u6e90\u53ef\u5728https://github.com/antgroup/SparkUI-Parser\u83b7\u53d6\u3002", "conclusion": "\u63d0\u51fa\u4e86SparkUI-Parser\uff0c\u4e00\u4e2a\u65b0\u9896\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u6574\u4e2a\u754c\u9762\u7684\u7ec6\u7c92\u5ea6\u89e3\u6790\u80fd\u529b\u3002\u5f15\u5165\u4e86\u57fa\u4e8e\u4fee\u6539\u540e\u7684\u5308\u7259\u5229\u5339\u914d\u7b97\u6cd5\u7684\u62d2\u7edd\u673a\u5236\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.04926", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04926", "abs": "https://arxiv.org/abs/2509.04926", "authors": ["Barbara Gendron", "Ga\u00ebl Guibon", "Mathieu D'aquin"], "title": "Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts", "comment": "Accepted at TOTh 2025 (Terminology \\& Ontology: Theories and\n  applications)", "summary": "The controllability of Large Language Models (LLMs) when used as\nconversational agents is a key challenge, particularly to ensure predictable\nand user-personalized responses. This work proposes an ontology-based approach\nto formally define conversational features that are typically qualitative in\nnature. By leveraging a set of linguistic descriptors, we derive quantitative\ndefinitions for qualitatively-defined concepts, enabling their integration into\nan ontology for reasoning and consistency checking. We apply this framework to\nthe task of proficiency-level control in conversations, using CEFR language\nproficiency levels as a case study. These definitions are then formalized in\ndescription logic and incorporated into an ontology, which guides controlled\ntext generation of an LLM through fine-tuning. Experimental results demonstrate\nthat our approach provides consistent and explainable proficiency-level\ndefinitions, improving transparency in conversational AI.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4e49\u5b9a\u6027\u7279\u5f81\u5b9e\u73b0\u5bf9LLMs\u5728\u5bf9\u8bdd\u4ee3\u7406\u4e2d\u7684\u53ef\u63a7\u6027\u3002\u7814\u7a76\u5229\u7528\u8bed\u8a00\u63cf\u8ff0\u7b26\u5c06\u5b9a\u6027\u6982\u5ff5\u8f6c\u5316\u4e3a\u5b9a\u91cf\u5b9a\u4e49\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u672c\u4f53\u4e2d\u8fdb\u884c\u63a8\u7406\u548c\u4e00\u81f4\u6027\u68c0\u67e5\u3002\u5c06\u8fd9\u4e00\u6846\u67b6\u5e94\u7528\u4e8e\u63a7\u5236\u5bf9\u8bdd\u4e2d\u7684\u719f\u7ec3\u6c34\u5e73\uff0c\u901a\u8fc7\u63cf\u8ff0\u903b\u8f91\u548c\u672c\u4f53\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u6307\u5bfcLLM\u8fdb\u884c\u53d7\u63a7\u6587\u672c\u751f\u6210\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u81f4\u548c\u53ef\u89e3\u91ca\u7684\u719f\u7ec3\u6c34\u5e73\u5b9a\u4e49\uff0c\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u4eba\u5de5\u667a\u80fd\u7684\u900f\u660e\u5ea6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3LLMs\u4f5c\u4e3a\u5bf9\u8bdd\u4ee3\u7406\u65f6\u7684\u53ef\u63a7\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u4e3a\u4e86\u786e\u4fdd\u53ef\u9884\u6d4b\u548c\u7528\u6237\u4e2a\u6027\u5316\u7684\u54cd\u5e94\u3002\u5e0c\u671b\u63d0\u4f9b\u4e00\u79cd\u65b9\u6cd5\u6765\u5b9a\u4e49\u548c\u7ba1\u7406\u5bf9\u8bdd\u4e2d\u7684\u5b9a\u6027\u6982\u5ff5\uff0c\u4ece\u800c\u63d0\u9ad8\u5bf9\u8bdd\u4eba\u5de5\u667a\u80fd\u7684\u900f\u660e\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "method": "\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u65b9\u6cd5\u5b9a\u4e49\u4e86\u5b9a\u6027\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u8bed\u8a00\u63cf\u8ff0\u7b26\u7684\u5b9a\u91cf\u5b9a\u4e49\u5c06\u5176\u6574\u5408\u5230\u672c\u4f53\u4e2d\uff0c\u5b9e\u73b0\u5bf9LLMs\u5728\u5bf9\u8bdd\u4ee3\u7406\u4e2d\u7684\u53ef\u63a7\u6027\u3002\u901a\u8fc7\u5c06\u5b9a\u6027\u6982\u5ff5\u5f62\u5f0f\u5316\u4e3a\u63cf\u8ff0\u903b\u8f91\uff0c\u5e76\u52a0\u5165\u672c\u4f53\uff0c\u6307\u5bfcLLM\u7684\u53d7\u63a7\u6587\u672c\u751f\u6210\uff0c\u63d0\u4f9b\u4e00\u81f4\u548c\u53ef\u89e3\u91ca\u7684\u719f\u7ec3\u6c34\u5e73\u5b9a\u4e49\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4e00\u81f4\u548c\u53ef\u89e3\u91ca\u7684\u719f\u7ec3\u6c34\u5e73\u5b9a\u4e49\uff0c\u4e3a\u5bf9\u8bdd\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u66f4\u591a\u7684\u900f\u660e\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4e49\u5b9a\u6027\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5bf9\u8bdd\u4ee3\u7406\u4e2d\u7684\u53ef\u63a7\u6027\u3002\u7814\u7a76\u5c06\u5b9a\u6027\u6982\u5ff5\u901a\u8fc7\u4e00\u7ec4\u8bed\u8a00\u63cf\u8ff0\u7b26\u8f6c\u5316\u4e3a\u5b9a\u91cf\u5b9a\u4e49\uff0c\u4ece\u800c\u4f7f\u5176\u6574\u5408\u5230\u4e00\u4e2a\u672c\u4f53\u8bba\u4e2d\u8fdb\u884c\u63a8\u7406\u548c\u4e00\u81f4\u6027\u68c0\u67e5\u3002\u5c06\u8fd9\u4e00\u6846\u67b6\u5e94\u7528\u4e8e\u5bf9\u8bdd\u4e2d\u7684\u719f\u7ec3\u6c34\u5e73\u63a7\u5236\u4efb\u52a1\uff0c\u4ee5CEFR\u8bed\u8a00\u719f\u7ec3\u6c34\u5e73\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u63cf\u8ff0\u903b\u8f91\u5c06\u8fd9\u4e9b\u5b9a\u4e49\u5f62\u5f0f\u5316\u5e76\u7eb3\u5165\u672c\u4f53\u8bba\uff0c\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u6307\u5bfcLLM\u7684\u53d7\u63a7\u6587\u672c\u751f\u6210\uff0c\u63d0\u4f9b\u4e00\u81f4\u548c\u53ef\u89e3\u91ca\u7684\u719f\u7ec3\u6c34\u5e73\u5b9a\u4e49\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u4eba\u5de5\u667a\u80fd\u7684\u900f\u660e\u5ea6\u3002"}}
{"id": "2509.04979", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04979", "abs": "https://arxiv.org/abs/2509.04979", "authors": ["Rajesh Tembarai Krishnamachari", "Srividya Rajesh"], "title": "Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents", "comment": null, "summary": "AI agents -- powered by reasoning-capable large language models (LLMs) and\nintegrated with tools, data, and web search -- are poised to transform the\ninternet into a \\emph{Web of Agents}: a machine-native ecosystem where\nautonomous agents interact, collaborate, and execute tasks at scale. Realizing\nthis vision requires \\emph{Agent Ranking} -- selecting agents not only by\ndeclared capabilities but by proven, recent performance. Unlike Web~1.0's\nPageRank, a global, transparent network of agent interactions does not exist;\nusage signals are fragmented and private, making ranking infeasible without\ncoordination.\n  We propose \\textbf{DOVIS}, a five-layer operational protocol\n(\\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that\nenables the collection of minimal, privacy-preserving aggregates of usage and\nperformance across the ecosystem. On this substrate, we implement\n\\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines\n\\emph{usage} (selection frequency) and \\emph{competence} (outcome quality,\ncost, safety, latency) into a unified ranking. We present simulation results\nand theoretical guarantees on convergence, robustness, and Sybil resistance,\ndemonstrating the viability of coordinated protocols and performance-aware\nranking in enabling a scalable, trustworthy Agentic Web.", "AI": {"tldr": "The paper discusses the transformation of the internet into a Web of Agents and the need for Agent Ranking based on proven performance. It proposes the DOVIS protocol and AgentRank-UC algorithm, showing their effectiveness through simulations and theoretical guarantees. The contributions highlight the potential for coordinated protocols and performance-aware ranking to facilitate a trustworthy Agentic Web.", "motivation": "The motivation is to transform the internet into a Web of Agents where autonomous agents interact at scale, requiring a method for selecting agents based on proven performance rather than just declared capabilities. The lack of a global, transparent network for agent interactions necessitates the development of coordinated protocols for ranking.", "method": "Proposes the DOVIS protocol and AgentRank-UC algorithm for enabling Agent Ranking based on usage and competence, conducts simulations, and provides theoretical guarantees on convergence, robustness, and Sybil resistance.", "result": "The paper introduces the DOVIS protocol and AgentRank-UC algorithm, showcasing their effectiveness through simulation results and theoretical guarantees on convergence, robustness, and Sybil resistance. These contributions demonstrate the potential for coordinated protocols and performance-aware ranking to enable a scalable and trustworthy Agentic Web.", "conclusion": "AI agents are poised to transform the internet into a Web of Agents, requiring Agent Ranking for selecting agents based on proven performance. The paper proposes the DOVIS protocol and AgentRank-UC algorithm to enable ranking based on usage and competence, with simulation results demonstrating viability for a trustworthy Agentic Web."}}
{"id": "2509.05007", "categories": ["cs.AI", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.05007", "abs": "https://arxiv.org/abs/2509.05007", "authors": ["Jie Chen", "Jinhao Jiang", "Yingqian Min", "Zican Dong", "Shijie Wang", "Wayne Xin Zhao", "Ji-Rong Wen"], "title": "Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework", "comment": "11 pages, 1 figures, 5 tables", "summary": "Large reasoning models (LRMs) have exhibited strong performance on complex\nreasoning tasks, with further gains achievable through increased computational\nbudgets at inference. However, current test-time scaling methods predominantly\nrely on redundant sampling, ignoring the historical experience utilization,\nthereby limiting computational efficiency. To overcome this limitation, we\npropose Sticker-TTS, a novel test-time scaling framework that coordinates three\ncollaborative LRMs to iteratively explore and refine solutions guided by\nhistorical attempts. At the core of our framework are distilled key\nconditions-termed stickers-which drive the extraction, refinement, and reuse of\ncritical information across multiple rounds of reasoning. To further enhance\nthe efficiency and performance of our framework, we introduce a two-stage\noptimization strategy that combines imitation learning with self-improvement,\nenabling progressive refinement. Extensive evaluations on three challenging\nmathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,\ndemonstrate that Sticker-TTS consistently surpasses strong baselines, including\nself-consistency and advanced reinforcement learning approaches, under\ncomparable inference budgets. These results highlight the effectiveness of\nsticker-guided historical experience utilization. Our code and data are\navailable at https://github.com/RUCAIBox/Sticker-TTS.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86Sticker-TTS\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u4e09\u4e2a\u5927\u63a8\u7406\u6a21\u578b\uff0c\u5229\u7528\u5386\u53f2\u5c1d\u8bd5\u6307\u5bfc\u7684\u8fed\u4ee3\u63a2\u7d22\u548c\u5b8c\u5584\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u65b9\u6cd5\u8fc7\u591a\u4f9d\u8d56\u5197\u4f59\u62bd\u6837\u800c\u5ffd\u7565\u5386\u53f2\u7ecf\u9a8c\u5229\u7528\u7684\u9650\u5236\u3002Sticker-TTS\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5197\u4f59\u62bd\u6837\uff0c\u5ffd\u7565\u5386\u53f2\u7ecf\u9a8c\u5229\u7528\uff0c\u9650\u5236\u4e86\u8ba1\u7b97\u6548\u7387\u3002\u672c\u7814\u7a76\u65e8\u5728\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u63d0\u51faSticker-TTS\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5bfc\u5386\u53f2\u5c1d\u8bd5\u6307\u5bfc\u8fed\u4ee3\u63a2\u7d22\u548c\u5b8c\u5584\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6211\u4eec\u7684\u6846\u67b6\u6838\u5fc3\u662f\u7cbe\u70bc\u5173\u952e\u6761\u4ef6\uff08\u79f0\u4e3asticker\uff09\uff0c\u9a71\u52a8\u5173\u952e\u4fe1\u606f\u7684\u63d0\u53d6\u3001\u5b8c\u5584\u548c\u590d\u7528\uff0c\u901a\u8fc7\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u548c\u81ea\u6211\u6539\u8fdb\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u5b8c\u5584\uff0c\u589e\u5f3a\u4e86\u6846\u67b6\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5bf9\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ecAIME-24\u3001AIME-25\u548cOlymMATH\uff09\u7684\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8bc1\u660eSticker-TTS\u5728\u53ef\u6bd4\u63a8\u7406\u9884\u7b97\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5305\u62ec\u81ea\u4e00\u81f4\u6027\u548c\u5148\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u6846\u67b6Sticker-TTS\uff0c\u901a\u8fc7\u534f\u8c03\u4e09\u4e2a\u534f\u540c\u5927\u63a8\u7406\u6a21\u578b\uff0c\u5f15\u5bfc\u7531\u5386\u53f2\u5c1d\u8bd5\u6307\u5bfc\u7684\u8fed\u4ee3\u63a2\u7d22\u548c\u5b8c\u5584\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u5f53\u524d\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u65b9\u6cd5\u8fc7\u591a\u4f9d\u8d56\u5197\u4f59\u62bd\u6837\u800c\u5ffd\u7565\u5386\u53f2\u7ecf\u9a8c\u5229\u7528\u7684\u9650\u5236\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cSticker-TTS\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5305\u62ec\u81ea\u4e00\u81f4\u6027\u548c\u5148\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u53ef\u6bd4\u63a8\u7406\u9884\u7b97\u4e0b\u3002"}}
{"id": "2509.05072", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.05072", "abs": "https://arxiv.org/abs/2509.05072", "authors": ["Nir Sweed", "Hanit Hakim", "Ben Wolfson", "Hila Lifshitz", "Dafna Shahaf"], "title": "Finding your MUSE: Mining Unexpected Solutions Engine", "comment": null, "summary": "Innovators often exhibit cognitive fixation on existing solutions or nascent\nideas, hindering the exploration of novel alternatives. This paper introduces a\nmethodology for constructing Functional Concept Graphs (FCGs), interconnected\nrepresentations of functional elements that support abstraction, problem\nreframing, and analogical inspiration. Our approach yields large-scale,\nhigh-quality FCGs with explicit abstraction relations, overcoming limitations\nof prior work. We further present MUSE, an algorithm leveraging FCGs to\ngenerate creative inspirations for a given problem. We demonstrate our method\nby computing an FCG on 500K patents, which we release for further research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6784\u5efaFunctional Concept Graphs\uff08FCGs\uff09\u7684\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u62bd\u8c61\u3001\u95ee\u9898\u91cd\u6784\u548c\u7c7b\u6bd4\u542f\u53d1\u3002\u4f7f\u7528\u8be5\u65b9\u6cd5\u751f\u6210\u4e86\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684FCGs\uff0c\u5e76\u63d0\u51fa\u4e86MUSE\u7b97\u6cd5\u6765\u4e3a\u7ed9\u5b9a\u95ee\u9898\u751f\u6210\u521b\u610f\u542f\u53d1\u3002\u901a\u8fc7\u5bf950\u4e07\u4e13\u5229\u8fdb\u884c\u8ba1\u7b97\u5f97\u5230\u4e86FCG\uff0c\u5e76\u5c06\u5176\u53d1\u5e03\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u4f7f\u7528\u3002", "motivation": "\u521b\u65b0\u8005\u7ecf\u5e38\u5728\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u6216\u65b0\u5174\u601d\u60f3\u4e0a\u8868\u73b0\u51fa\u8ba4\u77e5\u5b9a\u52bf\uff0c\u963b\u788d\u4e86\u5bf9\u65b0\u9896\u66ff\u4ee3\u65b9\u6848\u7684\u63a2\u7d22\u3002", "method": "\u6784\u5efaFunctional Concept Graphs\uff08FCGs\uff09\uff0c\u4f7f\u7528MUSE\u7b97\u6cd5\u751f\u6210\u521b\u610f\u542f\u53d1\uff0c\u8ba1\u7b97500K\u4e13\u5229\u4ee5\u83b7\u5f97FCG", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u514b\u670d\u5148\u524d\u5de5\u4f5c\u5c40\u9650\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u4e14\u9ad8\u8d28\u91cf\u7684FCGs\uff0c\u5e76\u5c55\u793a\u4e86\u5229\u7528FCGs\u751f\u6210\u521b\u610f\u542f\u53d1\u7684\u7b97\u6cd5MUSE\u3002", "conclusion": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6784\u5efaFunctional Concept Graphs\uff08FCGs\uff09\u7684\u65b9\u6cd5\uff0c\u652f\u6301\u62bd\u8c61\u3001\u95ee\u9898\u91cd\u6784\u548c\u7c7b\u6bd4\u542f\u53d1\u3002\u901a\u8fc7\u8be5\u65b9\u6cd5\u5f97\u5230\u4e86\u5927\u89c4\u6a21\u4e14\u9ad8\u8d28\u91cf\u7684FCGs\uff0c\u514b\u670d\u4e86\u5148\u524d\u5de5\u4f5c\u7684\u5c40\u9650\u3002\u63d0\u51fa\u4e86MUSE\u7b97\u6cd5\uff0c\u5229\u7528FCGs\u4e3a\u7ed9\u5b9a\u95ee\u9898\u751f\u6210\u521b\u610f\u542f\u53d1\u3002\u901a\u8fc7\u5bf950\u4e07\u9879\u4e13\u5229\u8ba1\u7b97\u5f97\u5230FCG\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u53d1\u5e03\u4e86\u8fd9\u4e00\u65b9\u6cd5\u3002"}}
{"id": "2509.05091", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05091", "abs": "https://arxiv.org/abs/2509.05091", "authors": ["Matteo Bortoletto", "Yichao Zhou", "Lance Ying", "Tianmin Shu", "Andreas Bulling"], "title": "ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback", "comment": "Website at https://www.matteobortoletto.org/protom/", "summary": "While humans are inherently social creatures, the challenge of identifying\nwhen and how to assist and collaborate with others - particularly when pursuing\nindependent goals - can hinder cooperation. To address this challenge, we aim\nto develop an AI system that provides useful feedback to promote prosocial\nbehaviour - actions that benefit others, even when not directly aligned with\none's own goals. We introduce ProToM, a Theory of Mind-informed facilitator\nthat promotes prosocial actions in multi-agent systems by providing targeted,\ncontext-sensitive feedback to individual agents. ProToM first infers agents'\ngoals using Bayesian inverse planning, then selects feedback to communicate by\nmaximising expected utility, conditioned on the inferred goal distribution. We\nevaluate our approach against baselines in two multi-agent environments: Doors,\nKeys, and Gems, as well as Overcooked. Our results suggest that\nstate-of-the-art large language and reasoning models fall short of\ncommunicating feedback that is both contextually grounded and well-timed -\nleading to higher communication overhead and task speedup. In contrast, ProToM\nprovides targeted and helpful feedback, achieving a higher success rate,\nshorter task completion times, and is consistently preferred by human users.", "AI": {"tldr": "The paper introduces ProToM, an AI system that promotes prosocial behavior in multi-agent systems by providing context-sensitive feedback. ProToM surpasses existing models in communication quality, task efficiency, and user preference.", "motivation": "Humans face challenges in identifying when and how to assist and collaborate with others, especially when pursuing independent goals. To overcome this hindrance to cooperation, the paper aims to develop an AI system that promotes prosocial behavior by offering useful feedback.", "method": "The AI system, ProToM, utilizes Bayesian inverse planning to infer agents' goals and maximizes expected utility to select feedback. It provides targeted and context-sensitive feedback to individual agents in multi-agent systems.", "result": "Evaluation of ProToM against baselines in two multi-agent environments shows superior performance in promoting prosocial actions. It outperforms large language and reasoning models in communication effectiveness, task completion speed, and user preference.", "conclusion": "ProToM, an AI system developed to promote prosocial behavior in multi-agent systems, outperforms state-of-the-art language and reasoning models in providing targeted and context-sensitive feedback. It achieves a higher success rate, shorter task completion times, and is preferred by human users."}}
{"id": "2509.05139", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05139", "abs": "https://arxiv.org/abs/2509.05139", "authors": ["Jaime Osvaldo Salas", "Paolo Pareti", "Semih Yumu\u015fak", "Soulmaz Gheisari", "Luis-Daniel Ib\u00e1\u00f1ez", "George Konstantinidis"], "title": "Evaluation and Comparison Semantics for ODRL", "comment": "Accepted as a full paper at the 14th International Joint Conference\n  on Knowledge Graphs (IJCKG 2025). This is the submitted manuscript, the\n  accepted manuscript will be published by Springer Nature", "summary": "We consider the problem of evaluating, and comparing computational policies\nin the Open Digital Rights Language (ODRL), which has become the de facto\nstandard for governing the access and usage of digital resources. Although\npreliminary progress has been made on the formal specification of the\nlanguage's features, a comprehensive formal semantics of ODRL is still missing.\nIn this paper, we provide a simple and intuitive formal semantics for ODRL that\nis based on query answering. Our semantics refines previous formalisations, and\nis aligned with the latest published specification of the language (2.2).\nBuilding on our evaluation semantics, and motivated by data sharing scenarios,\nwe also define and study the problem of comparing two policies, detecting\nequivalent, more restrictive or more permissive policies.", "AI": {"tldr": "\u672c\u6587\u5728ODRL\u9886\u57df\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u76f4\u89c2\u7684\u6b63\u5f0f\u8bed\u4e49\uff0c\u57fa\u4e8e\u67e5\u8be2\u56de\u7b54\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6bd4\u8f83\u8ba1\u7b97\u7b56\u7565\u3002\u8be5\u6b63\u5f0f\u8bed\u4e49\u4e0e\u6700\u65b0\u8bed\u8a00\u89c4\u8303\u4e00\u81f4\uff0c\u5b9a\u4e49\u4e86\u6bd4\u8f83\u4e24\u79cd\u7b56\u7565\u7684\u95ee\u9898\uff0c\u5e76\u53ef\u4ee5\u68c0\u6d4b\u7b49\u4ef7\u3001\u66f4\u4e25\u683c\u6216\u66f4\u5bbd\u677e\u7684\u7b56\u7565\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u7ecf\u5728\u8bed\u8a00\u529f\u80fd\u7684\u6b63\u5f0f\u89c4\u8303\u4e0a\u53d6\u5f97\u4e86\u521d\u6b65\u8fdb\u5c55\uff0c\u4f46\u4ecd\u7136\u7f3a\u4e4fODRL\u7684\u5168\u9762\u6b63\u5f0f\u8bed\u4e49\u3002\u53d7\u6570\u636e\u5171\u4eab\u573a\u666f\u7684\u6fc0\u52b1\uff0c\u5efa\u7acb\u5728\u8bc4\u4f30\u8bed\u4e49\u7684\u57fa\u7840\u4e0a\uff0c\u5b9a\u4e49\u5e76\u7814\u7a76\u4e86\u6bd4\u8f83\u4e24\u79cd\u7b56\u7565\u7684\u95ee\u9898\u3002", "method": "\u63d0\u4f9b\u4e86\u57fa\u4e8e\u67e5\u8be2\u56de\u7b54\u7684\u7b80\u5355\u76f4\u89c2\u7684ODRL\u6b63\u5f0f\u8bed\u4e49\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6bd4\u8f83\u8ba1\u7b97\u7b56\u7565\u3002", "result": "\u6b63\u5f0f\u8bed\u4e49\u901a\u8fc7\u67e5\u8be2\u56de\u7b54\u5efa\u7acb\u8bc4\u4f30\u548c\u6bd4\u8f83\u8ba1\u7b97\u7b56\u7565\uff0c\u4e0e\u6700\u65b0\u8bed\u8a00\u89c4\u8303\u4fdd\u6301\u4e00\u81f4\u3002\u63d0\u51fa\u4e86\u6bd4\u8f83\u4e24\u79cd\u7b56\u7565\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u68c0\u6d4b\u7b49\u4ef7\u3001\u66f4\u4e25\u683c\u6216\u66f4\u5bbd\u677e\u7684\u7b56\u7565\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u76f4\u89c2\u7684ODRL\u6b63\u5f0f\u8bed\u4e49\uff0c\u57fa\u4e8e\u67e5\u8be2\u56de\u7b54\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6bd4\u8f83\u8ba1\u7b97\u7b56\u7565\u3002\u5728\u6700\u65b0\u7684\u8bed\u8a00\u89c4\u8303\uff082.2\uff09\u4e0b\u4e0e\u524d\u51e0\u6b21\u6b63\u5f0f\u5316\u7684\u5185\u5bb9\u4fdd\u6301\u4e00\u81f4\u3002\u5b9a\u4e49\u548c\u7814\u7a76\u4e86\u6bd4\u8f83\u4e24\u79cd\u7b56\u7565\u7684\u95ee\u9898\uff0c\u68c0\u6d4b\u7b49\u4ef7\u3001\u66f4\u4e25\u683c\u6216\u66f4\u5bbd\u677e\u7b56\u7565\u3002"}}
{"id": "2509.05263", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05263", "abs": "https://arxiv.org/abs/2509.05263", "authors": ["Yinglin Duan", "Zhengxia Zou", "Tongwei Gu", "Wei Jia", "Zhan Zhao", "Luyi Xu", "Xinzhu Liu", "Hao Jiang", "Kang Chen", "Shuang Qiu"], "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "comment": null, "summary": "Recent research has been increasingly focusing on developing 3D world models\nthat simulate complex real-world scenarios. World models have found broad\napplications across various domains, including embodied AI, autonomous driving,\nentertainment, etc. A more realistic simulation with accurate physics will\neffectively narrow the sim-to-real gap and allow us to gather rich information\nabout the real world conveniently. While traditional manual modeling has\nenabled the creation of virtual 3D scenes, modern approaches have leveraged\nadvanced machine learning algorithms for 3D world generation, with most recent\nadvances focusing on generative methods that can create virtual worlds based on\nuser instructions. This work explores such a research direction by proposing\nLatticeWorld, a simple yet effective 3D world generation framework that\nstreamlines the industrial production pipeline of 3D environments. LatticeWorld\nleverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering\nengine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed\nframework accepts textual descriptions and visual instructions as multimodal\ninputs and creates large-scale 3D interactive worlds with dynamic agents,\nfeaturing competitive multi-agent interaction, high-fidelity physics\nsimulation, and real-time rendering. We conduct comprehensive experiments to\nevaluate LatticeWorld, showing that it achieves superior accuracy in scene\nlayout generation and visual fidelity. Moreover, LatticeWorld achieves over a\n$90\\times$ increase in industrial production efficiency while maintaining high\ncreative quality compared with traditional manual production methods. Our demo\nvideo is available at https://youtu.be/8VWZXpERR18", "AI": {"tldr": "\u6700\u8fd1\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u53d1\u5c55\u6a21\u62df\u590d\u6742\u771f\u5b9e\u573a\u666f\u7684 3D \u4e16\u754c\u6a21\u578b\u3002LatticeWorld \u662f\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684 3D \u4e16\u754c\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u63a5\u53d7\u6587\u672c\u63cf\u8ff0\u548c\u89c6\u89c9\u6307\u4ee4\uff0c\u53ef\u4ee5\u521b\u5efa\u5177\u6709\u52a8\u6001\u4ee3\u7406\u3001\u591a\u4ee3\u7406\u4e92\u52a8\u3001\u9ad8\u4fdd\u771f\u7269\u7406\u6a21\u62df\u548c\u5b9e\u65f6\u6e32\u67d3\u7684\u5927\u89c4\u6a21 3D \u4ea4\u4e92\u4e16\u754c\u3002\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u5de5\u4e1a\u751f\u4ea7\u6548\u7387\u5e76\u4fdd\u6301\u9ad8\u521b\u610f\u8d28\u91cf\u3002", "motivation": "\u6700\u8fd1\u7684\u7814\u7a76\u805a\u7126\u4e8e\u53d1\u5c55\u6a21\u62df\u590d\u6742\u771f\u5b9e\u573a\u666f\u7684 3D \u4e16\u754c\u6a21\u578b\u3002\u4f20\u7edf\u7684\u624b\u52a8\u5efa\u6a21\u867d\u7136\u80fd\u591f\u521b\u5efa\u865a\u62df 3D \u573a\u666f\uff0c\u4f46\u73b0\u4ee3\u65b9\u6cd5\u5229\u7528\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c 3D \u4e16\u754c\u751f\u6210\uff0c\u6700\u8fd1\u7684\u8fdb\u5c55\u96c6\u4e2d\u5728\u53ef\u4ee5\u6839\u636e\u7528\u6237\u6307\u4ee4\u521b\u5efa\u865a\u62df\u4e16\u754c\u7684\u751f\u6210\u65b9\u6cd5\u3002\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u63d0\u51fa LatticeWorld\uff0c\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684 3D \u4e16\u754c\u751f\u6210\u6846\u67b6\uff0c\u7b80\u5316\u4e86 3D \u73af\u5883\u7684\u5de5\u4e1a\u751f\u4ea7\u6d41\u7a0b\u3002", "method": "LatticeWorld \u4f7f\u7528\u8f7b\u91cf\u7ea7 LLMs\uff08LLaMA-2-7B\uff09\u548c\u884c\u4e1a\u7ea7\u6e32\u67d3\u5f15\u64ce\uff08\u4f8b\u5982 Unreal Engine 5\uff09\u6765\u751f\u6210\u52a8\u6001\u73af\u5883\u3002\u8be5\u6846\u67b6\u63a5\u53d7\u6587\u672c\u63cf\u8ff0\u548c\u89c6\u89c9\u6307\u4ee4\u4f5c\u4e3a\u591a\u6a21\u6001\u8f93\u5165\uff0c\u521b\u5efa\u5177\u6709\u52a8\u6001\u4ee3\u7406\u3001\u7ade\u4e89\u6027\u591a\u4ee3\u7406\u4e92\u52a8\u3001\u9ad8\u4fdd\u771f\u7269\u7406\u6a21\u62df\u548c\u5b9e\u65f6\u6e32\u67d3\u7684\u5927\u89c4\u6a21 3D \u4ea4\u4e92\u4e16\u754c\u3002", "result": "LatticeWorld \u5728\u5de5\u4e1a\u751f\u4ea7\u6548\u7387\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc7 90 \u500d\u7684\u589e\u52a0\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u521b\u610f\u8d28\u91cf\uff0c\u76f8\u6bd4\u4f20\u7edf\u624b\u52a8\u751f\u4ea7\u65b9\u6cd5\u3002", "conclusion": "LatticeWorld \u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684 3D \u4e16\u754c\u751f\u6210\u6846\u67b6\uff0c\u4f18\u5316\u4e86\u5de5\u4e1a\u751f\u4ea7\u7ba1\u9053\uff0c\u5b9e\u73b0\u4e86\u9ad8\u751f\u4ea7\u6548\u7387\u548c\u9ad8\u521b\u610f\u8d28\u91cf\u3002\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cLatticeWorld \u5728\u573a\u666f\u5e03\u5c40\u751f\u6210\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\u65b9\u9762\u8fbe\u5230\u4e86\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u3002"}}
