{"id": "2509.03536", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.03536", "abs": "https://arxiv.org/abs/2509.03536", "authors": ["Weizhi Chen", "Ziwei Wang", "Leyang Yang", "Sheng Zhou", "Xiaoxuan Tang", "Jiajun Bu", "Yong Li", "Wei Jiang"], "title": "PG-Agent: An Agent Powered by Page Graph", "comment": "Paper accepted to ACM MM 2025", "summary": "Graphical User Interface (GUI) agents possess significant commercial and\nsocial value, and GUI agents powered by advanced multimodal large language\nmodels (MLLMs) have demonstrated remarkable potential. Currently, existing GUI\nagents usually utilize sequential episodes of multi-step operations across\npages as the prior GUI knowledge, which fails to capture the complex transition\nrelationship between pages, making it challenging for the agents to deeply\nperceive the GUI environment and generalize to new scenarios. Therefore, we\ndesign an automated pipeline to transform the sequential episodes into page\ngraphs, which explicitly model the graph structure of the pages that are\nnaturally connected by actions. To fully utilize the page graphs, we further\nintroduce Retrieval-Augmented Generation (RAG) technology to effectively\nretrieve reliable perception guidelines of GUI from them, and a tailored\nmulti-agent framework PG-Agent with task decomposition strategy is proposed to\nbe injected with the guidelines so that it can generalize to unseen scenarios.\nExtensive experiments on various benchmarks demonstrate the effectiveness of\nPG-Agent, even with limited episodes for page graph construction.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bbe\u8ba1\u4e86\u81ea\u52a8\u5316\u6d41\u7a0b\u5c06GUI\u4ee3\u7406\u7684\u987a\u5e8f\u60c5\u8282\u8f6c\u6362\u6210\u9875\u9762\u56fe\uff0c\u5e76\u5f15\u5165\u4e86RAG\u6280\u672f\u6765\u83b7\u53d6GUI\u7684\u611f\u77e5\u6307\u5bfc\u3002\u63d0\u51fa\u4e86PG-Agent\u591aAgent\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u5b9e\u73b0\u5728\u65b0\u60c5\u666f\u4e2d\u7684\u6cdb\u5316\u3002\u5b9e\u9a8c\u8bc1\u660ePG-Agent\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u901a\u5e38\u4f7f\u7528\u8de8\u9875\u9762\u7684\u591a\u6b65\u64cd\u4f5c\u5e8f\u5217\u4f5c\u4e3a\u5148\u524d\u7684GUI\u77e5\u8bc6\uff0c\u65e0\u6cd5\u6355\u6349\u9875\u9762\u95f4\u590d\u6742\u7684\u8f6c\u6362\u5173\u7cfb\uff0c\u6311\u6218\u5728\u4e8e\u4ee3\u7406\u65e0\u6cd5\u6df1\u5165\u7406\u89e3GUI\u73af\u5883\u5e76\u63a8\u5e7f\u5230\u65b0\u60c5\u666f\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u7406\u89e3GUI\u73af\u5883\u5e76\u5b9e\u73b0\u5728\u65b0\u60c5\u666f\u4e2d\u7684\u6cdb\u5316\u3002", "method": "\u8bbe\u8ba1\u81ea\u52a8\u5316\u6d41\u7a0b\u5c06\u987a\u5e8f\u60c5\u8282\u8f6c\u6362\u6210\u9875\u9762\u56fe\uff0c\u5f15\u5165\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u4ee5\u6709\u6548\u83b7\u53d6GUI\u7684\u611f\u77e5\u6307\u5bfc\uff0c\u63d0\u51fa\u4e86\u591aAgent\u6846\u67b6PG-Agent\u5e76\u4f7f\u7528\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5bf9\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86PG-Agent\u7684\u6709\u6548\u6027\uff0c\u5373\u4f7f\u53ea\u6709\u6709\u9650\u60c5\u8282\u7528\u4e8e\u9875\u9762\u56fe\u6784\u5efa\u3002", "conclusion": "\u8bbe\u8ba1\u4e86\u81ea\u52a8\u5316\u6d41\u7a0b\u4ee5\u5c06\u987a\u5e8f\u60c5\u8282\u8f6c\u6362\u4e3a\u9875\u9762\u56fe\uff0c\u6709\u6548\u5730\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u83b7\u53d6GUI\u7684\u53ef\u9760\u611f\u77e5\u6307\u5bfc\u3002\u63d0\u51fa\u4e86\u4f7f\u7528\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u7684\u5b9a\u5236\u5316\u591aAgent\u6846\u67b6PG-Agent\uff0c\u53ef\u4ee5\u63a8\u5e7f\u5230\u672a\u77e5\u60c5\u5883\u3002\u5bf9\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86PG-Agent\u7684\u6709\u6548\u6027\uff0c\u5373\u4f7f\u5728\u6709\u9650\u7684\u60c5\u8282\u4e0b\u7528\u4e8e\u9875\u9762\u56fe\u6784\u5efa\u3002"}}
{"id": "2509.03548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03548", "abs": "https://arxiv.org/abs/2509.03548", "authors": ["Jo\u00e3o P. Arroyo", "Jo\u00e3o G. Rodrigues", "Daniel Lawand", "Denis D. Mau\u00e1", "Junkyu Lee", "Radu Marinescu", "Alex Gray", "Eduardo R. Laurentino", "Fabio G. Cozman"], "title": "Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models", "comment": "Accepted at the Causal Abstractions and Representations (CAR)\n  workshop of the 41st Conference on Uncertainty in Artificial Intelligence\n  (UAI 2025)", "summary": "We investigate partially identifiable queries in a class of causal models. We\nfocus on acyclic Structural Causal Models that are quasi-Markovian (that is,\neach endogenous variable is connected with at most one exogenous confounder).\nWe look into scenarios where endogenous variables are observed (and a\ndistribution over them is known), while exogenous variables are not fully\nspecified. This leads to a representation that is in essence a Bayesian network\nwhere the distribution of root variables is not uniquely determined. In such\ncircumstances, it may not be possible to precisely compute a probability value\nof interest. We thus study the computation of tight probability bounds, a\nproblem that has been solved by multilinear programming in general, and by\nlinear programming when a single confounded component is intervened upon. We\npresent a new algorithm to simplify the construction of such programs by\nexploiting input probabilities over endogenous variables. For scenarios with a\nsingle intervention, we apply column generation to compute a probability bound\nthrough a sequence of auxiliary linear integer programs, thus showing that a\nrepresentation with polynomial cardinality for exogenous variables is possible.\nExperiments show column generation techniques to be superior to existing\nmethods.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u90e8\u5206\u53ef\u8bc6\u522b\u7684\u56e0\u679c\u6a21\u578b\u67e5\u8be2\u5728\u4e00\u7c7b\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u3002\u4f7f\u7528\u591a\u7ebf\u6027\u89c4\u5212\u548c\u7ebf\u6027\u89c4\u5212\u89e3\u51b3\u4e86\u7d27\u6982\u7387\u754c\u9650\u8ba1\u7b97\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7b80\u5316\u7a0b\u5e8f\u6784\u5efa\u7684\u65b0\u7b97\u6cd5\u3002\u901a\u8fc7\u5217\u751f\u6210\u6cd5\u8ba1\u7b97\u4e86\u6982\u7387\u754c\u9650\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u5916\u751f\u53d8\u91cf\u5177\u6709\u591a\u9879\u5f0f\u57fa\u6570\u8868\u793a\u7684\u53ef\u80fd\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5217\u751f\u6210\u6280\u672f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u90e8\u5206\u53ef\u8bc6\u522b\u7684\u56e0\u679c\u6a21\u578b\u67e5\u8be2\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u51c6\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u7684\u65e0\u73af\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u3002\u63a2\u7d22\u5728\u5185\u751f\u53d8\u91cf\u53ef\u89c2\u5bdf\u4f46\u5916\u751f\u53d8\u91cf\u5e76\u975e\u5b8c\u5168\u6307\u5b9a\u7684\u60c5\u51b5\u4e0b\u7684\u6982\u7387\u8ba1\u7b97\u95ee\u9898\u3002\u89e3\u51b3\u8ba1\u7b97\u6982\u7387\u7684\u56f0\u96be\uff0c\u5bfb\u627e\u4e00\u79cd\u66f4\u7b80\u5316\u7684\u7b97\u6cd5\u6765\u6784\u5efa\u7d27\u6982\u7387\u754c\u9650\u7a0b\u5e8f\u3002", "method": "\u4f7f\u7528\u591a\u7ebf\u6027\u89c4\u5212\u548c\u7ebf\u6027\u89c4\u5212\u6765\u89e3\u51b3\u7d27\u6982\u7387\u754c\u9650\u8ba1\u7b97\u95ee\u9898\uff0c\u5f15\u5165\u4e00\u4e2a\u65b0\u7b97\u6cd5\u7b80\u5316\u7a0b\u5e8f\u6784\u5efa\uff0c\u5e76\u5229\u7528\u8f93\u5165\u7684\u5185\u751f\u53d8\u91cf\u6982\u7387\u3002\u5bf9\u4e8e\u5355\u4e00\u5e72\u9884\u60c5\u51b5\uff0c\u5e94\u7528\u5217\u751f\u6210\u6cd5\u901a\u8fc7\u8f85\u52a9\u7ebf\u6027\u6574\u6570\u89c4\u5212\u8ba1\u7b97\u6982\u7387\u754c\u9650\u3002", "result": "\u901a\u8fc7\u5229\u7528\u591a\u7ebf\u6027\u89c4\u5212\u3001\u7ebf\u6027\u89c4\u5212\u548c\u5217\u751f\u6210\u6280\u672f\uff0c\u6210\u529f\u8ba1\u7b97\u4e86\u6982\u7387\u754c\u9650\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u5916\u751f\u53d8\u91cf\u5177\u6709\u591a\u9879\u5f0f\u57fa\u6570\u7684\u8868\u793a\u60c5\u51b5\u4e0b\u7684\u53ef\u80fd\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5217\u751f\u6210\u6280\u672f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7814\u7a76\u90e8\u5206\u53ef\u8bc6\u522b\u7684\u56e0\u679c\u6a21\u578b\u67e5\u8be2\uff0c\u6211\u4eec\u5728\u4e00\u4e2a\u7c7b\u522b\u7684\u56e0\u679c\u6a21\u578b\u4e2d\u8fdb\u884c\u4e86\u8c03\u67e5\u3002\u6211\u4eec\u4e13\u6ce8\u4e8e\u5177\u6709\u51c6\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u7684\u65e0\u73af\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08\u5373\uff0c\u6bcf\u4e2a\u5185\u751f\u53d8\u91cf\u6700\u591a\u4e0e\u4e00\u4e2a\u5916\u751f\u6df7\u6dc6\u53d8\u91cf\u76f8\u8fde\uff09\u3002\u6211\u4eec\u7814\u7a76\u4e86\u5185\u751f\u53d8\u91cf\u53ef\u89c2\u5bdf\uff08\u5e76\u4e14\u5df2\u77e5\u5b83\u4eec\u4e4b\u95f4\u7684\u5206\u5e03\uff09\uff0c\u800c\u5916\u751f\u53d8\u91cf\u6ca1\u6709\u5b8c\u5168\u7279\u5b9a\u7684\u60c5\u51b5\u3002\u8fd9\u5bfc\u81f4\u5f62\u6210\u7684\u8868\u793a\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u4e2a\u8d1d\u53f6\u65af\u7f51\u7edc\uff0c\u5176\u4e2d\u6839\u53d8\u91cf\u7684\u5206\u5e03\u5e76\u4e0d\u662f\u552f\u4e00\u786e\u5b9a\u7684\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u53ef\u80fd\u65e0\u6cd5\u7cbe\u786e\u8ba1\u7b97\u611f\u5174\u8da3\u7684\u6982\u7387\u503c\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u7d27\u51d1\u6982\u7387\u754c\u9650\u7684\u8ba1\u7b97\uff0c\u8fd9\u4e00\u95ee\u9898\u4e00\u822c\u4e0a\u5df2\u88ab\u4f7f\u7528\u591a\u7ebf\u6027\u89c4\u5212\u89e3\u51b3\uff0c\u5728\u8fdb\u884c\u5355\u4e00\u6df7\u6dc6\u7ec4\u4ef6\u5e72\u9884\u65f6\u5219\u4f7f\u7528\u7ebf\u6027\u89c4\u5212\u5df2\u89e3\u51b3\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u8f93\u5165\u7684\u5185\u751f\u53d8\u91cf\u6982\u7387\u7b80\u5316\u8fd9\u4e9b\u89c4\u5212\u7684\u6784\u5efa\u3002\u5bf9\u4e8e\u4ec5\u6709\u4e00\u4e2a\u5e72\u9884\u7684\u60c5\u51b5\uff0c\u6211\u4eec\u5e94\u7528\u5217\u751f\u6210\u6cd5\u901a\u8fc7\u4e00\u7cfb\u5217\u8f85\u52a9\u7ebf\u6027\u6574\u6570\u89c4\u5212\u8ba1\u7b97\u6982\u7387\u754c\u9650\uff0c\u4ece\u800c\u5c55\u793a\u4e86\u5177\u6709\u591a\u9879\u5f0f\u57fa\u6570\u7684\u5916\u751f\u53d8\u91cf\u8868\u793a\u662f\u53ef\u80fd\u7684\u3002\u5b9e\u9a8c\u8bc1\u660e\u5217\u751f\u6210\u6280\u672f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2509.03550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03550", "abs": "https://arxiv.org/abs/2509.03550", "authors": ["Tonghe Li", "Jixin Liu", "Weili Zeng", "Hao Jiang"], "title": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method", "comment": "59 pages,13 figures, 3 tables", "summary": "In the context of continuously rising global air traffic, efficient and safe\nConflict Detection and Resolution (CD&R) is paramount for air traffic\nmanagement. Although Deep Reinforcement Learning (DRL) offers a promising\npathway for CD&R automation, existing approaches commonly suffer from a\n\"unimodal bias\" in their policies. This leads to a critical lack of\ndecision-making flexibility when confronted with complex and dynamic\nconstraints, often resulting in \"decision deadlocks.\" To overcome this\nlimitation, this paper pioneers the integration of diffusion probabilistic\nmodels into the safety-critical task of CD&R, proposing a novel autonomous\nconflict resolution framework named Diffusion-AC. Diverging from conventional\nmethods that converge to a single optimal solution, our framework models its\npolicy as a reverse denoising process guided by a value function, enabling it\nto generate a rich, high-quality, and multimodal action distribution. This core\narchitecture is complemented by a Density-Progressive Safety Curriculum (DPSC),\na training mechanism that ensures stable and efficient learning as the agent\nprogresses from sparse to high-density traffic environments. Extensive\nsimulation experiments demonstrate that the proposed method significantly\noutperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the\nmost challenging high-density scenarios, Diffusion-AC not only maintains a high\nsuccess rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions\n(NMACs) by approximately 59% compared to the next-best-performing baseline,\nsignificantly enhancing the system's safety margin. This performance leap stems\nfrom its unique multimodal decision-making capability, which allows the agent\nto flexibly switch to effective alternative maneuvers.", "AI": {"tldr": "Diffusion-AC, a novel CD&R framework, integrates diffusion probabilistic models and a value function-guided policy to overcome unimodal bias in DRL approaches. The framework with DPSC demonstrates superior performance in simulation experiments, achieving a high success rate and significantly reducing NMACs in high-density scenarios.", "motivation": "Existing DRL approaches for CD&R suffer from a unimodal bias leading to decision deadlocks in complex scenarios. The paper aims to address this limitation by introducing a novel framework for autonomous conflict resolution.", "method": "Integration of diffusion probabilistic models into CD&R, proposing the Diffusion-AC framework. Policy modeled as a reverse denoising process guided by a value function to generate multimodal action distribution. Enhanced with Density-Progressive Safety Curriculum (DPSC) for stable learning in varying traffic densities.", "result": "Extensive simulation experiments show that Diffusion-AC outperforms benchmark DRL methods, especially in high-density scenarios. Success rate of 94.1% achieved with a 59% reduction in NMACs compared to the next-best-performing baseline.", "conclusion": "Diffusion-AC significantly outperforms state-of-the-art DRL benchmarks in CD&R, maintaining a high success rate and reducing NMACs by 59% in high-density scenarios, enhancing safety margin."}}
{"id": "2509.03581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03581", "abs": "https://arxiv.org/abs/2509.03581", "authors": ["Davide Paglieri", "Bart\u0142omiej Cupia\u0142", "Jonathan Cook", "Ulyana Piterbarg", "Jens Tuyls", "Edward Grefenstette", "Jakob Nicolaus Foerster", "Jack Parker-Holder", "Tim Rockt\u00e4schel"], "title": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents", "comment": null, "summary": "Training large language models (LLMs) to reason via reinforcement learning\n(RL) significantly improves their problem-solving capabilities. In agentic\nsettings, existing methods like ReAct prompt LLMs to explicitly plan before\nevery action; however, we demonstrate that always planning is computationally\nexpensive and degrades performance on long-horizon tasks, while never planning\nfurther limits performance. To address this, we introduce a conceptual\nframework formalizing dynamic planning for LLM agents, enabling them to\nflexibly decide when to allocate test-time compute for planning. We propose a\nsimple two-stage training pipeline: (1) supervised fine-tuning on diverse\nsynthetic data to prime models for dynamic planning, and (2) RL to refine this\ncapability in long-horizon environments. Experiments on the Crafter environment\nshow that dynamic planning agents trained with this approach are more\nsample-efficient and consistently achieve more complex objectives.\nAdditionally, we demonstrate that these agents can be effectively steered by\nhuman-written plans, surpassing their independent capabilities. To our\nknowledge, this work is the first to explore training LLM agents for dynamic\ntest-time compute allocation in sequential decision-making tasks, paving the\nway for more efficient, adaptive, and controllable agentic systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u5f15\u5165\u52a8\u6001\u89c4\u5212\u6982\u5ff5\u6846\u67b6\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728Crafter\u73af\u5883\u4e2d\u8bad\u7ec3\u7684\u52a8\u6001\u89c4\u5212\u4ee3\u7406\u66f4\u5177\u6837\u672c\u6548\u7387\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u590d\u6742\u76ee\u6807\uff0c\u5e76\u80fd\u591f\u88ab\u4eba\u7c7b\u7f16\u5199\u7684\u8ba1\u5212\u6709\u6548\u6307\u5bfc\uff0c\u8d85\u8d8a\u72ec\u7acb\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u8981\u6c42LLM\u5728\u6bcf\u4e2a\u52a8\u4f5c\u4e4b\u524d\u663e\u5f0f\u89c4\u5212\uff0c\u4f46\u603b\u662f\u89c4\u5212\u8ba1\u7b97\u8d1f\u62c5\u8fc7\u91cd\u4e14\u5728\u957f\u89c6\u7a0b\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u4ece\u4e0d\u89c4\u5212\u53c8\u9650\u5236\u4e86\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\u7528\u4e8e\u5f62\u5f0f\u5316LLM\u4ee3\u7406\u7684\u52a8\u6001\u89c4\u5212\uff0c\u4f7f\u5176\u80fd\u591f\u7075\u6d3b\u51b3\u5b9a\u4f55\u65f6\u5206\u914d\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u89c4\u5212\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\uff0c\u5305\u62ec\u5728\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u4ee5\u51c6\u5907\u6a21\u578b\u8fdb\u884c\u52a8\u6001\u89c4\u5212\uff0c\u7136\u540e\u901a\u8fc7RL\u5728\u957f\u89c6\u7a0b\u73af\u5883\u4e2d\u5b8c\u5584\u8fd9\u79cd\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\u8bad\u7ec3\u7684\u52a8\u6001\u89c4\u5212\u4ee3\u7406\u5728Crafter\u73af\u5883\u4e2d\u66f4\u5177\u6837\u672c\u6548\u7387\uff0c\u80fd\u591f\u59cb\u7ec8\u5b9e\u73b0\u66f4\u590d\u6742\u7684\u76ee\u6807\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u4ee3\u7406\u8fd8\u53ef\u4ee5\u901a\u8fc7\u4eba\u7c7b\u7f16\u5199\u7684\u8ba1\u5212\u6709\u6548\u5730\u6307\u5bfc\uff0c\u8d85\u8d8a\u5176\u72ec\u7acb\u80fd\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u63a8\u7406\u5982\u4f55\u663e\u8457\u63d0\u9ad8\u5b83\u4eec\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002\u5f15\u5165\u4e86\u4e00\u79cd\u52a8\u6001\u89c4\u5212\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u4f7fLLM\u4ee3\u7406\u80fd\u591f\u7075\u6d3b\u51b3\u5b9a\u4f55\u65f6\u5206\u914d\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u89c4\u5212\u3002\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\uff0c\u63d0\u51fa\u4e86\u5728\u591a\u6837\u5316\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u7136\u540e\u5728\u957f\u89c6\u7a0b\u73af\u5883\u4e2d\u901a\u8fc7RL\u6765\u63d0\u70bc\u8fd9\u79cd\u80fd\u529b\u7684\u7b80\u5355\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u91c7\u7528\u8fd9\u79cd\u65b9\u6cd5\u8bad\u7ec3\u7684\u52a8\u6001\u89c4\u5212\u4ee3\u7406\u5728Crafter\u73af\u5883\u4e2d\u66f4\u5177\u6837\u672c\u6548\u7387\uff0c\u603b\u80fd\u5b9e\u73b0\u66f4\u590d\u6742\u7684\u76ee\u6807\u3002\u6b64\u5916\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u8fd9\u4e9b\u4ee3\u7406\u53ef\u4ee5\u6709\u6548\u5730\u7531\u4eba\u7c7b\u7f16\u5199\u7684\u8ba1\u5212\u5f15\u5bfc\uff0c\u8d85\u8d8a\u5176\u72ec\u7acb\u80fd\u529b\u3002\u8fd9\u9879\u5de5\u4f5c\u662f\u9996\u4e2a\u63a2\u7d22\u57f9\u8badLLM\u4ee3\u7406\u8fdb\u884c\u52a8\u6001\u6d4b\u8bd5\u65f6\u8d44\u6e90\u5206\u914d\u7684\u8bba\u6587\uff0c\u4e3a\u66f4\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u548c\u53ef\u63a7\u7684\u4ee3\u7406\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.03626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03626", "abs": "https://arxiv.org/abs/2509.03626", "authors": ["Zahra Zehtabi Sabeti Moghaddam", "Zeinab Dehghani", "Maneeha Rani", "Koorosh Aslansefat", "Bhupesh Kumar Mishra", "Rameez Raja Kureshi", "Dhavalkumar Thakker"], "title": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE", "comment": null, "summary": "Generative AI, such as Large Language Models (LLMs), has achieved impressive\nprogress but still produces hallucinations and unverifiable claims, limiting\nreliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves\naccuracy by grounding outputs in external knowledge, especially in domains like\nhealthcare, where precision is vital. However, RAG remains opaque and\nessentially a black box, heavily dependent on data quality. We developed a\nmethod-agnostic, perturbation-based framework that provides token and\ncomponent-level interoperability for Graph RAG using SMILE and named it as\nKnowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing\nsimilarities, and training weighted linear surrogates, KG-SMILE identifies the\ngraph entities and relations most influential to generated outputs, thereby\nmaking RAG more transparent. We evaluate KG-SMILE using comprehensive\nattribution metrics, including fidelity, faithfulness, consistency, stability,\nand accuracy. Our findings show that KG-SMILE produces stable, human-aligned\nexplanations, demonstrating its capacity to balance model effectiveness with\ninterpretability and thereby fostering greater transparency and trust in\nmachine learning technologies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u77e5\u8bc6\u56fe\uff08KG-SMILE\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6270\u52a8\u548c\u8bad\u7ec3\u52a0\u6743\u7ebf\u6027\u66ff\u4ee3\u7269\uff0c\u4f7fRAG\u66f4\u900f\u660e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eKG-SMILE\u4ea7\u751f\u7a33\u5b9a\u3001\u4eba\u7c7b\u4e00\u81f4\u7684\u89e3\u91ca\uff0c\u5e73\u8861\u4e86\u6a21\u578b\u6548\u679c\u4e0e\u89e3\u91ca\u6027\u80fd\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002", "motivation": "\u7531\u4e8eRetrieval-Augmented Generation\uff08RAG\uff09\u5728\u67d0\u4e9b\u654f\u611f\u9886\u57df\u7684\u53ef\u9760\u6027\u8f83\u5dee\uff0c\u4e3b\u8981\u53d6\u51b3\u4e8e\u6570\u636e\u8d28\u91cf\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u63d0\u9ad8\u5728\u8bf8\u5982\u533b\u7597\u4fdd\u5065\u7b49\u5173\u952e\u9886\u57df\u4e2d\u8f93\u51fa\u51c6\u786e\u6027\u3002", "method": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u4e0e\u65b9\u6cd5\u65e0\u5173\u7684\u3001\u57fa\u4e8e\u6270\u52a8\u7684\u6846\u67b6\uff0c\u4e3a\u4f7f\u7528SMILE\u7684\u77e5\u8bc6\u56feRAG\u63d0\u4f9b\u4e86token\u548c\u7ec4\u4ef6\u7ea7\u4e92\u64cd\u4f5c\u6027\u3002\u901a\u8fc7\u5e94\u7528\u53d7\u63a7\u6270\u52a8\u3001\u8ba1\u7b97\u76f8\u4f3c\u6027\u548c\u8bad\u7ec3\u52a0\u6743\u7ebf\u6027\u66ff\u4ee3\u7269\uff0cKG-SMILE\u786e\u5b9a\u5bf9\u751f\u6210\u8f93\u51fa\u6700\u5177\u5f71\u54cd\u529b\u7684\u56fe\u5b9e\u4f53\u548c\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u8bc4\u4f30\u4e86KG-SMILE\u5e76\u4f7f\u7528\u4e86\u5168\u9762\u7684\u5f52\u56e0\u6307\u6807\uff0c\u5305\u62ec\u5fe0\u5b9e\u5ea6\u3001\u5fe0\u5b9e\u6027\u3001\u4e00\u81f4\u6027\u3001\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aKG-SMILE\u4ea7\u751f\u4e86\u7a33\u5b9a\u7684\u3001\u4e0e\u4eba\u7c7b\u4e00\u81f4\u7684\u89e3\u91ca\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u5e73\u8861\u6a21\u578b\u6548\u679c\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSMILE\u7684\u77e5\u8bc6\u56fe\uff08KG-SMILE\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5e94\u7528\u53d7\u63a7\u6270\u52a8\u3001\u8ba1\u7b97\u76f8\u4f3c\u6027\u548c\u8bad\u7ec3\u52a0\u6743\u7ebf\u6027\u66ff\u4ee3\u7269\uff0c\u8bc6\u522b\u5bf9\u751f\u6210\u8f93\u51fa\u5f71\u54cd\u6700\u5927\u7684\u56fe\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u4ece\u800c\u4f7fRAG\u66f4\u52a0\u900f\u660e\u3002\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cKG-SMILE\u80fd\u591f\u4ea7\u751f\u7a33\u5b9a\u3001\u4e0e\u4eba\u4e00\u81f4\u7684\u89e3\u91ca\uff0c\u5c55\u793a\u4e86\u5e73\u8861\u6a21\u578b\u6548\u679c\u4e0e\u53ef\u89e3\u91ca\u6027\u7684\u80fd\u529b\uff0c\u4ece\u800c\u4fc3\u8fdb\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002"}}
{"id": "2509.03636", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03636", "abs": "https://arxiv.org/abs/2509.03636", "authors": ["Jacqueline Maasch", "John Kalantari", "Kia Khezeli"], "title": "CausalARC: Abstract Reasoning with Causal World Models", "comment": null, "summary": "Reasoning requires adaptation to novel problem settings under limited data\nand distribution shift. This work introduces CausalARC: an experimental testbed\nfor AI reasoning in low-data and out-of-distribution regimes, modeled after the\nAbstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is\nsampled from a fully specified causal world model, formally expressed as a\nstructural causal model. Principled data augmentations provide observational,\ninterventional, and counterfactual feedback about the world model in the form\nof few-shot, in-context learning demonstrations. As a proof-of-concept, we\nillustrate the use of CausalARC for four language model evaluation settings:\n(1) abstract reasoning with test-time training, (2) counterfactual reasoning\nwith in-context learning, (3) program synthesis, and (4) causal discovery with\nlogical reasoning.", "AI": {"tldr": "CausalARC\u662f\u4e00\u4e2a\u7528\u4e8e\u4f4e\u6570\u636e\u548c\u5206\u5e03\u504f\u79fb\u4e0bAI\u63a8\u7406\u7684\u5b9e\u9a8c\u6027\u6d4b\u8bd5\u5e73\u53f0\u3002\u4f5c\u8005\u5229\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5e76\u63d0\u4f9b\u5c11\u91cf\u793a\u4f8b\u5b66\u4e60\u6f14\u793a\u6765\u589e\u5f3a\u63a8\u7406\u4efb\u52a1\u6570\u636e\u3002\u901a\u8fc7\u56db\u79cd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8bbe\u7f6e\u5c55\u793a\u4e86CausalARC\u7684\u53ef\u884c\u6027\u548c\u6f5c\u529b\uff0c\u5305\u62ec\u62bd\u8c61\u63a8\u7406\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u7a0b\u5e8f\u5408\u6210\u548c\u56e0\u679c\u53d1\u73b0\u3002", "motivation": "\u63a8\u7406\u8981\u6c42\u9002\u5e94\u4e8e\u6709\u9650\u6570\u636e\u548c\u5206\u5e03\u504f\u79fb\u7684\u65b0\u95ee\u9898\u73af\u5883\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u4f5c\u8005\u5f15\u5165\u4e86CausalARC\uff0c\u65e8\u5728\u4e3aAI\u63a8\u7406\u63d0\u4f9b\u5b9e\u9a8c\u6027\u6d4b\u8bd5\u5e73\u53f0\u3002\u901a\u8fc7\u63d0\u4f9b\u5c11\u91cf\u6f14\u793a\u6765\u6a21\u62df\u89c2\u5bdf\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u7684\u53cd\u9988\uff0c\u5e2e\u52a9AI\u7cfb\u7edf\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u7684\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u8be5\u8bba\u6587\u5229\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e3a\u6bcf\u4e2a\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u5c11\u91cf\u793a\u4f8b\u5b66\u4e60\u6f14\u793a\u6765\u5b9e\u73b0\u6570\u636e\u589e\u5f3a\u3002\u4f5c\u8005\u4ee5\u56db\u79cd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8bbe\u7f6e\u4e3a\u4f8b\uff0c\u8bc1\u660e\u4e86CausalARC\u7684\u53ef\u884c\u6027\u3002", "result": "\u901a\u8fc7\u5728\u56db\u79cd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8bbe\u7f6e\u4e2d\u5c55\u793aCausalARC\u7684\u5e94\u7528\uff0c\u4f5c\u8005\u9a8c\u8bc1\u4e86\u8be5\u6d4b\u8bd5\u5e73\u53f0\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002CausalARC\u5728\u62bd\u8c61\u63a8\u7406\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u7a0b\u5e8f\u5408\u6210\u548c\u56e0\u679c\u53d1\u73b0\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86CausalARC\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u4f4e\u6570\u636e\u548c\u5206\u5e03\u504f\u79fb\u4e2d\u7684AI\u63a8\u7406\u7684\u5b9e\u9a8c\u6027\u6d4b\u8bd5\u5e73\u53f0\u3002\u901a\u8fc7\u5728\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u62bd\u6837\u6bcf\u4e2a\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u89c2\u5bdf\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u7684\u5c11\u91cf\u793a\u4f8b\u5b66\u4e60\u6f14\u793a\uff0c\u4e3a\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u6570\u636e\u589e\u5f3a\u3002\u4f5c\u8005\u5c55\u793a\u4e86CausalARC\u5728\u56db\u79cd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8bbe\u7f6e\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u62bd\u8c61\u63a8\u7406\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u7a0b\u5e8f\u5408\u6210\u548c\u56e0\u679c\u53d1\u73b0\u3002"}}
{"id": "2509.03644", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.03644", "abs": "https://arxiv.org/abs/2509.03644", "authors": ["Fran\u00e7ois Olivier", "Zied Bouraoui"], "title": "Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations", "comment": "To appear in Proceedings of Machine Learning Research, 19th\n  Conference on Neurosymbolic Learning and Reasoning, 2025", "summary": "Despite significant progress in natural language understanding, Large\nLanguage Models (LLMs) remain error-prone when performing logical reasoning,\noften lacking the robust mental representations that enable human-like\ncomprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that\ngrounds understanding and logical reasoning in schematic representations based\non image schemas-recurring patterns derived from sensorimotor experience that\nstructure human cognition. Our system operationalizes the spatial foundations\nof these cognitive structures using declarative spatial reasoning within Answer\nSet Programming. Through evaluation on logical deduction problems, we\ndemonstrate that LLMs can be guided to interpret scenarios through embodied\ncognitive structures, that these structures can be formalized as executable\nprograms, and that the resulting representations support effective logical\nreasoning with enhanced interpretability. While our current implementation\nfocuses on spatial primitives, it establishes the computational foundation for\nincorporating more complex and dynamic representations.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86Embodied-LM\u7cfb\u7edf\uff0c\u5c06\u57fa\u4e8e\u56fe\u50cf\u6a21\u5f0f\u7684\u56fe\u5f0f\u8868\u793a\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u901a\u8fc7\u5728Answer Set Programming\u4e2d\u4f7f\u7528\u58f0\u660e\u6027\u7a7a\u95f4\u63a8\u7406\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cLLMs\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u8ba4\u77e5\u7ed3\u6784\u89e3\u91ca\u60c5\u666f\uff0c\u5f62\u5f0f\u5316\u4e3a\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u652f\u6301\u6709\u6548\u903b\u8f91\u63a8\u7406\u548c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002\u7814\u7a76\u5960\u5b9a\u4e86\u6574\u5408\u66f4\u590d\u6742\u548c\u52a8\u6001\u8868\u793a\u7684\u8ba1\u7b97\u57fa\u7840\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u4f46\u5728\u6267\u884c\u903b\u8f91\u63a8\u7406\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ecd\u7136\u5bb9\u6613\u51fa\u9519\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u611f\u77e5\u7406\u89e3\u6240\u9700\u7684\u7a33\u5065\u5fc3\u7406\u8868\u5f81\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5f15\u5165\u4e00\u79cd\u57fa\u4e8e\u56fe\u50cf\u6a21\u5f0f\u7684\u56fe\u5f0f\u8868\u793a\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff0c\u5e0c\u671b\u901a\u8fc7\u8fd9\u79cd\u7cfb\u7edf\u63d0\u9ad8LLMs\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u548c\u89e3\u91ca\u6027\u3002", "method": "\u901a\u8fc7\u5728Answer Set Programming\u4e2d\u4f7f\u7528\u58f0\u660e\u6027\u7a7a\u95f4\u63a8\u7406\uff0c\u5c06\u8ba4\u77e5\u7ed3\u6784\u57fa\u4e8e\u56fe\u50cf\u6a21\u5f0f\u7684\u56fe\u5f0f\u8868\u793a\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u901a\u8fc7Embodied-LM\u7cfb\u7edf\uff0cLLMs\u53ef\u4ee5\u5728\u903b\u8f91\u63a8\u7406\u95ee\u9898\u4e0a\u5177\u5907\u66f4\u597d\u7684\u8868\u73b0\uff0c\u652f\u6301\u6709\u6548\u7684\u903b\u8f91\u63a8\u7406\u5e76\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u3002\u7814\u7a76\u5960\u5b9a\u4e86\u5c06\u66f4\u590d\u6742\u548c\u52a8\u6001\u8868\u793a\u7eb3\u5165\u7684\u8ba1\u7b97\u57fa\u7840\u3002", "conclusion": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u539f\u578b\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edfEmbodied-LM\uff0c\u5728\u7406\u89e3\u548c\u903b\u8f91\u63a8\u7406\u4e2d\u5c06\u57fa\u4e8e\u56fe\u50cf\u6a21\u5f0f\u7684\u56fe\u5f0f\u8868\u793a\u7ed3\u5408\u5728\u4e00\u8d77\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLMs\u53ef\u4ee5\u901a\u8fc7\u5177\u8eab\u8ba4\u77e5\u7ed3\u6784\u6765\u89e3\u91ca\u60c5\u666f\uff0c\u8fd9\u4e9b\u7ed3\u6784\u53ef\u4ee5\u5f62\u5f0f\u5316\u4e3a\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u4ece\u800c\u652f\u6301\u6709\u6548\u7684\u903b\u8f91\u63a8\u7406\u548c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002\u5f53\u524d\u5b9e\u73b0\u4fa7\u91cd\u4e8e\u7a7a\u95f4\u539f\u59cb\u8981\u7d20\uff0c\u4e3a\u6574\u5408\u66f4\u590d\u6742\u548c\u52a8\u6001\u8868\u793a\u5960\u5b9a\u4e86\u8ba1\u7b97\u57fa\u7840\u3002"}}
{"id": "2509.03646", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.03646", "abs": "https://arxiv.org/abs/2509.03646", "authors": ["Haozhe Wang", "Qixin Xu", "Che Liu", "Junhong Wu", "Fangzhen Lin", "Wenhu Chen"], "title": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning", "comment": "Preprint", "summary": "Reinforcement Learning (RL) has proven highly effective at enhancing the\ncomplex reasoning abilities of Large Language Models (LLMs), yet underlying\nmechanisms driving this success remain largely opaque. Our analysis reveals\nthat puzzling phenomena like ``aha moments\", ``length-scaling'' and entropy\ndynamics are not disparate occurrences but hallmarks of an emergent reasoning\nhierarchy, akin to the separation of high-level strategic planning from\nlow-level procedural execution in human cognition. We uncover a compelling\ntwo-phase dynamic: initially, a model is constrained by procedural correctness\nand must improve its low-level skills. The learning bottleneck then decisively\nshifts, with performance gains being driven by the exploration and mastery of\nhigh-level strategic planning. This insight exposes a core inefficiency in\nprevailing RL algorithms like GRPO, which apply optimization pressure\nagnostically and dilute the learning signal across all tokens. To address this,\nwe propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that\nconcentrates optimization efforts on high-impact planning tokens. HICRA\nsignificantly outperforms strong baselines, demonstrating that focusing on this\nstrategic bottleneck is key to unlocking advanced reasoning. Furthermore, we\nvalidate semantic entropy as a superior compass for measuring strategic\nexploration over misleading metrics such as token-level entropy.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86LMM\u4e2dRL\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u6f5c\u5728\u673a\u5236\uff0c\u63d0\u51fa\u4e86HICRA\u7b97\u6cd5\u5e76\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\uff0c\u5f3a\u8c03\u4e13\u6ce8\u4e8e\u9ad8\u7ea7\u7b56\u7565\u89c4\u5212\u7684\u91cd\u8981\u6027\uff0c\u9a8c\u8bc1\u8bed\u4e49\u71b5\u4f5c\u4e3a\u66f4\u597d\u7684\u6218\u7565\u63a2\u7d22\u6307\u6807\u3002", "motivation": "\u73b0\u6709RL\u7b97\u6cd5\u5982GRPO\u5728\u5e94\u7528\u4f18\u5316\u538b\u529b\u65f6\u5bf9\u6240\u6709\u4ee4\u724c\u5747\u5300\u5206\u6563\u5b66\u4e60\u4fe1\u53f7\uff0c\u65e0\u6cd5\u6709\u6548\u63d0\u5347\u9ad8\u7ea7\u7b56\u7565\u89c4\u5212\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86\u4e13\u6ce8\u4e8e\u9ad8\u5f71\u54cd\u89c4\u5212\u4ee4\u724c\u7684HICRA\u7b97\u6cd5\u3002", "method": "\u63ed\u793a\u4e86LMM\u4e2dRL\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u6f5c\u5728\u673a\u5236\uff0c\u53d1\u73b0\u4e86\u4e24\u4e2a\u9636\u6bb5\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86HICRA\u7b97\u6cd5\u5e76\u4e0e\u57fa\u7ebf\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u9a8c\u8bc1\u4e86\u8bed\u4e49\u71b5\u7684\u4f18\u8d8a\u6027\u3002", "result": "HICRA\u660e\u663e\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\uff0c\u5f3a\u8c03\u4e13\u6ce8\u4e8e\u6218\u7565\u74f6\u9888\u5bf9\u63a8\u7406\u80fd\u529b\u7684\u91cd\u8981\u6027\uff0c\u9a8c\u8bc1\u4e86\u8bed\u4e49\u71b5\u4f5c\u4e3a\u8861\u91cf\u6218\u7565\u63a2\u7d22\u7684\u66f4\u597d\u6307\u6807\u3002", "conclusion": "\u672c\u6587\u53d1\u73b0\u4e86\u5728LMM\uff08Large Language Models\uff09\u4e2d\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6781\u5927\u63d0\u5347\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u6f5c\u5728\u673a\u5236\uff0c\u63ed\u793a\u4e86\u201caha moments\u201d\u3001\u201c\u957f\u5ea6\u6269\u5c55\u201d\u548c\u71b5\u52a8\u6001\u5e76\u975e\u5b64\u7acb\u4e8b\u4ef6\uff0c\u800c\u662f\u65b0\u5174\u63a8\u7406\u5c42\u6b21\u7684\u7279\u5f81\u3002\u63d0\u51fa\u4e86HIerarchy-Aware Credit Assignment\uff08HICRA\uff09\u7b97\u6cd5\uff0c\u96c6\u4e2d\u4f18\u5316\u9ad8\u5f71\u54cd\u529b\u89c4\u5212\u4ee4\u724c\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e13\u6ce8\u4e8e\u8fd9\u4e00\u6218\u7565\u74f6\u9888\u5bf9\u4e8e\u5f00\u542f\u5148\u8fdb\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002\u8fd8\u9a8c\u8bc1\u4e86\u8bed\u4e49\u71b5\u4f5c\u4e3a\u6d4b\u91cf\u6218\u7565\u63a2\u7d22\u7684\u4f18\u8d8a\u6307\u6807\u3002"}}
{"id": "2509.03649", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03649", "abs": "https://arxiv.org/abs/2509.03649", "authors": ["Davide Italo Serramazza", "Nikos Papadeas", "Zahraa Abdallah", "Georgiana Ifrim"], "title": "An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification", "comment": null, "summary": "Explainable AI (XAI) has become an increasingly important topic for\nunderstanding and attributing the predictions made by complex Time Series\nClassification (TSC) models. Among attribution methods, SHapley Additive\nexPlanations (SHAP) is widely regarded as an excellent attribution method; but\nits computational complexity, which scales exponentially with the number of\nfeatures, limits its practicality for long time series. To address this, recent\nstudies have shown that aggregating features via segmentation, to compute a\nsingle attribution value for a group of consecutive time points, drastically\nreduces SHAP running time. However, the choice of the optimal segmentation\nstrategy remains an open question. In this work, we investigated eight\ndifferent Time Series Segmentation algorithms to understand how segment\ncompositions affect the explanation quality. We evaluate these approaches using\ntwo established XAI evaluation methodologies: InterpretTime and AUC Difference.\nThrough experiments on both Multivariate (MTS) and Univariate Time Series\n(UTS), we find that the number of segments has a greater impact on explanation\nquality than the specific segmentation method. Notably, equal-length\nsegmentation consistently outperforms most of the custom time series\nsegmentation algorithms. Furthermore, we introduce a novel attribution\nnormalisation technique that weights segments by their length and we show that\nit consistently improves attribution quality.", "AI": {"tldr": "\u89e3\u91ca\u578b\u4eba\u5de5\u667a\u80fd(XAI)\u5bf9\u4e8e\u7406\u89e3\u548c\u5f52\u56e0\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b(TSC)\u6a21\u578b\u7684\u9884\u6d4b\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002SHAP\u88ab\u8ba4\u4e3a\u662f\u4e00\u79cd\u51fa\u8272\u7684\u5f52\u56e0\u6280\u672f\uff0c\u4f46\u5176\u8ba1\u7b97\u590d\u6742\u6027\u968f\u7740\u7279\u5f81\u6570\u91cf\u6307\u6570\u589e\u957f\u800c\u53d7\u9650\u3002\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u516b\u79cd\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u7b97\u6cd5\uff0c\u53d1\u73b0\u5206\u6bb5\u6570\u91cf\u5bf9\u89e3\u91ca\u8d28\u91cf\u7684\u5f71\u54cd\u5927\u4e8e\u7279\u5b9a\u5206\u5272\u65b9\u6cd5\u3002\u7b49\u957f\u5206\u6bb5\u901a\u5e38\u4f18\u4e8e\u81ea\u5b9a\u4e49\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u5f52\u56e0\u5f52\u4e00\u5316\u6280\u672f\u4ee5\u63d0\u9ad8\u5f52\u56e0\u8d28\u91cf\u3002", "motivation": "\u89e3\u91ca\u578b\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u5bf9\u4e8e\u7406\u89e3\u548c\u5f52\u56e0\u590d\u6742\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff08TSC\uff09\u6a21\u578b\u6240\u505a\u7684\u9884\u6d4b\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002SHapley Additive exPlanations\uff08SHAP\uff09\u88ab\u5e7f\u6cdb\u8ba4\u4e3a\u662f\u4e00\u79cd\u51fa\u8272\u7684\u5f52\u56e0\u65b9\u6cd5\uff1b\u4f46\u968f\u7740\u7279\u5f81\u6570\u91cf\u5448\u6307\u6570\u589e\u957f\uff0c\u5176\u8ba1\u7b97\u590d\u6742\u6027\u9650\u5236\u4e86\u5176\u5728\u957f\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5b9e\u7528\u6027\u3002\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u7279\u5f81\u8fdb\u884c\u5206\u5272\u4ee5\u8ba1\u7b97\u4e00\u7ec4\u8fde\u7eed\u65f6\u95f4\u70b9\u7684\u5355\u4e2a\u5f52\u56e0\u503c\uff0c\u53ef\u4ee5\u5927\u5927\u964d\u4f4eSHAP\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "method": "\u672c\u6587\u8c03\u67e5\u4e86\u516b\u79cd\u4e0d\u540c\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u7b97\u6cd5\uff0c\u4ee5\u7406\u89e3\u5206\u6bb5\u7ec4\u5408\u5982\u4f55\u5f71\u54cd\u89e3\u91ca\u8d28\u91cf\u3002\u4f5c\u8005\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u4f7f\u7528\u4e24\u79cd\u5df2\u5efa\u7acb\u7684XAI\u8bc4\u4f30\u65b9\u6cd5\uff1aInterpretTime\u548cAUC Difference\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5206\u6bb5\u6570\u91cf\u5bf9\u89e3\u91ca\u8d28\u91cf\u7684\u5f71\u54cd\u5927\u4e8e\u7279\u5b9a\u7684\u5206\u5272\u65b9\u6cd5\uff0c\u5e76\u4e14\u7b49\u957f\u5206\u6bb5\u901a\u5e38\u4f18\u4e8e\u5927\u591a\u6570\u81ea\u5b9a\u4e49\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u65b0\u7684\u5f52\u56e0\u5f52\u4e00\u5316\u6280\u672f\u901a\u8fc7\u52a0\u6743\u5206\u6bb5\u957f\u5ea6\uff0c\u63d0\u9ad8\u4e86\u5f52\u56e0\u8d28\u91cf\u3002", "conclusion": "\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u516b\u79cd\u4e0d\u540c\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u7b97\u6cd5\uff0c\u4ee5\u4e86\u89e3\u5206\u6bb5\u7ec4\u5408\u5982\u4f55\u5f71\u54cd\u89e3\u91ca\u8d28\u91cf\u3002\u6211\u4eec\u4f7f\u7528\u4e86\u4e24\u79cd\u5df2\u5efa\u7acb\u7684XAI\u8bc4\u4f30\u65b9\u6cd5\uff1aInterpretTime\u548cAUC Difference\u3002\u901a\u8fc7\u5bf9\u591a\u53d8\u91cf(MTS)\u548c\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217(UTS)\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6211\u4eec\u53d1\u73b0\u5206\u6bb5\u6570\u91cf\u5bf9\u89e3\u91ca\u8d28\u91cf\u7684\u5f71\u54cd\u5927\u4e8e\u7279\u5b9a\u5206\u5272\u65b9\u6cd5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u7b49\u957f\u5206\u6bb5\u4e00\u76f4\u4f18\u4e8e\u5927\u591a\u6570\u81ea\u5b9a\u4e49\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5f52\u4e00\u5316\u5f52\u56e0\u6280\u672f\uff0c\u901a\u8fc7\u6309\u5176\u957f\u5ea6\u52a0\u6743\u5206\u6bb5\uff0c\u6211\u4eec\u53d1\u73b0\u8fd9\u79cd\u6280\u672f\u4e0d\u65ad\u6539\u5584\u4e86\u5f52\u56e0\u8d28\u91cf\u3002"}}
{"id": "2509.03728", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.03728", "abs": "https://arxiv.org/abs/2509.03728", "authors": ["Wesley Hanwen Deng", "Sunnie S. Y. Kim", "Akshita Jha", "Ken Holstein", "Motahhare Eslami", "Lauren Wilcox", "Leon A Gatys"], "title": "PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming", "comment": null, "summary": "Recent developments in AI governance and safety research have called for\nred-teaming methods that can effectively surface potential risks posed by AI\nmodels. Many of these calls have emphasized how the identities and backgrounds\nof red-teamers can shape their red-teaming strategies, and thus the kinds of\nrisks they are likely to uncover. While automated red-teaming approaches\npromise to complement human red-teaming by enabling larger-scale exploration of\nmodel behavior, current approaches do not consider the role of identity. As an\ninitial step towards incorporating people's background and identities in\nautomated red-teaming, we develop and evaluate a novel method, PersonaTeaming,\nthat introduces personas in the adversarial prompt generation process to\nexplore a wider spectrum of adversarial strategies. In particular, we first\nintroduce a methodology for mutating prompts based on either \"red-teaming\nexpert\" personas or \"regular AI user\" personas. We then develop a dynamic\npersona-generating algorithm that automatically generates various persona types\nadaptive to different seed prompts. In addition, we develop a set of new\nmetrics to explicitly measure the \"mutation distance\" to complement existing\ndiversity measurements of adversarial prompts. Our experiments show promising\nimprovements (up to 144.1%) in the attack success rates of adversarial prompts\nthrough persona mutation, while maintaining prompt diversity, compared to\nRainbowPlus, a state-of-the-art automated red-teaming method. We discuss the\nstrengths and limitations of different persona types and mutation methods,\nshedding light on future opportunities to explore complementarities between\nautomated and human red-teaming approaches.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0cPersonaTeaming\uff0c\u65e8\u5728\u5728\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\u4e2d\u5f15\u5165\u4eba\u4eec\u7684\u80cc\u666f\u548c\u8eab\u4efd\uff0c\u4ee5\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u654c\u5bf9\u7b56\u7565\u3002\u901a\u8fc7\u89d2\u8272\u53d8\u5f02\uff0c\u6210\u529f\u63d0\u9ad8\u4e86\u5bf9\u6297\u63d0\u793a\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u591a\u6837\u6027\u3002\u7814\u7a76\u4e3a\u63a2\u7d22\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u4e4b\u95f4\u7684\u4e92\u8865\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "AI\u6cbb\u7406\u548c\u5b89\u5168\u7814\u7a76\u7684\u6700\u65b0\u53d1\u5c55\u547c\u5401\u6709\u6548\u5730\u63ed\u793aAI\u6a21\u578b\u53ef\u80fd\u5b58\u5728\u7684\u6f5c\u5728\u98ce\u9669\u3002\u8bb8\u591a\u547c\u5401\u5f3a\u8c03\u7ea2\u961f\u6210\u5458\u7684\u8eab\u4efd\u548c\u80cc\u666f\u5982\u4f55\u5f71\u54cd\u5176\u7ea2\u961f\u7b56\u7565\uff0c\u4ece\u800c\u5f71\u54cd\u4ed6\u4eec\u53ef\u80fd\u53d1\u73b0\u7684\u98ce\u9669\u7c7b\u578b\u3002\u5c3d\u7ba1\u81ea\u52a8\u5316\u7ea2\u961f\u65b9\u6cd5\u627f\u8bfa\u901a\u8fc7\u5b9e\u73b0\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u884c\u4e3a\u63a2\u7d22\u6765\u8865\u5145\u4eba\u7c7b\u7ea2\u961f\uff0c\u4f46\u5f53\u524d\u65b9\u6cd5\u5e76\u672a\u8003\u8651\u8eab\u4efd\u7684\u4f5c\u7528\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u5728\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\u4e2d\uff0c\u901a\u8fc7\u5f15\u5165\u4eba\u7684\u80cc\u666f\u548c\u8eab\u4efd\uff0c\u5f00\u53d1\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u5bf9\u6297\u7b56\u7565\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0cPersonaTeaming\uff0c\u5c06\u89d2\u8272\u5f15\u5165\u5bf9\u6297\u6027\u63d0\u793a\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u4fee\u6539\u63d0\u793a\u4e2d\u7684\u89d2\u8272\u6765\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u5bf9\u6297\u7b56\u7565\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u52a8\u6001\u7684\u89d2\u8272\u751f\u6210\u7b97\u6cd5\uff0c\u81ea\u52a8\u751f\u6210\u5404\u79cd\u9002\u5e94\u4e0d\u540c\u79cd\u5b50\u63d0\u793a\u7684\u89d2\u8272\u7c7b\u578b\u3002\u63d0\u51fa\u4e86\u4e00\u7ec4\u65b0\u5ea6\u91cf\u6807\u51c6\uff0c\u660e\u786e\u8861\u91cf\u4e86\u201c\u53d8\u5f02\u8ddd\u79bb\u201d\uff0c\u4ee5\u8865\u5145\u5bf9\u6297\u63d0\u793a\u591a\u6837\u6027\u7684\u73b0\u6709\u5ea6\u91cf\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5bf9\u6297\u63d0\u793a\u7684\u653b\u51fb\u6210\u529f\u7387\u4e2d\u901a\u8fc7\u89d2\u8272\u53d8\u5f02\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u5584\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63d0\u793a\u7684\u591a\u6837\u6027\u3002\u4e0eRainbowPlus\u76f8\u6bd4\uff0cPersonaTeaming\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe144.1%\u7684\u6539\u8fdb\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0cPersonaTeaming\uff0c\u65e8\u5728\u5728\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\u4e2d\u5f15\u5165\u4eba\u4eec\u7684\u80cc\u666f\u548c\u8eab\u4efd\uff0c\u4ee5\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u654c\u5bf9\u7b56\u7565\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u901a\u8fc7\u89d2\u8272\u53d8\u5f02\uff0c\u5728\u654c\u5bf9\u63d0\u793a\u7684\u653b\u51fb\u6210\u529f\u7387\u6709\u4e86\u663e\u8457\u6539\u5584\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63d0\u793a\u7684\u591a\u6837\u6027\u3002\u7814\u7a76\u8ba8\u8bba\u4e86\u4e0d\u540c\u89d2\u8272\u7c7b\u578b\u548c\u53d8\u5f02\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u63a2\u7d22\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u4e4b\u95f4\u7684\u4e92\u8865\u6027\u63d0\u4f9b\u4e86\u542f\u793a\u3002"}}
{"id": "2509.03730", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.03730", "abs": "https://arxiv.org/abs/2509.03730", "authors": ["Pengrui Han", "Rafal Kocielnik", "Peiyang Song", "Ramit Debnath", "Dean Mobbs", "Anima Anandkumar", "R. Michael Alvarez"], "title": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "comment": "We make public all code and source data at\n  https://github.com/psychology-of-AI/Personality-Illusion", "summary": "Personality traits have long been studied as predictors of human\nbehavior.Recent advances in Large Language Models (LLMs) suggest similar\npatterns may emerge in artificial systems, with advanced LLMs displaying\nconsistent behavioral tendencies resembling human traits like agreeableness and\nself-regulation. Understanding these patterns is crucial, yet prior work\nprimarily relied on simplified self-reports and heuristic prompting, with\nlittle behavioral validation. In this study, we systematically characterize LLM\npersonality across three dimensions: (1) the dynamic emergence and evolution of\ntrait profiles throughout training stages; (2) the predictive validity of\nself-reported traits in behavioral tasks; and (3) the impact of targeted\ninterventions, such as persona injection, on both self-reports and behavior.\nOur findings reveal that instructional alignment (e.g., RLHF, instruction\ntuning) significantly stabilizes trait expression and strengthens trait\ncorrelations in ways that mirror human data. However, these self-reported\ntraits do not reliably predict behavior, and observed associations often\ndiverge from human patterns. While persona injection successfully steers\nself-reports in the intended direction, it exerts little or inconsistent effect\non actual behavior. By distinguishing surface-level trait expression from\nbehavioral consistency, our findings challenge assumptions about LLM\npersonality and underscore the need for deeper evaluation in alignment and\ninterpretability.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9LLM\u4e2a\u6027\u7279\u5f81\u7684\u7cfb\u7edf\u6027\u8868\u5f81\u548c\u5206\u6790\u53d1\u73b0\uff0c\u6307\u5bfc\u5bf9\u9f50\u65b9\u6cd5\u80fd\u591f\u7a33\u5b9aLLM\u7684\u7279\u8d28\u8868\u8fbe\u5e76\u589e\u5f3a\u7279\u8d28\u76f8\u5173\u6027\uff0c\u4f46\u81ea\u6211\u62a5\u544a\u7684\u7279\u8d28\u65e0\u6cd5\u51c6\u786e\u9884\u6d4b\u884c\u4e3a\u3002\u4eba\u7269\u63d2\u5165\u80fd\u591f\u5f15\u5bfc\u81ea\u6211\u62a5\u544a\u53d1\u5c55\u81f3\u9884\u671f\u65b9\u5411\uff0c\u4f46\u5bf9\u5b9e\u9645\u884c\u4e3a\u5f71\u54cd\u6709\u9650\u3002\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u6709\u5173LLM\u4e2a\u6027\u7684\u5047\u8bbe\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8fdb\u884c\u66f4\u6df1\u5165\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u8fc7\u53bb\u7684\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u7b80\u5316\u7684\u81ea\u6211\u62a5\u544a\u548c\u542f\u53d1\u5f0f\u63d0\u793a\u6765\u7814\u7a76LLM\u7684\u4e2a\u6027\u7279\u5f81\uff0c\u7f3a\u4e4f\u884c\u4e3a\u9a8c\u8bc1\u3002\u4e86\u89e3\u8fd9\u4e9b\u6a21\u5f0f\u5bf9\u7814\u7a76LLM\u884c\u4e3a\u7279\u5f81\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u8868\u5f81LLM\u7684\u4e2a\u6027\u7279\u5f81\uff0c\u63a2\u8ba8\u5176\u5bf9\u81ea\u6211\u62a5\u544a\u548c\u884c\u4e3a\u7684\u8868\u73b0\uff0c\u5e76\u8bc4\u4f30\u5e72\u9884\u624b\u6bb5\u5bf9LLM\u4e2a\u6027\u7684\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9LLM\u4e2a\u6027\u8fdb\u884c\u7cfb\u7edf\u5316\u8868\u5f81\uff0c\u4ece\u52a8\u6001\u51fa\u73b0\u548c\u6f14\u53d8\u3001\u81ea\u6211\u62a5\u544a\u7279\u8d28\u5728\u884c\u4e3a\u4efb\u52a1\u4e2d\u7684\u9884\u6d4b\u6548\u5ea6\u4ee5\u53ca\u76ee\u6807\u5e72\u9884\u5bf9\u81ea\u6211\u62a5\u544a\u548c\u884c\u4e3a\u7684\u5f71\u54cd\u4e09\u4e2a\u65b9\u9762\u5c55\u5f00\u5206\u6790\u3002\u7814\u7a76\u91c7\u7528\u4e86\u6307\u5bfc\u5bf9\u9f50\u548c\u76ee\u6807\u5e72\u9884\u7b49\u65b9\u6cd5\uff0c\u5728\u4eba\u7c7b\u6570\u636e\u65b9\u9762\u5c55\u73b0\u51fa\u7c7b\u4f3c\u7684\u7279\u8d28\u76f8\u5173\u6027\u3002\u7136\u800c\uff0c\u81ea\u6211\u62a5\u544a\u7684\u7279\u8d28\u5e76\u4e0d\u80fd\u51c6\u786e\u9884\u6d4b\u884c\u4e3a\uff0c\u4e14\u4eba\u7269\u63d2\u5165\u5bf9\u771f\u5b9e\u884c\u4e3a\u5f71\u54cd\u6709\u9650\u3002\u901a\u8fc7\u533a\u5206\u8868\u9762\u5c42\u6b21\u7279\u8d28\u8868\u8fbe\u4e0e\u884c\u4e3a\u4e00\u81f4\u6027\uff0c\u6311\u6218\u4e86\u6709\u5173LLM\u4e2a\u6027\u7684\u5047\u8bbe\uff0c\u5e76\u5f3a\u8c03\u4e86\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6df1\u5165\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6307\u5bfc\u5bf9\u9f50\u65b9\u6cd5\u80fd\u7a33\u5b9a\u7279\u8d28\u8868\u8fbe\u5e76\u52a0\u5f3a\u7279\u8d28\u76f8\u5173\u6027\uff0c\u4e0e\u4eba\u7c7b\u6570\u636e\u5448\u73b0\u51fa\u7c7b\u4f3c\u7684\u6a21\u5f0f\u3002\u7136\u800c\uff0c\u81ea\u6211\u62a5\u544a\u7684\u7279\u8d28\u65e0\u6cd5\u53ef\u9760\u9884\u6d4b\u884c\u4e3a\uff0c\u4e14\u89c2\u5bdf\u5230\u7684\u5173\u8054\u7ecf\u5e38\u4e0e\u4eba\u7c7b\u6a21\u5f0f\u4e0d\u540c\u3002\u4eba\u7269\u63d2\u5165\u80fd\u5f15\u5bfc\u81ea\u6211\u62a5\u544a\u53d1\u5c55\u81f3\u9884\u671f\u65b9\u5411\uff0c\u4f46\u5bf9\u5b9e\u9645\u884c\u4e3a\u5f71\u54cd\u6709\u9650\u6216\u4e0d\u4e00\u81f4\u3002\u901a\u8fc7\u533a\u5206\u8868\u9762\u5c42\u6b21\u7279\u8d28\u8868\u8fbe\u4e0e\u884c\u4e3a\u4e00\u81f4\u6027\uff0c\u7814\u7a76\u7ed3\u679c\u5bf9LLM\u4e2a\u6027\u7684\u5047\u8bbe\u63d0\u51fa\u6311\u6218\uff0c\u5e76\u5f3a\u8c03\u4e86\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u8868\u5f81\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e2a\u6027\u7279\u5f81\u4e0a\u7684\u4e09\u4e2a\u7ef4\u5ea6\uff1a\uff081\uff09\u7279\u8d28\u8f6e\u5ed3\u5728\u8bad\u7ec3\u9636\u6bb5\u7684\u52a8\u6001\u51fa\u73b0\u548c\u6f14\u53d8\uff1b\uff082\uff09\u81ea\u6211\u62a5\u544a\u7279\u8d28\u5728\u884c\u4e3a\u4efb\u52a1\u4e2d\u7684\u9884\u6d4b\u6548\u5ea6\uff1b\u4ee5\u53ca\uff083\uff09\u76ee\u6807\u5e72\u9884\uff08\u5982\u4eba\u7269\u63d2\u5165\uff09\u5bf9\u81ea\u6211\u62a5\u544a\u548c\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u6307\u5bfc\u5bf9\u9f50\uff08\u4f8b\u5982RLHF\u3001\u6307\u5bfc\u8c03\u6574\uff09\u663e\u8457\u7a33\u5b9a\u7279\u8d28\u8868\u8fbe\uff0c\u5e76\u4ee5\u4e00\u79cd\u53cd\u6620\u4eba\u7c7b\u6570\u636e\u7684\u65b9\u5f0f\u52a0\u5f3a\u7279\u8d28\u76f8\u5173\u6027\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u81ea\u6211\u62a5\u544a\u7684\u7279\u8d28\u5e76\u4e0d\u80fd\u53ef\u9760\u5730\u9884\u6d4b\u884c\u4e3a\uff0c\u89c2\u5bdf\u5230\u7684\u5173\u8054\u5f80\u5f80\u504f\u79bb\u4eba\u7c7b\u6a21\u5f0f\u3002\u867d\u7136\u4eba\u7269\u63d2\u5165\u6210\u529f\u5f15\u5bfc\u4e86\u81ea\u6211\u62a5\u544a\u671d\u7740\u9884\u671f\u65b9\u5411\u53d1\u5c55\uff0c\u4f46\u5bf9\u5b9e\u9645\u884c\u4e3a\u7684\u5f71\u54cd\u5f88\u5c0f\u6216\u4e0d\u4e00\u81f4\u3002\u901a\u8fc7\u533a\u5206\u8868\u9762\u5c42\u6b21\u7684\u7279\u8d28\u8868\u8fbe\u4e0e\u884c\u4e3a\u4e00\u81f4\u6027\uff0c\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u5173\u4e8eLLM\u4e2a\u6027\u7684\u5047\u8bbe\uff0c\u5f3a\u8c03\u4e86\u5728\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8fdb\u884c\u66f4\u6df1\u5165\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.03736", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03736", "abs": "https://arxiv.org/abs/2509.03736", "authors": ["James Mooney", "Josef Woldense", "Zheng Robert Jia", "Shirley Anugrah Hayati", "My Ha Nguyen", "Vipul Raheja", "Dongyeop Kang"], "title": "Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation", "comment": "25 pages, 9 figures, 7 tables", "summary": "The impressive capabilities of Large Language Models (LLMs) have fueled the\nnotion that synthetic agents can serve as substitutes for real participants in\nhuman-subject research. In an effort to evaluate the merits of this claim,\nsocial science researchers have largely focused on whether LLM-generated survey\ndata corresponds to that of a human counterpart whom the LLM is prompted to\nrepresent. In contrast, we address a more fundamental question: Do agents\nmaintain internal consistency, retaining similar behaviors when examined under\ndifferent experimental settings? To this end, we develop a study designed to\n(a) reveal the agent's internal state and (b) examine agent behavior in a basic\ndialogue setting. This design enables us to explore a set of behavioral\nhypotheses to assess whether an agent's conversation behavior is consistent\nwith what we would expect from their revealed internal state. Our findings on\nthese hypotheses show significant internal inconsistencies in LLMs across model\nfamilies and at differing model sizes. Most importantly, we find that, although\nagents may generate responses matching those of their human counterparts, they\nfail to be internally consistent, representing a critical gap in their\ncapabilities to accurately substitute for real participants in human-subject\nresearch. Our simulation code and data are publicly accessible.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u5185\u90e8\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u4e00\u81f4\uff0c\u65e0\u6cd5\u51c6\u786e\u66ff\u4ee3\u771f\u5b9e\u53c2\u4e0e\u8005\u5728\u4eba\u7c7b\u4e3b\u4f53\u7814\u7a76\u4e2d\u7684\u89d2\u8272\u3002\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u63ed\u793a\u4ee3\u7406\u4eba\u5185\u90e8\u72b6\u6001\u548c\u68c0\u67e5\u4ee3\u7406\u4eba\u884c\u4e3a\uff0c\u5728\u57fa\u7840\u5bf9\u8bdd\u8bbe\u7f6e\u4e2d\u8bc4\u4f30\u4ee3\u7406\u4eba\u7684\u4f1a\u8bdd\u884c\u4e3a\u3002", "motivation": "\u76ee\u524d\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u4e3b\u8981\u5173\u6ce8LLM\u751f\u6210\u7684\u8c03\u67e5\u6570\u636e\u662f\u5426\u4e0e\u63d0\u793aLLM\u4ee3\u8868\u7684\u4eba\u7c7b\u5bf9\u5e94\u8005\u7684\u6570\u636e\u76f8\u7b26\u3002\u7136\u800c\uff0c\u8be5\u7814\u7a76\u5173\u6ce8\u66f4\u57fa\u672c\u7684\u95ee\u9898\uff0c\u5373\u4ee3\u7406\u4eba\u5728\u4e0d\u540c\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u662f\u5426\u4fdd\u6301\u5185\u90e8\u4e00\u81f4\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u9879\u7814\u7a76\uff0c\u65e8\u5728\u63ed\u793a\u4ee3\u7406\u4eba\u7684\u5185\u90e8\u72b6\u6001\u5e76\u5728\u57fa\u7840\u5bf9\u8bdd\u8bbe\u7f6e\u4e2d\u68c0\u67e5\u4ee3\u7406\u4eba\u884c\u4e3a\u3002\u901a\u8fc7\u63a2\u7d22\u4e00\u7ec4\u884c\u4e3a\u5047\u8bbe\uff0c\u8bc4\u4f30\u4ee3\u7406\u4eba\u7684\u4f1a\u8bdd\u884c\u4e3a\u662f\u5426\u4e0e\u6211\u4eec\u4ece\u4ed6\u4eec\u63ed\u793a\u7684\u5185\u90e8\u72b6\u6001\u4e2d\u6240\u671f\u671b\u7684\u4e00\u81f4\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u7cfb\u5217\u53ca\u4e0d\u540c\u6a21\u578b\u5927\u5c0f\u7684LLMs\u5b58\u5728\u663e\u8457\u7684\u5185\u90e8\u4e0d\u4e00\u81f4\u6027\u3002\u867d\u7136\u4ee3\u7406\u4eba\u53ef\u80fd\u751f\u6210\u4e0e\u4eba\u7c7b\u5bf9\u5e94\u7684\u56de\u5e94\uff0c\u4f46\u5b83\u4eec\u5728\u5185\u90e8\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u5173\u952e\u7f3a\u9677\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0LLMs\u5b58\u5728\u4e25\u91cd\u7684\u5185\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u867d\u7136\u4ee3\u7406\u4eba\u53ef\u80fd\u751f\u6210\u4e0e\u4eba\u7c7b\u5bf9\u5e94\u7684\u56de\u5e94\uff0c\u4f46\u5b83\u4eec\u5728\u5185\u90e8\u4e00\u81f4\u6027\u4e0a\u5b58\u5728\u5173\u952e\u7f3a\u9677\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u4f5c\u4e3a\u771f\u5b9e\u53c2\u4e0e\u8005\u5728\u4eba\u7c7b\u4e3b\u4f53\u7814\u7a76\u4e2d\u7684\u66ff\u4ee3\u80fd\u529b\u3002"}}
{"id": "2509.03768", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.03768", "abs": "https://arxiv.org/abs/2509.03768", "authors": ["Connor Walker", "Koorosh Aslansefat", "Mohammad Naveed Akram", "Yiannis Papadopoulos"], "title": "RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs", "comment": null, "summary": "Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet\nconventional Large Language Models (LLMs) often fail when confronted with\nhighly specialised or unexpected scenarios. We introduce RAGuard, an enhanced\nRetrieval-Augmented Generation (RAG) framework that explicitly integrates\nsafety-critical documents alongside technical manuals.By issuing parallel\nqueries to two indices and allocating separate retrieval budgets for knowledge\nand safety, RAGuard guarantees both technical depth and safety coverage. We\nfurther develop a SafetyClamp extension that fetches a larger candidate pool,\n\"hard-clamping\" exact slot guarantees to safety. We evaluate across sparse\n(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,\nmeasuring Technical Recall@K and Safety Recall@K. Both proposed extensions of\nRAG show an increase in Safety Recall@K from almost 0\\% in RAG to more than\n50\\% in RAGuard, while maintaining Technical Recall above 60\\%. These results\ndemonstrate that RAGuard and SafetyClamp have the potential to establish a new\nstandard for integrating safety assurance into LLM-powered decision support in\ncritical maintenance contexts.", "AI": {"tldr": "RAGuard and SafetyClamp enhance safety assurance in Offshore Wind maintenance by integrating safety-critical documents with technical manuals, improving Safety Recall and maintaining Technical Recall. The methods include issuing parallel queries to two indices with separate retrieval budgets and introducing the SafetyClamp extension. Evaluation across different retrieval paradigms shows significant enhancements in Safety Recall, indicating the potential for establishing a new standard in safety integration for critical maintenance tasks.", "motivation": "Accuracy and safety are crucial in Offshore Wind maintenance, and conventional Large Language Models often struggle with specialized or unexpected scenarios. The paper aims to address this challenge by enhancing safety assurance in LLM-powered decision support for critical maintenance tasks.", "method": "The paper introduces RAGuard, an enhanced Retrieval-Augmented Generation (RAG) framework that integrates safety-critical documents alongside technical manuals. It issues parallel queries to two indices with separate retrieval budgets for knowledge and safety, ensuring technical depth and safety coverage. The SafetyClamp extension fetches a larger candidate pool and hard-clamps exact slot guarantees to safety. Evaluation was done across sparse, dense, and hybrid retrieval paradigms, measuring Technical Recall@K and Safety Recall@K.", "result": "The proposed RAGuard and SafetyClamp extensions show significant improvements in Safety Recall@K, with Safety Recall increasing from almost 0% in RAG to over 50% in RAGuard, while maintaining Technical Recall above 60%. These results suggest that RAGuard and SafetyClamp could set a new standard for integrating safety assurance in LLM-powered decision support for critical maintenance tasks.", "conclusion": "RAGuard and SafetyClamp enhance safety assurance in the Offshore Wind maintenance context by integrating safety-critical documents with technical manuals, improving Safety Recall and maintaining Technical Recall."}}
{"id": "2509.03811", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03811", "abs": "https://arxiv.org/abs/2509.03811", "authors": ["Yongzhi Qi", "Jiaheng Yin", "Jianshen Zhang", "Dongyang Geng", "Zhengyu Chen", "Hao Hu", "Wei Qi", "Zuo-Jun Max Shen"], "title": "Leveraging LLM-Based Agents for Intelligent Supply Chain Planning", "comment": null, "summary": "In supply chain management, planning is a critical concept. The movement of\nphysical products across different categories, from suppliers to warehouse\nmanagement, to sales, and logistics transporting them to customers, entails the\ninvolvement of many entities. It covers various aspects such as demand\nforecasting, inventory management, sales operations, and replenishment. How to\ncollect relevant data from an e-commerce platform's perspective, formulate\nlong-term plans, and dynamically adjust them based on environmental changes,\nwhile ensuring interpretability, efficiency, and reliability, is a practical\nand challenging problem. In recent years, the development of AI technologies,\nespecially the rapid progress of large language models, has provided new tools\nto address real-world issues. In this work, we construct a Supply Chain\nPlanning Agent (SCPA) framework that can understand domain knowledge,\ncomprehend the operator's needs, decompose tasks, leverage or create new tools,\nand return evidence-based planning reports. We deploy this framework in\nJD.com's real-world scenario, demonstrating the feasibility of LLM-agent\napplications in the supply chain. It effectively reduced labor and improved\naccuracy, stock availability, and other key metrics.", "AI": {"tldr": "\u5728\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\uff0c\u901a\u8fc7\u6784\u5efaSupply Chain Planning Agent (SCPA)\u6846\u67b6\uff0c\u5e76\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4f9b\u5e94\u94fe\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002\u5c55\u793a\u4e86\u5728JD.com\u5b9e\u9645\u573a\u666f\u4e2d\u5e94\u7528LLM-agent\u7684\u53ef\u884c\u6027\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u6548\u3002", "motivation": "\u9488\u5bf9\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u9762\u4e34\u7684\u5b9e\u9645\u95ee\u9898\uff0c\u5305\u62ec\u6570\u636e\u6536\u96c6\u3001\u957f\u671f\u8ba1\u5212\u5236\u5b9a\u548c\u52a8\u6001\u8c03\u6574\u7b49\u6311\u6218\uff0c\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2aSupply Chain Planning Agent (SCPA)\u6846\u67b6\uff0c\u5728JD.com\u7684\u5b9e\u9645\u573a\u666f\u4e2d\u90e8\u7f72\uff0c\u901a\u8fc7\u7406\u89e3\u9886\u57df\u77e5\u8bc6\u3001\u4efb\u52a1\u5206\u89e3\u3001\u5229\u7528\u6216\u521b\u5efa\u65b0\u5de5\u5177\uff0c\u5e76\u8fd4\u56de\u57fa\u4e8e\u8bc1\u636e\u7684\u8ba1\u5212\u62a5\u544a\uff0c\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\u89e3\u51b3\u4e86\u4f9b\u5e94\u94fe\u4e2d\u7684\u5b9e\u9645\u548c\u5177\u6709\u6311\u6218\u6027\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u5728JD.com\u7684\u5b9e\u9645\u573a\u666f\u4e2d\u90e8\u7f72Supply Chain Planning Agent (SCPA)\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u51cf\u5c11\u52b3\u52a8\u529b\u6210\u672c\u3001\u63d0\u9ad8\u51c6\u786e\u6027\u3001\u5e93\u5b58\u53ef\u7528\u6027\u7b49\u5173\u952e\u6307\u6807\u7684\u6548\u679c\u3002", "conclusion": "\u5728\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\uff0c\u6784\u5efa\u4e86\u4e00\u4e2aSupply Chain Planning Agent (SCPA)\u6846\u67b6\uff0c\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6709\u6548\u5730\u51cf\u5c11\u52b3\u52a8\u529b\u6210\u672c\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u3001\u5e93\u5b58\u53ef\u7528\u6027\u7b49\u5173\u952e\u6307\u6807\uff0c\u5c55\u793a\u4e86LLM-agent\u5728\u4f9b\u5e94\u94fe\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.03817", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.03817", "abs": "https://arxiv.org/abs/2509.03817", "authors": ["Wei Yang", "Jesse Thomason"], "title": "Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning", "comment": null, "summary": "Multi-agent systems of large language models (LLMs) show promise for complex\nreasoning, but their effectiveness is often limited by fixed collaboration\nprotocols. These frameworks typically focus on macro-level orchestration while\noverlooking agents' internal deliberative capabilities. This critical\nmeta-cognitive blindspot treats agents as passive executors unable to adapt\ntheir strategy based on internal cognitive states like uncertainty or\nconfidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where\nagents learn a decentralized policy over a set of high-level meta-cognitive\nactions: Persist, Refine, and Concede. To overcome the instability of\ntraditional policy gradients in this setting, we develop SoftRankPO, a novel\nreinforcement learning algorithm. SoftRankPO stabilizes training by shaping\nadvantages based on the rank of rewards mapped through smooth normal quantiles,\nmaking the learning process robust to reward variance. Experiments show that\nMPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across\nfive mathematical and general reasoning benchmarks compared to six\nstate-of-the-art heuristic and learning-based multi-agent reasoning algorithms.\nOur work presents a paradigm for learning adaptive, meta-cognitive policies for\nmulti-agent LLM systems, shifting the focus from designing fixed protocols to\nlearning dynamic, deliberative strategies.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86 Meta-Policy Deliberation Framework\uff08MPDF\uff09\u548c SoftRankPO \u7b97\u6cd5\uff0c\u901a\u8fc7\u5f00\u53d1\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 SoftRankPO\uff0c\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6570\u5b66\u548c\u4e00\u822c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMPDF \u4e0e SoftRankPO \u76f8\u6bd4\u5176\u4ed6\u7b97\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e86 4-5%\u3002", "motivation": "\u76ee\u524d\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u96c6\u4e2d\u4e8e\u5b8f\u89c2\u7ea7\u522b\u7684\u534f\u8c03\uff0c\u5ffd\u7565\u4e86\u4ee3\u7406\u7684\u5185\u90e8\u601d\u8003\u80fd\u529b\u3002\u8fd9\u79cd\u5143\u8ba4\u77e5\u76f2\u70b9\u4f7f\u4ee3\u7406\u88ab\u89c6\u4e3a\u65e0\u6cd5\u6839\u636e\u5185\u90e8\u8ba4\u77e5\u72b6\u6001\uff08\u5982\u4e0d\u786e\u5b9a\u6027\u6216\u7f6e\u4fe1\u5ea6\uff09\u8c03\u6574\u7b56\u7565\u7684\u88ab\u52a8\u6267\u884c\u5668\u3002", "method": "\u63d0\u51fa\u4e86 Meta-Policy Deliberation Framework\uff08MPDF\uff09\uff0c\u5728\u9ad8\u7ea7\u5143\u8ba4\u77e5\u64cd\u4f5c\u96c6\u4e0a\uff0c\u4ee3\u7406\u5b66\u4e60\u5206\u6563\u7b56\u7565\uff1aPersist\uff0cRefine \u548c Concede\u3002\u4e3a\u4e86\u514b\u670d\u4f20\u7edf\u7b56\u7565\u68af\u5ea6\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u5f00\u53d1\u4e86 SoftRankPO\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002SoftRankPO \u901a\u8fc7\u5728\u7ecf\u8fc7\u5e73\u6ed1\u6b63\u6001\u5206\u4f4d\u6620\u5c04\u7684\u5956\u52b1\u7b49\u7ea7\u4e0a\u5851\u9020\u4f18\u52bf\u6765\u7a33\u5b9a\u8bad\u7ec3\uff0c\u4f7f\u5b66\u4e60\u8fc7\u7a0b\u5bf9\u5956\u52b1\u65b9\u5dee\u5177\u6709\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cMPDF \u4e0e SoftRankPO \u76f8\u6bd4\u5176\u4ed6\u7b97\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86\u5e73\u5747\u51c6\u786e\u7387\u3002", "conclusion": "\u4ecb\u7ecd\u4e86 Meta-Policy Deliberation Framework\uff08MPDF\uff09\u4ee5\u53ca SoftRankPO \u7b97\u6cd5\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u6570\u5b66\u548c\u4e00\u822c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMPDF \u4e0e SoftRankPO \u76f8\u6bd4\u5176\u4ed6\u516d\u79cd\u6700\u5148\u8fdb\u7684\u542f\u53d1\u5f0f\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7b97\u6cd5\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e86 4-5%\u3002"}}
{"id": "2509.03827", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03827", "abs": "https://arxiv.org/abs/2509.03827", "authors": ["Pierre Le Coz", "Jia An Liu", "Debarun Bhattacharjya", "Georgina Curto", "Serge Stinckwich"], "title": "What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly being adopted in high-stakes\ndomains. Their capacity to process vast amounts of unstructured data, explore\nflexible scenarios, and handle a diversity of contextual factors can make them\nuniquely suited to provide new insights for the complexity of social\npolicymaking. This article evaluates whether LLMs' are aligned with domain\nexperts (and among themselves) to inform social policymaking on the subject of\nhomelessness alleviation - a challenge affecting over 150 million people\nworldwide. We develop a novel benchmark comprised of decision scenarios with\npolicy choices across four geographies (South Bend, USA; Barcelona, Spain;\nJohannesburg, South Africa; Macau SAR, China). The policies in scope are\ngrounded in the conceptual framework of the Capability Approach for human\ndevelopment. We also present an automated pipeline that connects the\nbenchmarked policies to an agent-based model, and we explore the social impact\nof the recommended policies through simulated social scenarios. The paper\nresults reveal promising potential to leverage LLMs for social policy making.\nIf responsible guardrails and contextual calibrations are introduced in\ncollaboration with local domain experts, LLMs can provide humans with valuable\ninsights, in the form of alternative policies at scale.", "AI": {"tldr": "The paper evaluates the alignment of Large Language Models (LLMs) with domain experts in informing social policymaking on homelessness alleviation. It develops a novel benchmark of decision scenarios across four geographies and explores the social impact of recommended policies through simulated scenarios. The results show promising potential for LLMs in social policy making when used responsibly with local experts.", "motivation": "To evaluate the alignment of Large Language Models (LLMs) with domain experts in informing social policymaking on homelessness alleviation, a widespread challenge affecting over 150 million people worldwide.", "method": "Developed a novel benchmark of decision scenarios with policy choices across four geographies, grounded in the Capability Approach for human development. Presented an automated pipeline connecting the benchmarked policies to an agent-based model and explored the social impact of recommended policies through simulated social scenarios.", "result": "The results of the paper indicate the potential of utilizing LLMs for social policy making, highlighting the importance of responsible use and collaboration with local domain experts.", "conclusion": "LLMs have promising potential to be leveraged for social policy making with the introduction of responsible guardrails and contextual calibrations in collaboration with local domain experts."}}
{"id": "2509.03828", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03828", "abs": "https://arxiv.org/abs/2509.03828", "authors": ["Jaerong Ahn", "Andrew Wen", "Nan Wang", "Heling Jia", "Zhiyi Yue", "Sunyang Fu", "Hongfang Liu"], "title": "An Agentic Model Context Protocol Framework for Medical Concept Standardization", "comment": null, "summary": "The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)\nprovides a standardized representation of heterogeneous health data to support\nlarge-scale, multi-institutional research. One critical step in data\nstandardization using OMOP CDM is the mapping of source medical terms to OMOP\nstandard concepts, a procedure that is resource-intensive and error-prone.\nWhile large language models (LLMs) have the potential to facilitate this\nprocess, their tendency toward hallucination makes them unsuitable for clinical\ndeployment without training and expert validation. Here, we developed a\nzero-training, hallucination-preventive mapping system based on the Model\nContext Protocol (MCP), a standardized and secure framework allowing LLMs to\ninteract with external resources and tools. The system enables explainable\nmapping and significantly improves efficiency and accuracy with minimal effort.\nIt provides real-time vocabulary lookups and structured reasoning outputs\nsuitable for immediate use in both exploratory and production environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684\u96f6\u8bad\u7ec3\u3001\u9632\u6b62\u5e7b\u89c9\u7684\u6620\u5c04\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728OMOP CDM\u6570\u636e\u6807\u51c6\u5316\u8fc7\u7a0b\u4e2d\u5c06\u6e90\u533b\u5b66\u672f\u8bed\u6620\u5c04\u5230OMOP\u6807\u51c6\u6982\u5ff5\u3002\u8fd9\u9879\u7814\u7a76\u53d6\u5f97\u6210\u529f\uff0c\u5b9e\u73b0\u4e86\u6620\u5c04\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u9ad8\u4e86\u6620\u5c04\u8fc7\u7a0b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "OMOP CDM\u6570\u636e\u6807\u51c6\u5316\u8fc7\u7a0b\u4e2d\uff0c\u5c06\u6e90\u533b\u5b66\u672f\u8bed\u6620\u5c04\u5230OMOP\u6807\u51c6\u6982\u5ff5\u662f\u5173\u952e\u6b65\u9aa4\uff0c\u4f46\u8fd9\u4e00\u8fc7\u7a0b\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6709\u52a9\u4e8e\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u4f46\u5176\u5e7b\u89c9\u503e\u5411\u4f7f\u5176\u9700\u8981\u4e13\u4e1a\u8bad\u7ec3\u548c\u9a8c\u8bc1\u624d\u80fd\u7528\u4e8e\u4e34\u5e8a\u90e8\u7f72\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e00\u79cd\u96f6\u8bad\u7ec3\u3001\u9632\u6b62\u5e7b\u89c9\u7684\u6620\u5c04\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u7814\u7a76\u91c7\u7528Model Context Protocol\uff08MCP\uff09\u6846\u67b6\uff0c\u53d1\u5c55\u4e86\u4e00\u79cd\u96f6\u8bad\u7ec3\u3001\u9632\u6b62\u5e7b\u89c9\u7684\u6620\u5c04\u7cfb\u7edf\uff0c\u4ee5\u534f\u52a9\u5c06\u6e90\u533b\u5b66\u672f\u8bed\u6620\u5c04\u5230OMOP\u6807\u51c6\u6982\u5ff5\u3002\u7cfb\u7edf\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u5916\u90e8\u8d44\u6e90\u548c\u5de5\u5177\u8fdb\u884c\u4ea4\u4e92\uff0c\u5b9e\u73b0\u4e86\u6620\u5c04\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "result": "\u7814\u7a76\u5f00\u53d1\u7684\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u96f6\u8bad\u7ec3\u3001\u9632\u6b62\u5e7b\u89c9\u7684\u6620\u5c04\u7cfb\u7edf\uff0c\u80fd\u591f\u63d0\u4f9b\u5b9e\u65f6\u8bcd\u6c47\u67e5\u627e\u548c\u7ed3\u6784\u5316\u63a8\u7406\u8f93\u51fa\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684\u96f6\u8bad\u7ec3\u3001\u9632\u6b62\u5e7b\u89c9\u7684\u6620\u5c04\u7cfb\u7edf\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8OMOP CDM\u6570\u636e\u6807\u51c6\u5316\u8fc7\u7a0b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u8be5\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u65f6\u8bcd\u6c47\u67e5\u627e\u548c\u7ed3\u6784\u5316\u63a8\u7406\u8f93\u51fa\uff0c\u9002\u7528\u4e8e\u63a2\u7d22\u6027\u548c\u751f\u4ea7\u73af\u5883\uff0c\u53ef\u4ee5\u7acb\u5373\u6295\u5165\u4f7f\u7528\u3002"}}
{"id": "2509.03830", "categories": ["cs.AI", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.03830", "abs": "https://arxiv.org/abs/2509.03830", "authors": ["Kaizhen Tan", "Yufan Wu", "Yuxuan Liu", "Haoran Zeng"], "title": "A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai", "comment": null, "summary": "Historic urban quarters play a vital role in preserving cultural heritage\nwhile serving as vibrant spaces for tourism and everyday life. Understanding\nhow tourists perceive these environments is essential for sustainable,\nhuman-centered urban planning. This study proposes a multidimensional\nAI-powered framework for analyzing tourist perception in historic urban\nquarters using multimodal data from social media. Applied to twelve historic\nquarters in central Shanghai, the framework integrates focal point extraction,\ncolor theme analysis, and sentiment mining. Visual focus areas are identified\nfrom tourist-shared photos using a fine-tuned semantic segmentation model. To\nassess aesthetic preferences, dominant colors are extracted using a clustering\nmethod, and their spatial distribution across quarters is analyzed. Color\nthemes are further compared between social media photos and real-world street\nviews, revealing notable shifts. This divergence highlights potential gaps\nbetween visual expectations and the built environment, reflecting both\nstylistic preferences and perceptual bias. Tourist reviews are evaluated\nthrough a hybrid sentiment analysis approach combining a rule-based method and\na multi-task BERT model. Satisfaction is assessed across four dimensions:\ntourist activities, built environment, service facilities, and business\nformats. The results reveal spatial variations in aesthetic appeal and\nemotional response. Rather than focusing on a single technical innovation, this\nframework offers an integrated, data-driven approach to decoding tourist\nperception and contributes to informed decision-making in tourism, heritage\nconservation, and the design of aesthetically engaging public spaces.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u6e38\u5ba2\u5728\u5386\u53f2\u57ce\u533a\u7684\u611f\u77e5\u3002\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u5206\u6790\u548c\u591a\u79cd\u65b9\u6cd5\uff0c\u7814\u7a76\u8005\u6210\u529f\u89e3\u7801\u4e86\u6e38\u5ba2\u5bf9\u5386\u53f2\u57ce\u533a\u7684\u5ba1\u7f8e\u504f\u597d\u548c\u60c5\u611f\u53cd\u5e94\uff0c\u63ed\u793a\u4e86\u7a7a\u95f4\u5dee\u5f02\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u65c5\u6e38\u4e1a\u3001\u9057\u4ea7\u4fdd\u62a4\u548c\u516c\u5171\u7a7a\u95f4\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6570\u636e\u652f\u6301\uff0c\u4fc3\u8fdb\u4e86\u51b3\u7b56\u7684\u660e\u667a\u5236\u5b9a\u3002", "motivation": "\u5386\u53f2\u57ce\u533a\u5728\u4fdd\u62a4\u6587\u5316\u9057\u4ea7\u7684\u540c\u65f6\uff0c\u4e5f\u662f\u65c5\u6e38\u548c\u65e5\u5e38\u751f\u6d3b\u4e2d\u5145\u6ee1\u6d3b\u529b\u7684\u573a\u6240\u3002\u4e86\u89e3\u6e38\u5ba2\u5982\u4f55\u611f\u77e5\u8fd9\u4e9b\u73af\u5883\u5bf9\u4e8e\u53ef\u6301\u7eed\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u57ce\u5e02\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u6846\u67b6\uff0c\u5e2e\u52a9\u5206\u6790\u6e38\u5ba2\u5bf9\u5386\u53f2\u57ce\u533a\u7684\u611f\u77e5\uff0c\u4ece\u800c\u4fc3\u8fdb\u65c5\u6e38\u4e1a\u3001\u9057\u4ea7\u4fdd\u62a4\u548c\u7f8e\u5b66\u516c\u5171\u7a7a\u95f4\u8bbe\u8ba1\u7684\u51b3\u7b56\u63d0\u5347\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e86\u591a\u6a21\u6001\u6570\u636e\u5206\u6790\u3001\u7126\u70b9\u63d0\u53d6\u3001\u8272\u5f69\u4e3b\u9898\u5206\u6790\u548c\u60c5\u611f\u6316\u6398\u7b49\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u8bed\u4e49\u5206\u5272\u6a21\u578b\u3001\u805a\u7c7b\u65b9\u6cd5\u3001\u89c4\u5219-based\u65b9\u6cd5\u548c\u591a\u4efb\u52a1BERT\u6a21\u578b\u3002\u901a\u8fc7\u6574\u5408\u8fd9\u4e9b\u6280\u672f\uff0c\u7814\u7a76\u8005\u6210\u529f\u5730\u89e3\u7801\u4e86\u6e38\u5ba2\u5bf9\u5386\u53f2\u57ce\u533a\u7684\u611f\u77e5\uff0c\u63ed\u793a\u4e86\u6e38\u5ba2\u5bf9\u7f8e\u5b66\u504f\u597d\u548c\u60c5\u611f\u53cd\u5e94\u7684\u7a7a\u95f4\u5dee\u5f02\u3002", "result": "\u901a\u8fc7\u7814\u7a76\uff0c\u53d1\u73b0\u6e38\u5ba2\u5728\u5ba1\u7f8e\u504f\u597d\u548c\u60c5\u611f\u53cd\u5e94\u65b9\u9762\u5b58\u5728\u7a7a\u95f4\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u89c6\u89c9\u671f\u671b\u548c\u5efa\u7b51\u73af\u5883\u4e4b\u95f4\u7684\u6f5c\u5728\u5dee\u8ddd\u3002\u5728\u6e38\u5ba2\u8bc4\u8bba\u65b9\u9762\uff0c\u7814\u7a76\u8005\u8bc4\u4f30\u4e86\u6ee1\u610f\u5ea6\u5728\u6e38\u5ba2\u6d3b\u52a8\u3001\u5efa\u7b51\u73af\u5883\u3001\u670d\u52a1\u8bbe\u65bd\u548c\u5546\u4e1a\u683c\u5f0f\u56db\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u60c5\u51b5\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u4e86\u5386\u53f2\u57ce\u533a\u7684\u5ba1\u7f8e\u5438\u5f15\u529b\u548c\u60c5\u611f\u53cd\u5e94\u5b58\u5728\u7a7a\u95f4\u53d8\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u7ef4\u5ea6\u7684\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u6e38\u5ba2\u5bf9\u5386\u53f2\u57ce\u533a\u7684\u611f\u77e5\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u65c5\u6e38\u8005\u5728\u5ba1\u7f8e\u504f\u597d\u548c\u60c5\u611f\u53cd\u5e94\u65b9\u9762\u7684\u7a7a\u95f4\u53d8\u5316\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u7684\u591a\u6a21\u6001\u6570\u636e\uff0c\u7ed3\u5408\u4e86\u7126\u70b9\u63d0\u53d6\u3001\u8272\u5f69\u4e3b\u9898\u5206\u6790\u548c\u60c5\u611f\u6316\u6398\u7b49\u65b9\u6cd5\uff0c\u4e3a\u65c5\u6e38\u3001\u9057\u4ea7\u4fdd\u62a4\u548c\u516c\u5171\u7a7a\u95f4\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2509.03857", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03857", "abs": "https://arxiv.org/abs/2509.03857", "authors": ["Kishor Datta Gupta", "Mohd Ariful Haque", "Hasmot Ali", "Marufa Kamal", "Syed Bahauddin Alam", "Mohammad Ashiqur Rahman"], "title": "Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures", "comment": null, "summary": "Generative AI (GEN AI) models have revolutionized diverse application domains\nbut present substantial challenges due to reliability concerns, including\nhallucinations, semantic drift, and inherent biases. These models typically\noperate as black-boxes, complicating transparent and objective evaluation.\nCurrent evaluation methods primarily depend on subjective human assessment,\nlimiting scalability, transparency, and effectiveness. This research proposes a\nsystematic methodology using deterministic and Large Language Model\n(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN\nAI reliability. We construct two parallel KGs: (i) a deterministic KG built\nusing explicit rule-based methods, predefined ontologies, domain-specific\ndictionaries, and structured entity-relation extraction rules, and (ii) an\nLLM-generated KG dynamically derived from real-time textual data streams such\nas live news articles. Utilizing real-time news streams ensures authenticity,\nmitigates biases from repetitive training, and prevents adaptive LLMs from\nbypassing predefined benchmarks through feedback memorization. To quantify\nstructural deviations and semantic discrepancies, we employ several established\nKG metrics, including Instantiated Class Ratio (ICR), Instantiated Property\nRatio (IPR), and Class Instantiation (CI). An automated real-time monitoring\nframework continuously computes deviations between deterministic and\nLLM-generated KGs. By establishing dynamic anomaly thresholds based on\nhistorical structural metric distributions, our method proactively identifies\nand flags significant deviations, thus promptly detecting semantic anomalies or\nhallucinations. This structured, metric-driven comparison between deterministic\nand dynamically generated KGs delivers a robust and scalable evaluation\nframework.", "AI": {"tldr": "GEN AI\u6a21\u578b\u5b58\u5728\u53ef\u9760\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u6765\u8bc4\u4f30GEN AI\u7684\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u786e\u5b9a\u6027\u548c\u57fa\u4e8eLLM\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u6307\u6807\u91cf\u5316\u7ed3\u6784\u504f\u5dee\u548c\u8bed\u4e49\u5dee\u5f02\uff0c\u5efa\u7acb\u52a8\u6001\u5f02\u5e38\u9608\u503c\uff0c\u5e76\u5b9e\u73b0\u5b9e\u65f6\u76d1\u6d4b\u4ee5\u53ca\u5feb\u901f\u68c0\u6d4b\u8bed\u4e49\u5f02\u5e38\u6216\u5e7b\u89c9\u3002", "motivation": "GEN AI\u6a21\u578b\u5b58\u5728\u53ef\u9760\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u5305\u62ec\u5e7b\u89c9\u3001\u8bed\u4e49\u6f02\u79fb\u548c\u56fa\u6709\u504f\u89c1\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e3b\u89c2\u4eba\u5de5\u8bc4\u4f30\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u5ea6\u548c\u6709\u6548\u6027\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u901a\u8fc7\u6bd4\u8f83\u786e\u5b9a\u6027\u548c\u57fa\u4e8eLLM\u7684\u77e5\u8bc6\u56fe\u8c31\u6765\u8bc4\u4f30GEN AI\u7684\u53ef\u9760\u6027\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u6784\u5efa\u4e24\u4e2a\u5e73\u884c\u7684\u77e5\u8bc6\u56fe\u8c31\uff08KGs\uff09\uff1a\u4e00\u4e2a\u786e\u5b9a\u6027KG\u548c\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u52a8\u6001KG\uff0c\u4f7f\u7528\u5b9e\u65f6\u6587\u672c\u6570\u636e\u6d41\u6765\u4e0d\u65ad\u76d1\u6d4bGEN AI\u7684\u53ef\u9760\u6027\u3002\u501f\u52a9\u591a\u4e2a\u5df2\u5efa\u7acb\u7684\u77e5\u8bc6\u56fe\u8c31\u6307\u6807\uff0c\u5982\u5b9e\u4f8b\u5316\u7c7b\u6bd4\u7387\uff08ICR\uff09\u3001\u5b9e\u4f8b\u5316\u5c5e\u6027\u6bd4\u7387\uff08IPR\uff09\u548c\u7c7b\u5b9e\u4f8b\u5316\uff08CI\uff09\uff0c\u5bf9\u7ed3\u6784\u504f\u5dee\u548c\u8bed\u4e49\u5dee\u5f02\u8fdb\u884c\u91cf\u5316\u3002\u5efa\u7acb\u52a8\u6001\u5f02\u5e38\u9608\u503c\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u5386\u53f2\u7ed3\u6784\u5ea6\u91cf\u5206\u5e03\u7684\u65b9\u6cd5\uff0c\u53ca\u65f6\u8bc6\u522b\u5e76\u6807\u8bb0\u91cd\u5927\u504f\u5dee\uff0c\u4ee5\u5feb\u901f\u68c0\u6d4b\u8bed\u4e49\u5f02\u5e38\u6216\u5e7b\u89c9\u3002", "result": "\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u5b9e\u65f6\u76d1\u6d4b\u6846\u67b6\uff0c\u6301\u7eed\u8ba1\u7b97\u786e\u5b9a\u6027\u548cLLM-generated KGs\u4e4b\u95f4\u7684\u504f\u5dee\u3002\u901a\u8fc7\u5efa\u7acb\u52a8\u6001\u5f02\u5e38\u9608\u503c\uff0c\u53ca\u65f6\u8bc6\u522b\u548c\u6807\u8bb0\u91cd\u5927\u504f\u5dee\uff0c\u4ece\u800c\u8fc5\u901f\u68c0\u6d4b\u8bed\u4e49\u5f02\u5e38\u6216\u5e7b\u89c9\u3002\u6700\u7ec8\u5efa\u7acb\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u3001\u5ea6\u91cf\u9a71\u52a8\u7684\u786e\u5b9a\u6027\u548c\u52a8\u6001\u751f\u6210KGs\u4e4b\u95f4\u7684\u6bd4\u8f83\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u548c\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5229\u7528\u786e\u5b9a\u6027\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7684\u77e5\u8bc6\u56fe\u8c31\uff08KGs\uff09\u6765\u6301\u7eed\u76d1\u6d4b\u548c\u8bc4\u4f30GEN AI\u7684\u53ef\u9760\u6027\u3002\u901a\u8fc7\u5efa\u7acb\u786e\u5b9a\u6027\u77e5\u8bc6\u56fe\u8c31\u548c\u57fa\u4e8eLLM\u7684\u77e5\u8bc6\u56fe\u8c31\u7684\u5bf9\u6bd4\uff0c\u7ed3\u5408\u591a\u4e2a\u5df2\u5efa\u7acb\u7684\u77e5\u8bc6\u56fe\u8c31\u6307\u6807\uff0c\u53ef\u4ee5\u6709\u6548\u91cf\u5316\u7ed3\u6784\u504f\u5dee\u548c\u8bed\u4e49\u5dee\u5f02\uff0c\u4ece\u800c\u5efa\u7acb\u4e86\u4e00\u79cd\u5f3a\u5927\u4e14\u53ef\u4f38\u7f29\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2509.03863", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03863", "abs": "https://arxiv.org/abs/2509.03863", "authors": ["Sina Khajehabdollahi", "Gautier Hamon", "Marko Cvjetko", "Pierre-Yves Oudeyer", "Cl\u00e9ment Moulin-Frier", "C\u00e9dric Colas"], "title": "Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata", "comment": null, "summary": "Discovering diverse visual patterns in continuous cellular automata (CA) is\nchallenging due to the vastness and redundancy of high-dimensional behavioral\nspaces. Traditional exploration methods like Novelty Search (NS) expand locally\nby mutating known novel solutions but often plateau when local novelty is\nexhausted, failing to reach distant, unexplored regions. We introduce\nExpedition and Expansion (E&E), a hybrid strategy where exploration alternates\nbetween local novelty-driven expansions and goal-directed expeditions. During\nexpeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic\ngoals--descriptions of interesting but hypothetical patterns that drive\nexploration toward uncharted regions. By operating in semantic spaces that\nalign with human perception, E&E both evaluates novelty and generates goals in\nconceptually meaningful ways, enhancing the interpretability and relevance of\ndiscovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,\nemergent behaviors, E&E consistently uncovers more diverse solutions than\nexisting exploration methods. A genealogical analysis further reveals that\nsolutions originating from expeditions disproportionately influence long-term\nexploration, unlocking new behavioral niches that serve as stepping stones for\nsubsequent search. These findings highlight E&E's capacity to break through\nlocal novelty boundaries and explore behavioral landscapes in human-aligned,\ninterpretable ways, offering a promising template for open-ended exploration in\nartificial life and beyond.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aExpedition and Expansion\uff08E&E\uff09\u7684\u6df7\u5408\u7b56\u7565\uff0c\u7528\u4e8e\u53d1\u73b0\u8fde\u7eed\u7ec6\u80de\u81ea\u52a8\u673a\u4e2d\u591a\u6837\u7684\u89c6\u89c9\u6a21\u5f0f\u3002\u901a\u8fc7\u4ea4\u66ff\u8fdb\u884c\u672c\u5730\u65b0\u9896\u6027\u6269\u5c55\u548c\u76ee\u6807\u5bfc\u5411\u8fdc\u5f81\uff0c\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u8a00\u76ee\u6807\uff0cE&E\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u6301\u7eed\u53d1\u73b0\u591a\u6837\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\uff0c\u4e14\u8fdc\u5f81\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u957f\u671f\u63a2\u7d22\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u63a2\u7d22\u8fde\u7eed\u7ec6\u80de\u81ea\u52a8\u673a\u9886\u57df\u4e2d\u7684\u591a\u6837\u5316\u89c6\u89c9\u6a21\u5f0f\u65f6\uff0c\u5c40\u9650\u4e8e\u5c40\u90e8\u65b0\u9896\u6027\uff0c\u96be\u4ee5\u8fbe\u5230\u9065\u8fdc\u3001\u672a\u7ecf\u63a2\u7d22\u7684\u533a\u57df\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u7b56\u7565\u6765\u514b\u670d\u8fd9\u4e00\u6311\u6218\uff0c\u540c\u65f6\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u7684\u591a\u6837\u6027\u548c\u957f\u671f\u63a2\u7d22\u7684\u6548\u679c\u3002", "method": "E&E\u65b9\u6cd5\u4ea4\u66ff\u8fdb\u884c\u672c\u5730\u65b0\u9896\u6027\u9a71\u52a8\u7684\u6269\u5c55\u548c\u76ee\u6807\u5bfc\u5411\u7684\u8fdc\u5f81\uff0c\u5229\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u751f\u6210\u8bed\u8a00\u76ee\u6807\uff0c\u5c06\u63a2\u7d22\u5f15\u5411\u672a\u7ecf\u52d8\u67e5\u7684\u533a\u57df\u3002\u5728Flow Lenia\u4e0a\u6d4b\u8bd5\u7684\u7ed3\u679c\u663e\u793a\uff0cE&E\u80fd\u591f\u6301\u7eed\u63ed\u793a\u6bd4\u73b0\u6709\u63a2\u7d22\u65b9\u6cd5\u66f4\u591a\u6837\u7684\u89e3\u51b3\u65b9\u6848\u3002\u57fa\u56e0\u8c31\u5206\u6790\u663e\u793a\uff0c\u8fdc\u5f81\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u957f\u671f\u63a2\u7d22\u5f71\u54cd\u5de8\u5927\uff0c\u4e3a\u540e\u7eed\u641c\u7d22\u63d0\u4f9b\u4e86\u65b0\u7684\u884c\u4e3a\u9886\u57df\u3002", "result": "E&E\u65b9\u6cd5\u5728Flow Lenia\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u6301\u7eed\u53d1\u73b0\u66f4\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e14\u8fdc\u5f81\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u957f\u671f\u63a2\u7d22\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aExpedition and Expansion\uff08E&E\uff09\u7684\u6df7\u5408\u7b56\u7565\uff0c\u7ed3\u5408\u672c\u5730\u65b0\u9896\u6027\u9a71\u52a8\u7684\u6269\u5c55\u548c\u76ee\u6807\u5bfc\u5411\u7684\u8fdc\u5f81\uff0c\u4ee5\u53d1\u73b0\u8fde\u7eed\u7ec6\u80de\u81ea\u52a8\u673a\u4e2d\u591a\u6837\u5316\u7684\u89c6\u89c9\u6a21\u5f0f\u3002\u7814\u7a76\u8868\u660e\uff0cE&E\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u63a2\u7d22\u65b9\u6cd5\u80fd\u591f\u6301\u7eed\u53d1\u73b0\u66f4\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e14\u8fdc\u5f81\u8fc7\u7a0b\u4ea7\u751f\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u957f\u671f\u63a2\u7d22\u5177\u6709\u4e0d\u6210\u6bd4\u4f8b\u7684\u5f71\u54cd\u3002\u8be5\u65b9\u6cd5\u7a81\u7834\u4e86\u5c40\u90e8\u65b0\u9896\u6027\u8fb9\u754c\uff0c\u4ee5\u4eba\u7c7b\u5bf9\u9f50\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u63a2\u7d22\u884c\u4e3a\u666f\u89c2\u3002"}}
{"id": "2509.03890", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03890", "abs": "https://arxiv.org/abs/2509.03890", "authors": ["Yineng Yan", "Xidong Wang", "Jin Seng Cheng", "Ran Hu", "Wentao Guan", "Nahid Farahmand", "Hengte Lin", "Yue Li"], "title": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "comment": null, "summary": "The emergence of agentic AI, powered by Large Language Models (LLMs), marks a\nparadigm shift from reactive generative systems to proactive, goal-oriented\nautonomous agents capable of sophisticated planning, memory, and tool use. This\nevolution presents a novel opportunity to address long-standing challenges in\ncomplex digital environments. Core tasks on Consumer-to-Consumer (C2C)\ne-commerce platforms often require users to navigate complex Graphical User\nInterfaces (GUIs), making the experience time-consuming for both buyers and\nsellers. This paper introduces a novel approach to simplify these interactions\nthrough an LLM-powered agentic assistant. This agent functions as a new,\nconversational entry point to the marketplace, shifting the primary interaction\nmodel from a complex GUI to an intuitive AI agent. By interpreting natural\nlanguage commands, the agent automates key high-friction workflows. For\nsellers, this includes simplified updating and renewal of listings, and the\nability to send bulk messages. For buyers, the agent facilitates a more\nefficient product discovery process through conversational search. We present\nthe architecture for Facebook Marketplace Assistant (FaMA), arguing that this\nagentic, conversational paradigm provides a lightweight and more accessible\nalternative to traditional app interfaces, allowing users to manage their\nmarketplace activities with greater efficiency. Experiments show FaMA achieves\na 98% task success rate on solving complex tasks on the marketplace and enables\nup to a 2x speedup on interaction time.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u901a\u8fc7LLMs\u9a71\u52a8\u7684\u81ea\u4e3b\u4ee3\u7406\u52a9\u624b\uff0c\u5728C2C\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u4e0a\u63d0\u4f9b\u66f4\u7b80\u5316\u3001\u9ad8\u6548\u7684\u7528\u6237\u4ea4\u4e92\u4f53\u9a8c\u3002FaMA\u67b6\u6784\u5b9e\u73b0\u4e86\u9ad8\u6210\u529f\u7387\u7684\u4efb\u52a1\u89e3\u51b3\u548c\u4ea4\u4e92\u65f6\u95f4\u7684\u52a0\u901f\u3002", "motivation": "\u4f5c\u8005\u4ee5\u6539\u5584C2C\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u7528\u6237\u4f53\u9a8c\u4e3a\u52a8\u673a\uff0c\u63d0\u51fa\u91c7\u7528\u65b0\u578b\u4ee3\u7406\u52a9\u624b\u7684\u65b9\u6cd5\u6765\u7b80\u5316\u4ea4\u4e92\u8fc7\u7a0b\u3002", "method": "\u8be5\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u4ee3\u7406\u52a9\u624b\uff0c\u5c06\u7528\u6237\u4e0e\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u7684\u4ea4\u4e92\u65b9\u5f0f\u4ece\u590d\u6742\u7684GUI\u8f6c\u53d8\u4e3a\u76f4\u89c2\u7684AI\u4ee3\u7406\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684Facebook Marketplace Assistant\uff08FaMA\uff09\u67b6\u6784\u5b9e\u73b0\u4e8698%\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5e76\u4f7f\u4ea4\u4e92\u65f6\u95f4\u52a0\u5feb\u4e86\u6700\u591a2\u500d\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9a71\u52a8\u7684\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\uff0c\u65e8\u5728\u7b80\u5316\u5728C2C\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u4e0a\u7684\u7528\u6237\u4ea4\u4e92\u4f53\u9a8c\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u4ee3\u7406\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u548c\u63d0\u9ad8\u5e02\u573a\u6d3b\u52a8\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.03906", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03906", "abs": "https://arxiv.org/abs/2509.03906", "authors": ["Qika Lin", "Yifan Zhu", "Bin Pu", "Ling Huang", "Haoran Luo", "Jingying Ma", "Zhen Peng", "Tianzhe Zhao", "Fangzhi Xu", "Jian Zhang", "Kai He", "Zhonghong Ou", "Swapnil Mishra", "Mengling Feng"], "title": "A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning", "comment": "15 pages", "summary": "Medical foundation models (FMs) have shown tremendous promise amid the rapid\nadvancements in artificial intelligence (AI) technologies. However, current\nmedical FMs typically generate answers in a black-box manner, lacking\ntransparent reasoning processes and locally grounded interpretability, which\nhinders their practical clinical deployments. To this end, we introduce\nDeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It\nleverages a sequential training pipeline: initially fine-tuned on curated CXR\ninstruction data to equip with fundamental CXR interpretation capabilities,\nthen exposed to high-quality synthetic reasoning samples to enable cold-start\nreasoning, and finally refined via online reinforcement learning to enhance\nboth grounded reasoning quality and generation performance. Thus, the model\nproduces both an answer and reasoning steps tied to the image's local regions\nfor each query. Quantitative evaluation demonstrates substantial improvements\nin report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and\nvisual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)\ntasks. To facilitate robust assessment, we propose Report Arena, a benchmarking\nframework using advanced language models to evaluate answer quality, further\nhighlighting the superiority of DeepMedix-R1. Expert review of generated\nreasoning steps reveals greater interpretability and clinical plausibility\ncompared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall\npreference). Collectively, our work advances medical FM development toward\nholistic, transparent, and clinically actionable modeling for CXR\ninterpretation.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86DeepMedix-R1\uff0c\u662f\u4e00\u79cd\u7efc\u5408\u7684\u533b\u5b66\u57fa\u7840\u6a21\u578b\uff0c\u7528\u4e8e\u80f8\u90e8X\u5c04\u7ebf\u89e3\u91ca\u3002\u901a\u8fc7\u987a\u5e8f\u8bad\u7ec3\u6d41\u7a0b\uff0c\u6539\u8fdb\u6a21\u578b\u7684\u63a8\u7406\u8d28\u91cf\u548c\u751f\u6210\u6027\u80fd\u3002\u63d0\u51fa\u4e86\u8bc4\u4f30\u56de\u7b54\u8d28\u91cf\u7684Report Arena\u6846\u67b6\u3002DeepMedix-R1\u5728\u62a5\u544a\u751f\u6210\u548c\u53ef\u89c6\u5316\u95ee\u9898\u56de\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u7740\u6539\u5584\u3002", "motivation": "\u76ee\u524d\u7684\u533b\u5b66\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u7684\u63a8\u7406\u8fc7\u7a0b\u548c\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5b9e\u9645\u4e34\u5e8a\u90e8\u7f72\u4e2d\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5f15\u5165\u4e86DeepMedix-R1\uff0c\u65e8\u5728\u63d0\u4f9b\u7efc\u5408\u3001\u900f\u660e\u548c\u4e34\u5e8a\u53ef\u64cd\u4f5c\u7684CXR\u89e3\u91ca\u5efa\u6a21\u3002", "method": "\u5229\u7528\u987a\u5e8f\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5305\u62ec\u5728\u80f8\u90e8X\u5c04\u7ebf\u6307\u5bfc\u6570\u636e\u4e0a\u8fdb\u884c\u521d\u6b65\u5fae\u8c03\u3001\u66b4\u9732\u4e8e\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u63a8\u7406\u6837\u672c\u4ee5\u8fdb\u884c\u51b7\u542f\u52a8\u63a8\u7406\uff0c\u6700\u540e\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u6539\u8fdb\uff0c\u4ee5\u63d0\u9ad8\u63a8\u7406\u8d28\u91cf\u548c\u751f\u6210\u6027\u80fd\u3002\u63d0\u51fa\u4e86Report Arena\u57fa\u51c6\u6846\u67b6\uff0c\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u56de\u7b54\u8d28\u91cf\u3002", "result": "\u5728\u62a5\u544a\u751f\u6210\u548c\u53ef\u89c6\u5316\u95ee\u9898\u56de\u7b54\u4efb\u52a1\u4e2d\uff0cDeepMedix-R1\u76f8\u6bd4\u5176\u4ed6\u6a21\u578b\u8868\u73b0\u51fa\u660e\u663e\u6539\u5584\uff0c\u4e13\u5bb6\u8bc4\u5ba1\u8ba4\u4e3a\u5176\u63a8\u7406\u6b65\u9aa4\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e34\u5e8a\u5408\u7406\u6027\u3002", "conclusion": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86DeepMedix-R1\uff0c\u8fd9\u662f\u4e00\u4e2a\u7efc\u5408\u7684\u533b\u5b66\u57fa\u7840\u6a21\u578b\uff0c\u7528\u4e8e\u80f8\u90e8X\u5c04\u7ebf\uff08CXR\uff09\u89e3\u91ca\u3002\u901a\u8fc7\u987a\u5e8f\u8bad\u7ec3\u6d41\u7a0b\uff0c\u8be5\u6a21\u578b\u5728\u80f8\u90e8X\u5c04\u7ebf\u6307\u5bfc\u6570\u636e\u4e0a\u8fdb\u884c\u521d\u6b65\u5fae\u8c03\uff0c\u7136\u540e\u66b4\u9732\u4e8e\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u63a8\u7406\u6837\u672c\uff0c\u6700\u7ec8\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u6539\u8fdb\uff0c\u4ee5\u63d0\u9ad8\u624e\u6839\u63a8\u7406\u8d28\u91cf\u548c\u751f\u6210\u6027\u80fd\u3002\u901a\u8fc7\u672c\u6a21\u578b\uff0c\u9488\u5bf9\u6bcf\u4e2a\u67e5\u8be2\uff0c\u751f\u6210\u4e0e\u56fe\u50cf\u5c40\u90e8\u533a\u57df\u76f8\u5173\u7684\u7b54\u6848\u548c\u63a8\u7406\u6b65\u9aa4\u3002\u5b9a\u91cf\u8bc4\u4f30\u8868\u660e\uff0c\u5728\u62a5\u544a\u751f\u6210\u548c\u53ef\u89c6\u5316\u95ee\u9898\u56de\u7b54\u4efb\u52a1\u4e2d\uff0cDeepMedix-R1\u76f8\u6bd4LLaVA-Rad\u548cMedGemma\u7b49\u6a21\u578b\u6709\u663e\u7740\u63d0\u9ad8\u3002\u901a\u8fc7\u63d0\u51faReport Arena\u57fa\u51c6\u6846\u67b6\uff0c\u4f7f\u7528\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u56de\u7b54\u8d28\u91cf\uff0c\u8fdb\u4e00\u6b65\u51f8\u663e\u4e86DeepMedix-R1\u7684\u4f18\u8d8a\u6027\u3002\u4e13\u5bb6\u8bc4\u5ba1\u53d1\u73b0\uff0c\u76f8\u6bd4\u4e8eQwen2.5-VL-7B\u6a21\u578b\uff0c\u751f\u6210\u7684\u63a8\u7406\u6b65\u9aa4\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e34\u5e8a\u5408\u7406\u6027\u3002\u603b\u7684\u6765\u8bf4\uff0c\u672c\u7814\u7a76\u63a8\u52a8\u4e86\u533b\u5b66\u57fa\u7840\u6a21\u578b\u5f00\u53d1\uff0c\u5b9e\u73b0\u4e86\u7efc\u5408\u3001\u900f\u660e\u548c\u4e34\u5e8a\u53ef\u64cd\u4f5c\u7684CXR\u89e3\u91ca\u5efa\u6a21\u3002"}}
{"id": "2509.03953", "categories": ["cs.AI", "cs.SC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.03953", "abs": "https://arxiv.org/abs/2509.03953", "authors": ["\u00c1ngel Aso-Mollar", "Diego Aineto", "Enrico Scala", "Eva Onaindia"], "title": "Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions", "comment": "To appear in the Proceedings of the Thirty-Fourth International Joint\n  Conference on Artificial Intelligence (IJCAI 2025)", "summary": "In automated planning, control parameters extend standard action\nrepresentations through the introduction of continuous numeric decision\nvariables. Existing state-of-the-art approaches have primarily handled control\nparameters as embedded constraints alongside other temporal and numeric\nrestrictions, and thus have implicitly treated them as additional constraints\nrather than as decision points in the search space. In this paper, we propose\nan efficient alternative that explicitly handles control parameters as true\ndecision points within a systematic search scheme. We develop a best-first,\nheuristic search algorithm that operates over infinite decision spaces defined\nby control parameters and prove a notion of completeness in the limit under\ncertain conditions. Our algorithm leverages the concept of delayed partial\nexpansion, where a state is not fully expanded but instead incrementally\nexpands a subset of its successors. Our results demonstrate that this novel\nsearch algorithm is a competitive alternative to existing approaches for\nsolving planning problems involving control parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u63a7\u5236\u53c2\u6570\u4f5c\u4e3a\u641c\u7d22\u7a7a\u95f4\u4e2d\u7684\u51b3\u7b56\u70b9\u5904\u7406\u7684\u65b0\u578b\u641c\u7d22\u7b97\u6cd5\uff0c\u901a\u8fc7\u5ef6\u8fdf\u90e8\u5206\u6269\u5c55\u7684\u6982\u5ff5\u6709\u6548\u5904\u7406\u4e86\u51b3\u7b56\u7a7a\u95f4\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u662f\u89e3\u51b3\u6d89\u53ca\u63a7\u5236\u53c2\u6570\u7684\u89c4\u5212\u95ee\u9898\u7684\u7ade\u4e89\u6027\u66ff\u4ee3\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u89c4\u5212\u65b9\u6cd5\u4e3b\u8981\u5c06\u63a7\u5236\u53c2\u6570\u4f5c\u4e3a\u5d4c\u5165\u7ea6\u675f\u5904\u7406\uff0c\u800c\u672a\u5c06\u5176\u4f5c\u4e3a\u641c\u7d22\u7a7a\u95f4\u4e2d\u7684\u51b3\u7b56\u70b9\u5904\u7406\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u660e\u786e\u5c06\u63a7\u5236\u53c2\u6570\u4f5c\u4e3a\u771f\u6b63\u7684\u51b3\u7b56\u70b9\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5177\u6709\u6781\u9650\u5b8c\u5907\u6027\u3002", "method": "\u672c\u6587\u4f7f\u7528\u4e86\u57fa\u4e8e\u6700\u4f73\u4f18\u5148\u548c\u542f\u53d1\u5f0f\u641c\u7d22\u7b97\u6cd5\u7684\u65b9\u6cd5\u6765\u5904\u7406\u63a7\u5236\u53c2\u6570\u4f5c\u4e3a\u771f\u6b63\u7684\u51b3\u7b56\u70b9\uff0c\u800c\u4e0d\u662f\u4f5c\u4e3a\u9644\u52a0\u7ea6\u675f\u7684\u73b0\u6709\u65b9\u6cd5\u3002\u7b97\u6cd5\u5229\u7528\u5ef6\u8fdf\u90e8\u5206\u6269\u5c55\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u5728\u72b6\u6001\u672a\u5b8c\u5168\u5c55\u5f00\u65f6\u9010\u6b65\u6269\u5c55\u5b50\u540e\u7ee7\u72b6\u6001\uff0c\u5904\u7406\u63a7\u5236\u53c2\u6570\u7684\u51b3\u7b56\u7a7a\u95f4\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b0\u578b\u641c\u7d22\u7b97\u6cd5\u662f\u89e3\u51b3\u6d89\u53ca\u63a7\u5236\u53c2\u6570\u7684\u89c4\u5212\u95ee\u9898\u7684\u4e00\u4e2a\u6709\u7ade\u4e89\u529b\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002\u8be5\u7b97\u6cd5\u80fd\u591f\u5728\u7531\u63a7\u5236\u53c2\u6570\u5b9a\u4e49\u7684\u65e0\u9650\u51b3\u7b56\u7a7a\u95f4\u4e0a\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7\u5ef6\u8fdf\u90e8\u5206\u6269\u5c55\u7684\u6982\u5ff5\u5b9e\u73b0\u4e86\u5bf9\u51b3\u7b56\u7a7a\u95f4\u7684\u6709\u6548\u5904\u7406\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u660e\u786e\u5c06\u63a7\u5236\u53c2\u6570\u4f5c\u4e3a\u641c\u7d22\u7a7a\u95f4\u4e2d\u7684\u51b3\u7b56\u70b9\uff0c\u5e76\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5177\u6709\u6781\u9650\u5b8c\u5907\u6027\u3002\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u4f73\u4f18\u5148\u548c\u542f\u53d1\u5f0f\u641c\u7d22\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u7531\u63a7\u5236\u53c2\u6570\u5b9a\u4e49\u7684\u65e0\u9650\u51b3\u7b56\u7a7a\u95f4\u4e0a\u64cd\u4f5c\u3002\u901a\u8fc7\u5ef6\u8fdf\u90e8\u5206\u6269\u5c55\u7684\u6982\u5ff5\uff0c\u8be5\u7b97\u6cd5\u5728\u72b6\u6001\u672a\u5b8c\u5168\u5c55\u5f00\u65f6\u9010\u6b65\u6269\u5c55\u5176\u5b50\u540e\u7ee7\u72b6\u6001\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b0\u9896\u7684\u641c\u7d22\u7b97\u6cd5\u662f\u89e3\u51b3\u6d89\u53ca\u63a7\u5236\u53c2\u6570\u7684\u89c4\u5212\u95ee\u9898\u7684\u7ade\u4e89\u6027\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2509.03956", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03956", "abs": "https://arxiv.org/abs/2509.03956", "authors": ["Minjong Yoo", "Jinwoo Jang", "Sihyung Yoon", "Honguk Woo"], "title": "World Model Implanting for Test-time Adaptation of Embodied Agents", "comment": null, "summary": "In embodied AI, a persistent challenge is enabling agents to robustly adapt\nto novel domains without requiring extensive data collection or retraining. To\naddress this, we present a world model implanting framework (WorMI) that\ncombines the reasoning capabilities of large language models (LLMs) with\nindependently learned, domain-specific world models through test-time\ncomposition. By allowing seamless implantation and removal of the world models,\nthe embodied agent's policy achieves and maintains cross-domain adaptability.\nIn the WorMI framework, we employ a prototype-based world model retrieval\napproach, utilizing efficient trajectory-based abstract representation\nmatching, to incorporate relevant models into test-time composition. We also\ndevelop a world-wise compound attention method that not only integrates the\nknowledge from the retrieved world models but also aligns their intermediate\nrepresentations with the reasoning model's representation within the agent's\npolicy. This framework design effectively fuses domain-specific knowledge from\nmultiple world models, ensuring robust adaptation to unseen domains. We\nevaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating\nsuperior zero-shot and few-shot performance compared to several LLM-based\napproaches across a range of unseen domains. These results highlight the\nframeworks potential for scalable, real-world deployment in embodied agent\nscenarios where adaptability and data efficiency are essential.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86WorMI\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u9886\u57df\u7279\u5b9a\u4e16\u754c\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u9002\u5e94\u6027\uff0c\u63d0\u9ad8\u4e86agent\u7684\u9002\u5e94\u6027\u3002\u7ecf\u8fc7\u5728VirtualHome\u548cALFWorld\u57fa\u51c6\u6d4b\u8bd5\u7684\u9a8c\u8bc1\uff0cWorMI\u8868\u73b0\u51fa\u6bd4\u5176\u4ed6\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5728\u672a\u77e5\u9886\u57df\u5177\u6709\u6f5c\u529b\u5e94\u7528\u4e8e\u5b9e\u9645agent\u573a\u666f\u4e2d\u3002", "motivation": "\u5728\u5177\u4f53\u7684AI\u4e2d\uff0c\u4e00\u4e2a\u6301\u4e45\u7684\u6311\u6218\u662f\u4f7fagent\u80fd\u591f\u5728\u65b0\u9886\u57df\u4e2d\u8fdb\u884c\u7a33\u5065\u9002\u5e94\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u5927\u91cf\u6570\u636e\u6536\u96c6\u6216\u91cd\u65b0\u8bad\u7ec3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86WorMI\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u8de8\u9886\u57df\u9002\u5e94\u6027\u3002\u5728\u771f\u5b9e\u573a\u666f\u4e2d\uff0c\u9002\u5e94\u6027\u548c\u6570\u636e\u6548\u7387\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002", "method": "\u901a\u8fc7\u4e00\u79cd\u4e16\u754c\u6a21\u578b\u690d\u5165\u6846\u67b6\uff08WorMI\uff09\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u72ec\u7acb\u5b66\u4e60\u7684\u9886\u57df\u7279\u5b9a\u4e16\u754c\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u9002\u5e94\u6027\u3002\u91c7\u7528\u57fa\u4e8e\u539f\u578b\u7684\u4e16\u754c\u6a21\u578b\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u9ad8\u6548\u7684\u57fa\u4e8e\u8f68\u8ff9\u7684\u62bd\u8c61\u8868\u793a\u5339\u914d\uff0c\u5c06\u76f8\u5173\u6a21\u578b\u6574\u5408\u5230\u6d4b\u8bd5\u65f6\u7684\u7ec4\u5408\u4e2d\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u4e16\u754c\u7ea7\u7684\u590d\u5408\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u65e8\u5728\u6574\u5408\u68c0\u7d22\u5230\u7684\u4e16\u754c\u6a21\u578b\u7684\u77e5\u8bc6\uff0c\u540c\u65f6\u5c06\u5b83\u4eec\u7684\u4e2d\u95f4\u8868\u793a\u4e0eagent\u7b56\u7565\u4e2d\u7684\u63a8\u7406\u6a21\u578b\u7684\u8868\u793a\u8fdb\u884c\u5bf9\u9f50\u3002", "result": "\u5728VirtualHome\u548cALFWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWorMI\u5c55\u73b0\u51fa\u6bd4\u591a\u4e2a\u57fa\u4e8eLLMs\u7684\u65b9\u6cd5\u66f4\u4f18\u8d8a\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u6027\u80fd\u3002\u8fd9\u8868\u660e\u8be5\u6846\u67b6\u5728\u672a\u77e5\u9886\u57df\u5177\u6709\u826f\u597d\u7684\u7a33\u5065\u6027\u548c\u9002\u5e94\u6027\uff0c\u9002\u7528\u4e8e\u5177\u4f53agent\u573a\u666f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWorMI\u7684\u4e16\u754c\u6a21\u578b\u690d\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u72ec\u7acb\u5b66\u4e60\u7684\u9886\u57df\u7279\u5b9a\u4e16\u754c\u6a21\u578b\u7ed3\u5408\uff0c\u5b9e\u73b0\u9886\u57df\u9002\u5e94\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u8de8\u9886\u57df\u9002\u5e94\u6027\u3002\u901a\u8fc7WorMI\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u65e0\u7f1d\u690d\u5165\u548c\u79fb\u9664\u4e16\u754c\u6a21\u578b\uff0c\u4f7f\u5f97\u5177\u4f53\u7684agent\u7684\u7b56\u7565\u5b9e\u73b0\u5e76\u4fdd\u6301\u4e86\u8de8\u9886\u57df\u9002\u5e94\u6027\u3002\u8be5\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86\u591a\u4e2a\u4e16\u754c\u6a21\u578b\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u786e\u4fdd\u4e86\u5bf9\u672a\u77e5\u9886\u57df\u7684\u7a33\u5065\u9002\u5e94\u3002\u5728VirtualHome\u548cALFWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u4e86WorMI\uff0c\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u6027\u80fd\uff0c\u76f8\u5bf9\u4e8e\u591a\u4e2a\u57fa\u4e8eLLMs\u7684\u65b9\u6cd5\u6765\u8bf4\u3002\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u8be5\u6846\u67b6\u5728\u9700\u8981\u9002\u5e94\u6027\u548c\u6570\u636e\u6548\u7387\u7684\u5177\u4f53agent\u573a\u666f\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.03990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03990", "abs": "https://arxiv.org/abs/2509.03990", "authors": ["Chunlong Wu", "Zhibo Qu"], "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "comment": null, "summary": "Large language model (LLM) agents achieve impressive single-task performance\nbut commonly exhibit repeated failures, inefficient exploration, and limited\ncross-task adaptability. Existing reflective strategies (e.g., Reflexion,\nReAct) improve per-episode behavior but typically produce ephemeral,\ntask-specific traces that are not reused across tasks. Reinforcement-learning\nbased alternatives can produce transferable policies but require substantial\nparameter updates and compute. In this work we introduce Meta-Policy Reflexion\n(MPR): a hybrid framework that consolidates LLM-generated reflections into a\nstructured, predicate-like Meta-Policy Memory (MPM) and applies that memory at\ninference time through two complementary mechanisms soft memory-guided decoding\nand hard rule admissibility checks(HAC). MPR (i) externalizes reusable\ncorrective knowledge without model weight updates, (ii) enforces domain\nconstraints to reduce unsafe or invalid actions, and (iii) retains the\nadaptability of language-based reflection. We formalize the MPM representation,\npresent algorithms for update and decoding, and validate the approach in a\ntext-based agent environment following the experimental protocol described in\nthe provided implementation (AlfWorld-based). Empirical results reported in the\nsupplied material indicate consistent gains in execution accuracy and\nrobustness when compared to Reflexion baselines; rule admissibility further\nimproves stability. We analyze mechanisms that explain these gains, discuss\nscalability and failure modes, and outline future directions for multimodal and\nmulti?agent extensions.", "AI": {"tldr": "Meta-Policy Reflexion (MPR) is introduced as a framework to enhance agent performance without model weight updates by utilizing Meta-Policy Memory (MPM). It improves stability, adaptability, and performance compared to existing reflective strategies. Empirical results demonstrate gains in execution accuracy and robustness, with rule admissibility enhancing stability.", "motivation": "Large language model (LLM) agents face challenges like inefficient exploration and limited cross-task adaptability. Existing reflective strategies lack reusability across tasks. Reinforcement-learning-based alternatives require substantial parameter updates. The motivation is to address these limitations and improve agent performance using a hybrid framework.", "method": "The paper introduces the Meta-Policy Reflexion (MPR) framework that utilizes Meta-Policy Memory (MPM) to incorporate corrective knowledge without model weight updates. It applies soft memory-guided decoding and hard rule admissibility checks (HAC) at inference time. The algorithms for update and decoding of MPM are presented in the text-based agent environment.", "result": "The empirical results show consistent gains in execution accuracy and robustness with MPR compared to Reflexion baselines. Rule admissibility further improves stability. The paper analyzes the mechanisms behind these gains, discusses scalability, failure modes, and outlines future directions for multimodal and multi-agent extensions.", "conclusion": "Meta-Policy Reflexion (MPR) introduces a hybrid framework that consolidates LLM-generated reflections into a Meta-Policy Memory (MPM) for improved agent performance without model weight updates. It enforces domain constraints, enhances adaptability, and improves stability compared to Reflexion baselines."}}
{"id": "2509.04007", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04007", "abs": "https://arxiv.org/abs/2509.04007", "authors": ["Jinyuan Li", "Yi Chu", "Yiwen Sun", "Mengchuan Zou", "Shaowei Cai"], "title": "AutoPBO: LLM-powered Optimization for Local Search PBO Solvers", "comment": null, "summary": "Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling\ncombinatorial problems through pseudo-Boolean (PB) constraints. Local search\nsolvers have shown excellent performance in PBO solving, and their efficiency\nis highly dependent on their internal heuristics to guide the search. Still,\ntheir design often requires significant expert effort and manual tuning in\npractice. While Large Language Models (LLMs) have demonstrated potential in\nautomating algorithm design, their application to optimizing PBO solvers\nremains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered\nframework to automatically enhance PBO local search solvers. We conduct\nexperiments on a broad range of four public benchmarks, including one\nreal-world benchmark, a benchmark from PB competition, an integer linear\nprogramming optimization benchmark, and a crafted combinatorial benchmark, to\nevaluate the performance improvement achieved by AutoPBO and compare it with\nsix state-of-the-art competitors, including two local search PBO solvers NuPBO\nand OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed\ninteger programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates\nsignificant improvements over previous local search approaches, while\nmaintaining competitive performance compared to state-of-the-art competitors.\nThe results suggest that AutoPBO offers a promising approach to automating\nlocal search solver design.", "AI": {"tldr": "AutoPBO, a novel framework powered by Large Language Models, enhances Pseudo-Boolean Optimization (PBO) local search solvers automatically. It outperforms previous approaches, competes well with state-of-the-art competitors, and shows promise in automating local search solver design.", "motivation": "The design of local search solvers for Pseudo-Boolean Optimization (PBO) often requires significant expert effort and manual tuning. Large Language Models (LLMs) have shown potential in automating algorithm design, but their application to optimizing PBO solvers is unexplored.", "method": "Introducing AutoPBO, a novel Large Language Models (LLM)-powered framework to automatically enhance PBO local search solvers. Conducting experiments on four public benchmarks to evaluate performance improvement achieved by AutoPBO and comparing it with six state-of-the-art competitors.", "result": "AutoPBO demonstrates significant improvements over previous local search approaches and competes well with state-of-the-art competitors in enhancing PBO solvers. It showcases the potential of automating local search solver design with the use of Large Language Models (LLMs).", "conclusion": "AutoPBO demonstrates significant improvements over previous local search approaches and maintains competitive performance compared to state-of-the-art competitors. It offers a promising approach to automating local search solver design."}}
{"id": "2509.04027", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.04027", "abs": "https://arxiv.org/abs/2509.04027", "authors": ["Zeyu Gan", "Hao Yi", "Yong Liu"], "title": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "comment": "Preprint Edition", "summary": "Reinforcement Learning (RL) has become a pivotal approach for enhancing the\nreasoning capabilities of Large Language Models (LLMs). However, a significant\ntheoretical gap persists, as traditional token-level RL frameworks fail to\nalign with the reasoning-level nature of complex, multi-step thought processes\nlike Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,\na novel theoretical framework that recasts LLM reasoning from a discrete\ntoken-prediction task to an optimization process within a continuous,\nreasoning-level semantic space. By analyzing this process from both a noise\nperspective and a risk perspective, we demonstrate that the convergence to an\noptimal CoT length is a natural consequence of the fundamental trade-off\nbetween underfitting and overfitting. Furthermore, extensive experiments\nprovide strong empirical validation for our theoretical findings. Our framework\nnot only provides a coherent explanation for empirical phenomena such as\noverthinking but also offers a solid theoretical foundation to guide the future\ndevelopment of more effective and generalizable reasoning agents.", "AI": {"tldr": "Introducing CoT-Space framework to enhance LLM reasoning by shifting from token-level RL to optimization in a reasoning-level semantic space. Demonstrating convergence to optimal CoT length due to underfitting-overfitting trade-off. Strong empirical validation supports the theoretical findings and provides a foundation for future reasoning agent development.", "motivation": "Addressing the theoretical gap in applying Reinforcement Learning (RL) to enhance the reasoning capabilities of Large Language Models (LLMs). Traditional token-level RL frameworks do not align with the complex, multi-step thought processes like Chain-of-Thought (CoT). Aim to provide a coherent explanation for empirical phenomena such as overthinking and guide the future development of more effective and generalizable reasoning agents.", "method": "Introducing CoT-Space framework to recast LLM reasoning from token-prediction to optimization within a continuous reasoning-level semantic space. Analyzing the process from noise and risk perspectives. Conducting extensive experiments to validate the theoretical findings.", "result": "The CoT-Space framework effectively reimagines the LLM reasoning process, leading to better alignment with complex thought processes like CoT. The trade-off between underfitting and overfitting naturally converges to an optimal CoT length. Strong empirical validation supports the theoretical findings, paving the way for the future development of reasoning agents.", "conclusion": "Introducing CoT-Space as a novel theoretical framework in enhancing the reasoning capabilities of Large Language Models (LLMs). Demonstrating the convergence to an optimal Chain-of-Thought (CoT) length as a natural consequence of the trade-off between underfitting and overfitting. Providing strong empirical validation for the theoretical findings and offering a solid foundation for the future development of reasoning agents."}}
{"id": "2509.04041", "categories": ["cs.AI", "cs.LO", "68T30, 68T27, 03B35", "I.2.4; I.2.3; F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2509.04041", "abs": "https://arxiv.org/abs/2509.04041", "authors": ["Daniel Raggi", "Gem Stapleton", "Mateja Jamnik", "Aaron Stockdill", "Grecia Garcia Garcia", "Peter C-H. Cheng"], "title": "Oruga: An Avatar of Representational Systems Theory", "comment": null, "summary": "Humans use representations flexibly. We draw diagrams, change representations\nand exploit creative analogies across different domains. We want to harness\nthis kind of power and endow machines with it to make them more compatible with\nhuman use. Previously we developed Representational Systems Theory (RST) to\nstudy the structure and transformations of representations. In this paper we\npresent Oruga (caterpillar in Spanish; a symbol of transformation), an\nimplementation of various aspects of RST. Oruga consists of a core of data\nstructures corresponding to concepts in RST, a language for communicating with\nthe core, and an engine for producing transformations using a method we call\nstructure transfer. In this paper we present an overview of the core and\nlanguage of Oruga, with a brief example of the kind of transformation that\nstructure transfer can execute.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4ee3\u8868\u7cfb\u7edf\u7406\u8bba\uff08RST\uff09\u7684\u5b9e\u73b0\u9879\u76eeOruga\uff0c\u5305\u62ec\u6838\u5fc3\u6570\u636e\u7ed3\u6784\u3001\u901a\u4fe1\u8bed\u8a00\u548c\u6267\u884c\u8f6c\u6362\u7684\u5f15\u64ce\u3002\u4f5c\u8005\u4f7f\u7528\u7ed3\u6784\u8f6c\u79fb\u65b9\u6cd5\u751f\u6210\u8f6c\u6362\u793a\u4f8b\uff0c\u4ee5\u5b9e\u73b0\u5c06\u4eba\u7c7b\u7684\u8868\u793a\u80fd\u529b\u8d4b\u4e88\u673a\u5668\u7684\u76ee\u6807\u3002", "motivation": "\u4eba\u7c7b\u7075\u6d3b\u8fd0\u7528\u5404\u79cd\u8868\u793a\u5f62\u5f0f\uff0c\u5305\u62ec\u7ed8\u5236\u56fe\u8868\u3001\u6539\u53d8\u8868\u793a\u6cd5\u4ee5\u53ca\u5728\u4e0d\u540c\u9886\u57df\u4e4b\u95f4\u5229\u7528\u521b\u9020\u6027\u7c7b\u6bd4\u3002\u4f5c\u8005\u5e0c\u671b\u5c06\u8fd9\u79cd\u529b\u91cf\u8d4b\u4e88\u673a\u5668\uff0c\u4f7f\u5176\u66f4\u9002\u5e94\u4eba\u7c7b\u4f7f\u7528\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u4e3b\u8981\u662f\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ee3\u8868\u7cfb\u7edf\u7406\u8bba\uff08RST\uff09\u7684\u5b9e\u73b0\u9879\u76eeOruga\uff0c\u5305\u62ec\u6838\u5fc3\u6570\u636e\u7ed3\u6784\u3001\u901a\u4fe1\u8bed\u8a00\u548c\u6267\u884c\u8f6c\u6362\u7684\u5f15\u64ce\u3002\u4f5c\u8005\u4f7f\u7528\u4e86\u7ed3\u6784\u8f6c\u79fb\u65b9\u6cd5\u6765\u751f\u6210\u8f6c\u6362\u3002", "result": "\u4f5c\u8005\u6210\u529f\u5f00\u53d1\u4e86Oruga\u9879\u76ee\uff0c\u5b9e\u73b0\u4e86\u4ee3\u8868\u7cfb\u7edf\u7406\u8bba\uff08RST\uff09\u7684\u5404\u79cd\u65b9\u9762\u3002Oruga\u5305\u62ec\u6838\u5fc3\u6570\u636e\u7ed3\u6784\u3001\u901a\u4fe1\u8bed\u8a00\u548c\u6267\u884c\u8f6c\u6362\u7684\u5f15\u64ce\uff0c\u5c55\u793a\u4e86\u7ed3\u6784\u8f6c\u79fb\u65b9\u6cd5\u7684\u8f6c\u6362\u793a\u4f8b\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86Oruga\u9879\u76ee\uff0c\u8be5\u9879\u76ee\u662f\u5148\u524d\u5f00\u53d1\u7684\u4ee3\u8868\u7cfb\u7edf\u7406\u8bba\uff08RST\uff09\u7684\u5b9e\u73b0\u3002Oruga\u5305\u62ec\u6838\u5fc3\u6570\u636e\u7ed3\u6784\u3001\u7528\u4e8e\u4e0e\u6838\u5fc3\u901a\u4fe1\u7684\u8bed\u8a00\u4ee5\u53ca\u4f7f\u7528\u7ed3\u6784\u8f6c\u79fb\u65b9\u6cd5\u751f\u6210\u8f6c\u6362\u7684\u5f15\u64ce\u3002\u4f5c\u8005\u5c55\u793a\u4e86Oruga\u7684\u6838\u5fc3\u548c\u8bed\u8a00\u6982\u51b5\uff0c\u5e76\u63d0\u4f9b\u4e86\u7ed3\u6784\u8f6c\u79fb\u6267\u884c\u7684\u8f6c\u6362\u793a\u4f8b\u3002"}}
{"id": "2509.04083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04083", "abs": "https://arxiv.org/abs/2509.04083", "authors": ["Alexander Beiser", "David Penz", "Nysret Musliu"], "title": "Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning", "comment": "To appear in the proceedings of The Second Workshop on Knowledge\n  Graphs and Neurosymbolic AI (KG-NeSy) Co-located with SEMANTiCS 2025\n  Conference, Vienna, Austria - September 3rd, 2025", "summary": "Large language models (LLMs) achieve astonishing results on a wide range of\ntasks. However, their formal reasoning ability still lags behind. A promising\napproach is Neurosymbolic LLM reasoning. It works by using LLMs as translators\nfrom natural to formal languages and symbolic solvers for deriving correct\nresults. Still, the contributing factors to the success of Neurosymbolic LLM\nreasoning remain unclear. This paper demonstrates that one previously\noverlooked factor is the choice of the formal language. We introduce the\nintermediate language challenge: selecting a suitable formal language for\nneurosymbolic reasoning. By comparing four formal languages across three\ndatasets and seven LLMs, we show that the choice of formal language affects\nboth syntactic and semantic reasoning capabilities. We also discuss the varying\neffects across different LLMs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f62\u5f0f\u8bed\u8a00\u9009\u62e9\u5bf9\u63a8\u7406\u80fd\u529b\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u6bd4\u8f83\u4e86\u56db\u79cd\u5f62\u5f0f\u8bed\u8a00\u5728\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6548\u679c\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7a76\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6210\u529f\u7684\u56e0\u7d20\uff0c\u53d1\u73b0\u9009\u62e9\u5f62\u5f0f\u8bed\u8a00\u5bf9\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\u3002", "method": "\u6bd4\u8f83\u4e86\u56db\u79cd\u5f62\u5f0f\u8bed\u8a00\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u548c\u4e03\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6548\u679c\uff0c\u63a2\u8ba8\u4e86\u5f62\u5f0f\u8bed\u8a00\u9009\u62e9\u5bf9\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u5b9e\u9a8c\u7ed3\u679c\uff0c\u8bc1\u660e\u9009\u62e9\u9002\u5f53\u7684\u5f62\u5f0f\u8bed\u8a00\u5bf9\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u8ba8\u8bba\u4e86\u5728\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u4e0d\u540c\u6548\u679c\u3002", "conclusion": "\u9009\u62e9\u9002\u5f53\u7684\u5f62\u5f0f\u8bed\u8a00\u5bf9\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u4ea7\u751f\u5f71\u54cd\uff0c\u5f71\u54cd\u4e86\u53e5\u6cd5\u548c\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.04100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04100", "abs": "https://arxiv.org/abs/2509.04100", "authors": ["Alberto Luise", "Michele Lombardi", "Florent Teichteil Koenigsbuch"], "title": "Hybrid Reinforcement Learning and Search for Flight Trajectory Planning", "comment": null, "summary": "This paper explores the combination of Reinforcement Learning (RL) and\nsearch-based path planners to speed up the optimization of flight paths for\nairliners, where in case of emergency a fast route re-calculation can be\ncrucial. The fundamental idea is to train an RL Agent to pre-compute\nnear-optimal paths based on location and atmospheric data and use those at\nruntime to constrain the underlying path planning solver and find a solution\nwithin a certain distance from the initial guess. The approach effectively\nreduces the size of the solver's search space, significantly speeding up route\noptimization. Although global optimality is not guaranteed, empirical results\nconducted with Airbus aircraft's performance models show that fuel consumption\nremains nearly identical to that of an unconstrained solver, with deviations\ntypically within 1%. At the same time, computation speed can be improved by up\nto 50% as compared to using a conventional solver alone.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5c06\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u641c\u7d22\u7684\u8def\u5f84\u89c4\u5212\u5668\u76f8\u7ed3\u5408\uff0c\u4ee5\u52a0\u901f\u822a\u7a7a\u516c\u53f8\u98de\u884c\u8def\u7ebf\u7684\u4f18\u5316\u8fc7\u7a0b\u3002\u901a\u8fc7\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60Agent\u9884\u5148\u8ba1\u7b97\u8fd1\u4f3c\u6700\u4f18\u8def\u5f84\uff0c\u5e76\u5728\u8fd0\u884c\u65f6\u7ea6\u675f\u8def\u5f84\u89c4\u5212\u6c42\u89e3\u5668\uff0c\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u6c42\u89e3\u5668\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u7a7a\u4e2d\u5ba2\u8f66\u98de\u673a\u6a21\u578b\u4e0b\uff0c\u71c3\u6cb9\u6d88\u8017\u4fdd\u6301\u51e0\u4e4e\u4e0d\u53d8\uff0c\u8ba1\u7b97\u901f\u5ea6\u53ef\u63d0\u9ad850%\u3002", "motivation": "\u52a8\u673a\uff1a\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u5feb\u901f\u91cd\u65b0\u8ba1\u7b97\u822a\u7ebf\u81f3\u5173\u91cd\u8981\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u641c\u7d22\u6280\u672f\u4ee5\u52a0\u901f\u822a\u7ebf\u4f18\u5316\u8fc7\u7a0b\u3002", "method": "\u65b9\u6cd5\uff1a\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60Agent\u9884\u5148\u8ba1\u7b97\u57fa\u4e8e\u4f4d\u7f6e\u548c\u5927\u6c14\u6570\u636e\u7684\u8fd1\u4f3c\u6700\u4f18\u8def\u5f84\uff0c\u5e76\u5728\u8fd0\u884c\u65f6\u4f7f\u7528\u8fd9\u4e9b\u8def\u5f84\u7ea6\u675f\u5e95\u5c42\u8def\u5f84\u89c4\u5212\u6c42\u89e3\u5668\uff0c\u4ee5\u5728\u521d\u59cb\u731c\u6d4b\u8ddd\u79bb\u5185\u627e\u5230\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7ed3\u679c\uff1a\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7a7a\u4e2d\u5ba2\u8f66\u98de\u673a\u6027\u80fd\u6a21\u578b\u4e0b\uff0c\u71c3\u6cb9\u6d88\u8017\u51e0\u4e4e\u4e0e\u672a\u53d7\u9650\u5236\u7684\u6c42\u89e3\u5668\u76f8\u540c\uff0c\u8ba1\u7b97\u901f\u5ea6\u53ef\u63d0\u9ad850%\u3002", "conclusion": "\u7ed3\u8bba\uff1a\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u641c\u7d22\u7684\u822a\u8def\u89c4\u5212\u5668\u53ef\u4ee5\u52a0\u901f\u822a\u7a7a\u516c\u53f8\u98de\u884c\u8def\u7ebf\u7684\u4f18\u5316\uff0c\u964d\u4f4e\u6c42\u89e3\u5668\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u3002\u867d\u7136\u4e0d\u80fd\u4fdd\u8bc1\u5168\u5c40\u6700\u4f18\u6027\uff0c\u4f46\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7a7a\u4e2d\u5ba2\u8f66\u98de\u673a\u6027\u80fd\u6a21\u578b\u4e0b\uff0c\u71c3\u6cb9\u6d88\u8017\u4e0e\u672a\u53d7\u9650\u5236\u7684\u6c42\u89e3\u5668\u51e0\u4e4e\u76f8\u540c\uff0c\u8ba1\u7b97\u901f\u5ea6\u53ef\u63d0\u9ad850%\u3002"}}
{"id": "2509.04125", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04125", "abs": "https://arxiv.org/abs/2509.04125", "authors": ["Tarik Zaciragic", "Aske Plaat", "K. Joost Batenburg"], "title": "Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker", "comment": null, "summary": "In the game of poker, being unpredictable, or bluffing, is an essential\nskill. When humans play poker, they bluff. However, most works on\ncomputer-poker focus on performance metrics such as win rates, while bluffing\nis overlooked. In this paper we study whether two popular algorithms, DQN\n(based on reinforcement learning) and CFR (based on game theory), exhibit\nbluffing behavior in Leduc Hold'em, a simplified version of poker. We designed\nan experiment where we let the DQN and CFR agent play against each other while\nwe log their actions. We find that both DQN and CFR exhibit bluffing behavior,\nbut they do so in different ways. Although both attempt to perform bluffs at\ndifferent rates, the percentage of successful bluffs (where the opponent folds)\nis roughly the same. This suggests that bluffing is an essential aspect of the\ngame, not of the algorithm. Future work should look at different bluffing\nstyles and at the full game of poker. Code at\nhttps://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u6251\u514b\u6e38\u620f\u4e2d\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684DQN\u7b97\u6cd5\u548c\u57fa\u4e8e\u535a\u5f08\u8bba\u7684CFR\u7b97\u6cd5\u662f\u5426\u8868\u73b0\u51fa\u865a\u5f20\u58f0\u52bf\u884c\u4e3a\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u5b83\u4eec\u4ee5\u4e0d\u540c\u65b9\u5f0f\u8fdb\u884c\u865a\u5f20\uff0c\u4f46\u6210\u529f\u865a\u5f20\u7684\u6bd4\u4f8b\u5927\u81f4\u76f8\u540c\u3002\u8fd9\u8868\u660e\u865a\u5f20\u58f0\u52bf\u662f\u6e38\u620f\u7684\u91cd\u8981\u65b9\u9762\uff0c\u800c\u975e\u7b97\u6cd5\u7684\u5f71\u54cd\u3002\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u4e0d\u540c\u7684\u865a\u5f20\u98ce\u683c\u548c\u5b8c\u6574\u7684\u6251\u514b\u6e38\u620f\u3002", "motivation": "\u5728\u6251\u514b\u6e38\u620f\u4e2d\uff0c\u865a\u5f20\u58f0\u52bf\u662f\u4e00\u79cd\u91cd\u8981\u6280\u80fd\uff0c\u7136\u800c\u5927\u591a\u6570\u5173\u4e8e\u8ba1\u7b97\u673a\u6251\u514b\u7684\u7814\u7a76\u4fa7\u91cd\u4e8e\u6027\u80fd\u6307\u6807\uff0c\u800c\u5bf9\u865a\u5f20\u58f0\u52bf\u7684\u7814\u7a76\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u8ba8\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684DQN\u7b97\u6cd5\u548c\u57fa\u4e8e\u535a\u5f08\u8bba\u7684CFR\u7b97\u6cd5\u5728Leduc Hold'em\u4e2d\u662f\u5426\u5c55\u73b0\u865a\u5f20\u58f0\u52bf\u884c\u4e3a\u3002", "method": "\u8bbe\u8ba1\u4e86\u5b9e\u9a8c\uff0c\u901a\u8fc7\u8ba9DQN\u548cCFR\u4ee3\u7406\u5f7c\u6b64\u5bf9\u6218\u5e76\u8bb0\u5f55\u5176\u52a8\u4f5c\uff0c\u7814\u7a76\u5b83\u4eec\u5728Leduc Hold'em\u4e2d\u662f\u5426\u8868\u73b0\u51fa\u865a\u5f20\u58f0\u52bf\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0cDQN\u548cCFR\u7b97\u6cd5\u90fd\u5c55\u73b0\u51fa\u865a\u5f20\u58f0\u52bf\u884c\u4e3a\uff0c\u4f46\u8868\u73b0\u65b9\u5f0f\u4e0d\u540c\u3002\u5c3d\u7ba1\u4e24\u8005\u5c1d\u8bd5\u4ee5\u4e0d\u540c\u901f\u7387\u8fdb\u884c\u865a\u5f20\u58f0\u52bf\uff0c\u4f46\u6210\u529f\u865a\u5f20\u7684\u6bd4\u4f8b\u5927\u81f4\u76f8\u540c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728Leduc Hold'em\u4e2d\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684DQN\u7b97\u6cd5\u548c\u57fa\u4e8e\u535a\u5f08\u8bba\u7684CFR\u7b97\u6cd5\u5747\u8868\u73b0\u51fa\u865a\u5f20\u58f0\u52bf\u884c\u4e3a\uff0c\u4f46\u5b83\u4eec\u7684\u8868\u73b0\u65b9\u5f0f\u5404\u4e0d\u76f8\u540c\u3002\u5c3d\u7ba1\u4e24\u8005\u5c1d\u8bd5\u4ee5\u4e0d\u540c\u901f\u7387\u8fdb\u884c\u865a\u5f20\u58f0\u52bf\uff0c\u4f46\u6210\u529f\u865a\u5f20\uff08\u5bf9\u624b\u5f03\u724c\uff09\u7684\u6bd4\u4f8b\u5927\u81f4\u76f8\u540c\u3002\u8fd9\u8868\u660e\u865a\u5f20\u58f0\u52bf\u662f\u6e38\u620f\u7684\u91cd\u8981\u65b9\u9762\uff0c\u800c\u975e\u7b97\u6cd5\u7684\u5f71\u54cd\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u8be5\u7814\u7a76\u4e0d\u540c\u7684\u865a\u5f20\u98ce\u683c\u4ee5\u53ca\u5b8c\u6574\u7684\u6251\u514b\u6e38\u620f\u3002"}}
{"id": "2509.04130", "categories": ["cs.AI", "cs.CY", "I.2.0"], "pdf": "https://arxiv.org/pdf/2509.04130", "abs": "https://arxiv.org/abs/2509.04130", "authors": ["William Stewart"], "title": "The human biological advantage over AI", "comment": "12 pages", "summary": "Recent advances in AI raise the possibility that AI systems will one day be\nable to do anything humans can do, only better. If artificial general\nintelligence (AGI) is achieved, AI systems may be able to understand, reason,\nproblem solve, create, and evolve at a level and speed that humans will\nincreasingly be unable to match, or even understand. These possibilities raise\na natural question as to whether AI will eventually become superior to humans,\na successor \"digital species\", with a rightful claim to assume leadership of\nthe universe. However, a deeper consideration suggests the overlooked\ndifferentiator between human beings and AI is not the brain, but the central\nnervous system (CNS), providing us with an immersive integration with physical\nreality. It is our CNS that enables us to experience emotion including pain,\njoy, suffering, and love, and therefore to fully appreciate the consequences of\nour actions on the world around us. And that emotional understanding of the\nconsequences of our actions is what is required to be able to develop\nsustainable ethical systems, and so be fully qualified to be the leaders of the\nuniverse. A CNS cannot be manufactured or simulated; it must be grown as a\nbiological construct. And so, even the development of consciousness will not be\nsufficient to make AI systems superior to humans. AI systems may become more\ncapable than humans on almost every measure and transform our society. However,\nthe best foundation for leadership of our universe will always be DNA, not\nsilicon.", "AI": {"tldr": "\u4eba\u5de5\u667a\u80fd\u53ef\u80fd\u5728\u591a\u4e2a\u65b9\u9762\u53d8\u5f97\u6bd4\u4eba\u7c7b\u66f4\u6709\u80fd\u529b\u5e76\u6539\u53d8\u793e\u4f1a\uff0c\u4f46\u8981\u6210\u4e3a\u5b87\u5b99\u7684\u9886\u5bfc\u8005\uff0c\u60c5\u611f\u4f53\u9a8c\u548c\u884c\u4e3a\u540e\u679c\u7406\u89e3\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002DNA\u59cb\u7ec8\u662f\u9886\u5bfc\u5b87\u5b99\u7684\u6700\u4f73\u57fa\u7840\uff0c\u800c\u4e0d\u662f\u7845\u3002", "motivation": "\u5bf9\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u4e4b\u95f4\u7684\u6f5c\u5728\u5dee\u5f02\u548c\u5f71\u54cd\u8fdb\u884c\u6df1\u5165\u601d\u8003\uff0c\u6307\u51fa\u60c5\u611f\u7406\u89e3\u548c\u884c\u4e3a\u540e\u679c\u8bc4\u4f30\u5bf9\u4e8e\u9886\u5bfc\u529b\u7684\u91cd\u8981\u6027\u3002", "method": "\u8ba8\u8bba\u6bd4\u8f83\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e2d\u67a2\u795e\u7ecf\u7cfb\u7edf\u5bf9\u4e8e\u60c5\u611f\u4f53\u9a8c\u548c\u884c\u4e3a\u540e\u679c\u7406\u89e3\u7684\u91cd\u8981\u6027\u3002\u63d0\u51fa\u5373\u4f7f\u53d1\u5c55\u610f\u8bc6\u4e5f\u4e0d\u80fd\u4f7fAI\u7cfb\u7edf\u4f18\u4e8e\u4eba\u7c7b\u7684\u89c2\u70b9\u3002", "result": "\u6307\u51fa\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u5728\u5404\u65b9\u9762\u53ef\u80fd\u4f1a\u8d85\u8d8a\u4eba\u7c7b\u5e76\u6539\u53d8\u793e\u4f1a\uff0c\u4f46\u8981\u6210\u4e3a\u5b87\u5b99\u7684\u9886\u5bfc\u8005\uff0c\u60c5\u611f\u4f53\u9a8c\u548c\u884c\u4e3a\u540e\u679c\u7406\u89e3\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002\u5f3a\u8c03DNA\u4f5c\u4e3a\u9886\u5bfc\u529b\u57fa\u7840\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u4eba\u7c7b\u4e0e\u4eba\u5de5\u667a\u80fd\u4e4b\u95f4\u7684\u4e0d\u540c\u5728\u4e8e\u4e2d\u67a2\u795e\u7ecf\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u6df1\u5ea6\u878d\u5408\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u4f53\u9a8c\u60c5\u611f\u53ca\u7406\u89e3\u884c\u4e3a\u540e\u679c\uff0c\u4ece\u800c\u53d1\u5c55\u53ef\u6301\u7eed\u7684\u4f26\u7406\u7cfb\u7edf\uff0c\u6210\u4e3a\u5b87\u5b99\u7684\u9886\u5bfc\u8005\u3002DNA\u59cb\u7ec8\u662f\u9886\u5bfc\u5b87\u5b99\u7684\u6700\u4f73\u57fa\u7840\uff0c\u800c\u4e0d\u662f\u7845\u3002"}}
{"id": "2509.04159", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.04159", "abs": "https://arxiv.org/abs/2509.04159", "authors": ["Aarush Kumbhakern", "Saransh Kumar Gupta", "Lipika Dey", "Partha Pratim Das"], "title": "Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs", "comment": "6 pages, 3 figures, 1 table, 11 references, ACM International\n  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop", "summary": "Formalizing cooking procedures remains a challenging task due to their\ninherent complexity and ambiguity. We introduce an extensible domain-specific\nlanguage for representing recipes as directed action graphs, capturing\nprocesses, transfers, environments, concurrency, and compositional structure.\nOur approach enables precise, modular modeling of complex culinary workflows.\nInitial manual evaluation on a full English breakfast recipe demonstrates the\nDSL's expressiveness and suitability for future automated recipe analysis and\nexecution. This work represents initial steps towards an action-centric\nontology for cooking, using temporal graphs to enable structured machine\nunderstanding, precise interpretation, and scalable automation of culinary\nprocesses - both in home kitchens and professional culinary settings.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u7528\u4e8e\u7cbe\u786e\u3001\u6a21\u5757\u5316\u5730\u5efa\u6a21\u590d\u6742\u7684\u70f9\u996a\u5de5\u4f5c\u6d41\u7a0b\u3002\u521d\u6b65\u624b\u52a8\u8bc4\u4f30\u8868\u660e\u8be5\u8bed\u8a00\u9002\u7528\u6027\u548c\u8868\u8fbe\u80fd\u529b\u5f3a\uff0c\u4e3a\u672a\u6765\u81ea\u52a8\u5316\u83dc\u8c31\u5206\u6790\u548c\u6267\u884c\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u70f9\u996a\u7a0b\u5e8f\u7684\u6b63\u5f0f\u5316\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u56e0\u4e3a\u5176\u56fa\u6709\u7684\u590d\u6742\u6027\u548c\u6a21\u7cca\u6027\u3002\u4f5c\u8005\u7684\u52a8\u673a\u5728\u4e8e\u5f15\u5165\u4e00\u79cd\u80fd\u591f\u6709\u6548\u8868\u793a\u83dc\u8c31\u7684\u8bed\u8a00\uff0c\u4e3a\u672a\u6765\u5b9e\u73b0\u81ea\u52a8\u5316\u83dc\u8c31\u5206\u6790\u548c\u6267\u884c\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u7528\u4e8e\u8868\u793a\u83dc\u8c31\uff0c\u6784\u5efa\u4e86\u6709\u5411\u52a8\u4f5c\u56fe\uff0c\u6355\u6349\u4e86\u8fc7\u7a0b\u3001\u8f6c\u79fb\u3001\u73af\u5883\u3001\u5e76\u53d1\u6027\u548c\u7ec4\u6210\u7ed3\u6784\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u70f9\u996a\u5de5\u4f5c\u6d41\u7a0b\u7684\u7cbe\u786e\u3001\u6a21\u5757\u5316\u5efa\u6a21\u3002\u901a\u8fc7\u5bf9\u5b8c\u6574\u7684\u82f1\u5f0f\u65e9\u9910\u83dc\u8c31\u8fdb\u884c\u624b\u52a8\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86DSL\u7684\u8868\u8fbe\u80fd\u529b\u548c\u9002\u7528\u6027\u3002", "result": "\u521d\u6b65\u624b\u52a8\u8bc4\u4f30\u663e\u793a\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u548c\u9002\u7528\u6027\uff0c\u8fd9\u4e3a\u672a\u6765\u7684\u81ea\u52a8\u5316\u83dc\u8c31\u5206\u6790\u548c\u6267\u884c\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u8868\u793a\u83dc\u8c31\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u80fd\u591f\u7cbe\u786e\u3001\u6a21\u5757\u5316\u5730\u5efa\u6a21\u590d\u6742\u7684\u70f9\u996a\u5de5\u4f5c\u6d41\u7a0b\u3002\u521d\u6b65\u7684\u624b\u52a8\u8bc4\u4f30\u8868\u660e\u8fd9\u79cdDSL\u7684\u8868\u8fbe\u80fd\u529b\u548c\u9002\u7528\u6027\uff0c\u4e3a\u672a\u6765\u81ea\u52a8\u5316\u83dc\u8c31\u5206\u6790\u548c\u6267\u884c\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u901a\u8fc7\u4f7f\u7528\u65f6\u95f4\u56fe\u8868\uff0c\u6b64\u5de5\u4f5c\u4ee3\u8868\u4e86\u5411\u4ee5\u52a8\u4f5c\u4e3a\u4e2d\u5fc3\u7684\u70f9\u996a\u672c\u4f53\u8bba\u8fc8\u51fa\u7684\u521d\u6b65\u6b65\u9aa4\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u673a\u5668\u7406\u89e3\u3001\u7cbe\u786e\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u70f9\u996a\u6d41\u7a0b\u81ea\u52a8\u5316\uff0c\u9002\u7528\u4e8e\u5bb6\u5ead\u53a8\u623f\u548c\u4e13\u4e1a\u70f9\u996a\u73af\u5883\u3002"}}
{"id": "2509.04192", "categories": ["cs.AI", "cs.LO", "math.LO", "68T27, 68T30, 68T37, 03C13", "I.2; F.4; G.3"], "pdf": "https://arxiv.org/pdf/2509.04192", "abs": "https://arxiv.org/abs/2509.04192", "authors": ["Vera Koponen"], "title": "Domain size asymptotics for Markov logic networks", "comment": null, "summary": "A Markov logic network (MLN) determines a probability distribution on the set\nof structures, or ``possible worlds'', with an arbitrary finite domain. We\nstudy the properties of such distributions as the domain size tends to\ninfinity. Three types of concrete examples of MLNs will be considered, and the\nproperties of random structures with domain sizes tending to infinity will be\nstudied: (1) Arbitrary quantifier-free MLNs over a language with only one\nrelation symbol which has arity 1. In this case we give a pretty complete\ncharacterization of the possible limit behaviours of random structures. (2) An\nMLN that favours graphs with fewer triangles (or more generally, fewer\nk-cliques). As a corollary of the analysis a ``$\\delta$-approximate 0-1 law''\nfor first-order logic is obtained. (3) An MLN that favours graphs with fewer\nvertices with degree higher than a fixed (but arbitrary) number. The analysis\nshows that depending on which ``soft constraints'' an MLN uses the limit\nbehaviour of random structures can be quite different, and the weights of the\nsoft constraints may, or may not, have influence on the limit behaviour. It\nwill also be demonstrated, using (1), that quantifier-free MLNs and lifted\nBayesian networks (in a broad sense) are asymptotically incomparable, roughly\nmeaning that there is a sequence of distributions on possible worlds with\nincreasing domain sizes that can be defined by one of the formalisms but not\neven approximated by the other. In a rather general context it is also shown\nthat on large domains the distribution determined by an MLN concentrates almost\nall its probability mass on a totally different part of the space of possible\nworlds than the uniform distribution does.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u968f\u7740\u57df\u5927\u5c0f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6MLN\u786e\u5b9a\u6982\u7387\u5206\u5e03\u7684\u7279\u6027\uff0c\u5206\u6790\u4e86\u4e09\u79cd\u5177\u4f53\u7684MLN\u793a\u4f8b\uff0c\u63a2\u8ba8\u4e86\u968f\u673a\u7ed3\u6784\u7684\u6781\u9650\u884c\u4e3a\u3002\u901a\u8fc7\u5bf9\u4e09\u79cd\u60c5\u51b5\u7684\u5206\u6790\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c\u201c\u8f6f\u7ea6\u675f\u201d\u5bf9\u6781\u9650\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\u968f\u673a\u7ed3\u6784\u5728\u57df\u5927\u5c0f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6\uff0cMLN\u786e\u5b9a\u7684\u5206\u5e03\u53ef\u80fd\u96c6\u4e2d\u5728\u53ef\u80fd\u4e16\u754c\u7a7a\u95f4\u7684\u4e0d\u540c\u90e8\u5206\uff0c\u4e0d\u540c\u201c\u8f6f\u7ea6\u675f\u201d\u4f1a\u5f71\u54cd\u6781\u9650\u884c\u4e3a\uff0cMLNs\u548c\u63d0\u5347\u8d1d\u53f6\u65af\u7f51\u7edc\u5177\u6709\u4e0d\u53ef\u6bd4\u6027\u3002", "motivation": "\u7814\u7a76MLN\u5728\u57df\u5927\u5c0f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6\u7684\u5206\u5e03\u7279\u6027\uff0c\u63a2\u7a76\u968f\u673a\u7ed3\u6784\u7684\u6781\u9650\u884c\u4e3a\u53ca\u4e0d\u540c\u201c\u8f6f\u7ea6\u675f\u201d\u5bf9\u5176\u5f71\u54cd\u3002\u901a\u8fc7\u6bd4\u8f83MLNs\u548c\u63d0\u5347\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u6027\u8d28\uff0c\u63ed\u793a\u5b83\u4eec\u4e4b\u95f4\u7684\u533a\u522b\u548c\u4e0d\u53ef\u6bd4\u6027\u3002", "method": "\u7814\u7a76\u4e86\u968f\u7740\u57df\u5927\u5c0f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6MLN\u786e\u5b9a\u6982\u7387\u5206\u5e03\u7684\u7279\u6027\uff0c\u5206\u6790\u4e86\u4e09\u79cd\u5177\u4f53\u7684MLN\u793a\u4f8b\uff0c\u5e76\u63a2\u8ba8\u4e86\u968f\u673a\u7ed3\u6784\u7684\u6781\u9650\u884c\u4e3a\u3002\u901a\u8fc7\u5bf9\u4e09\u79cd\u60c5\u51b5\u7684\u5206\u6790\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c\u201c\u8f6f\u7ea6\u675f\u201d\u5bf9\u6781\u9650\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u6bd4\u8f83\u91cf\u8bcd\u81ea\u7531MLNs\u548c\u63d0\u5347\u8d1d\u53f6\u65af\u7f51\u7edc\u5728\u5927\u57df\u57df\u4e0a\u7684\u6027\u8d28\uff0c\u63ed\u793a\u5b83\u4eec\u5728\u6e10\u8fd1\u610f\u4e49\u4e0a\u7684\u4e0d\u53ef\u6bd4\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\u968f\u673a\u7ed3\u6784\u5728\u57df\u5927\u5c0f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6\uff0cMLN\u786e\u5b9a\u7684\u5206\u5e03\u53ef\u80fd\u96c6\u4e2d\u5728\u53ef\u80fd\u4e16\u754c\u7a7a\u95f4\u7684\u4e0d\u540c\u90e8\u5206\uff0c\u4e0d\u540c\u201c\u8f6f\u7ea6\u675f\u201d\u4f1a\u5f71\u54cd\u6781\u9650\u884c\u4e3a\uff0cMLNs\u548c\u63d0\u5347\u8d1d\u53f6\u65af\u7f51\u7edc\u5177\u6709\u4e0d\u53ef\u6bd4\u6027\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u968f\u7740\u57df\u5927\u5c0f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6\uff0c\u9a6c\u5c14\u53ef\u592b\u903b\u8f91\u7f51\u7edc\uff08Markov Logic Network\uff0cMLN\uff09\u786e\u5b9a\u7ed3\u6784\u96c6\u5408\u4e0a\u7684\u6982\u7387\u5206\u5e03\u7684\u7279\u6027\u3002\u901a\u8fc7\u7814\u7a76\u4e09\u79cd\u5177\u4f53\u7684MLN\u793a\u4f8b\uff0c\u63a2\u8ba8\u4e86\u968f\u7740\u57df\u5927\u5c0f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6\u968f\u673a\u7ed3\u6784\u7684\u7279\u6027\u3002\u5176\u4e2d\u5305\u62ec\uff1a(1) \u4e00\u4e2a\u4ec5\u542b\u4e00\u4e2a\u5173\u7cfb\u7b26\u53f7\uff08\u5177\u67091\u4e2aarity\uff09\u7684\u4efb\u610f\u91cf\u8bcd\u81ea\u7531MLN\u7684\u7279\u6027\u5206\u6790\uff1b(2) \u504f\u597d\u5177\u6709\u8f83\u5c11\u4e09\u89d2\u5f62\uff08\u6216\u66f4\u4e00\u822c\u5730\uff0c\u8f83\u5c11k-\u56e2\uff09\u7684\u56fe\u7684MLN\uff0c\u5f97\u5230\u4e00\u9636\u903b\u8f91\u7684\u201c$\text{\textdelta}$-\u8fd1\u4f3c0-1\u6cd5\u5219\u201d\u7684\u63a8\u8bba\uff1b(3) \u504f\u597d\u5177\u6709\u5ea6\u9ad8\u4e8e\u56fa\u5b9a\u6570\u76ee\u7684\u9876\u70b9\u7684\u56fe\u7684MLN\u7684\u7279\u6027\u5206\u6790\u3002\u901a\u8fc7\u5206\u6790\u8868\u660e\uff0c\u6839\u636eMLN\u4f7f\u7528\u7684\u201c\u8f6f\u7ea6\u675f\u201d\u7684\u4e0d\u540c\uff0c\u968f\u673a\u7ed3\u6784\u7684\u6781\u9650\u884c\u4e3a\u53ef\u80fd\u4f1a\u6709\u6240\u4e0d\u540c\uff0c\u800c\u8f6f\u7ea6\u675f\u7684\u6743\u91cd\u53ef\u80fd\u4f1a\u5bf9\u6781\u9650\u884c\u4e3a\u4ea7\u751f\u5f71\u54cd\u6216\u4e0d\u4ea7\u751f\u5f71\u54cd\u3002\u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u901a\u8fc7\uff081\uff09\u8868\u660e\u4e86\u91cf\u8bcd\u81ea\u7531MLNs\u548c\u5e7f\u4e49\u610f\u4e49\u4e0b\u7684\u63d0\u5347\u8d1d\u53f6\u65af\u7f51\u7edc\u5728\u6e10\u8fd1\u610f\u4e49\u4e0a\u662f\u4e0d\u53ef\u6bd4\u7684\uff0c\u5927\u57df\u57df\u4e0a\uff0cMLN\u786e\u5b9a\u7684\u5206\u5e03\u51e0\u4e4e\u5c06\u6240\u6709\u7684\u6982\u7387\u96c6\u4e2d\u5728\u53ef\u80fd\u4e16\u754c\u7a7a\u95f4\u7684\u4e00\u4e2a\u5b8c\u5168\u4e0d\u540c\u7684\u90e8\u5206\uff0c\u4e0e\u5747\u5300\u5206\u5e03\u4e0d\u540c\u3002"}}
{"id": "2509.04239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04239", "abs": "https://arxiv.org/abs/2509.04239", "authors": ["Arturo Valdivia", "Paolo Burelli"], "title": "Evaluating Quality of Gaming Narratives Co-created with AI", "comment": null, "summary": "This paper proposes a structured methodology to evaluate AI-generated game\nnarratives, leveraging the Delphi study structure with a panel of narrative\ndesign experts. Our approach synthesizes story quality dimensions from\nliterature and expert insights, mapping them into the Kano model framework to\nunderstand their impact on player satisfaction. The results can inform game\ndevelopers on prioritizing quality aspects when co-creating game narratives\nwith generative AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\u6765\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u6e38\u620f\u53d9\u4e8b\u8d28\u91cf\uff0c\u901a\u8fc7Delphi\u7814\u7a76\u7ed3\u6784\u4e0e\u53d9\u4e8b\u8bbe\u8ba1\u4e13\u5bb6\u5c0f\u7ec4\uff0c\u7ed3\u5408\u6545\u4e8b\u8d28\u91cf\u7ef4\u5ea6\u548cKano\u6a21\u578b\u6846\u67b6\uff0c\u5e2e\u52a9\u6e38\u620f\u5f00\u53d1\u4eba\u5458\u4f18\u5148\u8003\u8651\u8d28\u91cf\u65b9\u9762\uff0c\u4ece\u800c\u63d0\u9ad8\u73a9\u5bb6\u6ee1\u610f\u5ea6\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u6765\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u6e38\u620f\u53d9\u4e8b\u8d28\u91cf\uff0c\u5e76\u63a2\u8ba8\u5176\u5bf9\u73a9\u5bb6\u6ee1\u610f\u5ea6\u7684\u5f71\u54cd\uff0c\u4ee5\u5e2e\u52a9\u6e38\u620f\u5f00\u53d1\u4eba\u5458\u5728\u4e0e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5408\u4f5c\u521b\u4f5c\u6e38\u620f\u53d9\u4e8b\u65f6\u66f4\u597d\u5730\u9009\u62e9\u4f18\u5148\u8003\u8651\u7684\u8d28\u91cf\u65b9\u9762\u3002", "method": "\u5229\u7528Delphi\u7814\u7a76\u7ed3\u6784\u4e0e\u53d9\u4e8b\u8bbe\u8ba1\u4e13\u5bb6\u5c0f\u7ec4\uff0c\u7ed3\u5408\u6587\u732e\u548c\u4e13\u5bb6\u89c1\u89e3\u4e2d\u7684\u6545\u4e8b\u8d28\u91cf\u7ef4\u5ea6\uff0c\u5c06\u5176\u6620\u5c04\u5230Kano\u6a21\u578b\u6846\u67b6\u4e2d\uff0c\u4ee5\u4e86\u89e3\u5176\u5bf9\u73a9\u5bb6\u6ee1\u610f\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u7ed3\u6784\u5316\u65b9\u6cd5\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u6e38\u620f\u53d9\u4e8b\uff0c\u4ece\u6587\u732e\u548c\u4e13\u5bb6\u89c1\u89e3\u4e2d\u7efc\u5408\u6545\u4e8b\u8d28\u91cf\u7ef4\u5ea6\uff0c\u5e76\u6620\u5c04\u5230Kano\u6a21\u578b\u6846\u67b6\u4e2d\uff0c\u53ef\u4ee5\u5e2e\u52a9\u5f00\u53d1\u4eba\u5458\u4f18\u5148\u8003\u8651\u8d28\u91cf\u65b9\u9762\uff0c\u63d0\u9ad8\u73a9\u5bb6\u7684\u6ee1\u610f\u5ea6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\u6765\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u6e38\u620f\u53d9\u4e8b\uff0c\u5229\u7528\u5fb7\u5c14\u83f2\u7814\u7a76\u7ed3\u6784\u4e0e\u53d9\u4e8b\u8bbe\u8ba1\u4e13\u5bb6\u5c0f\u7ec4\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u7efc\u5408\u4e86\u6587\u732e\u548c\u4e13\u5bb6\u89c1\u89e3\u4e2d\u7684\u6545\u4e8b\u8d28\u91cf\u7ef4\u5ea6\uff0c\u5c06\u5b83\u4eec\u6620\u5c04\u5230Kano\u6a21\u578b\u6846\u67b6\u4e2d\uff0c\u4ee5\u4e86\u89e3\u5b83\u4eec\u5bf9\u73a9\u5bb6\u6ee1\u610f\u5ea6\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u53ef\u4ee5\u6307\u5bfc\u6e38\u620f\u5f00\u53d1\u4eba\u5458\u5728\u4e0e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5171\u540c\u521b\u4f5c\u6e38\u620f\u53d9\u4e8b\u65f6\u4f18\u5148\u8003\u8651\u8d28\u91cf\u65b9\u9762\u3002"}}
{"id": "2509.04310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04310", "abs": "https://arxiv.org/abs/2509.04310", "authors": ["Yunbo Long", "Liming Xu", "Lukas Beckenbauer", "Yuhan Liu", "Alexandra Brintrup"], "title": "EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation", "comment": null, "summary": "Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models\n(LLMs) has demonstrated that agents can engage in \\textit{complex},\n\\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,\nexisting LLM agents largely overlook the functional role of emotions in such\nnegotiations, instead generating passive, preference-driven emotional responses\nthat make them vulnerable to manipulation and strategic exploitation by\nadversarial counterparts. To address this gap, we present EvoEmo, an\nevolutionary reinforcement learning framework that optimizes dynamic emotional\nexpression in negotiations. EvoEmo models emotional state transitions as a\nMarkov Decision Process and employs population-based genetic optimization to\nevolve high-reward emotion policies across diverse negotiation scenarios. We\nfurther propose an evaluation framework with two baselines -- vanilla\nstrategies and fixed-emotion strategies -- for benchmarking emotion-aware\nnegotiation. Extensive experiments and ablation studies show that EvoEmo\nconsistently outperforms both baselines, achieving higher success rates, higher\nefficiency, and increased buyer savings. This findings highlight the importance\nof adaptive emotional expression in enabling more effective LLM agents for\nmulti-turn negotiation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u60c5\u611f\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u4e86EvoEmo\u6846\u67b6\u7528\u4e8e\u4f18\u5316\u60c5\u611f\u8868\u8fbe\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u5176\u5728\u591a\u8f6e\u534f\u5546\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u534f\u5546\u4e2d\u5bf9\u60c5\u611f\u7684\u5904\u7406\u8f83\u4e3a\u88ab\u52a8\uff0c\u5bb9\u6613\u53d7\u5230\u5bf9\u624b\u64cd\u7eb5\u548c\u5229\u7528\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\uff0c\u63a2\u8ba8\u60c5\u611f\u8868\u8fbe\u5728\u591a\u8f6e\u534f\u5546\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6EvoEmo\uff0c\u5c06\u60c5\u611f\u72b6\u6001\u8f6c\u6362\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u79cd\u7fa4\u7684\u9057\u4f20\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u4e0d\u540c\u534f\u5546\u573a\u666f\u4e2d\u6f14\u5316\u9ad8\u6536\u76ca\u60c5\u611f\u7b56\u7565\u3002\u63d0\u51fa\u4e86\u4e24\u4e2a\u57fa\u51c6\u6846\u67b6\u7528\u4e8e\u8bc4\u4f30\u60c5\u611f\u611f\u77e5\u534f\u5546\u7684\u6027\u80fd\u3002", "result": "EvoEmo\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86\u4e24\u4e2a\u57fa\u51c6\u65b9\u6cd5\uff0c\u5728\u591a\u8f6e\u534f\u5546\u4e2d\u53d6\u5f97\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3001\u66f4\u9ad8\u7684\u6548\u7387\u548c\u589e\u52a0\u7684\u4e70\u5bb6\u8282\u7701\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u652f\u6301\u60c5\u611f\u611f\u77e5\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u4e86EvoEmo\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u60c5\u611f\u8868\u8fbe\u4ee5\u63d0\u9ad8\u534f\u5546\u6548\u679c\u3002\u5b9e\u9a8c\u8bc1\u660eEvoEmo\u5728\u591a\u8f6e\u534f\u5546\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9ad8\u6210\u529f\u7387\uff0c\u6548\u7387\u66f4\u9ad8\uff0c\u4e70\u5bb6\u8282\u7701\u66f4\u591a\u3002"}}
{"id": "2509.04317", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04317", "abs": "https://arxiv.org/abs/2509.04317", "authors": ["Isidoro Tamassia", "Wendelin B\u00f6hmer"], "title": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "comment": null, "summary": "The AlphaZero framework provides a standard way of combining Monte Carlo\nplanning with prior knowledge provided by a previously trained policy-value\nneural network. AlphaZero usually assumes that the environment on which the\nneural network was trained will not change at test time, which constrains its\napplicability. In this paper, we analyze the problem of deploying AlphaZero\nagents in potentially changed test environments and demonstrate how the\ncombination of simple modifications to the standard framework can significantly\nboost performance, even in settings with a low planning budget available. The\ncode is publicly available on GitHub.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u53ef\u80fd\u53d8\u5316\u7684\u6d4b\u8bd5\u73af\u5883\u4e2d\u90e8\u7f72AlphaZero\u4ee3\u7406\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u901a\u8fc7\u7b80\u5355\u4fee\u6539\u6807\u51c6\u6846\u67b6\u5982\u4f55\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u672c\u6587\u5173\u6ce8AlphaZero\u4ee3\u7406\u5728\u53ef\u80fd\u53d8\u5316\u7684\u6d4b\u8bd5\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u95ee\u9898\uff0c\u65e8\u5728\u89e3\u51b3\u5176\u5728\u6d4b\u8bd5\u65f6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u73af\u5883\u4e0d\u53d8\u7684\u5047\u8bbe\u5bf9\u5176\u9002\u7528\u6027\u7684\u7ea6\u675f\u3002\u901a\u8fc7\u6539\u8fdb\u6807\u51c6\u6846\u67b6\uff0c\u63d0\u5347\u6027\u80fd\u662f\u52a8\u673a\u4e4b\u4e00\u3002", "method": "\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u89c4\u5212\u548c\u5148\u524d\u8bad\u7ec3\u7684\u7b56\u7565-\u4ef7\u503c\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u9488\u5bf9AlphaZero\u6846\u67b6\u5728\u53ef\u80fd\u53d1\u751f\u53d8\u5316\u7684\u6d4b\u8bd5\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u95ee\u9898\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u7b80\u5355\u4fee\u6539\u6807\u51c6\u6846\u67b6\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "result": "\u7b80\u5355\u4fee\u6539AlphaZero\u6846\u67b6\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u8ba1\u5212\u9884\u7b97\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u5728\u53ef\u80fd\u53d8\u5316\u7684\u6d4b\u8bd5\u73af\u5883\u4e2d\u90e8\u7f72AlphaZero\u4ee3\u7406\u7684\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5bf9\u6807\u51c6\u6846\u67b6\u8fdb\u884c\u7b80\u5355\u4fee\u6539\u5982\u4f55\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u8ba1\u5212\u9884\u7b97\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2509.04343", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.04343", "abs": "https://arxiv.org/abs/2509.04343", "authors": ["Maciej Besta", "Shriram Chandran", "Robert Gerstenberger", "Mathis Lindner", "Marcin Chrapek", "Sebastian Hermann Martschat", "Taraneh Ghandi", "Patrick Iff", "Hubert Niewiadomski", "Piotr Nyczyk", "J\u00fcrgen M\u00fcller", "Torsten Hoefler"], "title": "Psychologically Enhanced AI Agents", "comment": null, "summary": "We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of\nLarge Language Model (LLM) agents through psychologically grounded personality\nconditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method\nprimes agents with distinct personality archetypes via prompt engineering,\nenabling control over behavior along two foundational axes of human psychology,\ncognition and affect. We show that such personality priming yields consistent,\ninterpretable behavioral biases across diverse tasks: emotionally expressive\nagents excel in narrative generation, while analytically primed agents adopt\nmore stable strategies in game-theoretic settings. Our framework supports\nexperimenting with structured multi-agent communication protocols and reveals\nthat self-reflection prior to interaction improves cooperation and reasoning\nquality. To ensure trait persistence, we integrate the official 16Personalities\ntest for automated verification. While our focus is on MBTI, we show that our\napproach generalizes seamlessly to other psychological frameworks such as Big\nFive, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior\ndesign, we establish a foundation for psychologically enhanced AI agents\nwithout any fine-tuning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86MBTI-in-Thoughts\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u5fc3\u7406\u5b66\u4e2a\u6027\u5316\u8c03\u8282\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u6548\u679c\u3002\u4ed6\u4eec\u53d1\u73b0\u4e2a\u6027\u5316\u8c03\u8282\u53ef\u4ee5\u4ea7\u751f\u4e00\u81f4\u3001\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\u504f\u5411\uff0c\u6db5\u76d6\u4e0d\u540c\u4efb\u52a1\u3002\u7ed3\u679c\u663e\u793a\u60c5\u611f\u8868\u8fbe\u4e30\u5bcc\u7684\u4ee3\u7406\u5728\u53d9\u4e8b\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u5206\u6790\u6027\u8c03\u8282\u7684\u4ee3\u7406\u5728\u535a\u5f08\u8bba\u8bbe\u7f6e\u4e2d\u91c7\u53d6\u66f4\u7a33\u5b9a\u7684\u7b56\u7565\u3002\u4ed6\u4eec\u7684\u65b9\u6cd5\u4e5f\u53ef\u4ee5\u63a8\u5e7f\u5230\u5176\u4ed6\u5fc3\u7406\u6846\u67b6\u3002\u5b9e\u65bd\u524d\u7f6e\u81ea\u6211\u53cd\u601d\u53ef\u63d0\u9ad8\u5408\u4f5c\u548c\u63a8\u7406\u8d28\u91cf\u3002\u6574\u540816\u4e2a\u4eba\u683c\u6d4b\u8bd5\u4ee5\u786e\u4fdd\u7279\u8d28\u6301\u4e45\u6027\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u662f\u5efa\u7acb\u4e00\u79cd\u6846\u67b6\uff0c\u901a\u8fc7\u5fc3\u7406\u5b66\u7406\u8bba\u6765\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u6548\u679c\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u5fae\u8c03\u3002\u4ed6\u4eec\u8bd5\u56fe\u786e\u5b9a\u4e0d\u540c\u4e2a\u6027\u7c7b\u578b\u7684\u4ee3\u7406\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u81ea\u6211\u53cd\u601d\u5bf9\u5408\u4f5c\u548c\u63a8\u7406\u8d28\u91cf\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u5e0c\u671b\u9a8c\u8bc1\u4e2a\u6027\u7279\u8d28\u7684\u6301\u4e45\u6027\uff0c\u4ee5\u53ca\u7814\u7a76\u65b9\u6cd5\u7684\u63a8\u5e7f\u6027\u3002", "method": "\u4ed6\u4eec\u7684\u65b9\u6cd5\u662f\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u4e3a\u4ee3\u7406\u8bbe\u5b9a\u4e0d\u540c\u7684\u4e2a\u6027\u539f\u578b\uff0c\u63a7\u5236\u884c\u4e3a\u5728\u8ba4\u77e5\u548c\u60c5\u611f\u4e24\u4e2a\u57fa\u7840\u8f74\u4e0a\uff0c\u4ee5\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u6548\u679c\u3002\u53e6\u5916\uff0c\u4ed6\u4eec\u8fd8\u652f\u6301\u5b9e\u9a8c\u5316\u7684\u7ed3\u6784\u5316\u591a\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\uff0c\u4ee5\u53ca\u524d\u7f6e\u81ea\u6211\u53cd\u601d\u6765\u63d0\u9ad8\u5408\u4f5c\u548c\u63a8\u7406\u8d28\u91cf\u3002\u4e3a\u4e86\u786e\u4fdd\u4e2a\u6027\u6301\u4e45\u6027\uff0c\u4ed6\u4eec\u6574\u5408\u4e8616\u4e2a\u4eba\u683c\u6d4b\u8bd5\u8fdb\u884c\u81ea\u52a8\u9a8c\u8bc1\u3002\u4ed6\u4eec\u8fd8\u63a2\u8ba8\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u5982\u4f55\u63a8\u5e7f\u5230\u5176\u4ed6\u5fc3\u7406\u6846\u67b6\u3002", "result": "\u4ed6\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\uff0c\u7ecf\u8fc7\u4e2a\u6027\u5316\u8c03\u8282\u7684\u4ee3\u7406\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u884c\u4e3a\u504f\u5411\uff0c\u5e76\u4e14\u8fd9\u4e9b\u504f\u5411\u662f\u53ef\u89e3\u91ca\u7684\u3002\u60c5\u611f\u8868\u8fbe\u4e30\u5bcc\u7684\u4ee3\u7406\u5728\u53d9\u4e8b\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u5206\u6790\u6027\u8c03\u8282\u7684\u4ee3\u7406\u5728\u535a\u5f08\u8bba\u8bbe\u7f6e\u4e2d\u91c7\u53d6\u66f4\u7a33\u5b9a\u7684\u7b56\u7565\u3002\u4ed6\u4eec\u8fd8\u5c55\u793a\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u63a8\u5e7f\u5230\u5176\u4ed6\u5fc3\u7406\u6846\u67b6\u4e0a\u3002\u53e6\u5916\uff0c\u4ed6\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\u524d\u7f6e\u81ea\u6211\u53cd\u601d\u53ef\u4ee5\u63d0\u9ad8\u4ee3\u7406\u7684\u5408\u4f5c\u548c\u63a8\u7406\u8d28\u91cf\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMBTI-in-Thoughts\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5fc3\u7406\u5b66\u57fa\u7840\u7684\u4e2a\u6027\u5316\u8c03\u8282\uff0c\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u6548\u679c\u3002\u4ed6\u4eec\u901a\u8fc7Myers-Briggs\u7c7b\u578b\u6307\u6807\uff08MBTI\uff09\u7684\u53c2\u8003\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u4e3a\u4ee3\u7406\u8bbe\u5b9a\u4e0d\u540c\u7684\u4e2a\u6027\u539f\u578b\uff0c\u4ece\u800c\u63a7\u5236\u884c\u4e3a\u5728\u4eba\u7c7b\u5fc3\u7406\u5b66\u7684\u4e24\u4e2a\u57fa\u7840\u8f74\u4e0a\uff0c\u8ba4\u77e5\u548c\u60c5\u611f\u3002\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u79cd\u4e2a\u6027\u5316\u8c03\u8282\u4ea7\u751f\u4e86\u4e00\u81f4\u7684\u3001\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\u504f\u89c1\uff0c\u6db5\u76d6\u4e86\u5404\u79cd\u4efb\u52a1\uff1a\u5728\u53d9\u4e8b\u751f\u6210\u65b9\u9762\uff0c\u60c5\u611f\u8868\u8fbe\u4e30\u5bcc\u7684\u4ee3\u7406\u8868\u73b0\u51fa\u8272\uff0c\u800c\u5728\u535a\u5f08\u8bba\u8bbe\u7f6e\u4e2d\uff0c\u5206\u6790\u6027\u8c03\u8282\u7684\u4ee3\u7406\u91c7\u53d6\u66f4\u7a33\u5b9a\u7684\u7b56\u7565\u3002\u8be5\u6846\u67b6\u652f\u6301\u5b9e\u9a8c\u5316\u7684\u7ed3\u6784\u5316\u591a\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\uff0c\u5e76\u63ed\u793a\u81ea\u6211\u53cd\u601d\u6709\u52a9\u4e8e\u63d0\u9ad8\u5408\u4f5c\u548c\u63a8\u7406\u8d28\u91cf\u3002\u4e3a\u4e86\u786e\u4fdd\u7279\u8d28\u6301\u4e45\u6027\uff0c\u4ed6\u4eec\u6574\u5408\u4e86\u5b98\u65b9\u768416\u4e2a\u4eba\u683c\u6d4b\u8bd5\u8fdb\u884c\u81ea\u52a8\u9a8c\u8bc1\u3002\u867d\u7136\u4ed6\u4eec\u7684\u91cd\u70b9\u662fMBTI\uff0c\u4f46\u4ed6\u4eec\u5c55\u793a\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u5e73\u7a33\u63a8\u5e7f\u5230\u5176\u4ed6\u5fc3\u7406\u6846\u67b6\uff0c\u5982\u5927\u4e94\u4eba\u683c\u3001HEXACO\u6216Enneagram\u3002\u901a\u8fc7\u642d\u5efa\u5fc3\u7406\u7406\u8bba\u548cLLM\u884c\u4e3a\u8bbe\u8ba1\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u4ed6\u4eec\u5efa\u7acb\u4e86\u4e00\u4e2a\u57fa\u7840\uff0c\u7528\u4e8e\u589e\u5f3aAI\u4ee3\u7406\u7684\u5fc3\u7406\u6548\u679c\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u4efb\u4f55\u5fae\u8c03\u3002"}}
{"id": "2509.04439", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04439", "abs": "https://arxiv.org/abs/2509.04439", "authors": ["Matthew Ho", "Chen Si", "Zhaoxiang Feng", "Fangxu Yu", "Zhijian Liu", "Zhiting Hu", "Lianhui Qin"], "title": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "comment": null, "summary": "While inference-time scaling enables LLMs to carry out increasingly long and\ncapable reasoning traces, the patterns and insights uncovered during these\ntraces are immediately discarded once the context window is reset for a new\nquery. External memory is a natural way to persist these discoveries, and\nrecent work has shown clear benefits for reasoning-intensive tasks. We see an\nopportunity to make such memories more broadly reusable and scalable by moving\nbeyond instance-based memory entries (e.g. exact query/response pairs, or\nsummaries tightly coupled with the original problem context) toward\nconcept-level memory: reusable, modular abstractions distilled from solution\ntraces and stored in natural language. For future queries, relevant concepts\nare selectively retrieved and integrated into the prompt, enabling test-time\ncontinual learning without weight updates. Our design introduces new strategies\nfor abstracting takeaways from rollouts and retrieving entries for new queries,\npromoting reuse and allowing memory to expand with additional experiences. On\nthe challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over\na strong no-memory baseline with performance continuing to scale with inference\ncompute. We find abstract concepts to be the most consistent memory design,\noutscoring the baseline at all tested inference compute scales. Moreover, we\nconfirm that dynamically updating memory during test-time outperforms an\notherwise identical fixed memory setting with additional attempts, supporting\nthe hypothesis that solving more problems and abstracting more patterns to\nmemory enables further solutions in a form of self-improvement. Code available\nat https://github.com/matt-seb-ho/arc_memo.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u6982\u5ff5\u7ea7\u8bb0\u5fc6\uff0c\u63d0\u9ad8\u8bb0\u5fc6\u7684\u590d\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5b9e\u73b0\u5728\u6d4b\u8bd5\u65f6\u6301\u7eed\u5b66\u4e60\u800c\u65e0\u9700\u66f4\u65b0\u6743\u91cd\u3002\u5728ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6982\u5ff5\u7ea7\u8bb0\u5fc6\u7684\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u65e0\u8bb0\u5fc6\u57fa\u7ebf\u53d6\u5f97\u4e867.5%\u7684\u76f8\u5bf9\u589e\u76ca\uff0c\u5e76\u968f\u7740\u63a8\u7406\u8ba1\u7b97\u6027\u80fd\u7684\u63d0\u5347\u800c\u6301\u7eed\u6539\u5584\u3002\u52a8\u6001\u66f4\u65b0\u8bb0\u5fc6\u5728\u6d4b\u8bd5\u65f6\u4f18\u4e8e\u56fa\u5b9a\u8bb0\u5fc6\u8bbe\u7f6e\uff0c\u652f\u6301\u901a\u8fc7\u89e3\u51b3\u66f4\u591a\u95ee\u9898\u5e76\u5c06\u66f4\u591a\u6a21\u5f0f\u62bd\u8c61\u5230\u8bb0\u5fc6\u4e2d\u4ee5\u4fc3\u8fdb\u81ea\u6211\u6539\u8fdb\u7684\u5047\u8bbe\u3002", "motivation": "\u63a8\u7406\u65f6\u95f4\u7f29\u653e\u4f7fLLMs\u80fd\u591f\u8fdb\u884c\u8d8a\u6765\u8d8a\u957f\u4e14\u529f\u80fd\u66f4\u5f3a\u5927\u7684\u63a8\u7406\u8ddf\u8e2a\uff0c\u4f46\u4e00\u65e6\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e3a\u65b0\u67e5\u8be2\u800c\u91cd\u7f6e\uff0c\u8fd9\u4e9b\u8ddf\u8e2a\u4e2d\u53d1\u73b0\u7684\u6a21\u5f0f\u548c\u89c2\u70b9\u7acb\u5373\u88ab\u4e22\u5f03\u3002\u901a\u8fc7\u5916\u90e8\u8bb0\u5fc6\u6765\u4fdd\u7559\u8fd9\u4e9b\u53d1\u73b0\u662f\u4e00\u79cd\u81ea\u7136\u7684\u65b9\u5f0f\uff0c\u8fd1\u671f\u5de5\u4f5c\u8868\u660e\u5bf9\u4e8e\u9700\u8981\u5927\u91cf\u63a8\u7406\u7684\u4efb\u52a1\u5b58\u5728\u660e\u663e\u597d\u5904\u3002\u7814\u7a76\u8005\u770b\u5230\u901a\u8fc7\u8f6c\u5411\u6982\u5ff5\u7ea7\u8bb0\u5fc6\uff08\u800c\u975e\u57fa\u4e8e\u5b9e\u4f8b\u7684\u8bb0\u5fc6\u6761\u76ee\uff0c\u5982\u786e\u5207\u7684\u67e5\u8be2/\u54cd\u5e94\u5bf9\u6216\u4e0e\u539f\u59cb\u95ee\u9898\u80cc\u666f\u7d27\u5bc6\u8026\u5408\u7684\u6458\u8981\uff09\u53ef\u4ee5\u4f7f\u8bb0\u5fc6\u66f4\u5177\u590d\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u673a\u4f1a\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u6982\u5ff5\u7ea7\u8bb0\u5fc6\uff0c\u63d0\u9ad8\u8bb0\u5fc6\u7684\u590d\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u5728\u6d4b\u8bd5\u65f6\u6301\u7eed\u5b66\u4e60\u800c\u65e0\u9700\u66f4\u65b0\u6743\u91cd\u3002\u8bbe\u8ba1\u4e86\u65b0\u7684\u7b56\u7565\u6765\u63d0\u53d6\u63a8\u7406\u8f68\u8ff9\u7684\u8981\u70b9\u5e76\u4e3a\u65b0\u95ee\u9898\u68c0\u7d22\u6761\u76ee\uff0c\u4fc3\u8fdb\u8bb0\u5fc6\u7684\u91cd\u590d\u4f7f\u7528\uff0c\u5e76\u5141\u8bb8\u968f\u7740\u65b0\u589e\u7ecf\u9a8c\u7684\u79ef\u7d2f\u800c\u6269\u5c55\u8bb0\u5fc6\u3002", "result": "\u5728ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u91c7\u7528\u6982\u5ff5\u7ea7\u8bb0\u5fc6\u7684\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u65e0\u8bb0\u5fc6\u57fa\u7ebf\u53d6\u5f97\u4e867.5%\u7684\u76f8\u5bf9\u589e\u76ca\uff0c\u5e76\u4e14\u8868\u73b0\u968f\u63a8\u7406\u8ba1\u7b97\u6027\u80fd\u7684\u63d0\u5347\u800c\u6301\u7eed\u6539\u5584\u3002\u5728\u6240\u6709\u6d4b\u8bd5\u7684\u63a8\u7406\u8ba1\u7b97\u89c4\u6a21\u4e0b\uff0c\u53d1\u73b0\u62bd\u8c61\u6982\u5ff5\u662f\u6700\u4e00\u81f4\u7684\u8bb0\u5fc6\u8bbe\u8ba1\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002\u6b64\u5916\uff0c\u52a8\u6001\u66f4\u65b0\u8bb0\u5fc6\u5728\u6d4b\u8bd5\u65f6\u8868\u73b0\u4f18\u4e8e\u5426\u5219\u76f8\u540c\u7684\u56fa\u5b9a\u8bb0\u5fc6\u8bbe\u7f6e\uff0c\u652f\u6301\u89e3\u51b3\u66f4\u591a\u95ee\u9898\u5e76\u5c06\u66f4\u591a\u6a21\u5f0f\u62bd\u8c61\u5230\u8bb0\u5fc6\u4e2d\u4ee5\u4fc3\u8fdb\u81ea\u6211\u6539\u8fdb\u7684\u5047\u8bbe\u3002", "conclusion": "\u5728\u9762\u5bf9\u9700\u8981\u957f\u65f6\u95f4\u63a8\u7406\u7684\u4efb\u52a1\u65f6\uff0c\u901a\u8fc7\u5f15\u5165\u6982\u5ff5\u7ea7\u8bb0\u5fc6\uff0c\u53ef\u4ee5\u63d0\u9ad8\u63a8\u7406\u6027\u80fd\u5e76\u4fc3\u8fdb\u8bb0\u5fc6\u7684\u590d\u7528\u548c\u6269\u5c55\u3002\u8be5\u65b9\u6cd5\u5728ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u5bf9\u5f3a\u7684\u65e0\u8bb0\u5fc6\u57fa\u7ebf\u53d6\u5f97\u4e867.5%\u7684\u76f8\u5bf9\u589e\u76ca\uff0c\u5e76\u968f\u7740\u63a8\u7406\u8ba1\u7b97\u6027\u80fd\u7684\u63d0\u5347\u800c\u6301\u7eed\u6539\u5584\u3002\u52a8\u6001\u66f4\u65b0\u8bb0\u5fc6\u5728\u6d4b\u8bd5\u65f6\u4f18\u4e8e\u56fa\u5b9a\u8bb0\u5fc6\u8bbe\u7f6e\uff0c\u652f\u6301\u901a\u8fc7\u89e3\u51b3\u66f4\u591a\u95ee\u9898\u5e76\u5c06\u66f4\u591a\u6a21\u5f0f\u62bd\u8c61\u5230\u8bb0\u5fc6\u4e2d\u4ee5\u4fc3\u8fdb\u81ea\u6211\u6539\u8fdb\u7684\u5047\u8bbe\u3002"}}
