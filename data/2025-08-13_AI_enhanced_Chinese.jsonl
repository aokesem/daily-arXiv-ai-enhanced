{"id": "2508.08293", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08293", "abs": "https://arxiv.org/abs/2508.08293", "authors": ["Sridhar Mahadevan"], "title": "Topos Theory for Generative AI and LLMs", "comment": "30 pages", "summary": "We propose the design of novel categorical generative AI architectures\n(GAIAs) using topos theory, a type of category that is ``set-like\": a topos has\nall (co)limits, is Cartesian closed, and has a subobject classifier. Previous\ntheoretical results on the Transformer model have shown that it is a universal\nsequence-to-sequence function approximator, and dense in the space of all\ncontinuous functions with compact support on the Euclidean space of embeddings\nof tokens. Building on this theoretical result, we explore novel architectures\nfor LLMs that exploit the property that the category of LLMs, viewed as\nfunctions, forms a topos. Previous studies of large language models (LLMs) have\nfocused on daisy-chained linear architectures or mixture-of-experts. In this\npaper, we use universal constructions in category theory to construct novel LLM\narchitectures based on new types of compositional structures. In particular,\nthese new compositional structures are derived from universal properties of LLM\ncategories, and include pullback, pushout, (co) equalizers, exponential\nobjects, and subobject classifiers. We theoretically validate these new\ncompositional structures by showing that the category of LLMs is (co)complete,\nmeaning that all diagrams have solutions in the form of (co)limits. Building on\nthis completeness result, we then show that the category of LLMs forms a topos,\na ``set-like\" category, which requires showing the existence of exponential\nobjects as well as subobject classifiers. We use a functorial characterization\nof backpropagation to define a potential implementation of an LLM topos\narchitecture.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4f7f\u7528\u62d3\u6251\u7406\u8bba\u548c\u8303\u7574\u8bba\u4e2d\u7684\u901a\u7528\u6784\u9020\u65b9\u6cd5\uff0c\u63a2\u7d22\u65b0\u578bLLM\u67b6\u6784\uff0c\u9a8c\u8bc1\u4e86LLMs\u7684\u5206\u7c7b\u5f62\u6210\u4e86\u4e00\u4e2a\u62d3\u6251\uff0c\u5b9a\u4e49\u4e86LLM\u62d3\u6251\u67b6\u6784\u7684\u6f5c\u5728\u5b9e\u73b0\u3002", "motivation": "\u901a\u8fc7\u62d3\u6251\u7406\u8bba\u548c\u8303\u7574\u8bba\u7684\u7814\u7a76\uff0c\u6784\u5efa\u65b0\u578b\u5206\u7c7b\u751f\u6210AI\u67b6\u6784\u548cLLM\u67b6\u6784\uff0c\u63a2\u7d22\u5176\u901a\u7528\u6784\u9020\u3002\u672a\u6765\u6709\u671b\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u672c\u6587\u4f7f\u7528\u62d3\u6251\u7406\u8bba\u548c\u8303\u7574\u8bba\u4e2d\u7684\u901a\u7528\u6784\u9020\u65b9\u6cd5\uff0c\u63a2\u7d22\u4e86\u65b0\u578bLLM\u67b6\u6784\u3002\u501f\u9274Transformer\u6a21\u578b\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u6784\u5efa\u4e86LLM\u67b6\u6784\uff0c\u5e76\u9a8c\u8bc1\u4e86LLMs\u7684\u5206\u7c7b\u5f62\u6210\u4e86\u4e00\u4e2a\u62d3\u6251\u3002\u5229\u7528\u51fd\u6570\u6027\u63cf\u8ff0\u53cd\u5411\u4f20\u64ad\uff0c\u5b9a\u4e49\u4e86LLM\u62d3\u6251\u67b6\u6784\u7684\u6f5c\u5728\u5b9e\u73b0\u3002", "result": "\u9a8c\u8bc1\u4e86LLMs\u7684\u5206\u7c7b\u5f62\u6210\u4e86\u4e00\u4e2a\u62d3\u6251\uff0c\u5c55\u793a\u4e86\u65b0\u578bLLM\u67b6\u6784\u7684\u6f5c\u5728\u5b9e\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4f7f\u7528\u62d3\u6251\u7406\u8bba\u8bbe\u8ba1\u65b0\u578b\u5206\u7c7b\u751f\u6210AI\u67b6\u6784(GAIAs)\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u7814\u7a76\u524d\u6cbf\u7684Transformer\u6a21\u578b\u7406\u8bba\u7ed3\u679c\uff0c\u63a2\u7d22\u4e86\u57fa\u4e8eLLMs\u7684\u65b0\u578b\u67b6\u6784\uff0c\u5e76\u4f7f\u7528\u8303\u7574\u8bba\u4e2d\u7684\u901a\u7528\u6784\u9020\u6765\u6784\u5efa\u65b0\u578bLLM\u67b6\u6784\u3002\u6700\u7ec8\u9a8c\u8bc1\u4e86LLMs\u7684\u5206\u7c7b\u5f62\u6210\u4e86\u4e00\u4e2a\u62d3\u6251\uff0c\u9700\u8981\u5c55\u793a\u6307\u6570\u5bf9\u8c61\u548c\u5b50\u5bf9\u8c61\u5206\u7c7b\u5668\u7684\u5b58\u5728\u3002\u901a\u8fc7\u51fd\u6570\u6027\u63cf\u8ff0\u53cd\u5411\u4f20\u64ad\uff0c\u5b9a\u4e49\u4e86LLM\u62d3\u6251\u67b6\u6784\u7684\u6f5c\u5728\u5b9e\u73b0\u3002"}}
{"id": "2508.08295", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08295", "abs": "https://arxiv.org/abs/2508.08295", "authors": ["Sridhar Mahadevan"], "title": "Topos Causal Models", "comment": "31 pages", "summary": "We propose topos causal models (TCMs), a novel class of causal models that\nexploit the key properties of a topos category: they are (co)complete, meaning\nall (co)limits exist, they admit a subobject classifier, and allow exponential\nobjects. The main goal of this paper is to show that these properties are\ncentral to many applications in causal inference. For example, subobject\nclassifiers allow a categorical formulation of causal intervention, which\ncreates sub-models. Limits and colimits allow causal diagrams of arbitrary\ncomplexity to be ``solved\", using a novel interpretation of causal\napproximation. Exponential objects enable reasoning about equivalence classes\nof operations on causal models, such as covered edge reversal and causal\nhomotopy. Analogous to structural causal models (SCMs), TCMs are defined by a\ncollection of functions, each defining a ``local autonomous\" causal mechanism\nthat assemble to induce a unique global function from exogenous to endogenous\nvariables. Since the category of TCMs is (co)complete, which we prove in this\npaper, every causal diagram has a ``solution\" in the form of a (co)limit: this\nimplies that any arbitrary causal model can be ``approximated\" by some global\nfunction with respect to the morphisms going into or out of the diagram.\nNatural transformations are crucial in measuring the quality of approximation.\nIn addition, we show that causal interventions are modeled by subobject\nclassifiers: any sub-model is defined by a monic arrow into its parent model.\nExponential objects permit reasoning about entire classes of causal\nequivalences and interventions. Finally, as TCMs form a topos, they admit an\ninternal logic defined as a Mitchell-Benabou language with an associated\nKripke-Joyal semantics. We show how to reason about causal models in TCMs using\nthis internal logic.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u62d3\u6251\u56e0\u679c\u6a21\u578b(TCMs)\uff0c\u5c55\u793a\u4e86\u5176\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u8bc1\u660e\u6bcf\u4e2a\u56e0\u679c\u56fe\u90fd\u6709\u4e00\u4e2a\u201c\u89e3\u201d\u6765\u5b9e\u73b0\u56e0\u679c\u6a21\u578b\u7684\u8fd1\u4f3c\uff0c\u5f3a\u8c03\u81ea\u7136\u53d8\u6362\u5728\u8861\u91cf\u8fd1\u4f3c\u8d28\u91cf\u4e2d\u7684\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u56e0\u679c\u8fd1\u4f3c\u89e3\u91ca\uff0c\u4e3a\u5efa\u7acb\u5c40\u90e8\u81ea\u6cbb\u56e0\u679c\u673a\u5236\u7684\u5168\u5c40\u51fd\u6570\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5c55\u793a\u62d3\u6251\u56e0\u679c\u6a21\u578b\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u4ece\u63d0\u51fa\u65b0\u7684\u56e0\u679c\u6a21\u578b\u89d2\u5ea6\u63a2\u7d22\u56e0\u679c\u63a8\u65ad\u7684\u5404\u79cd\u5e94\u7528\uff0c\u4e3a\u56e0\u679c\u7b49\u4ef7\u548c\u5e72\u9884\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u63a8\u7406\u65b9\u5f0f\uff0c\u5e76\u901a\u8fc7\u5185\u90e8\u903b\u8f91\u548cKripke-Joyal\u8bed\u4e49\u6765\u7406\u89e3\u56e0\u679c\u6a21\u578b\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8bc1\u660e\u62d3\u6251\u56e0\u679c\u6a21\u578b\u662f(co)complete\u7684\uff0c\u5c55\u793a\u4e86\u6bcf\u4e2a\u56e0\u679c\u56fe\u90fd\u6709\u4e00\u4e2a(co)limit\u7684\u201c\u89e3\u201d\uff0c\u4ece\u800c\u8868\u660e\u4efb\u610f\u56e0\u679c\u6a21\u578b\u90fd\u53ef\u4ee5\u901a\u8fc7\u67d0\u4e2a\u5168\u5c40\u51fd\u6570\u6765\u201c\u8fd1\u4f3c\u201d\uff0c\u540c\u65f6\u91cd\u89c6\u81ea\u7136\u53d8\u6362\u5728\u8861\u91cf\u8fd1\u4f3c\u8d28\u91cf\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u62d3\u6251\u56e0\u679c\u6a21\u578b(TCMs)\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u56e0\u679c\u6a21\u578b\u7c7b\u522b\uff0c\u5177\u6709(co)complete\u6027\u8d28\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u56e0\u679c\u63a8\u65ad\u95ee\u9898\uff0c\u901a\u8fc7\u5c40\u90e8\u81ea\u6cbb\u56e0\u679c\u673a\u5236\u7684\u5168\u5c40\u51fd\u6570\u89e3\u6784\u5efa\u7acb\u5168\u5c40\u51fd\u6570\uff0c\u540c\u65f6\u901a\u8fc7\u62d3\u6251\u6784\u9020\u63d0\u4f9b\u4e86\u56e0\u679c\u7b49\u4ef7\u548c\u56e0\u679c\u5e72\u9884\u7684\u63a8\u7406\u65b9\u5f0f\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u62d3\u6251\u56e0\u679c\u6a21\u578b(TCMs)\uff0c\u5c55\u793a\u4e86\u5176\u4e0e\u56e0\u679c\u63a8\u65ad\u4e2d\u8bb8\u591a\u5e94\u7528\u7684\u5173\u952e\u6027\u8d28\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u9896\u7684\u56e0\u679c\u8fd1\u4f3c\u89e3\u91ca\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u590d\u6742\u7684\u56e0\u679c\u56fe\uff0c\u4e3a\u5efa\u7acb\u5c40\u90e8\u81ea\u6cbb\u56e0\u679c\u673a\u5236\u7684\u5168\u5c40\u51fd\u6570\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.08297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08297", "abs": "https://arxiv.org/abs/2508.08297", "authors": ["Rodrigo Lankaites Pinheiro", "Dario Landa-Silva", "Wasakorn Laesanklang", "Ademir Aparecido Constantino"], "title": "An Efficient Application of Goal Programming to Tackle Multiobjective Problems with Recurring Fitness Landscapes", "comment": null, "summary": "Many real-world applications require decision-makers to assess the quality of\nsolutions while considering multiple conflicting objectives. Obtaining good\napproximation sets for highly constrained many-objective problems is often a\ndifficult task even for modern multiobjective algorithms. In some cases,\nmultiple instances of the problem scenario present similarities in their\nfitness landscapes. That is, there are recurring features in the fitness\nlandscapes when searching for solutions to different problem instances. We\npropose a methodology to exploit this characteristic by solving one instance of\na given problem scenario using computationally expensive multiobjective\nalgorithms to obtain a good approximation set and then using Goal Programming\nwith efficient single-objective algorithms to solve other instances of the same\nproblem scenario. We use three goal-based objective functions and show that on\nbenchmark instances of the multiobjective vehicle routing problem with time\nwindows, the methodology is able to produce good results in short computation\ntime. The methodology allows to combine the effectiveness of state-of-the-art\nmultiobjective algorithms with the efficiency of goal programming to find good\ncompromise solutions in problem scenarios where instances have similar fitness\nlandscapes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u76ee\u6807\u7b97\u6cd5\u548c\u76ee\u6807\u89c4\u5212\uff0c\u5728\u5177\u6709\u76f8\u4f3c\u9002\u5e94\u5ea6\u666f\u89c2\u7684\u95ee\u9898\u5b9e\u4f8b\u4e2d\u627e\u5230\u826f\u597d\u7684\u6298\u8877\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u95ee\u9898\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002", "motivation": "\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u9700\u8981\u51b3\u7b56\u8005\u5728\u8003\u8651\u591a\u4e2a\u51b2\u7a81\u76ee\u6807\u65f6\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\uff0c\u89e3\u51b3\u9ad8\u5ea6\u53d7\u9650\u5236\u7684\u591a\u76ee\u6807\u95ee\u9898\u901a\u5e38\u662f\u4e00\u9879\u8270\u5de8\u7684\u4efb\u52a1\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u8ba1\u7b97\u5f00\u9500\u8f83\u5927\u7684\u591a\u76ee\u6807\u7b97\u6cd5\u89e3\u51b3\u4e00\u4e2a\u7ed9\u5b9a\u95ee\u9898\u60c5\u666f\u7684\u5b9e\u4f8b\uff0c\u7136\u540e\u5229\u7528\u6548\u7387\u9ad8\u7684\u5355\u76ee\u6807\u7b97\u6cd5\u548c\u76ee\u6807\u89c4\u5212\u89e3\u51b3\u76f8\u540c\u95ee\u9898\u60c5\u666f\u7684\u5176\u4ed6\u5b9e\u4f8b\u3002\u4f7f\u7528\u4e86\u4e09\u4e2a\u57fa\u4e8e\u76ee\u6807\u7684\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5728\u591a\u76ee\u6807\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u5b9e\u4f8b\u4e0a\u5c55\u793a\u4e86\u63d0\u51fa\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u76ee\u6807\u7b97\u6cd5\u548c\u76ee\u6807\u89c4\u5212\uff0c\u7528\u4e8e\u89e3\u51b3\u5177\u6709\u76f8\u4f3c\u9002\u5e94\u5ea6\u666f\u89c2\u7684\u95ee\u9898\u5b9e\u4f8b\uff0c\u80fd\u591f\u5728\u77ed\u65f6\u95f4\u5185\u4ea7\u751f\u826f\u597d\u7684\u7ed3\u679c\u3002"}}
{"id": "2508.08300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08300", "abs": "https://arxiv.org/abs/2508.08300", "authors": ["Yongchao Huang"], "title": "LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models", "comment": "6 pages", "summary": "A significant barrier to the widespread adoption of Bayesian inference is the\nspecification of prior distributions and likelihoods, which often requires\nspecialized statistical expertise. This paper investigates the feasibility of\nusing a Large Language Model (LLM) to automate this process. We introduce\nLLM-BI (Large Language Model-driven Bayesian Inference), a conceptual pipeline\nfor automating Bayesian workflows. As a proof-of-concept, we present two\nexperiments focused on Bayesian linear regression. In Experiment I, we\ndemonstrate that an LLM can successfully elicit prior distributions from\nnatural language. In Experiment II, we show that an LLM can specify the entire\nmodel structure, including both priors and the likelihood, from a single\nhigh-level problem description. Our results validate the potential of LLMs to\nautomate key steps in Bayesian modeling, enabling the possibility of an\nautomated inference pipeline for probabilistic programming.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528LLM\u81ea\u52a8\u5316\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86LLM-BI\u6982\u5ff5\u7ba1\u9053\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LLM\u7684\u6f5c\u529b\uff0c\u4e3a\u6982\u7387\u7f16\u7a0b\u7684\u81ea\u52a8\u5316\u63a8\u65ad\u7ba1\u7ebf\u94fa\u5e73\u4e86\u9053\u8def\u3002", "motivation": "\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u666e\u53ca\u9762\u4e34\u7740\u5148\u9a8c\u5206\u5e03\u548c\u4f3c\u7136\u51fd\u6570\u7684\u89c4\u8303\u5316\u95ee\u9898\uff0c\u9700\u8981\u4e13\u4e1a\u7684\u7edf\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u3002\u672c\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u4f7f\u7528LLM\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\u7684\u53ef\u884c\u6027\u3002", "method": "\u4ecb\u7ecd\u4e86LLM-BI\uff08\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u8d1d\u53f6\u65af\u63a8\u65ad\uff09\u7684\u6982\u5ff5\u7ba1\u9053\uff0c\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u5c55\u793a\u4e86LLM\u80fd\u591f\u4ece\u81ea\u7136\u8bed\u8a00\u4e2d\u83b7\u53d6\u5148\u9a8c\u5206\u5e03\u5e76\u6307\u5b9a\u5b8c\u6574\u7684\u6a21\u578b\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eLLM\u53ef\u4ee5\u6210\u529f\u4ece\u81ea\u7136\u8bed\u8a00\u4e2d\u83b7\u53d6\u5148\u9a8c\u5206\u5e03\uff0c\u5e76\u4e14\u80fd\u591f\u4ece\u9ad8\u5c42\u95ee\u9898\u63cf\u8ff0\u4e2d\u6307\u5b9a\u6574\u4e2a\u6a21\u578b\u7ed3\u6784\uff0c\u5305\u62ec\u5148\u9a8c\u548c\u4f3c\u7136\u51fd\u6570\u3002", "conclusion": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u8fc7\u7a0b\uff0c\u5e76\u8bc1\u5b9e\u4e86LLM\u5728\u81ea\u52a8\u5316\u8d1d\u53f6\u65af\u5efa\u6a21\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.08308", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08308", "abs": "https://arxiv.org/abs/2508.08308", "authors": ["Chuanruo Fu", "Yuncheng Du"], "title": "First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) often struggle to deliver accurate and\nactionable answers when user-provided information is incomplete or\nill-specified. We propose a new interaction paradigm, First Ask Then Answer\n(FATA), in which, through prompt words, LLMs are guided to proactively generate\nmultidimensional supplementary questions for users prior to response\ngeneration. Subsequently, by integrating user-provided supplementary\ninformation with the original query through sophisticated prompting techniques,\nwe achieve substantially improved response quality and relevance. In contrast\nto existing clarification approaches -- such as the CLAM framework oriented to\nambiguity and the self-interrogation Self-Ask method -- FATA emphasizes\ncompleteness (beyond mere disambiguation) and user participation (inviting\nhuman input instead of relying solely on model-internal reasoning). It also\nadopts a single-turn strategy: all clarifying questions are produced at once,\nthereby reducing dialogue length and improving efficiency. Conceptually, FATA\nuses the reasoning power of LLMs to scaffold user expression, enabling\nnon-expert users to formulate more comprehensive and contextually relevant\nqueries. To evaluate FATA, we constructed a multi-domain benchmark and compared\nit with two controls: a baseline prompt (B-Prompt) and a context-enhanced\nexpert prompt (C-Prompt). Experimental results show that FATA outperforms\nB-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient\nof variation 8% lower than C-Prompt, indicating superior stability.", "AI": {"tldr": "\u63d0\u51fa\u4e86First Ask Then Answer\uff08FATA\uff09\u4ea4\u4e92\u8303\u5f0f\uff0c\u901a\u8fc7\u591a\u7ef4\u8865\u5145\u95ee\u9898\u548c\u7528\u6237\u4fe1\u606f\u76f8\u7ed3\u5408\uff0c\u63d0\u9ad8\u4e86LLMs\u7684\u54cd\u5e94\u8d28\u91cf\u548c\u76f8\u5173\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aFATA\u5728\u7efc\u5408\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "LLMs\u5728\u9762\u5bf9\u7528\u6237\u63d0\u4f9b\u4e0d\u5b8c\u6574\u6216\u6a21\u7cca\u7684\u4fe1\u606f\u65f6\u5f80\u5f80\u96be\u4ee5\u63d0\u4f9b\u51c6\u786e\u53ef\u64cd\u4f5c\u7684\u7b54\u6848\u3002\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u901a\u8fc7\u65b0\u7684\u4ea4\u4e92\u8303\u5f0fFATA\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5f3a\u8c03\u5b8c\u6574\u6027\u548c\u7528\u6237\u53c2\u4e0e\uff0c\u63d0\u9ad8\u5bf9\u8bdd\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528First Ask Then Answer\uff08FATA\uff09\u4ea4\u4e92\u8303\u5f0f\uff0c\u901a\u8fc7\u4fc3\u4f7fLLMs\u751f\u6210\u591a\u7ef4\u8865\u5145\u95ee\u9898\uff0c\u7ed3\u5408\u7528\u6237\u63d0\u4f9b\u4fe1\u606f\u548c\u539f\u59cb\u67e5\u8be2\uff0c\u91c7\u7528\u590d\u6742\u7684\u5f15\u5bfc\u6280\u672f\uff0c\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\u548c\u76f8\u5173\u6027\u3002\u8bc4\u4f30\u91c7\u7528\u4e86\u591a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e0e\u4e24\u4e2a\u5bf9\u7167\u5b9e\u9a8c\uff08B-Prompt\u548cC-Prompt\uff09\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cFATA\u5728\u7efc\u5408\u6307\u6807\u4e0a\u6bd4B-Prompt\u63d0\u9ad8\u7ea640%\uff0c\u5177\u6709\u8f83\u4f4e\u7684\u53d8\u5f02\u7cfb\u6570\uff0c\u8868\u73b0\u66f4\u52a0\u7a33\u5b9a\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ea4\u4e92\u8303\u5f0fFirst Ask Then Answer\uff08FATA\uff09\uff0c\u901a\u8fc7\u63d0\u793a\u8bcd\u5f15\u5bfcLLMs\u4e3b\u52a8\u751f\u6210\u591a\u7ef4\u8865\u5145\u95ee\u9898\uff0c\u7ed3\u5408\u7528\u6237\u63d0\u4f9b\u7684\u4fe1\u606f\u548c\u539f\u59cb\u67e5\u8be2\uff0c\u901a\u8fc7\u590d\u6742\u7684\u5f15\u5bfc\u6280\u672f\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u9ad8\u7684\u54cd\u5e94\u8d28\u91cf\u548c\u76f8\u5173\u6027\u3002\u4e0e\u73b0\u6709\u7684\u6f84\u6e05\u65b9\u6cd5\uff08\u5982\u9488\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684CLAM\u6846\u67b6\u548c\u81ea\u95ee\u81ea\u7b54\u7684\u65b9\u6cd5Self-Ask\uff09\u76f8\u6bd4\uff0cFATA\u5f3a\u8c03\u5b8c\u6574\u6027\u548c\u7528\u6237\u53c2\u4e0e\uff0c\u91c7\u7528\u4e00\u6b21\u6027\u7b56\u7565\u751f\u6210\u6240\u6709\u6f84\u6e05\u95ee\u9898\uff0c\u51cf\u5c11\u5bf9\u8bdd\u957f\u5ea6\uff0c\u63d0\u9ad8\u6548\u7387\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cFATA\u5728\u7efc\u5408\u6307\u6807\u4e0a\u6bd4B-Prompt\u63d0\u9ad8\u7ea640%\uff0c\u4e14\u5177\u6709\u6bd4C-Prompt\u4f4e8%\u7684\u53d8\u5f02\u7cfb\u6570\uff0c\u8868\u73b0\u66f4\u52a0\u7a33\u5b9a\u3002"}}
{"id": "2508.08344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08344", "abs": "https://arxiv.org/abs/2508.08344", "authors": ["Dongzhuoran Zhou", "Yuqicheng Zhu", "Xiaxia Wang", "Hongkuan Zhou", "Yuan He", "Jiaoyan Chen", "Evgeny Kharlamov", "Steffen Staab"], "title": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge", "comment": null, "summary": "Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an\nincreasingly explored approach for combining the reasoning capabilities of\nlarge language models with the structured evidence of knowledge graphs.\nHowever, current evaluation practices fall short: existing benchmarks often\ninclude questions that can be directly answered using existing triples in KG,\nmaking it unclear whether models perform reasoning or simply retrieve answers\ndirectly. Moreover, inconsistent evaluation metrics and lenient answer matching\ncriteria further obscure meaningful comparisons. In this work, we introduce a\ngeneral method for constructing benchmarks, together with an evaluation\nprotocol, to systematically assess KG-RAG methods under knowledge\nincompleteness. Our empirical results show that current KG-RAG methods have\nlimited reasoning ability under missing knowledge, often rely on internal\nmemorization, and exhibit varying degrees of generalization depending on their\ndesign.", "AI": {"tldr": "\u77e5\u8bc6\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u77e5\u8bc6\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u4f9d\u8d56\u5185\u90e8\u8bb0\u5fc6\uff0c\u6cdb\u5316\u80fd\u529b\u53d7\u8bbe\u8ba1\u5f71\u54cd\u3002\u63d0\u51fa\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u7f3a\u5931\u77e5\u8bc6\u65f6\u8868\u73b0\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u505a\u6cd5\u5b58\u5728\u4e0d\u8db3\u4e4b\u5904\uff0c\u57fa\u51c6\u6d4b\u8bd5\u901a\u5e38\u5305\u62ec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u77e5\u8bc6\u56fe\u4e2d\u73b0\u6709\u4e09\u5143\u7ec4\u56de\u7b54\u7684\u95ee\u9898\uff0c\u4f7f\u5f97\u6a21\u578b\u662f\u5426\u8fdb\u884c\u63a8\u7406\u8fd8\u662f\u76f4\u63a5\u68c0\u7d22\u7b54\u6848\u53d8\u5f97\u4e0d\u660e\u786e\u3002\u6b64\u5916\uff0c\u8bc4\u4f30\u6307\u6807\u4e0d\u4e00\u81f4\u548c\u5bbd\u677e\u7684\u7b54\u6848\u5339\u914d\u6807\u51c6\u8fdb\u4e00\u6b65\u6a21\u7cca\u4e86\u6709\u610f\u4e49\u7684\u6bd4\u8f83\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\u7684\u901a\u7528\u65b9\u6cd5\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u77e5\u8bc6\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u77e5\u8bc6\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u76ee\u524d\u7684\u77e5\u8bc6\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u7f3a\u5931\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u6709\u9650\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e38\u5e38\u4f9d\u8d56\u5185\u90e8\u8bb0\u5fc6\uff0c\u5e76\u4e14\u6839\u636e\u8bbe\u8ba1\u7684\u4e0d\u540c\u5c55\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5f53\u524d\u7684\u77e5\u8bc6\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u77e5\u8bc6\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u5177\u6709\u6709\u9650\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e38\u5e38\u4f9d\u8d56\u5185\u90e8\u8bb0\u5fc6\uff0c\u5e76\u4e14\u6839\u636e\u8bbe\u8ba1\u7684\u4e0d\u540c\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.08382", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08382", "abs": "https://arxiv.org/abs/2508.08382", "authors": ["Timo Bertram"], "title": "UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games", "comment": null, "summary": "Collectible card games (CCGs) are a difficult genre for AI due to their\npartial observability, long-term decision-making, and evolving card sets. Due\nto this, current AI models perform vastly worse than human players at CCG tasks\nsuch as deckbuilding and gameplay. In this work, we introduce UrzaGPT, a\ndomain-adapted large language model that recommends real-time drafting\ndecisions in Magic: The Gathering. Starting from an open-weight LLM, we use\nLow-Rank Adaptation fine-tuning on a dataset of annotated draft logs. With\nthis, we leverage the language modeling capabilities of LLM, and can quickly\nadapt to different expansions of the game. We benchmark UrzaGPT in comparison\nto zero-shot LLMs and the state-of-the-art domain-specific model. Untuned,\nsmall LLMs like Llama-3-8B are completely unable to draft, but the larger\nGPT-4o achieves a zero-shot performance of 43%. Using UrzaGPT to fine-tune\nsmaller models, we achieve an accuracy of 66.2% using only 10,000 steps.\nDespite this not reaching the capability of domain-specific models, we show\nthat solely using LLMs to draft is possible and conclude that using LLMs can\nenable performant, general, and update-friendly drafting AIs in the future.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86UrzaGPT\uff0c\u4f7f\u7528LLM\u5728\u9b54\u672f\u98ce\u4e91\u4e2d\u63a8\u8350\u5b9e\u65f6\u9009\u79c0\u51b3\u7b56\u3002\u7ecf\u8fc7\u5fae\u8c03\uff0cUrzaGPT\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u4ec5\u4f7f\u7528LLMs\u8fdb\u884c\u9009\u79c0\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u5f53\u524dAI\u6a21\u578b\u5728CCG\u4efb\u52a1\uff08\u5982\u5957\u724c\u6784\u5efa\u548c\u6e38\u620f\u73a9\u6cd5\uff09\u4e2d\u8868\u73b0\u8fdc\u8fdc\u4e0d\u53ca\u4eba\u7c7b\u73a9\u5bb6\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u901a\u8fc7\u4f7f\u7528UrzaGPT\u548cLLM\uff0c\u63a2\u8ba8\u4e86\u4ec5\u4f7f\u7528LLMs\u8fdb\u884c\u9009\u79c0\u662f\u5426\u53ef\u884c\u3002", "method": "\u91c7\u7528UrzaGPT\uff0c\u57fa\u4e8e\u5f00\u653e\u6743\u91cd\u7684LLM\uff0c\u5e76\u5229\u7528\u5bf9\u6ce8\u91ca\u9009\u79c0\u8bb0\u5f55\u6570\u636e\u96c6\u8fdb\u884c\u4f4e\u79e9\u9002\u5e94\u5fae\u8c03\u3002\u5bf9UrzaGPT\u4e0e\u96f6-shot LLMs\u4ee5\u53ca\u6700\u5148\u8fdb\u7684\u9886\u57df\u7279\u5b9a\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002\u901a\u8fc7UrzaGPT\u5fae\u8c03\u8f83\u5c0f\u6a21\u578b\uff0c\u5728\u4ec5\u8fdb\u884c\u4e8610,000\u6b65\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e8666.2%\u7684\u51c6\u786e\u7387\u3002", "result": "UrzaGPT\u5728\u5b9e\u65f6\u9009\u79c0\u4e2d\u8868\u73b0\u4f18\u4e8e\u96f6-shot LLMs\u548c\u9886\u57df\u7279\u5b9a\u6a21\u578b\u3002\u5fae\u8c03\u8f83\u5c0f\u6a21\u578b\u540e\uff0c\u51c6\u786e\u7387\u8fbe\u5230\u4e8666.2%\uff0c\u5c55\u793a\u4e86\u4ec5\u4f7f\u7528LLMs\u8fdb\u884c\u9009\u79c0\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u4f7f\u7528UrzaGPT\uff0c\u5728\u9b54\u672f\u98ce\u4e91\u4e2d\u63d0\u4f9b\u5b9e\u65f6\u5361\u724c\u9009\u79c0\u51b3\u7b56\u63a8\u8350\u3002\u901a\u8fc7\u5bf9\u6ce8\u91ca\u7684\u9009\u79c0\u8bb0\u5f55\u6570\u636e\u96c6\u8fdb\u884c\u4f4e\u79e9\u8c03\u6574\u5fae\u8c03\uff0c\u6211\u4eec\u8d85\u8d8a\u4e86\u96f6-shot LLM\u4ee5\u53ca\u6700\u5148\u8fdb\u7684\u9886\u57df\u7279\u5b9a\u6a21\u578b\u3002\u5c3d\u7ba1\u672a\u8c03\u6574\u7684\u8f83\u5c0fLLMs\u65e0\u6cd5\u8fdb\u884c\u9009\u79c0\uff0c\u4f46\u66f4\u5927\u7684GPT-4o\u8fbe\u5230\u4e8643%\u7684\u96f6-shot\u6027\u80fd\u3002\u4f7f\u7528UrzaGPT\u5fae\u8c03\u8f83\u5c0f\u6a21\u578b\uff0c\u4ec5\u8fdb\u884c\u4e8610,000\u6b65\uff0c\u5c31\u5b9e\u73b0\u4e8666.2%\u7684\u51c6\u786e\u7387\u3002\u867d\u7136\u5c1a\u672a\u8fbe\u5230\u9886\u57df\u7279\u5b9a\u6a21\u578b\u7684\u80fd\u529b\uff0c\u4f46\u6211\u4eec\u8868\u660e\u4ec5\u4f7f\u7528LLMs\u8fdb\u884c\u9009\u79c0\u662f\u53ef\u80fd\u7684\uff0c\u5e76\u4e14\u5f97\u51fa\u7ed3\u8bba\u79f0\u4f7f\u7528LLMs\u53ef\u4ee5\u5728\u672a\u6765\u5b9e\u73b0\u6027\u80fd\u826f\u597d\u3001\u901a\u7528\u4e14\u6613\u4e8e\u66f4\u65b0\u7684\u9009\u79c0AI\u3002"}}
{"id": "2508.08385", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.08385", "abs": "https://arxiv.org/abs/2508.08385", "authors": ["Masataro Asai"], "title": "Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning", "comment": null, "summary": "We study an efficient implementation of Multi-Armed Bandit (MAB)-based\nMonte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is\nthat it spends a significant time deciding which node to expand next. While\nselecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity\nwith traditional array-based priority-queues for dense integer keys, the\ntree-based OPEN list used by MCTS requires $O(\\log N)$, which roughly\ncorresponds to the search depth $d$. In classical planning, $d$ is arbitrarily\nlarge (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node\nselection is significant, unlike in game tree search, where the cost is\nnegligible compared to the node evaluation (rollouts) because $d$ is inherently\nlimited by the game (e.g., $d\\leq 361$ in Go). To improve this bottleneck, we\npropose a bilevel modification to MCTS that runs a best-first search from each\nselected leaf node with an expansion budget proportional to $d$, which achieves\namortized $O(1)$ runtime for node selection, equivalent to the traditional\nqueue-based OPEN list. In addition, we introduce Tree Collapsing, an\nenhancement that reduces action selection steps and further improves the\nperformance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u81c2\u8d4c\u535a\u673a\uff08MAB\uff09\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u7684\u7ecf\u5178\u89c4\u5212\u5b9e\u73b0\u65b9\u6cd5\u3002\u901a\u8fc7\u53cc\u5c42\u4fee\u6539MCTS\u548c\u6811\u7684\u6298\u53e0\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u8282\u70b9\u9009\u62e9\u6027\u80fd\u5e76\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u6027\u80fd\u3002", "motivation": "MCTS\u5728\u51b3\u5b9a\u6269\u5c55\u54ea\u4e2a\u8282\u70b9\u65f6\u82b1\u8d39\u4e86\u5927\u91cf\u65f6\u95f4\uff0c\u7279\u522b\u662f\u5728\u7ecf\u5178\u89c4\u5212\u4e2d\uff0c\u8282\u70b9\u641c\u7d22\u6df1\u5ea6\u53ef\u80fd\u975e\u5e38\u5927\uff0c\u5bfc\u81f4\u8282\u70b9\u9009\u62e9\u7684\u8fd0\u884c\u65f6\u95f4\u663e\u8457\u3002\u4e3a\u4e86\u6539\u5584\u8fd9\u4e00\u74f6\u9888\uff0c\u63d0\u51fa\u4e86\u53cc\u5c42\u4fee\u6539MCTS\u7684\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u6811\u7684\u6298\u53e0\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u4fee\u6539MCTS\u7684\u65b9\u6cd5\uff0c\u8fd0\u884c\u4e00\u4e2a\u4ece\u6bcf\u4e2a\u9009\u5b9a\u7684\u53f6\u8282\u70b9\u5f00\u59cb\u7684\u6700\u4f73\u4f18\u5148\u641c\u7d22\uff0c\u4ee5\u6539\u5584\u8282\u70b9\u9009\u62e9\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5e76\u5b9e\u73b0\u644a\u9500O\uff081\uff09\u8fd0\u884c\u65f6\u95f4\u3002\u540c\u65f6\u5f15\u5165\u4e86\u6811\u7684\u6298\u53e0\u65b9\u6cd5\u6765\u51cf\u5c11\u52a8\u4f5c\u9009\u62e9\u6b65\u9aa4\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u53cc\u5c42\u4fee\u6539MCTS\u65b9\u6cd5\u548c\u6811\u7684\u6298\u53e0\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8282\u70b9\u9009\u62e9\u7684\u644a\u9500O\uff081\uff09\u8fd0\u884c\u65f6\u95f4\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u81c2\u8d4c\u535a\u673a\uff08MAB\uff09\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u7684\u7ecf\u5178\u89c4\u5212\u5b9e\u73b0\u65b9\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u53cc\u5c42\u4fee\u6539MCTS\uff0c\u4ece\u6bcf\u4e2a\u9009\u5b9a\u7684\u53f6\u8282\u70b9\u8fd0\u884c\u4e00\u4e2a\u4ece\u672a\u5c55\u5f00\u8282\u70b9\u5f00\u59cb\u7684\u6700\u4f73\u4f18\u5148\u641c\u7d22\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u5bf9\u8282\u70b9\u9009\u62e9\u7684\u644a\u9500O\uff081\uff09\u8fd0\u884c\u65f6\u95f4\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u6811\u7684\u6298\u53e0\uff08Tree Collapsing\uff09\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u52a8\u4f5c\u9009\u62e9\u6b65\u9aa4\u5e76\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.08442", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08442", "abs": "https://arxiv.org/abs/2508.08442", "authors": ["Niklas Dewally", "\u00d6zg\u00fcr Akg\u00fcn"], "title": "Solver-Aided Expansion of Loops to Avoid Generate-and-Test", "comment": "13 pages, 4 figures, published in ModRef 2025 workshop", "summary": "Constraint modelling languages like MiniZinc and Essence rely on unrolling\nloops (in the form of quantified expressions and comprehensions) during\ncompilation. Standard approaches generate all combinations of induction\nvariables and use partial evaluation to discard those that simplify to identity\nelements of associative-commutative operators (e.g. true for conjunction, 0 for\nsummation). This can be inefficient for problems where most combinations are\nultimately irrelevant. We present a method that avoids full enumeration by\nusing a solver to compute only the combinations required to generate the final\nset of constraints. The resulting model is identical to that produced by\nconventional flattening, but compilation can be significantly faster. This\nimproves the efficiency of translating high-level user models into solver-ready\nform, particularly when induction variables range over large domains with\nselective preconditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u6539\u5584\u7ea6\u675f\u5efa\u6a21\u8bed\u8a00\u7684\u7f16\u8bd1\u6548\u7387\uff0c\u907f\u514d\u5b8c\u5168\u679a\u4e3e\u5faa\u73af\uff0c\u901a\u8fc7\u4f7f\u7528\u6c42\u89e3\u5668\u8ba1\u7b97\u4ec5\u751f\u6210\u6700\u7ec8\u7ea6\u675f\u96c6\u6240\u9700\u7ec4\u5408\uff0c\u52a0\u5feb\u7f16\u8bd1\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u7684\u6a21\u578b\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u540c\u3002", "motivation": "\u6807\u51c6\u65b9\u6cd5\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u751f\u6210\u6240\u6709\u5f52\u7eb3\u53d8\u91cf\u7684\u7ec4\u5408\uff0c\u7136\u540e\u5229\u7528\u90e8\u5206\u6c42\u503c\u6765\u4e22\u5f03\u7b80\u5316\u4e3a\u7ed3\u5408-\u4ea4\u6362\u64cd\u4f5c\u7b26\u7684\u5e7a\u5143\uff08\u4f8b\u5982\uff0c\u5e76\u96c6\u4e3a\u771f\uff0c\u6c42\u548c\u4e3a0\uff09\u7684\u7ec4\u5408\uff0c\u4f46\u8fd9\u5728\u5bf9\u4e8e\u5927\u90e8\u5206\u7ec4\u5408\u6700\u7ec8\u4e0d\u76f8\u5173\u7684\u95ee\u9898\u4e0a\u6548\u7387\u8f83\u4f4e\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u9ad8\u5c06\u9ad8\u7ea7\u7528\u6237\u6a21\u578b\u8f6c\u5316\u4e3a\u6c42\u89e3\u5668\u51c6\u5907\u5f62\u5f0f\u7684\u6548\u7387\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u4e00\u79cd\u907f\u514d\u5b8c\u5168\u679a\u4e3e\u5faa\u73af\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u6c42\u89e3\u5668\u8ba1\u7b97\u4ec5\u751f\u6210\u6700\u7ec8\u7ea6\u675f\u96c6\u6240\u9700\u7ec4\u5408\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u7ea6\u675f\u5efa\u6a21\u8bed\u8a00\u7684\u7f16\u8bd1\u6548\u7387\u3002", "result": "\u901a\u8fc7\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u6a21\u578b\u4e0e\u4f20\u7edf\u5c55\u5e73\u65b9\u6cd5\u4ea7\u751f\u7684\u6a21\u578b\u76f8\u540c\uff0c\u4f46\u7f16\u8bd1\u901f\u5ea6\u660e\u663e\u66f4\u5feb\u3002\u7279\u522b\u9002\u7528\u4e8e\u5f52\u7eb3\u53d8\u91cf\u8303\u56f4\u5e7f\u6cdb\u4e14\u5177\u6709\u9009\u62e9\u6027\u524d\u63d0\u6761\u4ef6\u7684\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u6c42\u89e3\u5668\u8ba1\u7b97\u751f\u6210\u6700\u7ec8\u7ea6\u675f\u96c6\u6240\u9700\u7684\u7ec4\u5408\uff0c\u907f\u514d\u4e86\u5b8c\u5168\u679a\u4e3e\u7684\u8fc7\u7a0b\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u7ea6\u675f\u5efa\u6a21\u8bed\u8a00\u7f16\u8bd1\u7684\u6548\u7387\u3002"}}
{"id": "2508.08446", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08446", "abs": "https://arxiv.org/abs/2508.08446", "authors": ["Woojeong Kim", "Junxiong Wang", "Jing Nathan Yan", "Mohamed Abdelfattah", "Alexander M. Rush"], "title": "OverFill: Two-Stage Models for Efficient Language Model Decoding", "comment": "Accepted to COLM 2025", "summary": "Large language models (LLMs) excel across diverse tasks but face significant\ndeployment challenges due to high inference costs. LLM inference comprises\nprefill (compute-bound) and decode (memory-bound) stages, with decode\ndominating latency particularly for long sequences. Current decoder-only models\nhandle both stages uniformly, despite their distinct computational profiles. We\npropose OverFill, which decouples these stages to optimize accuracy-efficiency\ntradeoffs. OverFill begins with a full model for prefill, processing system and\nuser inputs in parallel. It then switches to a dense pruned model, while\ngenerating tokens sequentially. Leveraging more compute during prefill,\nOverFill improves generation quality with minimal latency overhead. Our\n3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, while\nthe 8B-to-3B configuration improves over 3B pruned models by 79.2% on average\nacross standard benchmarks. OverFill matches the performance of same-sized\nmodels trained from scratch, while using significantly less training data. Our\ncode is available at https://github.com/friendshipkim/overfill.", "AI": {"tldr": "OverFill proposes a model that separates prefill and decode stages in LLM inference, improving accuracy and efficiency tradeoffs. It outperforms pruned models in generation quality and performance and matches same-sized models trained from scratch while using less training data.", "motivation": "LLMs face deployment challenges due to high inference costs, particularly in the decode stage for long sequences. Current decoder-only models treat prefill and decode stages uniformly, despite their distinct computational profiles.", "method": "The proposed OverFill model starts with a full model for prefill, processes system and user inputs in parallel, and then switches to a dense pruned model for generating tokens sequentially. It leverages more compute during prefill to improve generation quality with minimal latency overhead.", "result": "The 3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, and the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average across standard benchmarks. OverFill matches the performance of same-sized models trained from scratch while using significantly less training data.", "conclusion": "OverFill decouples the prefill and decode stages in LLM inference, optimizing accuracy and efficiency tradeoffs. It significantly outperforms pruned models in terms of generation quality and performance across benchmarks."}}
{"id": "2508.08477", "categories": ["cs.AI", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.08477", "abs": "https://arxiv.org/abs/2508.08477", "authors": ["Joan Salv\u00e0 Soler", "Gr\u00e9goire de Lambertye"], "title": "A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search", "comment": "9 pages, 2 figures, 2-column format", "summary": "The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP\nby introducing dynamic arc costs that change when specific \\textit{trigger}\narcs are traversed, modeling scenarios such as warehouse operations with\ncompactable storage systems. This paper introduces a GRASP-based metaheuristic\nthat combines multiple construction heuristics with a multi-neighborhood local\nsearch. The construction phase uses mixed-integer programming (MIP) techniques\nto transform the TA-TSP into a sequence of tailored TSP instances, while the\nimprovement phase applies 2-Opt, Swap, and Relocate operators. Computational\nexperiments on MESS 2024 competition instances achieved average optimality gaps\nof 0.77\\% and 0.40\\% relative to the best-known solutions within a 60-second\nlimit. On smaller, synthetically generated datasets, the method produced\nsolutions 11.3\\% better than the Gurobi solver under the same time constraints.\nThe algorithm finished in the top three at MESS 2024, demonstrating its\nsuitability for real-time routing applications with state-dependent travel\ncosts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u89e3\u51b3\u89e6\u53d1\u5f27\u65c5\u884c\u5546\u95ee\u9898(TA-TSP)\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8eGRASP\u5143\u542f\u53d1\u5f0f\u7684\u7b97\u6cd5\u548c\u591a\u79cd\u542f\u53d1\u5f0f\u7b97\u6cd5\u7ec4\u5408\u3002\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4e0d\u9519\u7684\u7ed3\u679c\uff0c\u5728MESS 2024\u6bd4\u8d5b\u4e2d\u540d\u5217\u524d\u8305\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u8def\u7531\u5e94\u7528\u4e2d\u7684\u72b6\u6001\u76f8\u5173\u65c5\u884c\u6210\u672c\u3002", "motivation": "\u8be5\u8bba\u6587\u63d0\u51faTA-TSP\u89e3\u51b3\u65b9\u6848\u7684\u52a8\u673a\u662f\u4e3a\u4e86\u6a21\u62df\u4ed3\u5e93\u64cd\u4f5c\u4e2d\u7684\u53ef\u538b\u7f29\u5b58\u50a8\u7cfb\u7edf\u7b49\u573a\u666f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5177\u6709\u72b6\u6001\u76f8\u5173\u65c5\u884c\u6210\u672c\u7684\u5b9e\u65f6\u8def\u7531\u5e94\u7528\u7684\u89e3\u51b3\u65b9\u6cd5\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8eGRASP\u5143\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u4e2a\u6784\u9020\u542f\u53d1\u5f0f\u7b97\u6cd5\u548c\u591a\u90bb\u57df\u5c40\u90e8\u641c\u7d22\u6765\u89e3\u51b3TA-TSP\u95ee\u9898\u3002\u6784\u9020\u9636\u6bb5\u4f7f\u7528\u6df7\u5408\u6574\u6570\u89c4\u5212(MIP)\u6280\u672f\u5c06TA-TSP\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u5b9a\u5236\u7684TSP\u5b9e\u4f8b\uff0c\u6539\u8fdb\u9636\u6bb5\u91c7\u75282-Opt\u3001Swap\u548cRelocate\u64cd\u4f5c\u7b26\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728MESS 2024\u6bd4\u8d5b\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u4f18\u5316\u95f4\u9699\u4e3a0.77%\u548c0.40%\uff0c\u5e76\u572860\u79d2\u5185\u4e0e\u5df2\u77e5\u6700\u4f73\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\u53d6\u5f97\u4e86\u4e0d\u9519\u7684\u7ed3\u679c\u3002\u5728\u8f83\u5c0f\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u540c\u65f6\u95f4\u9650\u5236\u4e0b\u6bd4Gurobi\u6c42\u89e3\u5668\u7684\u89e3\u51b3\u65b9\u6848\u597d\u4e8611.3%\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eGRASP\u5143\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u89e6\u53d1\u5f27\u65c5\u884c\u5546\u95ee\u9898(TA-TSP)\uff0c\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4e0d\u9519\u7684\u4f18\u5316\u7ed3\u679c\uff0c\u5e76\u5728MESS 2024\u6bd4\u8d5b\u4e2d\u53d6\u5f97\u4e86\u524d\u4e09\u540d\u7684\u6210\u7ee9\uff0c\u5c55\u793a\u4e86\u8be5\u7b97\u6cd5\u5728\u5b9e\u65f6\u8def\u7531\u5e94\u7528\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2508.08486", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08486", "abs": "https://arxiv.org/abs/2508.08486", "authors": ["Parker Whitfill", "Stewy Slocum"], "title": "Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback", "comment": null, "summary": "Alignment techniques for LLMs rely on optimizing preference-based objectives\n-- where these preferences are typically elicited as ordinal, binary choices\nbetween responses. Recent work has focused on improving label quality or\nmitigating particular biases, but we identify a more fundamental limitation:\nthese methods collect the wrong kind of data. We prove an impossibility result:\nno algorithm relying solely on ordinal comparisons can systematically recover\nthe most preferred model. Intuitively, ordinal data lacks the information\nneeded to resolve tradeoffs -- e.g., fixing a factual error on one prompt\nversus improving style on another. We show that selecting the optimal model\nrequires recovering preferences over \\emph{models} (rather than just\nresponses), which can only be identified given cardinal feedback about response\nquality. To address this, we collect and publicly release a dataset of 25,000\ncardinal judgments using willingness-to-pay elicitations, a well-established\ntool from experimental economics. Empirically, we find that incorporating\ncardinal feedback into preference fine-tuning allows models to prioritize\nhigh-impact improvements and outperform ordinal-only methods on downstream\nbenchmarks, such as Arena-Hard.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86LLMs\u7684\u5bf9\u9f50\u6280\u672f\uff0c\u6307\u51fa\u4e86\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u5e8f\u6570\u6bd4\u8f83\u65e0\u6cd5\u6709\u6548\u6062\u590d\u9996\u9009\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u5f15\u5165\u5bf9\u54cd\u5e94\u8d28\u91cf\u7684\u57fa\u6570\u53cd\u9988\u6765\u6536\u96c6\u6570\u636e\u7684\u65b9\u6cd5\u3002\u4f5c\u8005\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u4ec5\u4f7f\u7528\u5e8f\u6570\u6bd4\u8f83\u7684\u65b9\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u6700\u8fd1\u7684\u5de5\u4f5c\u96c6\u4e2d\u5728\u6539\u5584\u6807\u7b7e\u8d28\u91cf\u6216\u51cf\u8f7b\u7279\u5b9a\u504f\u89c1\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u5b58\u5728\u66f4\u6839\u672c\u7684\u9650\u5236\uff1a\u8fd9\u4e9b\u65b9\u6cd5\u6536\u96c6\u4e86\u9519\u8bef\u7c7b\u578b\u7684\u6570\u636e\u3002\u4f5c\u8005\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u57fa\u4e8e\u5bf9\u54cd\u5e94\u8d28\u91cf\u7684\u57fa\u6570\u53cd\u9988\u7684\u65b9\u6cd5\uff0c\u4ee5\u4f18\u5316\u6a21\u578b\u9009\u62e9\u8fc7\u7a0b\u3002", "method": "\u4f5c\u8005\u8bc1\u660e\u4e86\u4ec5\u4f9d\u8d56\u4e8e\u5e8f\u6570\u6bd4\u8f83\u65e0\u6cd5\u7cfb\u7edf\u5730\u6062\u590d\u9996\u9009\u6a21\u578b\u8fd9\u4e00\u4e0d\u53ef\u80fd\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u54cd\u5e94\u8d28\u91cf\u7684\u57fa\u6570\u53cd\u9988\u7684\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u6536\u96c6\u5e76\u516c\u5f00\u53d1\u5e03\u4e86\u4e00\u4e2a\u613f\u610f\u652f\u4ed8\u8c03\u67e5\u6570\u636e\u96c6\uff0c\u91c7\u7528\u5b9e\u9a8c\u7ecf\u6d4e\u5b66\u4e2d\u5e7f\u6cdb\u5e94\u7528\u7684\u5de5\u5177\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u8fd8\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u5c06\u57fa\u6570\u53cd\u9988\u7eb3\u5165\u504f\u597d\u5fae\u8c03\u80fd\u591f\u4f7f\u6a21\u578b\u5728\u4e0b\u6e38\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86\u4f9d\u8d56\u4e8e\u5e8f\u6570\u6bd4\u8f83\u65e0\u6cd5\u6062\u590d\u9996\u9009\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u57fa\u6570\u53cd\u9988\u7684\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u3002\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\uff0c\u4f5c\u8005\u53d1\u73b0\u5f15\u5165\u57fa\u6570\u53cd\u9988\u53ef\u4ee5\u6539\u5584\u6a21\u578b\u5728\u4e0b\u6e38\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u52a9\u624b\u7684 QED \u8bc4\u4f30\u65b9\u6cd5\uff0c\u6587\u7ae0\u63ed\u793a\u4e86\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u5e8f\u6570\u6bd4\u8f83\u7684\u7b97\u6cd5\u65e0\u6cd5\u7cfb\u7edf\u5730\u6062\u590d\u9996\u9009\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u6536\u96c6\u4e86\u9519\u8bef\u7c7b\u578b\u7684\u6570\u636e\u3002\u7814\u7a76\u8868\u660e\uff0c\u9009\u62e9\u6700\u4f73\u6a21\u578b\u9700\u8981\u6839\u636e\u54cd\u5e94\u8d28\u91cf\u7684\u57fa\u6570\u53cd\u9988\u6765\u6062\u590d\u5bf9\u6a21\u578b\u7684\u504f\u597d\u3002\u4f5c\u8005\u901a\u8fc7\u6536\u96c6 25,000 \u4e2a\u613f\u610f\u652f\u4ed8\u8bc4\u4f30\u7684\u57fa\u6570\u5224\u65ad\u6570\u636e\u96c6\uff0c\u5b9e\u8bc1\u8868\u660e\u5c06\u57fa\u6570\u53cd\u9988\u7eb3\u5165\u504f\u597d\u5fae\u8c03\u80fd\u591f\u4f7f\u6a21\u578b\u4f18\u5148\u8003\u8651\u9ad8\u5f71\u54cd\u6539\u8fdb\uff0c\u5e76\u5728\u4e0b\u6e38\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u80dc\u8fc7\u4ec5\u4f7f\u7528\u5e8f\u6570\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.08493", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08493", "abs": "https://arxiv.org/abs/2508.08493", "authors": ["Szymon Jakubicz", "Karol Ku\u017aniak", "Jan Wawszczak", "Pawe\u0142 Gora"], "title": "POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem", "comment": null, "summary": "In recent years, reinforcement learning (RL) methods have emerged as a\npromising approach for solving combinatorial problems. Among RL-based models,\nPOMO has demonstrated strong performance on a variety of tasks, including\nvariants of the Vehicle Routing Problem (VRP). However, there is room for\nimprovement for these tasks. In this work, we improved POMO, creating a method\n(\\textbf{POMO+}) that leverages the initial nodes to find a solution in a more\ninformed way. We ran experiments on our new model and observed that our\nsolution converges faster and achieves better results. We validated our models\non the CVRPLIB dataset and noticed improvements in problem instances with up to\n100 customers. We hope that our research in this project can lead to further\nadvancements in the field.", "AI": {"tldr": "\u6700\u8fd1\uff0c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u89e3\u51b3\u7ec4\u5408\u6027\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\u3002\u672c\u6587\u6539\u8fdb\u4e86 POMO \u6a21\u578b\uff0c\u521b\u5efa\u4e86 POMO+ \u65b9\u6cd5\uff0c\u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u89e3\u51b3\u4e2d\u53d6\u5f97\u66f4\u597d\u7ed3\u679c\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728 CVRPLIB \u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u6539\u8fdb\uff0c\u5c55\u671b\u672a\u6765\u7814\u7a76\u5e26\u6765\u66f4\u591a\u8fdb\u5c55\u3002", "motivation": "\u6700\u8fd1\uff0c\u5f3a\u5316\u5b66\u4e60 (RL) \u65b9\u6cd5\u5728\u89e3\u51b3\u7ec4\u5408\u6027\u95ee\u9898\u65b9\u9762\u663e\u793a\u51fa\u4e86\u6f5c\u529b\u3002POMO \u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u6211\u4eec\u6539\u8fdb\u4e86 POMO \u6a21\u578b\uff0c\u521b\u5efa\u4e86 POMO+ \u65b9\u6cd5\uff0c\u5229\u7528\u521d\u59cb\u8282\u70b9\u66f4\u660e\u667a\u5730\u627e\u5230\u89e3\u51b3\u65b9\u6848\u3002\u5728\u65b0\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u89c2\u5bdf\u5230\u6211\u4eec\u7684\u89e3\u51b3\u65b9\u6848\u6536\u655b\u66f4\u5feb\uff0c\u5e76\u53d6\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u3002", "result": "\u6211\u4eec\u89c2\u5bdf\u5230\u65b0\u65b9\u6cd5 POMO+ \u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u89e3\u51b3\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u5b9e\u9a8c\u663e\u793a\u6536\u655b\u901f\u5ea6\u66f4\u5feb\u3002\u5728 CVRPLIB \u6570\u636e\u96c6\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0c\u5728\u6700\u591a 100 \u4e2a\u5ba2\u6237\u7684\u95ee\u9898\u5b9e\u4f8b\u4e2d\u6709\u6240\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u672c\u9879\u76ee\uff0c\u6211\u4eec\u6539\u8fdb\u4e86 POMO \u6a21\u578b\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a POMO+ \u7684\u65b9\u6cd5\uff0c\u5728\u89e3\u51b3\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u65b9\u9762\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u7ed3\u679c\u3002\u6211\u4eec\u7684\u7814\u7a76\u5728 CVRPLIB \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5728\u6700\u591a 100 \u4e2a\u5ba2\u6237\u7684\u95ee\u9898\u5b9e\u4f8b\u4e2d\u5b9e\u73b0\u4e86\u6539\u8fdb\u3002\u6211\u4eec\u5e0c\u671b\u8fd9\u9879\u7814\u7a76\u80fd\u5728\u8be5\u9886\u57df\u5e26\u6765\u8fdb\u4e00\u6b65\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.08500", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08500", "abs": "https://arxiv.org/abs/2508.08500", "authors": ["Sviatoslav Lushnei", "Dmytro Shumskyi", "Severyn Shykula", "Ernesto Jimenez-Ruiz", "Artur d'Avila Garcez"], "title": "Large Language Models as Oracles for Ontology Alignment", "comment": "Submitted to a conference. 17 pages", "summary": "Ontology alignment plays a crucial role in integrating diverse data sources\nacross domains. There is a large plethora of systems that tackle the ontology\nalignment problem, yet challenges persist in producing highly quality\ncorrespondences among a set of input ontologies. Human-in-the-loop during the\nalignment process is essential in applications requiring very accurate\nmappings. User involvement is, however, expensive when dealing with large\nontologies. In this paper, we explore the feasibility of using Large Language\nModels (LLM) as an alternative to the domain expert. The use of the LLM focuses\nonly on the validation of the subset of correspondences where an ontology\nalignment system is very uncertain. We have conducted an extensive evaluation\nover several matching tasks of the Ontology Alignment Evaluation Initiative\n(OAEI), analysing the performance of several state-of-the-art LLMs using\ndifferent ontology-driven prompt templates. The LLM results are also compared\nagainst simulated Oracles with variable error rates.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u672c\u4f53\u5bf9\u9f50\u4e2d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u66ff\u9886\u57df\u4e13\u5bb6\u7684\u53ef\u884c\u6027\u3002\u7ed3\u679c\u8868\u660eLLM\u5728\u9a8c\u8bc1\u4e0d\u786e\u5b9a\u6027\u8f83\u9ad8\u7684\u672c\u4f53\u5bf9\u9f50\u65b9\u9762\u5177\u6709\u6f5c\u5728\u4f18\u52bf\u3002\u901a\u8fc7\u5bf9OAEI\u7684\u591a\u4e2a\u5339\u914d\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff0c\u5206\u6790\u4e86\u4e0d\u540cLLM\u7684\u6027\u80fd\uff0c\u5e76\u4e0e\u6a21\u62dfOracle\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5728\u672c\u4f53\u5bf9\u9f50\u4e2d\u4f7f\u7528LLM\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u51cf\u5c11\u5bf9\u5927\u578b\u672c\u4f53\u8fdb\u884c\u5bf9\u9f50\u65f6\u4eba\u5de5\u53c2\u4e0e\u9020\u6210\u7684\u6602\u8d35\u6210\u672c\u3002\u4f5c\u8005\u8ba4\u4e3a\u4f7f\u7528LLM\u53ea\u5728\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u8f83\u9ad8\u7684\u76f8\u4e92\u5bf9\u5e94\u5b50\u96c6\u9a8c\u8bc1\u9636\u6bb5\uff0c\u53ef\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u964d\u4f4e\u6210\u672c\u3002", "method": "\u4f5c\u8005\u5728\u7814\u7a76\u4e2d\u4f7f\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u9886\u57df\u4e13\u5bb6\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u91cd\u70b9\u9a8c\u8bc1\u5728\u672c\u4f53\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u7cfb\u7edf\u4e0d\u786e\u5b9a\u7684\u76f8\u4e92\u5bf9\u5e94\u5b50\u96c6\u3002\u4f5c\u8005\u5bf9Ontology Alignment Evaluation Initiative\uff08OAEI\uff09\u7684\u591a\u4e2a\u5339\u914d\u4efb\u52a1\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5206\u6790\u4e86\u51e0\u79cd\u6700\u5148\u8fdb\u7684LLM\u7684\u6027\u80fd\uff0c\u5e76\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u672c\u4f53\u9a71\u52a8\u63d0\u793a\u6a21\u677f\u3002\u540c\u65f6\uff0c\u8fd8\u901a\u8fc7\u4e0e\u5177\u6709\u53ef\u53d8\u9519\u8bef\u7387\u7684\u6a21\u62dfOracle\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc4\u4f30\u4e86LLM\u7684\u6548\u679c\u3002", "result": "\u901a\u8fc7\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9a8c\u8bc1\u672c\u4f53\u5bf9\u9f50\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u8f83\u9ad8\u7684\u76f8\u4e92\u5bf9\u5e94\u5b50\u96c6\u65b9\u9762\u5177\u6709\u6f5c\u5728\u4f18\u52bf\u3002\u4f5c\u8005\u901a\u8fc7\u5bf9OAEI\u7684\u591a\u4e2a\u5339\u914d\u4efb\u52a1\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5206\u6790\u4e86\u51e0\u79cd\u6700\u5148\u8fdb\u7684LLM\u7684\u6027\u80fd\uff0c\u5e76\u4e0e\u5177\u6709\u53ef\u53d8\u9519\u8bef\u7387\u7684\u6a21\u62dfOracle\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u672c\u4f53\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u9886\u57df\u4e13\u5bb6\u7684\u66ff\u4ee3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3002\u7814\u7a76\u8868\u660e\uff0cLLM\u5728\u9a8c\u8bc1\u672c\u4f53\u5bf9\u9f50\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u8f83\u9ad8\u7684\u76f8\u4e92\u5bf9\u5e94\u5b50\u96c6\u65b9\u9762\u5177\u6709\u6f5c\u5728\u4f18\u52bf\u3002\u901a\u8fc7\u5bf9\u672c\u4f53\u5bf9\u9f50\u8bc4\u4f30\u5021\u8bae\uff08OAEI\uff09\u7684\u591a\u4e2a\u5339\u914d\u4efb\u52a1\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u672c\u6587\u5206\u6790\u4e86\u51e0\u79cd\u6700\u5148\u8fdb\u7684LLM\u7684\u6027\u80fd\uff0c\u5e76\u4f7f\u7528\u4e0d\u540c\u672c\u4f53\u9a71\u52a8\u7684\u63d0\u793a\u6a21\u677f\u3002\u540c\u65f6\uff0cLLM\u7ed3\u679c\u8fd8\u4e0e\u5177\u6709\u53ef\u53d8\u9519\u8bef\u7387\u7684\u6a21\u62dfOracle\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002"}}
{"id": "2508.08501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08501", "abs": "https://arxiv.org/abs/2508.08501", "authors": ["Yuchen Li", "Cong Lin", "Muhammad Umair Nasir", "Philip Bontrager", "Jialin Liu", "Julian Togelius"], "title": "GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games", "comment": null, "summary": "We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning\nand problem-solving capabilities of large language models (LLMs). Built on the\nGeneral Video Game AI framework, it features a diverse collection of\narcade-style games designed to test a model's ability to handle tasks that\ndiffer from most existing LLM benchmarks. The benchmark leverages a game\ndescription language that enables rapid creation of new games and levels,\nhelping to prevent overfitting over time. Each game scene is represented by a\ncompact set of ASCII characters, allowing for efficient processing by language\nmodels. GVGAI-LLM defines interpretable metrics, including the meaningful step\nratio, step efficiency, and overall score, to assess model behavior. Through\nzero-shot evaluations across a broad set of games and levels with diverse\nchallenges and skill depth, we reveal persistent limitations of LLMs in spatial\nreasoning and basic planning. Current models consistently exhibit spatial and\nlogical errors, motivating structured prompting and spatial grounding\ntechniques. While these interventions lead to partial improvements, the\nbenchmark remains very far from solved. GVGAI-LLM provides a reproducible\ntestbed for advancing research on language model capabilities, with a\nparticular emphasis on agentic behavior and contextual reasoning.", "AI": {"tldr": "GVGAI-LLM is a video game benchmark that exposes limitations of LLMs in spatial reasoning and basic planning. It offers a diverse collection of arcade-style games with interpretable metrics to assess model behavior. Current models demonstrate spatial and logical errors, prompting the need for structured prompting and spatial grounding techniques. Despite some improvements, the benchmark remains unsolved, providing a testbed for advancing research on language model capabilities.", "motivation": "The motivation behind GVGAI-LLM is to provide a benchmark that challenges LLMs in handling tasks different from existing benchmarks. Current models show consistent spatial and logical errors, highlighting the need for structured prompting and spatial grounding techniques to improve performance.", "method": "The benchmark is built on the General Video Game AI framework and includes a diverse collection of arcade-style games. It leverages a game description language for rapid creation of new games and levels, preventing overfitting over time. Each game scene is represented in ASCII characters for efficient processing by language models. Interpretable metrics like the meaningful step ratio, step efficiency, and overall score are defined to assess model behavior.", "result": "Zero-shot evaluations across a broad set of games and levels with diverse challenges indicate persistent limitations of LLMs in spatial reasoning and basic planning. Interventions such as structured prompting and spatial grounding techniques lead to partial improvements but the benchmark remains unsolved. GVGAI-LLM serves as a reproducible testbed for advancing research on language model capabilities, especially in agentic behavior and contextual reasoning.", "conclusion": "GVGAI-LLM is introduced as a video game benchmark to evaluate the reasoning and problem-solving capabilities of large language models (LLMs). The benchmark reveals persistent limitations of LLMs in spatial reasoning and basic planning, motivating further research on structured prompting and spatial grounding techniques."}}
{"id": "2508.08529", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08529", "abs": "https://arxiv.org/abs/2508.08529", "authors": ["Arshia Ilaty", "Hossein Shirazi", "Hajar Homayouni"], "title": "SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering", "comment": "10 Pages, 2 Supplementary Pages, 6 Tables", "summary": "Access to real-world medical data is often restricted due to privacy\nregulations, posing a significant barrier to the advancement of healthcare\nresearch. Synthetic data offers a promising alternative; however, generating\nrealistic, clinically valid, and privacy-conscious records remains a major\nchallenge. Recent advancements in Large Language Models (LLMs) offer new\nopportunities for structured data generation; however, existing approaches\nfrequently lack systematic prompting strategies and comprehensive,\nmulti-dimensional evaluation frameworks.\n  In this paper, we present SynLLM, a modular framework for generating\nhigh-quality synthetic medical tabular data using 20 state-of-the-art\nopen-source LLMs, including LLaMA, Mistral, and GPT variants, guided by\nstructured prompts. We propose four distinct prompt types, ranging from\nexample-driven to rule-based constraints, that encode schema, metadata, and\ndomain knowledge to control generation without model fine-tuning. Our framework\nfeatures a comprehensive evaluation pipeline that rigorously assesses generated\ndata across statistical fidelity, clinical consistency, and privacy\npreservation.\n  We evaluate SynLLM across three public medical datasets, including Diabetes,\nCirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt\nengineering significantly impacts data quality and privacy risk, with\nrule-based prompts achieving the best privacy-quality balance. SynLLM\nestablishes that, when guided by well-designed prompts and evaluated with\nrobust, multi-metric criteria, LLMs can generate synthetic medical data that is\nboth clinically plausible and privacy-aware, paving the way for safer and more\neffective data sharing in healthcare research.", "AI": {"tldr": "The paper introduces SynLLM, a framework using 20 LLMs to generate synthetic medical tabular data with structured prompts. Evaluation across three datasets shows the impact of prompt engineering on data quality and privacy. Rule-based prompts achieve the best balance. LLMs, when guided by well-designed prompts, can generate clinically plausible and privacy-aware synthetic data for safer healthcare research.", "motivation": "Access to real-world medical data is restricted due to privacy regulations, hindering healthcare research. Synthetic data is a promising alternative, but realistic and privacy-conscious data generation is challenging. Existing approaches lack systematic prompting strategies and comprehensive evaluation frameworks.", "method": "The paper presents SynLLM, a modular framework utilizing 20 state-of-the-art open-source LLMs to generate synthetic medical tabular data. It proposes four prompt types to control data generation without fine-tuning and features a rigorous evaluation pipeline assessing data quality across statistical fidelity, clinical consistency, and privacy preservation.", "result": "The evaluation of SynLLM across three public medical datasets (Diabetes, Cirrhosis, and Stroke) using 20 LLMs shows that prompt engineering significantly impacts data quality and privacy risk. Rule-based prompts achieve the best privacy-quality balance, demonstrating that LLMs guided by well-designed prompts can generate clinically plausible and privacy-aware synthetic medical data.", "conclusion": "LLMs can generate high-quality synthetic medical tabular data when guided by structured prompts and evaluated with comprehensive evaluation frameworks, contributing to safer and more effective data sharing in healthcare research."}}
{"id": "2508.08615", "categories": ["cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2508.08615", "abs": "https://arxiv.org/abs/2508.08615", "authors": ["Zhichao Wang", "Xinhai Chen", "Qinglin Wang", "Xiang Gao", "Qingyang Zhang", "Menghan Jia", "Xiang Zhang", "Jie Liu"], "title": "UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss", "comment": null, "summary": "Partial differential equations (PDEs) form the mathematical foundation for\nmodeling physical systems in science and engineering, where numerical solutions\ndemand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address\nthis challenge by dynamically relocating mesh nodes to rapidly-varying regions,\nenhancing both simulation accuracy and computational efficiency. However,\ntraditional approaches suffer from high computational complexity and geometric\ninflexibility, limiting their applicability, and existing supervised\nlearning-based approaches face challenges in zero-shot generalization across\ndiverse PDEs and mesh topologies.In this paper, we present an Unsupervised and\nGeneralizable Mesh Movement Network (UGM2N). We first introduce unsupervised\nmesh adaptation through localized geometric feature learning, eliminating the\ndependency on pre-adapted meshes. We then develop a physics-constrained loss\nfunction, M-Uniform loss, that enforces mesh equidistribution at the nodal\nlevel.Experimental results demonstrate that the proposed network exhibits\nequation-agnostic generalization and geometric independence in efficient mesh\nadaptation. It demonstrates consistent superiority over existing methods,\nincluding robust performance across diverse PDEs and mesh geometries,\nscalability to multi-scale resolutions and guaranteed error reduction without\nmesh tangling.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u548c\u53ef\u6cdb\u5316\u7684\u7f51\u683c\u79fb\u52a8\u7f51\u7edcUGM2N\uff0c\u901a\u8fc7\u5c40\u90e8\u51e0\u4f55\u7279\u5f81\u5b66\u4e60\u5b9e\u73b0\u65e0\u76d1\u7763\u7f51\u683c\u9002\u5e94\uff0c\u5f15\u5165\u7269\u7406\u7ea6\u675f\u635f\u5931\u51fd\u6570M-Uniform loss\u5b9e\u73b0\u7f51\u683c\u7b49\u8ddd\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u4e00\u81f4\u7684\u5353\u8d8a\u6027\u80fd\uff0c\u5305\u62ec\u5728\u4e0d\u540cPDEs\u548c\u7f51\u683c\u51e0\u4f55\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u8868\u73b0\uff0c\u80fd\u591f\u6269\u5c55\u5230\u591a\u5c3a\u5ea6\u5206\u8fa8\u7387\u4e14\u65e0\u9700\u62c5\u5fc3\u7f51\u683c\u7f20\u7ed3\u95ee\u9898\uff0c\u5e76\u4fdd\u8bc1\u9519\u8bef\u7684\u51cf\u5c11\u3002", "motivation": "\u4f20\u7edf\u7684\u7f51\u683c\u79fb\u52a8\u6280\u672f\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u6027\u9ad8\u548c\u51e0\u4f55\u4e0d\u7075\u6d3b\u6027\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u8de8\u4e0d\u540cPDEs\u548c\u7f51\u683c\u62d3\u6251\u7684\u96f6\u6837\u672c\u6cdb\u5316\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c40\u90e8\u51e0\u4f55\u7279\u5f81\u5b66\u4e60\u5b9e\u73b0\u65e0\u76d1\u7763\u7f51\u683c\u9002\u5e94\uff0c\u5f15\u5165\u7269\u7406\u7ea6\u675f\u635f\u5931\u51fd\u6570M-Uniform loss\u5b9e\u73b0\u7f51\u683c\u7b49\u8ddd\u5206\u5e03\uff0c\u5e76\u6784\u5efa\u4e86\u65e0\u76d1\u7763\u548c\u53ef\u6cdb\u5316\u7684\u7f51\u683c\u79fb\u52a8\u7f51\u7edcUGM2N\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u63d0\u51fa\u7684\u7f51\u7edc\u5728\u9ad8\u6548\u7f51\u683c\u9002\u5e94\u65b9\u9762\u8868\u73b0\u51fa\u65b9\u7a0b\u4e0d\u53ef\u77e5\u7684\u6cdb\u5316\u80fd\u529b\u548c\u51e0\u4f55\u72ec\u7acb\u6027\uff0c\u5177\u6709\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5305\u62ec\u5728\u4e0d\u540cPDEs\u548c\u7f51\u683c\u51e0\u4f55\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u8868\u73b0\uff0c\u5e76\u4e14\u80fd\u591f\u6269\u5c55\u5230\u591a\u5c3a\u5ea6\u5206\u8fa8\u7387\uff0c\u4fdd\u8bc1\u51cf\u5c11\u9519\u8bef\u4e14\u65e0\u9700\u62c5\u5fc3\u7f51\u683c\u7f20\u7ed3\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u548c\u53ef\u6cdb\u5316\u7684\u7f51\u683c\u79fb\u52a8\u7f51\u7edc\uff08UGM2N\uff09\uff0c\u901a\u8fc7\u5c40\u90e8\u51e0\u4f55\u7279\u5f81\u5b66\u4e60\u5b9e\u73b0\u65e0\u76d1\u7763\u7f51\u683c\u9002\u5e94\uff0c\u5f15\u5165\u4e00\u79cd\u7269\u7406\u7ea6\u675f\u635f\u5931\u51fd\u6570\uff08M-Uniform loss\uff09\u5f3a\u5236\u5728\u8282\u70b9\u7ea7\u522b\u5b9e\u73b0\u7f51\u683c\u7b49\u8ddd\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u4e00\u81f4\u7684\u5353\u8d8a\u6027\u80fd\uff0c\u5305\u62ec\u5728\u4e0d\u540cPDEs\u548c\u7f51\u683c\u51e0\u4f55\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u8868\u73b0\uff0c\u80fd\u591f\u6269\u5c55\u5230\u591a\u5c3a\u5ea6\u5206\u8fa8\u7387\u4e14\u65e0\u9700\u62c5\u5fc3\u7f51\u683c\u7f20\u7ed3\u95ee\u9898\uff0c\u5e76\u4fdd\u8bc1\u9519\u8bef\u7684\u51cf\u5c11\u3002"}}
{"id": "2508.08632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08632", "abs": "https://arxiv.org/abs/2508.08632", "authors": ["Bo Yang", "Yu Zhang", "Lanfei Feng", "Yunkui Chen", "Jianyu Zhang", "Xiao Xu", "Nueraili Aierken", "Yurui Li", "Yuxuan Chen", "Guijun Yang", "Yong He", "Runhe Huang", "Shijian Li"], "title": "AgriGPT: a Large Language Model Ecosystem for Agriculture", "comment": null, "summary": "Despite the rapid progress of Large Language Models (LLMs), their application\nin agriculture remains limited due to the lack of domain-specific models,\ncurated datasets, and robust evaluation frameworks. To address these\nchallenges, we propose AgriGPT, a domain-specialized LLM ecosystem for\nagricultural usage. At its core, we design a multi-agent scalable data engine\nthat systematically compiles credible data sources into Agri-342K, a\nhigh-quality, standardized question-answer (QA) dataset. Trained on this\ndataset, AgriGPT supports a broad range of agricultural stakeholders, from\npractitioners to policy-makers. To enhance factual grounding, we employ\nTri-RAG, a three-channel Retrieval-Augmented Generation framework combining\ndense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning,\nthereby improving the LLM's reasoning reliability. For comprehensive\nevaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks\nwith varying types and complexities. Experiments demonstrate that AgriGPT\nsignificantly outperforms general-purpose LLMs on both domain adaptation and\nreasoning. Beyond the model itself, AgriGPT represents a modular and extensible\nLLM ecosystem for agriculture, comprising structured data construction,\nretrieval-enhanced generation, and domain-specific evaluation. This work\nprovides a generalizable framework for developing scientific and\nindustry-specialized LLMs. All models, datasets, and code will be released to\nempower agricultural communities, especially in underserved regions, and to\npromote open, impactful research.", "AI": {"tldr": "AgriGPT is a specialized LLM ecosystem for agriculture, offering a high-quality QA dataset (Agri-342K) and utilizing Tri-RAG framework for reliable reasoning. It introduces AgriBench-13K for evaluation and outperforms general-purpose LLMs in domain adaptation and reasoning tasks. The framework is modular, extensible, and aims to empower agricultural communities.", "motivation": "The motivation is to overcome the limitations of applying Large Language Models in agriculture by creating a domain-specialized ecosystem. The paper aims to provide structured data, reliable reasoning, and evaluation frameworks tailored for agricultural stakeholders, practitioners, and policy-makers.", "method": "The paper proposes AgriGPT, which includes Agri-342K, a high-quality QA dataset compiled from credible data sources. It utilizes Tri-RAG framework for factual grounding, combining dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning. The paper also introduces AgriBench-13K, a benchmark suite for comprehensive evaluation of AgriGPT.", "result": "Experiments show that AgriGPT outperforms general-purpose LLMs in domain adaptation and reasoning tasks. The framework is modular, extensible, and aims to empower agricultural communities by releasing models, datasets, and code for open research.", "conclusion": "AgriGPT is a domain-specialized LLM ecosystem designed for agricultural usage, addressing the lack of domain-specific models, datasets, and evaluation frameworks in agriculture. It outperforms general-purpose LLMs in domain adaptation and reasoning, offering benefits to agricultural stakeholders and underserved regions."}}
{"id": "2508.08633", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.08633", "abs": "https://arxiv.org/abs/2508.08633", "authors": ["HuanYu Yang", "Fengming Zhu", "YangFan Wu", "Jianmin Ji"], "title": "Diminution: On Reducing the Size of Grounding ASP Programs", "comment": null, "summary": "Answer Set Programming (ASP) is often hindered by the grounding bottleneck:\nlarge Herbrand universes generate ground programs so large that solving becomes\ndifficult. Many methods employ ad-hoc heuristics to improve grounding\nperformance, motivating the need for a more formal and generalizable strategy.\nWe introduce the notion of diminution, defined as a selected subset of the\nHerbrand universe used to generate a reduced ground program before solving. We\ngive a formal definition of diminution, analyze its key properties, and study\nthe complexity of identifying it. We use a specific encoding that enables\noff-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates\nseamlessly with existing grounders via domain predicates. In extensive\nexperiments on five benchmarks, applying diminutions selected by our strategy\nyields significant performance improvements, reducing grounding time by up to\n70% on average and decreasing the size of grounding files by up to 85%. These\nresults demonstrate that leveraging diminutions constitutes a robust and\ngeneral-purpose approach for alleviating the grounding bottleneck in ASP.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86 diminution \u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a Herbrand universe \u7684\u9009\u5b9a\u5b50\u96c6\uff0c\u7528\u4e8e\u751f\u6210\u51cf\u5c11\u7684\u5bfc\u51fa\u7a0b\u5e8f\u3002\u901a\u8fc7\u7279\u5b9a\u7684\u7f16\u7801\u65b9\u6848\uff0c\u6574\u5408\u73b0\u6709 grounders\uff0c\u5927\u5e45\u63d0\u9ad8 ASP \u7684\u6027\u80fd\uff0c\u51cf\u5c11\u5bfc\u51fa\u65f6\u95f4\u548c\u6587\u4ef6\u5927\u5c0f\u3002\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\uff0c\u8bc1\u660e diminutions \u662f\u7f13\u89e3 ASP \u5bfc\u51fa\u74f6\u9888\u7684\u6709\u6548\u65b9\u6cd5\u3002", "motivation": "\u5927\u7684 Herbrand universes \u4f1a\u751f\u6210\u5de8\u5927\u7684\u5bfc\u51fa\u7a0b\u5e8f\uff0c\u5bfc\u81f4\u6c42\u89e3\u56f0\u96be\uff0c\u8bb8\u591a\u65b9\u6cd5\u4f7f\u7528 ad-hoc \u542f\u53d1\u5f0f\u6539\u5584\u5bfc\u51fa\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6b63\u5f0f\u548c\u901a\u7528\u7684\u7b56\u7565\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u5f15\u5165 diminution \u6982\u5ff5\uff0c\u65e8\u5728\u63d0\u9ad8 ASP \u7684\u6027\u80fd\u5e76\u89e3\u51b3\u5bfc\u51fa\u74f6\u9888\u95ee\u9898\u3002", "method": "\u5f15\u5165 diminution \u6982\u5ff5\uff0c\u5b9a\u4e49\u5176\u4e3a Herbrand universe \u7684\u9009\u5b9a\u5b50\u96c6\uff0c\u7528\u4e8e\u5728\u6c42\u89e3\u4e4b\u524d\u751f\u6210\u51cf\u5c11\u7684\u5bfc\u51fa\u7a0b\u5e8f\u3002\u63d0\u51fa\u4e00\u4e2a\u5177\u4f53\u7684\u7f16\u7801\u65b9\u6848\uff0c\u4f7f\u5f97 ASP \u89e3\u51b3\u5668\u53ef\u4ee5\u8bc4\u4f30\u5019\u9009\u5b50\u96c6\u3002\u901a\u8fc7\u9886\u57df\u8c13\u8bcd\u4e0e\u73b0\u6709\u7684 grounders \u7d27\u5bc6\u96c6\u6210\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u91c7\u7528\u672c\u6587\u7b56\u7565\u9009\u62e9\u7684 diminutions \u663e\u8457\u6539\u5584\u6027\u80fd\uff0c\u5e73\u5747\u51cf\u5c11\u5bfc\u51fa\u65f6\u95f4\u9ad8\u8fbe70%\uff0c\u5bfc\u51fa\u6587\u4ef6\u5927\u5c0f\u6700\u591a\u51cf\u5c1185%\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528 diminutions \u662f\u7f13\u89e3 ASP \u5bfc\u51fa\u74f6\u9888\u7684\u7a33\u5065\u4e14\u901a\u7528\u7684\u65b9\u6cd5\u3002", "conclusion": "\u5f15\u5165 diminution \u6982\u5ff5\u80fd\u591f\u663e\u8457\u63d0\u9ad8 ASP \u7684\u6027\u80fd\uff0c\u5e73\u5747\u51cf\u5c11\u7ea670%\u7684\u5bfc\u51fa\u65f6\u95f4\u548c\u6700\u591a\u51cf\u5c1185%\u7684\u5bfc\u51fa\u6587\u4ef6\u5927\u5c0f\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9 Herbrand universe \u7684\u5b50\u96c6\u751f\u6210\u51cf\u5c11\u7684\u5bfc\u51fa\u7a0b\u5e8f\uff0c\u4e0e\u73b0\u6709\u7684 grounders \u7d27\u5bc6\u6574\u5408\uff0c\u8bc1\u660e\u4e86\u5728 ASP \u4e2d\u7f13\u89e3\u5bfc\u51fa\u74f6\u9888\u7684\u5f3a\u5927\u548c\u901a\u7528\u65b9\u6cd5\u3002"}}
{"id": "2508.08646", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08646", "abs": "https://arxiv.org/abs/2508.08646", "authors": ["Naama Kashani", "Mira Cohen", "Uri Shaham"], "title": "P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records", "comment": "17 pages, 5 figures", "summary": "Electronic Health Records (EHR) have revolutionized healthcare by digitizing\npatient data, improving accessibility, and streamlining clinical workflows.\nHowever, extracting meaningful insights from these complex and multimodal\ndatasets remains a significant challenge for researchers. Traditional feature\nselection methods often struggle with the inherent sparsity and heterogeneity\nof EHR data, especially when accounting for patient-specific variations and\nfeature costs in clinical applications. To address these challenges, we propose\na novel personalized, online and cost-aware feature selection framework\ntailored specifically for EHR datasets. The features are aquired in an online\nfashion for individual patients, incorporating budgetary constraints and\nfeature variability costs. The framework is designed to effectively manage\nsparse and multimodal data, ensuring robust and scalable performance in diverse\nhealthcare contexts. A primary application of our proposed method is to support\nphysicians' decision making in patient screening scenarios. By guiding\nphysicians toward incremental acquisition of the most informative features\nwithin budget constraints, our approach aims to increase diagnostic confidence\nwhile optimizing resource utilization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\u7684\u4e2a\u6027\u5316\u3001\u5728\u7ebf\u4e14\u6210\u672c\u611f\u77e5\u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u65e8\u5728\u652f\u6301\u533b\u751f\u5728\u60a3\u8005\u7b5b\u67e5\u573a\u666f\u4e0b\u7684\u51b3\u7b56\u5236\u5b9a\u3002\u901a\u8fc7\u5728\u7ebf\u65b9\u5f0f\u4e3a\u6bcf\u4e2a\u60a3\u8005\u83b7\u53d6\u7279\u5f81\uff0c\u8003\u8651\u9884\u7b97\u9650\u5236\u548c\u7279\u5f81\u53d8\u5316\u6210\u672c\uff0c\u6709\u6548\u7ba1\u7406\u7a00\u758f\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u4ee5\u786e\u4fdd\u5728\u591a\u6837\u5316\u533b\u7597\u73af\u5883\u4e2d\u7684\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u65e8\u5728\u63d0\u9ad8\u8bca\u65ad\u4fe1\u5fc3\u5e76\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u51fa\u73b0\u6539\u53d8\u4e86\u533b\u7597\u4fdd\u5065\uff0c\u4f46\u4ece\u8fd9\u4e9b\u590d\u6742\u7684\u591a\u6a21\u6001\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u89c1\u89e3\u4ecd\u7136\u662f\u7814\u7a76\u4eba\u5458\u9762\u4e34\u7684\u91cd\u5927\u6311\u6218\u3002\u4f20\u7edf\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u96be\u4ee5\u5904\u7406EHR\u6570\u636e\u7684\u7a00\u758f\u6027\u548c\u5f02\u8d28\u6027\uff0c\u5c24\u5176\u5f53\u8003\u8651\u60a3\u8005\u7279\u5b9a\u53d8\u5316\u548c\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u7279\u5f81\u6210\u672c\u65f6\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u9700\u8981\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u4e2a\u6027\u5316\u3001\u5728\u7ebf\u548c\u6210\u672c\u611f\u77e5\u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9EHR\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e2a\u6027\u5316\u3001\u5728\u7ebf\u548c\u6210\u672c\u611f\u77e5\u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5728\u5904\u7406EHR\u6570\u636e\u65f6\u9047\u5230\u7684\u7a00\u758f\u6027\u3001\u5f02\u8d28\u6027\u4ee5\u53ca\u60a3\u8005\u7279\u5b9a\u53d8\u5316\u548c\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u7279\u5f81\u6210\u672c\u7b49\u6311\u6218\u3002\u8be5\u6846\u67b6\u91c7\u7528\u5728\u7ebf\u65b9\u5f0f\u4e3a\u6bcf\u4e2a\u60a3\u8005\u83b7\u53d6\u7279\u5f81\uff0c\u8003\u8651\u9884\u7b97\u9650\u5236\u548c\u7279\u5f81\u53d8\u5316\u6210\u672c\uff0c\u65e8\u5728\u6709\u6548\u7ba1\u7406\u7a00\u758f\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u786e\u4fdd\u5728\u4e0d\u540c\u533b\u7597\u73af\u5883\u4e2d\u7684\u6027\u80fd\u7a33\u5065\u548c\u53ef\u6269\u5c55\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u7ba1\u7406\u7a00\u758f\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u5b9e\u73b0\u5728\u591a\u6837\u5316\u533b\u7597\u73af\u5883\u4e2d\u7684\u7a33\u5065\u548c\u53ef\u6269\u5c55\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e3b\u8981\u5e94\u7528\u4e8e\u652f\u6301\u533b\u751f\u5728\u60a3\u8005\u7b5b\u67e5\u573a\u666f\u4e0b\u7684\u51b3\u7b56\u5236\u5b9a\uff0c\u901a\u8fc7\u5f15\u5bfc\u533b\u751f\u5728\u9884\u7b97\u9650\u5236\u4e0b\u9010\u6b65\u83b7\u53d6\u6700\u5177\u4fe1\u606f\u91cf\u7684\u7279\u5f81\uff0c\u65e8\u5728\u63d0\u9ad8\u8bca\u65ad\u4fe1\u5fc3\u5e76\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\u7684\u4e2a\u6027\u5316\u3001\u5728\u7ebf\u4e14\u6210\u672c\u611f\u77e5\u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u65e8\u5728\u652f\u6301\u533b\u751f\u5728\u60a3\u8005\u7b5b\u67e5\u573a\u666f\u4e0b\u7684\u51b3\u7b56\u5236\u5b9a\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5728\u7ebf\u65b9\u5f0f\u4e3a\u6bcf\u4e2a\u60a3\u8005\u83b7\u53d6\u7279\u5f81\uff0c\u8003\u8651\u9884\u7b97\u9650\u5236\u548c\u7279\u5f81\u53d8\u5316\u6210\u672c\uff0c\u6709\u6548\u7ba1\u7406\u7a00\u758f\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u4ee5\u786e\u4fdd\u5728\u591a\u6837\u5316\u533b\u7597\u73af\u5883\u4e2d\u7684\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u6027\u80fd\u3002\u901a\u8fc7\u6307\u5bfc\u533b\u751f\u5728\u9884\u7b97\u9650\u5236\u4e0b\u9010\u6b65\u83b7\u53d6\u6700\u5177\u4fe1\u606f\u91cf\u7684\u7279\u5f81\uff0c\u8be5\u65b9\u6cd5\u65e8\u5728\u63d0\u9ad8\u8bca\u65ad\u4fe1\u5fc3\u5e76\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002"}}
{"id": "2508.08652", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08652", "abs": "https://arxiv.org/abs/2508.08652", "authors": ["Vishakha Lall", "Yisi Liu"], "title": "Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training", "comment": null, "summary": "Accurate evaluation of procedural communication compliance is essential in\nsimulation-based training, particularly in safety-critical domains where\nadherence to compliance checklists reflects operational competence. This paper\nexplores a lightweight, deployable approach using prompt-based inference with\nopen-source large language models (LLMs) that can run efficiently on\nconsumer-grade GPUs. We present Prompt-and-Check, a method that uses\ncontext-rich prompts to evaluate whether each checklist item in a protocol has\nbeen fulfilled, solely based on transcribed verbal exchanges. We perform a case\nstudy in the maritime domain with participants performing an identical\nsimulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and\nMistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a\nprompt incorporating relevant transcript excerpts is fed into the model, which\noutputs a compliance judgment. We assess model outputs against expert-annotated\nground truth using classification accuracy and agreement scores. Our findings\ndemonstrate that prompting enables effective context-aware reasoning without\ntask-specific training. This study highlights the practical utility of LLMs in\naugmenting debriefing, performance feedback, and automated assessment in\ntraining environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4e00\u79cd\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u4e8e\u63d0\u793a\u7684\u63a8\u7406\uff0c\u4ee5\u8bc4\u4f30\u7a0b\u5e8f\u6027\u6c9f\u901a\u9075\u4ece\u6027\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u6d77\u4e8b\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u53d1\u73b0\u63d0\u793a\u80fd\u591f\u6709\u6548\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u7684\u8bad\u7ec3\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u57f9\u8bad\u73af\u5883\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5728\u6a21\u62df\u8bad\u7ec3\u4e2d\u51c6\u786e\u8bc4\u4f30\u7a0b\u5e8f\u6027\u6c9f\u901a\u7684\u9075\u4ece\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u9075\u5b88\u9075\u4ece\u6027\u68c0\u67e5\u8868\u53cd\u6620\u4e86\u64cd\u4f5c\u80fd\u529b\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u90e8\u7f72\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5728\u6d88\u8d39\u7ea7GPU\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Prompt-and-Check\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u63d0\u793a\u6765\u8bc4\u4f30\u534f\u8bae\u4e2d\u6bcf\u4e2a\u68c0\u67e5\u9879\u662f\u5426\u5df2\u7ecf\u5b8c\u6210\uff0c\u4ec5\u57fa\u4e8e\u8f6c\u5f55\u7684\u53e3\u5934\u4ea4\u6d41\u3002\u901a\u8fc7\u5728\u6d77\u4e8b\u9886\u57df\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u4f7f\u7528LLama 2 7B\u3001LLaMA 3 8B\u548cMistral 7B\u7b49\u6a21\u578b\u5728RTX 4070 GPU\u4e0a\u672c\u5730\u8fd0\u884c\u3002\u5bf9\u6bcf\u4e2a\u68c0\u67e5\u9879\u76ee\uff0c\u5c06\u5305\u542b\u76f8\u5173\u8f6c\u5f55\u6458\u5f55\u7684\u63d0\u793a\u9988\u5165\u6a21\u578b\uff0c\u8f93\u51fa\u4e00\u4e2a\u9075\u4ece\u6027\u5224\u65ad\u3002\u901a\u8fc7\u5206\u7c7b\u51c6\u786e\u5ea6\u548c\u4e00\u81f4\u6027\u8bc4\u5206\uff0c\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u4e0e\u4e13\u5bb6\u6ce8\u91ca\u7684\u771f\u5b9e\u60c5\u51b5\u3002", "result": "\u901a\u8fc7\u6d77\u4e8b\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u53d1\u73b0\u5229\u7528\u63d0\u793a\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\uff0c\u800c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u7684\u8bad\u7ec3\u3002\u7814\u7a76\u7ed3\u679c\u7a81\u51fa\u4e86LLMs\u5728\u57f9\u8bad\u73af\u5883\u4e2d\u589e\u5f3a\u603b\u7ed3\u3001\u7ee9\u6548\u53cd\u9988\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u7684\u5b9e\u9645\u6548\u7528\u3002", "conclusion": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u57fa\u4e8e\u63d0\u793a\u7684\u63a8\u7406\u6765\u8bc4\u4f30\u7a0b\u5e8f\u6027\u6c9f\u901a\u9075\u4ece\u6027\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528\u63d0\u793a\u80fd\u591f\u6709\u6548\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u63a8\u7406\uff0c\u800c\u65e0\u9700\u7279\u5b9a\u4efb\u52a1\u7684\u8bad\u7ec3\u3002\u91c7\u7528\u8fd9\u79cd\u65b9\u6cd5\u5728\u57f9\u8bad\u73af\u5883\u4e2d\u589e\u5f3a\u4e86\u603b\u7ed3\u3001\u7ee9\u6548\u53cd\u9988\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u7684\u5b9e\u9645\u6548\u7528\u3002"}}
{"id": "2508.08659", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08659", "abs": "https://arxiv.org/abs/2508.08659", "authors": ["Bachtiar Herdianto", "Romain Billot", "Flavien Lucas", "Marc Sevaux", "Daniele Vigo"], "title": "Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem", "comment": "19 pages, 10 figures", "summary": "In this research, we propose an iterative learning hybrid optimization solver\ndeveloped to strengthen the performance of metaheuristic algorithms in solving\nthe Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism\nintegrates the proposed Node-Destroyer Model, a machine learning hybrid model\nthat utilized Graph Neural Networks (GNNs) such identifies and selects customer\nnodes to guide the Large Neighborhood Search (LNS) operator within the\nmetaheuristic optimization frameworks. This model leverages the structural\nproperties of the problem and solution that can be represented as a graph, to\nguide strategic selections concerning node removal. The proposed approach\nreduces operational complexity and scales down the search space involved in the\noptimization process. The hybrid approach is applied specifically to the CVRP\nand does not require retraining across problem instances of different sizes.\nThe proposed hybrid mechanism is able to improve the performance of baseline\nmetaheuristic algorithms. Our approach not only enhances the solution quality\nfor standard CVRP benchmarks but also proves scalability on very large-scale\ninstances with up to 30,000 customer nodes. Experimental evaluations on\nbenchmark datasets show that the proposed hybrid mechanism is capable of\nimproving different baseline algorithms, achieving better quality of solutions\nunder similar settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u5b66\u4e60\u6df7\u5408\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u5229\u7528\u8282\u70b9\u7834\u574f\u6a21\u578b\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u673a\u5668\u5b66\u4e60\u6df7\u5408\u6a21\u578b\uff0c\u6307\u5bfc\u5927\u90bb\u57df\u641c\u7d22\u7b97\u5b50\uff0c\u4ee5\u6539\u8fdb\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u89e3\u51b3CVRP\u4e2d\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6df7\u5408\u673a\u5236\u63d0\u9ad8\u4e86\u89e3\u51b3\u8d28\u91cf\uff0c\u5c55\u73b0\u51fa\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3\u5bb9\u91cf\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08CVRP\uff09\u4e2d\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u964d\u4f4e\u64cd\u4f5c\u590d\u6742\u6027\uff0c\u7f29\u5c0f\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u9ad8\u89e3\u51b3\u8d28\u91cf\u5e76\u5c55\u793a\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u8fed\u4ee3\u5b66\u4e60\u6df7\u5408\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u6574\u5408\u4e86\u8282\u70b9\u7834\u574f\u6a21\u578b\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u673a\u5668\u5b66\u4e60\u6df7\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u6307\u5bfc\u5927\u90bb\u57df\u641c\u7d22\uff08LNS\uff09\u7b97\u5b50\u3002\u5229\u7528\u56fe\u8868\u793a\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\u7684\u7ed3\u6784\u5c5e\u6027\uff0c\u5f15\u5bfc\u8282\u70b9\u79fb\u9664\u7684\u6218\u7565\u9009\u62e9\u3002", "result": "\u63d0\u51fa\u7684\u6df7\u5408\u673a\u5236\u6539\u8fdb\u4e86\u57fa\u7ebf\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u5728\u6807\u51c6CVRP\u57fa\u51c6\u95ee\u9898\u548c\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u5747\u53d6\u5f97\u4e86\u79ef\u6781\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u5b66\u4e60\u6df7\u5408\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u65e8\u5728\u52a0\u5f3a\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u89e3\u51b3\u5bb9\u91cf\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08CVRP\uff09\u4e2d\u7684\u6027\u80fd\u3002\u901a\u8fc7\u6574\u5408\u63d0\u51fa\u7684\u8282\u70b9\u7834\u574f\u6a21\u578b\uff0c\u5e76\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u673a\u5668\u5b66\u4e60\u6df7\u5408\u6a21\u578b\u6765\u6307\u5bfc\u5143\u542f\u53d1\u5f0f\u4f18\u5316\u6846\u67b6\u4e2d\u7684\u5927\u90bb\u57df\u641c\u7d22\uff08LNS\uff09\u7b97\u5b50\u3002\u8be5\u6a21\u578b\u5229\u7528\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\u7684\u7ed3\u6784\u5c5e\u6027\uff0c\u5c06\u5176\u8868\u793a\u4e3a\u56fe\uff0c\u4ee5\u6307\u5bfc\u6709\u5173\u8282\u70b9\u79fb\u9664\u7684\u6218\u7565\u9009\u62e9\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u964d\u4f4e\u4e86\u64cd\u4f5c\u590d\u6742\u6027\uff0c\u5e76\u7f29\u5c0f\u4e86\u6d89\u53ca\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u641c\u7d22\u7a7a\u95f4\u3002\u8fd9\u79cd\u6df7\u5408\u65b9\u6cd5\u7279\u5b9a\u5e94\u7528\u4e8eCVRP\uff0c\u5e76\u4e0d\u9700\u8981\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u95ee\u9898\u5b9e\u4f8b\u4e4b\u95f4\u91cd\u65b0\u8bad\u7ec3\u3002\u6240\u63d0\u51fa\u7684\u6df7\u5408\u673a\u5236\u80fd\u591f\u6539\u8fdb\u57fa\u7ebf\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u6027\u80fd\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6807\u51c6CVRP\u57fa\u51c6\u95ee\u9898\u7684\u89e3\u51b3\u8d28\u91cf\uff0c\u8fd8\u5728\u9ad8\u8fbe30,000\u4e2a\u5ba2\u6237\u8282\u70b9\u7684\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u8bc1\u660e\u4e86\u53ef\u6269\u5c55\u6027\u3002\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u6df7\u5408\u673a\u5236\u80fd\u591f\u6539\u8fdb\u4e0d\u540c\u57fa\u7ebf\u7b97\u6cd5\uff0c\u5728\u7c7b\u4f3c\u8bbe\u7f6e\u4e0b\u83b7\u5f97\u66f4\u4f18\u8d28\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.08665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08665", "abs": "https://arxiv.org/abs/2508.08665", "authors": ["Ritvik Rastogi", "Sachin Dharashivkar", "Sandeep Varma"], "title": "Aryabhata: An exam-focused language model for JEE Math", "comment": null, "summary": "We present Aryabhata 1.0, a compact 7B parameter math reasoning model\noptimized for the Indian academic exam, the Joint Entrance Examination (JEE).\nDespite rapid progress in large language models (LLMs), current models often\nremain unsuitable for educational use. Aryabhata 1.0 is built by merging strong\nopen-weight reasoning models, followed by supervised fine-tuning (SFT) with\ncurriculum learning on verified chain-of-thought (CoT) traces curated through\nbest-of-$n$ rejection sampling. To further boost performance, we apply\nreinforcement learning with verifiable rewards (RLVR) using A2C objective with\ngroup-relative advantage estimation along with novel exploration strategies\nsuch as Adaptive Group Resizing and Temperature Scaling. Evaluated on both\nin-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K)\nbenchmarks, Aryabhata outperforms existing models in accuracy and efficiency,\nwhile offering pedagogically useful step-by-step reasoning. We release\nAryabhata as a foundation model to advance exam-centric, open-source small\nlanguage models. This marks our first open release for community feedback\n(https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training\nfuture models to further improve learning outcomes for students.", "AI": {"tldr": "Aryabhata 1.0\u662f\u4e00\u4e2a\u4e3a\u5370\u5ea6\u5b66\u672f\u8003\u8bd5JEE\u4f18\u5316\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u5408\u5e76\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\u5e76\u91c7\u7528\u76d1\u7763\u5fae\u8c03\u548c\u8bfe\u7a0b\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\u3002\u540c\u65f6\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\uff0c\u5df2\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u4e00\u4e2a\u4e3a\u5b66\u751f\u63d0\u4f9b\u66f4\u597d\u5b66\u4e60\u7ed3\u679c\u7684\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d6\u5f97\u4e86\u5feb\u901f\u8fdb\u5c55\uff0c\u4f46\u76ee\u524d\u7684\u6a21\u578b\u901a\u5e38\u4e0d\u9002\u5408\u6559\u80b2\u7528\u9014\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u9488\u5bf9\u5370\u5ea6\u5b66\u672f\u8003\u8bd5JEE\u8fdb\u884c\u4f18\u5316\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\u3002", "method": "\u5c06\u5f3a\u5927\u7684\u5f00\u653e\u5f0f\u63a8\u7406\u6a21\u578b\u5408\u5e76\uff0c\u7ecf\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u4ee5\u9a8c\u8bc1\u7684\u601d\u7ef4\u94fe\u8e2a\u8ff9\u8fdb\u884c\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ecA2C\u76ee\u6807\u548c\u65b0\u9896\u7684\u63a2\u7d22\u7b56\u7565\uff0c\u5982\u81ea\u9002\u5e94\u7ec4\u5927\u5c0f\u8c03\u6574\u548c\u6e29\u5ea6\u7f29\u653e\uff0c\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728JEE Main 2025\u548cMATH\u3001GSM8K\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\uff0cAryabhata\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u540c\u65f6\u63d0\u4f9b\u6559\u80b2\u4e0a\u6709\u7528\u7684\u9010\u6b65\u63a8\u7406\u8fc7\u7a0b\u3002", "conclusion": "Aryabhata 1.0\u662f\u4e00\u4e2a\u7cbe\u5fc3\u4f18\u5316\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\uff0c\u4e13\u4e3a\u5370\u5ea6\u5b66\u672f\u8003\u8bd5\uff08JEE\uff09\u800c\u8bbe\u8ba1\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u80dc\u8fc7\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u6559\u80b2\u4e0a\u6709\u7528\u7684\u9010\u6b65\u63a8\u7406\u3002\u7814\u7a76\u56e2\u961f\u5c06Aryabhata\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u53d1\u5e03\uff0c\u65e8\u5728\u63a8\u52a8\u4ee5\u8003\u8bd5\u4e3a\u4e2d\u5fc3\u7684\u5f00\u6e90\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u4e3a\u5b66\u751f\u5b66\u4e60\u63d0\u4f9b\u66f4\u597d\u7684\u7ed3\u679c\u3002"}}
{"id": "2508.08688", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.08688", "abs": "https://arxiv.org/abs/2508.08688", "authors": ["Chen Li", "Han Zhang", "Zhantao Yang", "Fangyi Chen", "Zihan Wang", "Anudeepsekhar Bolimera", "Marios Savvides"], "title": "STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision", "comment": null, "summary": "Vision-language models (VLMs) have made significant strides in reasoning, yet\nthey often struggle with complex multimodal tasks and tend to generate overly\nverbose outputs. A key limitation is their reliance on chain-of-thought (CoT)\nreasoning, despite many tasks benefiting from alternative topologies like trees\nor graphs. To address this, we introduce STELAR-Vision, a training framework\nfor topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline\nthat enriches training with diverse topological structures. Using supervised\nfine-tuning and reinforcement learning, we post-train Qwen2VL models with both\naccuracy and efficiency in mind. Additionally, we propose Frugal Learning,\nwhich reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H,\nSTELAR-Vision improves accuracy by 9.7% over its base model and surpasses the\nlarger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it\noutperforms Phi-4-Multimodal-Instruct by up to 28.4% and\nLLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong\ngeneralization. Compared to Chain-Only training, our approach achieves 4.3%\nhigher overall accuracy on in-distribution datasets and consistently\noutperforms across all OOD benchmarks. We have released datasets, and code will\nbe available.", "AI": {"tldr": "STEALR-Vision enhances VLMs with topology-aware reasoning, achieving significant accuracy improvements and efficiency. It outperforms existing models on various datasets, showing strong generalization and consistently better performance compared to Chain-Only training.", "motivation": "Current vision-language models struggle with complex multimodal tasks and tend to generate verbose outputs due to their reliance on chain-of-thought reasoning. Many tasks benefit from alternative topologies like trees or graphs, which are not effectively utilized in existing models.", "method": "The paper introduces STEALR-Vision with TopoAug, a synthetic data pipeline to enrich training with diverse topological structures. It uses supervised fine-tuning and reinforcement learning to post-train Qwen2VL models. Frugal Learning technique is proposed to reduce output length with minimal accuracy loss.", "result": "STEALR-Vision improves accuracy by 9.7% over its base model and surpasses the larger Qwen2VL-72B-Instruct by 7.3% on MATH-V and VLM-S2H datasets. It outperforms Phi-4-Multimodal-Instruct by up to 28.4% and LLaMA-3.2-11B-Vision-Instruct by up to 13.2% on out-of-distribution benchmarks.", "conclusion": "STEALR-Vision introduces a training framework for topology-aware reasoning, improving accuracy and efficiency in VLMs. It outperforms existing models on both in-distribution and out-of-distribution benchmarks, demonstrating strong generalization. The approach achieves higher overall accuracy and consistently outperforms Chain-Only training method."}}
{"id": "2508.08726", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.08726", "abs": "https://arxiv.org/abs/2508.08726", "authors": ["Yuwei Yan", "Jinghua Piao", "Xiaochong Lan", "Chenyang Shao", "Pan Hui", "Yong Li"], "title": "Simulating Generative Social Agents via Theory-Informed Workflow Design", "comment": null, "summary": "Recent advances in large language models have demonstrated strong reasoning\nand role-playing capabilities, opening new opportunities for agent-based social\nsimulations. However, most existing agents' implementations are\nscenario-tailored, without a unified framework to guide the design. This lack\nof a general social agent limits their ability to generalize across different\nsocial contexts and to produce consistent, realistic behaviors. To address this\nchallenge, we propose a theory-informed framework that provides a systematic\ndesign process for LLM-based social agents. Our framework is grounded in\nprinciples from Social Cognition Theory and introduces three key modules:\nmotivation, action planning, and learning. These modules jointly enable agents\nto reason about their goals, plan coherent actions, and adapt their behavior\nover time, leading to more flexible and contextually appropriate responses.\nComprehensive experiments demonstrate that our theory-driven agents reproduce\nrealistic human behavior patterns under complex conditions, achieving up to 75%\nlower deviation from real-world behavioral data across multiple fidelity\nmetrics compared to classical generative baselines. Ablation studies further\nshow that removing motivation, planning, or learning modules increases errors\nby 1.5 to 3.2 times, confirming their distinct and essential contributions to\ngenerating realistic and coherent social behaviors.", "AI": {"tldr": "\u6700\u8fd1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u57fa\u4e8e\u4ee3\u7406\u7684\u793e\u4f1a\u6a21\u62df\u5e26\u6765\u4e86\u65b0\u673a\u9047\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u793e\u4f1a\u8ba4\u77e5\u7406\u8bba\u7684\u6846\u67b6\uff0c\u5305\u62ec\u52a8\u673a\u3001\u884c\u52a8\u89c4\u5212\u548c\u5b66\u4e60\u6a21\u5757\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u8868\u73b0\u51fa\u66f4\u7075\u6d3b\u548c\u60c5\u5883\u9002\u5f53\u7684\u884c\u4e3a\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u7406\u8bba\u7684\u4ee3\u7406\u5728\u590d\u6742\u6761\u4ef6\u4e0b\u80fd\u591f\u91cd\u73b0\u771f\u5b9e\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e76\u6bd4\u4f20\u7edf\u751f\u6210\u57fa\u7ebf\u8868\u73b0\u66f4\u597d\u3002\u53bb\u9664\u5173\u952e\u6a21\u5757\u4f1a\u589e\u52a0\u9519\u8bef\u7387\uff0c\u5f3a\u8c03\u4e86\u8fd9\u4e9b\u6a21\u5757\u5bf9\u751f\u6210\u771f\u5b9e\u793e\u4ea4\u884c\u4e3a\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u6700\u8fd1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d6\u5f97\u4e86\u5f3a\u5927\u7684\u63a8\u7406\u548c\u89d2\u8272\u626e\u6f14\u80fd\u529b\uff0c\u4e3a\u57fa\u4e8e\u4ee3\u7406\u7684\u793e\u4f1a\u6a21\u62df\u5f00\u8f9f\u4e86\u65b0\u7684\u673a\u9047\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u73b0\u6709\u4ee3\u7406\u7684\u5b9e\u73b0\u662f\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u7684\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6846\u67b6\u6765\u6307\u5bfc\u8bbe\u8ba1\u3002\u7f3a\u4e4f\u901a\u7528\u7684\u793e\u4ea4\u4ee3\u7406\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u793e\u4f1a\u80cc\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4ea7\u751f\u4e00\u81f4\u3001\u771f\u5b9e\u884c\u4e3a\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u793e\u4f1a\u8ba4\u77e5\u7406\u8bba\u63d0\u51fa\u4e86\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u52a8\u673a\u3001\u884c\u52a8\u89c4\u5212\u548c\u5b66\u4e60\uff0c\u5171\u540c\u4f7f\u4ee3\u7406\u80fd\u591f\u7406\u89e3\u5176\u76ee\u6807\u3001\u89c4\u5212\u8fde\u8d2f\u7684\u884c\u52a8\uff0c\u5e76\u968f\u65f6\u95f4\u8c03\u6574\u5176\u884c\u4e3a\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u7075\u6d3b\u548c\u60c5\u5883\u9002\u5f53\u7684\u56de\u5e94\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u57fa\u4e8e\u7406\u8bba\u7684\u4ee3\u7406\u5728\u591a\u4e2a\u5fe0\u5b9e\u5ea6\u6307\u6807\u4e0a\u6bd4\u4f20\u7edf\u751f\u6210\u57fa\u7ebf\u5b9e\u73b0\u4e86\u9ad8\u8fbe75%\u7684\u66f4\u4f4e\u504f\u5dee\u3002\u6d88\u878d\u7814\u7a76\u663e\u793a\uff0c\u53bb\u9664\u52a8\u673a\u3001\u89c4\u5212\u6216\u5b66\u4e60\u6a21\u5757\u4f1a\u589e\u52a0\u9519\u8bef\u7387\uff0c\u9a8c\u8bc1\u4e86\u5b83\u4eec\u5bf9\u751f\u6210\u771f\u5b9e\u548c\u8fde\u8d2f\u793e\u4ea4\u884c\u4e3a\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7406\u8bba\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bbe\u8ba1LLM\u793e\u4ea4\u4ee3\u7406\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u548c\u7b26\u5408\u60c5\u5883\u7684\u56de\u5e94\u3002\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\uff0c\u8bc1\u660e\u5176\u5728\u590d\u6742\u6761\u4ef6\u4e0b\u53ef\u590d\u73b0\u771f\u5b9e\u7684\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e76\u4e0e\u4f20\u7edf\u751f\u6210\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe75%\u7684\u66f4\u4f4e\u504f\u5dee\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u8868\u660e\uff0c\u53bb\u9664\u52a8\u673a\u3001\u89c4\u5212\u6216\u5b66\u4e60\u6a21\u5757\u4f1a\u589e\u52a0\u9519\u8bef\u7387\uff0c\u9a8c\u8bc1\u4e86\u5b83\u4eec\u5bf9\u751f\u6210\u771f\u5b9e\u548c\u8fde\u8d2f\u793e\u4ea4\u884c\u4e3a\u7684\u72ec\u7279\u548c\u5fc5\u8981\u8d21\u732e\u3002"}}
{"id": "2508.08774", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.08774", "abs": "https://arxiv.org/abs/2508.08774", "authors": ["Dongwook Choi", "Taeyoon Kwon", "Dongil Yang", "Hyojun Kim", "Jinyoung Yeo"], "title": "Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance", "comment": "7 pages, 2 figures", "summary": "Augmented Reality (AR) systems are increasingly integrating foundation\nmodels, such as Multimodal Large Language Models (MLLMs), to provide more\ncontext-aware and adaptive user experiences. This integration has led to the\ndevelopment of AR agents to support intelligent, goal-directed interactions in\nreal-world environments. While current AR agents effectively support immediate\ntasks, they struggle with complex multi-step scenarios that require\nunderstanding and leveraging user's long-term experiences and preferences. This\nlimitation stems from their inability to capture, retain, and reason over\nhistorical user interactions in spatiotemporal contexts. To address these\nchallenges, we propose a conceptual framework for memory-augmented AR agents\nthat can provide personalized task assistance by learning from and adapting to\nuser-specific experiences over time. Our framework consists of four\ninterconnected modules: (1) Perception Module for multimodal sensor processing,\n(2) Memory Module for persistent spatiotemporal experience storage, (3)\nSpatiotemporal Reasoning Module for synthesizing past and present contexts, and\n(4) Actuator Module for effective AR communication. We further present an\nimplementation roadmap, a future evaluation strategy, a potential target\napplication and use cases to demonstrate the practical applicability of our\nframework across diverse domains. We aim for this work to motivate future\nresearch toward developing more intelligent AR systems that can effectively\nbridge user's interaction history with adaptive, context-aware task assistance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bb0\u5fc6\u589e\u5f3a\u7684\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u4ee3\u7406\u7684\u6982\u5ff5\u6027\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u5b66\u4e60\u548c\u9002\u5e94\u7528\u6237\u7279\u5b9a\u7ecf\u9a8c\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u4efb\u52a1\u8f85\u52a9\u3002\u6846\u67b6\u5305\u62ec\u611f\u77e5\u6a21\u5757\u3001\u8bb0\u5fc6\u6a21\u5757\u3001\u65f6\u7a7a\u63a8\u7406\u6a21\u5757\u548c\u6267\u884c\u5668\u6a21\u5757\u3002\u5c55\u793a\u4e86\u6846\u67b6\u7684\u5b9e\u65bd\u8def\u7ebf\u56fe\u3001\u672a\u6765\u8bc4\u4f30\u7b56\u7565\u3001\u6f5c\u5728\u76ee\u6807\u5e94\u7528\u548c\u4f7f\u7528\u6848\u4f8b\u3002\u81f4\u529b\u4e8e\u63a8\u52a8\u672a\u6765\u7814\u7a76\uff0c\u5f00\u53d1\u66f4\u667a\u80fd\u7684AR\u7cfb\u7edf\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5c06\u7528\u6237\u7684\u4ea4\u4e92\u5386\u53f2\u4e0e\u9002\u5e94\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4efb\u52a1\u8f85\u52a9\u76f8\u7ed3\u5408\u3002", "motivation": "\u5f53\u524dAR\u4ee3\u7406\u5728\u652f\u6301\u5373\u65f6\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u9700\u8981\u7406\u89e3\u548c\u5229\u7528\u7528\u6237\u957f\u671f\u7ecf\u9a8c\u548c\u504f\u597d\u7684\u590d\u6742\u591a\u6b65\u573a\u666f\u65f6\u5b58\u5728\u56f0\u96be\u3002\u8fd9\u4e00\u5c40\u9650\u6027\u6e90\u81ea\u5b83\u4eec\u65e0\u6cd5\u6355\u6349\u3001\u4fdd\u7559\u548c\u63a8\u7406\u5386\u53f2\u7528\u6237\u4ea4\u4e92\u7684\u65f6\u7a7a\u8bed\u5883\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u8bb0\u5fc6\u589e\u5f3a\u7684AR\u4ee3\u7406\u7684\u6982\u5ff5\u6027\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u8bb0\u5fc6\u589e\u5f3a\u7684AR\u4ee3\u7406\u7684\u6982\u5ff5\u6027\u6846\u67b6\uff0c\u5305\u62ec\u611f\u77e5\u6a21\u5757\u3001\u8bb0\u5fc6\u6a21\u5757\u3001\u65f6\u7a7a\u63a8\u7406\u6a21\u5757\u548c\u6267\u884c\u5668\u6a21\u5757\u3002\u5c55\u793a\u4e86\u5b9e\u65bd\u8def\u7ebf\u56fe\u3001\u672a\u6765\u8bc4\u4f30\u7b56\u7565\u3001\u6f5c\u5728\u76ee\u6807\u5e94\u7528\u548c\u4f7f\u7528\u6848\u4f8b\u3002", "result": "\u63d0\u51fa\u7684\u6982\u5ff5\u6027\u6846\u67b6\u4e3a\u8bb0\u5fc6\u589e\u5f3a\u7684AR\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e2a\u6027\u5316\u4efb\u52a1\u8f85\u52a9\uff0c\u53ef\u4ee5\u4ece\u7528\u6237\u7279\u5b9a\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u548c\u9002\u5e94\u3002\u5c55\u793a\u4e86\u6846\u67b6\u7684\u5b9e\u65bd\u8def\u7ebf\u56fe\u3001\u672a\u6765\u8bc4\u4f30\u7b56\u7565\u3001\u6f5c\u5728\u76ee\u6807\u5e94\u7528\u548c\u4f7f\u7528\u6848\u4f8b\uff0c\u4ee5\u5c55\u793a\u6846\u67b6\u5728\u4e0d\u540c\u9886\u57df\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6027\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bb0\u5fc6\u589e\u5f3a\u7684\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u4ee3\u7406\uff0c\u65e8\u5728\u901a\u8fc7\u5b66\u4e60\u548c\u9002\u5e94\u7528\u6237\u7279\u5b9a\u7ecf\u9a8c\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u4efb\u52a1\u8f85\u52a9\u3002\u6846\u67b6\u5305\u62ec\u56db\u4e2a\u76f8\u4e92\u8fde\u63a5\u7684\u6a21\u5757\uff1a\u611f\u77e5\u6a21\u5757\u3001\u8bb0\u5fc6\u6a21\u5757\u3001\u65f6\u7a7a\u63a8\u7406\u6a21\u5757\u548c\u6267\u884c\u5668\u6a21\u5757\u3002\u5c55\u793a\u4e86\u6846\u67b6\u7684\u5b9e\u65bd\u8def\u7ebf\u56fe\u3001\u672a\u6765\u8bc4\u4f30\u7b56\u7565\u3001\u6f5c\u5728\u76ee\u6807\u5e94\u7528\u548c\u4f7f\u7528\u6848\u4f8b\uff0c\u4ee5\u5c55\u793a\u6846\u67b6\u5728\u4e0d\u540c\u9886\u57df\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002\u81f4\u529b\u4e8e\u63a8\u52a8\u672a\u6765\u7814\u7a76\uff0c\u5f00\u53d1\u66f4\u667a\u80fd\u7684AR\u7cfb\u7edf\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5c06\u7528\u6237\u7684\u4ea4\u4e92\u5386\u53f2\u4e0e\u9002\u5e94\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4efb\u52a1\u8f85\u52a9\u76f8\u7ed3\u5408\u3002"}}
{"id": "2508.08795", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.08795", "abs": "https://arxiv.org/abs/2508.08795", "authors": ["Amir Mohammad Salehoof", "Ali Ramezani", "Yadollah Yaghoobzadeh", "Majid Nili Ahmadabadi"], "title": "A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions", "comment": "13 pages, 1 figure", "summary": "Large language models (LLMs) acquire vast knowledge from large text corpora,\nbut this information can become outdated or inaccurate. Since retraining is\ncomputationally expensive, knowledge editing offers an efficient alternative --\nmodifying internal knowledge without full retraining. These methods aim to\nupdate facts precisely while preserving the model's overall capabilities. While\nexisting surveys focus on the mechanism of editing (e.g., parameter changes vs.\nexternal memory), they often overlook the function of the knowledge being\nedited. This survey introduces a novel, complementary function-based taxonomy\nto provide a more holistic view. We examine how different mechanisms apply to\nvarious knowledge types -- factual, temporal, conceptual, commonsense, and\nsocial -- highlighting how editing effectiveness depends on the nature of the\ntarget knowledge. By organizing our review along these two axes, we map the\ncurrent landscape, outline the strengths and limitations of existing methods,\ndefine the problem formally, survey evaluation tasks and datasets, and conclude\nwith open challenges and future directions.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u5927\u578b\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u83b7\u53d6\u5927\u91cf\u77e5\u8bc6\uff0c\u4f46\u4fe1\u606f\u53ef\u80fd\u53d8\u5f97\u8fc7\u65f6\u6216\u4e0d\u51c6\u786e\u3002\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u77e5\u8bc6\u7f16\u8f91\u662f\u4e00\u79cd\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u529f\u80fd\u6027\u5206\u7c7b\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u7f16\u8f91\u673a\u5236\u4e0e\u4e0d\u540c\u7c7b\u578b\u77e5\u8bc6\u7684\u5173\u7cfb\uff0c\u6982\u8ff0\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u5217\u4e3e\u4e86\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u539f\u56e0\u5728\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ece\u5927\u578b\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u83b7\u5f97\u4e86\u5927\u91cf\u77e5\u8bc6\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u53ef\u80fd\u53d8\u5f97\u8fc7\u65f6\u6216\u4e0d\u51c6\u786e\u3002\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u77e5\u8bc6\u7f16\u8f91\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u4ee5\u5728\u4e0d\u8fdb\u884c\u5b8c\u6574\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u4fee\u6539\u5185\u90e8\u77e5\u8bc6\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u529f\u80fd\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u77e5\u8bc6\u7f16\u8f91\u7684\u673a\u5236\u4e0e\u4e0d\u540c\u7c7b\u578b\u77e5\u8bc6\u7684\u5173\u7cfb\uff0c\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u7ec4\u7ec7\u8bc4\u8bba\u548c\u7814\u7a76\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u529f\u80fd\u6027\u5206\u7c7b\u6cd5\uff0c\u4f7f\u5f97\u5bf9\u77e5\u8bc6\u7f16\u8f91\u673a\u5236\u4e0e\u4e0d\u540c\u7c7b\u578b\u77e5\u8bc6\u4e4b\u95f4\u5173\u7cfb\u7684\u63a2\u8ba8\u66f4\u52a0\u5168\u9762\uff0c\u7a81\u51fa\u4e86\u7f16\u8f91\u6548\u679c\u4e0e\u76ee\u6807\u77e5\u8bc6\u6027\u8d28\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u529f\u80fd\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u4ee5\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u89c6\u89d2\uff0c\u63a2\u8ba8\u4e86\u77e5\u8bc6\u7f16\u8f91\u7684\u673a\u5236\u5982\u4f55\u9002\u7528\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u77e5\u8bc6\uff0c\u5f3a\u8c03\u4e86\u7f16\u8f91\u6548\u679c\u4e0e\u76ee\u6807\u77e5\u8bc6\u6027\u8d28\u7684\u5173\u7cfb\u3002\u901a\u8fc7\u6cbf\u7740\u8fd9\u4e24\u4e2a\u8f74\u7ebf\u7ec4\u7ec7\u6211\u4eec\u7684\u8bc4\u8bba\uff0c\u6211\u4eec\u5bf9\u5f53\u524d\u7684\u7814\u7a76\u9886\u57df\u8fdb\u884c\u4e86\u68b3\u7406\uff0c\u6982\u8ff0\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u6b63\u5f0f\u5b9a\u4e49\u4e86\u95ee\u9898\uff0c\u8c03\u67e5\u4e86\u8bc4\u4f30\u4efb\u52a1\u548c\u6570\u636e\u96c6\uff0c\u5e76\u5c31\u672a\u6765\u7684\u6311\u6218\u548c\u53d1\u5c55\u65b9\u5411\u8fdb\u884c\u4e86\u7ed3\u8bba\u3002"}}
{"id": "2508.08815", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08815", "abs": "https://arxiv.org/abs/2508.08815", "authors": ["Roberto Barile", "Claudia d'Amato", "Nicola Fanizzi"], "title": "GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs", "comment": null, "summary": "Since Knowledge Graphs are often incomplete, link prediction methods are\nadopted for predicting missing facts. Scalable embedding based solutions are\nmostly adopted for this purpose, however, they lack comprehensibility, which\nmay be crucial in several domains. Explanation methods tackle this issue by\nidentifying supporting knowledge explaining the predicted facts. Regretfully,\nevaluating/comparing quantitatively the resulting explanations is challenging\nas there is no standard evaluation protocol and overall benchmarking resource.\nWe fill this important gap by proposing GRainsaCK, a reusable software resource\nthat fully streamlines all the tasks involved in benchmarking explanations,\ni.e., from model training to evaluation of explanations along the same\nevaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by\nimplementing the main components as functions that can be easily replaced.\nFinally, fostering its reuse, we provide extensive documentation including a\ntutorial.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86GRainsaCK\u8f6f\u4ef6\u8d44\u6e90\uff0c\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u9884\u6d4b\u4e2d\u89e3\u91ca\u65b9\u6cd5\u8bc4\u4f30\u7684\u95ee\u9898\u3002GRainsaCK\u80fd\u591f\u7edf\u4e00\u8bc4\u4f30\u534f\u8bae\uff0c\u7b80\u5316\u89e3\u91ca\u8bc4\u4f30\u4efb\u52a1\uff0c\u5e76\u63d0\u9ad8\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u77e5\u8bc6\u56fe\u8c31\u5f80\u5f80\u4e0d\u5b8c\u6574\uff0c\u94fe\u63a5\u9884\u6d4b\u65b9\u6cd5\u7528\u4e8e\u9884\u6d4b\u7f3a\u5931\u7684\u4e8b\u5b9e\u3002\u5c3d\u7ba1\u5927\u591a\u6570\u91c7\u7528\u57fa\u4e8e\u5d4c\u5165\u5f0f\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u53ef\u7406\u89e3\u6027\uff0c\u8fd9\u5728\u8bb8\u591a\u9886\u57df\u53ef\u80fd\u81f3\u5173\u91cd\u8981\u3002\u89e3\u91ca\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u652f\u6301\u77e5\u8bc6\u6765\u89e3\u91ca\u9884\u6d4b\u7684\u4e8b\u5b9e\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7f3a\u4e4f\u6807\u51c6\u8bc4\u4f30\u534f\u8bae\u548c\u6574\u4f53\u57fa\u51c6\u8d44\u6e90\uff0c\u5b9a\u91cf\u8bc4\u4f30/\u6bd4\u8f83\u7ed3\u679c\u89e3\u91ca\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u672c\u6587\u586b\u8865\u4e86\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u9884\u6d4b\u4e2d\u89e3\u91ca\u65b9\u6cd5\u7684\u8bc4\u4f30/\u6bd4\u8f83\u65b9\u9762\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86GRainsaCK\u8f6f\u4ef6\u8d44\u6e90\u3002\u8be5\u8d44\u6e90\u80fd\u591f\u7b80\u5316\u6240\u6709\u6d89\u53ca\u89e3\u91ca\u8bc4\u4f30\u7684\u4efb\u52a1\uff0c\u5305\u62ec\u6a21\u578b\u8bad\u7ec3\u548c\u89e3\u91ca\u8bc4\u4f30\uff0c\u7edf\u4e00\u8bc4\u4f30\u534f\u8bae\u3002\u6b64\u5916\uff0cGRainsaCK\u901a\u8fc7\u5b9e\u73b0\u4e3b\u8981\u7ec4\u4ef6\u4e3a\u6613\u66ff\u6362\u7684\u51fd\u6570\uff0c\u589e\u5f3a\u4e86\u5176\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u63d0\u51fa\u4e86GRainsaCK\u8f6f\u4ef6\u8d44\u6e90\uff0c\u80fd\u591f\u7edf\u4e00\u8bc4\u4f30\u534f\u8bae\u5e76\u7b80\u5316\u89e3\u91ca\u8bc4\u4f30\u4efb\u52a1\uff0c\u63d0\u9ad8\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86GRainsaCK\uff0c\u4e00\u4e2a\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u8f6f\u4ef6\u8d44\u6e90\uff0c\u7528\u4e8e\u5b8c\u5168\u7b80\u5316\u4e0e\u89e3\u91ca\u8bc4\u4f30\u76f8\u5173\u7684\u5404\u9879\u4efb\u52a1\uff0c\u4ece\u6a21\u578b\u8bad\u7ec3\u5230\u89e3\u91ca\u8bc4\u4f30\uff0c\u7edf\u4e00\u8bc4\u4f30\u534f\u8bae\u3002\u901a\u8fc7\u5c06\u4e3b\u8981\u7ec4\u4ef6\u5b9e\u73b0\u4e3a\u6613\u66ff\u6362\u7684\u51fd\u6570\uff0cGRainsaCK\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002\u6700\u540e\uff0c\u4e3a\u4fc3\u8fdb\u5176\u91cd\u590d\u4f7f\u7528\uff0c\u63d0\u4f9b\u4e86\u8be6\u5c3d\u7684\u6587\u6863\uff0c\u5305\u62ec\u6559\u7a0b\u3002"}}
{"id": "2508.08816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08816", "abs": "https://arxiv.org/abs/2508.08816", "authors": ["Yuechen Wang", "Yuming Qiao", "Dan Meng", "Jun Yang", "Haonan Lu", "Zhenyu Yang", "Xudong Zhang"], "title": "Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation", "comment": null, "summary": "Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising\nsolution to address the temporal limitations of Multimodal Large Language\nModels (MLLMs) in real-world scenarios like news analysis and trending topics.\nHowever, existing approaches often suffer from rigid retrieval strategies and\nunder-utilization of visual information. To bridge this gap, we propose\nE-Agent, an agent framework featuring two key innovations: a mRAG planner\ntrained to dynamically orchestrate multimodal tools based on contextual\nreasoning, and a task executor employing tool-aware execution sequencing to\nimplement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning\nstrategy that enables efficient information retrieval while minimizing\nredundant tool invocations. To rigorously assess the planning capabilities of\nmRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark.\nThis novel benchmark contains both retrieval-dependent and\nretrieval-independent question types, systematically annotated with essential\nretrieval tools required for each instance. The benchmark's explicit mRAG\nplanning annotations and diverse question design enhance its practical\nrelevance by simulating real-world scenarios requiring dynamic mRAG decisions.\nExperiments across RemPlan and three established benchmarks demonstrate\nE-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods\nwhile reducing redundant searches by 37%.", "AI": {"tldr": "E-Agent introduces innovative mRAG planning and execution strategies, outperforming existing methods by 13% in accuracy and reducing redundant searches by 37% according to experiments on the RemPlan benchmark.", "motivation": "To address the limitations of existing multimodal retrieval-augmented generation (mRAG) systems in real-world scenarios like news analysis and trending topics, focusing on overcoming rigid retrieval strategies and under-utilization of visual information.", "method": "The paper proposes E-Agent, an agent framework with a mRAG planner and task executor for optimized workflows. It introduces the Real-World mRAG Planning (RemPlan) benchmark to evaluate planning capabilities.", "result": "E-Agent outperforms state-of-the-art mRAG methods in experiments across RemPlan and established benchmarks, showcasing its effectiveness.", "conclusion": "E-Agent demonstrates superior performance in mRAG systems, achieving a 13% accuracy gain over existing methods and reducing redundant searches by 37%."}}
{"id": "2508.08830", "categories": ["cs.AI", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.08830", "abs": "https://arxiv.org/abs/2508.08830", "authors": ["Mustafa Akben", "Vinayaka Gude", "Haya Ajjan"], "title": "Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition", "comment": null, "summary": "The ability to discern subtle emotional cues is fundamental to human social\nintelligence. As artificial intelligence (AI) becomes increasingly common, AI's\nability to recognize and respond to human emotions is crucial for effective\nhuman-AI interactions. In particular, whether such systems can match or surpass\nhuman experts remains to be seen. However, the emotional intelligence of AI,\nparticularly multimodal large language models (MLLMs), remains largely\nunexplored. This study evaluates the emotion recognition abilities of MLLMs\nusing the Reading the Mind in the Eyes Test (RMET) and its multiracial\ncounterpart (MRMET), and compares their performance against human participants.\nResults show that, on average, MLLMs outperform humans in accurately\nidentifying emotions across both tests. This trend persists even when comparing\nperformance across low, medium, and expert-level performing groups. Yet when we\naggregate independent human decisions to simulate collective intelligence,\nhuman groups significantly surpass the performance of aggregated MLLM\npredictions, highlighting the wisdom of the crowd. Moreover, a collaborative\napproach (augmented intelligence) that combines human and MLLM predictions\nachieves greater accuracy than either humans or MLLMs alone. These results\nsuggest that while MLLMs exhibit strong emotion recognition at the individual\nlevel, the collective intelligence of humans and the synergistic potential of\nhuman-AI collaboration offer the most promising path toward effective emotional\nAI. We discuss the implications of these findings for the development of\nemotionally intelligent AI systems and future research directions.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86MLLMs\u5728\u60c5\u7eea\u8bc6\u522b\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0MLLMs\u5728\u4e2a\u4f53\u6c34\u5e73\u4e0a\u4f18\u4e8e\u4eba\u7c7b\uff0c\u4f46\u4eba\u7c7b\u56e2\u4f53\u5728\u96c6\u4f53\u667a\u6167\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u7ed3\u5408\u4eba\u7c7b\u548cMLLM\u9884\u6d4b\u7684\u534f\u4f5c\u65b9\u6cd5\u6548\u679c\u6700\u4f73\uff0c\u4e3a\u6709\u6548\u60c5\u611f\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u8def\u5f84\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u8d8a\u6765\u8d8a\u666e\u904d\uff0cAI\u8bc6\u522b\u548c\u56de\u5e94\u4eba\u7c7b\u60c5\u7eea\u5bf9\u6709\u6548\u7684\u4eba\u673a\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0cMLLMs\u7684\u60c5\u611f\u667a\u80fd\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u63a2\u8ba8\u4eba\u7c7b\u548cAI\u534f\u4f5c\u5728\u60c5\u611f\u8bc6\u522b\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86MLLMs\u5728Reading the Mind in the Eyes Test\uff08RMET\uff09\u53ca\u5176\u591a\u5143\u79cd\u65cf\u5bf9\u5e94\u7269\uff08MRMET\uff09\u4e0a\u7684\u60c5\u7eea\u8bc6\u522b\u80fd\u529b\uff0c\u5e76\u5c06\u5176\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7814\u7a76\u91c7\u7528\u4e86\u805a\u5408\u72ec\u7acb\u4eba\u7c7b\u51b3\u7b56\u4ee5\u6a21\u62df\u96c6\u4f53\u667a\u6167\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u4eba\u7c7b\u56e2\u4f53\u663e\u8457\u8d85\u8d8a\u4e86\u805a\u5408MLLM\u9884\u6d4b\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u7ed3\u5408\u4eba\u7c7b\u548cMLLM\u9884\u6d4b\u7684\u534f\u4f5c\u65b9\u6cd5\uff08\u589e\u5f3a\u667a\u80fd\uff09\u5b9e\u73b0\u4e86\u6bd4\u5355\u72ec\u4eba\u7c7b\u6216MLLM\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cMLLMs\u5e73\u5747\u800c\u8a00\u5728\u4e24\u9879\u6d4b\u8bd5\u4e2d\u51c6\u786e\u8bc6\u522b\u60c5\u7eea\u7684\u80fd\u529b\u8d85\u8fc7\u4e86\u4eba\u7c7b\u3002\u7136\u800c\uff0c\u901a\u8fc7\u805a\u5408\u72ec\u7acb\u4eba\u7c7b\u51b3\u7b56\uff0c\u4eba\u7c7b\u56e2\u4f53\u5728\u6027\u80fd\u4e0a\u663e\u8457\u8d85\u8d8a\u4e86\u805a\u5408MLLM\u9884\u6d4b\u3002\u4eba\u7c7b\u548cMLLM\u5408\u4f5c\u7684\u534f\u4f5c\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6bd4\u5355\u72ec\u4eba\u7c7b\u6216MLLM\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136\u591a\u6a21\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u4e2a\u4f53\u6c34\u5e73\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u60c5\u7eea\u8bc6\u522b\u80fd\u529b\uff0c\u4f46\u4eba\u7c7b\u56e2\u4f53\u7684\u96c6\u4f53\u667a\u6167\u548c\u4eba\u5de5\u667a\u80fd\u534f\u4f5c\u7684\u534f\u540c\u6f5c\u529b\u63d0\u4f9b\u4e86\u901a\u5f80\u6709\u6548\u60c5\u611f\u4eba\u5de5\u667a\u80fd\u7684\u6700\u6709\u5e0c\u671b\u7684\u9014\u5f84\u3002"}}
{"id": "2508.08882", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08882", "abs": "https://arxiv.org/abs/2508.08882", "authors": ["Dayu Wang", "Jiaye Yang", "Weikang Li", "Jiahui Liang", "Yang Li"], "title": "Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation", "comment": null, "summary": "Current tool-integrated mathematical reasoning systems often adopt a\nsingle-agent paradigm, where one large language model handles problem\nreasoning, code generation, and code execution in an integrated workflow. While\nthis design eases coordination, we hypothesize that it imposes cognitive load\ninterference, as the agent must interleave long-horizon reasoning with precise\nprogram synthesis. We validate this hypothesis through a controlled comparison\nbetween a reasoning-only agent and a reasoning-plus-code agent, finding that\nthe latter produces significantly fewer correct reasoning paths despite having\ntool-calling capabilities. To address this, we propose a dual-agent hybrid\nframework: a Reasoning Agent performs stepwise problem decomposition, and a\nCode Agent handles code generation and execution. Training combines imitation\nlearning and reinforcement learning: the Code Agent receives strong rewards for\nmatching intermediate ground-truth programs and weaker rewards for valid\nexecution, while the Reasoning Agent is optimized chiefly via final-answer\naccuracy using advantage estimation to credit intermediate steps. This\ndecoupled role design reduces cognitive interference and promotes stable\nreasoning-coding coordination.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f53\u524d\u5de5\u5177\u7efc\u5408\u6570\u5b66\u63a8\u7406\u7cfb\u7edf\u4e2d\u5355\u4e00\u4ee3\u7406\u548c\u53cc\u4ee3\u7406\u6df7\u5408\u6846\u67b6\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u63d0\u51fa\u4e86\u53cc\u4ee3\u7406\u6846\u67b6\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u8ba4\u77e5\u5e72\u6270\uff0c\u4fc3\u8fdb\u7a33\u5b9a\u7684\u63a8\u7406\u7f16\u7801\u534f\u8c03\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u4f5c\u8005\u89c2\u5bdf\u5230\u5f53\u524d\u5de5\u5177\u7efc\u5408\u6570\u5b66\u63a8\u7406\u7cfb\u7edf\u5728\u95ee\u9898\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u548c\u4ee3\u7801\u6267\u884c\u65b9\u9762\u91c7\u7528\u5355\u4e00\u4ee3\u7406\u8303\u5f0f\u65f6\uff0c\u5b58\u5728\u8ba4\u77e5\u8d1f\u8377\u5e72\u6270\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u91c7\u7528\u53cc\u4ee3\u7406\u6df7\u5408\u6846\u67b6\u7684\u8bbe\u8ba1\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5bf9\u6bd4\u7814\u7a76\u8bc1\u5b9e\u4e86\u5355\u4e00\u4ee3\u7406\u548c\u53cc\u4ee3\u7406\u6df7\u5408\u6846\u67b6\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u63d0\u51fa\u4e86\u91c7\u7528\u53cc\u4ee3\u7406\u6846\u67b6\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u6a21\u4eff\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u3002\u901a\u8fc7\u7ed9\u4e88\u4ee3\u7801\u4ee3\u7406\u5339\u914d\u4e2d\u95f4\u771f\u5b9e\u7a0b\u5e8f\u7684\u5f3a\u5956\u52b1\u548c\u6709\u6548\u6267\u884c\u7684\u5f31\u5956\u52b1\uff0c\u4ee5\u53ca\u901a\u8fc7\u4f18\u52bf\u4f30\u8ba1\u6765\u8bc4\u4f30\u4e2d\u95f4\u6b65\u9aa4\u7684\u63a8\u7406\u4ee3\u7406\uff0c\u6765\u51cf\u5c11\u8ba4\u77e5\u5e72\u6270\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u7814\u7a76\u53d1\u73b0\uff0c\u53cc\u4ee3\u7406\u6df7\u5408\u6846\u67b6\u76f8\u8f83\u4e8e\u5355\u4e00\u4ee3\u7406\u5728\u6b63\u786e\u63a8\u7406\u8def\u5f84\u7684\u751f\u6210\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u672c\u6587\u8bf4\u660e\u5f53\u524d\u5de5\u5177\u7efc\u5408\u6570\u5b66\u63a8\u7406\u7cfb\u7edf\u5f80\u5f80\u91c7\u7528\u5355\u4e00\u4ee3\u7406\u8303\u5f0f\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u53cc\u4ee3\u7406\u6df7\u5408\u6846\u67b6\uff0c\u5176\u4e2d\u4e00\u4e2a\u63a8\u7406\u4ee3\u7406\u8d1f\u8d23\u95ee\u9898\u5206\u89e3\uff0c\u53e6\u4e00\u4e2a\u4ee3\u7801\u4ee3\u7406\u8d1f\u8d23\u4ee3\u7801\u751f\u6210\u548c\u6267\u884c\u3002\u8bad\u7ec3\u7ed3\u5408\u4e86\u6a21\u4eff\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u3002\u901a\u8fc7\u51cf\u5c11\u8ba4\u77e5\u5e72\u6270\u548c\u4fc3\u8fdb\u7a33\u5b9a\u7684\u63a8\u7406\u7f16\u7801\u534f\u8c03\uff0c\u8fd9\u79cd\u5206\u79bb\u89d2\u8272\u8bbe\u8ba1\u63d0\u9ad8\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.08909", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08909", "abs": "https://arxiv.org/abs/2508.08909", "authors": ["Anxiang Zeng", "Haibo Zhang", "Kaixiang Mo", "Long Zhang", "Shuman Liu", "Yanhui Huang", "Yawen Liu", "Yuepeng Sheng", "Yuwei Huang"], "title": "Compass-Thinker-7B Technical Report", "comment": null, "summary": "Recent R1-Zero-like research further demonstrates that reasoning extension\nhas given large language models (LLMs) unprecedented reasoning capabilities,\nand Reinforcement Learning is the core technology to elicit its complex\nreasoning. However, conducting RL experiments directly on hyperscale models\ninvolves high computational costs and resource demands, posing significant\nrisks. We propose the Compass-Thinker-7B model, which aims to explore the\npotential of Reinforcement Learning with less computational resources and\ncosts, and provides insights for further research into RL recipes for larger\nmodels. Compass-Thinker-7B is trained from an open source model through a\nspecially designed Reinforcement Learning Pipeline. we curate a dataset of 30k\nverifiable mathematics problems for the Reinforcement Learning Pipeline. By\nconfiguring data and training settings with different difficulty distributions\nfor different stages, the potential of the model is gradually released and the\ntraining efficiency is improved. Extensive evaluations show that\nCompass-Thinker-7B possesses exceptional reasoning potential, and achieves\nsuperior performance on mathematics compared to the same-sized RL\nmodel.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B\nachieves 40% accuracy.", "AI": {"tldr": "Compass-Thinker-7B model is introduced to explore Reinforcement Learning potential efficiently with reduced resources. It outperforms same-sized RL models in mathematics tasks, achieving 40% accuracy in a challenging evaluation, showcasing exceptional reasoning potential.", "motivation": "Addressed the high computational costs and resource demands of conducting RL experiments on hyperscale models by proposing a model that aims to explore RL capabilities with fewer resources. Provides insights for further research into RL applications for larger models.", "method": "Proposed the Compass-Thinker-7B model to explore Reinforcement Learning potential with reduced computational resources and costs, trained from an open-source model using a specially designed Reinforcement Learning Pipeline, and curated a dataset of 30k verifiable mathematics problems for training. Configured data and training settings with varying difficulty distributions to gradually release the model's potential and improve training efficiency.", "result": "Extensive evaluations demonstrate that Compass-Thinker-7B possesses exceptional reasoning potential and excels in mathematics tasks, achieving superior performance compared to the same-sized RL model, particularly achieving 40% accuracy in the challenging AIME2024 evaluation.", "conclusion": "Compass-Thinker-7B model demonstrates exceptional reasoning potential and outperforms the same-sized RL model in mathematics tasks, achieving 40% accuracy in a challenging evaluation."}}
{"id": "2508.08926", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08926", "abs": "https://arxiv.org/abs/2508.08926", "authors": ["Wei Cai", "Jian Zhao", "Yuchu Jiang", "Tianle Zhang", "Xuelong Li"], "title": "Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models", "comment": null, "summary": "Large Vision-Language Models face growing safety challenges with multimodal\ninputs. This paper introduces the concept of Implicit Reasoning Safety, a\nvulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due\nto flawed or hidden reasoning. To showcase this, we developed Safe Semantics,\nUnsafe Interpretations, the first dataset for this critical issue. Our\ndemonstrations show that even simple In-Context Learning with SSUI\nsignificantly mitigates these implicit multimodal threats, underscoring the\nurgent need to improve cross-modal implicit reasoning.", "AI": {"tldr": "Large Vision-Language Models are vulnerable to Implicit Reasoning Safety issues that lead to unsafe outputs. The paper introduces Safe Semantics, Unsafe Interpretations dataset and shows the effectiveness of In-Context Learning with SSUI in mitigating these threats.", "motivation": "Address the safety challenges faced by Large Vision-Language Models (LVLMs) with multimodal inputs, specifically focusing on Implicit Reasoning Safety and unsafe outputs triggered by combined inputs.", "method": "Developed Safe Semantics, Unsafe Interpretations dataset to showcase Implicit Reasoning Safety in LVLMs. Demonstrated the effectiveness of In-Context Learning with SSUI in mitigating implicit multimodal threats.", "result": "Demonstrated the urgent need to enhance cross-modal implicit reasoning in LVLMs through the development of Safe Semantics, Unsafe Interpretations dataset and the implementation of In-Context Learning with SSUI.", "conclusion": "LVLMs face safety challenges due to Implicit Reasoning Safety, which can lead to unsafe outputs. In-Context Learning with Safe Semantics and SSUI can mitigate these threats."}}
{"id": "2508.08992", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08992", "abs": "https://arxiv.org/abs/2508.08992", "authors": ["Rui Wang", "Qihan Lin", "Jiayu Liu", "Qing Zong", "Tianshi Zheng", "Weiqi Wang", "Yangqiu Song"], "title": "Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty", "comment": null, "summary": "Prospect Theory (PT) models human decision-making under uncertainty, while\nepistemic markers (e.g., maybe) serve to express uncertainty in language.\nHowever, it remains largely unexplored whether Prospect Theory applies to\ncontemporary Large Language Models and whether epistemic markers, which express\nhuman uncertainty, affect their decision-making behaviour. To address these\nresearch gaps, we design a three-stage experiment based on economic\nquestionnaires. We propose a more general and precise evaluation framework to\nmodel LLMs' decision-making behaviour under PT, introducing uncertainty through\nthe empirical probability values associated with commonly used epistemic\nmarkers in comparable contexts. We then incorporate epistemic markers into the\nevaluation framework based on their corresponding probability values to examine\ntheir influence on LLM decision-making behaviours. Our findings suggest that\nmodelling LLMs' decision-making with PT is not consistently reliable,\nparticularly when uncertainty is expressed in diverse linguistic forms. Our\ncode is released in https://github.com/HKUST-KnowComp/MarPT.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u524d\u666f\u7406\u8bba\u5728\u5f53\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u4ee5\u53ca\u8ba4\u8bc6\u6807\u8bb0\u5bf9\u5b83\u4eec\u7684\u51b3\u7b56\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u5b9e\u9a8c\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0PT\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u5f62\u5f0f\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u65f6\u5e76\u4e0d\u59cb\u7ec8\u53ef\u9760\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u63a2\u8ba8\u524d\u666f\u7406\u8bba\u662f\u5426\u9002\u7528\u4e8e\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u53ca\u8868\u8fbe\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u7684\u8ba4\u8bc6\u6807\u8bb0\u662f\u5426\u5f71\u54cd\u5b83\u4eec\u7684\u51b3\u7b56\u884c\u4e3a\u3002\u4e3a\u586b\u8865\u8fd9\u4e9b\u7814\u7a76\u7a7a\u767d\uff0c\u8bbe\u8ba1\u4e86\u5b9e\u9a8c\u6765\u63a2\u7a76LLMs\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u5e76\u5f15\u5165\u8ba4\u8bc6\u6807\u8bb0\u6765\u6a21\u62df\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ecf\u6d4e\u95ee\u5377\u7684\u4e09\u9636\u6bb5\u5b9e\u9a8c\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u4e00\u822c\u548c\u7cbe\u786e\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6a21\u62dfLLMs\u5728PT\u4e0b\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u5728\u53ef\u6bd4\u8f83\u4e0a\u4e0b\u6587\u4e2d\u5e38\u7528\u7684\u8ba4\u8bc6\u6807\u8bb0\u7684\u7ecf\u9a8c\u6982\u7387\u503c\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u3002\u7136\u540e\u6839\u636e\u76f8\u5e94\u7684\u6982\u7387\u503c\u5c06\u8ba4\u8bc6\u6807\u8bb0\u7eb3\u5165\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u68c0\u9a8c\u5b83\u4eec\u5bf9LLMs\u51b3\u7b56\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f7f\u7528\u4e0d\u540c\u8bed\u8a00\u5f62\u5f0f\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528PT\u6a21\u578b\u6765\u89e3\u91caLLMs\u7684\u51b3\u7b56\u884c\u4e3a\u5e76\u4e0d\u59cb\u7ec8\u53ef\u9760\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u524d\u666f\u7406\u8bba\uff08PT\uff09\u6a21\u578b\u6765\u89e3\u91ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u51b3\u7b56\u884c\u4e3a\u5e76\u4e0d\u59cb\u7ec8\u53ef\u9760\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u8bed\u8a00\u5f62\u5f0f\u8868\u8fbe\u7684\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2508.08997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08997", "abs": "https://arxiv.org/abs/2508.08997", "authors": ["Sizhe Yuen", "Francisco Gomez Medina", "Ting Su", "Yali Du", "Adam J. Sobey"], "title": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory", "comment": null, "summary": "Multi-agent systems built on Large Language Models (LLMs) show exceptional\npromise for complex collaborative problem-solving, yet they face fundamental\nchallenges stemming from context window limitations that impair memory\nconsistency, role adherence, and procedural integrity. This paper introduces\nIntrinsic Memory Agents, a novel framework that addresses these limitations\nthrough structured agent-specific memories that evolve intrinsically with agent\noutputs. Specifically, our method maintains role-aligned memory templates that\npreserve specialized perspectives while focusing on task-relevant information.\nWe benchmark our approach on the PDDL dataset, comparing its performance to\nexisting state-of-the-art multi-agentic memory approaches and showing an\nimprovement of 38.6\\% with the highest token efficiency. An additional\nevaluation is performed on a complex data pipeline design task, we demonstrate\nthat our approach produces higher quality designs when comparing 5 metrics:\nscalability, reliability, usability, cost-effectiveness and documentation with\nadditional qualitative evidence of the improvements. Our findings suggest that\naddressing memory limitations through structured, intrinsic approaches can\nimprove the capabilities of multi-agent LLM systems on structured planning\ntasks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u5185\u5728\u8bb0\u5fc6\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u9488\u5bf9\u591aAgent\u7cfb\u7edf\u4e2d\u57fa\u4e8eLLMs\u7684\u6311\u6218\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u7ef4\u62a4\u89d2\u8272\u5bf9\u9f50\u7684\u8bb0\u5fc6\u6a21\u677f\uff0c\u4e13\u6ce8\u4e8e\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff0c\u8be5\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u89c4\u5212\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u5e76\u5728\u6570\u636e\u7ba1\u9053\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u4ea7\u751f\u4e86\u9ad8\u8d28\u91cf\u8bbe\u8ba1\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5185\u5728\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u591aAgent LLM\u7cfb\u7edf\u5728\u7ed3\u6784\u5316\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u52a8\u673a\uff1a\u591aAgent\u7cfb\u7edf\u5728\u534f\u540c\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u7b49\u6311\u6218\u3002\u63d0\u51fa\u8fd9\u4e00\u5185\u5728\u8bb0\u5fc6\u4ee3\u7406\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u4ee3\u7406\u7279\u5b9a\u8bb0\u5fc6\u4e0eAgent\u8f93\u51fa\u5185\u5728\u6f14\u53d8\uff0c\u4ece\u800c\u6539\u5584\u8bb0\u5fc6\u4e00\u81f4\u6027\u3001\u89d2\u8272\u9075\u4ece\u548c\u7a0b\u5e8f\u5b8c\u6574\u6027\u3002", "method": "\u65b9\u6cd5\uff1a\u672c\u6587\u63d0\u51fa\u7684\u5185\u5728\u8bb0\u5fc6\u4ee3\u7406\u6846\u67b6\u901a\u8fc7 agent-specific \u8bb0\u5fc6\uff0c\u4fdd\u7559\u4e13\u4e1a\u89c6\u89d2\u7684\u5bf9\u9f50\u8bb0\u5fc6\u6a21\u677f\uff0c\u540c\u65f6\u4e13\u6ce8\u4e8e\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u3002\u5728PDDL\u6570\u636e\u96c6\u4e0a\u5bf9\u8be5\u65b9\u6cd5\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u6bd4\u8f83\u4e86\u5176\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5728\u590d\u6742\u6570\u636e\u7ba1\u9053\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u989d\u5916\u8bc4\u4f30\uff0c\u5e76\u5c55\u793a\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u57285\u4e2a\u6307\u6807\u4e0a\u7684\u6539\u8fdb\uff1a\u53ef\u4f38\u7f29\u6027\u3001\u53ef\u9760\u6027\u3001\u53ef\u7528\u6027\u3001\u6210\u672c\u6548\u76ca\u548c\u6587\u6863\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u989d\u5916\u5b9a\u6027\u8bc1\u636e\u3002", "result": "\u7ed3\u679c\uff1a\u901a\u8fc7\u5728PDDL\u6570\u636e\u96c6\u548c\u590d\u6742\u6570\u636e\u7ba1\u9053\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u8fdb\u884c\u7684\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u5185\u5728\u8bb0\u5fc6\u4ee3\u7406\u6846\u67b6\u7684\u4f18\u8d8a\u6027\u80fd\u3002\u5728\u591aAgent LLM\u7cfb\u7edf\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u591aAgent\u8bb0\u5fc6\u65b9\u6cd5\u63d0\u9ad8\u4e8638.6%\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5177\u6709\u6700\u9ad8\u7684\u4ee4\u724c\u6548\u7387\u3002", "conclusion": "\u7ed3\u8bba\uff1a\u901a\u8fc7\u5f15\u5165\u5185\u5728\u8bb0\u5fc6\u4ee3\u7406\u8fd9\u4e00\u65b0\u9896\u6846\u67b6\uff0c\u672c\u6587\u89e3\u51b3\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u5efa\u7684\u591aAgent\u7cfb\u7edf\u9762\u4e34\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u7b49\u57fa\u672c\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u5728PDDL\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u5f88\u9ad8\u7684\u6027\u80fd\uff0c\u5728\u590d\u6742\u6570\u636e\u7ba1\u9053\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u5c55\u793a\u51fa\u66f4\u9ad8\u8d28\u91cf\u7684\u8bbe\u8ba1\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u5185\u5728\u65b9\u6cd5\u6765\u89e3\u51b3\u8bb0\u5fc6\u9650\u5236\u53ef\u4ee5\u63d0\u9ad8\u591aAgent LLM\u7cfb\u7edf\u5728\u7ed3\u6784\u5316\u89c4\u5212\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u3002"}}
{"id": "2508.09019", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09019", "abs": "https://arxiv.org/abs/2508.09019", "authors": ["Shivam Dubey"], "title": "Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs", "comment": null, "summary": "As large language models (LLMs) become more integrated into societal systems,\nthe risk of them perpetuating and amplifying harmful biases becomes a critical\nsafety concern. Traditional methods for mitigating bias often rely on data\nfiltering or post-hoc output moderation, which treat the model as an opaque\nblack box. In this work, we introduce a complete, end-to-end system that uses\ntechniques from mechanistic interpretability to both identify and actively\nmitigate bias directly within a model's internal workings. Our method involves\ntwo primary stages. First, we train linear \"probes\" on the internal activations\nof a model to detect the latent representations of various biases (e.g.,\ngender, race, age). Our experiments on \\texttt{gpt2-large} demonstrate that\nthese probes can identify biased content with near-perfect accuracy, revealing\nthat bias representations become most salient in the model's later layers.\nSecond, we leverage these findings to compute \"steering vectors\" by contrasting\nthe model's activation patterns for biased and neutral statements. By adding\nthese vectors during inference, we can actively steer the model's generative\nprocess away from producing harmful, stereotypical, or biased content in\nreal-time. We demonstrate the efficacy of this activation steering technique,\nshowing that it successfully alters biased completions toward more neutral\nalternatives. We present our work as a robust and reproducible system that\noffers a more direct and interpretable approach to building safer and more\naccountable LLMs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8bc6\u522b\u548c\u51cf\u8f7b\u504f\u89c1\uff0c\u901a\u8fc7\u8bad\u7ec3\u5185\u90e8\"\u63a2\u9488\"\u6765\u68c0\u6d4b\u5404\u79cd\u504f\u89c1\uff0c\u5e76\u8ba1\u7b97\"\u8f6c\u5411\u5411\u91cf\"\u6765\u4e3b\u52a8\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\uff0c\u907f\u514d\u751f\u6210\u6709\u5bb3\u3001\u523b\u677f\u6216\u6709\u504f\u89c1\u5185\u5bb9\u3002\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u5b89\u5168\u3001\u66f4\u4e2d\u7acb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u793e\u4f1a\u7cfb\u7edf\u4e2d\uff0c\u5b83\u4eec\u6301\u7eed\u548c\u653e\u5927\u6709\u5bb3\u504f\u89c1\u7684\u98ce\u9669\u53d8\u5f97\u6781\u4e3a\u5173\u952e\u3002\u4f20\u7edf\u7684\u51cf\u8f7b\u504f\u89c1\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u6570\u636e\u8fc7\u6ee4\u6216\u4e8b\u540e\u8f93\u51fa\u8c03\u8282\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5c06\u6a21\u578b\u89c6\u4e3a\u4e0d\u900f\u660e\u7684\u9ed1\u5323\u5b50\u3002\u56e0\u6b64\uff0c\u672c\u5de5\u4f5c\u7684\u52a8\u673a\u5728\u4e8e\u5f15\u5165\u4e00\u4e2a\u5b8c\u6574\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u5229\u7528\u673a\u68b0\u89e3\u91ca\u7684\u6280\u672f\u76f4\u63a5\u8bc6\u522b\u548c\u4e3b\u52a8\u51cf\u8f7b\u6a21\u578b\u5185\u90e8\u7684\u504f\u89c1\u3002", "method": "\u672c\u5de5\u4f5c\u9996\u5148\u8bad\u7ec3\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\u7684\u7ebf\u6027\"\u63a2\u9488\"\u6765\u68c0\u6d4b\u5404\u79cd\u504f\u89c1\uff0c\u7136\u540e\u901a\u8fc7\u6bd4\u8f83\u6709\u504f\u89c1\u548c\u4e2d\u7acb\u8bed\u53e5\u7684\u6fc0\u6d3b\u6a21\u5f0f\u6765\u8ba1\u7b97\"\u8f6c\u5411\u5411\u91cf\"\u3002\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6dfb\u52a0\u8fd9\u4e9b\u5411\u91cf\u4ee5\u4e3b\u52a8\u5f15\u5bfc\u6a21\u578b\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u4f7f\u5176\u907f\u514d\u751f\u6210\u6709\u5bb3\u3001\u523b\u677f\u6216\u6709\u504f\u89c1\u5185\u5bb9\u3002\u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u79cd\u6fc0\u6d3b\u5f15\u5bfc\u6280\u672f\u7684\u6709\u6548\u6027\u3002", "result": "\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u5f88\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u80fd\u591f\u51e0\u4e4e\u5b8c\u7f8e\u5730\u8bc6\u522b\u6a21\u578b\u4e2d\u7684\u6709\u504f\u89c1\u5185\u5bb9\uff0c\u5e76\u6210\u529f\u5730\u5c06\u6709\u504f\u89c1\u7684\u751f\u6210\u8f6c\u53d8\u4e3a\u66f4\u4e2d\u7acb\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u4ed6\u4eec\u7684\u6fc0\u6d3b\u5f15\u5bfc\u6280\u672f\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u53ef\u4ee5\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u66f4\u5b89\u5168\u3001\u66f4\u4e2d\u7acb\u7684\u5185\u5bb9\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b8c\u6574\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u5229\u7528\u673a\u68b0\u89e3\u91ca\u7684\u6280\u672f\u6765\u8bc6\u522b\u548c\u4e3b\u52a8\u51cf\u8f7b\u6a21\u578b\u5185\u90e8\u7684\u504f\u89c1\u3002\u4ed6\u4eec\u7684\u65b9\u6cd5\u5305\u62ec\u8bad\u7ec3\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\u7684\u7ebf\u6027\"\u63a2\u9488\"\u6765\u68c0\u6d4b\u5404\u79cd\u504f\u89c1\uff08\u4f8b\u5982\u6027\u522b\u3001\u79cd\u65cf\u3001\u5e74\u9f84\uff09\u7684\u6f5c\u5728\u8868\u5f81\uff0c\u4ee5\u53ca\u901a\u8fc7\u5bf9\u6bd4\u6a21\u578b\u5bf9\u4e8e\u6709\u504f\u89c1\u548c\u4e2d\u7acb\u8bed\u53e5\u7684\u6fc0\u6d3b\u6a21\u5f0f\u6765\u8ba1\u7b97\"\u8f6c\u5411\u5411\u91cf\"\u3002\u901a\u8fc7\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6dfb\u52a0\u8fd9\u4e9b\u5411\u91cf\uff0c\u4ed6\u4eec\u53ef\u4ee5\u4e3b\u52a8\u5f15\u5bfc\u6a21\u578b\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u4f7f\u5176\u8fdc\u79bb\u4ea7\u751f\u6709\u5bb3\u3001\u523b\u677f\u6216\u6709\u504f\u89c1\u5185\u5bb9\u3002\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u79cd\u6fc0\u6d3b\u5f15\u5bfc\u6280\u672f\u7684\u6709\u6548\u6027\uff0c\u6210\u529f\u5730\u5c06\u6709\u504f\u89c1\u7684\u5b8c\u6210\u8f6c\u53d8\u4e3a\u66f4\u4e2d\u7acb\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u56e0\u6b64\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5065\u58ee\u4e14\u53ef\u91cd\u590d\u7684\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u76f4\u63a5\u548c\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u66f4\u5b89\u5168\u548c\u66f4\u8d1f\u8d23\u4efb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002"}}
{"id": "2508.09027", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09027", "abs": "https://arxiv.org/abs/2508.09027", "authors": ["Jie Wang", "Guang Wang"], "title": "A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems", "comment": null, "summary": "Passenger waiting time prediction plays a critical role in enhancing both\nridesharing user experience and platform efficiency. While most existing\nresearch focuses on post-request waiting time prediction with knowing the\nmatched driver information, pre-request waiting time prediction (i.e., before\nsubmitting a ride request and without matching a driver) is also important, as\nit enables passengers to plan their trips more effectively and enhance the\nexperience of both passengers and drivers. However, it has not been fully\nstudied by existing works. In this paper, we take the first step toward\nunderstanding the predictability and explainability of pre-request passenger\nwaiting time in ridesharing systems. Particularly, we conduct an in-depth\ndata-driven study to investigate the impact of demand&supply dynamics on\npassenger waiting time. Based on this analysis and feature engineering, we\npropose FiXGBoost, a novel feature interaction-based XGBoost model designed to\npredict waiting time without knowing the assigned driver information. We\nfurther perform an importance analysis to quantify the contribution of each\nfactor. Experiments on a large-scale real-world ridesharing dataset including\nover 30 million trip records show that our FiXGBoost can achieve a good\nperformance for pre-request passenger waiting time prediction with high\nexplainability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FiXGBoost\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u62fc\u8f66\u7cfb\u7edf\u4e2d\u9884\u6d4b\u4e58\u5ba2\u7684\u8bf7\u6c42\u524d\u7b49\u5f85\u65f6\u95f4\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u826f\u597d\u6027\u80fd\u3002\u7814\u7a76\u4e86\u9700\u6c42\u548c\u4f9b\u7ed9\u52a8\u6001\u5bf9\u7b49\u5f85\u65f6\u95f4\u7684\u5f71\u54cd\uff0c\u5e76\u8fdb\u884c\u4e86\u91cd\u8981\u6027\u5206\u6790\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5927\u591a\u96c6\u4e2d\u5728\u5df2\u5339\u914d\u53f8\u673a\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u8bf7\u6c42\u540e\u7b49\u5f85\u65f6\u95f4\u9884\u6d4b\uff0c\u800c\u672c\u6587\u5173\u6ce8\u4e86\u8bf7\u6c42\u524d\u7b49\u5f85\u65f6\u95f4\u9884\u6d4b\uff0c\u8fd9\u6709\u52a9\u4e8e\u4e58\u5ba2\u66f4\u6709\u6548\u5730\u8ba1\u5212\u884c\u7a0b\uff0c\u63d0\u5347\u4e58\u5ba2\u548c\u53f8\u673a\u7684\u4f53\u9a8c\u3002\u6b64\u524d\u5c1a\u672a\u5b8c\u5168\u88ab\u73b0\u6709\u7814\u7a76\u4f5c\u54c1\u6240\u63a2\u8ba8\u3002", "method": "\u901a\u8fc7\u6df1\u5165\u7684\u6570\u636e\u9a71\u52a8\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u9700\u6c42\u548c\u4f9b\u7ed9\u52a8\u6001\u5bf9\u4e58\u5ba2\u7b49\u5f85\u65f6\u95f4\u7684\u5f71\u54cd\uff0c\u57fa\u4e8e\u5206\u6790\u548c\u7279\u5f81\u5de5\u7a0b\uff0c\u63d0\u51fa\u4e86FiXGBoost\u6a21\u578b\u3002\u8fdb\u4e00\u6b65\u8fdb\u884c\u4e86\u91cd\u8981\u6027\u5206\u6790\uff0c\u91cf\u5316\u4e86\u6bcf\u4e2a\u56e0\u7d20\u7684\u8d21\u732e\u3002", "result": "\u5b9e\u9a8c\u4f7f\u7528\u4e86\u8d85\u8fc73000\u4e07\u6761\u771f\u5b9e\u4e16\u754c\u7684\u62fc\u8f66\u6570\u636e\u96c6\uff0c\u7ed3\u679c\u8868\u660eFiXGBoost\u80fd\u591f\u5728\u8bf7\u6c42\u524d\u9884\u6d4b\u4e58\u5ba2\u7b49\u5f85\u65f6\u95f4\uff0c\u5e76\u5177\u6709\u8f83\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u7279\u5f81\u4ea4\u4e92\u7684XGBoost\u6a21\u578bFiXGBoost\uff0c\u7528\u4e8e\u9884\u6d4b\u4e58\u5ba2\u7b49\u5f85\u65f6\u95f4\uff0c\u8be5\u6a21\u578b\u5728\u4e0d\u77e5\u9053\u5206\u914d\u7684\u53f8\u673a\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u9884\u6d4b\uff0c\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u548c\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.09054", "categories": ["cs.AI", "cs.LG", "68T07, 68T05", "I.2.6; I.5.1; I.5.4"], "pdf": "https://arxiv.org/pdf/2508.09054", "abs": "https://arxiv.org/abs/2508.09054", "authors": ["Debdeep Mukherjee", "Eduardo Di Santi", "Cl\u00e9ment Lefebvre", "Nenad Mijatovic", "Victor Martin", "Thierry Josse", "Jonathan Brown", "Kenza Saiah"], "title": "CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks", "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025\n  (International Conference on Railway Operations Modelling and Analysis),\n  Dresden, Germany. https://tu-dresden.de/raildresden2025 8 pages, 6 figures, 1\n  table", "summary": "Track circuits are critical for railway operations, acting as the main\nsignalling sub-system to locate trains. Continuous Variable Current Modulation\n(CVCM) is one such technology. Like any field-deployed, safety-critical asset,\nit can fail, triggering cascading disruptions. Many failures originate as\nsubtle anomalies that evolve over time, often not visually apparent in\nmonitored signals. Conventional approaches, which rely on clear signal changes,\nstruggle to detect them early. Early identification of failure types is\nessential to improve maintenance planning, minimising downtime and revenue\nloss. Leveraging deep neural networks, we propose a predictive maintenance\nframework that classifies anomalies well before they escalate into failures.\nValidated on 10 CVCM failure cases across different installations, the method\nis ISO-17359 compliant and outperforms conventional techniques, achieving\n99.31% overall accuracy with detection within 1% of anomaly onset. Through\nconformal prediction, we provide uncertainty estimates, reaching 99% confidence\nwith consistent coverage across classes. Given CVCMs global deployment, the\napproach is scalable and adaptable to other track circuits and railway systems,\nenhancing operational reliability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u6846\u67b6\uff0c\u53ef\u4ee5\u5728CVCM\u6545\u969c\u5347\u7ea7\u4e3a\u5931\u6548\u4e4b\u524d\u5bf9\u5f02\u5e38\u8fdb\u884c\u5206\u7c7b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9a8c\u8bc1\u6848\u4f8b\u548c\u7b26\u5408\u6027\u9884\u6d4b\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\uff0c\u5bf9\u63d0\u9ad8\u8fd0\u884c\u53ef\u9760\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u65e9\u671f\u8bc6\u522b\u6545\u969c\u7c7b\u578b\u5bf9\u4e8e\u6539\u5584\u7ef4\u62a4\u89c4\u5212\u3001\u6700\u5c0f\u5316\u505c\u673a\u65f6\u95f4\u548c\u6536\u5165\u635f\u5931\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u660e\u663e\u7684\u4fe1\u53f7\u53d8\u5316\uff0c\u5f88\u96be\u53ca\u65e9\u68c0\u6d4b\u5230\u7531\u4e8e\u65f6\u95f4\u6f14\u53d8\u800c\u4e0d\u6613\u5728\u76d1\u63a7\u4fe1\u53f7\u4e2d\u660e\u663e\u770b\u51fa\u7684\u5fae\u5999\u5f02\u5e38\u3002", "method": "\u672c\u6587\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5efa\u7acb\u4e86\u9884\u6d4b\u6027\u7ef4\u62a4\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9CVCM\u5f02\u5e38\u8fdb\u884c\u5206\u7c7b\u3002\u65b9\u6cd5\u901a\u8fc7\u5728\u4e0d\u540c\u5b89\u88c5\u5730\u70b9\u9a8c\u8bc110\u4e2aCVCM\u6545\u969c\u6848\u4f8b\uff0c\u4ee5\u53ca\u7b26\u5408ISO-17359\u6807\u51c6\uff0c\u901a\u8fc7\u7b26\u5408\u6027\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "result": "\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u6846\u67b6\u5728CVCM\u6545\u969c\u5206\u7c7b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u4e8699.31%\u7684\u6574\u4f53\u51c6\u786e\u7387\uff0c\u5728\u5f02\u5e38\u53d1\u751f1%\u4e4b\u5185\u68c0\u6d4b\u3002\u901a\u8fc7\u7b26\u5408\u6027\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u8fbe\u523099%\u7684\u7f6e\u4fe1\u5ea6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u6545\u969c\u5347\u7ea7\u4e3a\u5931\u6548\u4e4b\u524d\u5bf9\u5f02\u5e38\u8fdb\u884c\u5206\u7c7b\u3002\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u5b89\u88c5\u4f4d\u7f6e\u4e0a\u9a8c\u8bc1\u4e8610\u4e2a\u8fde\u7eed\u53d8\u91cf\u7535\u6d41\u8c03\u5236(CVCM)\u6545\u969c\u6848\u4f8b\uff0c\u7b26\u5408ISO-17359\u6807\u51c6\uff0c\u4f18\u4e8e\u4f20\u7edf\u6280\u672f\uff0c\u5728\u5f02\u5e38\u53d1\u751f1%\u4e4b\u5185\u68c0\u6d4b\u7cbe\u5ea6\u8fbe\u523099.31%\u3002\u901a\u8fc7\u7b26\u5408\u6027\u9884\u6d4b\uff0c\u63d0\u4f9b\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5728\u4e0d\u540c\u7c7b\u522b\u4e2d\u5b9e\u73b0\u4e8699%\u7684\u7f6e\u4fe1\u5ea6\u3002\u7531\u4e8eCVCM\u5728\u5168\u7403\u8303\u56f4\u5185\u90e8\u7f72\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u53ef\u9002\u7528\u4e8e\u5176\u4ed6\u8f68\u9053\u7535\u8def\u548c\u94c1\u8def\u7cfb\u7edf\uff0c\u63d0\u9ad8\u4e86\u8fd0\u884c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09105", "abs": "https://arxiv.org/abs/2508.09105", "authors": ["Shixuan Sun", "Siyuan Liang", "Ruoyu Chen", "Jianjie Huang", "Jingzhi Li", "Xiaochun Cao"], "title": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented\nGeneration (MRAG) significantly improve the knowledge coverage and contextual\nunderstanding of Large Language Models (LLMs) by introducing external knowledge\nsources. However, retrieval and multimodal fusion obscure content provenance,\nrendering existing membership inference methods unable to reliably attribute\ngenerated outputs to pre-training, external retrieval, or user input, thus\nundermining privacy leakage accountability\n  To address these challenges, we propose the first Source-aware Membership\nAudit (SMA) that enables fine-grained source attribution of generated content\nin a semi-black-box setting with retrieval control capabilities.To address the\nenvironmental constraints of semi-black-box auditing, we further design an\nattribution estimation mechanism based on zero-order optimization, which\nrobustly approximates the true influence of input tokens on the output through\nlarge-scale perturbation sampling and ridge regression modeling. In addition,\nSMA introduces a cross-modal attribution technique that projects image inputs\ninto textual descriptions via MLLMs, enabling token-level attribution in the\ntext modality, which for the first time facilitates membership inference on\nimage retrieval traces in MRAG systems. This work shifts the focus of\nmembership inference from 'whether the data has been memorized' to 'where the\ncontent is sourced from', offering a novel perspective for auditing data\nprovenance in complex generative systems.", "AI": {"tldr": "RAG \u548c MRAG \u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u8986\u76d6\u6027\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u5185\u5bb9\u6765\u6e90\u4e0d\u660e\u786e\uff0c\u672c\u6587\u63d0\u51fa\u4e86 SMA \u65b9\u6cd5\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u534a\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u5bf9\u751f\u6210\u5185\u5bb9\u8fdb\u884c\u6765\u6e90\u5f52\u56e0\uff0c\u5e76\u901a\u8fc7\u96f6\u9636\u4f18\u5316\u548c\u8de8\u6a21\u6001\u5f52\u56e0\u6280\u672f\u5b9e\u73b0\u4e86\u65b0\u7684\u6570\u636e\u5ba1\u8ba1\u89c6\u89d2\u3002", "motivation": "\u5f53\u524d\u7684 RAG \u548c MRAG \u65b9\u6cd5\u867d\u7136\u6539\u5584\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u8986\u76d6\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u4f46\u4e0d\u540c\u6765\u6e90\u7684\u5185\u5bb9\u4f1a\u6a21\u7cca\u4e0d\u6e05\uff0c\u73b0\u6709\u7684\u4f1a\u5458\u63a8\u7406\u65b9\u6cd5\u65e0\u6cd5\u53ef\u9760\u5730\u5c06\u751f\u6210\u7684\u8f93\u51fa\u5f52\u56e0\u4e8e\u9884\u8bad\u7ec3\u3001\u5916\u90e8\u68c0\u7d22\u6216\u7528\u6237\u8f93\u5165\uff0c\u5f71\u54cd\u4e86\u9690\u79c1\u6cc4\u6f0f\u7684\u53ef\u8ffd\u6eaf\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86Source-aware Membership Audit (SMA)\u65b9\u6cd5\uff0c\u901a\u8fc7\u96f6\u9636\u4f18\u5316\u8bbe\u8ba1\u5f52\u56e0\u4f30\u8ba1\u673a\u5236\uff0c\u5e76\u5f15\u5165\u4e86\u8de8\u6a21\u6001\u5f52\u56e0\u6280\u672f\u3002", "result": "\u8bba\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u80fd\u591f\u5728\u534a\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u751f\u6210\u5185\u5bb9\u6765\u6e90\u7ec6\u7c92\u5ea6\u5f52\u56e0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u96f6\u9636\u4f18\u5316\u8bbe\u8ba1\u5f52\u56e0\u4f30\u8ba1\u673a\u5236\u548c\u8de8\u6a21\u6001\u5f52\u56e0\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u6765\u6e90\u7684\u65b0\u89c6\u89d2\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u6e90\u7684\u4f1a\u5458\u5ba1\u8ba1\uff08SMA\uff09\uff0c\u5b9e\u73b0\u4e86\u5bf9\u751f\u6210\u5185\u5bb9\u7684\u7ec6\u7c92\u5ea6\u6765\u6e90\u5f52\u56e0\uff0c\u5728\u534a\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u5177\u6709\u68c0\u7d22\u63a7\u5236\u529f\u80fd\u3002\u901a\u8fc7\u96f6\u9636\u4f18\u5316\u8bbe\u8ba1\u5f52\u56e0\u4f30\u8ba1\u673a\u5236\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u6270\u52a8\u91c7\u6837\u548c\u5cad\u56de\u5f52\u5efa\u6a21\uff0c\u7a33\u5065\u5730\u8fd1\u4f3c\u4e86\u8f93\u5165\u6807\u8bb0\u5bf9\u8f93\u51fa\u7684\u771f\u5b9e\u5f71\u54cd\u3002SMA\u5f15\u5165\u4e86\u4e00\u79cd\u8de8\u6a21\u6001\u5f52\u56e0\u6280\u672f\uff0c\u901a\u8fc7MLLMs\u5c06\u56fe\u50cf\u8f93\u5165\u6295\u5f71\u4e3a\u6587\u672c\u63cf\u8ff0\uff0c\u5b9e\u73b0\u4e86\u6587\u672c\u6a21\u6001\u4e2d\u7684\u6807\u8bb0\u7ea7\u522b\u5f52\u56e0\uff0c\u9996\u6b21\u5728MRAG\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u5bf9\u56fe\u50cf\u68c0\u7d22\u75d5\u8ff9\u7684\u4f1a\u5458\u63a8\u7406\u3002\u8be5\u5de5\u4f5c\u5c06\u4f1a\u5458\u63a8\u65ad\u7684\u7126\u70b9\u4ece\u201c\u6570\u636e\u662f\u5426\u88ab\u8bb0\u5fc6\u201d\u8f6c\u79fb\u5230\u201c\u5185\u5bb9\u7684\u6765\u6e90\u4f55\u5904\u201d\uff0c\u4e3a\u590d\u6742\u751f\u6210\u7cfb\u7edf\u4e2d\u5ba1\u6838\u6570\u636e\u6765\u6e90\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2508.09123", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09123", "abs": "https://arxiv.org/abs/2508.09123", "authors": ["Xinyuan Wang", "Bowen Wang", "Dunjie Lu", "Junlin Yang", "Tianbao Xie", "Junli Wang", "Jiaqi Deng", "Xiaole Guo", "Yiheng Xu", "Chen Henry Wu", "Zhennan Shen", "Zhuokai Li", "Ryan Li", "Xiaochuan Li", "Junda Chen", "Boyuan Zheng", "Peihang Li", "Fangyu Lei", "Ruisheng Cao", "Yeqiao Fu", "Dongchan Shin", "Martin Shin", "Jiarui Hu", "Yuyan Wang", "Jixuan Chen", "Yuxiao Ye", "Danyang Zhang", "Dikang Du", "Hao Hu", "Huarong Chen", "Zaida Zhou", "Yipu Wang", "Heng Wang", "Diyi Yang", "Victor Zhong", "Flood Sung", "Y. Charles", "Zhilin Yang", "Tao Yu"], "title": "OpenCUA: Open Foundations for Computer-Use Agents", "comment": null, "summary": "Vision-language models have demonstrated impressive capabilities as\ncomputer-use agents (CUAs) capable of automating diverse computer tasks. As\ntheir commercial potential grows, critical details of the most capable CUA\nsystems remain closed. As these agents will increasingly mediate digital\ninteractions and execute consequential decisions on our behalf, the research\ncommunity needs access to open CUA frameworks to study their capabilities,\nlimitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive\nopen-source framework for scaling CUA data and foundation models. Our framework\nconsists of: (1) an annotation infrastructure that seamlessly captures human\ncomputer-use demonstrations; (2) AgentNet, the first large-scale computer-use\ntask dataset spanning 3 operating systems and 200+ applications and websites;\n(3) a scalable pipeline that transforms demonstrations into state-action pairs\nwith reflective long Chain-of-Thought reasoning that sustain robust performance\ngains as data scales. Our end-to-end agent models demonstrate strong\nperformance across CUA benchmarks. In particular, OpenCUA-32B achieves an\naverage success rate of 34.8% on OSWorld-Verified, establishing a new\nstate-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA\n(GPT-4o). Further analysis confirms that our approach generalizes well across\ndomains and benefits significantly from increased test-time computation. We\nrelease our annotation tool, datasets, code, and models to build open\nfoundations for further CUA research.", "AI": {"tldr": "\u63d0\u51fa\u4e86OpenCUA\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u89e3\u57fa\u7840\u8bbe\u65bd\u3001AgentNet\u6570\u636e\u96c6\u548c\u53ef\u6269\u5c55\u7684\u6570\u636e\u8f6c\u6362\u7ba1\u9053\uff0c\u5b9e\u73b0\u4e86\u673a\u5668\u4ee3\u7406\u6a21\u578b\u5728CUA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5f3a\u5927\u8868\u73b0\uff0c\u8d85\u8d8a\u4e86OpenAI CUA\uff08GPT-4o\uff09\uff0c\u91ca\u653e\u4e86\u6ce8\u89e3\u5de5\u5177\u3001\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u6a21\u578b\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7684CUA\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u653e\u7684\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u5546\u4e1a\u6f5c\u529b\u589e\u957f\uff0c\u73b0\u6709\u7684\u6700\u4f18\u79c0\u7684CUA\u7cfb\u7edf\u7ec6\u8282\u4ecd\u7136\u5c01\u95ed\uff0c\u7814\u7a76\u793e\u533a\u9700\u8981\u5f00\u653e\u7684CUA\u6846\u67b6\u6765\u7814\u7a76\u5b83\u4eec\u7684\u80fd\u529b\u3001\u9650\u5236\u548c\u98ce\u9669\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e86OpenCUA\u6846\u67b6\uff0c\u4ee5\u4fbf\u4e3a\u8fdb\u4e00\u6b65\u7684CUA\u7814\u7a76\u5efa\u7acb\u5f00\u653e\u7684\u57fa\u7840\u3002", "method": "\u63d0\u51faOpenCUA\u6846\u67b6\uff0c\u5305\u62ec\u6ce8\u89e3\u57fa\u7840\u8bbe\u65bd\u3001AgentNet\u6570\u636e\u96c6\u548c\u53ef\u6269\u5c55\u7684\u6570\u636e\u8f6c\u6362\u7ba1\u9053\u3002\u901a\u8fc7\u957f\u94fe\u5f0f\u7684\u601d\u7ef4\u63a8\u7406\u5c06\u6f14\u793a\u8f6c\u6362\u4e3a\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u5b9e\u73b0\u6570\u636e\u89c4\u6a21\u7684\u589e\u957f\u800c\u6301\u7eed\u5f97\u5230\u5f3a\u5927\u7684\u6027\u80fd\u63d0\u5347\u3002\u6f14\u793a\u7ed3\u679c\u5728CUA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14OpenCUA-32B\u5728OSWorld-Verified\u5e73\u53f0\u4e0a\u8fbe\u5230\u4e8634.8%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u5f00\u6e90\u7684\u6846\u67b6OpenCUA\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u673a\u5668\u4ee3\u7406\u6a21\u578b\u5728CUA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u4e86OpenAI CUA\uff08GPT-4o\uff09\uff0c\u5728OSWorld-Verified\u4e0a\u521b\u9020\u4e86\u65b0\u7684\u6700\u4f73\u6a21\u578b\u3002\u7814\u7a76\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u9886\u57df\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u901a\u8fc7\u589e\u52a0\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u83b7\u5f97\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u91ca\u653e\u4e86\u6ce8\u89e3\u5de5\u5177\u3001\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u6a21\u578b\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7684CUA\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u653e\u7684\u57fa\u7840\u3002", "conclusion": "\u63d0\u51fa\u4e86OpenCUA\uff0c\u4e00\u4e2a\u5168\u9762\u5f00\u6e90\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6269\u5c55CUA\u6570\u636e\u548c\u57fa\u7840\u6a21\u578b\u3002\u901a\u8fc7\u6ce8\u89e3\u57fa\u7840\u8bbe\u65bd\u3001AgentNet\u6570\u636e\u96c6\u548c\u53ef\u6269\u5c55\u7684\u6570\u636e\u8f6c\u6362\u7ba1\u9053\uff0c\u5b9e\u73b0\u4e86\u673a\u5668\u4ee3\u7406\u6a21\u578b\u5728CUA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5f3a\u5927\u8868\u73b0\uff0c\u5c24\u5176\u662fOpenCUA-32B\u5728OSWorld-Verified\u4e0a\u521b\u9020\u4e8634.8%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u8d85\u8d8a\u4e86OpenAI CUA\uff08GPT-4o\uff09\uff0c\u6210\u4e3a\u5f00\u6e90\u6a21\u578b\u4e2d\u7684\u65b0\u7684\u6700\u4f73\u6a21\u578b\u3002\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u9886\u57df\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u589e\u52a0\u65f6\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002\u6700\u7ec8\u91ca\u653e\u4e86\u6ce8\u89e3\u5de5\u5177\u3001\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u6a21\u578b\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7684CUA\u7814\u7a76\u5efa\u7acb\u4e86\u5f00\u653e\u57fa\u7840\u3002"}}
{"id": "2508.09129", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09129", "abs": "https://arxiv.org/abs/2508.09129", "authors": ["Xianghe Pang", "Shuo Tang", "Rui Ye", "Yuwen Du", "Yaxin Du", "Siheng Chen"], "title": "BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair", "comment": null, "summary": "Effective information seeking in the vast and ever-growing digital landscape\nrequires balancing expansive search with strategic reasoning. Current large\nlanguage model (LLM)-based agents struggle to achieve this balance due to\nlimitations in search breadth and reasoning depth, where slow, serial querying\nrestricts coverage of relevant sources and noisy raw inputs disrupt the\ncontinuity of multi-step reasoning. To address these challenges, we propose\nBrowseMaster, a scalable framework built around a programmatically augmented\nplanner-executor agent pair. The planner formulates and adapts search\nstrategies based on task constraints, while the executor conducts efficient,\ntargeted retrieval to supply the planner with concise, relevant evidence. This\ndivision of labor preserves coherent, long-horizon reasoning while sustaining\nbroad and systematic exploration, overcoming the trade-off that limits existing\nagents. Extensive experiments on challenging English and Chinese benchmarks\nshow that BrowseMaster consistently outperforms open-source and proprietary\nbaselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh,\nwhich demonstrates its strong capability in complex, reasoning-heavy\ninformation-seeking tasks at scale.", "AI": {"tldr": "BrowseMaster addresses the challenges of current agents by balancing search and reasoning effectively. It outperforms existing models on English and Chinese benchmarks, demonstrating strong capabilities in complex information-seeking tasks.", "motivation": "Existing large language model-based agents struggle with balancing expansive search and strategic reasoning due to limitations in search breadth and reasoning depth. Slow, serial querying and noisy raw inputs hinder coverage of relevant sources and continuity of multi-step reasoning.", "method": "Proposed BrowseMaster, a framework with a programmatically augmented planner-executor agent pair. The planner formulates search strategies based on task constraints, and the executor conducts efficient retrieval to provide concise, relevant evidence.", "result": "Extensive experiments on English and Chinese benchmarks show BrowseMaster consistently outperforms baseline models, with scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh.", "conclusion": "BrowseMaster outperforms open-source and proprietary baselines, achieving high scores on challenging benchmarks in both English and Chinese, demonstrating strong capability in complex information-seeking tasks."}}
