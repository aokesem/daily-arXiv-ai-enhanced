<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 42]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
*Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 该研究提出了Diligent Learner学习范式，能够高效地学习来自CoT数据，解决了现有方法的失败。通过深度优先搜索和验证者引导，支持回溯。该方法为发展大型推理模型提供了路径，具有可扩展性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT学习方法在复杂推理任务上经常失败，因为相关理论基础仍不完善。为了克服这些问题，该研究旨在提出一种创新的学习范式，能够有效克服CoT学习中的核心障碍，从而实现有效推理系统的构建。

Method: 该研究识别了妨碍有效CoT学习的核心障碍，包括分布漂移、缺乏嵌入式搜索和指数推理成本。引入了Diligent Learner，一种新的学习范式，明确将推理建模为深度优先搜索，并支持在失败时的回溯。研究假设下，证明了Diligent Learner能够高效地学习来自CoT数据，而现有方法则无法做到。

Result: 通过证明Diligent Learner的有效性，该研究为解决从自然数据中训练推理系统所面临的挑战提供了新的思路和方法。

Conclusion: 该研究提出了一种新的学习范式——Diligent Learner，能够高效地从Chain-of-Thought (CoT)数据中学习，而现有的方法无法做到。这一框架为基于自然数据训练的可扩展可靠的推理系统的建设提供了路径，为开发具有强大可解释问题解决能力的大型推理模型（LRM）铺平了道路。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing
the problem-solving capabilities of large language models (LLMs). However, the
theoretical foundations of learning from CoT data remain underdeveloped, and
existing approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement
Learning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --
often fail on complex reasoning tasks. In this work, we identify core obstacles
that hinder effective CoT learning, including distribution drift, lack of
embedded search, and exponential inference costs. We introduce the Diligent
Learner, a new learning paradigm that explicitly models reasoning as a
depth-first search guided by a validator and supports backtracking upon
failure. Under two mild and realistic assumptions, we prove that the Diligent
Learner can efficiently learn from CoT data while existing methods fail to do
so. This framework offers a path toward building scalable and reliable
reasoning systems trained on naturally occurring, incomplete data -- paving the
way for the development of Large Reasoning Models (LRMs) with robust,
interpretable problem-solving abilities.

</details>


### [2] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
*Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski*

Main category: cs.AI

TL;DR: 这篇论文解决了肉类加工公司面临的采购和材料处理优化问题，提出了基于整数线性规划的简单迭代方法，证明了问题的NP难度，并成功找到最优解。实验结果显示算法在真实数据场景下表现良好，快速找到最优解。


<details>
  <summary>Details</summary>
Motivation: 食品生产行业，特别是肉类生产部门面临许多挑战，尤其是近期欧盟能源危机的爆发加剧了这些挑战，材料的高效利用是影响这些公司利润的一个重要因素。本研究旨在解决采购和后续材料加工方面的优化问题，着重关注生产阶段，而非供应链管理。

Method: 本研究基于整数线性规划设计了一个简单的迭代方法，主要集中在生产阶段而非供应链管理，通过使用开源整数线性规划求解器，解决了现实生活中的实例。

Result: 实验结果表明，本算法能够在几秒内找到所有情况下的最优解，使用真实数据进行了验证。

Conclusion: 本研究解决了肉类加工公司面临的采购和材料处理优化问题，提出了一个简单的基于整数线性规划的迭代方法，在使用开源整数线性规划求解器的情况下能够在几秒内找到所有情况下的最优解，证明了两个特定约束条件使得问题是NP难的。

Abstract: The food production industry, especially the meat production sector, faces
many challenges that have even escalated due to the recent outbreak of the
energy crisis in the European Union. Therefore, efficient use of input
materials is an essential aspect affecting the profit of such companies. This
paper addresses an optimization problem concerning the purchase and subsequent
material processing we solved for a meat processing company. Unlike the
majority of existing papers, we do not concentrate on how this problem concerns
supply chain management, but we focus purely on the production stage. The
problem involves the concept of alternative ways of material processing, stock
of material with different expiration dates, and extra constraints widely
neglected in the current literature, namely, the minimum order quantity and the
minimum percentage in alternatives. We prove that each of these two constraints
makes the problem \mbox{$\mathcal{NP}$-hard}, and hence we design a simple
iterative approach based on integer linear programming that allows us to solve
real-life instances even using an open-source integer linear programming
solver. Another advantage of this approach is that it mitigates numerical
issues, caused by the extensive range of data values, we experienced with a
commercial solver. The results obtained using real data from the meat
processing company showed that our algorithm can find the optimum solution in a
few seconds for all considered use cases.

</details>


### [3] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
*Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner*

Main category: cs.AI

TL;DR: 该研究提出了一种利用大型语言模型（LLM）的框架，用于理解和推理驾驶场景。通过双通道情景检索方法，支持已知和未知情景的搜索，实验证明该方法优于基于规则的方法，并且泛化能力良好。


<details>
  <summary>Details</summary>
Motivation: 鉴于ADAS装备车辆数量的增长导致驾驶数据大幅增加，但大多数数据捕获的是常规驾驶行为，识别和理解安全关键边缘情况仍然是一个重大挑战。刹车事件特别能指示潜在的危险情况，促使我们的研究核心问题：车辆为什么刹车？现有方法主要依赖基于规则的启发式来使用预定义条件过滤器检索目标场景。然而，在复杂的城市环境中，这些方法缺乏泛化能力。

Method: 该研究使用了大型语言模型（LLM）作为框架的核心，提出了一种双通道情景检索方法，支持基于类别的已知情景搜索和基于嵌入的未知超出分布（OOD）情景检索。研究还在Argoverse 2 Sensor Dataset上进行了情景标注，以便评估方法的性能。

Result: 实验结果显示，所提出的方法在场景理解和分类方面优于基于规则的基线方法，并且具有良好的泛化能力。研究者还通过在Argoverse 2 Sensor Dataset上的情景标注来评估方法的性能。

Conclusion: 该研究提出了一种新颖的框架，利用大型语言模型（LLM）来理解和推理场景，在情景理解和分类方面取得了良好表现。实验结果表明，该方法优于基于规则的基线方法，并且对OOD场景具有良好的泛化能力。

Abstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase
in driving data, yet most of them capture routine driving behavior. Identifying
and understanding safety-critical corner cases within this vast dataset remains
a significant challenge. Braking events are particularly indicative of
potentially hazardous situations, motivating the central question of our
research: Why does a vehicle brake? Existing approaches primarily rely on
rule-based heuristics to retrieve target scenarios using predefined condition
filters. While effective in simple environments such as highways, these methods
lack generalization in complex urban settings. In this paper, we propose a
novel framework that leverages Large Language Model (LLM) for scenario
understanding and reasoning. Our method bridges the gap between low-level
numerical signals and natural language descriptions, enabling LLM to interpret
and classify driving scenarios. We propose a dual-path scenario retrieval that
supports both category-based search for known scenarios and embedding-based
retrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate
evaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.
Experimental results show that our method outperforms rule-based baselines and
generalizes well to OOD scenarios.

</details>


### [4] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
*Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni*

Main category: cs.AI

TL;DR: 本研究扩展了Differential Attention机制到文本-视觉模型PaliGemma，以减少噪声信息检索和幻觉。不同的注意机制可以被整合到现有模型的微调中，从而提高问答能力。


<details>
  <summary>Details</summary>
Motivation: 小语言模型因其高效和不断增长的功能而受到广泛关注。然而，引入额外的模态，如视觉，可能会加剧由于引入噪声而导致的有限上下文窗口的挑战。先前的研究强调了Transformer注意机制往往过度关注不相关的上下文。因此，本研究旨在评估Differential Attention机制在文本-视觉模型中的效果。

Method: 在PaliGemma 3B模型上使用LoRA进行微调，结合不同的注意力机制，并尝试不同的参数设置和配置。

Result: 通过实验结果表明，Differential Attention机制可以通过微调现有模型来提高噪声信息检索和问答能力。

Conclusion: 本研究扩展了不同注意机制，用于文本-视觉模型PaliGemma，以减少噪声信息的检索和减少幻觉。结果表明，不同的注意力机制可以被适应和整合到现有模型的微调中，以增强噪声信息检索和问答能力。

Abstract: Small language models have gained significant popularity due to their
efficiency and growing capabilities. However, incorporating additional
modalities, such as vision, can exacerbate the challenge of limited context
windows by introducing noise. Recent studies have highlighted that Transformer
attention mechanisms often disproportionately focus on irrelevant contexts. In
this work, we extend the Differential Attention mechanism, originally designed
for text-only models, to the text-vision model PaliGemma. Our aim is to
evaluate its ability to mitigate noisy information retrieval and reduce
hallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,
incorporating Differential Attention, and experimented with various parameter
settings and configurations. We demonstrate that Differential Attention can be
adapted and integrated into the fine-tuning of existing models to enhance noisy
information retrieval and question-answering capabilities.

</details>


### [5] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
*Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot*

Main category: cs.AI

TL;DR: 该论文利用贝叶斯图模型动态分解CTA回报，研究短期趋势、长期趋势和市场贝塔因子的交互作用，揭示不同时间跨度对策略的风险调整绩效的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管有大量关于趋势跟踪的研究，短期与长期趋势系统的相对优劣和交互仍存在争议，本文旨在为该争论添砖加瓦。

Method: 使用贝叶斯图模型动态分解CTA回报，分析短期趋势、长期趋势和市场贝塔因子的相互作用。

Result: 揭示了不同时间跨度对CTA策略风险调整绩效的影响，并为趋势跟踪策略提供了更深入的理解。

Conclusion: 该论文动态地将CTA回报分解为短期趋势、长期趋势和市场贝塔因子，并展示了不同时间跨度对策略的风险调整绩效的影响。

Abstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following
rules that operate on vastly different horizons from long-term breakouts that
capture major directional moves to short-term momentum signals that thrive in
fast-moving markets. Despite a large body of work on trend following, the
relative merits and interactions of short-versus long-term trend systems remain
controversial. This paper adds to the debate by (i) dynamically decomposing CTA
returns into short-term trend, long-term trend and market beta factors using a
Bayesian graphical model, and (ii) showing how the blend of horizons shapes the
strategy's risk-adjusted performance.

</details>


### [6] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
*Simon Ouellette*

Main category: cs.AI

TL;DR: 研究比较了神经程序综合和测试时间微调方法在ARC-AGI领域的表现。结果显示，执行引导的神经程序综合在合成新解决方案方面表现最佳，而TTFT的成功主要源于调用分布内知识。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI是一个开放世界问题领域，对于泛化到分布之外的能力是成功的重要特征。研究的动机在于探讨在这一领域中不同方法的性能表现。

Method: 在ARC-AGI领域运行了一项受控组成泛化实验，比较了神经程序综合和测试时间微调方法。

Result: 执行引导的神经程序综合在合成新解决方案方面胜过所有基准算法。TTFT在ARC-AGI上的成功主要在于调用分布内知识。

Conclusion: 神经程序综合在ARC-AGI领域中的执行引导方式优于所有基准算法，在合成新颖解决方案方面表现更好。实验结果表明，TTFT在ARC-AGI上的成功主要在于调用分布内知识，而LLM无法直接依赖该知识。

Abstract: We run a controlled compositional generalization experiment in the ARC-AGI
domain: an open-world problem domain in which the ability to generalize
out-of-distribution is, by design, an essential characteristic for success. We
compare neural program synthesis and test-time fine-tuning approaches on this
experiment. We find that execution-guided neural program synthesis outperforms
all reference algorithms in its ability to compose novel solutions. Our
empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly
in eliciting in-distribution knowledge that the LLM otherwise fails to rely on
directly.

</details>


### [7] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
*Andy E. Williams*

Main category: cs.AI

TL;DR: 本论文介绍了递归一致性原则（RCP）和功能模型智能（FMI），强调了在推理系统中保持结构一致性的重要性。作者指出没有足够的递归一致性会导致系统在扩展时出现问题，提出FMI作为唯一解决方案。该研究对AI领域的发展具有重要影响，提倡通过结构一致性而非行为约束实现AI的可靠发展。


<details>
  <summary>Details</summary>
Motivation: 作者认为智能（生物、人工或集体）需要在递归推理过程中保持结构一致性才能有效扩展。随着复杂系统的增长，缺乏高阶结构会导致连续性变得脆弱，因此引入RCP以确保语义一致性。

Method: 研究引入了递归一致性原则（RCP）和功能智能模型（FMI），提出了FMI作为唯一符合RCP的操作符。FMI是一个最小、可组合的架构，具有内部功能（评估、建模、适应、稳定性、分解、桥接）和外部功能（存储、回忆、系统1和系统2推理），对于跨推理和协调层保持语义结构至关重要。

Result: 论文提出的递归一致性原则（RCP）及功能智能模型（FMI）阐明了对于保持语义一致性的重要性。作者证明任何缺乏FMI的系统在扩展时会出现递归一致性破裂，认为常见的AI问题是结构一致性丧失的症状。

Conclusion: 该论文介绍了递归一致性原则（RCP），指出在任何N阶的推理系统中，由N-1阶概念空间系统组成，只有通过递归可评估的泛化运算符，才能保持语义一致性。作者推断缺乏FMI的系统在扩展时将经历递归一致性破裂，将常见的AI问题视为结构一致性丧失的症状。RCP独特捕捉了推理系统所需的内部递归动态，有助于建模递归下的语义一致性。该研究对AI的发展产生重大影响，主张从行为约束转向结构一致性，为实现可扩展、强大一致的AI提供了途径。

Abstract: Intelligence-biological, artificial, or collective-requires structural
coherence across recursive reasoning processes to scale effectively. As complex
systems grow, coherence becomes fragile unless a higher-order structure ensures
semantic consistency. This paper introduces the Recursive Coherence Principle
(RCP): a foundational constraint stating that for any reasoning system of order
N, composed of systems operating over conceptual spaces of order N-1, semantic
coherence is preserved only by a recursively evaluable generalization operator
that spans and aligns those lower-order conceptual spaces. Crucially, this
coherence enables structural alignment. Without recursive coherence, no system
can reliably preserve goals, meanings, or reasoning consistency at scale. We
formally define the Functional Model of Intelligence (FMI) as the only known
operator capable of satisfying the RCP at any scale. The FMI is a minimal,
composable architecture with internal functions (evaluation, modeling,
adaptation, stability, decomposition, bridging) and external functions
(storage, recall, System 1 and System 2 reasoning) vital for preserving
semantic structure across inference and coordination layers. We prove that any
system lacking the FMI will experience recursive coherence breakdown as it
scales, arguing that common AI issues like misalignment, hallucination, and
instability are symptoms of this structural coherence loss. Unlike other
foundational principles, RCP uniquely captures the internal, recursive dynamics
needed for coherent, alignable intelligence, modeling semantic coherence under
recursion. This work significantly impacts AI alignment, advocating a shift
from behavioral constraints to structural coherence, and offers a pathway for
safely generalizable, robustly coherent AI at scale.

</details>


### [8] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
*Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe*

Main category: cs.AI

TL;DR: Large language models have led to powerful AI agents integrated into daily life. Current guidance on human-centered AI agent development is scattered. ADEPTS introduces a capability framework to define core user-facing capabilities and provide unified guidance in AI agent development. It aims to enhance understandability, controllability, and trustworthiness in everyday use.


<details>
  <summary>Details</summary>
Motivation: The motivation is to fill the gap in current scattered guidance on human-centered AI agent development. Existing guidelines focus on specific aspects like interface behaviors, internal pipelines, and high-level governance, lacking a concise vocabulary for fundamental user-facing capabilities of AI agents.

Method: The paper introduces ADEPTS, a capability framework based on six principles for human-centered agent design. It aims to address the scattered guidance on human-centered AI agent development by defining user-facing capabilities that AI agents should demonstrate.

Result: The result is the proposed ADEPTS framework that bridges the gap between technical and experience development for AI agents. It aims to condense complex AI-UX requirements into actionable guidance for AI researchers, designers, engineers, and policy reviewers.

Conclusion: Introducing ADEPTS, a capability framework defining core user-facing capabilities for AI agents, aiming to provide unified guidance in their development. The framework focuses on six principles for human-centered agent design to ensure understandability, controllability, and trustworthiness in everyday use.

Abstract: Large language models have paved the way to powerful and flexible AI agents,
assisting humans by increasingly integrating into their daily life. This
flexibility, potential, and growing adoption demands a holistic and
cross-disciplinary approach to developing, monitoring and discussing the
capabilities required for agent-driven user experiences. However, current
guidance on human-centered AI agent development is scattered: UX heuristics
focus on interface behaviors, engineering taxonomies describe internal
pipelines, and ethics checklists address high-level governance. There is no
concise, user-facing vocabulary that tells teams what an agent should
fundamentally be able to do. We introduce ADEPTS, a capability framework
defining a set of core user-facing capabilities to provide unified guidance
around the development of AI agents. ADEPTS is based on six principles for
human-centered agent design, that express the minimal, user-facing capabilities
an AI agent should demonstrate to be understandable, controllable and
trustworthy in everyday use. ADEPTS complements existing frameworks and
taxonomies; differently from them, it sits at the interface between technical
and experience development. By presenting ADEPTS, we aim to condense complex
AI-UX requirements into a compact framework that is actionable guidance for AI
researchers, designers, engineers, and policy reviewers alike. We believe
ADEPTS has the potential of accelerating the improvement of user-relevant agent
capabilities, of easing the design of experiences that take advantage of those
capabilities, and of providing a shared language to track and discuss progress
around the development of AI agents.

</details>


### [9] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
*Lisa Dargasz*

Main category: cs.AI

TL;DR: 本研究探讨了基于理由的人工道德智能体的发展，通过强化学习架构扩展实现道德决策。研究展示了RBAMA的潜力，并提出将其作为一种具体且可部署的框架，以实现关键道德要求。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于探讨构建满足道德要求的智能体，以解决人工道德智能体面临的挑战。随着人工智能技术的不断发展，对于智能体的道德行为提出了特定要求，研究紧扣计算机科学和哲学的交叉领域。

Method: 该研究使用了一种基于强化学习架构扩展的方法，使智能体具备根据理由做出道德决策的功能。通过案例反馈学习理由理论，使智能体能够推导出道德义务，并确保符合这些义务，同时实现其任务的目标。

Result: 研究展示了RBAMA的潜力，并在初步实验中展示了RBAMA的可行性。

Conclusion: 该研究探讨了基于理由的人工道德智能体的发展，该智能体通过扩展强化学习架构实现道德决策，能够基于正当的规范推理做出道德决策。研究展示了RBAMA的潜力，并提出将其作为一种具体且可部署的框架，以实现关键道德要求。

Abstract: Reinforcement Learning is a machine learning methodology that has
demonstrated strong performance across a variety of tasks. In particular, it
plays a central role in the development of artificial autonomous agents. As
these agents become increasingly capable, market readiness is rapidly
approaching, which means those agents, for example taking the form of humanoid
robots or autonomous cars, are poised to transition from laboratory prototypes
to autonomous operation in real-world environments. This transition raises
concerns leading to specific requirements for these systems - among them, the
requirement that they are designed to behave ethically. Crucially, research
directed toward building agents that fulfill the requirement to behave
ethically - referred to as artificial moral agents(AMAs) - has to address a
range of challenges at the intersection of computer science and philosophy.
This study explores the development of reason-based artificial moral agents
(RBAMAs). RBAMAs are build on an extension of the reinforcement learning
architecture to enable moral decision-making based on sound normative
reasoning, which is achieved by equipping the agent with the capacity to learn
a reason-theory - a theory which enables it to process morally relevant
propositions to derive moral obligations - through case-based feedback. They
are designed such that they adapt their behavior to ensure conformance to these
obligations while they pursue their designated tasks. These features contribute
to the moral justifiability of the their actions, their moral robustness, and
their moral trustworthiness, which proposes the extended architecture as a
concrete and deployable framework for the development of AMAs that fulfills key
ethical desiderata. This study presents a first implementation of an RBAMA and
demonstrates the potential of RBAMAs in initial experiments.

</details>


### [10] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.AI

TL;DR: 该文章分析了在家庭环境中实施人工智能（AI），特别是以主动自主代理的形式，带来的舒适和关注可能性，以及其中存在的伦理挑战。提供了针对道德智能家居系统的实用指导，强调了设计要求和支持方法，旨在为未来发展透明、包容和可信的智能家居系统提供实践指南和建议。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨代理人工智能在家庭环境中的实施带来的可能性和挑战，特别是与伦理问题相关的方面。通过对代理AI应用、用户群体和设计原则的分析，旨在为未来发展透明、包容和可信的智能家居系统提供实践指南和建议。

Method: 通过审核代理AI和其应用，关注其从被动到主动自治的转变以及相关伦理挑战。审查可靠的创新框架、以人为本的设计原则和治理实践，以提炼出对道德智能家居系统的实用指导。对老年人、儿童和神经发育异常者等易受风险用户群体进行详细研究，强调设计要求和支持方法。探索了数据驱动的见解，以了解特定用户需求和伦理关切。

Result: 提供了详细的分析和建议，包括如何在代理智能家居中处理隐私、公平性和用户控制等伦理问题。强调了定制解释性、细粒度同意机制和强大的覆盖控制等设计要求，以支持参与性和包容性方法。同时，探讨了数据驱动见解如何帮助理解用户需求和伦理关切。

Conclusion: 该文章分析了在家庭环境中实施人工智能（AI），特别是以主动自主代理的形式，带来的舒适和关注可能性，以及其中存在的伦理挑战。重点分析了代理AI及其应用，着眼于其从被动到主动自治的变化，隐私、公平性和用户控制。回顾了负责任创新框架、以人为本的设计原则和治理实践，提炼出对道德智能家居系统的实用指导。详细研究了易受监视、偏见和隐私风险较高的脆弱用户群体，如老年人、儿童和神经发育异常者，在代理AI背景下。突出了设计要求，如定制可解释性、细粒度同意机制和强大的覆盖控制，支持参与性和包容性方法论。还探讨了数据驱动的洞见，包括通过自然语言处理（NLP）进行社交媒体分析，如何为特定用户需求和伦理关切提供信息。本调查旨在为在家庭自动化中开发透明、包容和值得信赖的代理AI提供概念基础和建议。

Abstract: The implementation of Artificial Intelligence (AI) in household environments,
especially in the form of proactive autonomous agents, brings about
possibilities of comfort and attention as well as it comes with intra or
extramural ethical challenges. This article analyzes agentic AI and its
applications, focusing on its move from reactive to proactive autonomy,
privacy, fairness and user control. We review responsible innovation
frameworks, human-centered design principles, and governance practices to
distill practical guidance for ethical smart home systems. Vulnerable user
groups such as elderly individuals, children, and neurodivergent who face
higher risks of surveillance, bias, and privacy risks were studied in detail in
context of Agentic AI. Design imperatives are highlighted such as tailored
explainability, granular consent mechanisms, and robust override controls,
supported by participatory and inclusive methodologies. It was also explored
how data-driven insights, including social media analysis via Natural Language
Processing(NLP), can inform specific user needs and ethical concerns. This
survey aims to provide both a conceptual foundation and suggestions for
developing transparent, inclusive, and trustworthy agentic AI in household
automation.

</details>


### [11] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
*Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal*

Main category: cs.AI

TL;DR: 本文研究了推断时间计算对模型鲁棒性的影响。发现推断时间计算的好处取决于对手环境和部署情境。在安全敏感的真实应用中，即使是隐藏推理链的模型仍然容易受到攻击。因此，在应用推断时间计算时需要注意权衡各种因素。


<details>
  <summary>Details</summary>
Motivation: 之前的研究表明，增加推断时间计算能提高大型专有推理LLM的鲁棒性，本文试图探究是否较小规模的开源模型也能从推断时间缩放中受益。另外，针对之前工作中隐藏推理步骤的假设展开研究，发现了一个重要的安全风险。

Method: 在较小规模的开源模型中使用了一种简单的预算迫使策略，展示推断时间缩放的好处。对先前的工作进行了批判性检查，发现中间推理步骤对于对手是可见的，引入了一个重要的安全风险。通过放松这一假设，并通过直观动机和经验验证，发现了一个逆向缩放定律。最终讨论了一些实际场景，展示了即使是隐藏推理链的模型仍然容易受到攻击的情况。

Result: 发现推断时间计算的好处依赖于对手环境和部署情境，同时警示在真实应用中需要谨慎考虑这些微妙的权衡。

Conclusion: 推断时间计算的增加可以提高模型的鲁棒性，但其效果依赖于对手环境和部署情境。在一些情况下，模型的隐藏推理链仍然容易受到攻击，特别是工具集成推理和高级推理提取攻击。因此，在安全敏感的真实应用中，需要仔细权衡这些微妙的权衡之后再应用推断时间计算。

Abstract: Recently, Zaremba et al. demonstrated that increasing inference-time
computation improves robustness in large proprietary reasoning LLMs. In this
paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,
Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a
simple budget forcing strategy. More importantly, we reveal and critically
examine an implicit assumption in prior work: intermediate reasoning steps are
hidden from adversaries. By relaxing this assumption, we identify an important
security risk, intuitively motivated and empirically verified as an inverse
scaling law: if intermediate reasoning steps become explicitly accessible,
increased inference-time computation consistently reduces model robustness.
Finally, we discuss practical scenarios where models with hidden reasoning
chains are still vulnerable to attacks, such as models with tool-integrated
reasoning and advanced reasoning extraction attacks. Our findings collectively
demonstrate that the robustness benefits of inference-time scaling depend
heavily on the adversarial setting and deployment context. We urge
practitioners to carefully weigh these subtle trade-offs before applying
inference-time scaling in security-sensitive, real-world applications.

</details>


### [12] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
*Xi Yang,Jiachen Wang,Song Han,Suining He*

Main category: cs.AI

TL;DR: 该论文提出了BikeMAN网络，通过多层次时空注意力机制来预测整个自行车共享系统中各个站点的自行车流量，实验结果显示其在纽约市的数据集上表现出很高的准确性。


<details>
  <summary>Details</summary>
Motivation: 之前的研究已致力于准确预测自行车流量以提高系统效率，但站点级别的预测由于自行车共享系统的时空复杂性和大量站点等因素而变得困难。因此，为填补这一空白，作者提出了BikeMAN网络来解决这一挑战。

Method: 论文采用了多层次时空注意力神经网络来解决自行车共享系统中站点级别自行车流量的预测问题。网络包括编码器和解码器，具有注意力机制，用于表示系统中自行车站特征之间的空间相关性以及描述自行车站流量的时间特征。

Result: BikeMAN网络在纽约市的自行车共享系统数据集上表现出很高的预测准确性，为整个城市的所有站点的自行车流量进行了准确预测。

Conclusion: 该论文提出了一种名为BikeMAN的多层次时空注意力神经网络，用于预测整个自行车共享系统中各个站点的自行车流量。实验结果表明，该网络在纽约市的超过700个站点、1000万次的自行车共享系统行程中表现出很高的准确性。

Abstract: Efficient use of urban micromobility resources such as bike sharing is
challenging due to the unbalanced station-level demand and supply, which causes
the maintenance of the bike sharing systems painstaking. Prior efforts have
been made on accurate prediction of bike traffics, i.e., demand/pick-up and
return/drop-off, to achieve system efficiency. However, bike station-level
traffic prediction is difficult because of the spatial-temporal complexity of
bike sharing systems. Moreover, such level of prediction over entire bike
sharing systems is also challenging due to the large number of bike stations.
To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention
neural network to predict station-level bike traffic for entire bike sharing
systems. The proposed network consists of an encoder and a decoder with an
attention mechanism representing the spatial correlation between features of
bike stations in the system and another attention mechanism describing the
temporal characteristic of bike station traffic. Through experimental study on
over 10 millions trips of bike sharing systems (> 700 stations) of New York
City, our network showed high accuracy in predicting the bike station traffic
of all stations in the city.

</details>


### [13] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
*Tehseen Rug,Felix Böhmer,Tessa Pfattheicher*

Main category: cs.AI

TL;DR: 本文介绍了传统形式语言和自然语言问题解决范式的对比，引入了信任指数Q和两个统计质量维度，提供了更深入的问题解决方法。


<details>
  <summary>Details</summary>
Motivation: 传统计算基于形式、逻辑系统，长期以来一直推动着技术进步，擅长描述具有明确规则的问题。然而，这种范式留下了一个巨大的人类问题领域，这些问题特征是模糊性、动态环境和主观上下文。大型语言模型的出现代表了一种根本性转变，使计算系统能够使用自然语言来处理这些以前无法接触的领域。

Method: 本文引入了一个统一框架，用于理解和对比传统形式语言和自然语言问题解决范式。提出了一个矢量值信任指数Q，反映解决质量，区分了形式解决方案的二元正确性和自然语言解决方案特征连续充分度谱。在这个框架内，提出了两个统计质量维度，归一化的双语义熵测量了LLM回答在问题表述中的语义变化下的稳健性和概念多样性，情绪价值代表了对解决方案的主观评价至一个可量化的度量。

Result: 通过引入统一框架和信任指数Q，本文提供了更深入的对比传统形式语言和自然语言问题解决范式的理解，提出了两个统计质量维度。

Conclusion: 本文介绍了一个统一框架，用于理解和对比传统形式语言和自然语言问题解决范式，提出了解决这两种问题范式的方法。

Abstract: Classical computation, grounded in formal, logical systems, has been the
engine of technological progress for decades, excelling at problems that can be
described with unambiguous rules. This paradigm, however, leaves a vast ocean
of human problems -- those characterized by ambiguity, dynamic environments,
and subjective context -- largely untouched. The advent of Large Language
Models (LLMs) represents a fundamental shift, enabling computational systems to
engage with this previously inaccessible domain using natural language. This
paper introduces a unified framework to understand and contrast these
problem-solving paradigms. We define and delineate the problem spaces
addressable by formal languages versus natural language. While solutions to the
former problem class can be evaluated using binary quality measures, the latter
requires a much more nuanced definition of approximate solution space taking
into account the vagueness, subjectivity and ambiguity inherent to natural
language. We therefore introduce a vector-valued trust index Q, which reflects
solution quality and distinguishes the binary correctness of formal solutions
from the continuous adequacy spectrum characteristic of natural language
solutions. Within this framework, we propose two statistical quality
dimensions. Normalized bi-semantic entropy measures robustness and conceptual
diversity of LLM answers given semantic variation in problem formulations.
Emotional valence maps subjective valuation of a solution to a quantifiable
metric that can be maximized by invoking statistical measures. The concepts
introduced in this work will provide a more rigorous understanding of the
capabilities, limitations, and inherent nature of problem-solving in the age of
LLMs.

</details>


### [14] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
*Jeroen Spaans,Jesse Heyninck*

Main category: cs.AI

TL;DR: 该研究提出了一个扩展的CLP，允许在体中使用否定，并在近似不动点理论框架下提供了语义。研究总结了半环属性对语义的影响，并提供了一个统一框架，捕捉了现有方法并允许扩展。


<details>
  <summary>Details</summary>
Motivation: 之前对CLP进行了各种扩展，但没有研究允许在体中使用否定的子句。研究这一扩展，提供语义，并探讨半环属性对语义的影响，以提供一个捕捉现有方法的统一框架。

Method: 研究了一个扩展的CLP，统一了许多这些扩展并允许在体中使用否定。提供了这些程序的语义，使用了近似不动点理论框架，并详细概述了半环属性对结果语义的影响。

Result: 提供了一个统一的框架，可以扩展现有方法，并允许使用更具表达力的语言。

Conclusion: 提供了一个统一的框架，捕捉了现有方法并允许用更具表达力的语言进行扩展。

Abstract: Constraint Logic Programming (CLP) is a logic programming formalism used to
solve problems requiring the consideration of constraints, like resource
allocation and automated planning and scheduling. It has previously been
extended in various directions, for example to support fuzzy constraint
satisfaction, uncertainty, or negation, with different notions of semiring
being used as a unifying abstraction for these generalizations. None of these
extensions have studied clauses with negation allowed in the body. We
investigate an extension of CLP which unifies many of these extensions and
allows negation in the body. We provide semantics for such programs, using the
framework of approximation fixpoint theory, and give a detailed overview of the
impacts of properties of the semirings on the resulting semantics. As such, we
provide a unifying framework that captures existing approaches and allows
extending them with a more expressive language.

</details>


### [15] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
*Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo*

Main category: cs.AI

TL;DR: ChatBattery是一种新颖的代理性框架，整合领域知识来指导LLMs进行更有效的推理，成功发现并改进了三种新型锂离子电池阴极材料，显示了人工智能驱动推理在革新材料发现方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 该研究受到的启发是推理类似于一种引导搜索的形式，旨在探索LLMs在材料设计中的推理潜力，特别是在电池发现领域。

Method: ChatBattery是通过引入领域知识来引导LLMs实现更有效的推理，从而发现、合成和表征新型锂离子电池阴极材料。

Result: ChatBattery成功地发现了三种新颖的锂离子电池阴极材料，分别达到28.8%、25.2%和18.5%的实际容量改善，相比广泛使用的阴极材料LiNi0.8Mn0.1Co0.1O2（NMC811）。

Conclusion: ChatBattery提出了一种新颖的代理性框架，成功利用其引入的领域知识引导LLMs，发现、合成和表征了三种新颖的锂离子电池阴极材料，实现了分别为28.8%、25.2%和18.5%的实际容量改善。此外，ChatBattery为显示一种成功的依赖LLM驱动和基于推理的电池材料发明平台开辟了新途径。通过这一完整的人工智能驱动循环-从设计到合成再到表征-展示了人工智能驱动推理在革新材料发现方面的潜力。

Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to
tackle complex problems, representing a transformative breakthrough in
artificial intelligence (AI). However, their reasoning capabilities have
primarily been demonstrated in solving math and coding problems, leaving their
potential for domain-specific applications-such as battery discovery-largely
unexplored. Inspired by the idea that reasoning mirrors a form of guided
search, we introduce ChatBattery, a novel agentic framework that integrates
domain knowledge to steer LLMs toward more effective reasoning in materials
design. Using ChatBattery, we successfully identify, synthesize, and
characterize three novel lithium-ion battery cathode materials, which achieve
practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over
the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this
discovery, ChatBattery paves a new path by showing a successful LLM-driven and
reasoning-based platform for battery materials invention. This complete
AI-driven cycle-from design to synthesis to characterization-demonstrates the
transformative potential of AI-driven reasoning in revolutionizing materials
discovery.

</details>


### [16] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
*Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah*

Main category: cs.AI

TL;DR: 本研究提出了TaxCalcBench，用于评估模型计算个人所得税报表的能力。研究发现现有模型在处理美国个人所得税计算任务时存在问题，需要进一步基础设施支持。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是计算美国个人所得税是一个复杂的任务，需要理解大量的英文文本，并利用这些知识来仔细计算结果。

Method: 提出了TaxCalcBench，用于评估模型计算个人所得税报表的能力。通过实验表明，尽管使用了最先进的模型，但在这个简化的样本集上，模型成功计算了不到三分之一的联邦个人所得税申报表。

Result: 研究结果显示，最先进的模型在计算简化样本集上仅成功计算不到三分之一的联邦个人所得税申报表。模型普遍误用税表，计算错误且判断资格不准确。

Conclusion: 研究结论表明，目前的模型在计算美国个人所得税时存在诸多问题，包括误用税表、计算错误和资格判断不准确。需要进一步的基础设施来应用LLM（大型语言模型）来处理个人所得税计算任务。

Abstract: Can AI file your taxes? Not yet. Calculating US personal income taxes is a
task that requires building an understanding of vast amounts of English text
and using that knowledge to carefully compute results. We propose TaxCalcBench,
a benchmark for determining models' abilities to calculate personal income tax
returns given all of the necessary information. Our experiment shows that
state-of-the-art models succeed in calculating less than a third of federal
income tax returns even on this simplified sample set. Our analysis concludes
that models consistently misuse tax tables, make errors in tax calculation, and
incorrectly determine eligibility. Our findings point to the need for
additional infrastructure to apply LLMs to the personal income tax calculation
task.

</details>


### [17] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
*Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong*

Main category: cs.AI

TL;DR: 研究提出了SpiroLLM模型，是第一个能理解呼吸曲线的多模态大语言模型。该模型在COPD诊断方面表现出色，鲁棒性强，展示了深度融合生理信号与大语言模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前大多数COPD诊断的AI模型仅限于输出分类结果，而不能提供诊断过程的理由，同时目前的大语言模型无法理解呼吸图。为解决这一挑战，本研究旨在融合生理信号和大语言模型，提出了SpiroLLM模型。

Method: 该研究利用来自英国生物库（UKB）的234,028名个体，提出了SpiroLLM模型。该模型通过SpiroEncoder从呼吸曲线中提取形态特征，并借助SpiroProjector将这些特征与PFT数值在统一的潜在空间中对齐，最终使大语言模型能够生成全面的诊断报告。

Result: 实验结果表明，SpiroLLM在诊断方面表现出色，且在缺少核心数据的情况下具有很强的鲁棒性，远远优于仅文本模型。

Conclusion: 该研究提出了SpiroLLM，这是第一个能理解呼吸曲线的多模态大语言模型。实验结果显示，SpiroLLM在诊断方面取得了AUROC为0.8980的成绩，且在缺少核心数据的鲁棒性测试中保持了100%的有效响应率。该研究展示了深度融合生理信号与大语言模型的巨大潜力，为下一代可解释和可靠的临床决策支持工具奠定了新的范式。

Abstract: Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory
disease with persistent airflow limitation, is a leading global cause of
disability and mortality. Respiratory spirogram time series, routinely
collected during pulmonary function tests (PFTs), play a critical role in the
early detection of repsiratory diseases and in monitoring lung function over
time. However, most current AI models for COPD diagnosis are limited to
outputting classification results without providing a rationale for their
diagnostic process, while current Large Language Models (LLMs) cannot
understand spirograms yet, which severely limits their clinical trust and
adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals
from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large
language model that can understand spirogram. The model extracts morphological
features from respiratory curves via a SpiroEncoder and aligns them with PFT
numerical values in a unified latent space using a SpiroProjector, ultimately
empowering a large language model to generate a comprehensive diagnostic
report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC
of 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,
it maintained a 100% valid response rate, far surpassing the 13.4% of a
text-only model and showcasing the superiority of its multimodal design. This
work demonstrates the substantial potential of deeply fusing physiological
signals with large language models, establishing a new paradigm for the next
generation of interpretable and reliable clinical decision support tools.

</details>


### [18] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 介绍了Agentic Flow，一个实用AI agent架构，通过比较实验展示了与四种心理理论的结构趋同性。引入了PEACE作为描述性元架构。最终成果为结构化代理在推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在解决大语言模型的局限性，通过实际设计选择展示理论结构如何可能出现。

Method: 设计了Agentic Flow，包括五个互相依存的模块，通过循环认知回路排列。进行了与基线LLM代理的比较实验，以评估这种趋同性。引入了PEACE作为描述性元架构，捕捉到Agentic Flow中的设计级规律。这篇论文应被视为立场论文，探讨实现如何呈现认知理论的潜在结构回声，而不断言理论统一。

Result: 结构化的代理在多步推理任务中取得了95.8%的任务成功率，展现了较强的约束符合性，而基线系统成功率为62.3%。

Conclusion: 报告了四种心理理论之间的结构趋同性，在实用AI agent架构Agentic Flow中无意中获得。

Abstract: We report the discovery of a structural convergence across four influential
theories of mind: Kahneman's dual-system theory, Friston's predictive
processing, Minsky's society of mind, and Clark's extended mind-emerging
unintentionally within a practical AI agent architecture called Agentic Flow.
Designed to address limitations in large language models (LLMs), Agentic Flow
comprises five interdependent modules such as Retrieval, Cognition, Control,
Memory, and Action arranged in a recurrent cognitive loop. Although originally
inspired only by Minsky and Clark, the system's structure retrospectively
aligns with computational motifs found in all four theories, including
predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with
baseline LLM agents on multi-step reasoning tasks. The structured agent
achieved 95.8% task success and exhibited strong constraint adherence, while
the baseline system succeeded 62.3% of the time. These results were not aimed
at proving superiority, but at illustrating how theoretical structures may
emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures
design-level regularities observed in Agentic Flow. Not intended as a new
theory, PEACE provides a shared vocabulary for understanding architectures
shaped by real-world implementation demands. This paper should be read as a
position paper - an exploratory reflection on how implementation can surface
latent structural echoes of cognitive theory, without asserting theoretical
unification.

</details>


### [19] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
*Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: cs.AI

TL;DR: 本文提出了一种空天地一体化网络（SAGIN）架构，利用多功能可重构智能表面（MF-RIS）解决低地球轨道卫星在阴影区域能量短缺问题。引入CHIMERA框架优化系统参数以最大化长期能源效率，在能源效率方面显著优于传统方案。所提出的SAGIN-MF-RIS架构具有显著优势并具备更好的覆盖性能。


<details>
  <summary>Details</summary>
Motivation: 解决低地球轨道卫星在阴影区域能量短缺问题，最大化长期能源效率，提高空天地一体化网络系统性能。

Method: 采用混合智能双模增强多智能体深度强化学习（CHIMERA）框架解决高度非凸非线性的优化问题，其中包括信号放大、相位移、能量收集比和主动元素选择等MF-RIS参数以及波束成形矢量、高空平台站（HAPS）部署、用户关联和计算能力等SAGIN参数。

Result: 提出的CHIMERA方案在能源效率方面明显优于传统方案，这种SAGIN-MF-RIS架构具有显著的优势，并与传统部署方式相比，提供了更好的覆盖性能。

Conclusion: 提出了一种空天地一体化网络（SAGIN）架构，利用多功能可重构智能表面（MF-RIS）实现了同时反射、放大和收集无线能量。通过关注SAGIN节点的通信和计算能耗，解决了低地球轨道（LEO）卫星在阴影区域运行时的能量短缺问题。采用混合智能双模增强多智能体深度强化学习（CHIMERA）框架，优化MF-RIS和SAGIN参数来最大化长期能源效率（EE）。仿真结果表明，所提出的CHIMERA方案在EE方面明显优于传统基准方案，包括固定配置或非收集MF-RIS、传统RIS和无RIS情况，以及集中式和多智能体深度强化学习基线。SAGIN-MF-RIS架构由于其互补覆盖性能，相比独立卫星、空中或仅地面部署具有显著优势。

Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed,
empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)
capable of simultaneously reflecting, amplifying, and harvesting wireless
energy. The MF-RIS plays a pivotal role in addressing the energy shortages of
low-Earth orbit (LEO) satellites operating in shadowed regions, while
explicitly accounting for both communication and computing energy consumption
across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we
formulate a joint optimization problem over the MF-RIS parameters, including
signal amplification, phase-shifts, energy harvesting ratio, and active element
selection as well as the SAGIN parameters of beamforming vectors, high-altitude
platform station (HAPS) deployment, user association, and computing capability.
The formulated problem is highly non-convex and non-linear and contains mixed
discrete-continuous parameters. To tackle this, we conceive a compressed hybrid
intelligence for twin-model enhanced multi-agent deep reinforcement learning
(CHIMERA) framework, which integrates semantic state-action compression and
parametrized sharing under hybrid reinforcement learning to efficiently explore
suitable complex actions. The simulation results have demonstrated that the
proposed CHIMERA scheme substantially outperforms the conventional benchmarks,
including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and
no-RIS cases, as well as centralized and multi-agent deep reinforcement
learning baselines in terms of the highest EE. Moreover, the proposed
SAGIN-MF-RIS architecture achieves superior EE performance due to its
complementary coverage, offering notable advantages over either standalone
satellite, aerial, or ground-only deployments.

</details>


### [20] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
*Dong Ben,Hui Feng,Qian Wang*

Main category: cs.AI

TL;DR: 本研究评估了在Intel Trust Domain Extensions（TDX）下的LLMs表现，发现小型化模型（如DeepSeek）在性能上优于其他模型，尤其适用于资源受限设备。量化模型（如Q4和Q8）比FP16模型性能提升高达3倍。研究结果表明，在安全环境中，TDX实现在执行计算时表现优异，适用于半导体CAD应用。


<details>
  <summary>Details</summary>
Motivation: LLMs在电路设计任务中日益广泛应用，并经历了多轮训练，训练出的模型及其相关的训练数据被视为机密知识产权，需要免受曝露。保密计算通过受信任执行环境（TEEs）为数据和模型提供了一种保护方案，但现有的TEE实现并未高效支持LLMs的资源密集特性。因此，本研究旨在评估LLMs在TEE启用下的表现，并探索在资源受限系统上有效部署轻量级LLMs的潜力。

Method: 本文首先在TEE启用的受信任执行环境中对LLMs进行全面评估，比较TEE、仅CPU和CPU-GPU混合实现的性能，评估其每秒token的性能。研究还观察到，由于其更小的参数，经过提炼的模型（如DeepSeek）在性能上超越其他模型，适合资源受限设备。另外，在量化模型中，如4位量化（Q4）和8位量化（Q8），我们观察到性能提升高达3倍，相比于FP16模型。

Result: 通过对LLMs的综合评估，本研究发现在少量参数集合下，TDX实现超过CPU版本的执行计算性能，特别适用于安全环境中。通过量化模型，如4位和8位量化，性能显著提升，成为在资源受限系统上部署LLMs的有效策略。最终的验证结果展示了在半导体CAD应用中成功部署轻量级LLMs的潜力。

Conclusion: 本文通过在受信任执行环境中使用Intel Trust Domain Extensions（TDX）对LLMs进行了综合评估，发现在资源受限系统上，精简模型（如DeepSeek）具有更好的性能表现。通过量化模型（如4位量化和8位量化），性能可提高多达3倍，与FP16模型相比。研究结果表明，在少量参数集合（如DeepSeek-r1-1.5B）的情况下，TDX实现在安全环境内执行计算时胜过CPU版本。验证结果还使用了设计用于SoC设计任务的测试台，展现了在半导体CAD应用中有效部署轻量级LLMs的潜力。

Abstract: Large Language Models (LLMs) are increasingly used in circuit design tasks
and have typically undergone multiple rounds of training. Both the trained
models and their associated training data are considered confidential
intellectual property (IP) and must be protected from exposure. Confidential
Computing offers a promising solution to protect data and models through
Trusted Execution Environments (TEEs). However, existing TEE implementations
are not designed to support the resource-intensive nature of LLMs efficiently.
In this work, we first present a comprehensive evaluation of the LLMs within a
TEE-enabled confidential computing environment, specifically utilizing Intel
Trust Domain Extensions (TDX). We constructed experiments on three
environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and
evaluated their performance in terms of tokens per second.
  Our first observation is that distilled models, i.e., DeepSeek, surpass other
models in performance due to their smaller parameters, making them suitable for
resource-constrained devices. Also, in the quantized models such as 4-bit
quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain
of up to 3x compared to FP16 models. Our findings indicate that for fewer
parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms
the CPU version in executing computations within a secure environment. We
further validate the results using a testbench designed for SoC design tasks.
These validations demonstrate the potential of efficiently deploying
lightweight LLMs on resource-constrained systems for semiconductor CAD
applications.

</details>


### [21] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: 本文探讨了声音AI代理在医疗保健中的应用，通过Agent PULSE的试点研究展示了AI代理可以提供具有成本效益的医疗保健服务。结果表明声音AI代理可以提高医疗保健的可扩展性、效率和患者参与度，但也需要解决技术挑战和政策考虑。研究建议声音AI代理能够作为公平、可持续数字医疗解决方案的重要组成部分。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨声音AI代理在医疗保健中的应用，特别是在改善预防保健和患者监测方面的作用，以及解决现有的经济和可及性难题。通过对Agent PULSE的试点研究，展示了AI代理在提供可承担的医疗保健服务方面的潜力，并强调AI代理在提升医疗保健可扩展性、效率和患者参与度方面的优势。

Method: 通过Agent PULSE（Patient Understanding and Liaison Support Engine）的开发和试点研究，展示了AI代理如何在人工干预在经济上不可行的情况下提供具有成本效益的医疗保健服务的经济模型。对33名患炎症性肠病的患者进行了试点研究，结果显示70%的患者接受了AI驱动的监测，其中37%更倾向于AI代理而非传统的形式。分析了包括实时对话式AI处理、与医疗系统集成以及隐私合规性在内的技术挑战，以及涉及监管、偏见缓解和患者自主权的政策考虑。

Result: 试点研究表明，AI驱动的声音代理不仅可以提升医疗保健的可扩展性和效率，还可以增加患者的参与度和可及性。针对技术挑战和政策考虑提出了相关分析，同时对医疗保健领导者提出了潜在的巨大节省，并建议技术人员利用该框架来优先考虑产生最大患者影响的改进。

Conclusion: 声音AI代理在医疗保健中的整合提供了一个转变性机会，可以弥合数字健康传递中的经济和可及性差距。研究探讨了大型语言模型（LLM）驱动的语音助手在增强预防保健和持续患者监测方面的作用，特别是在服务不足人群中。通过Agent PULSE（Patient Understanding and Liaison Support Engine）的开发和试点研究，展示了AI代理如何在人工干预在经济上不可行的情况下提供具有成本效益的医疗保健服务的经济模型。研究结果表明，声音AI代理不仅提高了医疗保健的可扩展性和效率，还提高了患者的参与度和可及性。针对当前限制，通过将AI发展与伦理和监管框架保持一致，声音AI代理可以作为公平、可持续数字医疗解决方案的重要切入点。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [22] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
*Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu*

Main category: cs.AI

TL;DR: 该论文介绍了ResearcherBench基准测试，评估Deep AI Research Systems在前沿科学问题上的表现。OpenAI Deep Research和Gemini Deep Research在开放式咨询问题上表现出色。通过提供开源ResearcherBench，为促进下一代AI研究助手的发展并推动新的科学协作模式提供新的AI研究评估视角。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估这些系统作为网络检索和报告生成的代理，而忽略了它们在科学研究前沿发现新见解的潜力。为填补这一空白，引入了ResearcherBench，专注于评估这些先进的Deep AI Research Systems在前沿AI科学问题上的能力。

Method: 该论文采用了双重评估框架，结合专家设计的评估标准对见解质量进行评估，同时使用事实评估来衡量引用准确性和覆盖范围。评估了多种领先的商业DARS和基准系统，以及OpenAI Deep Research和Gemini Deep Research等系统在开放式咨询问题上的优越表现。

Result: 通过对65个来自真实科学场景的研究问题进行数据集编制和双重评估框架的评估，证明了OpenAI Deep Research和Gemini Deep Research在开放式咨询问题上具有明显优势。这种能力代表了AI自我改进的重要一步，符合ASI对AI的愿景。

Conclusion: 该论文介绍了ResearcherBench这一基准测试，专注于评估先进的Deep AI Research Systems在前沿人工智能科学问题上的能力。通过对来自真实科学场景的65个研究问题进行数据集编制，并结合专家设计的评估标准和事实评估，评估了几种主要商业DARS和基准系统。结果显示OpenAI Deep Research和Gemini Deep Research在开放式咨询问题上表现出色，是其他系统的显著优势。开源ResearcherBench旨在提供一个标准化平台，促进下一代AI研究助手的发展，为促进一种新的科学协作模式提供新的AI研究评估视角。

Abstract: The emergence of deep research systems presents significant capabilities in
problem-solving, extending from basic queries to sophisticated research tasks.
However, existing benchmarks primarily evaluate these systems as agents for web
retrieval and report generation, overlooking their potential to discover novel
insights on the frontiers of scientific research. To address this gap, we
introduce ResearcherBench, the first benchmark focused on evaluating the
capabilities of these advanced, agentic systems - which we refer to as Deep AI
Research Systems (DARS) - on frontier AI scientific questions. We compiled a
dataset of 65 research questions expertly selected from real-world scientific
scenarios such as laboratory discussions and interviews, spanning 35 different
AI subjects and categorized into three types: technical details, literature
review, and open consulting. Our dual evaluation framework combines rubric
assessment, which uses expert-designed criteria to evaluate insight quality,
with factual assessment, which measures citation accuracy (faithfulness) and
coverage (groundedness). We evaluated several leading commercial DARS and
baseline systems. Results show that OpenAI Deep Research and Gemini Deep
Research significantly outperform other systems, with particular strength in
open-ended consulting questions. Such capabilities represent a meaningful step
toward AI self-improvement, aligning with the vision of ASI for AI. We
open-source ResearcherBench to provide a standardized platform for promoting
the development of next-generation AI research assistants, hoping to foster a
new perspective in AI research evaluation for a novel pattern of scientific
collaboration: https://github.com/GAIR-NLP/ResearcherBench.

</details>


### [23] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
*Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu*

Main category: cs.AI

TL;DR: 论文介绍了一种通过教师模型将区分性知识传递给学生模型的跨模态蒸馏框架，通过软约束知识蒸馏策略和基于质量的自适应权重模块实现稳健的模型训练，有效实现了图像、文本和语音等多种模态之间的知识传递。


<details>
  <summary>Details</summary>
Motivation: 作者指出，通过引入教师模型并利用跨模态蒸馏可以解决多模态学习中知识传递的挑战，但跨模态之间的巨大领域差异容易导致过拟合。因此，作者提出了一种新的跨模态蒸馏框架和软约束知识蒸馏策略，旨在解决这一问题。另外，作者还提出了基于数据质量的自适应权重模块，以实现模型训练的稳健性。

Method: 引入跨模态蒸馏框架，分别在特征级和分类器级提出两种软约束知识蒸馏策略，同时提出了基于质量的自适应权重模块来实现模型训练的稳健性。通过实验在说话者识别和图像分类任务上验证了论文提出的方法有效实现了知识传递。

Result: 通过实验在说话者识别和图像分类任务上验证了论文提出的跨模态蒸馏框架的有效性，能够实现图像、文本和语音等多种模态之间的知识传递。

Conclusion: 该论文介绍了一种跨模态蒸馏框架，通过引入教师模型将区分性知识传递给学生模型，以实现多模态学习。引入了两种软约束的知识蒸馏策略以解决跨模态蒸馏中的过拟合问题，并提出了一个基于质量的自适应权重模块，通过定量数据质量来调整输入样本权重，从而实现模型训练的稳健性。实验证明，该方法能够有效地在图像、文本和语音这些常用且差异较大的模态之间实现知识传递。

Abstract: Deep learning achieved great progress recently, however, it is not easy or
efficient to further improve its performance by increasing the size of the
model. Multi-modal learning can mitigate this challenge by introducing richer
and more discriminative information as input. To solve the problem of limited
access to multi-modal data at the time of use, we conduct multi-modal learning
by introducing a teacher model to transfer discriminative knowledge to a
student model during training. However, this knowledge transfer via
distillation is not trivial because the big domain gap between the widely
differing modalities can easily lead to overfitting. In this work, we introduce
a cross-modal distillation framework. Specifically, we find hard constrained
loss, e.g. l2 loss forcing the student being exact the same as the teacher, can
easily lead to overfitting in cross-modality distillation. To address this, we
propose two soft constrained knowledge distillation strategies at the feature
level and classifier level respectively. In addition, we propose a
quality-based adaptive weights module to weigh input samples via quantified
data quality, leading to robust model training. We conducted experiments on
speaker recognition and image classification tasks, and the results show that
our approach is able to effectively achieve knowledge transfer between the
commonly used and widely differing modalities of image, text, and speech.

</details>


### [24] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.AI

TL;DR: 这篇论文批评现有医学语言模型基准未能充分反映非洲地区的医学需求，提出了Alama Health QA作为更适合非洲地区的解决方案。研究通过系统回顾了31篇医学语言模型评估论文，发现Alama Health QA在NTD提及的捕获上表现最佳，强调了地域性资源在模型评估和部署中的重要性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于现有的医学语言模型基准未充分考虑非洲地区的疾病负担和监管背景，可能导致性能评价存在误导性。作者希望提出更具地域性的资源，如Alama Health QA，以确保在非洲卫生系统中进行安全、公平的模型评估和部署。

Method: 作者通过系统回顾了31篇定量的医学语言模型评估论文，识别出19个英文医学质量保证基准。他们开发了Alama Health QA，采用了一个基于肯尼亚临床实践指南的检索增强生成框架。接着对六个广泛使用的基准进行了语义分析和盲审，评估了临床关联性、指南一致性、清晰度、干扰因素合理性和语言/文化适配等五个维度。

Result: Alama Health QA在语料库中捕获了超过40%的所有NTD提及，并在疟疾（7.7%）、HIV（4.1%）和结核病（5.2%）等方面的使用频率最高。在相关性和指南一致性方面，Alama得分最高。而全球基准在非洲疾病方面的代表性较低，存在潜在的误导性。

Conclusion: 本文指出现有的医学语言模型基准主要反映高收入国家的考试大纲和疾病概况，对于在非洲部署的有效性存在疑问。作者提出Alama Health QA是一个有潜力的解决方案，能够更好地反映非洲地区的疾病负担和国家指南。

Abstract: Introduction: Existing medical LLM benchmarks largely reflect examination
syllabi and disease profiles from high income settings, raising questions about
their validity for African deployment where malaria, HIV, TB, sickle cell
disease and other neglected tropical diseases (NTDs) dominate burden and
national guidelines drive care. Methodology: We systematically reviewed 31
quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English
medical QA benchmarks. Alama Health QA was developed using a retrieval
augmented generation framework anchored on the Kenyan Clinical Practice
Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,
MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized
semantic profiling (NTD proportion, recency, readability, lexical diversity
metrics) and blinded expert rating across five dimensions: clinical relevance,
guideline alignment, clarity, distractor plausibility, and language/cultural
fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora
and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB
(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global
benchmarks showed minimal representation (e.g., sickle cell disease absent in
three sets) despite large scale. Qualitatively, Alama scored highest for
relevance and guideline alignment; PubMedQA lowest for clinical utility.
Discussion: Quantitative medical LLM benchmarks widely used in the literature
underrepresent African disease burdens and regulatory contexts, risking
misleading performance claims. Guideline anchored, regionally curated resources
such as Alama Health QA and expanded disease specific derivatives are essential
for safe, equitable model evaluation and deployment across African health
systems.

</details>


### [25] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
*Alexander Strunk,Roland Assam*

Main category: cs.AI

TL;DR: 该论文介绍了Higher Gauge Flow Models，利用L$_{∞}$-代数扩展Lie代数，将高阶几何和高阶对称性整合到生成式Flow Models中。实验证明在高斯混合模型数据集上，Higher Gauge Flow Models相比传统Flow Models有更好的性能表现。


<details>
  <summary>Details</summary>
Motivation: 本文动机在于引入一种新型的生成式Flow Models，通过利用L$_{∞}$-代数来扩展Lie代数，将高阶几何和高阶对称性融入模型中。目的是实现比传统模型更好的性能。

Method: 该论文的方法是建立Higher Gauge Flow Models，利用了L$_{∞}$-代数来扩展Lie代数，将高阶几何和高阶对称性整合到生成式Flow Models中。经过实验评估，论文证明了其在高斯混合模型数据集上的性能优于传统Flow Models。

Result: 实验结果表明，在高斯混合模型数据集上，Higher Gauge Flow Models相比传统Flow Models表现出显著的性能提升。

Conclusion: 这篇论文介绍了Higher Gauge Flow Models，这是一种新型的生成式Flow Models。通过在普通Gauge Flow Models（arXiv:2507.13414）的基础上构建，这些Higher Gauge Flow Models利用了一个L$_{∞}$-代数，有效地扩展了Lie代数。这种扩展允许将与高阶群相关的高阶几何和高阶对称性整合到生成式Flow Models的框架中。在高斯混合模型数据集上的实验评估显示，与传统Flow Models相比，实现了显著的性能提升。

Abstract: This paper introduces Higher Gauge Flow Models, a novel class of Generative
Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these
Higher Gauge Flow Models leverage an L$_{\infty}$-algebra, effectively
extending the Lie Algebra. This expansion allows for the integration of the
higher geometry and higher symmetries associated with higher groups into the
framework of Generative Flow Models. Experimental evaluation on a Gaussian
Mixture Model dataset revealed substantial performance improvements compared to
traditional Flow Models.

</details>


### [26] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
*Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe*

Main category: cs.AI

TL;DR: mHealth项目利用自动语音信息传递健康信息，尤其针对服务不足的社区。印度的Kilkari项目通过每周语音电话向数百万母亲传递重要的孕产妇健康信息。研究使用协作强盗算法进行现场试验，优化呼叫时间以提高呼叫接听率。结果显示该算法在Kilkari参与者中表现出显著改善，突显了个性化安排在移动健康干预中的功效，并强调机器学习在规模化改善孕产妇健康宣传中的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前的随机呼叫安排导致了未接电话和降低的信息传递。这项研究旨在解决这一问题，提高卫生信息传递效果，特别针对印度数百万母亲。

Method: 本研究进行了一个协作强盗算法的现场试验，用于优化电话呼叫时间，通过学习个体母亲的首选通话时间。与基线随机呼叫方法相比，我们在大约6500名Kilkari参与者中部署了该算法作为试点研究，结果显示出呼叫接听率有显著提高，具有统计学意义。

Result: 研究结果表明使用协作强盗算法显著改善了呼叫接听率，显示出改善信息传递和影响印度数百万母亲的潜力。

Conclusion: 使用协作强盗算法优化通话时间显示出潜力，可以提高卫生信息传递效果，影响印度数百万母亲。

Abstract: Mobile health (mHealth) programs utilize automated voice messages to deliver
health information, particularly targeting underserved communities,
demonstrating the effectiveness of using mobile technology to disseminate
crucial health information to these populations, improving health outcomes
through increased awareness and behavioral change. India's Kilkari program
delivers vital maternal health information via weekly voice calls to millions
of mothers. However, the current random call scheduling often results in missed
calls and reduced message delivery. This study presents a field trial of a
collaborative bandit algorithm designed to optimize call timing by learning
individual mothers' preferred call times. We deployed the algorithm with around
$6500$ Kilkari participants as a pilot study, comparing its performance to the
baseline random calling approach. Our results demonstrate a statistically
significant improvement in call pick-up rates with the bandit algorithm,
indicating its potential to enhance message delivery and impact millions of
mothers across India. This research highlights the efficacy of personalized
scheduling in mobile health interventions and underscores the potential of
machine learning to improve maternal health outreach at scale.

</details>


### [27] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
*Lucas de Lara*

Main category: cs.AI

TL;DR: 本研究在Pearl的因果框架中提出了一种替代方法，即反事实模型，用于表示与给定因果图模型兼容的反事实。通过引入反事实模型和规范化程序，实现了描述和实现各种反事实构思，同时不改变观测和干预约束。


<details>
  <summary>Details</summary>
Motivation: 由于许多反事实陈述甚至不能通过随机实验来验证，但它们支撑了诸如个人公平等基本概念，因此提供模型来正式化和实现反事实信念仍然是一个基本的科学问题。

Method: 在Pearl的因果框架中，提出了一种替代方法来表示与给定因果图模型兼容的反事实，即反事实模型或结构因果模型的标准表示。介绍了一种规范化过程来描述和实现各种反事实构思，使得能够指定许多反事实构思而不会改变观测和干预约束。

Result: 通过引入反事实模型和提出的规范化程序，实现了对各种反事实构思的描述和实现，而不会改变观测和干预约束。与结构因果模型相比，允许指定许多反事实构思，并且无需估计反事实层对应模型的内容，而只需要做出选择。

Conclusion: 提出了一种基于计数事实推理的结构因果模型的替代方法，称为反事实模型。通过引入反事实模型，使分析人员能够选择通过具有预分配边际的随机过程概率分布来描述反事实构思，并表征结构因果模型的反事实等价类。 还介绍了一种规范化程序，用于描述和实现各种反事实构思。与结构因果模型相比，它允许指定许多反事实构思，而不会改变观测和干预约束。此外，与反事实层对应的模型内容不需要进行估计，只需做出选择。最后，通过理论和数值示例，说明了反事实在因果性中的特定作用以及我们方法的好处。

Abstract: Counterfactual reasoning aims at answering contrary-to-fact questions like
''Would have Alice recovered had she taken aspirin?'' and corresponds to the
most fine-grained layer of causation. Critically, while many counterfactual
statements cannot be falsified -- even by randomized experiments -- they
underpin fundamental concepts like individual-wise fairness. Therefore,
providing models to formalize and implement counterfactual beliefs remains a
fundamental scientific problem. In the Markovian setting of Pearl's causal
framework, we propose an alternative approach to structural causal models to
represent counterfactuals compatible with a given causal graphical model. More
precisely, we introduce counterfactual models, also called canonical
representations of structural causal models. They enable analysts to choose a
counterfactual conception via random-process probability distributions with
preassigned marginals and characterize the counterfactual equivalence class of
structural causal models. Then, we present a normalization procedure to
describe and implement various counterfactual conceptions. Compared to
structural causal models, it allows to specify many counterfactual conceptions
without altering the observational and interventional constraints. Moreover,
the content of the model corresponding to the counterfactual layer does not
need to be estimated; only to make a choice. Finally, we illustrate the
specific role of counterfactuals in causality and the benefits of our approach
on theoretical and numerical examples.

</details>


### [28] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
*Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang*

Main category: cs.AI

TL;DR: 本论文介绍了ColaUntangle，一个新的协作咨询框架，用于处理混乱提交。通过集成大型语言模型驱动的智能体，从显式和隐式依赖关系出发，实现了代码整理的自动化。在实验中，ColaUntangle在两个数据集上表现优异，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发人员经常因为实际限制或不清晰的边界而产生混杂的提交，影响代码审查和维护。现有的提交整理方法往往基于表面信号，未能区分显式和隐式依赖关系。因此，本文提出了ColaUntangle以处理这一问题。

Method: ColaUntangle将大型语言模型（LLM）驱动的智能体集成到多智能体架构中，一个智能体专注于显式依赖关系，另一个专注于隐式依赖关系，审阅者智能体通过迭代协商综合它们的观点。构建多版本程序依赖图（delta-PDG）来捕捉显式和隐式上下文信息，使智能体能够从符号和语义深度推理代码关系。

Result: ColaUntangle在两个广泛使用的数据集上进行了评估，并在实验结果中表现出色，性能优于最佳基准线，分别在C#数据集上提高了44%，在Java数据集上提高了100%。

Conclusion: 本论文提出了ColaUntangle，一个新的协作咨询框架用于处理混乱的提交，同时在实验结果中表现优于现有方法，为自动化提交整理任务的进展指明了潜力。

Abstract: Atomic commits, each of which addresses a single development concern, are a
best practice in software development. However, developers frequently produce
tangled commits that mix unrelated changes due to practical constraints or
unclear boundaries, negatively impacting code review and maintenance. Although
prior commit untangling approaches: rule-based, feature-based, or graph-based,
have made progress, they often rely on shallow signals and fail to distinguish
between explicit dependencies (e.g., control/data flow) and implicit ones
(e.g., semantic or conceptual relationships). In this paper, we propose
ColaUntangle, a new collaborative consultation framework for commit untangling
that models both explicit and implicit dependencies among code changes.
ColaUntangle integrates Large Language Model (LLM)-driven agents in a
multi-agent architecture: one agent specializes in explicit dependencies,
another in implicit ones, and a reviewer agent synthesizes their perspectives
through iterative consultation. To capture explicit and implicit contextual
information, we construct multi-version Program Dependency Graphs (delta-PDG),
enabling agents to reason over code relationships with both symbolic and
semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#
and 14k Java tangled commits). Experimental results show that ColaUntangle
outperforms the best-performing baseline, achieving an improvement of 44% on
the C# dataset and 100% on the Java dataset. These findings highlight the
potential of LLM-based collaborative frameworks for advancing automated commit
untangling tasks.

</details>


### [29] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: The paper introduces Poker, a new MIL algorithm for Self-Supervised ILP that learns without problem-specific background theory or negative examples. Poker outperforms Louise in learning grammars for languages by automatically generating and labeling new examples during learning, improving performance with more generated examples.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of learning recursive logic programs in ILP without problem-specific background theory or negative examples. By introducing Self-Supervised ILP and the Poker algorithm, the paper aims to improve the generalization of learned programs and avoid over-generalization.

Method: The paper formalizes a new setting for Self-Supervised Inductive Logic Programming (ILP) where a problem-specific background theory or negative examples are not available. It presents a new MIL algorithm implemented in Prolog called Poker, which learns from positive labeled and unlabeled examples and generates new examples during learning. The approach also introduces a Second Order Definite Normal Form (SONF) as a general second-order background theory, eliminating the need for a tailored background theory for a learning task.

Result: The results show that Poker outperforms the existing MIL system Louise in learning grammars for different languages without negative examples. Poker's performance improves with the generation of more examples, while Louise tends to over-generalize due to the lack of negative examples.

Conclusion: Poker, a new Meta-Interpretive Learning (MIL) algorithm, outperforms the state-of-the-art MIL system Louise in learning grammars for Context-Free and L-System languages without the need for negative examples. Poker automatically generates and labels new positive and negative examples during learning, improving performance with an increasing number of generated examples.

Abstract: Inductive Logic Programming (ILP) approaches like Meta \-/ Interpretive
Learning (MIL) can learn, from few examples, recursive logic programs with
invented predicates that generalise well to unseen instances. This ability
relies on a background theory and negative examples, both carefully selected
with expert knowledge of a learning problem and its solutions. But what if such
a problem-specific background theory or negative examples are not available? We
formalise this question as a new setting for Self-Supervised ILP and present a
new MIL algorithm that learns in the new setting from some positive labelled,
and zero or more unlabelled examples, and automatically generates, and labels,
new positive and negative examples during learning. We implement this algorithm
in Prolog in a new MIL system, called Poker. We compare Poker to
state-of-the-art MIL system Louise on experiments learning grammars for
Context-Free and L-System languages from labelled, positive example strings, no
negative examples, and just the terminal vocabulary of a language, seen in
examples, as a first-order background theory. We introduce a new approach for
the principled selection of a second-order background theory as a Second Order
Definite Normal Form (SONF), sufficiently general to learn all programs in a
class, thus removing the need for a backgound theory tailored to a learning
task. We find that Poker's performance improves with increasing numbers of
automatically generated examples while Louise, bereft of negative examples,
over-generalises.

</details>


### [30] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
*Hongyi Tang,Zhihao Zhu,Yi Yang*

Main category: cs.AI

TL;DR: 提出了NA-PDD和CCNewsPDD，通过分析LLM中不同数据类型的神经元激活模式来改善PDD任务性能并引入无时间偏见的基准测试，实验证明NA-PDD优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于现有的PDD方法通常依赖于表面特征，如预测置信度和损失，表现一般，为了解决LLMs面临的问题，需要提出更精确的方法。

Method: 提出了NA-PDD算法，通过分析LLM中不同类型数据激活神经元的方式来改善PDD任务性能。引入了CCNewsPDD作为一个无时间偏见的基准测试。

Result: 实验证明，NA-PDD在多个LLMs上明显优于现有方法，CCNewsPDD作为基准测试也得到了有效验证。

Conclusion: 提出了一种新的算法NA-PDD，通过分析LLM中训练数据和非训练数据之间的神经元激活模式差异来改善PDD任务性能。引入了CCNewsPDD，一个无时间偏见的基准测试，通过严格的数据转换确保训练数据和非训练数据之间的时间分布一致。实验证明，NA-PDD在三个基准测试和多个LLMs上显著优于现有方法。

Abstract: The performance of large language models (LLMs) is closely tied to their
training data, which can include copyrighted material or private information,
raising legal and ethical concerns. Additionally, LLMs face criticism for
dataset contamination and internalizing biases. To address these issues, the
Pre-Training Data Detection (PDD) task was proposed to identify if specific
data was included in an LLM's pre-training corpus. However, existing PDD
methods often rely on superficial features like prediction confidence and loss,
resulting in mediocre performance. To improve this, we introduce NA-PDD, a
novel algorithm analyzing differential neuron activation patterns between
training and non-training data in LLMs. This is based on the observation that
these data types activate different neurons during LLM inference. We also
introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data
transformations to ensure consistent time distributions between training and
non-training data. Our experiments demonstrate that NA-PDD significantly
outperforms existing methods across three benchmarks and multiple LLMs.

</details>


### [31] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 通过元解释学习创建了能够结合模型解算器和模型自由控制器能力的自主代理，在两种环境中证明了两种代理在解决格子导航问题上的等效性。


<details>
  <summary>Details</summary>
Motivation: 为了在新颖环境中实现自主行动的代理，需要结合模型解算器和模型自由控制器的能力。

Method: 使用元解释学习创建一个能够在新颖环境中独立行动的自主代理，该代理同时具备模型解算器和模型自由控制器的能力。

Result: 通过在随机生成的迷宫和湖泊地图中进行格子导航问题的实例，证明模型解算器和模型自由控制器在问题解决能力上是等效的。

Conclusion: 在随机生成的迷宫和湖泊地图等环境中，模型解算器和模型自由控制器在解决格子导航问题方面具有同等的问题解决能力。

Abstract: A "model" is a theory that describes the state of an environment and the
effects of an agent's decisions on the environment. A model-based agent can use
its model to predict the effects of its future actions and so plan ahead, but
must know the state of the environment. A model-free agent cannot plan, but can
act without a model and without completely observing the environment. An
autonomous agent capable of acting independently in novel environments must
combine both sets of capabilities. We show how to create such an agent with
Meta-Interpretive Learning used to learn a model-based Solver used to train a
model-free Controller that can solve the same planning problems as the Solver.
We demonstrate the equivalence in problem-solving ability of the two agents on
grid navigation problems in two kinds of environment: randomly generated mazes,
and lake maps with wide open areas. We find that all navigation problems solved
by the Solver are also solved by the Controller, indicating the two are
equivalent.

</details>


### [32] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
*Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi*

Main category: cs.AI

TL;DR: 手术室排班问题挑战性，当前解决方案仅验证编码与实际数据一致性，无法生成临时排班表且排班表稳健性有待提高。本论文通过机器学习预测手术持续时间，结合置信度更新编码，生成稳健排班表，历史数据验证了集成方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 手术室排班问题是一个挑战性问题，仅基于Answer Set Programming（ASP）的解决方案仅能验证编码是否与实际数据一致。本研究旨在解决这一问题，使得能够生成临时排班表并提高排班表的稳健性。

Method: 本论文采用归纳和演绎技术，首先利用机器学习算法预测手术持续时间，然后结合预测的置信度，对问题进行编码更新以生成更加稳健的排班表。

Result: 从意大利ASL1 Liguria的历史数据结果证实了该集成方法的可行性。

Conclusion: 该论文融合归纳和演绎技术以解决手术室排班问题，首先利用机器学习算法预测手术持续时间，然后考虑预测的置信度作为额外输入，以计算更加稳健的排班表。历史数据结果验证了这种集成方法的可行性。

Abstract: The Operating Room Scheduling (ORS) problem deals with the optimization of
daily operating room surgery schedules. It is a challenging problem subject to
many constraints, like to determine the starting time of different surgeries
and allocating the required resources, including the availability of beds in
different department units. Recently, solutions to this problem based on Answer
Set Programming (ASP) have been delivered. Such solutions are overall
satisfying but, when applied to real data, they can currently only verify
whether the encoding aligns with the actual data and, at most, suggest
alternative schedules that could have been computed. As a consequence, it is
not currently possible to generate provisional schedules. Furthermore, the
resulting schedules are not always robust.
  In this paper, we integrate inductive and deductive techniques for solving
these issues. We first employ machine learning algorithms to predict the
surgery duration, from historical data, to compute provisional schedules. Then,
we consider the confidence of such predictions as an additional input to our
problem and update the encoding correspondingly in order to compute more robust
schedules. Results on historical data from the ASL1 Liguria in Italy confirm
the viability of our integration.
  Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [33] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
*Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He*

Main category: cs.AI

TL;DR: 研究提出了一种框架，利用潜在空间进行隐式推理，采用 VMOC 算法和连续 MDP 同态理论扩展，提供了冷启动程序，通过监督微调数据初始化模型推理能力。在实验中展示了该方法在逻辑推理和运动任务上的强大性能。


<details>
  <summary>Details</summary>
Motivation: 论文旨在开发一种针对大语言模型（LLMs）生成逐步文本解释时计算昂贵和缓慢问题的有效隐式推理框架。提出的方法旨在通过在潜在空间中“思考”，而非为每个步骤生成显式文本，以提高推理效率。

Method: 研究使用 Variational Markovian Option Critic（VMOC）算法进行模型训练，在 HiT-MDP 框架内进行变分推断。通过扩展连续 MDP 同态理论为抽象推理空间提供严格基础。另外，利用监督微调数据将人类推理演示转化为潜在选项空间以进行冷启动。

Result: 研究通过大量实验证明，所提出的方法在复杂逻辑推理基准和具有挑战性的运动任务上取得了很好的性能表现。

Conclusion: 该研究提出了一种在潜在空间内进行有效的隐式推理的框架，为解决生成逐步解释的文本所带来的计算昂贵和缓慢问题。通过引入Variational Markovian Option Critic（VMOC）以及连续MDP同态理论的扩展，研究证明了在简化的抽象潜在空间学习政策可以保持原始复杂问题解的最优性。最终，提出了一套冷启动程序，通过监督微调数据将人类推理演示转化为潜在选项空间，为模型的推理能力提供丰富的初始化，并在逻辑推理基准和挑战性运动任务上取得了强大的性能表现，验证了该框架作为学习语言和控制领域抽象技能的原则性方法。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning ability through
explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step
textual explanations is computationally expensive and slow. To overcome this,
we aim to develop a framework for efficient, implicit reasoning, where the
model "thinks" in a latent space without generating explicit text for every
step. We propose that these latent thoughts can be modeled as
temporally-extended abstract actions, or options, within a hierarchical
reinforcement learning framework. To effectively learn a diverse library of
options as latent embeddings, we first introduce the Variational Markovian
Option Critic (VMOC), an off-policy algorithm that uses variational inference
within the HiT-MDP framework. To provide a rigorous foundation for using these
options as an abstract reasoning space, we extend the theory of continuous MDP
homomorphisms. This proves that learning a policy in the simplified, abstract
latent space, for which VMOC is suited, preserves the optimality of the
solution to the original, complex problem. Finally, we propose a cold-start
procedure that leverages supervised fine-tuning (SFT) data to distill human
reasoning demonstrations into this latent option space, providing a rich
initialization for the model's reasoning capabilities. Extensive experiments
demonstrate that our approach achieves strong performance on complex logical
reasoning benchmarks and challenging locomotion tasks, validating our framework
as a principled method for learning abstract skills for both language and
control.

</details>


### [34] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
*Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina*

Main category: cs.AI

TL;DR: Auto-Train for Code Translation (ACT) is an innovative framework that enhances code translation capabilities by in-house finetuning of open-source Large Language Models (LLMs). It bridges the gap between open-source accessibility and high performance of closed-source solutions, offering businesses a secure and reliable alternative. The framework has consistently improved open-source model effectiveness and accelerated developer productivity in industry-scale migration projects.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to address the limitations of traditional automated translation methods and proprietary, API-based implementations in code translation. It aims to improve code translation capabilities by utilizing open-source Large Language Models (LLMs) and enhancing interoperability between different programming languages. The goal is to provide businesses and developers with a secure and reliable alternative for code translation, ultimately increasing developer acceleration in migration projects.

Method: The paper introduces Auto-Train for Code Translation (ACT), a framework that utilizes in-house finetuning of open-source Large Language Models (LLMs) for code translation. It emphasizes the importance of automated pipeline, synthetic data generation module, evaluation framework, and controller module to enhance the performance of language models. The framework dynamically adjusts hyperparameters, orchestrates iterative data generation, and finetunes based on real-time evaluations to optimize the training process.

Result: Auto-Train for Code Translation (ACT) has been successful in enhancing the effectiveness of open-source models and accelerating developer productivity in industry-scale migration projects. The framework's automated pipeline, synthetic data generation module, evaluation framework, and controller module have proven to be effective in improving code translation capabilities. The results demonstrate a notable improvement in the performance of language models and offer businesses and developers a secure alternative for code translation.

Conclusion: Auto-Train for Code Translation (ACT) is an innovative framework that significantly enhances code translation capabilities by enabling in-house finetuning of open-source Large Language Models (LLMs). It bridges the gap between open-source accessibility and high performance of closed-source solutions, offering businesses and developers a secure and reliable alternative. The framework has shown consistent improvements in the effectiveness of open-source models and has led to notable acceleration in developer productivity in industry-scale migration projects.

Abstract: Code translation is a crucial process in software development and migration
projects, enabling interoperability between different programming languages and
enhancing software adaptability and thus longevity. Traditional automated
translation methods rely heavily on handcrafted transformation rules, which
often lack flexibility and scalability. Meanwhile, advanced language models
present promising alternatives but are often limited by proprietary, API-based
implementations that raise concerns over data security and reliance. In this
paper, we present Auto-Train for Code Translation (ACT), an innovative
framework that aims to improve code translation capabilities by enabling
in-house finetuning of open-source Large Language Models (LLMs). ACT's
automated pipeline significantly boosts the performance of these models,
narrowing the gap between open-source accessibility and the high performance of
closed-source solutions. Central to ACT is its synthetic data generation
module, which builds extensive, high-quality datasets from initial code
samples, incorporating unit tests to ensure functional accuracy and diversity.
ACT's evaluation framework incorporates execution-level checks, offering a
comprehensive assessment of translation quality. A key feature in ACT is its
controller module, which manages the entire pipeline by dynamically adjusting
hyperparameters, orchestrating iterative data generation, and finetuning based
on real-time evaluations. This enables ACT to intelligently optimize when to
continue training, generate additional targeted training data, or stop the
process. Our results demonstrate that ACT consistently enhances the
effectiveness of open-source models, offering businesses and developers a
secure and reliable alternative. Additionally, applying our data generation
pipeline to industry-scale migration projects has led to a notable increase in
developer acceleration.

</details>


### [35] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
*Jean Lelong,Adnane Errazine,Annabelle Blangero*

Main category: cs.AI

TL;DR: INRAExplorer is a specialized RAG system designed for exploring scientific data from INRAE. It overcomes the limitations of conventional systems by enabling complex queries, exhaustive dataset retrieval, multi-hop reasoning, and structured answer delivery. The system enhances knowledge interaction in specialized fields, particularly in knowledge-intensive domains.


<details>
  <summary>Details</summary>
Motivation: The motivation behind the development of INRAExplorer is to bridge the gap in knowledge-intensive domains by providing a system that can handle complex queries, multiple targeted retrievals, and intricate entity relationships effectively. It aims to enhance knowledge interaction in specialized fields, specifically focusing on scientific data from INRAE.

Method: INRAExplorer utilizes an LLM-based agent with a multi-tool architecture to interact with a rich knowledge base derived from INRAE publications. It employs a comprehensive knowledge graph to enable iterative, targeted queries, exhaustive dataset retrieval, multi-hop reasoning, and structured answer delivery.

Result: INRAExplorer successfully enhances the interaction with scientific data from INRAE by offering a system that can handle complex queries, retrieve exhaustive datasets, perform multi-hop reasoning, and deliver structured answers. It demonstrates the potential of agentic RAG systems in specialized fields by addressing the limitations of conventional systems.

Conclusion: INRAExplorer is introduced as an agentic RAG system for exploring INRAE scientific data, addressing the limitations of conventional RAG systems in handling complex queries and intricate entity relationships in knowledge-intensive domains.

Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large
Language Models (LLMs) but often fall short on complex queries, delivering
limited, extractive answers and struggling with multiple targeted retrievals or
navigating intricate entity relationships. This is a critical gap in
knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system
for exploring the scientific data of INRAE (France's National Research
Institute for Agriculture, Food and Environment). INRAExplorer employs an
LLM-based agent with a multi-tool architecture to dynamically engage a rich
knowledge base, through a comprehensive knowledge graph derived from open
access INRAE publications. This design empowers INRAExplorer to conduct
iterative, targeted queries, retrieve exhaustive datasets (e.g., all
publications by an author), perform multi-hop reasoning, and deliver
structured, comprehensive answers. INRAExplorer serves as a concrete
illustration of enhancing knowledge interaction in specialized fields.

</details>


### [36] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
*Shanghai AI Lab,:,Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou*

Main category: cs.AI

TL;DR: 该报告通过评估人工智能模型的前沿风险，发现目前所有模型均处于绿色和黄色风险区域，呼吁采取集体行动以缓解这些挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解和识别人工智能模型带来的前所未有风险，引入了前沿AI风险管理框架，评估了其带来的关键风险。

Method: 采用了E-T-C分析（部署环境、威胁来源、启用能力）以及AI风险管理框架（SafeWork-F1-Framework）中的“AI-45度法”，评估了风险，并定义了风险区域为绿色、黄色和红色。

Result: 实验结果显示，所有最新的前沿人工智能模型都处于绿色和黄色风险区域，未超越红线。

Conclusion: 该报告对人工智能模型的前沿风险进行了全面评估，确定了七个关键风险领域。实验结果表明，所有最新的前沿人工智能模型都处于绿色和黄色区域，没有超越红线。报告呼吁采取集体行动以缓解这些挑战。

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing
artificial intelligence (AI) models, this report presents a comprehensive
assessment of their frontier risks. Drawing on the E-T-C analysis (deployment
environment, threat source, enabling capability) from the Frontier AI Risk
Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks
in seven areas: cyber offense, biological and chemical risks, persuasion and
manipulation, uncontrolled autonomous AI R\&D, strategic deception and
scheming, self-replication, and collusion. Guided by the "AI-$45^\circ$ Law,"
we evaluate these risks using "red lines" (intolerable thresholds) and "yellow
lines" (early warning indicators) to define risk zones: green (manageable risk
for routine deployment and continuous monitoring), yellow (requiring
strengthened mitigations and controlled deployment), and red (necessitating
suspension of development and/or deployment). Experimental results show that
all recent frontier AI models reside in green and yellow zones, without
crossing red lines. Specifically, no evaluated models cross the yellow line for
cyber offense or uncontrolled AI R\&D risks. For self-replication, and
strategic deception and scheming, most models remain in the green zone, except
for certain reasoning models in the yellow zone. In persuasion and
manipulation, most models are in the yellow zone due to their effective
influence on humans. For biological and chemical risks, we are unable to rule
out the possibility of most models residing in the yellow zone, although
detailed threat modeling and in-depth assessment are required to make further
claims. This work reflects our current understanding of AI frontier risks and
urges collective action to mitigate these challenges.

</details>


### [37] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
*Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim*

Main category: cs.AI

TL;DR: 该论文引入了基于MDP的数学模型，利用深度强化学习代理优化工业装配线的任务和资源调度。提出了动作屏蔽技术和多代理方法以提高训练效率，采用集中式训练框架和分散式执行，提供可扩展的学习架构。数值模拟验证了该方案的有效性，显示出更快收敛到最优解。


<details>
  <summary>Details</summary>
Motivation: 现代工业装配线需要高效规划活动，确保制造标准、避免项目约束违规并实现成本效益。整数规划存在计算上的困难，启发式方法如遗传算法在大规模场景下效果不佳。本论文旨在解决这些挑战，提出一种新颖的数学模型应用于工业装配线优化。

Method: 引入了基于MDP的数学模型，利用DRL代理进行任务和资源调度优化。提出动作屏蔽技术和多代理方法以提高训练效率。采用集中式训练框架和分散式执行的学习架构。利用神经网络映射当前工厂状态到最优行动，实现实时解决方案。

Result: 通过数值模拟验证了提出的方案较之类似基于模型的方法更快收敛到最优解。

Conclusion: 该论文提出了一种以马尔可夫决策过程（MDP）为基础的通用工业装配线数学模型，利用深度强化学习（DRL）代理优化任务和资源调度。提出了两种创新工具以增强代理训练效率，即动作屏蔽技术和多代理方法。采用集中式训练框架和分散式执行，为优化工业装配线提供了可扩展的学习架构。通过数值模拟验证了该方案的有效性，显示出比类似基于模型的方法更快收敛到最优解。

Abstract: Efficient planning of activities is essential for modern industrial assembly
lines to uphold manufacturing standards, prevent project constraint violations,
and achieve cost-effective operations. While exact solutions to such challenges
can be obtained through Integer Programming (IP), the dependence of the search
space on input parameters often makes IP computationally infeasible for
large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also
be applied, but they frequently produce suboptimal solutions in extensive
cases. This paper introduces a novel mathematical model of a generic industrial
assembly line formulated as a Markov Decision Process (MDP), without imposing
assumptions on the type of assembly line a notable distinction from most
existing models. The proposed model is employed to create a virtual environment
for training Deep Reinforcement Learning (DRL) agents to optimize task and
resource scheduling. To enhance the efficiency of agent training, the paper
proposes two innovative tools. The first is an action-masking technique, which
ensures the agent selects only feasible actions, thereby reducing training
time. The second is a multi-agent approach, where each workstation is managed
by an individual agent, as a result, the state and action spaces were reduced.
A centralized training framework with decentralized execution is adopted,
offering a scalable learning architecture for optimizing industrial assembly
lines. This framework allows the agents to learn offline and subsequently
provide real-time solutions during operations by leveraging a neural network
that maps the current factory state to the optimal action. The effectiveness of
the proposed scheme is validated through numerical simulations, demonstrating
significantly faster convergence to the optimal solution compared to a
comparable model-based approach.

</details>


### [38] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
*Amandeep Kaur,Gyan Prakash*

Main category: cs.AI

TL;DR: 本研究旨在利用深度强化学习算法解决农产品库存管理中的不确定性挑战，提出一种新颖的库存优化方法，通过实证数据验证其在库存管理中的有效性和性能优化。


<details>
  <summary>Details</summary>
Motivation: 现有文献中未考虑食品供应链各级利益相关者之间的协调，本研究要填补这一研究空白。传统方法由于产品保质期和不确定性的存在变得难以实施，因此需要提出新的解决方案。针对这些挑战，研究提出了基于深度强化学习的库存优化算法，以最大化整个农产品供应链的利润。

Method: 本研究采用深度强化学习算法，结合值函数和策略函数的优势，针对农产品库存优化问题设计了一种新颖算法。该算法通过连续动作空间选择最优订货量，有效应对库存优化挑战。利用新鲜农产品供应链库存的实证数据进行严格评估，并证实了在随机需求模式和交货时间情景下所提出的库存补货策略的性能优化。

Result: 通过实验数据验证，所提出的库存优化方法在处理农产品库存管理中的不确定性方面表现出色，为管理者提供了有效的决策依据。

Conclusion: 该研究旨在解决农产品库存管理中的挑战，提出一种基于深度强化学习算法的库存优化方法，以最大化整个供应链的利润。实验结果表明，在考虑需求和交货时间的不确定性情况下，所提出的库存补货策略性能显著提高，对管理农产品库存具有重要的管理启示。

Abstract: Agricultural products are often subject to seasonal fluctuations in
production and demand. Predicting and managing inventory levels in response to
these variations can be challenging, leading to either excess inventory or
stockouts. Additionally, the coordination among stakeholders at various level
of food supply chain is not considered in the existing body of literature. To
bridge these research gaps, this study focuses on inventory management of
agri-food products under demand and lead time uncertainties. By implementing
effective inventory replenishment policy results in maximize the overall profit
throughout the supply chain. However, the complexity of the problem increases
due to these uncertainties and shelf-life of the product, that makes
challenging to implement traditional approaches to generate optimal set of
solutions. Thus, the current study propose a novel Deep Reinforcement Learning
(DRL) algorithm that combines the benefits of both value- and policy-based DRL
approaches for inventory optimization under uncertainties. The proposed
algorithm can incentivize collaboration among stakeholders by aligning their
interests and objectives through shared optimization goal of maximizing
profitability along the agri-food supply chain while considering perishability,
and uncertainty simultaneously. By selecting optimal order quantities with
continuous action space, the proposed algorithm effectively addresses the
inventory optimization challenges. To rigorously evaluate this algorithm, the
empirical data from fresh agricultural products supply chain inventory is
considered. Experimental results corroborate the improved performance of the
proposed inventory replenishment policy under stochastic demand patterns and
lead time scenarios. The research findings hold managerial implications for
policymakers to manage the inventory of agricultural products more effectively
under uncertainty.

</details>


### [39] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
*Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang*

Main category: cs.AI

TL;DR: 该论文提出了Deliberative Searcher框架，是第一个将确定性校准与基于检索的搜索相结合的框架，用于开放领域的问答。实证结果表明，该方法提高了模型置信度和正确性之间的一致性，产生更可信赖的输出。


<details>
  <summary>Details</summary>
Motivation: 在实际场景部署中，提高大型语言模型（LLMs）的可靠性至关重要。本文针对这一问题，提出了Deliberative Searcher框架，旨在改善模型置信度和正确性之间的一致性，以产生更可信赖的输出。

Method: Deliberative Searcher框架整合了确定性校准和基于检索的搜索，使用强化学习算法进行训练，优化准确性，同时遵循软可靠性约束。

Result: 实证结果显示，提出的方法改善了模型置信度和正确性之间的一致性，使输出更加可信赖。

Conclusion: 该论文提出了Deliberative Searcher框架，是第一个将确定性校准与基于检索的搜索相结合的框架，用于开放领域的问答。通过在维基百科数据上执行多步反思和验证，并使用强化学习算法进行训练，优化准确性，同时遵循软可靠性约束。实证结果表明，所提出的方法提高了模型置信度和正确性之间的一致性，产生更可信赖的输出。

Abstract: Improving the reliability of large language models (LLMs) is critical for
deploying them in real-world scenarios. In this paper, we propose
\textbf{Deliberative Searcher}, the first framework to integrate certainty
calibration with retrieval-based search for open-domain question answering. The
agent performs multi-step reflection and verification over Wikipedia data and
is trained with a reinforcement learning algorithm that optimizes for accuracy
under a soft reliability constraint. Empirical results show that proposed
method improves alignment between model confidence and correctness, leading to
more trustworthy outputs. This paper will be continuously updated.

</details>


### [40] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
*Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.AI

TL;DR: 提出了一种新的结构化解码方法wgrammar，通过将约束分解为静态和动态组件，并利用一组操作符来建模常规格式，实现了高效的输出生成。该方法相对现有系统可获得多达250倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在生成需要特定格式的输出时效率较低，受限于语法编译、状态跟踪和掩码创建。许多现实任务嵌入了强大先验知识关于输出结构。

Method: 将约束分解为静态和动态组件，离线预编译静态结构并在运行时使用语法片段实例化动态参数。采用一组操作符来建模常规格式，而不是依赖下推自动机。引入了wgrammar解码引擎，集成了领域感知简化、约束分解和掩码缓存。

Result: 通过引入wgrammar解码引擎，实现了相对现有系统多达250倍的速度提升。

Conclusion: 提出了一种新的方法结构化解码，能够实现更高效的输出生成，相比现有系统可获得多达250倍的加速。

Abstract: Structured decoding enables large language models (LLMs) to generate outputs
in formats required by downstream systems, such as HTML or JSON. However,
existing methods suffer from efficiency bottlenecks due to grammar compilation,
state tracking, and mask creation. We observe that many real-world tasks embed
strong prior knowledge about output structure. Leveraging this, we propose a
decomposition of constraints into static and dynamic components -- precompiling
static structures offline and instantiating dynamic arguments at runtime using
grammar snippets. Instead of relying on pushdown automata, we employ a
compositional set of operators to model regular formats, achieving lower
transition latency. We introduce wgrammar, a lightweight decoding engine that
integrates domain-aware simplification, constraint decomposition, and mask
caching, achieving up to 250x speedup over existing systems. wgrammar's source
code is publicly available at https://github.com/wrran/wgrammar.

</details>


### [41] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
*Roman Mayr,Michel Schimpf,Thomas Bohné*

Main category: cs.AI

TL;DR: ChatChecker框架通过LLM模拟用户交互，识别对话故障，并评估对话质量。设计包含错误分类法在提示中，改进了故障检测性能。引入了挑战性人物形象的非合作用户模拟器，更有效地揭示了目标对话系统的弱点。该框架减少了设置工作，具有通用性，不需要参考对话，且与目标对话系统的实现分离。ChatChecker有助于彻底和可扩展的测试，加速了健壮对话系统的开发。


<details>
  <summary>Details</summary>
Motivation: 现代对话系统涉及大型语言模型(LLMs)以及外部工具和数据库，评估单纯基于LLM的对话系统效果已不足够，需要整体测试和评估，但这仍然是一个主要挑战。先前的工作大多集中在轮次级别分析，对集成式对话级别质量保证给予的关注较少。为了解决这个问题，我们提出了ChatChecker框架，用于自动化评估和测试复杂对话系统。

Method: ChatChecker框架利用LLM模拟用户交互、识别对话故障和评估质量。通过在提示中引入错误分类法，改进了故障检测性能。提出了一个基于挑战性人物形象的非合作用户模拟器，有效揭示了对话系统的弱点。该设计减少了设置工作，并具有通用性，不需要参考对话，与目标对话系统的实现分离。

Result: ChatChecker框架成功通过LLM模拟用户交互，识别对话故障，并评估对话质量。与先前方法相比，它通过错误分类法在提示中提高了故障检测性能。此外，引入了一种新颖的非合作用户模拟器，有效揭示了目标对话系统的弱点。ChatChecker有助于彻底和可扩展的测试，加速了健壮对话系统的开发。

Conclusion: ChatChecker是一个用于自动化评估和测试复杂对话系统的框架，通过使用LLM模拟多样化的用户互动，识别对话故障并评估质量。它通过包含错误分类法在提示中，改进了先前基于LLM的方法的故障检测性能。还提出了一个基于具有挑战性人物形象的新型非合作用户模拟器，更有效地揭示了目标对话系统的弱点。ChatChecker有助于彻底和可扩展的测试，加速了健壮对话系统的开发。

Abstract: While modern dialogue systems heavily rely on large language models (LLMs),
their implementation often goes beyond pure LLM interaction. Developers
integrate multiple LLMs, external tools, and databases. Therefore, assessment
of the underlying LLM alone does not suffice, and the dialogue systems must be
tested and evaluated as a whole. However, this remains a major challenge. With
most previous work focusing on turn-level analysis, less attention has been
paid to integrated dialogue-level quality assurance. To address this, we
present ChatChecker, a framework for automated evaluation and testing of
complex dialogue systems. ChatChecker uses LLMs to simulate diverse user
interactions, identify dialogue breakdowns, and evaluate quality. Compared to
previous approaches, our design reduces setup effort and is generalizable, as
it does not require reference dialogues and is decoupled from the
implementation of the target dialogue system. We improve breakdown detection
performance over a prior LLM-based approach by including an error taxonomy in
the prompt. Additionally, we propose a novel non-cooperative user simulator
based on challenging personas that uncovers weaknesses in target dialogue
systems more effectively. Through this, ChatChecker contributes to thorough and
scalable testing. This enables both researchers and practitioners to accelerate
the development of robust dialogue systems.

</details>


### [42] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
*Mian Ibad Ali Shah,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 提出了一种新的P2P能源交易框架，结合不确定性感知预测和多智能体强化学习，实现了可靠的概率预测和置信区间，优化了交易策略，有效降低能源成本，增加销售收入，减少电网需求峰值。


<details>
  <summary>Details</summary>
Motivation: 针对P2P能源交易的不确定性环境，弥补了以往依赖确定性预测的不足，重点在于量化预测的不确定性，提高决策的鲁棒性。旨在优化能源交易策略，降低成本，提高收入，减少电网需求峰值。

Method: 结合了不确定性感知的预测模型（KTU）与多智能体强化学习框架（MARL），采用定制损失函数训练KTU模型，确保可靠的概率预测和置信区间。优化了交易策略，明确风险和变化性，通过实验结果验证了方法的有效性。

Result: 实验证实了不确定性感知的DQN在降低能源采购成本和增加电力销售收入方面的有效性，对减少峰值小时电网需求也有积极影响，并强调了P2P交易在此框架下的重要性。

Conclusion: 提出了一个新颖的框架，将不确定性感知预测与多智能体强化学习相结合，填补了当前文献中的关键空白。实验证明，这种基于不确定性的深度Q网络（DQN）能够降低能源采购成本，同时增加电力销售收入，降低峰值小时电网需求。显示了先进预测和市场机制在构建具有韧性和经济高效能源社区方面的协同作用。

Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading
that integrates uncertainty-aware prediction with multi-agent reinforcement
learning (MARL), addressing a critical gap in current literature. In contrast
to previous works relying on deterministic forecasts, the proposed approach
employs a heteroscedastic probabilistic transformer-based prediction model
called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify
prediction uncertainty, which is essential for robust decision-making in the
stochastic environment of P2P energy trading. The KTU model leverages
domain-specific features and is trained with a custom loss function that
ensures reliable probabilistic forecasts and confidence intervals for each
prediction. Integrating these uncertainty-aware forecasts into the MARL
framework enables agents to optimize trading strategies with a clear
understanding of risk and variability. Experimental results show that the
uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to
5.7% without P2P trading and 3.2% with P2P trading, while increasing
electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak
hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These
improvements are even more pronounced when P2P trading is enabled, highlighting
the synergy between advanced forecasting and market mechanisms for resilient,
economically efficient energy communities.

</details>
