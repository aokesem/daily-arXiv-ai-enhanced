<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Initial Steps in Integrating Large Reasoning and Action Models for Service Composition](https://arxiv.org/abs/2507.18775)
*Ilche Georgievski,Marco Aiello*

Main category: cs.AI

TL;DR: 本文探讨了利用大型语言模型实现的LRMs和LAMs两种范式的集成，提出了集成LRM-LAM架构框架作为推进自动化服务组合的方向。通过集成的架构框架，实现了服务需求和约束的推理能力以及动态执行工作流程的能力，从而将服务组合过程转变为用户友好的全自动化过程。


<details>
  <summary>Details</summary>
Motivation: 本文针对构建自适应智能软件系统中服务组合仍然面临的挑战，探讨了利用大型语言模型实现LRMs和LAMs集成的可能性。作者认为这种集成可以弥补现有范式的限制，推动自动化服务组合的发展。

Method: 本文提出了集成LRM-LAM架构框架，将LRMs和LAMs的优势结合起来，解决了两者各自的局限性，实现了服务需求和约束的推理能力以及动态执行工作流程的能力。

Result: 通过集成LRMs和LAMs的架构框架，本文展示了推进自动化服务组合的潜力，将服务组合过程转变为用户友好的全自动化过程。

Conclusion: 本文探讨了利用大型语言模型实现的两种新兴范式：大型推理模型（LRMs）和大型行动模型（LAMs）之间的集成，提出了集成LRM-LAM架构框架作为推进自动化服务组合的方向。该集成系统结合了LRMs的语义推理和生态系统复杂性处理能力以及LAMs在动态行动执行和系统互操作性方面的优势，有望将服务组合转变为完全自动化、用户友好的过程。

Abstract: Service composition remains a central challenge in building adaptive and
intelligent software systems, often constrained by limited reasoning
capabilities or brittle execution mechanisms. This paper explores the
integration of two emerging paradigms enabled by large language models: Large
Reasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs
address the challenges of semantic reasoning and ecosystem complexity while
LAMs excel in dynamic action execution and system interoperability. However,
each paradigm has complementary limitations - LRMs lack grounded action
capabilities, and LAMs often struggle with deep reasoning. We propose an
integrated LRM-LAM architectural framework as a promising direction for
advancing automated service composition. Such a system can reason about service
requirements and constraints while dynamically executing workflows, thus
bridging the gap between intention and execution. This integration has the
potential to transform service composition into a fully automated,
user-friendly process driven by high-level natural language intent.

</details>


### [2] [Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization](https://arxiv.org/abs/2507.18795)
*Fatima Al-Ani,Molly Wang,Jevon Charles,Aaron Ong,Joshua Forday,Vinayak Modi*

Main category: cs.AI

TL;DR: 本研究提出了基于仿真驱动的强化学习框架（Dyna-DDPG），用于优化排队网络系统中的路由决策。通过整合深度确定性策略梯度（DDPG）和Dyna风格规划，提高了在动态不确定环境中性能的稳定性和样本效率。实验证明框架能够快速学习有效的路由策略，并在干扰下保持鲁棒性，适用于各种网络规模。软件工程实践确保了框架的可重现性和可维护性。


<details>
  <summary>Details</summary>
Motivation: 鉴于传统排队方法在动态不确定环境中的局限性，本研究的动机是提出一种强化学习方法，能够有效优化路由决策。

Method: 采用了深度确定性策略梯度（DDPG）与Dyna风格规划相结合的方法（Dyna-DDPG），提出了灵活可配置的仿真环境模型，用于建模各种排队场景、干扰和不可预测条件。通过引入独立的预测模型，显著改进了Dyna-DDPG的稳定性和样本效率。

Result: 通过全面实验和严格评估，证明了该框架学习有效的路由策略，并在各种干扰下保持鲁棒性，能够有效扩展到更大的网络规模。

Conclusion: 本研究提出了基于仿真驱动的强化学习框架，用于优化复杂排队网络系统中的路由决策。采用了深度确定性策略梯度（DDPG）与Dyna风格规划相结合的方法（Dyna-DDPG），显著改进了传统排队方法在动态不确定环境中的性能。通过分离预测模型，我们提高了Dyna-DDPG的稳定性和样本效率。实验结果表明，该框架可以迅速学习有效的路由策略，并在干扰下保持鲁棒性，在更大的网络规模下也能有效扩展。此外，强调了采用的软件工程实践，确保框架的可重现性和可维护性，便于在实际场景中部署。

Abstract: This study focuses on the development of a simulation-driven reinforcement
learning (RL) framework for optimizing routing decisions in complex queueing
network systems, with a particular emphasis on manufacturing and communication
applications. Recognizing the limitations of traditional queueing methods,
which often struggle with dynamic, uncertain environments, we propose a robust
RL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with
Dyna-style planning (Dyna-DDPG). The framework includes a flexible and
configurable simulation environment capable of modeling diverse queueing
scenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG
implementation incorporates separate predictive models for next-state
transitions and rewards, significantly improving stability and sample
efficiency. Comprehensive experiments and rigorous evaluations demonstrate the
framework's capability to rapidly learn effective routing policies that
maintain robust performance under disruptions and scale effectively to larger
network sizes. Additionally, we highlight strong software engineering practices
employed to ensure reproducibility and maintainability of the framework,
enabling practical deployment in real-world scenarios.

</details>


### [3] [A Neuroscience-Inspired Dual-Process Model of Compositional Generalization](https://arxiv.org/abs/2507.18868)
*Alex Noviello,Claas Beger,Jacob Groner,Kevin Ellis,Weinan Sun*

Main category: cs.AI

TL;DR: 本文提出了MIRAGE框架，通过Transformer神经分解器和Schema Engine模块之间的互动实现了对组合任务的系统泛化，在SCAN基准测试上取得了很高的准确率。


<details>
  <summary>Details</summary>
Motivation: 人类认知通过海马体（HPC）和前额叶皮质（PFC）的相互作用实现对组合任务的灵活性，海马体快速编码事件，前额叶皮质 consololidates 他们成可重用的推理模式。本文基于这些观察，提出了MIRAGE框架，旨在实现组合任务的系统泛化。

Method: 本文采用了MIRAGE框架，其中包含两个互动模块：Meta-Trained Transformer Neural Decomposer和Schema Engine，分别类比大脑的反思性HPC-PFC环路和直觉性的新皮质模式识别。Transformer神经分解器在随机抽样的组合语法上进行训练，并通过迭代提炼序列表示来应用分解步骤。Schema Engine动态提取、排名和应用可重用的模式，将可变绑定存储在情景记忆中，并在需要时扩展。

Result: MIRAGE在SCAN基准测试上实现了> 99%的准确率，在Transformer模块中仅使用1.19M参数。消融研究验证了MIRAGE的系统性依赖于提取的模式质量和模型的迭代细化过程。

Conclusion: 本文提出了MIRAGE框架，通过在Transformer神经分解器和Schema Engine模块之间建立互动，实现了对组合任务的系统泛化。实验证明该模型在SCAN基准测试上取得了> 99%的准确率，仅使用1.19M参数。消融研究证实，MIRAGE的系统性关键取决于提取的模式和模型的迭代细化过程。

Abstract: Systematic compositional generalization - constructing and understanding
novel combinations of known building blocks - remains a core challenge for AI
systems. Human cognition achieves this flexibility via the interplay of the
hippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes
episodes, and the prefrontal cortex consolidates them into reusable schemas for
reasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with
Rules and Abstractions from Generalized Experience), a framework that achieves
systematic generalization on compositional tasks. MIRAGE has two interacting
modules mirroring the brain's deliberative HPC-PFC loop and intuitive
neocortical pattern recognition. (1) The meta-trained Transformer Neural
Decomposer, paralleling neocortical "System 1" computation, is trained on a
task-agnostic stream of randomly sampled compositional grammars and applies one
decomposition step per pass, with successive passes iteratively refining the
sequence representation. (2) The Schema Engine, analogous to the HPC-PFC
"System 2" loop, dynamically extracts, ranks, and applies reusable schemas,
storing variable bindings in episodic memory and expanding them when needed. By
explicitly equipping the Transformer component of MIRAGE with actively managed
schematic structures, our model performs systematic compositional operations
through explicit schema application and transformation, relying solely on
frozen weights when solving entirely novel tasks. This approach demonstrates
systematic compositional generalization on the SCAN benchmark, achieving > 99%
accuracy on all task splits with only 1.19M parameters in the transformer
module. Ablation studies confirm that MIRAGE's systematicity critically depends
on the quality of extracted schemas and the model's iterative refinement
process.

</details>


### [4] [Success in Humanoid Reinforcement Learning under Partial Observation](https://arxiv.org/abs/2507.18883)
*Wuhao Wang,Zhiyong Chen*

Main category: cs.AI

TL;DR: 该研究在Gymnasium Humanoid-v4环境中成功展示了在部分可观察性条件下学习的例子。使用一种新颖的历史编码器，并将其集成到无模型算法中，实现了性能可与完全观测到的基准相媲美。学习到的策略在性能上与具有完整状态访问权限的结果相当。研究结果表明，编码器能够从最近的观测中重建出关键的上下文信息，从而实现健壮的决策制定。


<details>
  <summary>Details</summary>
Motivation: 在机器人控制中，有效的政策学习在部分可观察性条件下仍然是一个重要挑战。特别是在类似人形机器人行走这样的高维任务中。以往的研究尚未展示在Gymnasium Humanoid-v4环境中成功稳定地训练具有不完整状态信息的机器人策略。因此，本研究的动机在于尝试解决这一挑战，并展示在这一环境中学习在部分可观察性条件下的成功例子。

Method: 该研究采用了一种新颖的历史编码器，用于处理机器人在部分可观察性环境下的学习。编码器能够并行处理过去观测序列，通过将其集成到标准的无模型算法中，实现了性能与完全观测到的基准相媲美。研究通过在Gymnasium Humanoid-v4环境中进行实验，展示了学习在部分可观察性条件下的成果。

Result: 研究结果表明，学习到的策略在Gymnasium Humanoid-v4环境中取得了成功，性能可与具有完整状态访问权限的先进结果相媲美。此外，学习到的策略还展示出对机器人属性的适应性，如机器人身体部分质量的变化。这一成功的关键在于使用了一种新颖的历史编码器，能够并行处理过去观测序列，并使性能与完全观测到的基准相媲美。

Conclusion: 该研究成功展示了在部分可观察性条件下，在Gymnasium Humanoid-v4环境中学习的例子。学习到的策略在性能上可以与具有完整状态访问权限的先进结果相媲美，尽管只使用了原始状态的三分之一到三分之二。此外，该策略还表现出对机器人属性的适应性，比如身体部分质量的变化。该研究的关键成功因素是一种新颖的历史编码器，能够并行处理过去观测序列。将编码器集成到标准的无模型算法中，使得性能可以与完全观测到的基准相媲美。研究假设编码器能够从最近的观测中重建出关键的上下文信息，从而实现健壮的决策制定。

Abstract: Reinforcement learning has been widely applied to robotic control, but
effective policy learning under partial observability remains a major
challenge, especially in high-dimensional tasks like humanoid locomotion. To
date, no prior work has demonstrated stable training of humanoid policies with
incomplete state information in the benchmark Gymnasium Humanoid-v4
environment. The objective in this environment is to walk forward as fast as
possible without falling, with rewards provided for staying upright and moving
forward, and penalties incurred for excessive actions and external contact
forces. This research presents the first successful instance of learning under
partial observability in this environment. The learned policy achieves
performance comparable to state-of-the-art results with full state access,
despite using only one-third to two-thirds of the original states. Moreover,
the policy exhibits adaptability to robot properties, such as variations in
body part masses. The key to this success is a novel history encoder that
processes a fixed-length sequence of past observations in parallel. Integrated
into a standard model-free algorithm, the encoder enables performance on par
with fully observed baselines. We hypothesize that it reconstructs essential
contextual information from recent observations, thereby enabling robust
decision-making.

</details>


### [5] [Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling](https://arxiv.org/abs/2507.18977)
*Mehrnoosh Mirtaheri,Ryan A. Rossi,Sungchul Kim,Kanak Mahadik,Tong Yu,Xiang Chen,Mohammad Rostami*

Main category: cs.AI

TL;DR: 本文提出了一种专门为TKG设计的增量训练框架，旨在解决训练期间未观察到或连接稀疏的实体的挑战。他们的方法在两个基准数据集上进行评估，证明其在总链接预测、归纳链接预测和解决长尾实体方面优于现有方法。值得注意的是，他们的方法在这些数据集上实现了10%的改进和15%的MRR提升。结果突显了他们的方法在减轻灾难性遗忘和增强TKG完成方法的稳健性方面的潜力，特别是在增量训练环境中。


<details>
  <summary>Details</summary>
Motivation: TKG完成模型通常假定在训练期间可以访问整个图，但忽视了TKG不断演化的挑战，如模型普适新知识和管理新或不常见实体的需求。

Method: 结合模型不可知的增强层和加权抽样策略，以解决TKG中未观察到或连接稀疏实体的挑战。增强层利用更广泛的全局实体相似性定义，超越了基于GNN方法的仅局部邻域接近性。训练中采用的加权抽样策略突出了与不经常出现的实体相关的边。

Result: 作者在两个基准数据集上评估了他们的方法，证明其在总链接预测、归纳链接预测和处理长尾实体方面优于现有方法。他们的方法在这些数据集上实现了10%的改进和15%的MRR提升。

Conclusion: 本文提出了一种专门为TKG设计的增量训练框架，旨在解决训练期间未观察到或连接稀疏的实体的挑战。他们的方法在两个基准数据集上进行评估，证明其在总链接预测、归纳链接预测和解决长尾实体方面优于现有方法。值得注意的是，他们的方法在这些数据集上实现了10%的改进和15%的MRR提升。结果突显了他们的方法在减轻灾难性遗忘和增强TKG完成方法的稳健性方面的潜力，特别是在增量训练环境中。

Abstract: Temporal Knowledge Graph (TKG) completion models traditionally assume access
to the entire graph during training. This overlooks challenges stemming from
the evolving nature of TKGs, such as: (i) the model's requirement to generalize
and assimilate new knowledge, and (ii) the task of managing new or unseen
entities that often have sparse connections. In this paper, we present an
incremental training framework specifically designed for TKGs, aiming to
address entities that are either not observed during training or have sparse
connections. Our approach combines a model-agnostic enhancement layer with a
weighted sampling strategy, that can be augmented to and improve any existing
TKG completion method. The enhancement layer leverages a broader, global
definition of entity similarity, which moves beyond mere local neighborhood
proximity of GNN-based methods. The weighted sampling strategy employed in
training accentuates edges linked to infrequently occurring entities. We
evaluate our method on two benchmark datasets, and demonstrate that our
framework outperforms existing methods in total link prediction, inductive link
prediction, and in addressing long-tail entities. Notably, our method achieves
a 10\% improvement and a 15\% boost in MRR for these datasets. The results
underscore the potential of our approach in mitigating catastrophic forgetting
and enhancing the robustness of TKG completion methods, especially in an
incremental training context

</details>


### [6] [Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation](https://arxiv.org/abs/2507.19089)
*Shuhao Li,Weidong Yang,Yue Cui,Xiaoxing Liu,Lingkai Meng,Lipeng Ma,Fan Zhang*

Main category: cs.AI

TL;DR: 本文提出了细粒度道路交通推理（FRTI）任务，旨在利用有限的道路数据生成更详细的车道级交通信息，为精确交通管理提供更节能和经济有效的解决方案。通过设计两阶段框架RoadDiff，充分利用有限的时空依赖关系和道路数据的分布关系，准确推断细粒度车道交通状态，并在六个数据集上进行实验验证模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于传感器类型和数量受限以及跟踪算法精度的问题，获取车道级交通数据已成为数据驱动模型的关键障碍。因此，为了解决这一问题，本文提出了FRTI任务，旨在利用有限的道路数据生成更详细的车道级交通信息，为精确交通管理提供更节能和经济有效的解决方案。

Method: 本文设计了两阶段框架RoadDiff来解决FRTI任务，利用了道路-车道相关性自编码器-解码器和车道扩散模块，充分利用有限的时空依赖关系和道路数据的分布关系，准确推断细粒度车道交通状态。通过设计了几种潜在可解决FRTI任务的基准模型，并在六个数据集上进行了广泛实验以验证RoadDiff模型的有效性。

Result: 通过设计了RoadDiff框架和进行了实验验证，证明了该模型在解决FRTI任务方面的有效性和优越性。

Conclusion: 本文提出了细粒度道路交通推理（Fine-grained Road Traffic Inference，FRTI）任务，旨在利用有限的道路数据生成更详细的车道级交通信息，为精确交通管理提供更节能和经济有效的解决方案。通过设计了两阶段框架RoadDiff来解决FRTI任务，利用了道路-车道相关性自编码器-解码器和车道扩散模块，充分利用有限的时空依赖关系和道路数据的分布关系，准确推断细粒度车道交通状态。在六个代表不同道路状况的数据集上进行了大量实验，验证了RoadDiff模型在解决FRTI任务中的有效性。

Abstract: Fine-grained traffic management and prediction are fundamental to key
applications such as autonomous driving, lane change guidance, and traffic
signal control. However, obtaining lane-level traffic data has become a
critical bottleneck for data-driven models due to limitations in the types and
number of sensors and issues with the accuracy of tracking algorithms. To
address this, we propose the Fine-grained Road Traffic Inference (FRTI) task,
which aims to generate more detailed lane-level traffic information using
limited road data, providing a more energy-efficient and cost-effective
solution for precise traffic management. This task is abstracted as the first
scene of the spatio-temporal graph node generation problem. We designed a
two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.
This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the
Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies
and distribution relationships of road data to accurately infer fine-grained
lane traffic states. Based on existing research, we designed several baseline
models with the potential to solve the FRTI task and conducted extensive
experiments on six datasets representing different road conditions to validate
the effectiveness of the RoadDiff model in addressing the FRTI task. The
relevant datasets and code are available at
https://github.com/ShuhaoLii/RoadDiff.

</details>


### [7] [Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization](https://arxiv.org/abs/2507.19109)
*Noé Lallouet,Tristan Cazenave,Cyrille Enderli*

Main category: cs.AI

TL;DR: Pareto-NRPA是一种适用于多目标优化问题的新蒙特卡洛算法，扩展了NRPA算法思想。在基准测试中，Pareto-NRPA表现出色，在收敛性和解的多样性方面竞争力强。该算法在受约束搜索空间中特别突出，是NRPA首次应用于多目标设定的工作。


<details>
  <summary>Details</summary>
Motivation: 文章的动机在于扩展NRPA算法以解决多目标优化问题，并提出一种适用于多目标优化领域的新算法Pareto-NRPA。作者希望通过引入Pareto-NRPA算法来实现解空间的多样性和隔离性，以解决多目标优化问题。

Method: 作者引入了Pareto-NRPA算法，将NRPA算法的思想推广到多目标优化领域。算法使用一组策略同时探索解空间的不同区域，维护每个搜索级别上的非支配前沿。策略的调整基于Pareto前沿中序列的多样性和隔离性。作者在两类问题上进行了基准测试：MO-TSPTW问题和神经架构搜索任务。

Result: 作者在双目标TSPTW问题和神经架构搜索任务上对Pareto-NRPA进行了基准测试，结果显示Pareto-NRPA在性能方面表现优异，尤其在收敛性和解的多样性方面。Pareto-NRPA在受约束的搜索空间中表现强于当前的进化多目标算法。

Conclusion: Pareto-NRPA是一种针对离散搜索空间的多目标优化问题设计的新的蒙特卡洛算法。它广泛应用了最初针对单目标问题提出的NRPA算法的思想，将嵌套搜索和策略更新机制推广到多目标优化领域。该算法使用一组策略同时探索解空间的不同区域，并在每个搜索级别上保持非支配前沿。策略的调整是根据Pareto前沿中序列的多样性和隔离性进行的。作者在两类问题上对Pareto-NRPA进行了基准测试：一种新颖的双目标旅行推销员问题与时间窗口问题（MO-TSPTW），以及在知名基准测试上的神经架构搜索任务。结果表明，Pareto-NRPA在收敛性和解的多样性方面与当前最先进的多目标算法具有竞争力。特别是，在受约束的搜索空间中，Pareto-NRPA明显优于当前最先进的进化多目标算法。据我们所知，这项工作是将NRPA首次应用于多目标设定。

Abstract: We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for
multi-objective optimization problems over discrete search spaces. Extending
the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for
single-objective problems, Pareto-NRPA generalizes the nested search and policy
update mechanism to multi-objective optimization. The algorithm uses a set of
policies to concurrently explore different regions of the solution space and
maintains non-dominated fronts at each level of search. Policy adaptation is
performed with respect to the diversity and isolation of sequences within the
Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel
bi-objective variant of the Traveling Salesman Problem with Time Windows
problem (MO-TSPTW), and a neural architecture search task on well-known
benchmarks. Results demonstrate that Pareto-NRPA achieves competitive
performance against state-of-the-art multi-objective algorithms, both in terms
of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly
outperforms state-of-the-art evolutionary multi-objective algorithms on
constrained search spaces. To our knowledge, this work constitutes the first
adaptation of NRPA to the multi-objective setting.

</details>


### [8] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: 这篇论文介绍了OS-MAP，一个用于日常计算机自动化的基准测试，通过对任务和代理人进行细粒度评估，揭示了当前计算机代理人研究和部署中的挑战和需要。实验结果显示即使最先进的代理人也在某些高级任务上面临困难，强调了对代理人当前优势和限制的深入了解的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能考虑到内部任务异质性、代理人能力以及它们与实际用户需求的对齐，这妨碍了针对性能力发展和研究进展可靠转化为实际部署。为了弥合这一差距，作者提出了OS-MAP，旨在推动计算机代理人研究和部署进展。

Method: OS-MAP使用了五级自动化分类和真实用户需求层次结构的泛化范围，以设计性能-泛化评估矩阵进行结构化和全面评估。针对代理人的能力和与实际场景的对齐进行了评估，以辅助深入了解代理人在不同任务类型下的自主性和泛化水平。

Result: 实验表明，即使是采用了VLM（Very Large Models）骨干的最先进代理人在涉及感知、推理和协调的高级任务上也遇到困难。设计的性能-泛化评估矩阵为代理人的自主性和泛化水平提供了结构化和全面评估。

Conclusion: 这篇论文介绍了OS-MAP，一个针对日常计算机自动化的基准测试。通过对416个现实任务进行组织，涵盖了15个应用程序，在自动化水平和泛化范围两个维度上评估代理人，以便进行细粒度分析和对实际用户需求的对齐。实验结果显示，即使采用了VLM骨干的现有技术代理人在涉及感知、推理和协调的高级任务上也存在困难，突出了对当前优势和局限性的深入了解的必要性，以推动计算机代理人研究和部署的未来进展。

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>


### [9] [PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring](https://arxiv.org/abs/2507.19172)
*Jiyao Wang,Xiao Yang,Qingyong Hu,Jiankai Tang,Can Liu,Dengbo He,Yuntao Wang,Yingcong Chen,Kaishun Wu*

Main category: cs.AI

TL;DR: PhysDrive是第一个大规模多模态数据集，用于无接触车载生理感知。研究收集了来自48名驾驶员的数据，包括各种传感器数据和六种同步的地面真实数据。在数据集上进行了信号处理和深度学习方法的评估，建立了全面的基准。研究希望PhysDrive能成为研究驾驶员监测和智能驾驶舱系统的基础资源。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于现有资源在规模、模态多样性、生物测量注释的广度和捕获条件范围方面存在局限性，忽略了驾驶中固有的现实挑战。为了克服这一限制，研究人员开发了PhysDrive数据集，以支持驾驶安全和用户体验。

Method: 该研究通过收集来自48名驾驶员的数据，包括RGB、近红外摄像头和原始毫米波雷达数据，并提供六种同步的地面真实数据（ECG、BVP、呼吸、心率、RR和SpO2）。同时在数据集上进行了信号处理和深度学习方法的广泛评估，建立了全面的基准。

Result: PhysDrive收集了来自48名驾驶员的大规模多模态数据集，涵盖了各种自然驾驶条件，包括驾驶员动作、动态自然光、车辆类型和道路条件。研究通过对该数据集的广泛评估，建立了跨所有模态的全面基准，在智能驾驶舱系统和多模态驾驶员监测方面具有重要意义。

Conclusion: PhysDrive是第一个大规模多模态数据集，用于无接触车载生理感知，并针对多种模态设置和驾驶因素进行考虑。研究通过对PhysDrive进行信号处理和深度学习方法的广泛评估，建立了跨所有模态的全面基准，并发布了完整的开源代码，兼容主流公共工具包。研究预计PhysDrive将成为基础资源，加速多模态驾驶员监测和智能驾驶舱系统的研究。

Abstract: Robust and unobtrusive in-vehicle physiological monitoring is crucial for
ensuring driving safety and user experience. While remote physiological
measurement (RPM) offers a promising non-invasive solution, its translation to
real-world driving scenarios is critically constrained by the scarcity of
comprehensive datasets. Existing resources are often limited in scale, modality
diversity, the breadth of biometric annotations, and the range of captured
conditions, thereby omitting inherent real-world challenges in driving. Here,
we present PhysDrive, the first large-scale multimodal dataset for contactless
in-vehicle physiological sensing with dedicated consideration on various
modality settings and driving factors. PhysDrive collects data from 48 drivers,
including synchronized RGB, near-infrared camera, and raw mmWave radar data,
accompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,
and SpO2). It covers a wide spectrum of naturalistic driving conditions,
including driver motions, dynamic natural light, vehicle types, and road
conditions. We extensively evaluate both signal-processing and deep-learning
methods on PhysDrive, establishing a comprehensive benchmark across all
modalities, and release full open-source code with compatibility for mainstream
public toolboxes. We envision PhysDrive will serve as a foundational resource
and accelerate research on multimodal driver monitoring and smart-cockpit
systems.

</details>


### [10] [Faster Lifting for Ordered Domains with Predecessor Relations](https://arxiv.org/abs/2507.19182)
*Kuncheng Zou,Jiahao Mai,Yonggang Zhang,Yuyi Wang,Ondřej Kuželka,Yuanhong Wang,Yi Chang*

Main category: cs.AI

TL;DR: 该论文探讨了在有序域中具有前驱关系的抬升推理问题。他们提出了一种新算法，能够有效处理前驱关系，并在实验中取得了显著的速度提升。


<details>
  <summary>Details</summary>
Motivation: 前人工作主要通过加权一阶模型计数（WFOMC）来解决这一问题，但现有算法在处理实际应用时存在困难。因此，本文希望设计一种新算法，能够有效支持具有前驱关系的情况。

Method: 该论文通过设计一种新算法来处理在有序域上的抬升推理问题，将前驱关系视为axiom的一个组成部分，从而提高处理速度。

Result: 他们提出的算法不仅在处理直接和第二前驱关系时提供了指数级加速，而且能够处理一般的第k个前驱关系。通过广泛的实验验证了算法的效率，获得了一个数量级的速度提升。

Conclusion: 该论文研究了在具有前驱关系的有序域上的抬升推理，其中域的元素遵守一个总的（循环）顺序，每个元素都有一个不同的（顺时针）前驱。他们提出了一种新的算法，旨在提高先前算法在处理具有前驱关系的情况下的实际应用中的效率。通过实验证明，这种算法在抬升推理任务和组合数学问题上取得了显著的速度提升。

Abstract: We investigate lifted inference on ordered domains with predecessor
relations, where the elements of the domain respect a total (cyclic) order, and
every element has a distinct (clockwise) predecessor. Previous work has
explored this problem through weighted first-order model counting (WFOMC),
which computes the weighted sum of models for a given first-order logic
sentence over a finite domain. In WFOMC, the order constraint is typically
encoded by the linear order axiom introducing a binary predicate in the
sentence to impose a linear ordering on the domain elements. The immediate and
second predecessor relations are then encoded by the linear order predicate.
Although WFOMC with the linear order axiom is theoretically tractable, existing
algorithms struggle with practical applications, particularly when the
predecessor relations are involved. In this paper, we treat predecessor
relations as a native part of the axiom and devise a novel algorithm that
inherently supports these relations. The proposed algorithm not only provides
an exponential speedup for the immediate and second predecessor relations,
which are known to be tractable, but also handles the general k-th predecessor
relations. The extensive experiments on lifted inference tasks and
combinatorics math problems demonstrate the efficiency of our algorithm,
achieving speedups of a full order of magnitude.

</details>


### [11] [Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments](https://arxiv.org/abs/2507.19261)
*Osama Almurshed,Ashish Kaushal,Asmail Muftah,Nitin Auluck,Omer Rana*

Main category: cs.AI

TL;DR: 本文介绍了知识嫁接方法，通过将大型模型的特征转移到较小模型来优化资源受限环境下的人工智能模型。研究表明，该方法显著减小了模型大小，同时提高了模型的性能，适用于各种边缘计算场景，有助于推动人工智能在资源受限领域的应用。


<details>
  <summary>Details</summary>
Motivation: 作者指出随着人工智能的普及，模型变得越来越复杂，需要大量计算资源，而这些资源在许多现实应用场景中并不常见。因此，他们提出了知识嫁接的方法，旨在解决在资源受限环境下优化人工智能模型的挑战。

Method: 本文提出了知识嫁接的方法，即将大型模型的选定特征转移到较小模型中，以优化资源受限环境下的人工智能模型。作者在农业领域测试了这一方法，并对比了各项指标，验证了其在模型大小、性能等方面的优势。

Result: 研究结果表明，知识嫁接方法使得模型在模型大小和性能上都取得了显著改进，验证了该方法的有效性。新的母体模型在验证准确度、验证损失等指标上表现优异，并在未见测试数据上也表现出色。

Conclusion: 本文介绍了一种名为知识嫁接的新机制，通过将大型捐赠模型的选定特征（扦）转移到较小的母体模型，优化了面向资源受限环境的人工智能模型。新的母体模型在模型大小减少88.54%的同时，提高了模型的泛化能力。验证结果显示，新的母体模型在验证准确度方面达到89.97%，维持较低的验证损失，且在未见测试数据上表现出色，准确率达到90.45%。该方法解决了常见的大小与性能之间的权衡问题，并使得在资源受限设备上部署人工智能框架具有增强性能的可能性。虽然作者将方法运用于农业杂草检测场景，但其在各种边缘计算场景下具有潜在的推广价值，可以加速人工智能在硬件/软件支持有限的领域的采纳。

Abstract: The increasing adoption of Artificial Intelligence (AI) has led to larger,
more complex models with numerous parameters that require substantial computing
power -- resources often unavailable in many real-world application scenarios.
Our paper addresses this challenge by introducing knowledge grafting, a novel
mechanism that optimizes AI models for resource-constrained environments by
transferring selected features (the scion) from a large donor model to a
smaller rootstock model. The approach achieves an 88.54% reduction in model
size (from 64.39 MB to 7.38 MB), while improving generalization capability of
the model. Our new rootstock model achieves 89.97% validation accuracy (vs.
donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and
performs exceptionally well on unseen test data with 90.45% accuracy. It
addresses the typical size vs performance trade-off, and enables deployment of
AI frameworks on resource-constrained devices with enhanced performance. We
have tested our approach on an agricultural weed detection scenario, however,
it can be extended across various edge computing scenarios, potentially
accelerating AI adoption in areas with limited hardware/software support -- by
mirroring in a similar manner the horticultural grafting enables productive
cultivation in challenging agri-based environments.

</details>


### [12] [Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games](https://arxiv.org/abs/2507.19263)
*Achille Morenville,Éric Piette*

Main category: cs.AI

TL;DR: 本文研究了在不完全信息游戏中使用约束性信念和概率推理的两种方法。发现约束性信念状态可以在许多情境下支持有效决策，其结果与概率推理相当。


<details>
  <summary>Details</summary>
Motivation: 在不完全信息游戏中，智能体必须基于对游戏状态的部分了解做出决策。Belief Stochastic Game模型通过将状态估计委托给游戏模型本身来解决这一挑战。

Method: 本文研究了在隐藏信息游戏中代表信念的两种方法：基于约束满足问题的约束性模型和使用信念传播的概率扩展。评估了这两种表示方法在两个不同游戏中的影响。

Result: 评估了约束性信念和概率推理在智能体决策中的表现，并发现两者结果相当，智能体表现没有显著差异。

Conclusion: 通过对约束性信念和概率推理在隐藏信息游戏中的应用进行研究，发现约束性信念状态在智能体决策中与概率推理结果相当，智能体表现没有明显差异。因此，在许多情境下，仅使用约束性信念状态可能就足以支持有效决策。

Abstract: In imperfect-information games, agents must make decisions based on partial
knowledge of the game state. The Belief Stochastic Game model addresses this
challenge by delegating state estimation to the game model itself. This allows
agents to operate on externally provided belief states, thereby reducing the
need for game-specific inference logic. This paper investigates two approaches
to represent beliefs in games with hidden piece identities: a constraint-based
model using Constraint Satisfaction Problems and a probabilistic extension
using Belief Propagation to estimate marginal probabilities. We evaluated the
impact of both representations using general-purpose agents across two
different games. Our findings indicate that constraint-based beliefs yield
results comparable to those of probabilistic inference, with minimal
differences in agent performance. This suggests that constraint-based belief
states alone may suffice for effective decision-making in many settings.

</details>


### [13] [Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges](https://arxiv.org/abs/2507.19364)
*Patrick Taillandier,Jean Daniel Zucker,Arnaud Grignard,Benoit Gaudou,Nghi Quang Huynh,Alexis Drogoul*

Main category: cs.AI

TL;DR: 本论文分析了LLMs在社会模拟中的应用，讨论了其能力和局限性，提出了混合方法的解决方案。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在社会模拟中的应用潜力和限制

Method: 综述研究和调查分析

Result: 通过研究LLMs在模拟人类认知方面的能力和新兴应用，揭示了其局限性和挑战，提出了解决方案并提倡混合方法

Conclusion: 该论文通过从计算社会科学的角度分析，探讨了大型语言模型（LLMs）在社会模拟中的潜力和局限性。提到LLMs能够复制人类认知的关键方面，如心理理论推断和社会推断，同时也指出了认知偏见、缺乏真正理解和行为不一致等重要局限性。对LLMs在多智能体模拟框架中的新兴应用进行了调查，重点关注系统架构、规模和验证策略。论文通过讨论项目如生成代理（Smallville）和AgentSociety的设计选择、经验基础和方法创新，特别关注LLM驱动的大规模模拟中行为保真度、校准和可复现性方面的挑战。最后一部分区分了LLMs在交互式模拟和严肃游戏等方面直接提供价值的情境与在解释性或预测性建模中使用更为问题的情境。最终，论文主张采用混合方法，将LLMs整合到传统的基于代理的建模平台（如GAMA、Netlogo等）中，使建模者可以将基于语言推理的表达灵活性与经典基于规则系统的透明性和分析严谨性相结合。

Abstract: This position paper examines the use of Large Language Models (LLMs) in
social simulation, analyzing both their potential and their limitations from a
computational social science perspective. The first part reviews recent
findings on the ability of LLMs to replicate key aspects of human cognition,
including Theory of Mind reasoning and social inference, while also
highlighting significant limitations such as cognitive biases, lack of true
understanding, and inconsistencies in behavior. The second part surveys
emerging applications of LLMs in multi-agent simulation frameworks, focusing on
system architectures, scale, and validation strategies. Notable projects such
as Generative Agents (Smallville) and AgentSociety are discussed in terms of
their design choices, empirical grounding, and methodological innovations.
Particular attention is given to the challenges of behavioral fidelity,
calibration, and reproducibility in large-scale LLM-driven simulations. The
final section distinguishes between contexts where LLMs, like other black-box
systems, offer direct value-such as interactive simulations and serious
games-and those where their use is more problematic, notably in explanatory or
predictive modeling. The paper concludes by advocating for hybrid approaches
that integrate LLMs into traditional agent-based modeling platforms (GAMA,
Netlogo, etc), enabling modelers to combine the expressive flexibility of
language-based reasoning with the transparency and analytical rigor of
classical rule-based systems.

</details>


### [14] [Learning neuro-symbolic convergent term rewriting systems](https://arxiv.org/abs/2507.19372)
*Flavio Petruzzellis,Alberto Testolin,Alessandro Sperduti*

Main category: cs.AI

TL;DR: 该论文提出了一个神经符号架构用于学习符号算法，具有出色的泛化能力和性能。介绍了两种模块化实现的结构：神经重写系统（NRS）和快速神经重写系统（FastNRS），在算法设计和关键架构元素的基础上能够在超出分布范围的实例中泛化。作者评估了这两种结构的性能，并在数学公式简化和多领域学习中展示了其优越性。该系统超越了其他神经模型，包括Transformer变种和大规模语言模型，在推理基准测试中也表现出色。


<details>
  <summary>Details</summary>
Motivation: 人工智能领域中，构建能够学习执行符号算法的神经系统一直是一个具有挑战性的开放问题。特别是在追求强泛化能力和超出分布性能方面。本文针对这一问题提出了一个通用框架，并设计了神经符号架构，灵感来自于重写算法本身。

Method: 论文介绍了两种模块化实现的结构：神经重写系统（NRS）和快速神经重写系统（FastNRS），这两个模型通过算法设计和关键架构元素的结果，能够泛化到超出分布的实例。作者对这两种结构进行了四项任务的评估，并展示了它们在多域学习场景中的多功能性表现。

Result: 通过神经符号架构的设计和关键元素，该论文提出的模型在超出分布范围的实例中能够泛化，其中FastNRS在内存效率、训练速度和推理时间方面带来显著改进。作者将这两种结构与其他基线模型进行了评估，证明了其在算法问题解决和多领域学习中的优越性。

Conclusion: 该论文提出了一个神经符号架构，用于学习收敛的术语重写系统，能够在超出分布范围的实例中实现泛化，并且在内存效率、训练速度和推理时间方面取得显著改进。研究结果显示该系统在数学公式简化和多领域学习场景中表现出色，能够优于最近设计用于解决算法问题的变种Transformer模型和大规模通用语言模型。同时，在推理基准测试中，该系统与OpenAI最新的o1-preview模型相媲美甚至优于其。

Abstract: Building neural systems that can learn to execute symbolic algorithms is a
challenging open problem in artificial intelligence, especially when aiming for
strong generalization and out-of-distribution performance. In this work, we
introduce a general framework for learning convergent term rewriting systems
using a neuro-symbolic architecture inspired by the rewriting algorithm itself.
We present two modular implementations of such architecture: the Neural
Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a
result of algorithmic-inspired design and key architectural elements, both
models can generalize to out-of-distribution instances, with FastNRS offering
significant improvements in terms of memory efficiency, training speed, and
inference time. We evaluate both architectures on four tasks involving the
simplification of mathematical formulas and further demonstrate their
versatility in a multi-domain learning scenario, where a single model is
trained to solve multiple types of problems simultaneously. The proposed system
significantly outperforms two strong neural baselines: the Neural Data Router,
a recent transformer variant specifically designed to solve algorithmic
problems, and GPT-4o, one of the most powerful general-purpose large-language
models. Moreover, our system matches or outperforms the latest o1-preview model
from OpenAI that excels in reasoning benchmarks.

</details>


### [15] [Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints](https://arxiv.org/abs/2507.19458)
*Amir Fard,Arnold X. -X. Yuan*

Main category: cs.AI

TL;DR: 本文提出了一种分层深度强化学习方法，用于多年基础设施规划，通过高层次的预算规划和低层次的维护规划，并结合线性规划投影解决了行动空间增长和预算合规性问题。在污水网络案例研究中表现出了高效性和有效性，相对于传统方法具有更好的性能。


<details>
  <summary>Details</summary>
Motivation: 基础设施资产管理中，预算规划和维护优化对于成本效益和可持续性至关重要。然而，由于组合行动空间的复杂性、多样化资产恶化、严格的预算限制和环境不确定性，现有方法的可扩展性受到显著限制。因此，有必要提出一种针对多年基础设施规划的新方法。

Method: 本文提出了一种分层深度强化学习方法，将基础设施规划问题分解为高层次的预算规划和低层次的维护规划，通过结构化地分离预算决策和资产优先级排序，并在层次化Soft Actor-Critic框架中集成线性规划投影，以处理行动空间的指数增长和确保预算合规性。通过对污水网络的案例研究，展示了该方法的有效性。

Result: 本文提出的分层深度强化学习方法在多年基础设施规划中展现了高效性和有效性，相对于传统方法有更快的收敛速度、更好的可扩展性，并在网络规模增长时仍能提供接近最优解的结果。

Conclusion: 本文提出了一种针对多年基础设施规划的分层深度强化学习方法，将问题分解为两个层次：高层次的预算规划员在明确的可行性范围内分配年度预算，低层次的维护规划员在分配的预算内优先考虑资产。通过在层次化Soft Actor-Critic框架中结构地将宏观预算决策与资产级别优先级排序分离，并集成线性规划投影，该方法有效地解决了行动空间呈指数增长且确保严格预算合规性的问题。案例研究评估不同规模的污水网络（10、15和20个污水流域）展示了所提方法的有效性。与传统Deep Q-Learning和增强遗传算法相比，我们的方法收敛更快，有效扩展，并在网络规模增长时始终提供接近最优解的结果。

Abstract: Budget planning and maintenance optimization are crucial for infrastructure
asset management, ensuring cost-effectiveness and sustainability. However, the
complexity arising from combinatorial action spaces, diverse asset
deterioration, stringent budget constraints, and environmental uncertainty
significantly limits existing methods' scalability. This paper proposes a
Hierarchical Deep Reinforcement Learning methodology specifically tailored to
multi-year infrastructure planning. Our approach decomposes the problem into
two hierarchical levels: a high-level Budget Planner allocating annual budgets
within explicit feasibility bounds, and a low-level Maintenance Planner
prioritizing assets within the allocated budget. By structurally separating
macro-budget decisions from asset-level prioritization and integrating linear
programming projection within a hierarchical Soft Actor-Critic framework, the
method efficiently addresses exponential growth in the action space and ensures
rigorous budget compliance. A case study evaluating sewer networks of varying
sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed
approach. Compared to conventional Deep Q-Learning and enhanced genetic
algorithms, our methodology converges more rapidly, scales effectively, and
consistently delivers near-optimal solutions even as network size grows.

</details>
