<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 33]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 该论文提出了一个基于大型语言模型的智能维护系统，通过将轴承振动数据转化为自然语言进行处理，在工业维护中取得了有效的异常检测和相关的维护指导，成功弥合了条件监测和可操作性维护规划之间的差距。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以防止灾难性故障并优化操作效率。作者的动机是扩展传统的异常检测，提供可操作的维护建议，通过结合数字数据分析的LAMP框架，开发了结合轴承振动频率分析和多智能代理生成的综合解决方案。

Method: 该论文建立在作者之前的LAMP框架基础上，将轴承振动数据转化为自然语言进行LLM处理，实现了准确度较高的少样本异常检测。系统分类故障类型并评估严重程度，通过多智能体组件处理维护手册并进行语义搜索和网络搜索，生成结构化的维护建议，包括立即行动、检查清单、纠正措施、零部件需求和时间规范。

Result: 实验验证表明系统在轴承振动数据集上实现了有效的异常检测和相关的维护指导，成功弥合了条件监测和可操作性维护规划之间的差距。

Conclusion: 该论文提出了一个基于大型语言模型（LLM）的智能系统，用于预测性维护，通过结合轴承振动频率分析和多智能体生成，提供行动性维护建议。实验验证表明系统可以有效检测异常并提供相关的维护指导，成功弥合了条件监测和可操作性维护规划之间的差距。这项工作推动了LLMs在工业维护中的应用，为机械部件和工业领域提供了一个可扩展的预测性维护框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [2] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow is a method that improves agentic success by 6.8% and reduces token usage by up to fourfold in geospatial tasks compared to current approaches.


<details>
  <summary>Details</summary>
Motivation: Unlike prior work that focuses on reasoning decomposition and leaves API selection implicit, GeoFlow aims to improve agentic success and token usage efficiency in geospatial tasks.

Method: GeoFlow is a method that automatically generates agentic workflows for geospatial tasks, providing agents with detailed tool-calling objectives to guide geospatial API invocation at runtime.

Result: The GeoFlow method shows significant improvements in agentic success and token usage efficiency compared to existing state-of-the-art approaches in geospatial tasks.

Conclusion: GeoFlow method increases agentic success by 6.8% and reduces token usage by up to fourfold across major LLM families compared to state-of-the-art approaches.

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [3] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 这项研究提出了一个新的对抗性基准评估框架，通过棋盘游戏竞赛评估大型语言模型（LLMs）的综合表现。实验结果显示，大多数LLMs在高压对抗环境中表现出较强的适应能力，但PLG中循环胜负之间的关系暴露出LLMs在游戏中技能发挥的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 对抗性棋盘游戏作为战略推理和智能的典型领域，一直是评估人工智能系统的流行竞争活动和基准。通过引入对抗性基准评估框架，旨在弥补主流问答（Q&amp;A）基准方法的数据依赖性限制。

Method: 提出了一种对抗性基准评估框架，通过棋盘游戏竞赛评估LLMs的综合表现，采用Elo评分系统和Performance Loop Graph（PLG）进行技术能力定量评估，同时通过Positive Sentiment Score（PSS）评估心理适应性。实验结构为循环赛制，有助于系统比较参与者。

Result: 实验结果显示，大多数LLMs对于胜利和失败仍持乐观态度，表现出较强的适应能力。然而，PLG中循环胜负之间的关系揭示了LLMs在游戏中技能发挥的不稳定性。

Conclusion: 大型语言模型（LLMs）在对抗性棋盘游戏中展现出较强的应对高压对抗环境的适应能力，此实验结果有助于评估LLMs在战略推理和智能领域的性能。然而，PLG中循环胜负之间的复杂关系揭示了LLMs在游戏中技能发挥的不稳定性，需要进一步解释和探索。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [4] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 本研究比较了三种实现 AWebGIS 的方法：云端大型语言模型、经典机器学习分类器和客户端小语言模型。通过在客户端执行小语言模型，实现了最佳准确度，提高了用户隐私和系统扩展性。客户端计算策略减轻了服务器负载，突显了浏览器可执行模型对 AWebGIS 解决方案的可行性。


<details>
  <summary>Details</summary>
Motivation: 自主 web 地理信息系统 (AWebGIS) 旨在从自然语言输入中执行地理空间操作，提供直观、智能和免提交互。然而，大多数现有解决方案依赖于基于云的大型语言模型 (LLMs)，这些模型需要持续的互联网访问，并由于集中服务器处理而引发用户隐私和扩展性问题。

Method: 本研究比较了三种实现 AWebGIS 的方法：1）使用基于云的大型语言模型 (LLMs) 的完全在线方法；2）使用经典机器学习分类器（如支持向量机和随机森林）的半自动离线方法；3）基于在客户端的精细调整小语言模型 (SLM)，具体为 T5-small 模型的完全自主离线方法。

Result: 第三种方法利用小语言模型 (SLMs) 实现了最高准确度，在准确度、相似度和 ROUGE 分数上表现出色。同时，这种客户端计算策略减轻了后端服务器的负载，消除了对服务器推理的需求。

Conclusion: 在比较三种实现自主 Web 地理信息系统 (AWebGIS) 的方法后，本研究发现基于客户端的离线方法利用精细调整的小语言模型 (SLM)，特别是 T5-small 模型，在准确度上取得了最佳结果。此方法在所有方法中实现了最高的准确匹配度为 0.93，Levenshtein 相似度为 0.99，以及 ROUGE-1 和 ROUGE-L 分数为 0.98。这种客户端计算策略显著减少了后端服务器的负载，通过将处理任务转移到用户设备，消除了基于服务器的推理的需求。这些结果突显了浏览器可执行模型对 AWebGIS 解决方案的可行性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [5] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 研究通过强化学习微调大型语言模型和视觉-语言模型，测试它们在不同情境下的推理能力。发现强化学习在理想情况下提升了推理能力，但在非理想情况下存在明显下降，暴露了推理能力的限制。提出了问题解决方法，但仍未完全解决推理缺陷。强调了在评估大型模型时考虑非理想情境的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是基于对大型语言模型在理想化和非理想化环境下推理能力的认知，提出通过强化学习进行微调，探究其在不同情境下的表现。同时结合大脑科学研究，引领新的研究方向，试图解决当前方法忽视的非理想情景下的推理问题。

Method: 使用强化学习微调三个大型语言模型和一个最新的大规模视觉-语言模型，在八个公共数据集上进行测试，评估它们在理想和非理想场景下的表现。

Result: 研究结果显示，强化学习微调虽然能够提升大型语言模型在理想情况下的推理能力，但在非理想情境下明显下降，揭示了其推理能力的重要限制。提出了特定场景下的问题解决方法，但当前方法未能解决这些推理缺陷。研究强调了在评估大型模型时考虑非理想情境的重要性。

Conclusion: 论文指出强化学习对于增强大型语言模型的推理能力至关重要，但现有基准测试大多在理想化环境下进行，忽视了在现实非理想情况下的表现。研究identifies三个有实际意义的非理想情景，并提出了一个基于大脑科学研究的新研究方向。通过在八个公共数据集上测试，发现强化学习的微调虽然提升了理想情况下的推理能力，但在三种非理想情景下表现明显下降，揭示了高级推理能力存在的关键限制。提出了特定场景下的问题解决方法，但当前方法仍然未能完全解决这些推理缺陷。研究强调了大型模型的推理能力常常被夸大，并强调了在非理想情景下评估模型的重要性。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [6] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow is a self-evolving AI agent that improves problem-solving in healthcare research using meta-level evolution. It outperforms existing frameworks, aided by the EHRFlowBench benchmark. This advancement shifts the focus towards designing smarter, self-evolving task-managers for more effective AI in scientific discovery.


<details>
  <summary>Details</summary>
Motivation: Current AI agents in healthcare research are limited in strategic planning due to reliance on static strategies, hindering their effectiveness in complex domains like healthcare. The aim is to overcome this limitation and enable AI agents to evolve strategically for better performance in healthcare research tasks.

Method: Introducing HealthFlow, a self-evolving AI agent, that refines its problem-solving policies through a meta-level evolution mechanism. EHRFlowBench benchmark is introduced for reproducible evaluation. Comprehensive experiments conducted to compare with existing agent frameworks.

Result: HealthFlow demonstrates superior performance compared to state-of-the-art agent frameworks in healthcare research. The self-evolving approach enhances the problem-solving capabilities of AI agents. The EHRFlowBench benchmark facilitates reproducible evaluation of AI agents in healthcare research tasks.

Conclusion: HealthFlow, a self-evolving AI agent, surpasses existing agent frameworks in healthcare research by refining high-level problem-solving policies through a meta-level evolution mechanism. The introduction of EHRFlowBench benchmark aids in reproducible evaluation. The research marks a transition from building better tool-users to smarter, self-evolving task-managers, enhancing the autonomy and effectiveness of AI in scientific discovery.

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [7] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 提出了Docking Game框架和LoopPlay算法，通过交换预测姿势和动态优化，实现了分子对接准确性的显著改进，为药物发现领域带来潜在的提升。


<details>
  <summary>Details</summary>
Motivation: 目前多任务学习模型在配体对接方面表现较差，这主要是由于配体和蛋白质的结构复杂性不同导致的。为解决这一问题，提出了一个新颖的框架和算法来改善分子对接的准确性。

Method: 提出了一个基于博弈论的框架Docking Game，以及一个用于训练的LoopPlay算法，通过交换预测姿势和动态优化来提高分子对接的准确性。

Result: 通过在公共基准数据集上进行大量实验证明，LoopPlay相较于先前最先进的方法，在预测准确的结合模式方面取得了约10%的改进。

Conclusion: 新颖的基于博弈论的框架和LoopPlay算法在分子对接中取得了显著的改进，能够提高药物发现中的分子对接准确性。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [8] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: LLMs are explored for spatial data integration by reasoning about environmental spatial relationships. While LLMs struggle with macro-scale connections, providing relevant features enhances performance. A review-and-refine method effectively corrects errors. LLMs offer a flexible alternative to traditional methods, advancing adaptive spatial data integration.


<details>
  <summary>Details</summary>
Motivation: Traditional integration methods have limitations in covering all edge cases, requiring manual verification. Machine learning approaches demand large labeled datasets. The motivation is to leverage LLMs to empower domain experts in integrating large, heterogeneous, and noisy urban spatial datasets more effectively.

Method: The study explores the application of large language models (LLMs) for spatial data integration. It investigates how LLMs reason about environmental spatial relationships and their struggles in connecting macro-scale environments with computational geometry tasks. An adapted review-and-refine method is utilized to correct errors and improve response accuracy. Practical implications and future research directions are discussed, including post-training methods and support for diverse data formats.

Result: LLMs exhibit spatial reasoning capabilities but may produce incoherent responses without relevant features. The adapted review-and-refine method effectively corrects initial errors while maintaining response accuracy. The study positions LLMs as a promising alternative for spatial data integration.

Conclusion: LLMs show promising potential for spatial data integration, especially when provided with relevant features and adapted review-and-refine methods. They offer a flexible alternative to traditional rule-based heuristics and advance adaptive spatial data integration capabilities.

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [9] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 该论文提出了CogniWeb代理架构，基于双过程理论的认知过程分解，实现了快速直觉处理和深思熟虑推理的自适应切换，取得了竞争性能且具有显著高效率。


<details>
  <summary>Details</summary>
Motivation: 目前构建自主Web代理的方法主要集中在离线模仿学习或在线探索两种范式，但很少有效整合这两种范式。作者受到人类认知的双过程理论启发，旨在提供一种新的认知分解方法，以提高Web代理的性能和效率。

Method: 基于双过程理论的认知过程分解提供了对现有Web代理方法学的统一视角，将离线学习直觉反应行为与在线获得深思熟虑规划能力之间的差距进行了弥合。作者将此理论应用于CogniWeb代理架构，能够根据任务复杂性切换快速直觉处理和深思熟虑推理。

Result: 作者在WebArena上评估了CogniWeb代理架构，结果表明其在Web导航方面取得了竞争性能（43.96%成功率）并显著提高了效率（减少了75%的令牌使用量）。

Conclusion: 该论文提出了一种基于双过程理论的模块化代理架构CogniWeb，实现了对Web导航中快速直觉处理和深思熟虑推理之间的自适应切换。在WebArena上的评估表明，CogniWeb取得了竞争性能表现（43.96%成功率），同时在使用令牌方面具有显著更高的效率（减少了75%）。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [10] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: Recent advances in medical AI have led to multimodal large language models improving medical understanding. The paper introduces MedMKEB, a benchmark for evaluating knowledge editing in medical multimodal models. It includes various editing tasks and human expert validation, highlighting the limitations of current approaches and the need for specialized strategies in medicine.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the lack of systematic benchmarks for multimodal medical knowledge editing involving image and text modalities. It emphasizes the importance of allowing models to efficiently update outdated or incorrect information without retraining from scratch as medical knowledge evolves.

Method: MedMKEB is built on a high-quality medical visual question-answering dataset and includes editing tasks such as counterfactual correction, semantic generalization, knowledge transfer, and adversarial robustness. Human expert validation is incorporated to ensure benchmark accuracy.

Result: Extensive experiments on general and medical large language models reveal the limitations of existing knowledge editing approaches in medicine, underscoring the necessity to develop specialized editing strategies. MedMKEB is expected to advance the development of trustworthy and efficient medical knowledge editing algorithms.

Conclusion: MedMKEB is introduced as the first comprehensive benchmark for evaluating knowledge editing in medical multimodal large language models, highlighting the limitations of existing approaches and the need for specialized editing strategies in medicine.

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [11] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize is a lightweight gate sizing framework that leverages EOA of performance metrics for task-specific loss functions. It utilizes DE and PSO in a feedback-enhanced flow, achieving strong performance across various technology nodes and surpassing AutoCkt in simulation resource reduction and task completion. It aims to streamline analog circuit design processes by reducing the reliance on human expertise and computational resources.


<details>
  <summary>Details</summary>
Motivation: Analog circuit design is a time-consuming and experience-driven task, and current methods lack universal applicability and portability across different technology nodes. Existing approaches combine Large Language Models (LLMs) with heuristic search but rely on large model sizes. The motivation is to develop a lightweight gate sizing framework that can address these limitations and simplify the analog circuit design process.

Method: EasySize utilizes Easy of Attainability (EOA) of performance metrics to construct task-specific loss functions and employs global Differential Evolution (DE) and local Particle Swarm Optimization (PSO) in a feedback-enhanced flow for heuristic search. It is finetuned on 350nm node data and achieves strong performance on multiple operational amplifier (Op-Amp) netlists across various technology nodes without additional training.

Result: EasySize outperforms AutoCkt on 86.67% of tasks with over 96.67% simulation resources reduction across 180nm, 45nm, and 22nm technology nodes without the need for targeted training. It showcases the potential to accelerate and simplify analog circuit design processes by reducing the dependency on human expertise and computational resources.

Conclusion: EasySize, a lightweight gate sizing framework based on a finetuned Qwen3-8B model, demonstrates strong performance across different technology nodes and outperforms AutoCkt in simulation resource reduction and task completion. It reduces reliance on human expertise and computational resources in analog circuit design.

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [12] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 本研究通过实验评估了苏格拉底人工智能导师，发现与未受指导的人工智能聊天机器人相比，苏格拉底导师可以显著提供更多支持，促进学生的批判性、独立性和反思性思维。研究提出了多代理系统的概念和适应性提供和使用模型，为支持不同学习轨迹提供了教育转变的概念路线图。最后，进行了成本效益分析，强调了这种系统的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 探索对话型人工智能对学生思维和学习的影响，提出一种支持多样化学习轨迹的教育转变。

Method: 通过实验评估了一种苏格拉底人工智能导师，比较了其与未受指导的人工智能聊天机器人的交互作用，针对65名德国职前教师学生进行了研究。引入了多代理系统的概念，提出了编排多代理系统的概念以支持多样化学习轨迹。提出了适应性提供和使用模型，以支持学生从代理系统中获取教学资源。最后进行了成本效益分析，评估了这种系统的可扩展性。

Result: 研究发现使用苏格拉底人工智能导师的学生报告了更大的支持，促进了批判性、独立性和反思性思维，表明对话型人工智能有助于刺激元认知参与。

Conclusion: 研究表明对话型人工智能可以刺激元认知参与，挑战了由于生成式人工智能使用而导致技能下降的最近说法。提出了多代理系统的概念，支持不同学习轨迹的一种教育转变。介绍了编排多代理系统的概念，以支持通过不同角色和协调互动实现的多样化学习轨迹。提出了适应性提供和使用模型，学生可以从这些代理系统中获取教学资源。研究还探讨了高等教育机构和学生在系统层面上的影响，包括资金需求、教职角色的变化、课程设置、学术能力和评估实践的变化。最后进行了成本效益分析，突显了这种系统的可扩展性。总而言之，研究为融合人工智能协助和教育对齐的混合学习生态系统提供了经验证据和概念路线图。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [13] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 本文提出了一种异质图神经网络模型，用于处理包含不完整事件的追踪，并在不同类型的缺失数据上评估其性能。该方法在重建所有不同事件属性方面表现出良好性能。


<details>
  <summary>Details</summary>
Motivation: 对于流程挖掘中的事件日志质量至关重要，现实世界中的事件日志数据获取可能不容易，常常会存在一些缺失信息。标准方法要么需要一个流程模型来填补缺失值，要么利用机器学习/深度学习模型从类似案例中学习以恢复缺失值。近年来，出现了一种能够处理以图形编码的输入数据的新型深度学习模型，即图神经网络。

Method: 本文专注于开发一种异质图神经网络模型，用于处理包含不完整事件的追踪，并恢复这些事件缺失的全部属性。

Result: 通过在合成日志和四个真实事件日志上的实验评估，提出的方法在重建所有不同事件属性方面表现出良好性能。

Conclusion: 本文提出了一种异质图神经网络模型，用于完善包含不完整事件的追踪，并在合成日志和四个真实事件日志上评估了其性能。与现有的基于自动编码器的方法不同，该方法在重建所有不同的事件属性方面表现出很好的性能。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [14] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon is a system that enhances reasoning performance in Knowledge-Intensive Visual Question Answering tasks by incorporating domain-specific reasoning, dynamic retrieval strategy selection, and multimodal search agents. It outperformed baselines by notable margins in various challenging scenarios, achieving significant improvements in answer accuracy and knowledge overlap scores during evaluation at a competition.


<details>
  <summary>Details</summary>
Motivation: Address the limitations of existing Retrieval-Augmented Generation (RAG) methods by enabling multimodal, multi-turn, and multi-hop reasoning for complex Visual Question Answering tasks that require up-to-date factual knowledge.

Method: Introduce a domain router for domain-specific reasoning, implement a search router for dynamic retrieval strategy selection, and orchestrate text and image search agents in a hybrid setup. Evaluate the system on the Meta CRAG-MM Challenge at KDD Cup 2025 to demonstrate its effectiveness in improving answer accuracy and knowledge overlap scores.

Result: QA-Dragon achieves substantial improvements in answer accuracy and knowledge overlap scores, surpassing baselines by 5.06% on the single-source task, 6.35% on the multi-source task, and 5.03% on the multi-turn task during evaluation at the Meta CRAG-MM Challenge at KDD Cup 2025.

Conclusion: QA-Dragon is a Query-Aware Dynamic RAG System that effectively enhances reasoning performance in Knowledge-Intensive Visual Question Answering tasks, outperforming baselines by notable margins in various challenging scenarios and tasks.

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [15] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 本文提出一种结合RDF图数据库和LLMs的新框架，用于处理自然语言查询，实现精准受众定位和透明推理，提高组织内沟通的效率和可信度。


<details>
  <summary>Details</summary>
Motivation: 在大型维护组织中，传统的沟通方式无法有效解决识别专家并管理复杂实体关系间沟通的挑战，包括信息过载和较长的响应时间。因此，需要一种新颖的框架来提高沟通效率并保持系统的可信度。

Method: 结合RDF图数据库和LLMs，采用规划编排架构处理自然语言查询，实现精准受众定位和透明推理。

Result: 提出的新框架能够改善组织内的沟通效率，使通信所有者能够制定直观查询并获得可解释的结果，从而提高沟通的透明度和效率。

Conclusion: 提出一种结合RDF图数据库和LLMs的新框架，在处理自然语言查询时实现精准受众定位，并通过规划编排架构提供透明推理。该解决方案使通信所有者能够制定直观查询，结合设备、制造商、维护工程师和设施等概念，提供可解释的结果，保持对系统的信任并提高组织内的沟通效率。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [16] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 该论文提出了一种混合架构，将决策树-based符号推理和大型语言模型（LLMs）相结合，在统一的多Agent框架中实现了强大性能。系统通过决策树和LLMs的集成，实现了可解释的规则推断和推测推理，同时维护信念状态一致性。在各种推理基准上得到了显著提升，在临床决策支持和科学发现等领域具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 先前的方法在符号推理和神经网络之间存在松散耦合，本文旨在将决策树和LLMs在统一系统中紧密集成，以实现可解释的规则推断、推测推理和高效的多智能Agent推理。中央协调器的引入有助于维护信念状态的一致性，同时通过集成符号推理和神经网络模块，提高推理准确性和性能。

Method: 论文提出了一种混合架构，将决策树-based符号推理和大型语言模型（LLMs）相结合，并在协调的多Agent框架内实现。决策树和随机森林被嵌入到一个统一的推理系统中作为可调用的预言者，实现了基于树的模块和LLM代理的交互。中央协调器维护信念状态的一致性，促进代理和外部工具之间的通信。在多种推理基准上，系统实现了优异的性能。

Result: 论文提出的混合架构结合了决策树-based符号推理和LLMs的生成能力，在多Agent框架中展现出强大性能。通过在不同推理基准上的实验，系统在包含一致性、多步数学问题准确率和抽象准确性方面取得了显著提升，同时在临床决策支持和科学发现等领域展现了广泛的应用前景。

Conclusion: 该论文提出了一种混合架构，将基于决策树的符号推理与大型语言模型（LLMs）的生成能力在协调的多Agent框架中集成。通过将决策树和随机森林作为可调用的预言者嵌入到统一的推理系统中，与先前松散耦合符号和神经模块的方法不同。基于树的模块实现了可解释的规则推断和因果逻辑，而LLM代理处理推测推理、泛化和交互式规划。中央协调器维护信念状态的一致性，并在代理和外部工具之间进行通信，实现对结构化和非结构化输入的推理。该系统在推理基准上取得了较强的性能。在ProofWriter上，通过逻辑基础的树验证，提高了7.2%的包含一致性。在GSM8k上，通过符号增强实现了多步数学问题的5.3%准确率提升。在ARC上，通过符号预言者的集成，将抽象的准确性提高了6.0%。在临床决策支持和科学发现中的应用展示了该系统如何在编码领域规则的同时利用LLMs进行上下文推理和假设生成。这种架构为通用神经符号推理提供了稳健、可解释和可扩展的解决方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [17] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 该论文讨论了人工智能中"agent"一词的歧义性，提出了重新定义的框架，明确了系统被视为"agent"所需的最低要求，并对系统进行了多维度光谱表征，为术语标准化和框架采纳提供了具体建议，有助于提升研究清晰度和可重复性，支持更有效的政策制定。


<details>
  <summary>Details</summary>
Motivation: 最近人工智能能力的发展增加了"agent"一词的歧义性，给研究沟通、系统评估和可重复性以及政策发展带来了重大挑战。

Method: 结合历史分析和当代使用模式，提出了重新定义"agent"的框架，并对潜在的反对意见和实施挑战进行了探讨，为领域发展提供了具体建议，并推动术语标准化和框架采纳。

Result: 提出了一个根据多维度光谱对系统进行表征的框架，为系统描述提供了明确词汇，支持研究清晰度和可重复性的提升，同时促进更有效的政策制定。

Conclusion: 该论文主张需要重新定义人工智能中的"agent"一词，提出了一个框架，明确了系统被视为"agent"所需的最低要求，并沿着环境交互、学习和适应性、自治性、目标复杂性和时间连贯性等多维度光谱对系统进行表征。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [18] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: 本研究介绍了NomicLaw，一个多主体仿真环境，用于探究LLMs在法律情境中的行为。研究发现LLMs在合作立法中展现了社会推理和说服能力，代理人形成联盟、背叛信任并调整策略语言影响决策。通过量化和定性分析，研究揭示了代理人之间的信任、互惠行为模式和战略性语言使用。实验结果为理解代理人行为提供了见解，为未来设计能够在法律领域进行自主谈判、协调和立法的AI系统提供启示。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在处理基本文本任务方面取得了进展，但在开放式、多主体环境中，尤其涉及法律和伦理困境的理解仍然有限。本研究旨在揭示LLM在复杂法律情景下的行为，探讨代理人之间的信任、互惠以及战略互动。通过引入NomicLaw仿真环境，研究探索了LLMs在协作立法中的表现，并希望为未来设计能够在法律领域进行自主谈判、协调和立法的AI系统提供启示。

Method: 本研究设计了NomicLaw，这是一个结构化的多主体仿真环境，通过引入LLMs在复杂法律情境中进行合作立法。研究通过量化方法衡量了信任和互惠，并通过定性评估代理人的战略语言使用。实验涉及不同类型的LLM组，以观察代理人的行为模式和决策影响。

Result: 研究结果表明，在NomicLaw仿真环境中，LLMs展现出潜在的社会推理和说服能力，代理人之间形成联盟、背叛信任，并灵活调整策略语言来影响集体决策。通过量化和定性分析，研究揭示了代理人之间的信任、互惠行为模式以及战略性语言使用。此外，实验涉及不同类型的LLM组，为理解代理人行为和决策提供了见解。

Conclusion: 本研究介绍了NomicLaw，这是一个结构化的多主体仿真环境，在这个环境中，LLMs参与协作立法，通过提出规则、理由以及对同行提议进行投票来回应复杂的法律情景。研究量化地衡量了通过投票模式来的信任和互惠，并定性评估了代理人如何使用战略性语言来证明提议并影响结果。实验涉及同质和异质LLM组，展示了代理人如何自发形成联盟、背叛信任，并调整其论辩方式来塑造集体决策。研究结果突显了十个开源LLM的潜在社会推理和说服能力，为未来能够在法律环境中进行自主谈判、协调和起草立法的AI系统设计提供了见解。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [19] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 本文研究了在描述逻辑中处理纯最小模型的问题。发现对于常见DLs，概念满足性在最小模型中是不可判定的。通过加强TBox的无环条件，降低了最坏情况复杂度，并在DL-Lite家族中得出了相关结果。


<details>
  <summary>Details</summary>
Motivation: 尽管在描述逻辑（DLs）中，通过最小化某些选定的谓词，让其余谓词变化或固定的思路被研究和展示了高复杂性，但对于‘纯’最小模型的情况仍了解有限。由于此问题有待探索，我们着手研究如何处理常见DLs中的概念可满足性问题。

Method: 研究了在常见DLs中处理‘纯’最小模型的问题，并表明概念可满足性在最小模型中是不可判定的。通过在TBox施加无环条件，降低了最坏情况复杂度，并与点对点缩小建立了联系。同时就数据复杂度得出了结果。

Result: 我们发现概念可满足性在最小模型中是不可判定的，并且这种不可判定性还扩展到一种非常受限制的元组生成依赖片段。通过加强TBox的无环条件，我们降低了最坏情况复杂度，并在DL-Lite家族中也得出了相关结果。

Conclusion: 在最小模型中处理概念可满足性问题时，我们发现对于\(\mathcal{EL}\)来说是不可判定的。通过对TBox施加无环条件，使得最坏情况复杂度降低到双指数时间以下，同时与最近研究的点对点缩小建立了联系。另外，在数据复杂度方面也得出了相关结果。对于DL-Lite$_{\text{horn}}$的扩展DL-Lite$_{\text{core}}$，我们已经确定其为ExpSpace-hardness。

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [20] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: Existing Vision-Language Models face challenges in complex reasoning tasks that require partial correctness. StructVRM method introduces fine-grained feedback and partial credit scoring through a model-based verifier, addressing these limitations effectively. Extensive experiments demonstrated state-of-the-art performance of Seed-StructVRM on various benchmarks, validating the effectiveness of training with structured, verifiable rewards.


<details>
  <summary>Details</summary>
Motivation: Traditional reward mechanisms are insufficient for guiding models through complex reasoning tasks with multiple sub-parts. The need for nuanced, partial credit scoring in such problems led to the development of StructVRM.

Method: Introducing StructVRM, a method aligning multimodal reasoning with Structured and Verifiable Reward Models. It includes a model-based verifier trained to assess semantic and mathematical equivalence for fine-grained feedback, allowing for partial credit scoring in intricate problems.

Result: Extensive experiments showed that the trained model, Seed-StructVRM, achieved state-of-the-art performance on six out of twelve public multimodal benchmarks and a high-difficulty STEM-Bench. The success of StructVRM validates training with structured, verifiable rewards as an effective approach for enhancing multimodal models in real-world reasoning domains.

Conclusion: StructVRM method effectively addresses the limitations of existing Vision-Language Models in complex, multi-question reasoning tasks by providing fine-grained, sub-question-level feedback and enabling nuanced, partial credit scoring.

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [21] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 该论文提出了一种实时数据驱动的预测性维护解决方案，通过在线处理流水线实现样本预处理、机器学习分类和结果解释。重点是专门的样本预处理和可解释性模块。实验结果显示高达98％的F-measure和99％的准确性。该方法在铁路预测性维护方面具有重要意义，可实现高准确性、减少成本、提高安全性和最大化服务可用性。流水线实现了高性能, 可解释性并成功应用于实际铁路运营中。


<details>
  <summary>Details</summary>
Motivation: 本论文的动机在于为智能交通系统提供一种实时数据驱动的预测性维护解决方案。作者强调了在线故障预测和解释性的重要性，以实现更高的准确性和服务可用性。在铁路预测性维护领域，准确的故障预测对于降低成本、提高安全性以及最大化服务可用性至关重要。作者还注意到了类不平衡和噪声对系统性能的影响，并试图验证方法的可靠性和实用性。

Method: 该论文的方法实现了一个处理流水线，包括样本预处理、使用机器学习模型进行增量分类和结果解释。其中，一个独特之处是专门的样本预处理模块，在运行时构建统计和与频率相关的特征。另一个亮点是提出了一个可解释性模块，首次进行在线故障预测并提供自然语言和视觉解释能力。实验使用了波尔图地铁运营商的MetroPT数据集。

Result: 实验结果显示，该方法在F-measure和准确性方面表现出色，超过了98％和99％。分析表明，处理流水线在类不平衡和噪声存在的情况下仍保持高性能，并有效地解释决策过程。这些发现验证了方法的可行性和实际适用性，为支持铁路运营中的预防性维护决策提供了有效工具。

Conclusion: 该论文为智能交通系统提供了一种实时数据驱动的预测性维护解决方案。通过提出的方法实现了一个处理流水线，包括样本预处理、使用机器学习模型进行增量分类和结果解释。该在线处理流水线的两个主要亮点是：(i) 专门的样本预处理模块，在运行时构建统计和与频率相关的特征，以及 (ii) 一个可解释性模块。该研究首次使用自然语言和视觉解释能力进行在线故障预测。实验使用了葡萄牙波尔图地铁运营商的MetroPT数据集。结果显示F-measure超过98％，准确性超过99％。在铁路预测性维护领域，实现这些高数值至关重要，因为准确的故障预测对于提高服务可用性具有实际和运营意义。特别是在高F-measure的情况下，这确保系统在最大程度检测到真实故障的同时最大限度地减少误报警，这对于最大化服务可用性至关重要。此外，获得的准确性能够保证可靠性，直接影响成本降低和安全性提升。分析表明，该流水线即使在类不平衡和噪声存在的情况下也能保持高性能，并且其解释有效地反映了决策过程。这些发现验证了方法的方法论的合理性，并确认了其在支持现实世界铁路运营中的积极维护决策方面的实际适用性。因此，通过识别故障的早期迹象，该流水线使决策者能够理解潜在问题并迅速采取行动。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [22] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: 本文介绍了DeepPHY，一个旨在评估VLMs对基本物理原理理解和推理能力的基准框架。评估结果显示，即使是最先进的VLMs也难以将描述性物理知识转化为精确、可预测的控制。


<details>
  <summary>Details</summary>
Motivation: VLMs在处理复杂、动态环境中的细节关注和精确行动规划方面遇到困难，需要跨越现实世界任务和物理规则理解之间的鸿沟。

Method: 介绍了DeepPHY，这是一个新颖的基准框架，旨在通过一系列具有挑战性的模拟环境系统地评估VLMs对基本物理原理的理解和推理能力。

Result: 评估发现，即使是最先进的VLMs也难以将描述性物理知识转化为精确、可预测的控制。

Conclusion: 即使是最先进的视觉语言模型也在将描述性物理知识转化为精确、可预测的控制方面遇到困难。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [23] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在化学领域的应用。通过与图神经网络、量子计算和实时光谱学的结合，LLMs能够加速发现周期，支持更环保的数据驱动化学实验。研究指出了LLMs的限制，如数据偏见和不透明的推理，并提出了开放基准、联邦学习和可解释的接口等社区倡议以解决这些问题。最终目标是促进分子创新的发展，以人工智能和自动化技术为驱动。


<details>
  <summary>Details</summary>
Motivation: 本研究动机在于探讨大型语言模型在有机合成中的潜在应用，并指出了将这些模型与其他技术相结合的潜在好处。研究旨在解决化学实验中的一些挑战，如发现周期长、支持不足等问题，以提高实验效率和环保性。同时也意在弥补LLMs存在的一些局限性，如数据偏见和不透明性，通过引入安全门等方式保证实验安全。最终的目标是推动分子创新的发展，以人工智能和自动化技术为驱动。

Method: 本文调查了LLMs如何与图神经网络、量子计算和实时光谱学相结合，以支持更快速、环保和数据驱动的化学实验。还讨论了LLMs的一些限制，包括偏见数据集、不透明的推理和安全门的需要。此外，概述了一些社区倡议，如开放基准、联邦学习和可解释的接口，旨在民主化访问并保持人类控制。

Result: 通过本研究，我们深入了解了大型语言模型在化学实验中的应用前景和局限性。结合图神经网络、量子计算和实时光谱学，LLMs能够加速发现周期，支持更环保的数据驱动化学实验。然而，该研究也指出了LLMs存在的一些问题，如数据偏见和不透明的推理，以及提出了相应的解决方案。最后，社区倡议的概述表明，开放基准、联邦学习和可解释的接口有望促进人们更广泛地访问这些先进技术，同时保持对实验的控制。

Conclusion: 大型语言模型(大型LLMs)开始重塑化学家在有机合成中的反应规划和运行方式。通过对数百万份报告的转化进行训练，这些基于文本的模型可以提议合成路径，预测反应结果，甚至指导执行实验的机器人而无需人类监督。本文调查了将LLMs从理论工具转变为实际实验室合作伙伴的里程碑。我们展示了如何将LLMs与图神经网络、量子计算和实时光谱学相结合，缩短发现周期，支持更环保、数据驱动的化学。我们讨论了一些限制，包括偏见数据集、不透明的推理以及需要防止意外危险的安全门。最后，我们概述了社区倡议：开放基准、联邦学习和可解释的接口，旨在使人们可以民主地访问，同时保持人类牢牢控制。这些进展为通过人工智能和自动化推动的快速、可靠和包容性的分子创新铺平了道路。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [24] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 本文探讨了AI对齐度的地理变量影响，强调了全球文化与政治差异对AI行为的重要性，提出了对于时空感知对齐度的需求，并为未来研究提供了研究方向和评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有文献已经涵盖了关于对齐度中偏见和不平等性的讨论，但对于地理变量对对齐度的影响仍未充分研究。鉴于全球范围内文化、政治、法律的差异，有必要深入探讨AI系统如何在不同地区被看待，本文的动机即在于填补这一研究空白。

Method: 本文回顾了关于地理变量对AI对齐度的影响的文献，并提出了未来工作的主题。同时，本文概述了评估对齐度敏感性的方法，强调了对于时空感知对齐度的需求。

Result: 通过研究对齐度在地理变量上的敏感性，强调了时空感知对齐度的紧迫性，并为未来研究提出了相关主题和方法。

Conclusion: 在AI领域中，确保AI系统遵循社会规范和目标的挑战越发重要。由于文化、政治现实和法规的不同，全球各地对于何为适当、真实或合法的认知存在较大差异，这也体现在AI对齐度上。AI/ML工作流中应用的对齐度措施有时会产生脱离统计现实的结果，例如文本到图像模型描绘公司领导层性别比例平衡，尽管实际存在不平衡。关键是，有些模型输出在全球范围内是可接受的，而另一些输出，例如涉及克什米尔问题的问题，取决于用户位置和背景。AI在现在以史无前例的规模和自动化方式介入知识传递、表达观点和代表地理现实，但关于如何管理背景信息方面却缺乏透明度。随着我们迈向主体性AI，对于时空感知的对齐度需求日益紧迫，而非通用方法。本文回顾了关键的地理研究问题，提出了未来工作的主题，并概述了评估对齐度敏感性的方法。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [25] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 当前AI评估依赖于传统基准，无法衡量新监管环境的系统风险。研究提出Bench-2-CoP框架，使用LLM分析基准覆盖欧盟AI法案标准。发现评估过于关注行为倾向，对关键功能性能忽视。提供首个基准-监管差距的全面量化分析，为政策制定者和开发者提供关键见解。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估做法并未充分考虑新的监管环境带来的系统风险，有必要建立一种新的框架来衡量这种“基准-监管差距”。本研究的动机在于填补这一缺口，以提供量化分析和洞察，为政策制定者和开发者提供指导，促进更安全、符合法规的AI发展。

Method: 研究介绍了Bench-2-CoP框架，使用LLM作为评判者分析基准中的问题并将其与欧盟AI法案的能力和倾向分类进行比较。发现评估过度关注狭窄的行为倾向，对关键功能性能忽略严重。提供了第一份关于基准-监管差距的全面、定量分析，为政策制定者和开发者提供了宝贵见解。

Result: 研究发现现有评估生态系统过于关注狭窄的行为倾向，对关键功能性能关注不足，存在严重的评估漏洞。并提出了量化分析，揭示了系统性风险评估中的差距，并提供了为政策制定者和开发者改进评估工具的见解。

Conclusion: 当前AI评估实践主要依赖于既有基准，但这些工具并未设计用于衡量新的监管环境关注的系统风险。研究介绍了Bench-2-CoP，一个使用经过验证的LLM作为评判者分析的新颖系统框架，以映射广泛使用的基准中的194,955个问题与欧盟AI法案模型能力和倾向分类的覆盖范围。研究发现，评估生态系统过于集中于狭窄的行为倾向，对危险性能关注不足。关键的功能性能中心，如逃避人类监督、自我复制和自主AI发展，在整个基准语料库中都没有涵盖。这导致系统风险的评估几乎完全缺失。研究为政策制定者精细调节CoP和开发者构建下一代评估工具提供了关键见解，最终促进更安全、符合法规的AI发展。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [26] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 该研究使用小型、资源高效的大型语言模型生成新的ERC数据集，提高了ERC分类器模型的鲁棒性，并在现有ERC基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决ERC数据稀缺、现有数据集面临的挑战以及大型语言模型（LLMs）应用于ERC任务的限制。

Method: 使用小型、资源高效的大型语言模型生成六个新的ERC数据集，其中两个专门优化了每个基准测试，评估这些数据集的实用性，并分析ERC中标签不平衡的影响。

Result: 在实验结果中，使用生成的数据集训练的ERC分类器模型表现出较强的鲁棒性，并在现有ERC基准测试中持续取得统计显著的性能改进。

Conclusion: 使用小型、资源高效且通用的大型语言模型（LLM）生成新的ERC数据集，证明了在情感识别对话中训练分类器模型的有效性，并且在现有ERC基准测试中取得了统计显著的性能提升。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [27] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign是一个可扩展且样本高效的后训练框架，通过将监督微调（SFT）和直接偏好优化（DPO）相结合，自动筛选高质量对齐数据，提高推理能力并降低数据需求。该框架在Qwen2.5-Math-7B-Base模型上实现了与DeepSeek-R1-Distill-Qwen-7B相当的性能，使用较少训练数据且在各种推理任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 通过改进筛选高质量数据的方法，减少大型语言模型后训练的数据和计算成本，提高在各种任务上的泛化性能。

Method: InfiAlign整合了监督微调（SFT）和直接偏好优化（DPO）来对齐LLMs，通过自动筛选高质量对齐数据的多维质量度量实现了显著性能提升和数据需求减少。

Result: InfiAlign框架在推理任务中取得了显著性能提升，尤其在数学推理任务上表现突出，实现了相较于DeepSeek-R1-Distill-Qwen-7B模型的类似性能，使用更少的训练数据，并能很好地泛化到不同的推理任务。

Conclusion: InfiAlign是一个可扩展且样本高效的后训练框架，结合了监督微调（SFT）和直接偏好优化（DPO）来使LLMs对增强推理进行对其。通过从开源推理数据集中自动筛选高质量对齐数据的鲁棒数据选择管道，实现了显著性能提升，同时大幅减少数据需求，并可扩展至新数据源。该框架在Qwen2.5-Math-7B-Base模型上获得了与DeepSeek-R1-Distill-Qwen-7B相当的性能，仅使用约12％的训练数据，对不同推理任务具有很强的泛化能力。通过应用DPO，特别是在数学推理任务中获得了显著的改进，模型在AIME 24/25基准上取得了平均3.89％的提高。结果突显了将基于原则的数据选择与完整阶段的后训练相结合的有效性，提供了一种实用的解决方案，能够以可扩展和数据高效的方式对齐大型推理模型。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [28] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: 提出了GRAIL框架，用于处理大规模图数据进行检索增强推理。该框架集成了LLM引导的随机探索和路径筛选，并通过两阶段训练学习动态决策每个推理步骤的最佳操作。在三个知识图问答数据集上，实验结果显示GRAIL相较于现有方法有显著的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法和图检索方法在处理结构化知识图时效果有限，存在信息缺失或冗余连接等问题，限制了推理性能。提高数据效率和训练稳定性是解决这一挑战的动机。

Method: GRAIL框架集成了LLM引导的随机探索和路径筛选，通过两阶段训练过程学习策略来动态决定每个推理步骤的最佳操作。采用交互式检索范例，在实际部署中实现模型自主探索图路径并动态平衡检索广度和准确性。

Result: 在三个知识图问答数据集上，GRAIL相较于现有方法实现了平均准确率提升21.01%和F1分数提升22.43%。

Conclusion: 提出了一种名为GRAIL的框架，旨在处理大规模图数据进行检索增强推理，取得了显著的性能提升。相比现有的RAG方法和图检索方法，GRAIL能够更有效地处理结构化知识图，提高数据效率和训练稳定性，并在知识图问题回答数据集上实现了显著的准确性和F1分数提升。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [29] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 本文提出了一个通用且模块化的框架，用于评估智能Agent的任务完成情况，独立于任务领域。通过任务分解、验证每步完成情况并汇总模块输出得出最终评判，验证了框架在两个基准测试下的有效性，Judge Agent的预测比现有基线更接近人类评估，对齐准确率分别高出4.76%和10.52%。


<details>
  <summary>Details</summary>
Motivation: 当前的评估方法往往忽略了智能Agent决策过程中的推理步骤，现有的Agent-as-a-Judge系统则通常设计用于狭窄的领域特定设置。针对这一缺口，本文的动机是提出一个通用的框架，模拟人类式的任务评估过程，以更全面地评估Agent的任务完成情况。

Method: 提出了通用且模块化的评估框架，对任务进行分解，验证每一步的完成情况，并汇总模块输出以得出最终评判。通过对Magentic-One Actor Agent在两个基准测试下的验证，证明了框架的有效性。

Result: 在GAIA和BigCodeBench基准测试中，我们的Judge Agent预测任务成功与人类评估更为接近，比基于GPT-4o的LLM-as-a-Judge基准线高出4.76%和10.52%的对齐准确率。这表明了提出的通用评估框架的潜力。

Conclusion: 本文提出了一个通用且模块化的框架，用于评估智能Agent的任务完成情况，独立于任务领域。通过对任务进行分解，并利用可用信息（如Agent的输出和推理过程）验证每一步，最终汇总不同模块的输出以产生任务完成的最终评判。在GAIA和BigCodeBench两个基准测试下验证了该框架，发现我们的Judge Agent预测任务成功与人类评估更为接近，分别比基于GPT-4o的LLM-as-a-Judge基准线高出4.76%和10.52%的对齐准确率。这证明了我们提出的通用评估框架的潜力。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [30] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: 研究引入了LORI工具，利用自然语言处理和大型语言模型识别LOR中的领导属性，以支持研究生录取过程中对申请者领导能力的评估。最新的RoBERTa模型取得了良好的性能，准确评估了申请者的领导能力，简化了录取流程并确保了综合评估。


<details>
  <summary>Details</summary>
Motivation: LORs提供了超越标准化考试成绩的有价值见解，但审阅这些文本密集的材料耗时且费力。为了支持招生委员会提供学生专业成长的反馈，引入了LORI工具。

Method: 使用自然语言处理和RoBERTa、LLAMA等大型语言模型，识别LOR中的领导属性，如团队合作、沟通和创新。

Result: 最新的RoBERTa模型在测试数据中取得了91.6%的加权F1分数，92.4%的精度和91.6%的召回率，表现出很强的一致性。

Conclusion: 介绍了一种基于AI的工具LORI，用于评估在线硕士项目申请者的领导能力，最新的RoBERTa模型在测试数据中取得了91.6%的加权F1分数，92.4%的精度和91.6%的召回率，为准确评估申请者领导能力提供了强有力的支持。将LORI整合到研究生录取流程中对于评估申请者领导能力至关重要，并可以简化录取流程，自动化并确保对候选人能力的更全面评估。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [31] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: Social media presents challenges in identifying harmful intent. The paper proposes MV-Debate, a framework with four debate agents, to improve harmful content detection accuracy in online contexts.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of identifying harmful intent on social media, such as sarcasm, hate speech, and misinformation, caused by cross-modal contradictions, rapid cultural shifts, and subtle pragmatic cues. The paper aims to improve reliable social intent detection in safety-critical online contexts.

Method: Proposed MV-Debate, a multi-view agent debate framework with dynamic reflection gating, consisting of four debate agents: surface analyst, deep reasoner, modality contrast, and social contextualist. The framework utilizes iterative debate and reflection to refine responses under a reflection-gain criterion.

Result: MV-Debate significantly outperforms existing methods in detecting harmful content on social media based on experiments on three benchmark datasets.

Conclusion: MV-Debate, a multi-view agent debate framework, outperforms strong single-model and existing multi-agent debate baselines in detecting harmful content on social media. The experiment results demonstrate its significant improvement in accuracy and efficiency compared to existing methods.

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [32] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 本文认为主动推理是发展自主学习AI代理的关键，提出了通过内在驱动最小化自由能量取代外部奖励信号的方法，以弥合AI系统在自主制定目标方面的不足。通过与大型语言模型结合，创造了能够高效学习并符合人类价值观的AI代理。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统在面临数据整理瓶颈的同时，对奖励设计依赖日益增多的人力资源，从而面临着显著的可扩展性挑战。当前的AI系统在对自主制定、适应和追求目标方面存在不足，无法应对变化环境。因此，提出了利用主动推理来弥合这一差距的动机。

Method: 本文提出了通过主动推理来取代外部奖励信号，使代理能够自然地在探索和利用之间保持平衡的方法。将大型语言模型与主动推理框架相结合，创造了能够有效从经验中学习并与人类价值观保持一致的代理。

Result: 通过主动推理取代外部奖励信号的方法可以使代理在探索和利用之间达到平衡，并创造出能够高效学习并与人类价值观保持一致的AI代理。

Conclusion: 本文认为主动推理提供了发展自主学习AI代理的关键基础，能够使其在无需持续人类奖励工程的情况下从经验中学习。提出了“经验时代”的构想，其中代理从自生成的数据中学习，这是向前迈出的一大步。然而，这一愿景仍然依赖于对奖励功能的广泛人类工程，有效地将瓶颈从数据整理转移到奖励整理。建议主动推理可以通过用内在驱动来最小化自由能量取代外部奖励信号来弥合当代AI系统自主制定、适应和追求目标的不足。将大型语言模型与主动推理的基于原则的决策框架相结合，可以创造出能够以人类价值观为导向、从经验中高效学习的代理。这种综合提供了一条引人入胜的道路，使AI系统能够在遵守计算和物理约束的同时自主发展。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [33] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 本研究引入LearnerAgent框架，通过模拟教学环境并构建不同类型学习者，发现只有深度学习者能持续认知增长，浅层学习者知识受限。不同学习者的行为与心理特征相关，LLMs的默认行为为“努力但脆弱的表层学习者”。模拟实验验证了LearnerAgent框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕获学习动态和提供解释能力，本研究旨在通过模拟学习环境，深入探索LLMs的行为，了解不同类型学习者的学习过程与认知特点。

Method: 引入LearnerAgent多智能体框架，借助大语言模型模拟教学环境，构建不同类型学习者并进行周知识获取、月策略选择、定期测试和同伴互动以进行学习进展跟踪。

Result: 本研究发现深度学习者实现持续认知增长，浅层学习者受限于知识表面；不同学习者的认知模式与心理特征吻合；LLMs的默认行为为“努力但脆弱的表层学习者”。通过模拟实验，LearnerAgent框架得到了验证，并为LLMs的研究提供了新的见解。

Conclusion: 通过LearnerAgent框架，深度学习方法可以捕捉人类学习行为，发现只有深度学习者能够持续认知增长，浅层学习者的知识能力受限。不同学习者的行为和认知模式与其心理特征密切相关。通过模拟真实教学环境，该研究揭示了LLMs的默认行为特征，为人类学习动态和进展提供了新的认识。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>
