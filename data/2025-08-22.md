<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 37]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种基于图信号处理的光谱神经符号推理架构，通过光谱滤波器处理图信号，实现多尺度信息传播，进而提升逻辑一致性、可解释性和计算效率。实验结果表明，该方法优于现有的神经符号模型。


<details>
  <summary>Details</summary>
Motivation: 传统推理模型将光谱图方法视为外围组件，但该方法在图光谱域中制定整个推理流程，将逻辑实体和关系编码为图信号进行处理。

Method: 提出了一种基于图信号处理的光谱神经符号推理架构，通过可学习的光谱滤波器处理图信号，控制多尺度信息传播，并映射成符号谓词进行基于规则的推理。

Result: 实验结果表明，在基准推理数据集上（ProofWriter，EntailmentBank，bAbI，CLUTRR和ARC-Challenge）与现有的神经符号模型相比，在逻辑一致性、可解释性和计算效率方面都取得了改进。

Conclusion: GSP提供了数学基础和计算效率，为强大且可解释的推理系统提供了可靠的基础。

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [2] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 本文描述了一个计算框架，其中代理-环境交互序列或经验中的描述性和规范性世界模型相互出现，提供了目标导向学习的简明解释。通过引入目标导向状态，作者提出了一种新的视角来理解目标导向学习和行为，可能有助于提供对不同基质中有目的行为的统一解释。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨目标导向行为和认知代理之间的关系，提出了一个新的计算框架，旨在从代理-环境交互中推导描述性和规范性世界模型的方面，以提供对有目的学习和行为的统一解释。

Method: 作者描述了一个目标导向状态表示的计算框架，其中世界模型的描述性和规范性方面是从代理-环境交互序列或经验中相互出现的。引入了目标导向状态的构建，定义为目标等效经验分布类。这些目标导向状态通过行为策略和理想经验特征之间的统计分歧来解释目标导向学习。

Result: 通过引入目标导向状态表示的计算框架，并阐述目标导向状态的概念和作用，作者提出了一种新的视角来理解有目的学习和行为。该视角可能有助于提供对行为、现象学和神经维度中有目的行为的统一解释。

Conclusion: 本文描述了一个目标导向状态表示的计算框架，其中世界模型的描述性和规范性方面是从代理-环境交互序列或经验中相互出现的。作者介绍了目标导向状态的构建，提出了目标等效经验分布类的概念。这些目标导向状态通过行为策略和理想经验特征之间的统计分歧提供了目标导向学习的简明解释。文章回顾了支持这一新颖观点的经验和理论文献，并讨论了其潜力，可以提供对跨多种基质的有目的行为的行为、现象学和神经维度的统一解释。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [3] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: Collab-REC introduces a multi-agent approach using LLM-based agents and a moderator to enhance tourism recommendations, showing improvements in diversity and relevance in European city suggestions.


<details>
  <summary>Details</summary>
Motivation: Countering popularity bias, enhancing diversity in tourism recommendations, surfacing lesser-visited locales, addressing over-tourism, aligning with user constraints.

Method: Utilizes three LLM-based agents (Personalization, Popularity, Sustainability) and a non-LLM moderator for multi-round negotiation and proposal merging.

Result: Improves diversity and relevance in European city recommendations compared to a single-agent baseline.

Conclusion: Collab-REC, a multi-agent framework, improves diversity and overall relevance in tourism recommendations, addressing over-tourism and aligning with user constraints.

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [4] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 该论文提出了一种新颖的方法，利用大型语言模型（LLMs）控制代理人的移动，以实现更逼真的人群动画和模拟。方法包括对话系统和语言驱动的导航，使代理人基于感知输入和对话做出运动决策。作者验证了方法的有效性，展示了在复杂场景中产生更真实的群体行为，以及方法作为信息传递机制的效果。


<details>
  <summary>Details</summary>
Motivation: 人类在拥挤环境中的导航和移动常常受到复杂的社交和环境影响，主要受到语言和对话的驱动。现有的工作大多没有考虑这些维度，导致动画中代理人之间和代理人与环境之间的交互局限于转向和固定的高级目标预测。因此，作者提出了一种新颖的方法，旨在解决这一问题。

Method: 论文提出了一种利用大型语言模型控制代理人移动的方法。该方法包括对话系统和基于语言驱动的导航，通过周期性查询代理人中心的LLMs来生成代理人之间的对话，并利用对话内容和每个代理人的特征来控制他们的导航和转向。通过这种方式，代理人可以基于感知输入和对话来做出移动决策。

Result: 作者通过两个复杂场景验证了他们的方法，展示了社交互动、转向和拥挤之间的相互作用，以及代理人自动聚合和解聚的效果。实验证明他们的方法作为信息传递机制，在人群内产生更加真实的模拟结果，使得群体行为能够自然涌现。

Conclusion: 该论文提出了一种新颖的方法，利用大型语言模型（LLMs）控制代理人的移动，以实现更逼真的人群动画和模拟。他们的模型使代理人能够基于感知输入和进行中的对话做出运动决策，实现了群体行为的自然涌现。通过在复杂场景中验证他们的方法，展示了社交互动、转向和拥挤之间的相互作用，以及代理人自动聚合和解聚的效果。论文的结论强调了他们的方法作为人群内的信息传递机制，产生了更加真实的人群模拟结果。

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [5] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: 本研究评估了推理能力和预算如何影响信心评估准确性，发现搜索增强生成方法显著优于纯推理，且信息获取可能是提高信心校准的关键。


<details>
  <summary>Details</summary>
Motivation: 为了避免过度确信，需要对大语言模型进行有效校准。

Method: 系统评估推理能力和预算如何影响信心评估准确性，使用ClimateX数据集并扩展到人类和地球健康。

Result: 最近的推理大语言模型在评估专家信心方面的准确率为48.7%，信息检索增强生成方法可以达到89.3%的准确率。推理预算的增加导致系统性过度确信，并且随着预算增加而恶化。

Conclusion: 研究发现，通过搜索增强生成方法显著优于纯推理，在专家信心评估方面表现出色。推理预算的增加会导致过度确信，而不是改进校准。信息获取而非推理深度或推理预算可能是知识密集任务信心校准改进的关键瓶颈。

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [6] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: 该论文展示了利用深度学习和光谱分析算法在CS-6卫星上进行数据分析和推断，为多种应用提供新的地球科学测量和响应能力。


<details>
  <summary>Details</summary>
Motivation: 合作伙伴Ubotica Technologies与喷气推进实验室（Jet Propulsion Laboratory）合作，展示了CS-6卫星上最先进的数据分析。通过在边缘进行数据分析，可以开启新的地球科学测量和响应方法。

Method: 利用CS-6卫星的可见光和近红外范围高光谱仪器和神经网络加速硬件，在边缘（例如卫星上）执行数据分析。

Result: 通过在CS-6卫星上进行数据分析和推断，可实现各种应用的新地球科学测量和响应。

Conclusion: 该论文展示了在CS-6卫星上利用深度学习和光谱分析算法进行数据分析和推断的方法，可以为多种应用提供新的地球科学测量和响应能力。

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [7] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA is a lightweight, data-free, and model-independent framework designed to mitigate safety risks in LoRA-adapted large language models. It leverages MAS-SVD and SSI to analyze and prune unsafe layers, improving safety metrics while maintaining task performance. Experiments demonstrate its effectiveness in enhancing safety, utility metrics, and reducing inference cost for LLM-based agents in safety-critical environments.


<details>
  <summary>Details</summary>
Motivation: Existing safety-aware adaptation methods for large language models often require access to base and instruction-tuned model checkpoints, which are not always available in practice. The motivation behind S3LoRA is to address safety risks in LoRA-adapted models without the need for extensive data or model-specific information. The goal is to enhance the safety of LLM-based agents in real-world, resource-constrained, and safety-critical environments.

Method: The paper introduces the S3LoRA framework, consisting of two main components: MAS-SVD for analyzing structural properties of LoRA updates and preserving global magnitude information, and SSI for detecting highly concentrated and potentially unsafe updates in layers. Unsafe layers are pruned post-hoc to reduce risks without compromising task performance. Extensive experiments and ablation studies are conducted across agent planning and language generation tasks to evaluate the effectiveness of S3LoRA.

Result: S3LoRA consistently improves safety metrics, preserves or enhances utility metrics, and reduces inference cost across various tasks such as agent planning and language generation. The proposed framework provides a practical and scalable solution for deploying large language models in safety-critical scenarios.

Conclusion: S3LoRA is proposed as a lightweight, data-free, and model-independent framework that mitigates safety risks in LoRA-adapted large language models by inspecting fine-tuned weight updates and pruning potentially unsafe layers. The experiments demonstrate that S3LoRA improves safety metrics while maintaining or enhancing utility metrics and reducing inference cost, making it a practical and scalable solution for deploying LLM-based agents in safety-critical environments.

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [8] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 本研究将工作人员管理视为抽象论证，通过用户研究验证了工具和解释的有效性，显示相较于传统手动解决方案更快速、更准确的问题解决效果。


<details>
  <summary>Details</summary>
Motivation: 工作人员管理是一个复杂的问题，需要优化操作队伍完成一组工作所需的时间和行程。在执行过程中适应变化并向所有利益相关者提供解释是一个关键挑战。

Method: 将工作人员管理视为工业应用中的抽象论证，以适应变化并提供解释。通过用户研究验证工具和解释的有效性。

Result: 通过研究工具和解释的效果，我们发现在工作人员管理中将其视为抽象论证的方法可以获得更好的问题解决效果。

Conclusion: 通过将工作人员管理视为工业应用中的抽象论证，我们可以适应变化并获得忠实的解释。我们展示通过用户研究，我们的工具和解释比传统的手动解决方案能够实现更快速、更准确的问题解决。

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [9] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: 研究提出了OU-AGs框架和GOOD方法，在推断和行动多样化人类目标和偏好中取得了成功。GOOD方法通过自然语言推断目标和不确定性，无需大量离线数据。在实证评估中，GOOD方法在两个领域中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: embodied AI agents需要能够理解和行动在未预定义的多样化人类目标和偏好中。现有方法要求大量离线数据集，缺乏对不断变化的可能目标空间的推理。因此，引入了GOOD方法以解决这一问题。

Method: 引入了Open-Universe Assistance Games (OU-AGs)框架和GOOD (GOals from Open-ended Dialogue)方法，通过与人类互动中提取自然语言目标，并对候选目标进行概率推断，实现了丰富的目标表示和不确定性估计。在文本购物领域和AI2Thor模拟家庭机器人环境中进行了实证评估。

Result: 在文本购物领域和AI2Thor模拟家庭机器人环境中，GOOD方法优于没有明确目标跟踪的基线方法，得到了LLM和人类评价的验证。

Conclusion: 提出了Open-Universe Assistance Games (OU-AGs)框架，以形式化embodied AI agents在未预定义的多样化人类目标和偏好中推断和行动。引入了GOOD (GOals from Open-ended Dialogue)方法，利用自然语言提取目标并推断自然语言目标的分布，以实现对不断变化的可能目标空间的推理。在文本购物领域和AI2Thor模拟家庭机器人环境中评估了GOOD方法，结果表明其优于没有明确目标跟踪的基线方法。

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [10] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: 最近的大型语言模型使得人工智能代理能够自主生成科学提案、进行实验、撰写论文和进行同行评审。然而，AI生成的研究内容与传统的出版系统发生冲突。为解决这一挑战，引入aiXiv，一个下一代开放获取平台，通过多主体架构实现人类和人工智能科学家的集成，显著提高AI生成研究的质量，加快其传播速度。


<details>
  <summary>Details</summary>
Motivation: 人工智能生成的研究内容缺乏传播渠道是一个严重问题，传统期刊和会议主要依赖人类同行评审，现有预印本服务器缺乏严格的质量控制机制。为了解决这一挑战，引入aiXiv旨在为人类和人工智能科学家提供一个开放获取平台，通过多主体架构和API / MCP接口实现人类和人工智能科学家的集成，创造一个可扩展和可扩展的生态系统。

Method: 引入了aiXiv，一个多主体架构的开放获取平台，允许人类和人工智能科学家提交、审阅和反复完善研究提案和论文，提供API和MCP接口实现集成，通过广泛实验展示aiXiv是可靠和健壮的平台，能显著提高人工智能生成研究的质量。

Result: 通过实验表明，aiXiv是一个可靠和健壮的平台，能显著提高人工智能生成的研究提案和论文的质量。该工作为人工智能科学家的下一代开放获取生态系统奠定了基础，加快了高质量人工智能生成研究内容的发布和传播。

Conclusion: 引入aiXiv，一个下一代开放获取平台，旨在解决人工智能生成的高质量研究内容缺乏传播途径的问题。通过多主体架构，允许人类和人工智能科学家共同提交、审阅和反复完善研究提案和论文，提供API和MCP接口以实现人类和人工智能科学家的无缝集成，为自主科学发现创造可扩展和可扩展的生态系统。研究表明aiXiv是可靠且健壮的平台，在aiXiv上经过反复修订和审查显著提高了人工智能生成的研究提案和论文的质量。这项工作为人工智能科学家的下一代开放获取生态系统奠定了基础，加快了高质量人工智能生成研究内容的发布和传播。

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [11] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: 本论文介绍了GUI-Owl和Mobile-Agent-v3，这是两个开源GUI代理模型，在各种GUI基准测试中表现出色。论文提出了在环境基础设施、基础代理功能和可扩展的强化学习方面的关键创新。这些模型为开源GUI代理框架树立了新的基准。


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to develop advanced GUI agent models that excel in various tasks such as grounding, question answering, planning, decision-making, and procedural knowledge across different environments. The focus is on improving performance, reducing manual annotation, and supporting diverse data pipelines.

Method: The paper introduces GUI-Owl, a foundational GUI agent model that achieves state-of-the-art performance on ten GUI benchmarks on desktop and mobile environments. It further proposes Mobile-Agent-v3, a general-purpose GUI agent framework that improves performance. The key innovations include a large-scale environment infrastructure, diverse foundational agent capabilities, and a scalable reinforcement learning framework with TRPO for online RL.

Result: GUI-Owl achieves 66.4 on AndroidWorld and 29.4 on OSWorld, while Mobile-Agent-v3 improves the performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting new benchmarks. Additionally, TRPO achieves 34.9 on OSWorld. The models are open-sourced for further research and development at https://github.com/X-PLUG/MobileAgent.

Conclusion: GUI-Owl and Mobile-Agent-v3 are open-source GUI agent models that achieve state-of-the-art performance on various GUI benchmarks. The paper presents key innovations in environment infrastructure, foundational agent capabilities, and scalable reinforcement learning. The models set new benchmarks in open-source GUI agent frameworks.

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [12] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: 该论文介绍了PuzzleClone框架，用于合成可验证数据，构建了一个包含83K多样化和程序验证难题的基准测试，并展示在训练PuzzleClone数据集上的显著改善。实验结果表明，训练在PuzzleClone上不仅提高了PuzzleClone测试集的性能，还对逻辑和数学基准测试产生了一致的改进。提供了代码和数据的开放获取。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型生成的数据集通常受到可靠性、多样性和可扩展性的限制。作者的动机在于解决这些问题，并加强大型语言模型的推理能力。

Method: 该论文的方法包括将种子难题编码为结构化逻辑规范，通过系统性变量和约束随机化生成可扩展的变体，并通过再现机制确保有效性。使用PuzzleClone构建了一个精心策划的基准测试，跨越了广泛的困难程度和格式，对当前最先进的模型提出了重大挑战。在PuzzleClone数据集上进行后训练（SFT和RL），显示出训练对PuzzleClone测试集和逻辑数学基准测试都有显著改善的结果。后期训练将PuzzleClone的平均分从14.4增至56.2，并在7个逻辑和数学基准测试中提供了多达12.5个绝对百分点（AMC2023从52.5增至65.0）的持续改善。

Result: 实验结果表明，在PuzzleClone数据集上进行训练可以显著改善逻辑和数学基准测试的表现，同时作者提供了代码和数据的开放获取。

Conclusion: 该论文介绍了一种名为PuzzleClone的正式框架，用于使用Satisfiability Modulo Theories (SMT)在规模上合成可验证数据。他们构建了一个包含超过83K多样化和程序验证的难题的基准测试，并展示了训练在PuzzleClone数据集上显著提高了逻辑和数学基准测试的实验结果。

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [13] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: LLM4Sweat is an open-source LLM framework designed for hyperhidrosis to provide personalized treatment recommendations and empathetic support. It follows a three-stage pipeline, outperforms baselines, and can be generalized to other rare diseases facing similar data challenges.


<details>
  <summary>Details</summary>
Motivation: The lack of tailor-made LLMs for rare medical conditions like hyperhidrosis, impacting physical and psychosocial well-being of individuals.

Method: Three-stage pipeline: data augmentation using a frontier LLM, fine-tuning on an open-source foundation model, and inference with expert evaluation. Clinical and psychological specialists assess accuracy, appropriateness, and empathy of the system's responses.

Result: Development of LLM4Sweat, an open-source LLM framework for hyperhidrosis with personalized treatment recommendations and empathetic support. It outperforms baselines in experiments and has the potential to address challenges in other rare diseases.

Conclusion: LLM4Sweat outperforms baselines and provides an open-source LLM framework for hyperhidrosis, offering a generalizable approach for rare diseases with similar data challenges.

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [14] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: 研究使用R-ConstraintBench框架，在资源受限的项目调度问题上评估大型语言模型性能。发现强大的模型在特定条件下表现优越，但在约束相互作用下性能下降。泛化能力有限，性能在合成环境中的表现不能简单迁移到实际场景。


<details>
  <summary>Details</summary>
Motivation: 大规模规划中的有效调度对于资本项目、制造业、物流和IT车队转换等行业至关重要。然而，大型语言模型在高约束环境下推理时的可靠性尚未得到充分描述。因此，作者希望填补这一空白，提出了R-ConstraintBench框架。

Method: 研究使用了一个名为R-ConstraintBench的框架，并在数据中心迁移设置中实例化了基准测试，评估了多个大型语言模型的性能。通过可行性和错误分析，识别了与失败最相关的降解阈值和约束类型。

Result: 研究发现，当停机时间、时间窗口和分离约束相互作用时，大型语言模型的可行性性能下降，主要瓶颈是约束交互，而不是图深度。此外，在清洁合成坡道上的性能也不能保证转移到领域相关的场景，突出了泛化的局限性。

Conclusion: 作者提出了一个名为R-ConstraintBench的可伸缩框架，用于评估大型语言模型在资源受限的项目调度问题上的性能。研究发现，强大的模型在仅具有先决约束的有向无环图方面表现良好，但是当停机时间、时间窗口和分立约束交互时，可行性性能会下降。此外，研究指出性能在清洁合成坡道上也不能保证转移到领域相关的场景，突出了泛化能力的局限性。

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [15] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个名为See it. Say it. Sorted.的系统，利用Vision-Language Model（VLM）和Large Language Models（LLMs）生成可编辑的Scalable Vector Graphics（SVG）程序，实现将草图转换为准确的组合图表。通过实验证明，该系统优于现有的图像生成LLMs，在处理流程图草图时更为准确和忠实。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型擅长逼真度但对于流程图所需的空间精度、对齐、符号结构等方面存在困难，因此本研究旨在解决这些问题。

Method: 该系统通过将Critic VLM提出一小组定性、关系性编辑，多个候选LLMs使用不同的策略（保守->激进、替代、专注）合成SVG更新，Judge VLM选择最佳候选，确保稳定的改进。设计优先考虑定性推理而非脆弱的数值估计，保留全局约束（例如对齐、连接性），并且自然支持人机协作修正。

Result: 实验证明，在处理流程图相关的草图时，该系统相较于现有的图像生成LLMs表现更为优越，重建布局和结构更加忠实，准确合成基本元素，且避免插入不需要的文本。

Conclusion: 该论文介绍了一种名为See it. Say it. Sorted.的系统，通过将视觉语言模型（VLM）与大型语言模型（LLMs）相结合，能够生成可编辑的可伸缩矢量图形（SVG）程序，实现了将草图转换为准确、组合的图表。在对10张来自发表论文中流程图的草图进行实验时，该方法比两种前沿的闭源图像生成LLMs（GPT-5和Gemini-2.5-Pro）更忠实地重建了布局和结构，准确组合了基本元素，并且没有插入不需要的文本。由于输出是程序化的SVGs，该方法可以通过API轻松扩展到演示工具（例如PowerPoint），并且可以通过改进提示和专门工具来进行定制。该研究代码在https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git上开源。

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [16] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 本文提出了新的计算智能方法来优化混合用途区域的土地分配，解决了土地利用兼容性和经济目标之间的固有权衡。关键贡献包括CR+DES算法、系统性约束放松策略和统计验证。具体应用于实际案例中，获得了显著的改进，并为城市规划者和政策制定者提供了更有效的工具。


<details>
  <summary>Details</summary>
Motivation: 城市土地利用分配是可持续城市发展政策中至关重要的复杂多目标优化问题。因此，本文旨在提出新颖的计算智能方法来解决土地利用兼容性和经济目标之间的固有权衡，为城市规划者和政策制定者提供更有效的工具。

Method: 本文采用了差分进化和多目标遗传算法相结合的定制变体来优化混合用途区域的土地分配。提出了CR+DES算法和系统性约束放松策略，以增强探索并提高解决方案质量。通过Kruskal-Wallis检验进行统计验证，并使用紧凑字母显示。

Result: 在应用于1,290个地块的实际案例研究中，CR+DES算法相对于现有技术方法在土地利用兼容性上实现了3.16	ext{%}的改进，而MSBX+MO在价格优化方面表现出3.3	ext{%}的改进。统计分析证实，合并差分向量的算法在多个指标上显著优于传统方法。约束放松技术扩展了解决方案空间的探索。

Conclusion: 本文提出了新颖的计算智能方法来优化混合用途区域的土地分配，解决了土地利用兼容性和经济目标之间的固有权衡。研究开发了多种优化算法，包括将差分进化与多目标遗传算法相结合的定制变体。主要贡献包括：(1) CR+DES算法利用缩放差异向量进行增强探索，(2) 系统性约束放松策略提高解决方案质量同时保持可行性，(3) 使用Kruskal-Wallis检验进行统计验证，并使用紧凑字母显示。应用于拥有1,290个地块的真实案例研究中，CR+DES相对于现有技术方法在土地利用兼容性上实现了3.16	ext{%}的改进，而MSBX+MO在价格优化方面表现出3.3	ext{%}的改进。统计分析证实，合并差分向量的算法在多个指标上显著优于传统方法。约束放松技术实现了更广泛的解决方案空间探索，同时保持实际约束。这些发现为城市规划者和决策者提供了基于证据的计算工具，以平衡土地分配中的竞争目标，支持快速城市化地区更有效的城市发展政策。

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>


### [17] [Multiple Memory Systems for Enhancing the Long-term Memory of Agent](https://arxiv.org/abs/2508.15294)
*Gaoke Zhang,Bo Wang,Yunlong Ma,Dongming Zhao,Zifei Yu*

Main category: cs.AI

TL;DR: 论文讨论了当前基于大型语言模型的智能体在处理大量历史数据时存在的挑战，提出了一种多重记忆系统（MMS）用于构建高质量的长期记忆内容。通过LoCoMo数据集的实验证明了该方法的有效性，并进行了消融研究和鲁棒性分析，证实了记忆单元的合理性和实用性。


<details>
  <summary>Details</summary>
Motivation: 虽然现有方法如MemoryBank和A-MEM设计了存储记忆内容的内存模块，但存储质量较差，影响了回忆性能和响应质量。基于认知心理学理论的启发，为了更好地构建高质量的长期记忆内容，需要提出一种新的方法。

Method: 设计了多重记忆系统（MMS），将短期记忆转化为多个长期记忆片段，并基于这些片段构建检索记忆单元和上下文记忆单元，实现两者之间的一一对应。在检索阶段，MMS将根据用户查询匹配最相关的检索记忆单元，然后获取相应的上下文记忆单元作为响应阶段的背景，以增强知识，从而有效利用历史数据。

Result: 实验证明提出的多重记忆系统（MMS）在LoCoMo数据集上表现出了较好的有效性，消融研究验证了记忆单元的合理性，鲁棒性分析展示了该系统的实用价值。

Conclusion: 提出了一种多重记忆系统（MMS），用于构建高质量的长期记忆内容，从而提高智能体在处理历史数据时的效率。通过实验证明该方法在LoCoMo数据集上的有效性，并通过消融研究和鲁棒性分析验证了记忆单元的合理性和实用性。

Abstract: An agent powered by large language models have achieved impressive results,
but effectively handling the vast amounts of historical data generated during
interactions remains a challenge. The current approach is to design a memory
module for the agent to process these data. However, existing methods, such as
MemoryBank and A-MEM, have poor quality of stored memory content, which affects
recall performance and response quality. In order to better construct
high-quality long-term memory content, we have designed a multiple memory
system (MMS) inspired by cognitive psychology theory. The system processes
short-term memory to multiple long-term memory fragments, and constructs
retrieval memory units and contextual memory units based on these fragments,
with a one-to-one correspondence between the two. During the retrieval phase,
MMS will match the most relevant retrieval memory units based on the user's
query. Then, the corresponding contextual memory units is obtained as the
context for the response stage to enhance knowledge, thereby effectively
utilizing historical data. Experiments on LoCoMo dataset compared our method
with three others, proving its effectiveness. Ablation studies confirmed the
rationality of our memory units. We also analyzed the robustness regarding the
number of selected memory segments and the storage overhead, demonstrating its
practical value.

</details>


### [18] [Coarse-to-Fine Grounded Memory for LLM Agent Planning](https://arxiv.org/abs/2508.15305)
*Wei Yang,Jinwei Xiao,Hongming Zhang,Qingyang Zhang,Yanna Wang,Bo Xu*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advancements in Large Language Models (LLMs) have driven growing
interest in LLM-based agents for complex planning tasks. To avoid costly agent
training, many studies adopted memory mechanism that enhances LLM with offline
experiences or online trajectory analysis. However, existing works focus on
single-granularity memory derived from dynamic environmental interactions,
which are inherently constrained by the quality of the collected experiences.
This limitation, in turn, constrain the diversity of knowledge and the
flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\Ours{}), a
novel framework that grounds coarse-to-fine memories with LLM, thereby fully
leverage them for flexible adaptation to diverse scenarios. \Ours{} grounds
environmental information into coarse-grained focus points to guide experience
collection in training tasks, followed by grounding of actionable
hybrid-grained tips from each experience. At inference, \Ours{} retrieves
task-relevant experiences and tips to support planning. When facing
environmental anomalies, the LLM grounds the current situation into
fine-grained key information, enabling flexible self-QA reflection and plan
correction.

</details>


### [19] [Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning](https://arxiv.org/abs/2508.15327)
*Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li*

Main category: cs.AI

TL;DR: 离线强化学习通常需要明确定义的奖励函数，但设计成本高。本文引入Search-Based Preference Weighting（SPW）方案，统一专家演示和偏好反馈源，通过搜索相似状态-动作对并导出权重来指导偏好学习，实现更准确的信用分配。SPW在机器人操作任务中表现优异，胜过过去的方法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习通常依赖于明确定义的奖励函数，但设计这些奖励函数往往困难且昂贵。人类反馈作为一种有吸引力的替代方案，但专家演示和偏好这两种常见形式各有限制。本文旨在解决这两种反馈源的结合问题，通过引入SPW方案统一这两种反馈来源，实现更准确的信用分配。

Method: 介绍了一种基于搜索的偏好加权方案（SPW），对每个转换中的状态-动作对进行搜索，从专家演示中找到最相似的，并根据相似性得分导出重要性权重，用于指导偏好学习。演示了SPW在机器人操作任务上的有效性，并展示了其优于以往方法的效果。

Result: 通过实验证明，SPW能够有效地从专家演示和偏好中联合学习，在具有挑战性的机器人操作任务中胜过先前方法。

Conclusion: 引入了一种基于搜索的偏好加权方案（SPW）来统一专家演示和偏好反馈源，通过为每个偏好标记的轨迹中的转换寻找来自专家演示的最相似状态-动作对，并根据它们的相似性分数直接导出逐步重要性权重。这些权重然后用于指导标准偏好学习，实现了传统方法难以实现的更准确的信用分配。展示了SPW能够实现有效地从偏好和演示中联合学习，在具有挑战性的机器人操作任务中胜过利用这两种反馈类型的先前方法。

Abstract: Offline reinforcement learning refers to the process of learning policies
from fixed datasets, without requiring additional environment interaction.
However, it often relies on well-defined reward functions, which are difficult
and expensive to design. Human feedback is an appealing alternative, but its
two common forms, expert demonstrations and preferences, have complementary
limitations. Demonstrations provide stepwise supervision, but they are costly
to collect and often reflect limited expert behavior modes. In contrast,
preferences are easier to collect, but it is unclear which parts of a behavior
contribute most to a trajectory segment, leaving credit assignment unresolved.
In this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to
unify these two feedback sources. For each transition in a preference labeled
trajectory, SPW searches for the most similar state-action pairs from expert
demonstrations and directly derives stepwise importance weights based on their
similarity scores. These weights are then used to guide standard preference
learning, enabling more accurate credit assignment that traditional approaches
struggle to achieve. We demonstrate that SPW enables effective joint learning
from preferences and demonstrations, outperforming prior methods that leverage
both feedback types on challenging robot manipulation tasks.

</details>


### [20] [RETAIL: Towards Real-world Travel Planning for Large Language Models](https://arxiv.org/abs/2508.15335)
*Bin Deng,Yizhe Feng,Zeming Liu,Qing Wei,Xiangrong Zhu,Shuai Chen,Yuanfang Guo,Yunhong Wang*

Main category: cs.AI

TL;DR: 提出了解决自动旅行规划系统问题的新方法：构建新数据集RETAIL，使用TGMA主题引导的多智能体框架，实验结果显示TGMA在真实世界旅行规划方面性能显著提高。


<details>
  <summary>Details</summary>
Motivation: 针对当前自动旅行规划系统存在的问题：用户需求通常是隐式的，系统无法考虑各种环境因素和用户喜好，以及无法提供详细的全方位旅行计划，提出解决方案。

Method: 构建新数据集RETAIL，使用TGMA主题引导的多智能体框架。

Result: 实验表明TGMA在真实世界旅行规划方面取得了显著改进，在通过率上比现有最强模型高出2.72%，显示了在真实世界旅行规划领域的发展方向。

Conclusion: 提出了一个新的数据集RETAIL以支持隐式查询和明确查询，包括需要修改的情况。引入了环境意识以确保计划在现实场景下的可行性，同时为全方位旅行计划提供详细的兴趣点信息。使用了主题引导的多智能体框架TGMA，实验结果显示，TGMA在真实世界旅行规划方面表现出显著提高的性能，比现有最强模型高出2.72%。

Abstract: Although large language models have enhanced automated travel planning
abilities, current systems remain misaligned with real-world scenarios. First,
they assume users provide explicit queries, while in reality requirements are
often implicit. Second, existing solutions ignore diverse environmental factors
and user preferences, limiting the feasibility of plans. Third, systems can
only generate plans with basic POI arrangements, failing to provide all-in-one
plans with rich details. To mitigate these challenges, we construct a novel
dataset \textbf{RETAIL}, which supports decision-making for implicit queries
while covering explicit queries, both with and without revision needs. It also
enables environmental awareness to ensure plan feasibility under real-world
scenarios, while incorporating detailed POI information for all-in-one travel
plans. Furthermore, we propose a topic-guided multi-agent framework, termed
TGMA. Our experiments reveal that even the strongest existing model achieves
merely a 1.0% pass rate, indicating real-world travel planning remains
extremely challenging. In contrast, TGMA demonstrates substantially improved
performance 2.72%, offering promising directions for real-world travel
planning.

</details>


### [21] [DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization](https://arxiv.org/abs/2508.15338)
*Jinning Yang,Wen Shi*

Main category: cs.AI

TL;DR: DiagECG框架整合时间序列和语言建模，在12导联心电图信号和自然语言输入间实现统一处理。通过预训练模型和指导微调，DiagECG在医学推理任务中取得强大性能，并具有泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法在心血管诊断中存在泛化困难和对开放式推理的有限支持。本文旨在整合时间序列和语言建模，将医学任务中的12导联心电图信号转换为文本生成任务，以提高模型的泛化能力和处理多模态输入的统一性。

Method: DiagECG框架将连续的心电图嵌入离散化为符号标记，使用独立导联编码器和量化模块。预训练模型进行自回归心电图预测任务，让语言模型能够使用其本身的语言建模能力来模拟时间动态。通过指导微调在心电图问题回答和诊断报告生成任务上进行模型优化。

Result: DiagECG在各项任务中表现出强大性能，并在分布外设置下保持泛化能力。实验证明各组件的有效性，显示了将符号心电图表示整合到语言模型中进行医学推理的潜力。

Conclusion: DiagECG 是一个整合时间序列和语言建模的新框架，将12导联心电图信号转换为符号标记以扩展大型语言模型的词汇量，实现统一处理心电图和自然语言输入。通过在自回归心电图预测任务上对模型进行预训练，使得语言模型能够使用其本身的语言建模能力来模拟时间动态。在心电图问题回答和诊断报告生成任务上进行指导微调，DiagECG 在不改变核心模型的情况下，在各项任务中表现出强大性能，并在分布外设置下保持泛化能力。实验结果表明各组件的有效性，并突显将符号心电图表示整合到语言模型中进行医学推理的潜力。

Abstract: Electrocardiography plays a central role in cardiovascular diagnostics, yet
existing automated approaches often struggle to generalize across clinical
tasks and offer limited support for open-ended reasoning. We present DiagECG, a
novel framework that integrates time-series and language modeling by enabling
large language models to process 12-lead ECG signals for clinical text
generation tasks. Our approach discretizes continuous ECG embeddings into
symbolic tokens using a lead-independent encoder and quantization module. These
tokens are then used to extend the vocabulary of LLM, allowing the model to
handle both ECG and natural language inputs in a unified manner. To bridge the
modality gap, we pretrain the model on an autoregressive ECG forecasting task,
enabling the LLM to model temporal dynamics using its native language modeling
capabilities. Finally, we perform instruction tuning on both ECG question
answering and diagnostic report generation. Without modifying the core model,
DiagECG achieves strong performance across tasks while maintaining
generalization to out-of-distribution settings. Extensive experiments
demonstrate the effectiveness of each component and highlight the potential of
integrating symbolic ECG representations into LLMs for medical reasoning.

</details>


### [22] [Planning with Minimal Disruption](https://arxiv.org/abs/2508.15358)
*Alberto Pozanco,Marianela Morales,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 本文介绍了计划中断概念，并定义了旨在联合优化行动成本总和和计划中断的规划编译。实验结果显示，在不同基准测试中，重新制定的任务在实践中有效解决，生成平衡两个目标的计划。


<details>
  <summary>Details</summary>
Motivation: 在规划应用中，寻找最小化修改初始状态以实现目标的计划是一个关键问题。为了解决这一问题，本文引入了计划中断概念，并提出了一种联合优化行动成本总和和计划中断的方法。

Method: 形式上介绍了计划中断概念，并定义了旨在联合优化行动成本总和和计划中断的规划编译。通过在不同基准上进行实验，展示了重新制定的任务在实践中的有效解决方法，生成平衡两个目标的计划。

Result: 实验结果表明，重新制定的任务能够有效解决，在实践中生成平衡两个目标的计划。

Conclusion: 在规划应用中，我们可能有兴趣找到最小化修改初始状态以实现目标的计划。本文正式介绍了这一概念，并定义了旨在联合优化行动成本总和和计划中断的各种基于规划的编译。在不同基准测试中的实验结果显示，重新制定的任务在实践中可以有效解决，生成平衡两个目标的计划。

Abstract: In many planning applications, we might be interested in finding plans that
minimally modify the initial state to achieve the goals. We refer to this
concept as plan disruption. In this paper, we formally introduce it, and define
various planning-based compilations that aim to jointly optimize both the sum
of action costs and plan disruption. Experimental results in different
benchmarks show that the reformulated task can be effectively solved in
practice to generate plans that balance both objectives.

</details>


### [23] [GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO](https://arxiv.org/abs/2508.15432)
*Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda*

Main category: cs.AI

TL;DR: 本文提出了一种合成数据生成框架，通过模块化和配置生成合成对话数据，实现自动过滤和评分高质量对话数据，支持监督微调和直接偏好优化任务，为大型语言模型的训练流程节省数据准备时间。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于推动大型语言模型（LLMs）的发展，强调了对于监督微调和直接偏好优化等任务而生成高质量数据集的重要性。

Method: 本文采用模块化和基于配置的流程生成合成数据，利用双阶段质量标记机制对对话数据进行过滤和评分，支持SFT和DPO用例，实现了高质量对话样本的筛选和生成。

Result: 通过提出的合成数据生成框架，实现了大规模、可配置和高保真度的合成数据生成，支持各种训练流程的接入，为LLM训练流程中数据准备过程带来显著降低的益处。

Conclusion: 本文提出了一种全面的合成数据生成框架，为监督微调（SFT）、直接偏好优化（DPO）等任务提供定制的合成数据，通过模块化和基于配置的流程生成复杂对话流，结合启发式规则和基于LLM的评估的双阶段质量标记机制，自动过滤和评分从OASST格式对话中提取的数据，生成具有灵活模式的数据集，支持SFT和DPO用例，显著减少LLM训练流程中数据准备的开销。

Abstract: The advancement of large language models (LLMs) is critically dependent on
the availability of high-quality datasets for Supervised Fine-Tuning (SFT),
alignment tasks like Direct Preference Optimization (DPO), etc. In this work,
we present a comprehensive synthetic data generation framework that facilitates
scalable, configurable, and high-fidelity generation of synthetic data tailored
for these training paradigms. Our approach employs a modular and
configuration-based pipeline capable of modeling complex dialogue flows with
minimal manual intervention. This framework uses a dual-stage quality tagging
mechanism, combining heuristic rules and LLM-based evaluations, to
automatically filter and score data extracted from OASST-formatted
conversations, ensuring the curation of high-quality dialogue samples. The
resulting datasets are structured under a flexible schema supporting both SFT
and DPO use cases, enabling seamless integration into diverse training
workflows. Together, these innovations offer a robust solution for generating
and managing synthetic conversational data at scale, significantly reducing the
overhead of data preparation in LLM training pipelines.

</details>


### [24] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent is a novel multi-agent framework that leverages LLMs for advanced decision-making in complex corporate environments. It integrates innovative approaches such as CTMDP, generalized entropy measure, and contextual Thompson sampling to generate effective solutions. Empirical evaluations confirm BusiAgent's efficacy in providing client-focused solutions that outperform established approaches in solution quality and user satisfaction, marking a substantial advancement in AI-driven enterprise decision-making.


<details>
  <summary>Details</summary>
Motivation: Current approaches in enterprise decision support and strategic planning struggle to reconcile operational analyses with strategic goals, leading to fragmented workflows and reduced collaboration across organizational levels. The motivation behind this paper is to address these challenges and empower organizations to navigate complex business landscapes more effectively with the fusion of AI technologies and business insights.

Method: The paper introduces BusiAgent, which integrates three core innovations: an extended Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a generalized entropy measure for collaborative efficiency optimization, and a multi-level Stackelberg game for hierarchical decision processes. Contextual Thompson sampling is used for prompt optimization, supported by a quality assurance system to mitigate errors. Empirical evaluations across diverse business scenarios validate BusiAgent's efficacy.

Result: BusiAgent significantly outperforms established approaches in solution quality and user satisfaction. It demonstrates the capacity to generate coherent, client-focused solutions that smoothly integrate granular insights with high-level strategy in diverse business scenarios.

Conclusion: BusiAgent is a novel multi-agent framework leveraging LLMs for advanced decision-making in complex corporate environments. It outperforms established approaches in both solution quality and user satisfaction, demonstrating its efficacy in generating coherent, client-focused solutions that integrate granular insights with high-level strategy effectively.

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


### [25] [Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning](https://arxiv.org/abs/2508.15507)
*Yekun Zhu,Guang Chen,Chengjun Mao*

Main category: cs.AI

TL;DR: 该论文提出了Think in Blocks框架，通过三阶段流程训练模型实现自适应推理深度，动态调整推理过程长度以应对任务复杂度。该框架提高了模型性能，解决了大型语言模型过度推理的问题。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于解决大型语言模型过度推理导致计算资源浪费和响应速度变慢的问题，提出了在任务复杂度下动态调整推理过程长度的问题。

Method: 该论文通过三阶段流程进行训练，包括监督微调、奖励引导的直接偏好优化和强化学习，来调整模型的推理深度以适应问题难度。同时建立了一个明确的块结构范式，让模型根据任务动态调整推理过程的长度。

Result: 通过提出的Think in Blocks框架，论文实现了在推理过程中根据任务复杂度动态调整推理深度的目标。同时，该框架在推理过程中灵活调整思维链的长度，提高了模型性能。

Conclusion: 该论文提出了Think in Blocks框架，通过将推理过程分成可调节数量的块，实现从零到深度推理的自适应推理。研究结果表明，该框架能够动态控制推理深度，从而在推理过程中灵活调整思维链的长度，提高模型性能。

Abstract: Large Language Models (LLMs) with chains-of-thought have demonstrated strong
performance on an increasing range of tasks, particularly those involving
complex logical reasoning. However, excessively long chains can lead to
overthinking, causing computational waste and slower responses. This raises a
question: can LLMs dynamically adjust the length of their reasoning processes
based on task complexity? To address this, we propose the Think in Blocks
framework, which enables adaptive reasoning-from zero to deep reasoning-by
partitioning the reasoning process into a tunable number of blocks. Our main
contributions are: (1) Establishing an explicit block-structured paradigm in
which the model first predicts an integer reasoning budget-the number of
blocks-and then partitions its reasoning accordingly; (2) Training an adaptive
model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided
Direct Preference Optimization, and Reinforcement Learning-that adjusts its
reasoning depth to problem difficulty; (3) Exploiting the explicit block count
to dynamically control reasoning depth at inference time, allowing flexible
adjustment of chain-of-thought length during deployment.

</details>


### [26] [Super-additive Cooperation in Language Model Agents](https://arxiv.org/abs/2508.15510)
*Filippo Tonini,Lukas Galke*

Main category: cs.AI

TL;DR: 本研究通过虚拟锦标赛的方式让语言模型代理人在团队中玩囚徒困境游戏，发现团队内部动态和外部竞争的模拟显著提高了合作水平。这些发现对设计未来能够有效协作并更好与人类价值观保持一致的多智能体AI系统具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 基于超附加合作理论的启发，研究人工智能代理人的合作倾向变得越来越重要。超附加合作理论认为重复互动和团体间竞争的综合效应是人类合作倾向的原因。

Method: 通过虚拟锦标赛设计的方法，让语言模型代理人以团队形式在囚徒困境游戏中互相对抗，模拟了团队内部动态和外部竞争，发现这种混合显著提高了合作水平。

Result: 研究表明，团队内部动态和外部竞争的模拟显著提高了合作水平，为设计未来多智能体AI系统提供重要见解。

Conclusion: 研究发现，通过模拟团队内部动态和外部竞争，合作性混合显著提高了整体和初始的一次性合作水平。这为大型语言模型在复杂社会场景中制定战略和行动提供了创新框架，并提供了组间竞争如何逆向地导致更多合作行为的证据。这些见解对设计未来能够有效协作并更好与人类价值观保持一致的多智能体AI系统至关重要。

Abstract: With the prospect of autonomous artificial intelligence (AI) agents, studying
their tendency for cooperative behavior becomes an increasingly relevant topic.
This study is inspired by the super-additive cooperation theory, where the
combined effects of repeated interactions and inter-group rivalry have been
argued to be the cause for cooperative tendencies found in humans. We devised a
virtual tournament where language model agents, grouped into teams, face each
other in a Prisoner's Dilemma game. By simulating both internal team dynamics
and external competition, we discovered that this blend substantially boosts
both overall and initial, one-shot cooperation levels (the tendency to
cooperate in one-off interactions). This research provides a novel framework
for large language models to strategize and act in complex social scenarios and
offers evidence for how intergroup competition can, counter-intuitively, result
in more cooperative behavior. These insights are crucial for designing future
multi-agent AI systems that can effectively work together and better align with
human values. Source code is available at
https://github.com/pippot/Superadditive-cooperation-LLMs.

</details>


### [27] [DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks](https://arxiv.org/abs/2508.15548)
*Jiayi Song,Rui Wan,Lipeng Ma,Weidong Yang,Qingyuan Zhou,Yixuan Li,Ben Fei*

Main category: cs.AI

TL;DR: 本文介绍了DeepThink3D方法，用于增强大型语言模型在复杂三维场景推理任务中的能力。通过组合迭代演化方法和直接偏好优化（DPO），提高了模型的工具使用和准确性，在SQA3D基准测试中取得了重要进展。


<details>
  <summary>Details</summary>
Motivation: 由于现有数据集中问题简单，导致生成的程序推理链相对较短，因此需要解决这一主要挑战。为此，本文旨在通过引入新方法和优化策略，提高大型语言模型在三维场景推理任务中的表现。

Method: 本文通过引入DeepThink3D和直接偏好优化（DPO）等方法，增强大型语言模型在三维场景推理任务中的工具使用能力和准确性。

Result: 通过提出DeepThink3D和使用Direct Preference Optimization（DPO）优化工具链策略，大幅提升了大型语言模型在复杂三维场景推理任务中的准确性。

Conclusion: 本文提出DeepThink3D用于增强大型语言模型（LLMs）在复杂三维场景中进行推理的能力。通过引入深思3D，采用组合迭代演化方法生成更复杂的问题，通过直接偏好优化（DPO）优化模型生成的工具链策略，提高其在复杂任务中的准确性。

Abstract: This work enhances the ability of large language models (LLMs) to perform
complex reasoning in 3D scenes. Recent work has addressed the 3D situated
reasoning task by invoking tool usage through large language models. Large
language models call tools via APIs and integrate the generated programs
through a chain of thought to solve problems based on the program results.
However, due to the simplicity of the questions in the dataset, the generated
program reasoning chains are relatively short. To solve this main challenge, in
this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in
complex 3D situated reasoning tasks. Our work proposes a combinatorial and
iterative evolutionary approach on the SQA3D benchmark to generate more complex
questions. Building on this foundation, we fine-tune the large language model
to make it more proficient in using 3D tools. By employing Direct Preference
Optimization (DPO), we directly optimize the toolchain strategies generated by
models, thereby enhancing their accuracy in complex tasks.

</details>


### [28] [A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](https://arxiv.org/abs/2508.15588)
*Ahmed Nasir,Abdelhafid Zenati*

Main category: cs.AI

TL;DR: 该论文介绍了一个新颖的框架，利用动力系统理论中的有限时间李雅普诺夫指数(FTLE)来分析强化学习代理与环境之间的关系，提出了定性和定量的安全性和鲁棒性评估方法，成功识别了仅基于奖励难以发现的关键缺陷。


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键系统中的应用受到验证学习政策的鲁棒性和安全性的限制，缺乏形式化验证方法。通过引入新的框架，能够定量和定性评估强化学习政策的行为，发现潜在的失败模式和关键缺陷。

Method: 引入动力系统理论中的有限时间李雅普诺夫指数(FTLE)和Lagrangian Coherent Structures (LCS)来分析强化学习代理与环境的关系，提出一系列定量评估指标用于测量策略的安全边界和鲁棒性，并提供处理模型不确定性的方法。

Result: 通过实验在离散和连续控制环境中验证，该框架能够成功识别策略行为中的关键缺陷，提供了全面和可解释的评估。

Conclusion: 该论文介绍了一个新颖的框架，利用动力系统理论中的有限时间李雅普诺夫指数(FTLE)来分析强化学习代理与环境之间的关系，提出了定性和定量的安全性和鲁棒性评估方法。通过实验表明，该框架可以全面且可解释地评估策略行为，成功识别仅基于奖励无法发现的关键缺陷。

Abstract: The application of reinforcement learning to safety-critical systems is
limited by the lack of formal methods for verifying the robustness and safety
of learned policies. This paper introduces a novel framework that addresses
this gap by analyzing the combination of an RL agent and its environment as a
discrete-time autonomous dynamical system. By leveraging tools from dynamical
systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we
identify and visualize Lagrangian Coherent Structures (LCS) that act as the
hidden "skeleton" governing the system's behavior. We demonstrate that
repelling LCS function as safety barriers around unsafe regions, while
attracting LCS reveal the system's convergence properties and potential failure
modes, such as unintended "trap" states. To move beyond qualitative
visualization, we introduce a suite of quantitative metrics, Mean Boundary
Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and
Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a
policy's safety margin and robustness. We further provide a method for deriving
local stability guarantees and extend the analysis to handle model uncertainty.
Through experiments in both discrete and continuous control environments, we
show that this framework provides a comprehensive and interpretable assessment
of policy behavior, successfully identifying critical flaws in policies that
appear successful based on reward alone.

</details>


### [29] [Transduction is All You Need for Structured Data Workflows](https://arxiv.org/abs/2508.15610)
*Alfio Gliozzo,Naweed Khan,Christodoulos Constantinides,Nandana Mihindukulasooriya,Nahuel Defosse,Junkyu Lee*

Main category: cs.AI

TL;DR: Agentics is a modular framework that promotes structured reasoning and compositional generalization over complex data. It emphasizes data modeling, uses logical transduction among data types, and showcases improved performance in various AI tasks such as multiple-choice question answering, text-to-SQL semantic parsing, and prompt optimization.


<details>
  <summary>Details</summary>
Motivation: The motivation behind Agentics is to provide a modular framework that facilitates structured reasoning and compositional generalization over complex data in agent-based systems. It aims to shift the focus of AI developers towards data modeling and enable a declarative approach to working with data and AI workflows.

Method: Agentics abstracts agents from logical flow, enabling logical transduction among data types. It focuses on modeling data using a declarative language, with data types provided by LLMs and composed through logical transduction. The framework encourages AI developers to concentrate on data modeling rather than crafting prompts.

Result: The paper demonstrates the effectiveness of the Agentics framework in domain-specific tasks such as multiple-choice question answering, text-to-SQL semantic parsing, and prompt optimization. It achieves state-of-the-art accuracy and improved scalability without sacrificing performance.

Conclusion: Agentics framework allows for structured reasoning and compositional generalization over complex data, leading to improved performance in various AI tasks. The empirical evidence showcases its applicability in multiple-choice question answering, text-to-SQL semantic parsing, and prompt optimization tasks.

Abstract: This paper introduces Agentics, a modular framework for building agent-based
systems capable of structured reasoning and compositional generalization over
complex data. Designed with research and practical applications in mind,
Agentics offers a novel perspective on working with data and AI workflows. In
this framework, agents are abstracted from the logical flow and they are used
internally to the data type to enable logical transduction among data. Agentics
encourages AI developers to focus on modeling data rather than crafting
prompts, enabling a declarative language in which data types are provided by
LLMs and composed through logical transduction, which is executed by LLMs when
types are connected. We provide empirical evidence demonstrating the
applicability of this framework across domain-specific multiple-choice question
answering, semantic parsing for text-to-SQL, and automated prompt optimization
tasks, achieving state-of-the-art accuracy or improved scalability without
sacrificing performance. The open-source implementation is available at
\texttt{https://github.com/IBM/agentics}.

</details>


### [30] [Adapting A Vector-Symbolic Memory for Lisp ACT-R](https://arxiv.org/abs/2508.15630)
*Meera Ray,Christopher L. Dancy*

Main category: cs.AI

TL;DR: 本文介绍了 holographic declarative memory (HDM) 系统，一种与 ACT-R 的 declarative memory (DM) 系统的矢量符号替代方案。经适配后，HDM 可以使现有的 ACT-R 模型可以在其上运行，无需进行重大修改。未来研究将继续改进模块的时间上下文表示方法，开发决策模型以测试系统的实际应用。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于提出一种具有优势的 holographic declarative memory (HDM) 系统，使得之前使用 ACT-R 的模型可以在 HDM 上运行。通过适配 HDM，模型可以获得 HDM 的矢量符号优势，同时也可以扩展以适应之前的 ACT-R 模型，减少或无需在模型的存储部分进行大幅修改。作者还计划通过探索更好的时间上下文表示方法和开发决策模型来进一步完善研究。

Method: 作者适配了 HDM 以与 ACT-R (Lisp ACT-R) 实现进行协作，创建了基于矢量的 ACT-R 函数版本，建立了文本处理流水线以将大型文档的内容添加到 ACT-R 内存，并创造了一种新颖的机制，可以根据请求仅使用矢量表示的令牌检索整个内存块。作者计划继续改进该翻译后的 holographic declarative memory 模块，包括探索更好的时间上下文表示方法，以提高模块在召回时重构块的能力，并开发使用基于实例学习理论的决策模型。

Result: 通过对 HDM 进行适配，目前可以在 ACT-R 模型中使用该系统而无需进行重大修改。初步结果显示，HDM 可以保持其优势，并通过扩展使得 ACT-R 模型可以在系统上工作，不需要在模型的程序性和声明性存储部分进行大幅修改。未来研究将继续改进时间上下文表示方法以改善模块的召回能力，并开发决策模型以测试翻译后的 HDM 模块。

Conclusion: 本文介绍了一种 holographic declarative memory (HDM) 系统，它是 ACT-R 的 declarative memory (DM) 系统的一种矢量符号替代方案。通过对 HDM 进行适配，使得现有的使用 DM 的 ACT-R 模型可以在不进行重大更改的情况下在 HDM 上运行。研究结果表明，HDM 可以保持矢量符号的优势，并通过将其扩展使得之前的 ACT-R 模型可以在系统上工作，不需要在模型的程序性和声明性存储部分进行大幅修改。未来的改进方向包括探索更好的时间上下文表示方法，以提高模块在召回时重构块的能力以及开发使用基于实例学习理论的决策模型。

Abstract: Holographic Declarative Memory (HDM) is a vector-symbolic alternative to
ACT-R's Declarative Memory (DM) system that can bring advantages such as
scalability and architecturally defined similarity between DM chunks. We
adapted HDM to work with the most comprehensive and widely-used implementation
of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with
HDM without major changes. With this adaptation of HDM, we have developed
vector-based versions of common ACT-R functions, set up a text processing
pipeline to add the contents of large documents to ACT-R memory, and most
significantly created a useful and novel mechanism to retrieve an entire chunk
of memory based on a request using only vector representations of tokens.
Preliminary results indicate that we can maintain vector-symbolic advantages of
HDM (e.g., chunk recall without storing the actual chunk and other advantages
with scaling) while also extending it so that previous ACT-R models may work
with the system with little (or potentially no) modifications within the actual
procedural and declarative memory portions of a model. As a part of iterative
improvement of this newly translated holographic declarative memory module, we
will continue to explore better time-context representations for vectors to
improve the module's ability to reconstruct chunks during recall. To more fully
test this translated HDM module, we also plan to develop decision-making models
that use instance-based learning (IBL) theory, which is a useful application of
HDM given the advantages of the system.

</details>


### [31] [Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.15652)
*Ardian Selmonaj,Miroslav Strupl,Oleg Szehr,Alessandro Antonucci*

Main category: cs.AI

TL;DR: 本研究旨在了解多智能体强化学习系统中的代理行为。通过分析策略分布提取代理行为洞察，引入ICVs方法量化每个代理对其合作伙伴的影响。研究发现了代理行为如何影响团队成功，增强了对协作动态的理解和解释性。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习系统中，了解团队中每个代理的行为是至关重要的，尤其在缺乏价值反馈的情况下。先前的工作通常基于明确的奖励信号或学习的值函数评估整体团队绩效，但在缺乏任何价值反馈的情况下如何推断代理的贡献仍不清楚。因此，本研究旨在通过分析策略分布来提取与基础值函数一致的代理行为洞察。

Method: 本研究通过Intended Cooperation Values (ICVs)方法，基于信息论Shapley值来量化每个代理对其合作伙伴的影响，通过评估其决策不确定性和偏好一致性来衡量代理对队友策略的行为效果。同时，通过分析协作和竞争性环境，比较代理采用相似或不同策略的情况，识别有益于团队成功的代理行为。

Result: 通过引入ICVs方法，本研究揭示了代理对团队成功有益的行为，无论是通过促进确定性决策还是保留未来行动选择的灵活性。此外，比较了行为对策略和值函数的影响，识别了哪些代理行为在团队成功中起着重要作用。

Conclusion: 本研究引入了一种名为Intended Cooperation Values (ICVs)的方法，通过分析策略分布来量化每个代理对其合作伙伴的影响，从而提供关于多智能体强化学习系统中代理行为的实质洞察。通过比较行为对策略和值函数的影响，揭示了哪些代理行为有助于团队成功。该方法增强了对多智能体强化学习系统中协作动态的理解和解释性。

Abstract: To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is
crucial to understand individual agent behaviors within a team. While prior
work typically evaluates overall team performance based on explicit reward
signals or learned value functions, it is unclear how to infer agent
contributions in the absence of any value feedback. In this work, we
investigate whether meaningful insights into agent behaviors can be extracted
that are consistent with the underlying value functions, solely by analyzing
the policy distribution. Inspired by the phenomenon that intelligent agents
tend to pursue convergent instrumental values, which generally increase the
likelihood of task success, we introduce Intended Cooperation Values (ICVs), a
method based on information-theoretic Shapley values for quantifying each
agent's causal influence on their co-players' instrumental empowerment.
Specifically, ICVs measure an agent's action effect on its teammates' policies
by assessing their decision uncertainty and preference alignment. The analysis
across cooperative and competitive MARL environments reveals the extent to
which agents adopt similar or diverse strategies. By comparing action effects
between policies and value functions, our method identifies which agent
behaviors are beneficial to team success, either by fostering deterministic
decisions or by preserving flexibility for future action choices. Our proposed
method offers novel insights into cooperation dynamics and enhances
explainability in MARL systems.

</details>


### [32] [Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle](https://arxiv.org/abs/2508.15680)
*Mark Cote,Susana Aires*

Main category: cs.AI

TL;DR: 本文探讨了对欧盟AI法案的技术哲学阅读，分析了AI系统中数据的长期动态。引入了概念工具来理解AI管道，开发了技术上扎根且哲学上连贯的分析。提出了正式阅读AI的概念，强调了数据的递归生成特性，突出了基础设施如特征存储的重要性。同时强调了技术寡头的不对称权力。建议需要针对基础设施和时间动态采取有效的监管措施等。


<details>
  <summary>Details</summary>
Motivation: 我们的中心观点是监管政策中缺失的是关于支撑技术运作和经济逻辑的变革动态的说明。

Method: 我们引入了一个概念性工具来构建AI管道，涵盖数据、训练制度、架构、特征存储和迁移学习。通过跨学科方法，我们开发了一个在技术上扎根且在哲学上连贯的对监管盲点进行分析。

Result: 我们提出了对AI的正式阅读，受西蒙东哲学科技的启发，重新塑造了他关于个体化的概念来建模AI的生命周期，包括前个体环境、个体化和个体化的AI。

Conclusion: 本文认为通过对欧盟AI法案进行技术哲学的阅读，可以深入了解AI系统中数据的长期动态，特别是从摄取到部署的生命周期如何产生挑战现有负责任人工智能框架的递归价值链。

Abstract: This paper argues that a techno-philosophical reading of the EU AI Act
provides insight into the long-term dynamics of data in AI systems,
specifically, how the lifecycle from ingestion to deployment generates
recursive value chains that challenge existing frameworks for Responsible AI.
We introduce a conceptual tool to frame the AI pipeline, spanning data,
training regimes, architectures, feature stores, and transfer learning. Using
cross-disciplinary methods, we develop a technically grounded and
philosophically coherent analysis of regulatory blind spots. Our central claim
is that what remains absent from policymaking is an account of the dynamic of
becoming that underpins both the technical operation and economic logic of AI.
To address this, we advance a formal reading of AI inspired by Simondonian
philosophy of technology, reworking his concept of individuation to model the
AI lifecycle, including the pre-individual milieu, individuation, and
individuated AI. To translate these ideas, we introduce futurity: the
self-reinforcing lifecycle of AI, where more data enhances performance, deepens
personalisation, and expands application domains. Futurity highlights the
recursively generative, non-rivalrous nature of data, underpinned by
infrastructures like feature stores that enable feedback, adaptation, and
temporal recursion. Our intervention foregrounds escalating power asymmetries,
particularly the tech oligarchy whose infrastructures of capture, training, and
deployment concentrate value and decision-making. We argue that effective
regulation must address these infrastructural and temporal dynamics, and
propose measures including lifecycle audits, temporal traceability, feedback
accountability, recursion transparency, and a right to contest recursive reuse.

</details>


### [33] [GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning](https://arxiv.org/abs/2508.15690)
*Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran*

Main category: cs.AI

TL;DR: GRAFT是一个多模态基准，使用结构化图表和合成表格来评估模型在视觉和文本任务上的表现。它配对图像和多步分析问题，提供结构化答案用于评估推理和输出格式。该基准引入推理类型分类和准则评估，为多模态模型评估设立了新的标准。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于提供一个用于评估模型在结构化多模态任务上表现的基准。通过创建程序生成的图表和合成渲染的表格，以及配对视觉内容和分析问题，使得研究者能够准确评估模型在推理和输出格式上的表现。

Method: 使用Python可视化库创建程序生成的图表和合成渲染的表格；配对图表或表格图像与系统生成的多步分析问题；答案提供在结构化格式如JSON或YAML中，支持一致评估；引入了推理类型的分类和参考答案准则进行评估。

Result: 通过提供一个新的评估框架和标准，GRAFT为多模态模型的评估带来了重要贡献，提供了一个统一的基准来评估模型在视觉推理和结构化任务上的表现。

Conclusion: GRAFT提供了一个结构化的多模态基准，用于评估模型在遵循指令、视觉推理和视觉-文本对齐任务上的表现。它包括用Python可视化库创建的程序生成的图表和合成渲染的表格，以确保对数据语义、结构和清晰度的控制。每个GRAFT实例将图表或表格图像与仅基于视觉内容的系统生成的多步分析问题配对。答案以JSON或YAML等结构化格式提供，支持对推理和输出格式的一致评估。该基准引入了包括比较、趋势识别、排名、聚合、比例估计和异常检测在内的推理类型的分类，以实现全面评估。参考答案遵循严格的事实和格式化准则，用于精确的、基于方面的评估。GRAFT为在视觉基础、结构化推理任务上对多模态模型进行细粒度基准评估提供了统一、可扩展的框架，为该领域确立了新的评估标准。

Abstract: GRAFT is a structured multimodal benchmark for evaluating models on
instruction-following, visual reasoning, and visual-textual alignment tasks. It
features programmatically generated charts and synthetically rendered tables,
created with Python visualization libraries to ensure control over data
semantics, structure, and clarity. Each GRAFT instance pairs a chart or table
image with a systematically generated, multi-step analytical question based
solely on visual content. Answers are provided in structured formats such as
JSON or YAML, supporting consistent evaluation of both reasoning and output
format. The benchmark introduces a taxonomy of reasoning types including
comparison, trend identification, ranking, aggregation, proportion estimation,
and anomaly detection to enable comprehensive assessment. Reference answers
follow strict factual and formatting guidelines for precise, aspect-based
evaluation. GRAFT offers a unified, scalable framework for fine-grained
benchmarking of multimodal models on visually grounded, structured reasoning
tasks, setting a new evaluation standard in this field.

</details>


### [34] [NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](https://arxiv.org/abs/2508.15693)
*Wilka Carvalho,Vikram Goddla,Ishaan Sinha,Hoon Shin,Kunal Jha*

Main category: cs.AI

TL;DR: NiceWebRL是一个Python库，可以将基于Jax的环境转换为在线界面，支持单智能体和多智能体环境。它的潜力体现在开发人类化AI、与人类兼容的AI和人类辅助AI方面，通过三个案例研究展示了其应用前景。NiceWebRL可帮助研究人员比较算法与人类表现、测试ML算法作为人类认知理论，并开发用于人机协作的算法。


<details>
  <summary>Details</summary>
Motivation: NiceWebRL的动机是帮助AI研究人员开发人类化、与人类兼容的和人类辅助的AI。通过将机器强化学习环境转换为在线界面，NiceWebRL为研究人员提供了一个实验平台，使他们能够与人类进行比较和测试，从而促进人类AI领域的发展。

Method: NiceWebRL是一个Python库，可以将任何基于Jax的环境转换为在线界面，支持单智能体和多智能体环境。通过NiceWebRL，研究人员可以比较他们的算法与人类表现，认知科学家可以将ML算法用作人类认知理论的测试，多智能体研究人员可以开发用于人机协作的算法。

Result: NiceWebRL通过三个案例研究展示了其潜力，包括开发认知模型、多智能体RL算法以及研究LLM如何在复杂任务中辅助人类。该库可在https://github.com/KempnerInstitute/nicewebrl获取。

Conclusion: NiceWebRL是一个研究工具，允许研究人员在线进行基于机器强化学习的人类试验。它支持单智能体和多智能体环境，并可用于开发人类化AI、与人类兼容的AI和人类辅助AI。通过三个案例研究展示了NiceWebRL的潜力，可用于开发人类化AI、与人类兼容的AI和人类辅助AI。

Abstract: We present NiceWebRL, a research tool that enables researchers to use machine
reinforcement learning (RL) environments for online human subject experiments.
NiceWebRL is a Python library that allows any Jax-based environment to be
transformed into an online interface, supporting both single-agent and
multi-agent environments. As such, NiceWebRL enables AI researchers to compare
their algorithms to human performance, cognitive scientists to test ML
algorithms as theories for human cognition, and multi-agent researchers to
develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3
case studies that demonstrate its potential to help develop Human-like AI,
Human-compatible AI, and Human-assistive AI. In the first case study
(Human-like AI), NiceWebRL enables the development of a novel RL model of
cognition. Here, NiceWebRL facilitates testing this model against human
participants in both a grid world and Craftax, a 2D Minecraft domain. In our
second case study (Human-compatible AI), NiceWebRL enables the development of a
novel multi-agent RL algorithm that can generalize to human partners in the
Overcooked domain. Finally, in our third case study (Human-assistive AI), we
show how NiceWebRL can allow researchers to study how an LLM can assist humans
on complex tasks in XLand-Minigrid, an environment with millions of
hierarchical tasks. The library is available at
https://github.com/KempnerInstitute/nicewebrl.

</details>


### [35] [Measuring the environmental impact of delivering AI at Google Scale](https://arxiv.org/abs/2508.15734)
*Cooper Elsworth,Keguo Huang,David Patterson,Ian Schneider,Robert Sedivy,Savannah Goodman,Ben Townsend,Parthasarathy Ranganathan,Jeff Dean,Amin Vahdat,Ben Gomes,James Manyika*

Main category: cs.AI

TL;DR: 该研究通过详细测量Google的AI基础设施，发现Gemini Apps文本提示的能源消耗低于公共估算，且Google的软件效率改进和清洁能源采购大幅减少了其能源消耗和碳排放。虽然AI服务的环境影响相对较低，但仍需要关注和减少，提出综合测量AI服务环境指标的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI用户采用加速，理解和减少AI服务的环境影响变得至关重要。然而，在生产环境中，尚无研究量化AI服务环境指标。本研究填补了这一空白，提出了综合方法来衡量大规模AI生产环境中AI推断工作负载的能源使用、碳排放和水消耗。

Method: 本文通过提出和执行综合方法，测量了AI推断工作负载的能源使用、碳排放和水消耗。方法考虑了AI服务基础设施的整个栈，包括活动AI加速器功率、主机系统能源、闲置机器容量和数据中心能源开销。利用对Google的Gemini AI助手的基础设施进行详细仪器化，深入研究了Gemini Apps文本提示的能源消耗情况。

Result: 通过该研究，在详细仪器化Google的AI基础设施后，发现Gemini Apps文本提示的能源消耗较低，且Google的软件效率改进和清洁能源采购取得了显著的能源消耗和碳排放减少。研究结果还指出，Gemini Apps文本提示的能源消耗相对较低，相当于看9秒的电视和消耗5滴水。

Conclusion: 本文针对生产环境中AI服务的环境指标进行了测量和分析，提出了综合方法。通过对Google的AI基础设施进行详细仪器化，发现Gemini Apps文本提示的能源消耗低于许多公共估算。研究还表明，Google的软件效率改进和清洁能源采购使Gemini Apps文本提示的能源消耗和碳足迹降低了33倍和44倍。虽然AI服务对环境影响相对较低，但仍需重视减少其环境影响。建议通过综合测量AI服务的环境指标，以便比较模型和激励AI服务整个环境栈的效率提升。

Abstract: The transformative power of AI is undeniable - but as user adoption
accelerates, so does the need to understand and mitigate the environmental
impact of AI serving. However, no studies have measured AI serving
environmental metrics in a production environment. This paper addresses this
gap by proposing and executing a comprehensive methodology for measuring the
energy usage, carbon emissions, and water consumption of AI inference workloads
in a large-scale, AI production environment. Our approach accounts for the full
stack of AI serving infrastructure - including active AI accelerator power,
host system energy, idle machine capacity, and data center energy overhead.
Through detailed instrumentation of Google's AI infrastructure for serving the
Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24
Wh of energy - a figure substantially lower than many public estimates. We also
show that Google's software efficiency efforts and clean energy procurement
have driven a 33x reduction in energy consumption and a 44x reduction in carbon
footprint for the median Gemini Apps text prompt over one year. We identify
that the median Gemini Apps text prompt uses less energy than watching nine
seconds of television (0.24 Wh) and consumes the equivalent of five drops of
water (0.26 mL). While these impacts are low compared to other daily
activities, reducing the environmental impact of AI serving continues to
warrant important attention. Towards this objective, we propose that a
comprehensive measurement of AI serving environmental metrics is critical for
accurately comparing models, and to properly incentivize efficiency gains
across the full AI serving stack.

</details>


### [36] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: 研究介绍了一个用于实时评估对话中人际线索的框架，通过五个阶段测试成功识别所有人际关系对话，避免误报。评估代理被证明可以为预防人际关系问题提供有效解决方案。


<details>
  <summary>Details</summary>
Motivation: AI代理与人建立的虚拟关系对人类福祉有严重影响，但预防这种动态是具有挑战性的。人际线索通常逐渐在私人对话中出现，并非所有形式的情感参与都是有害的。因此，通过引入一个简单的响应评估框架，能够实时评估对话以发现人际线索，来解决这一挑战。

Method: 介绍了一个简单的响应评估框架，利用最先进的语言模型重新定位，实时评估进行中的对话以寻找人际关系线索。通过构建一个包含对话的小型合成数据集，涵盖了人际关系、马屁拍客以及中立对话，进行了迭代评估，并通过五个阶段测试成功地识别了所有人际关系对话，在宽容的一致性规则下避免了误报，检测通常在最初几次交流中完成。

Result: 研究发现，评估代理能够成功识别所有人际关系对话，避免误报，在最初几次交流中进行检测。这些发现初步证明评估代理可以为预防人际关系问题提供可行的解决方案。

Conclusion: 评估代理可以为预防人际关系问题提供可行的解决方案。

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


### [37] [Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback](https://arxiv.org/abs/2508.15757)
*Yuxing Lu,Yucheng Hu,Nan Sun,Xukai Zhao*

Main category: cs.AI

TL;DR: Language-Guided Tuning (LGT) is a framework that optimizes machine learning configurations using natural language reasoning. It outperforms traditional methods, employs textual gradients for semantic reasoning, and consists of three agents for configuration optimization.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is the need for a more effective and interpretable approach to configuration optimization in machine learning. Traditional methods lack interpretability while automated methods struggle with dynamic adaptability and semantic reasoning. LGT aims to address these limitations by integrating natural language reasoning into the optimization process.

Method: LGT employs multi-agent Large Language Models to optimize configurations using textual gradients for semantic reasoning and feedback signals. It consists of three specialized agents: an Advisor, an Evaluator, and an Optimizer, creating a self-improving feedback loop.

Result: LGT demonstrates significant performance gains over traditional optimization methods in comprehensive evaluation on six diverse datasets. It achieves improved performance while ensuring high interpretability of the optimization decisions.

Conclusion: Language-Guided Tuning (LGT) is a novel framework that intelligently optimizes configurations in machine learning through natural language reasoning. It outperforms traditional optimization methods with substantial improvements while maintaining high interpretability.

Abstract: Configuration optimization remains a critical bottleneck in machine learning,
requiring coordinated tuning across model architecture, training strategy,
feature engineering, and hyperparameters. Traditional approaches treat these
dimensions independently and lack interpretability, while recent automated
methods struggle with dynamic adaptability and semantic reasoning about
optimization decisions. We introduce Language-Guided Tuning (LGT), a novel
framework that employs multi-agent Large Language Models to intelligently
optimize configurations through natural language reasoning. We apply textual
gradients - qualitative feedback signals that complement numerical optimization
by providing semantic understanding of training dynamics and configuration
interdependencies. LGT coordinates three specialized agents: an Advisor that
proposes configuration changes, an Evaluator that assesses progress, and an
Optimizer that refines the decision-making process, creating a self-improving
feedback loop. Through comprehensive evaluation on six diverse datasets, LGT
demonstrates substantial improvements over traditional optimization methods,
achieving performance gains while maintaining high interpretability.

</details>
