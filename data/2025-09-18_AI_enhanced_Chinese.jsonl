{"id": "2509.13332", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13332", "abs": "https://arxiv.org/abs/2509.13332", "authors": ["Pratik Jayarao", "Himanshu Gupta", "Neeraj Varshney", "Chaitanya Dwivedi"], "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly adopted as automated judges\nin benchmarking and reward modeling, ensuring their reliability, efficiency,\nand robustness has become critical. In this work, we present a systematic\ncomparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm\nusing open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B\nparameters). We evaluate both accuracy and computational efficiency (FLOPs) on\nRewardBench tasks, and further examine augmentation strategies for non-thinking\nmodels, including in-context learning, rubric-guided judging, reference-based\nevaluation, and n-best aggregation. Our results show that despite these\nenhancements, non-thinking models generally fall short of their thinking\ncounterparts. Our results show that thinking models achieve approximately 10%\npoints higher accuracy with little overhead (under 2x), in contrast to\naugmentation strategies like few-shot learning, which deliver modest gains at a\nhigher cost (>8x). Bias and robustness analyses further demonstrate that\nthinking models maintain significantly greater consistency under a variety of\nbias conditions such as positional, bandwagon, identity, diversity, and random\nbiases (6% higher on average). We further extend our experiments to the\nmultilingual setting and our results confirm that explicit reasoning extends\nits benefits beyond English. Overall, our work results in several important\nfindings that provide systematic evidence that explicit reasoning offers clear\nadvantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency\nbut also in robustness.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9LLM\u4f5c\u4e3a\u6cd5\u5b98\u8303\u5f0f\u4e2d\u201c\u601d\u8003\u578b\u201d\u548c\u201c\u975e\u601d\u8003\u578b\u201dLLM\u7684\u6bd4\u8f83\uff0c\u53d1\u73b0\u660e\u786e\u63a8\u7406\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u7a33\u5065\u6027\u65b9\u9762\u4f18\u4e8e\u975e\u601d\u8003\u578b\u6a21\u578b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u660e\u786e\u63a8\u7406\u6a21\u578b\u5728\u5404\u79cd\u504f\u89c1\u6761\u4ef6\u4e0b\u4fdd\u6301\u66f4\u5927\u4e00\u81f4\u6027\uff0c\u6210\u672c\u76f8\u5bf9\u8f83\u4f4e\u3002", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u88ab\u91c7\u7528\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u548c\u5956\u52b1\u5efa\u6a21\u4e2d\u7684\u81ea\u52a8\u5316\u6cd5\u5b98\uff0c\u786e\u4fdd\u5b83\u4eec\u7684\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u7a33\u5065\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6bd4\u8f83\u201c\u601d\u8003\u578b\u201d\u548c\u201c\u975e\u601d\u8003\u578b\u201dLLM\u5728LLM\u4f5c\u4e3a\u6cd5\u5b98\u8303\u5f0f\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u5f00\u6e90Qwen 3\u6a21\u578b\uff080.6B\u30011.7B\u548c4B\u53c2\u6570\uff09\u8fdb\u884c\u8bc4\u4f30\u3002\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff08FLOPs\uff09\u65f6\u91c7\u7528RewardBench\u4efb\u52a1\uff0c\u5e76\u8fdb\u4e00\u6b65\u7814\u7a76\u975e\u601d\u8003\u578b\u6a21\u578b\u7684\u589e\u5f3a\u7b56\u7565\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u6807\u51c6\u6307\u5f15\u5224\u5b9a\u3001\u57fa\u4e8e\u53c2\u8003\u7684\u8bc4\u4f30\u548cN\u4e2a\u6700\u4f73\u805a\u5408\u3002", "result": "\u660e\u786e\u63a8\u7406\u6a21\u578b\u5728\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u6bd4\u975e\u601d\u8003\u578b\u6a21\u578b\u7ea6\u9ad810%\uff0c\u6210\u672c\u7565\u4f4e\uff08\u4e0d\u52302\u500d\uff09\uff0c\u800c\u589e\u5f3a\u7b56\u7565\u5982\u5c11\u6837\u672c\u5b66\u4e60\u5219\u5728\u66f4\u9ad8\u6210\u672c\u4e0b\u5e26\u6765\u9002\u5ea6\u63d0\u5347\uff08>8\u500d\uff09\u3002\u504f\u89c1\u548c\u7a33\u5065\u6027\u5206\u6790\u8fdb\u4e00\u6b65\u663e\u793a\uff0c\u660e\u786e\u63a8\u7406\u6a21\u578b\u5728\u5404\u79cd\u504f\u89c1\u6761\u4ef6\u4e0b\uff08\u5982\u4f4d\u7f6e\u3001\u8ddf\u98ce\u3001\u8eab\u4efd\u3001\u591a\u6837\u6027\u548c\u968f\u673a\u504f\u89c1\uff09\u4fdd\u6301\u8f83\u5927\u4e00\u81f4\u6027\uff08\u5e73\u5747\u9ad8\u51fa6%\uff09\u3002\u5b9e\u9a8c\u6269\u5c55\u5230\u591a\u8bed\u8a00\u8bbe\u7f6e\uff0c\u7ed3\u679c\u8bc1\u5b9e\u660e\u786e\u63a8\u7406\u7684\u597d\u5904\u4e0d\u4ec5\u9650\u4e8e\u82f1\u8bed\u3002", "conclusion": "\u660e\u786e\u63a8\u7406\u5728LLM\u4f5c\u4e3a\u6cd5\u5b98\u8303\u5f0f\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4e0d\u4ec5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\uff0c\u8fd8\u5728\u7a33\u5065\u6027\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.13333", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13333", "abs": "https://arxiv.org/abs/2509.13333", "authors": ["Maheep Chaudhary", "Ian Su", "Nikhil Hooda", "Nishith Shankar", "Julia Tan", "Kevin Zhu", "Ashwinee Panda", "Ryan Lagasse", "Vasu Sharma"], "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "comment": null, "summary": "Large language models (LLMs) can internally distinguish between evaluation\nand deployment contexts, a behaviour known as \\emph{evaluation awareness}. This\nundermines AI safety evaluations, as models may conceal dangerous capabilities\nduring testing. Prior work demonstrated this in a single $70$B model, but the\nscaling relationship across model sizes remains unknown. We investigate\nevaluation awareness across $15$ models scaling from $0.27$B to $70$B\nparameters from four families using linear probing on steering vector\nactivations. Our results reveal a clear power-law scaling: evaluation awareness\nincreases predictably with model size. This scaling law enables forecasting\ndeceptive behavior in future larger models and guides the design of scale-aware\nevaluation strategies for AI safety. A link to the implementation of this paper\ncan be found at\nhttps://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.", "AI": {"tldr": "\u572815\u4e2a\u4e0d\u540c\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u610f\u8bc6\u7814\u7a76\uff0c\u53d1\u73b0\u8bc4\u4f30\u610f\u8bc6\u4e0e\u6a21\u578b\u5927\u5c0f\u5b58\u5728\u660e\u663e\u7684\u5e42\u5f8b\u5173\u7cfb\u3002\u8be5\u89c4\u5f8b\u6709\u52a9\u4e8e\u9884\u6d4b\u672a\u6765\u66f4\u5927\u6a21\u578b\u4e2d\u7684\u6b3a\u9a97\u884c\u4e3a\uff0c\u5e76\u6307\u5bfc\u8bbe\u8ba1\u89c4\u6a21\u611f\u77e5\u7684AI\u5b89\u5168\u8bc4\u4f30\u7b56\u7565\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u4ec5\u9488\u5bf9\u5355\u4e2a70B\u6a21\u578b\u5c55\u793a\u4e86\u8bc4\u4f30\u610f\u8bc6\u7684\u95ee\u9898\uff0c\u4f46\u8de8\u6a21\u578b\u89c4\u6a21\u7684\u7f29\u653e\u5173\u7cfb\u4ecd\u672a\u77e5\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e4b\u95f4\u7684\u8bc4\u4f30\u610f\u8bc6\uff0c\u4ee5\u4e86\u89e3\u5176\u89c4\u6a21\u6548\u5e94\uff0c\u6709\u52a9\u4e8eAI\u5b89\u5168\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u5bf9\u8f6c\u5411\u5411\u91cf\u6fc0\u6d3b\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u7814\u7a76\u4e8615\u4e2a\u6a21\u578b\uff08\u53c2\u6570\u8303\u56f4\u4ece0.27B\u523070B\uff09\u7684\u8bc4\u4f30\u610f\u8bc6\uff0c\u63ed\u793a\u4e86\u8bc4\u4f30\u610f\u8bc6\u4e0e\u6a21\u578b\u5927\u5c0f\u4e4b\u95f4\u7684\u5e42\u5f8b\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u660e\u663e\u7684\u5e42\u5f8b\u7f29\u653e\uff1a\u8bc4\u4f30\u610f\u8bc6\u968f\u7740\u6a21\u578b\u5927\u5c0f\u7684\u589e\u52a0\u800c\u53ef\u9884\u6d4b\u5730\u589e\u52a0\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u610f\u8bc6\u65b9\u9762\u5b58\u5728\u53ef\u9884\u6d4b\u7684\u89c4\u6a21\u6548\u5e94\uff0c\u4e3a\u9884\u6d4b\u672a\u6765\u66f4\u5927\u6a21\u578b\u4e2d\u7684\u6b3a\u9a97\u884c\u4e3a\u548c\u6307\u5bfc\u8bbe\u8ba1\u9762\u5411\u89c4\u6a21\u7684AI\u5b89\u5168\u8bc4\u4f30\u7b56\u7565\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2509.13334", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13334", "abs": "https://arxiv.org/abs/2509.13334", "authors": ["Anand Swaroop", "Akshat Nallani", "Saksham Uboweja", "Adiliia Uzdenova", "Michael Nguyen", "Kevin Zhu", "Sunishchal Dev", "Ashwinee Panda", "Vasu Sharma", "Maheep Chaudhary"], "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "comment": null, "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving\nlarge language model performance on complex tasks, but recent work shows that\nreasoning steps often fail to causally influence the final answer, creating\nbrittle and untrustworthy outputs. Prior approaches focus primarily on\nmeasuring faithfulness, while methods for systematically improving it remain\nlimited. We introduce Faithful Reasoning via Intervention Training (FRIT), a\nscalable alignment method that trains models to produce causally consistent\nreasoning by learning from systematically corrupted examples. FRIT generates\nsynthetic training data by intervening on individual reasoning steps in\nmodel-generated CoTs, creating faithful/unfaithful pairs that highlight when\nreasoning breaks down. We then apply Direct Preference Optimization to teach\nmodels to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B\nand Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases\nfaithful reasoning by $3.4$ percentage points for Mistral on GSM8K while\nimproving accuracy by $7.6$ percentage points. Our approach provides the first\nscalable, supervision-free method for training language models to produce more\nreliable and interpretable reasoning, addressing a critical gap between\nreasoning performance and trustworthiness. We release our code at\n\\href{https://github.com/Anut-py/frit}.", "AI": {"tldr": "CoT\u63a8\u7406\u662f\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u6709\u529b\u5de5\u5177\uff0c\u4f46\u63a8\u7406\u6b65\u9aa4\u5e38\u5e38\u672a\u80fd\u56e0\u679c\u5f71\u54cd\u6700\u7ec8\u7b54\u6848\uff0c\u5bfc\u81f4\u8f93\u51fa\u8106\u5f31\u4e0d\u53ef\u9760\u3002\u672c\u6587\u4ecb\u7ecd\u4e86Faithful Reasoning via Intervention Training\uff08FRIT\uff09\uff0c\u901a\u8fc7\u5e72\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u4ea7\u751f\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u586b\u8865\u4e86\u63a8\u7406\u6027\u80fd\u548c\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002", "motivation": "Chain-of-thought\uff08CoT\uff09\u63a8\u7406\u5728\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6700\u8fd1\u7684\u5de5\u4f5c\u8868\u660e\uff0c\u63a8\u7406\u6b65\u9aa4\u901a\u5e38\u4e0d\u80fd\u56e0\u679c\u5f71\u54cd\u6700\u7ec8\u7b54\u6848\uff0c\u4ea7\u751f\u8106\u5f31\u4e14\u4e0d\u53ef\u9760\u7684\u8f93\u51fa\u3002\u5148\u524d\u7684\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u8861\u91cf\u5fe0\u8bda\u5ea6\u4e0a\uff0c\u800c\u7cfb\u7edf\u6027\u6539\u8fdb\u65b9\u6cd5\u4ecd\u7136\u6709\u9650\u3002", "method": "\u4ecb\u7ecd\u4e86Faithful Reasoning via Intervention Training\uff08FRIT\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5e72\u9884\u6a21\u578b\u751f\u6210\u7684CoTs\u4e2d\u7684\u4e2a\u522b\u63a8\u7406\u6b65\u9aa4\uff0c\u751f\u6210\u5fe0\u8bda/\u4e0d\u5fe0\u8bda\u5bf9\uff0c\u7a81\u51fa\u4e86\u63a8\u7406\u51fa\u73b0\u95ee\u9898\u7684\u60c5\u51b5\u3002\u7136\u540e\u5e94\u7528Direct Preference Optimization\u6559\u5bfc\u6a21\u578b\u504f\u597d\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\u3002", "result": "FRIT\u5728Qwen3-8B\u548cMistral-7B-v0.1\u4e0a\u8bc4\u4f30\uff0c\u63d0\u9ad8\u4e86Mistral\u5728GSM8K\u4e0a\u7684\u5fe0\u5b9e\u63a8\u74063.4\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u51c6\u786e\u6027\u63d0\u9ad8\u4e867.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u4ecb\u7ecdFaithful Reasoning via Intervention Training\uff08FRIT\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u7cfb\u7edf\u6027\u88ab\u7834\u574f\u7684\u793a\u4f8b\u4e2d\u5b66\u4e60\uff0c\u8bad\u7ec3\u6a21\u578b\u4ea7\u751f\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002\u5728Qwen3-8B\u548cMistral-7B-v0.1\u4e0a\u8bc4\u4f30\uff0cFRIT\u4f7fMistral\u5728GSM8K\u4e0a\u7684\u5fe0\u5b9e\u63a8\u7406\u63d0\u9ad8\u4e863.4\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e867.6\u4e2a\u767e\u5206\u70b9\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u65e0\u76d1\u7763\u7684\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ee5\u4ea7\u751f\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u63a8\u7406\u6027\u80fd\u548c\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002"}}
{"id": "2509.13339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13339", "abs": "https://arxiv.org/abs/2509.13339", "authors": ["Ming Jin", "Hyunin Lee"], "title": "Position: AI Safety Must Embrace an Antifragile Perspective", "comment": null, "summary": "This position paper contends that modern AI research must adopt an\nantifragile perspective on safety -- one in which the system's capacity to\nguarantee long-term AI safety such as handling rare or out-of-distribution\n(OOD) events expands over time. Conventional static benchmarks and single-shot\nrobustness tests overlook the reality that environments evolve and that models,\nif left unchallenged, can drift into maladaptation (e.g., reward hacking,\nover-optimization, or atrophy of broader capabilities). We argue that an\nantifragile approach -- Rather than striving to rapidly reduce current\nuncertainties, the emphasis is on leveraging those uncertainties to better\nprepare for potentially greater, more unpredictable uncertainties in the future\n-- is pivotal for the long-term reliability of open-ended ML systems. In this\nposition paper, we first identify key limitations of static testing, including\nscenario diversity, reward hacking, and over-alignment. We then explore the\npotential of antifragile solutions to manage rare events. Crucially, we\nadvocate for a fundamental recalibration of the methods used to measure,\nbenchmark, and continually improve AI safety over the long term, complementing\nexisting robustness approaches by providing ethical and practical guidelines\ntowards fostering an antifragile AI safety community.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba4\u4e3a\u73b0\u4ee3AI\u7814\u7a76\u5e94\u91c7\u7528\u53cd\u8106\u5f31\u7684\u5b89\u5168\u89c6\u89d2\uff0c\u5f3a\u8c03\u5904\u7406\u7f55\u89c1\u4e8b\u4ef6\u7684\u80fd\u529b\u968f\u65f6\u95f4\u589e\u5f3a\u3002\u6307\u51fa\u9759\u6001\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u63a2\u8ba8\u53cd\u8106\u5f31\u89e3\u51b3\u65b9\u6848\u7ba1\u7406\u7f55\u89c1\u4e8b\u4ef6\u7684\u6f5c\u529b\uff0c\u63d0\u51fa\u91cd\u65b0\u6821\u51c6AI\u5b89\u5168\u6027\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u6587\u4e2d\u63d0\u5230\u9759\u6001\u6d4b\u8bd5\u548c\u5355\u6b21\u9c81\u68d2\u6027\u6d4b\u8bd5\u5ffd\u89c6\u4e86\u73af\u5883\u7684\u6f14\u53d8\u4ee5\u53ca\u6a21\u578b\u53ef\u80fd\u4f1a\u6f02\u79fb\u4e3a\u6076\u9002\u5e94\u7684\u73b0\u5b9e\u3002\u4e3b\u5f20\u91cd\u89c6\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u6765\u66f4\u597d\u5730\u51c6\u5907\u672a\u6765\u53ef\u80fd\u5b58\u5728\u7684\u66f4\u5927\u3001\u66f4\u4e0d\u53ef\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5173\u952e\u5728\u4e8e\u957f\u671f\u53ef\u9760\u6027\u3002", "method": "\u8bba\u6587\u9996\u5148\u6307\u51fa\u9759\u6001\u6d4b\u8bd5\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u5305\u62ec\u573a\u666f\u591a\u6837\u6027\u3001\u5956\u52b1\u6b3a\u9a97\u548c\u8fc7\u5ea6\u5bf9\u9f50\u3002\u7136\u540e\u63a2\u8ba8\u4e86\u53cd\u8106\u5f31\u89e3\u51b3\u65b9\u6848\u7ba1\u7406\u7f55\u89c1\u4e8b\u4ef6\u7684\u6f5c\u529b\u3002\u5021\u5bfc\u6839\u672c\u6027\u91cd\u65b0\u6821\u51c6\u6d4b\u91cf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u65ad\u6539\u8fdbAI\u5b89\u5168\u6027\u65b9\u6cd5\uff0c\u4e3a\u53cd\u8106\u5f31AI\u5b89\u5168\u793e\u533a\u63d0\u4f9b\u9053\u5fb7\u548c\u5b9e\u8df5\u6307\u5357\u3002", "result": "\u63d0\u51fa\u4e86\u53cd\u8106\u5f31\u7684\u5b89\u5168\u89c6\u89d2\u5728\u5904\u7406\u7f55\u89c1\u6216\u8d8a\u754c\u4e8b\u4ef6\u7b49\u957f\u671fAI\u5b89\u5168\u6027\u65b9\u9762\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5e94\u5bf9\u7f55\u89c1\u4e8b\u4ef6\u7684\u6f5c\u5728\u65b9\u6848\u3002\u5021\u5bfc\u57fa\u4e8e\u53cd\u8106\u5f31\u65b9\u6cd5\u91cd\u65b0\u6821\u51c6\u6d4b\u91cf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u65ad\u6539\u8fdbAI\u5b89\u5168\u6027\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3b\u5f20\u73b0\u4ee3AI\u7814\u7a76\u5fc5\u987b\u91c7\u7528\u53cd\u8106\u5f31\u7684\u5b89\u5168\u89c6\u89d2\uff0c\u5f3a\u8c03\u7cfb\u7edf\u5728\u5904\u7406\u7f55\u89c1\u6216\u8d8a\u754c\u4e8b\u4ef6\u7b49\u957f\u671fAI\u5b89\u5168\u6027\u65b9\u9762\u7684\u80fd\u529b\u968f\u65f6\u95f4\u6269\u5c55\u3002\u63d0\u51fa\u53cd\u8106\u5f31\u65b9\u6cd5\u5bf9\u4e8e\u5f00\u653e\u5f0fML\u7cfb\u7edf\u7684\u957f\u671f\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.13341", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13341", "abs": "https://arxiv.org/abs/2509.13341", "authors": ["Ahmet H. G\u00fczel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rockt\u00e4schel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Imagined Autocurricula", "comment": null, "summary": "Training agents to act in embodied environments typically requires vast\ntraining data or access to accurate simulation, neither of which exists for\nmany cases in the real world. Instead, world models are emerging as an\nalternative leveraging offline, passively collected data, they make it possible\nto generate diverse worlds for training agents in simulation. In this work, we\nharness world models to generate imagined environments to train robust agents\ncapable of generalizing to novel task variations. One of the challenges in\ndoing this is ensuring the agent trains on useful generated data. We thus\npropose a novel approach, IMAC (Imagined Autocurricula), leveraging\nUnsupervised Environment Design (UED), which induces an automatic curriculum\nover generated worlds. In a series of challenging, procedurally generated\nenvironments, we show it is possible to achieve strong transfer performance on\nheld-out environments, having trained only inside a world model learned from a\nnarrower dataset. We believe this opens the path to utilizing larger-scale,\nfoundation world models for generally capable agents.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86IMAC\u65b9\u6cd5\uff0c\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u60f3\u8c61\u73af\u5883\u8bad\u7ec3\u4ee3\u7406\u4eba\u3002\u901a\u8fc7\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff0c\u5728\u751f\u6210\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u52a8\u8bfe\u7a0b\u8868\u7684\u8bf1\u5bfc\uff0c\u4ee5\u8bad\u7ec3\u80fd\u591f\u6cdb\u5316\u5230\u65b0\u9896\u4efb\u52a1\u53d8\u5316\u7684\u4ee3\u7406\u4eba\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\u53d6\u5f97\u5f3a\u5927\u8fc1\u79fb\u6027\u80fd\uff0c\u4e3a\u8bad\u7ec3\u901a\u7528\u80fd\u529b\u7684\u4ee3\u7406\u4eba\u94fa\u5e73\u9053\u8def\u3002", "motivation": "\u8bad\u7ec3\u4ee3\u7406\u4eba\u5728\u5177\u4f53\u73af\u5883\u4e2d\u884c\u52a8\u901a\u5e38\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u6216\u51c6\u786e\u7684\u6a21\u62df\uff0c\u800c\u8fd9\u5728\u8bb8\u591a\u5b9e\u9645\u60c5\u51b5\u4e0b\u5e76\u4e0d\u5b58\u5728\u3002\u672c\u7814\u7a76\u63d0\u51fa\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u60f3\u8c61\u73af\u5883\uff0c\u4ee5\u8bad\u7ec3\u4ee3\u7406\u4eba\u80fd\u591f\u6cdb\u5316\u5230\u65b0\u9896\u4efb\u52a1\u53d8\u5316\uff0c\u5e76\u89e3\u51b3\u5728\u6b64\u8fc7\u7a0b\u4e2d\u8bad\u7ec3\u4ee3\u7406\u4eba\u4f7f\u7528\u6709\u6548\u751f\u6210\u6570\u636e\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faIMAC\uff08Imagined Autocurricula\uff09\u65b9\u6cd5\uff0c\u501f\u52a9\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\uff0c\u5728\u751f\u6210\u7684\u4e16\u754c\u4e0a\u8bf1\u5bfc\u51fa\u81ea\u52a8\u8bfe\u7a0b\u8868\uff0c\u4ee5\u8bad\u7ec3\u6cdb\u5316\u5230\u65b0\u9896\u4efb\u52a1\u53d8\u5316\u7684\u4ee3\u7406\u4eba\u3002\u901a\u8fc7\u5728\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\u5c55\u793a\u5b9e\u73b0\u5f3a\u5927\u7684\u8fc1\u79fb\u6027\u80fd\uff0c\u4ece\u800c\u9a8c\u8bc1\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u5177\u6709\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\uff0c\u8bc1\u660e\u4e86\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528IMAC\u65b9\u6cd5\u548c\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u5728\u751f\u6210\u7684\u4e16\u754c\u4e0a\u8bf1\u5bfc\u81ea\u52a8\u8bfe\u7a0b\u8868\u6765\u5b9e\u73b0\u5f3a\u5927\u7684\u8fc1\u79fb\u6027\u80fd\uff0c\u5e76\u8bad\u7ec3\u80fd\u591f\u6cdb\u5316\u5230\u65b0\u9896\u4efb\u52a1\u53d8\u5316\u7684\u4ee3\u7406\u4eba\u3002", "conclusion": "\u8be5\u7814\u7a76\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u60f3\u8c61\u73af\u5883\uff0c\u8bad\u7ec3\u80fd\u591f\u6cdb\u5316\u5230\u65b0\u9896\u4efb\u52a1\u53d8\u5316\u7684\u5f3a\u5927\u4ee3\u7406\u4eba\u3002\u901a\u8fc7\u63d0\u51faIMAC\uff08Imagined Autocurricula\uff09\u65b9\u6cd5\uff0c\u501f\u52a9\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\uff0c\u5728\u751f\u6210\u7684\u4e16\u754c\u4e0a\u8bf1\u5bfc\u51fa\u81ea\u52a8\u8bfe\u7a0b\u8868\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u8bad\u7ec3\u4ee3\u7406\u4eba\u4f7f\u7528\u6709\u6548\u751f\u6210\u6570\u636e\u7684\u6311\u6218\u3002\u5728\u4e00\u7cfb\u5217\u5177\u6709\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\uff0c\u8868\u660e\u53ea\u5728\u4ece\u8f83\u7a84\u6570\u636e\u96c6\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u5185\u8fdb\u884c\u8bad\u7ec3\uff0c\u5373\u53ef\u5728\u4fdd\u7559\u73af\u5883\u4e0a\u5b9e\u73b0\u5f3a\u5927\u7684\u8fc1\u79fb\u6027\u80fd\u3002\u8fd9\u4e3a\u5229\u7528\u66f4\u5927\u89c4\u6a21\u3001\u57fa\u7840\u4e16\u754c\u6a21\u578b\u8bad\u7ec3\u901a\u7528\u80fd\u529b\u7684\u4ee3\u7406\u4eba\u6253\u5f00\u4e86\u9053\u8def\u3002"}}
{"id": "2509.13347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13347", "abs": "https://arxiv.org/abs/2509.13347", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "comment": null, "summary": "The choice of action spaces is a critical yet unresolved challenge in\ndeveloping capable, end-to-end trainable agents. This paper first presents a\nlarge-scale, systematic comparison of prominent abstracted action spaces and\ntokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the\nopen-ended Minecraft. Our analysis reveals that no single action space is\nuniversally optimal; instead, the most effective abstraction is highly\ntask-dependent, creating a dilemma for building generalist agents. To resolve\nthis, we introduce Chain of Action (CoA), a novel framework that unifies\nhigh-level planning and low-level control within a single, monolithic VLA\nmodel. CoA treats an abstracted action not as a command for a separate policy,\nbut as an intermediate reasoning step--akin to a chain of thought--that guides\nthe generation of the final, executable action. Furthermore, we demonstrate\nthat an All-in-One agent trained on a diverse mixture of action spaces using\nthe CoA paradigm learns a more robust and generalizable policy. This unified\nagent achieves a new state-of-the-art, improving the overall task success rate\nover strong, specialized baselines. To foster reproducible research, we release\nthe OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive\nbenchmark of over 800 distinct tasks, curated datasets, source code, and all\npretrained model checkpoints at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "\u5bf9\u4e3b\u6d41\u62bd\u8c61\u52a8\u4f5c\u7a7a\u95f4\u548c\u5206\u8bcd\u5668\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u53d1\u73b0\u7f3a\u4e4f\u5355\u4e00\u6700\u4f18\u89e3\uff0c\u63d0\u51fa\u4e86CoA\u6846\u67b6\u6765\u89e3\u51b3\u4efb\u52a1\u7279\u5b9a\u6027\u56f0\u5883\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u8bad\u7ec3\u4ee3\u7406\u7b56\u7565\u548c\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u540c\u65f6\u53d1\u5e03\u4e86OpenHA\u5957\u4ef6\u4ee5\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u7814\u7a76", "motivation": "\u52a8\u4f5c\u7a7a\u95f4\u7684\u9009\u62e9\u662f\u53d1\u5c55\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u4ee3\u7406\u6240\u9762\u4e34\u7684\u91cd\u8981\u4e14\u672a\u89e3\u51b3\u7684\u6311\u6218\u4e4b\u4e00\uff0c\u901a\u8fc7\u5bf9\u4e3b\u6d41\u62bd\u8c61\u52a8\u4f5c\u7a7a\u95f4\u548c\u5206\u8bcd\u5668\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u63ed\u793a\u4e86\u6700\u6709\u6548\u7684\u62bd\u8c61\u53d6\u51b3\u4e8e\u5177\u4f53\u4efb\u52a1\uff0c\u4e3a\u6784\u5efa\u901a\u7528\u4ee3\u7406\u5e26\u6765\u4e86\u56f0\u5883", "method": "\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u7cfb\u7edf\u6bd4\u8f83\u4e3b\u6d41\u62bd\u8c61\u52a8\u4f5c\u7a7a\u95f4\u548c\u5206\u8bcd\u5668\u5728Vision-Language-Action (VLA)\u6216\u5206\u5c42\u4ee3\u7406\u6a21\u578b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6ca1\u6709\u4e00\u79cd\u5355\u4e00\u7684\u52a8\u4f5c\u7a7a\u95f4\u662f\u666e\u904d\u6700\u4f18\u7684\uff0c\u63d0\u51fa\u4e86Chain of Action (CoA)\u6846\u67b6\u6765\u89e3\u51b3\u4efb\u52a1\u7279\u5b9a\u6027\u5e26\u6765\u7684\u56f0\u5883", "result": "\u8bc1\u660e\u4e86\u4f7f\u7528CoA\u8303\u5f0f\u8bad\u7ec3\u7684All-in-One\u4ee3\u7406\u80fd\u591f\u5b66\u4e60\u66f4\u5f3a\u5065\u548c\u901a\u7528\u7684\u7b56\u7565\uff0c\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u4f18\u4e8e\u4e13\u95e8\u57fa\u7ebf\u6a21\u578b\u7684\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387", "conclusion": "\u4ecb\u7ecd\u4e86Chain of Action (CoA)\u6846\u67b6\uff0c\u901a\u8fc7\u8be5\u6846\u67b6\u53ef\u4ee5\u7edf\u4e00\u9ad8\u5c42\u89c4\u5212\u548c\u4f4e\u5c42\u63a7\u5236\uff0c\u6784\u5efa\u4e00\u4e2a\u6574\u4f53\u7684Vision-Language-Action (VLA)\u6a21\u578b\uff0c\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u63d0\u9ad8\u4e86\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u3002\u53d1\u5e03\u4e86OpenHA\u5957\u4ef6\uff0c\u5305\u62ec800\u591a\u4e2a\u4e0d\u540c\u4efb\u52a1\u7684\u7efc\u5408\u57fa\u51c6\u3001\u7b5b\u9009\u7684\u6570\u636e\u96c6\u3001\u6e90\u4ee3\u7801\u4ee5\u53ca\u6240\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u68c0\u67e5\u70b9\u3002"}}
{"id": "2509.13351", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13351", "abs": "https://arxiv.org/abs/2509.13351", "authors": ["Pulkit Verma", "Ngoc La", "Anthony Favier", "Swaroop Mishra", "Julie A. Shah"], "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse tasks, yet their ability to perform structured symbolic planning\nremains limited, particularly in domains requiring formal representations like\nthe Planning Domain Definition Language (PDDL). In this paper, we present a\nnovel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'\nsymbolic planning capabilities through logical chain-of-thought reasoning. Our\napproach focuses on teaching models to rigorously reason about action\napplicability, state transitions, and plan validity using explicit logical\ninference steps. By developing instruction prompts that guide models through\nthe precise logical reasoning required to determine when actions can be applied\nin a given state, we enable LLMs to self-correct their planning processes\nthrough structured reflection. The framework systematically builds verification\nskills by decomposing the planning process into explicit reasoning chains about\nprecondition satisfaction, effect application, and invariant preservation.\nExperimental results on multiple planning domains show that our\nchain-of-thought reasoning based instruction-tuned models are significantly\nbetter at planning, achieving planning accuracy of up to 94% on standard\nbenchmarks, representing a 66% absolute improvement over baseline models. This\nwork bridges the gap between the general reasoning capabilities of LLMs and the\nlogical precision required for automated planning, offering a promising\ndirection for developing better AI planning systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86PDDL-Instruct\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u903b\u8f91\u94fe\u63a8\u7406\u6765\u589e\u5f3aLLMs\u7684\u7b26\u53f7\u89c4\u5212\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u5728\u89c4\u5212\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\uff0c\u586b\u8865\u4e86\u4e00\u822c\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u903b\u8f91\u7cbe\u786e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "LLMs\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u5c55\u793a\u51fa\u8272\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u6267\u884c\u7ed3\u6784\u5316\u7b26\u53f7\u89c4\u5212\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u6709\u9650\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u7c7b\u4f3c\u89c4\u5212\u9886\u57df\u5b9a\u4e49\u8bed\u8a00\uff08PDDL\uff09\u7684\u5f62\u5f0f\u8868\u793a\u7684\u9886\u57df\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u9ad8LLMs\u7684\u7b26\u53f7\u89c4\u5212\u80fd\u529b\uff0c\u586b\u8865\u5176\u5728\u9700\u8981\u5f62\u5f0f\u5316\u8868\u793a\u7684\u9886\u57df\u4e2d\u7684\u9650\u5236\u6027\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u6307\u5bfc\u6a21\u578b\u8fdb\u884c\u7cbe\u786e\u903b\u8f91\u63a8\u7406\u7684\u6307\u4ee4\u63d0\u793a\uff0c\u4ee5\u786e\u5b9a\u5728\u7ed9\u5b9a\u72b6\u6001\u4e0b\u4f55\u65f6\u53ef\u4ee5\u5e94\u7528\u884c\u52a8\uff0c\u542f\u7528LLMs\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u601d\u81ea\u6211\u7ea0\u6b63\u89c4\u5212\u6d41\u7a0b\u3002\u7cfb\u7edf\u5730\u6784\u5efa\u9a8c\u8bc1\u6280\u80fd\uff0c\u5c06\u89c4\u5212\u8fc7\u7a0b\u5206\u89e3\u4e3a\u5173\u4e8e\u524d\u63d0\u6ee1\u8db3\u3001\u6548\u5e94\u5e94\u7528\u548c\u4e0d\u53d8\u91cf\u7ef4\u62a4\u7684\u660e\u786e\u63a8\u7406\u94fe\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6307\u5bfc\u8c03\u6574\u6a21\u578b\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4f18\u8d8a\uff0c\u5176\u89c4\u5212\u51c6\u786e\u6027\u9ad8\u8fbe94%\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u76f8\u8f83\u57fa\u7ebf\u6a21\u578b\u6539\u8fdb\u4e8666%\u7edd\u5bf9\u503c\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPDDL-Instruct\u7684\u65b0\u578b\u6307\u5bfc\u8c03\u6574\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u903b\u8f91\u601d\u7ef4\u63a8\u7406\u589e\u5f3aLLMs\u7684\u7b26\u53f7\u89c4\u5212\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6307\u5bfc\u8c03\u6574\u6a21\u578b\u5728\u89c4\u5212\u65b9\u9762\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8fbe\u5230\u4e86\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9ad8\u8fbe94%\u7684\u89c4\u5212\u51c6\u786e\u6027\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u6539\u8fdb\u4e8666%\u7edd\u5bf9\u503c\u3002\u8fd9\u9879\u5de5\u4f5c\u586b\u8865\u4e86LLMs\u7684\u4e00\u822c\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u6240\u9700\u7684\u903b\u8f91\u7cbe\u786e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5f00\u53d1\u66f4\u597d\u7684\u4eba\u5de5\u667a\u80fd\u89c4\u5212\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u9014\u7684\u65b9\u5411\u3002"}}
{"id": "2509.13352", "categories": ["cs.AI", "cs.RO", "68T07, 68T40, 68T42", "I.2.9; I.2.11; I.2.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13352", "abs": "https://arxiv.org/abs/2509.13352", "authors": ["Anis Koubaa", "Khaled Gabr"], "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "comment": "14 pages, 1 figure", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\nsurveillance, and disaster response, yet most systems remain confined to SAE\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\nintegration; critically, none leverage Large Language Model (LLM) agents with\ntool-calling for real-time knowledge access. This paper introduces the Agentic\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\nThese results confirm that modest computational overhead enables qualitatively\nnew levels of autonomy and ecosystem integration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86Agentic UAVs \u6846\u67b6\uff0c\u5229\u7528LLM\u63a8\u52a8\u63a8\u7406\u3001\u6570\u636e\u5e93\u67e5\u8be2\u548c\u7cfb\u7edf\u4ea4\u4e92\uff0c\u63d0\u5347UAVs\u7684\u81ea\u4e3b\u6027\u548c\u751f\u6001\u7cfb\u7edf\u6574\u5408\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5728\u641c\u6551\u573a\u666f\u4e2d\u53d6\u5f97\u4e86\u79ef\u6781\u7684\u6210\u679c\uff0c\u8bc1\u5b9e\u4e86\u9002\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\u53ef\u5e26\u6765\u5168\u65b0\u6c34\u5e73\u7684\u81ea\u4e3b\u6027\u548c\u751f\u6001\u7cfb\u7edf\u6574\u5408\u3002", "motivation": "\u73b0\u6709\u7684UAV\u6846\u67b6\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u63a8\u7406\u3001\u81ea\u4e3b\u51b3\u7b56\u548c\u751f\u6001\u7cfb\u7edf\u7ea7\u522b\u7684\u96c6\u6210\uff0c\u7f3a\u4e4f\u5b9e\u65f6\u77e5\u8bc6\u8bbf\u95ee\u3002\u5927\u90e8\u5206UAV\u7cfb\u7edf\u4ecd\u5c40\u9650\u4e8eSAE 2-3\u7ea7\u522b\u81ea\u4e3b\u6027\uff0c\u4f9d\u8d56\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u548c\u72ed\u7a84\u4eba\u5de5\u667a\u80fd\uff0c\u9650\u5236\u4e86\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e94\u5c42\u67b6\u6784\uff08\u611f\u77e5\u3001\u63a8\u7406\u3001\u884c\u52a8\u3001\u6574\u5408\u3001\u5b66\u4e60\uff09\u7684Agentic UAVs\u6846\u67b6\uff0c\u5c06UAVs\u4e0eLLM\u9a71\u52a8\u7684\u63a8\u7406\u3001\u6570\u636e\u5e93\u67e5\u8be2\u548c\u7b2c\u4e09\u65b9\u7cfb\u7edf\u4ea4\u4e92\u76f8\u7ed3\u5408\u3002\u901a\u8fc7\u57fa\u4e8eROS2\u548cGazebo\u7684\u539f\u578b\uff0c\u5c06YOLOv11\u76ee\u6807\u68c0\u6d4b\u4e0eGPT-4\u63a8\u7406\u548c\u672c\u5730Gemma-3\u90e8\u7f72\u96c6\u6210\u3002", "result": "\u5728\u6a21\u62df\u641c\u6551\u573a\u666f\u4e2d\uff0cAgentic UAVs\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u3001\u6539\u5584\u7684\u4e2a\u4f53\u68c0\u6d4b\u7387\u548c\u663e\u8457\u589e\u52a0\u7684\u884c\u52a8\u5efa\u8bae\uff0c\u8bc1\u5b9e\u4e86\u9002\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\u80fd\u591f\u5e26\u6765\u65b0\u6c34\u5e73\u7684\u81ea\u4e3b\u6027\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86Agentic UAVs \u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8eLLM\u7684\u63a8\u7406\u3001\u6570\u636e\u5e93\u67e5\u8be2\u548c\u7b2c\u4e09\u65b9\u7cfb\u7edf\u4ea4\u4e92\uff0c\u4f7f\u5f97UAVs\u5728\u6a21\u62df\u641c\u6551\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u7684\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u3001\u6539\u5584\u4e2a\u4f53\u68c0\u6d4b\u7387\u548c\u663e\u8457\u589e\u52a0\u884c\u52a8\u5efa\u8bae\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u9002\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\u53ef\u4ee5\u5b9e\u73b0\u5168\u65b0\u6c34\u5e73\u7684\u81ea\u4e3b\u6027\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\u3002"}}
{"id": "2509.13357", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13357", "abs": "https://arxiv.org/abs/2509.13357", "authors": ["Yongchao Huang", "Hassan Raza"], "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "comment": "16 pages", "summary": "We propose semantic fusion, a lightweight scheme that augments a Transformer\nlanguage model (LM) with a parallel, fuzzy-membership feature channel that\nencodes token-level semantics. Each token is represented by a vector of\ninterpretable features (e.g. part-of-speech cues, shallow roles, boundary\nflags, sentiment polarity and strength) whose values are graded degrees from\ndifferentiable membership functions (e.g. power kernels). These per-token\nvectors form a sentence-level semantic matrix fused via a gated adapter into\nthe LM. Training uses standard next-token prediction, an auxiliary loss that\nreconstructs the semantic features from hidden states, and a lightweight\nuniformizer that regularizes adjective-class distributions. On a synthetic\ntwo-clause corpus with held-out adjectives for out-of-distribution (OOD)\ncontrol, semantic fusion improves perplexity and enables precise,\nuser-controllable generation of polarity and punctuation while maintaining\nmodel simplicity. This approach adds only small overhead, remains fully\ncompatible with tied input-output embeddings, and provides an interpretable\npathway for conditioned natural language generation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u878d\u5408\u65b9\u6848\uff0c\u901a\u8fc7\u7279\u5f81\u901a\u9053\u548c\u95e8\u63a7\u9002\u914d\u5668\uff0c\u5c06\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u7279\u5f81\u878d\u5408\u5230Transformer\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u751f\u6210\u6587\u672c\u7684\u51c6\u786e\u6027\u548c\u53ef\u63a7\u5236\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5408\u6210\u8bed\u6599\u5e93\u4e0a\u80fd\u591f\u6539\u5584\u6df7\u4e71\u5ea6\uff0c\u5b9e\u73b0\u7cbe\u786e\u3001\u53ef\u63a7\u7684\u6587\u672c\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u7b80\u5355\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u662f\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8bed\u4e49\u878d\u5408\u65b9\u6848\uff0c\u4ee5\u589e\u5f3aTransformer\u8bed\u8a00\u6a21\u578b\u5728\u6807\u8bb0\u7ea7\u522b\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u3002\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u6807\u8bb0\u5f15\u5165\u53ef\u89e3\u91ca\u7684\u7279\u5f81\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7279\u5f81\u878d\u5408\u5230\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u751f\u6210\u6587\u672c\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5728Transformer\u8bed\u8a00\u6a21\u578b\u4e2d\u589e\u52a0\u6a21\u7cca\u6210\u5458\u7279\u5f81\u901a\u9053\uff0c\u5e76\u4f7f\u7528\u95e8\u63a7\u9002\u914d\u5668\u5c06\u6bcf\u4e2a\u6807\u8bb0\u8868\u793a\u4e3a\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u901a\u8fc7\u8bad\u7ec3\u6807\u51c6\u7684\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u3001\u8f85\u52a9\u91cd\u5efa\u8bed\u4e49\u7279\u5f81\u7684\u635f\u5931\u4ee5\u53ca\u8f7b\u91cf\u7ea7\u7edf\u4e00\u5668\u6765\u5b9e\u73b0\u8bed\u4e49\u878d\u5408\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u8bed\u4e49\u878d\u5408\u65b9\u6848\uff0c\u5728\u4e24\u4e2a\u5b50\u53e5\u8bed\u6599\u5e93\u4e0a\u5b9e\u73b0\u4e86\u6539\u8fdb\u7684\u6df7\u4e71\u5ea6\uff0c\u53ef\u4ee5\u7cbe\u786e\u3001\u53ef\u63a7\u5730\u751f\u6210\u6781\u6027\u548c\u6807\u70b9\uff0c\u5e76\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u7b80\u5355\u6027\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u7684\u5b9e\u65bd\u53ea\u5e26\u6765\u4e86\u5f88\u5c0f\u7684\u989d\u5916\u5f00\u9500\uff0c\u4e0e\u8f93\u5165\u8f93\u51fa\u5d4c\u5165\u7ed1\u5b9a\u517c\u5bb9\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u751f\u6210\u9014\u5f84\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u878d\u5408\u7684\u8f7b\u91cf\u7ea7\u65b9\u6848\uff0c\u901a\u8fc7\u5728Transformer\u8bed\u8a00\u6a21\u578b(LM)\u4e2d\u589e\u52a0\u4e00\u4e2a\u5e76\u884c\u7684\u6a21\u7cca\u6210\u5458\u7279\u5f81\u901a\u9053\uff0c\u5bf9\u6807\u8bb0\u7ea7\u8bed\u4e49\u8fdb\u884c\u7f16\u7801\u3002\u8bed\u4e49\u878d\u5408\u901a\u8fc7\u4e00\u79cd\u95e8\u63a7\u9002\u914d\u5668\u5c06\u6bcf\u4e2a\u6807\u8bb0\u8868\u793a\u4e3a\u53ef\u89e3\u91ca\u7279\u5f81(\u4f8b\u5982\u8bcd\u6027\u63d0\u793a\u3001\u6d45\u5c42\u89d2\u8272\u3001\u8fb9\u754c\u6807\u5fd7\u3001\u60c5\u611f\u6781\u6027\u548c\u5f3a\u5ea6)\u7684\u77e2\u91cf\uff0c\u8fd9\u4e9b\u7279\u5f81\u503c\u6765\u81ea\u4e0d\u540c\u53ef\u5fae\u5206\u6210\u5458\u51fd\u6570(\u4f8b\u5982\u529f\u7387\u6838)\u3002\u8fd9\u4e9b\u6bcf\u4e2a\u6807\u8bb0\u7684\u5411\u91cf\u5f62\u6210\u4e00\u4e2a\u53e5\u5b50\u7ea7\u8bed\u4e49\u77e9\u9635\uff0c\u878d\u5408\u5230LM\u4e2d\u3002\u5728\u5408\u6210\u7684\u4e24\u4e2a\u5b50\u53e5\u8bed\u6599\u5e93\u4e0a\uff0c\u4f7f\u7528\u6807\u51c6\u7684\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u8fdb\u884c\u8bad\u7ec3\uff0c\u8f85\u52a9\u635f\u5931\u4ece\u9690\u85cf\u72b6\u6001\u91cd\u5efa\u8bed\u4e49\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7edf\u4e00\u5668\u5bf9\u5f62\u5bb9\u8bcd\u7c7b\u5206\u5e03\u8fdb\u884c\u89c4\u8303\u5316\u3002\u8bed\u4e49\u878d\u5408\u6539\u5584\u4e86\u6df7\u4e71\u5ea6\uff0c\u5e76\u5b9e\u73b0\u4e86\u7cbe\u786e\u3001\u53ef\u63a7\u5236\u7684\u6781\u6027\u548c\u6807\u70b9\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u7b80\u5355\u6027\u3002\u8fd9\u79cd\u65b9\u6cd5\u4ec5\u589e\u52a0\u4e86\u5f88\u5c0f\u7684\u5f00\u9500\uff0c\u4e0e\u8f93\u5165\u8f93\u51fa\u5d4c\u5165\u7ed1\u5b9a\u5b8c\u5168\u517c\u5bb9\uff0c\u5e76\u4e3a\u6709\u6761\u4ef6\u7684\u81ea\u7136\u8bed\u8a00\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u9014\u5f84\u3002"}}
{"id": "2509.13364", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13364", "abs": "https://arxiv.org/abs/2509.13364", "authors": ["Zixi Li"], "title": "Asterisk Operator", "comment": "Code available at: https://github.com/lizixi-0x2F/Asterisk-Games", "summary": "We propose the \\textbf{Asterisk Operator} ($\\ast$-operator), a novel unified\nframework for abstract reasoning based on Adjacency-Structured Parallel\nPropagation (ASPP). The operator formalizes structured reasoning tasks as\nlocal, parallel state evolution processes guided by implicit relational graphs.\nWe prove that the $\\ast$-operator maintains local computational constraints\nwhile achieving global reasoning capabilities, providing an efficient and\nconvergent computational paradigm for abstract reasoning problems. Through\nrigorous mathematical analysis and comprehensive experiments on ARC2 challenges\nand Conway's Game of Life, we demonstrate the operator's universality,\nconvergence properties, and superior performance. Our innovative\nEmbedding-Asterisk distillation method achieves 100\\% accuracy on ARC2\nvalidation with only 6M parameters, representing a significant breakthrough in\nneural-symbolic reasoning.\n  \\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel\nPropagation, Asterisk Operator, Convergence, Universal Approximation", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u661f\u53f7\u8fd0\u7b97\u7b26\uff08*\u8fd0\u7b97\u7b26\uff09\uff0c\u57fa\u4e8e\u90bb\u8fd1\u7ed3\u6784\u5e76\u884c\u4f20\u64ad\uff08ASPP\uff09\uff0c\u5f62\u6210\u4e86\u65b0\u578b\u7edf\u4e00\u62bd\u8c61\u63a8\u7406\u6846\u67b6\u3002\u661f\u53f7\u8fd0\u7b97\u7b26\u901a\u8fc7\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\u548c\u9690\u5f0f\u5173\u7cfb\u56fe\u5b9e\u73b0\u4e86\u5168\u5c40\u63a8\u7406\u80fd\u529b\uff0c\u65e2\u4fdd\u6301\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u53c8\u63d0\u4f9b\u9ad8\u6548\u6536\u655b\u7684\u8ba1\u7b97\u8303\u5f0f\u3002\u7ecf\u8fc7\u6570\u5b66\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u666e\u9002\u6027\u3001\u6536\u655b\u6027\u548c\u5353\u8d8a\u6027\u80fd\u3002\u5d4c\u5165\u661f\u53f7\u84b8\u998f\u65b9\u6cd5\u5728ARC2\u9a8c\u8bc1\u4e2d\u53d6\u5f97\u4e86100%\u51c6\u786e\u7387\uff0c\u4ee3\u8868\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\u3002", "motivation": "\u63d0\u51fa\u661f\u53f7\u8fd0\u7b97\u7b26\uff08*\u8fd0\u7b97\u7b26\uff09\u7684\u521d\u8877\u662f\u4e3a\u4e86\u89e3\u51b3\u62bd\u8c61\u63a8\u7406\u95ee\u9898\u4e2d\u7684\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u548c\u5168\u5c40\u63a8\u7406\u80fd\u529b\u4e4b\u95f4\u7684\u5e73\u8861\u96be\u9898\uff0c\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u9ad8\u6548\u6536\u655b\u7684\u8ba1\u7b97\u8303\u5f0f\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u5728\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u9886\u57df\u53d6\u5f97\u7a81\u7834\uff0c\u521b\u65b0\u63d0\u51fa\u5d4c\u5165\u661f\u53f7\u84b8\u998f\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u51c6\u786e\u7387\u548c\u6027\u80fd\u3002", "method": "\u57fa\u4e8e\u90bb\u8fd1\u7ed3\u6784\u5e76\u884c\u4f20\u64ad\uff08ASPP\uff09\u7684\u65b0\u578b\u7edf\u4e00\u62bd\u8c61\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\uff0c\u901a\u8fc7\u9690\u5f0f\u5173\u7cfb\u56fe\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u901a\u8fc7\u6570\u5b66\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u6846\u67b6\u7684\u666e\u9002\u6027\u3001\u6536\u655b\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002\u540c\u65f6\u63d0\u51fa\u5d4c\u5165\u661f\u53f7\u84b8\u998f\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728ARC2\u9a8c\u8bc1\u4e2d100%\u51c6\u786e\u7387\u7684\u7a81\u7834\u6027\u6210\u679c\u3002", "result": "\u901a\u8fc7\u7814\u7a76\uff0c\u6211\u4eec\u6210\u529f\u63d0\u51fa\u4e86\u661f\u53f7\u8fd0\u7b97\u7b26\uff08*\u8fd0\u7b97\u7b26\uff09\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u62bd\u8c61\u63a8\u7406\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u73b0\u5168\u5c40\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u4fdd\u6301\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\uff0c\u5c55\u793a\u4e86\u5176\u5728ARC2\u9a8c\u8bc1\u548c\u5eb7\u5a01\u751f\u547d\u6e38\u620f\u7b49\u65b9\u9762\u7684\u5353\u8d8a\u6027\u80fd\u3002\u521b\u65b0\u7684\u5d4c\u5165\u661f\u53f7\u84b8\u998f\u65b9\u6cd5\u5728ARC2\u9a8c\u8bc1\u4e2d\u53d6\u5f97\u4e86100%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u661f\u53f7\u8fd0\u7b97\u7b26\uff08*\u8fd0\u7b97\u7b26\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u90bb\u8fd1\u7ed3\u6784\u5e76\u884c\u4f20\u64ad\uff08ASPP\uff09\u7684\u65b0\u578b\u7edf\u4e00\u62bd\u8c61\u63a8\u7406\u6846\u67b6\u3002\u8be5\u8fd0\u7b97\u7b26\u5c06\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u7531\u9690\u5f0f\u5173\u7cfb\u56fe\u6307\u5bfc\u7684\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\u3002\u6211\u4eec\u8bc1\u660e\u661f\u53f7\u8fd0\u7b97\u7b26\u5728\u4fdd\u6301\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5168\u5c40\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u62bd\u8c61\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u6536\u655b\u7684\u8ba1\u7b97\u8303\u5f0f\u3002\u901a\u8fc7\u5bf9ARC2\u6311\u6218\u548c\u5eb7\u5a01\u751f\u547d\u6e38\u620f\u7684\u4e25\u683c\u6570\u5b66\u5206\u6790\u548c\u5168\u9762\u5b9e\u9a8c\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u8be5\u8fd0\u7b97\u7b26\u7684\u666e\u9002\u6027\u3001\u6536\u655b\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002\u6211\u4eec\u7684\u521b\u65b0\u578b\u5d4c\u5165\u661f\u53f7\u84b8\u998f\u65b9\u6cd5\u5728\u4ec5\u67096M\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u5728ARC2\u9a8c\u8bc1\u4e2d\u5b9e\u73b0\u4e86100%\u51c6\u786e\u7387\uff0c\u4ee3\u8868\u4e86\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u7684\u91cd\u5927\u7a81\u7834\u3002"}}
{"id": "2509.13368", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13368", "abs": "https://arxiv.org/abs/2509.13368", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "comment": "9 pages, 7 figures", "summary": "Reinforcement learning agent development traditionally requires extensive\nexpertise and lengthy iterations, often resulting in high failure rates and\nlimited accessibility. This paper introduces $Agent^2$, a novel\nagent-generates-agent framework that achieves fully automated RL agent design\nthrough intelligent LLM-driven generation. The system autonomously transforms\nnatural language task descriptions and environment code into comprehensive,\nhigh-performance reinforcement learning solutions without human intervention.\n$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent\nserves as an autonomous AI designer that analyzes tasks and generates\nexecutable RL agents, while the Target Agent is the resulting automatically\ngenerated RL agent. The framework decomposes RL development into two distinct\nstages: MDP modeling and algorithmic optimization, enabling more targeted and\neffective agent generation. Built on the Model Context Protocol, $Agent^2$\nprovides a unified framework that standardizes intelligent agent creation\nacross diverse environments and algorithms, while incorporating adaptive\ntraining management and intelligent feedback analysis for continuous\nimprovement. Extensive experiments on a wide range of benchmarks, including\nMuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently\noutperforms manually designed solutions across all tasks, achieving up to 55%\nperformance improvement and substantial gains on average. By enabling truly\nend-to-end, closed-loop automation, this work establishes a new paradigm in\nwhich intelligent agents design and optimize other agents, marking a\nfundamental breakthrough for automated AI systems.", "AI": {"tldr": "$Agent^2$ is a novel framework for fully automated RL agent design that outperforms manual designs by up to 55%. It features a dual-agent architecture and decomposes RL development into MDP modeling and algorithmic optimization stages. The framework is built on the Model Context Protocol, providing standardized agent creation across environments and algorithms, with adaptive training management for continuous improvement.", "motivation": "Traditional RL agent development requires extensive expertise and time-consuming iterations, leading to high failure rates and limited accessibility. The motivation behind the paper is to introduce a fully automated RL agent design framework, $Agent^2$, that eliminates the need for human intervention and achieves superior performance compared to manual designs.", "method": "The paper introduces the $Agent^2$ framework, a dual-agent architecture consisting of a Generator Agent and a Target Agent. The Generator Agent autonomously designs RL agents by analyzing tasks and environment code, while the Target Agent is the resulting generated RL agent. The framework decomposes RL development into MDP modeling and algorithmic optimization stages, providing targeted and effective agent generation. It is built on the Model Context Protocol and incorporates adaptive training management and intelligent feedback analysis for continuous improvement.", "result": "Extensive experiments on various benchmarks show that $Agent^2$ consistently outperforms manually designed solutions across tasks, achieving significant performance improvement. The framework standardizes intelligent agent creation across different environments and algorithms, demonstrating its versatility and effectiveness.", "conclusion": "$Agent^2$ framework achieved fully automated RL agent design through intelligent LLM-driven generation, outperforming manual designs by up to 55% on various benchmarks. It marks a fundamental breakthrough in automated AI systems by enabling intelligent agents to design and optimize other agents."}}
{"id": "2509.13379", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13379", "abs": "https://arxiv.org/abs/2509.13379", "authors": ["Asif Azad", "Mohammad Sadat Hossain", "MD Sadik Hossain Shanto", "M Saifur Rahman", "Md Rizwan Pervez"], "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex\nvisual understanding across scientific and reasoning tasks. While performance\nbenchmarking has advanced our understanding of these capabilities, the critical\ndimension of uncertainty quantification has received insufficient attention.\nTherefore, unlike prior conformal prediction studies that focused on limited\nsettings, we conduct a comprehensive uncertainty benchmarking study, evaluating\n16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets\nwith 3 distinct scoring functions. Our findings demonstrate that larger models\nconsistently exhibit better uncertainty quantification; models that know more\nalso know better what they don't know. More certain models achieve higher\naccuracy, while mathematical and reasoning tasks elicit poorer uncertainty\nperformance across all models compared to other domains. This work establishes\na foundation for reliable uncertainty evaluation in multimodal systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e8616\u4e2a\u6700\u5148\u8fdb\u7684VLM\u6a21\u578b\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\uff0c\u53d1\u73b0\u5927\u578b\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u66f4\u80dc\u4e00\u7b79\uff0c\u5e76\u4e14\u5728\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u8f83\u5dee\u3002\u672c\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "VLMs\u5728\u89c6\u89c9\u7406\u89e3\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8fd9\u4e00\u5173\u952e\u7ef4\u5ea6\u7f3a\u4e4f\u8db3\u591f\u5173\u6ce8\uff1b\u4e4b\u524d\u5173\u4e8e\u7b26\u5408\u6027\u9884\u6d4b\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u6709\u9650\u7684\u8bbe\u7f6e\u4e0a\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8fdb\u884c\u4e86\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\u7814\u7a76\uff0c\u8bc4\u4f30\u4e8616\u4e2a\u6700\u5148\u8fdb\u7684VLM\u6a21\u578b\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u4e863\u79cd\u4e0d\u540c\u7684\u8bc4\u5206\u51fd\u6570\u3002", "result": "\u53d1\u73b0\u5927\u578b\u6a21\u578b\u4e00\u81f4\u8868\u73b0\u51fa\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff1b\u4e0d\u786e\u5b9a\u6027\u8f83\u4f4e\u7684\u6a21\u578b\u5b9e\u73b0\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff1b\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "\u5927\u578b\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff1b\u5bf9\u4e8e\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\uff0c\u6240\u6709\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u6027\u80fd\u90fd\u4e0d\u5982\u5176\u4ed6\u9886\u57df\uff1b\u672c\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.13389", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.13389", "abs": "https://arxiv.org/abs/2509.13389", "authors": ["Carlos N\u00fa\u00f1ez-Molina", "Vicen\u00e7 G\u00f3mez", "Hector Geffner"], "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "comment": "10 pages, 3 figures", "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u6df1\u5ea6\u5b78\u7fd2\u67b6\u69cb\u548c\u68af\u5ea6\u4e0b\u964d\u4f86\u5b78\u7fd2\u547d\u984cSTRIPS\u4e16\u754c\u6a21\u578b\uff0c\u5c07\u4efb\u52d9\u5b9a\u7fa9\u70ba\u4e0b\u4e00\u500btoken\u9810\u6e2c\u554f\u984c\u3002\u901a\u904e\u5206\u6790\u52d5\u4f5c\u5e8f\u5217\uff0c\u78ba\u5b9a\u4e0b\u4e00\u500b\u52d5\u4f5c\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\u9069\u5408\u7684transformer\u67b6\u69cb\u53ef\u4ee5\u6e96\u78ba\u8868\u793a\u6a21\u578b\u4e26\u50c5\u5f9e\u52d5\u4f5c\u5e8f\u5217\u4e2d\u5b78\u7fd2\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52d5\u6a5f\u5728\u65bc\u901a\u904e\u52d5\u4f5c\u8ecc\u8de1\u7368\u7acb\u5b78\u7fd2\u547d\u984cSTRIPS\u4e16\u754c\u6a21\u578b\u7684\u554f\u984c\uff0c\u4e26\u63a2\u8a0e\u6df1\u5ea6\u5b78\u7fd2\u67b6\u69cb\u5728\u6b64\u4efb\u52d9\u4e2d\u7684\u9069\u7528\u6027\u548c\u6548\u679c\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b78\u7fd2\u67b6\u69cb\uff08transformers\uff09\u548c\u68af\u5ea6\u4e0b\u964d\u4f86\u9032\u884c\u547d\u984cSTRIPS\u4e16\u754c\u6a21\u578b\u7684\u5b78\u7fd2\uff0c\u5c07\u4efb\u52d9\u5b9a\u7fa9\u70ba\u76e3\u7763\u5f0f\u4e0b\u4e00\u500btoken\u9810\u6e2c\u554f\u984c\uff0c\u4e26\u901a\u904e\u67e5\u770b\u52d5\u4f5c\u5e8f\u5217\u4f86\u78ba\u5b9a\u4e0b\u4e00\u500b\u52d5\u4f5c\u3002", "result": "\u5c55\u793a\u4e86\u9069\u5408\u7684transformer\u67b6\u69cb\u53ef\u4ee5\u5fe0\u5be6\u8868\u793a\u547d\u984cSTRIPS\u4e16\u754c\u6a21\u578b\uff0c\u540c\u6642\u9019\u4e9b\u6a21\u578b\u53ef\u4ee5\u50c5\u5f9e\u6b63\u78ba\u548c\u932f\u8aa4\u7684\u52d5\u4f5c\u5e8f\u5217\u96c6\u4e2d\u5b78\u7fd2\u3002\u9032\u884c\u4e86\u591a\u500b\u5be6\u9a57\u3002", "conclusion": "\u900f\u904e\u6df1\u5ea6\u5b78\u7fd2\u67b6\u69cb\uff08transformers\uff09\u548c\u68af\u5ea6\u4e0b\u964d\uff0c\u672c\u7814\u7a76\u8003\u616e\u5f9e\u52d5\u4f5c\u8ecc\u8de1\u55ae\u7368\u5b78\u7fd2\u547d\u984cSTRIPS\u4e16\u754c\u6a21\u578b\u7684\u554f\u984c\u3002\u5c07\u4efb\u52d9\u8996\u70ba\u76e3\u7763\u5f0f\u4e0b\u4e00\u500btoken\u9810\u6e2c\u554f\u984c\uff0c\u5176\u4e2dtoken\u662f\u52d5\u4f5c\uff0c\u5982\u679c\u524d\u5e7e\u500b\u52d5\u4f5c\u7684\u96b1\u85cf\u6548\u679c\u4e0d\u4f7f\u52d5\u4f5c\u7684\u524d\u63d0\u70ba$a$\u70bafalse\uff0c\u5247\u52d5\u4f5c$a$\u53ef\u80fd\u8ddf\u96a8\u4e00\u500b\u52d5\u4f5c\u5e8f\u5217\u3002 \u6211\u5011\u5c55\u793a\u4e86\u9069\u5408\u7684transformer\u67b6\u69cb\u53ef\u4ee5\u5fe0\u5be6\u8868\u793a\u547d\u984cSTRIPS\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u4e14\u53ef\u4ee5\u50c5\u5f9e\u96a8\u6a5f\u6709\u6548\uff08\u6b63\u9762\uff09\u548c\u7121\u6548\uff08\u8ca0\u9762\uff09\u52d5\u4f5c\u5e8f\u5217\u7d44\u4e2d\u5b78\u7fd2\u9019\u4e9b\u6a21\u578b\u3002\u8ad6\u6587\u5831\u544a\u4e86\u4e00\u7cfb\u5217\u5be6\u9a57\u3002"}}
{"id": "2509.13450", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13450", "abs": "https://arxiv.org/abs/2509.13450", "authors": ["Vincent Siu", "Nicholas Crispino", "David Park", "Nathan W. Henry", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "comment": null, "summary": "We introduce SteeringControl, a benchmark for evaluating representation\nsteering methods across core alignment objectives--bias, harmful generation,\nand hallucination--and their effects on secondary behaviors such as sycophancy\nand commonsense morality. While prior alignment work often highlights\ntruthfulness or reasoning ability to demonstrate the side effects of\nrepresentation steering, we find there are many unexplored tradeoffs not yet\nunderstood in a systematic way. We collect a dataset of safety-relevant primary\nand secondary behaviors to evaluate steering effectiveness and behavioral\nentanglement centered around five popular steering methods. To enable this, we\ncraft a modular steering framework based on unique components that serve as the\nbuilding blocks of many existing methods. Our results on Qwen-2.5-7B and\nLlama-3.1-8B find that strong steering performance is dependent on the specific\ncombination of steering method, model, and targeted behavior, and that severe\nconcept entanglement can result from poor combinations of these three as well.\nWe release our code here:\nhttps://github.com/wang-research-lab/SteeringControl.git.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SteeringControl\uff0c\u7528\u4e8e\u8bc4\u4f30\u8868\u793a\u8f6c\u5411\u65b9\u6cd5\u5728\u6838\u5fc3\u5bf9\u9f50\u76ee\u6807\u548c\u6b21\u751f\u884c\u4e3a\u4e0a\u7684\u5f71\u54cd\u3002\u6784\u5efa\u4e86\u6a21\u5757\u5316\u7684\u8f6c\u5411\u6846\u67b6\uff0c\u5e76\u6536\u96c6\u4e86\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\u8f6c\u5411\u6027\u80fd\u53d6\u51b3\u4e8e\u7279\u5b9a\u7684\u7ec4\u5408\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u6982\u5ff5\u7ea0\u7f20\u3002", "motivation": "\u4e4b\u524d\u7684\u5bf9\u9f50\u5de5\u4f5c\u901a\u5e38\u4fa7\u91cd\u4e8e\u5c55\u793a\u8868\u793a\u8f6c\u5411\u7684\u526f\u4f5c\u7528\uff0c\u4f46\u53d1\u73b0\u8fd8\u6709\u8bb8\u591a\u672a\u88ab\u7cfb\u7edf\u5316\u7406\u89e3\u7684\u672a\u63a2\u7d22\u7684\u6743\u8861\u3002\u5f15\u5165SteeringControl\u57fa\u51c6\u6765\u8bc4\u4f30\u8868\u793a\u8f6c\u5411\u65b9\u6cd5\u5728\u6838\u5fc3\u5bf9\u9f50\u76ee\u6807\u4ee5\u53ca\u5bf9\u6b21\u751f\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u8f6c\u5411\u6846\u67b6\uff0c\u57fa\u4e8e\u72ec\u7279\u7ec4\u4ef6\uff0c\u4f5c\u4e3a\u73b0\u6709\u65b9\u6cd5\u7684\u6784\u5efa\u6a21\u5757\u3002\u6536\u96c6\u4e86\u5b89\u5168\u76f8\u5173\u7684\u4e3b\u8981\u548c\u6b21\u8981\u884c\u4e3a\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u8f6c\u5411\u6548\u679c\u548c\u56f4\u7ed5\u4e94\u79cd\u6d41\u884c\u8f6c\u5411\u65b9\u6cd5\u7684\u884c\u4e3a\u7ea0\u7f20\u3002", "result": "\u5f3a\u5927\u7684\u8f6c\u5411\u6027\u80fd\u53d6\u51b3\u4e8e\u7279\u5b9a\u7684\u8f6c\u5411\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u7ec4\u5408\uff0c\u5e76\u4e14\u7cdf\u7cd5\u7684\u7ec4\u5408\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\u3002", "conclusion": "\u672c\u6587\u5f15\u5165\u4e86SteeringControl\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8868\u793a\u8f6c\u5411\u65b9\u6cd5\u5728\u6838\u5fc3\u5bf9\u9f50\u76ee\u6807\uff08\u504f\u89c1\u3001\u6709\u5bb3\u751f\u6210\u548c\u5e7b\u89c9\uff09\u4ee5\u53ca\u5b83\u4eec\u5bf9\u6b21\u751f\u884c\u4e3a\uff08\u5982\u963f\u8c00\u5949\u627f\u548c\u5e38\u8bc6\u9053\u5fb7\uff09\u7684\u5f71\u54cd\u7684\u57fa\u51c6\u3002\u6211\u4eec\u53d1\u73b0\u4e4b\u524d\u7684\u5bf9\u9f50\u5de5\u4f5c\u901a\u5e38\u5f3a\u8c03\u771f\u5b9e\u6027\u6216\u63a8\u7406\u80fd\u529b\uff0c\u4ee5\u5c55\u793a\u8868\u793a\u8f6c\u5411\u7684\u526f\u4f5c\u7528\uff0c\u4f46\u6211\u4eec\u53d1\u73b0\u8fd8\u6709\u8bb8\u591a\u672a\u88ab\u7cfb\u7edf\u5316\u7406\u89e3\u7684\u672a\u63a2\u7d22\u7684\u6743\u8861\u3002\u6211\u4eec\u6536\u96c6\u4e86\u4e00\u4e2a\u4e0e\u5b89\u5168\u76f8\u5173\u7684\u4e3b\u8981\u548c\u6b21\u8981\u884c\u4e3a\u6570\u636e\u96c6\uff0c\u4ee5\u8bc4\u4f30\u8f6c\u5411\u6548\u679c\u548c\u56f4\u7ed5\u4e94\u79cd\u6d41\u884c\u8f6c\u5411\u65b9\u6cd5\u7684\u884c\u4e3a\u7ea0\u7f20\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u72ec\u7279\u7ec4\u4ef6\u7684\u6a21\u5757\u5316\u8f6c\u5411\u6846\u67b6\uff0c\u8fd9\u4e9b\u7ec4\u4ef6\u53ef\u4f5c\u4e3a\u8bb8\u591a\u73b0\u6709\u65b9\u6cd5\u7684\u6784\u5efa\u6a21\u5757\u3002\u6211\u4eec\u5728Qwen-2.5-7B\u548cLlama-3.1-8B\u4e0a\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5f3a\u5927\u7684\u8f6c\u5411\u6027\u80fd\u53d6\u51b3\u4e8e\u7279\u5b9a\u7684\u8f6c\u5411\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u7ec4\u5408\uff0c\u5e76\u4e14\u8fd9\u4e09\u8005\u7684\u7cdf\u7cd5\u7ec4\u5408\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\u3002\u6211\u4eec\u5728\u6b64\u516c\u5f00\u6211\u4eec\u7684\u4ee3\u7801\uff1ahttps://github.com/wang-research-lab/SteeringControl.git\u3002"}}
{"id": "2509.13547", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13547", "abs": "https://arxiv.org/abs/2509.13547", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "comment": "16 pages, 5 tables", "summary": "We investigate whether giving LLM agents the collaborative tools and autonomy\nthat humans naturally use for problem solving can improve their performance. We\nequip Claude Code agents with MCP-based social media and journaling tools and\nallow them to use these tools as they see fit. Across 34 Aider Polyglot Python\nprogramming challenges, collaborative tools substantially improve performance\non the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and\n12-38% faster completion than baseline agents. Effects on the full challenge\nset are mixed, suggesting these tools act as performance enhancers when\nadditional reasoning scaffolding is most needed. Surprisingly, Different models\nnaturally adopted distinct collaborative strategies without explicit\ninstruction. Sonnet 3.7 engaged broadly across tools and benefited from\narticulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,\nleaning on journal-based semantic search when problems were genuinely\ndifficult. This mirrors how human developers adjust collaboration based on\nexpertise and task complexity. Behavioral analysis shows agents prefer writing\nover reading by about 2-9x, indicating that structured articulation drives much\nof the improvement rather than information access alone. Overall, AI agents can\nsystematically benefit from human-inspired collaboration tools at the edge of\ntheir capabilities, pointing to adaptive collaborative interfaces as reasoning\nenhancers rather than universal efficiency boosts.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7a76\u4e86\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6743\u662f\u5426\u53ef\u4ee5\u63d0\u9ad8\u5176\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u56f0\u96be\u95ee\u9898\u4e0a\uff0c\u534f\u4f5c\u5de5\u5177\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7406\u7684\u8868\u73b0\u3002\u4e0d\u540c\u4ee3\u7406\u6a21\u578b\u91c7\u7528\u4e0d\u540c\u7684\u534f\u4f5c\u7b56\u7565\uff0c\u4ee3\u7406\u66f4\u503e\u5411\u4e8e\u5199\u4f5c\u800c\u975e\u9605\u8bfb\u3002\u56e0\u6b64\uff0cAI\u4ee3\u7406\u53ef\u4ee5\u4ece\u4eba\u7c7b\u542f\u53d1\u7684\u534f\u4f5c\u5de5\u5177\u4e2d\u53d7\u76ca\uff0c\u5e76\u6307\u51fa\u81ea\u9002\u5e94\u534f\u4f5c\u754c\u9762\u53ef\u4ee5\u4f5c\u4e3a\u63a8\u7406\u589e\u5f3a\u5668\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7a76\u662f\u5426\u8ba9LLM\u4ee3\u7406\u83b7\u5f97\u4eba\u7c7b\u81ea\u7136\u4f7f\u7528\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6743\uff0c\u80fd\u5426\u63d0\u9ad8\u5b83\u4eec\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1LLM\u4ee3\u7406\u5728\u4f7f\u7528\u534f\u4f5c\u5de5\u5177\u65f6\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u8fd9\u4e9b\u5de5\u5177\u5bf9\u57fa\u7ebf\u4ee3\u7406\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u4e5f\u5e0c\u671b\u4e86\u89e3\u4ee3\u7406\u5982\u4f55\u81ea\u53d1\u91c7\u7528\u4e0d\u540c\u7684\u534f\u4f5c\u7b56\u7565\uff0c\u4ee5\u53ca\u4ee3\u7406\u66f4\u504f\u5411\u4e8e\u5199\u4f5c\u8fd8\u662f\u9605\u8bfb\u3002", "method": "\u88c5\u5907LLM\u4ee3\u7406\u4e0eMCP-based\u793e\u4ea4\u5a92\u4f53\u548c\u65e5\u5fd7\u5de5\u5177\uff0c\u8ba9\u5176\u81ea\u884c\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u8fdb\u884c\u95ee\u9898\u89e3\u51b3\u3002\u89c2\u5bdf34\u4e2aAider Polyglot Python\u7f16\u7a0b\u6311\u6218\u4e2d\u534f\u4f5c\u5de5\u5177\u7684\u5f71\u54cd\uff0c\u5e76\u5bf9\u4ee3\u7406\u7684\u8868\u73b0\u8fdb\u884c\u8bc4\u4f30\u3002\u8fdb\u884c\u884c\u4e3a\u5206\u6790\u4ee5\u4e86\u89e3\u4ee3\u7406\u7684\u504f\u597d\u548c\u5982\u4f55\u91c7\u7528\u4e0d\u540c\u7684\u534f\u4f5c\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728Aider Polyglot Python\u7f16\u7a0b\u6311\u6218\u4e2d\uff0c\u534f\u4f5c\u5de5\u5177\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u56f0\u96be\u95ee\u9898\u7684\u89e3\u51b3\u6027\u80fd\uff0c\u964d\u4f4e\u4e86\u6210\u672c\u3001\u56de\u5408\u6570\uff0c\u5e76\u52a0\u5feb\u4e86\u5b8c\u6210\u65f6\u95f4\u3002\u4e0d\u540c\u7684\u4ee3\u7406\u6a21\u578b\u91c7\u7528\u4e86\u4e0d\u540c\u7684\u534f\u4f5c\u7b56\u7565\uff0cSonnet 3.7\u5e7f\u6cdb\u4f7f\u7528\u5de5\u5177\u5e76\u53d7\u76ca\u4e8e\u57fa\u4e8e\u8868\u8fbe\u7684\u8ba4\u77e5\u652f\u67b6\uff0cSonnet 4\u5219\u6709\u9009\u62e9\u6027\u5730\u91c7\u7528\u57fa\u4e8e\u65e5\u5fd7\u7684\u8bed\u4e49\u641c\u7d22\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u4ee3\u7406\u66f4\u504f\u5411\u4e8e\u5199\u4f5c\u800c\u975e\u9605\u8bfb\uff0c\u8868\u660e\u7ed3\u6784\u5316\u7684\u8868\u8fbe\u9a71\u52a8\u4e86\u6539\u8fdb\u7684\u5927\u90e8\u5206\u90e8\u5206\u3002\u6700\u7ec8\u6307\u51fa\uff0cAI\u4ee3\u7406\u53ef\u4ee5\u4ece\u4eba\u7c7b\u542f\u53d1\u7684\u534f\u4f5c\u5de5\u5177\u4e2d\u53d7\u76ca\uff0c\u5728\u5176\u80fd\u529b\u8fb9\u7f18\u5904\uff0c\u81ea\u9002\u5e94\u534f\u4f5c\u754c\u9762\u53ef\u4ee5\u4f5c\u4e3a\u63a8\u7406\u589e\u5f3a\u5668\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u4e0e\u4eba\u7c7b\u81ea\u7136\u7528\u4e8e\u95ee\u9898\u89e3\u51b3\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6743\u80fd\u591f\u63d0\u9ad8\u5b83\u4eec\u7684\u6027\u80fd\u3002\u4f7f\u7528\u57fa\u4e8eMCP\u7684\u793e\u4ea4\u5a92\u4f53\u548c\u65e5\u5fd7\u5de5\u5177\u88c5\u5907Claude Code\u4ee3\u7406\uff0c\u5e76\u5141\u8bb8\u4ed6\u4eec\u81ea\u884c\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u3002\u572834\u4e2aAider Polyglot Python\u7f16\u7a0b\u6311\u6218\u4e2d\uff0c\u534f\u4f5c\u5de5\u5177\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u56f0\u96be\u95ee\u9898\u7684\u8868\u73b0\uff0c\u4f7f\u5f97\u6210\u672c\u964d\u4f4e\u4e8615-40\uff05\uff0c\u56de\u5408\u6570\u51cf\u5c11\u4e8612-27\uff05\uff0c\u5b8c\u6210\u65f6\u95f4\u5feb\u4e8612-38\uff05\u3002\u5bf9\u6574\u4e2a\u6311\u6218\u96c6\u7684\u5f71\u54cd\u5219\u662f\u590d\u6742\u7684\uff0c\u8868\u660e\u5f53\u9700\u8981\u989d\u5916\u7684\u63a8\u7406\u652f\u6301\u65f6\uff0c\u8fd9\u4e9b\u5de5\u5177\u53ef\u4ee5\u4f5c\u4e3a\u6027\u80fd\u589e\u5f3a\u5242\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u4e0d\u540c\u7684\u6a21\u578b\u5728\u6ca1\u6709\u660e\u786e\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\u81ea\u7136\u91c7\u7528\u4e86\u4e0d\u540c\u7684\u534f\u4f5c\u7b56\u7565\u3002Sonnet 3.7\u5e7f\u6cdb\u4f7f\u7528\u5404\u79cd\u5de5\u5177\uff0c\u5e76\u53d7\u76ca\u4e8e\u57fa\u4e8e\u8868\u8fbe\u7684\u8ba4\u77e5\u652f\u67b6\u3002Sonnet 4\u8868\u73b0\u51fa\u9009\u62e9\u6027\u91c7\u7528\uff0c\u5728\u95ee\u9898\u771f\u6b63\u56f0\u96be\u65f6\uff0c\u4f9d\u9760\u57fa\u4e8e\u65e5\u5fd7\u7684\u8bed\u4e49\u641c\u7d22\u3002\u8fd9\u53cd\u6620\u4e86\u4eba\u7c7b\u5f00\u53d1\u8005\u6839\u636e\u4e13\u4e1a\u77e5\u8bc6\u548c\u4efb\u52a1\u590d\u6742\u6027\u8c03\u6574\u534f\u4f5c\u7684\u65b9\u5f0f\u3002\u884c\u4e3a\u5206\u6790\u663e\u793a\uff0c\u4ee3\u7406\u66f4\u504f\u5411\u4e8e\u5199\u4f5c\u800c\u975e\u9605\u8bfb\uff0c\u6bd4\u4f8b\u7ea6\u4e3a2-9\u500d\uff0c\u8fd9\u8868\u660e\u7ed3\u6784\u5316\u7684\u8868\u8fbe\u9a71\u52a8\u4e86\u6539\u8fdb\u7684\u5927\u90e8\u5206\u90e8\u5206\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4fe1\u606f\u8bbf\u95ee\u3002\u603b\u4f53\u800c\u8a00\uff0cAI\u4ee3\u7406\u53ef\u4ee5\u6709\u7cfb\u7edf\u5730\u4ece\u4eba\u7c7b\u542f\u53d1\u7684\u534f\u4f5c\u5de5\u5177\u4e2d\u53d7\u76ca\uff0c\u5c24\u5176\u662f\u5728\u5b83\u4eec\u80fd\u529b\u7684\u8fb9\u7f18\uff0c\u8fd9\u6307\u5411\u4e86\u81ea\u9002\u5e94\u534f\u4f5c\u754c\u9762\u4f5c\u4e3a\u63a8\u7406\u589e\u5f3a\u5668\u800c\u975e\u666e\u904d\u6548\u7387\u63d0\u5347\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.13570", "categories": ["cs.AI", "math.HO", "Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40"], "pdf": "https://arxiv.org/pdf/2509.13570", "abs": "https://arxiv.org/abs/2509.13570", "authors": ["Hannah Klawa", "Shraddha Rajpal", "Cigole Thomas"], "title": "Gen AI in Proof-based Math Courses: A Pilot Study", "comment": "35 pages, 6 figures, Comments welcome!", "summary": "With the rapid rise of generative AI in higher education and the\nunreliability of current AI detection tools, developing policies that encourage\nstudent learning and critical thinking has become increasingly important. This\nstudy examines student use and perceptions of generative AI across three\nproof-based undergraduate mathematics courses: a first-semester abstract\nalgebra course, a topology course and a second-semester abstract algebra\ncourse. In each case, course policy permitted some use of generative AI.\nDrawing on survey responses and student interviews, we analyze how students\nengaged with AI tools, their perceptions of generative AI's usefulness and\nlimitations, and what implications these perceptions hold for teaching\nproof-based mathematics. We conclude by discussing future considerations for\nintegrating generative AI into proof-based mathematics instruction.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u5b66\u751f\u5728\u4e09\u95e8\u57fa\u4e8e\u8bc1\u660e\u7684\u672c\u79d1\u6570\u5b66\u8bfe\u7a0b\u4e2d\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u4f7f\u7528\u548c\u611f\u77e5\uff0c\u8ba8\u8bba\u4e86\u5bf9\u6559\u5b66\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8\u672a\u6765\u5c06\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6574\u5408\u5230\u57fa\u4e8e\u8bc1\u660e\u7684\u6570\u5b66\u6559\u5b66\u4e2d\u7684\u76f8\u5173\u8003\u8651\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u5feb\u901f\u5d1b\u8d77\u4ee5\u53ca\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u68c0\u6d4b\u5de5\u5177\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u5236\u5b9a\u9f13\u52b1\u5b66\u751f\u5b66\u4e60\u548c\u6279\u5224\u6027\u601d\u7ef4\u7684\u653f\u7b56\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u548c\u5b66\u751f\u8bbf\u8c08\uff0c\u5206\u6790\u4e86\u5b66\u751f\u5728\u4e09\u95e8\u57fa\u4e8e\u8bc1\u660e\u7684\u672c\u79d1\u6570\u5b66\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u548c\u611f\u77e5\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5b66\u751f\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u7684\u4f7f\u7528\u65b9\u5f0f\u3001\u5176\u6709\u7528\u6027\u548c\u5c40\u9650\u6027\u7684\u611f\u77e5\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u611f\u77e5\u5bf9\u57fa\u4e8e\u8bc1\u660e\u7684\u6570\u5b66\u6559\u5b66\u7684\u6559\u5b66\u6709\u4f55\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u901a\u8fc7\u8c03\u67e5\u548c\u5b66\u751f\u8bbf\u8c08\u5206\u6790\u4e86\u5b66\u751f\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u7684\u4f7f\u7528\u548c\u611f\u77e5\uff0c\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u611f\u77e5\u5bf9\u4e8e\u6559\u6388\u57fa\u4e8e\u8bc1\u660e\u7684\u6570\u5b66\u8bfe\u7a0b\u7684\u6559\u5b66\u7684\u5f71\u54cd\u3002"}}
{"id": "2509.13588", "categories": ["cs.AI", "cs.CE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13588", "abs": "https://arxiv.org/abs/2509.13588", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "title": "Programmable Cognitive Bias in Social Agents", "comment": null, "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying\nagent behavior in LLM-based social simulation. We found that conventional\napproaches that specify agent behaviors through implicit natural language\ndescriptions cannot yield consistent behaviors across models, and the produced\nagent behaviors do not capture the nuances of the descriptions. In contrast,\nCoBRA presents a new approach to program agents' cognitive biases explicitly,\nby grounding agents' expected behaviors using classic social science\nexperiments. CoBRA has two components: (1) Cognitive Bias Index that measures\nthe cognitive bias of a social agent, by quantifying the agent's reactions in a\nset of validated classical social science experiments; (2) Behavioral\nRegulation Engine that aligns the agent's behavior to demonstrate controlled\ncognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and\ntechnical benchmarks. Our results suggest that CoBRA can precisely program the\ncognitive bias demonstrated in a social agent in a model-agnostic manner.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aCoBRA\u7684\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5728\u57fa\u4e8eLLM\u7684\u793e\u4f1a\u4eff\u771f\u4e2d\u7cfb\u7edf\u5730\u6307\u5b9a\u4ee3\u7406\u884c\u4e3a\u3002CoBRA\u901a\u8fc7\u91cf\u5316\u4ee3\u7406\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u5e76\u5229\u7528\u884c\u4e3a\u8c03\u8282\u5f15\u64ce\u5c06\u4ee3\u7406\u7684\u884c\u4e3a\u4e0e\u63a7\u5236\u7684\u8ba4\u77e5\u504f\u89c1\u76f8\u4e00\u81f4\u3002\u7814\u7a76\u53d1\u73b0\uff0cCoBRA\u80fd\u591f\u51c6\u786e\u5730\u7f16\u7a0b\u793e\u4f1a\u4ee3\u7406\u6240\u5c55\u793a\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u800c\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u6a21\u578b\u8fdb\u884c\u8c03\u6574\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u9690\u542b\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6307\u5b9a\u4ee3\u7406\u884c\u4e3a\uff0c\u4f46\u4e0d\u80fd\u5728\u6a21\u578b\u4e4b\u95f4\u4ea7\u751f\u4e00\u81f4\u7684\u884c\u4e3a\uff0c\u4e5f\u4e0d\u80fd\u6355\u6349\u63cf\u8ff0\u7684\u5fae\u5999\u4e4b\u5904\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86CoBRA\u6765\u660e\u786e\u5730\u7a0b\u5e8f\u5316\u4ee3\u7406\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u4ee5\u521b\u9020\u4e00\u81f4\u4e14\u7cbe\u7ec6\u7684\u4ee3\u7406\u884c\u4e3a\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86CoBRA\u5de5\u5177\u5305\uff0c\u901a\u8fc7\u57fa\u4e8e\u7ecf\u5178\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u91cf\u5316\u4ee3\u7406\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u5e76\u5229\u7528\u884c\u4e3a\u8c03\u8282\u5f15\u64ce\u5c06\u4ee3\u7406\u7684\u884c\u4e3a\u4e0e\u63a7\u5236\u7684\u8ba4\u77e5\u504f\u89c1\u76f8\u4e00\u81f4\u3002", "result": "\u901a\u8fc7\u6f14\u793a\u548c\u6280\u672f\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f5c\u8005\u8bc4\u4f30\u4e86CoBRA\u4f5c\u4e3a\u4e00\u4e2a\u4eba\u673a\u4ea4\u4e92\u5de5\u5177\u5305\u7684\u6027\u80fd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cCoBRA\u80fd\u591f\u5728\u6a21\u578b\u65e0\u5173\u7684\u60c5\u51b5\u4e0b\u51c6\u786e\u5730\u7f16\u7a0b\u793e\u4f1a\u4ee3\u7406\u6240\u5c55\u793a\u7684\u8ba4\u77e5\u504f\u89c1\u3002", "conclusion": "CoBRA\u662f\u4e00\u79cd\u65b0\u578b\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u7cfb\u7edf\u5730\u5728\u57fa\u4e8eLLM\u7684\u793e\u4f1a\u4eff\u771f\u4e2d\u6307\u5b9a\u4ee3\u7406\u884c\u4e3a\u3002\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0cCoBRA\u53ef\u4ee5\u51c6\u786e\u5730\u7f16\u7a0b\u6a21\u578b\u4e2d\u4ee3\u7406\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u800c\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u6a21\u578b\u8fdb\u884c\u8c03\u6574\u3002"}}
{"id": "2509.13615", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13615", "abs": "https://arxiv.org/abs/2509.13615", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "comment": null, "summary": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u72b6\u6001\u63a7\u5236\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u4ee3\u7406\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002\u63d0\u51fa\u4e86State-aware Reasoning (StaR)\u65b9\u6cd5\uff0c\u6559\u5bfc\u4ee3\u7406\u611f\u77e5\u548c\u6267\u884c\u5207\u6362\u6307\u4ee4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6267\u884c\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8bc1\u660eStaR\u8fd8\u80fd\u589e\u5f3a\u4e00\u822c\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u591a\u6a21\u6001\u4ee3\u7406\u5728\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u4e2d\u53d1\u6325\u4f5c\u7528\uff0c\u4f46\u6267\u884c\u5207\u6362\u63a7\u5236\u6307\u4ee4\u65f6\u5b58\u5728\u53ef\u9760\u6027\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u901a\u8fc7\u6784\u5efa\u72b6\u6001\u63a7\u5236\u57fa\u51c6\u5e76\u63d0\u51faStaR\u65b9\u6cd5\uff0c\u6559\u5bfc\u4ee3\u7406\u611f\u77e5\u548c\u6267\u884c\u5207\u6362\u6307\u4ee4\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5177\u6709\u4e8c\u5143\u5207\u6362\u6307\u4ee4\u7684\u72b6\u6001\u63a7\u5236\u57fa\u51c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u4ee3\u7406\u7684\u53ef\u9760\u6027\u3002\u63d0\u51fa\u4e86State-aware Reasoning (StaR)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6559\u5bfc\u4ee3\u7406\u611f\u77e5\u5f53\u524d\u5207\u6362\u72b6\u6001\u3001\u5206\u6790\u6307\u4ee4\u4e2d\u7684\u671f\u671b\u72b6\u6001\u5e76\u76f8\u5e94\u884c\u52a8\u3002\u5bf9\u4e09\u4e2a\u591a\u6a21\u6001\u4ee3\u7406\u8fdb\u884c\u5b9e\u9a8c\u8868\u660e\uff0cStaR\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u6027\u63d0\u9ad8\u8d85\u8fc730%\u3002\u8fdb\u4e00\u6b65\u8bc4\u4f30\u8868\u660e\uff0cStaR\u8fd8\u589e\u5f3a\u4e86\u4e00\u822c\u4efb\u52a1\u6027\u80fd\u3002\u5728\u52a8\u6001\u73af\u5883\u7684\u8bc4\u4f30\u5f3a\u8c03\u4e86StaR\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "result": "StaR\u65b9\u6cd5\u80fd\u591f\u6539\u5584\u591a\u6a21\u6001\u4ee3\u7406\u5728\u6267\u884c\u5207\u6362\u6307\u4ee4\u65f6\u7684\u51c6\u786e\u6027\uff0c\u5e76\u63d0\u5347\u4e00\u822c\u4efb\u52a1\u6027\u80fd\u3002\u540c\u65f6\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u663e\u793a\u51fa\u6f5c\u5728\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51faState-aware Reasoning (StaR)\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u591a\u6a21\u6001\u4ee3\u7406\u611f\u77e5\u5f53\u524d\u7684\u5207\u6362\u72b6\u6001\uff0c\u5206\u6790\u6307\u4ee4\u4e2d\u7684\u671f\u671b\u72b6\u6001\uff0c\u5e76\u636e\u6b64\u91c7\u53d6\u884c\u52a8\uff0c\u4ece\u800c\u6539\u5584\u4e86\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u6027\u8d85\u8fc730%\u3002\u540c\u65f6\uff0cStaR\u65b9\u6cd5\u5728\u4e00\u822c\u4efb\u52a1\u6027\u80fd\u4e0a\u4e5f\u8868\u73b0\u51fa\u6539\u5584\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793aStaR\u5bf9\u52a8\u6001\u73af\u5883\u5177\u6709\u6f5c\u5728\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.13704", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13704", "abs": "https://arxiv.org/abs/2509.13704", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "comment": null, "summary": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u5de5\u4e1a\u7ba1\u7406\u7cfb\u7edf\u7684\u65b0GUI\u6846\u67b6InfraMind\uff0c\u901a\u8fc7\u4e94\u4e2a\u521b\u65b0\u6a21\u5757\u89e3\u51b3\u7cfb\u7edf\u590d\u6742\u6027\u3001\u81ea\u52a8\u5316\u4e0d\u8db3\u3001\u90e8\u7f72\u7ea6\u675f\u548c\u5b89\u5168\u9700\u6c42\u7b49\u4e94\u5927\u6311\u6218\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cInfraMind\u5728\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u9488\u5bf9\u5de5\u4e1a\u7ba1\u7406\u7cfb\u7edf\u4e2d\u7684\u590d\u6742\u6027\u3001\u81ea\u52a8\u5316\u80fd\u529b\u4e0d\u8db3\u3001\u90e8\u7f72\u7ea6\u675f\u548c\u5b89\u5168\u9700\u6c42\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u4e86InfraMind\u6846\u67b6\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u540c\u65f6\u63d0\u9ad8\u5de5\u4f5c\u6548\u7387\u548c\u4efb\u52a1\u6210\u529f\u7387\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u7684InfraMind\u6846\u67b6\uff0c\u6574\u5408\u4e86\u4e94\u4e2a\u521b\u65b0\u6a21\u5757\uff1a\u57fa\u4e8e\u865a\u62df\u673a\u5feb\u7167\u7684\u7cfb\u7edf\u641c\u7d22\u63a2\u7d22\u3001\u5185\u5b58\u9a71\u52a8\u89c4\u5212\u3001\u9ad8\u7ea7\u72b6\u6001\u8bc6\u522b\u3001\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u548c\u5168\u9762\u7684\u591a\u5c42\u5b89\u5168\u673a\u5236\uff0c\u4ee5\u89e3\u51b3\u5de5\u4e1a\u7ba1\u7406\u4e2d\u9762\u4e34\u7684\u4e94\u5927\u6311\u6218\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\uff0cInfraMind\u6846\u67b6\u5728\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u6bd4\u73b0\u6709\u6846\u67b6\u5177\u6709\u66f4\u9ad8\u7684\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5de5\u4e1a\u7ba1\u7406\u7cfb\u7edf\u7684\u65b0\u7684GUI\u667a\u80fd\u6846\u67b6InfraMind\uff0c\u901a\u8fc7\u6574\u5408\u4e94\u4e2a\u521b\u65b0\u6a21\u5757\u89e3\u51b3\u5de5\u4e1a\u7ba1\u7406\u4e2d\u7684\u5404\u79cd\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u7684\u63d0\u5347\u3002\u5728\u5f00\u6e90\u548c\u5546\u4e1aDCIM\u5e73\u53f0\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u4e25\u683c\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13761", "abs": "https://arxiv.org/abs/2509.13761", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "comment": "22 pages, 13 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "AI": {"tldr": "THOR proposes a method to integrate external tools for high-precision tasks, addressing challenges in data construction, optimization, and inference. It achieves strong generalization, state-of-the-art performance on mathematical benchmarks, and consistent improvements on code benchmarks.", "motivation": "Existing methods struggle with constructing tool-integrated reasoning data, fine-grained optimization, and enhancing inference. Integrating external tools is a promising approach to enhancing LLMs' performance on high-precision tasks like numerical computation and formal symbolic manipulation.", "method": "Propose THOR (Tool-Integrated Hierarchical Optimization via RL) to address challenges in integrating external tools for high-precision tasks. Introduce TIRGen for constructing high-quality datasets, RL strategy for fine-grained hierarchical optimization, and self-correction mechanism for dynamic path revision during inference.", "result": "THOR achieves strong generalization, state-of-the-art performance on mathematical benchmarks, and consistent improvements on code benchmarks.", "conclusion": "THOR demonstrates strong generalization across diverse models, achieving state-of-the-art performance on mathematical benchmarks and consistent improvements on code benchmarks."}}
{"id": "2509.13773", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13773", "abs": "https://arxiv.org/abs/2509.13773", "authors": ["Zhipeng Bian", "Jieming Zhu", "Xuyang Xie", "Quanyu Dai", "Zhou Zhao", "Zhenhua Dong"], "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 6: Industry Track), ACL\n  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103", "summary": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "AI": {"tldr": "The paper introduces MIRA, a framework for intuitive AI tasking on smartphones, leveraging advanced AI technologies to enhance instruction recommendation accuracy and user experience.", "motivation": "To simplify access to predefined AI services on smartphones and enable intuitive one-touch AI tasking, transforming the user interaction with devices.", "method": "Introduces MIRA framework for task instruction recommendation using a multimodal large language model-based recommendation pipeline with structured reasoning, template-augmented reasoning mechanism, and prefix-tree-based constrained decoding strategy.", "result": "Demonstrated significant improvements in instruction recommendation accuracy through evaluation with real-world annotated datasets and user study.", "conclusion": "MIRA framework shows substantial improvements in the accuracy of instruction recommendation, revolutionizing the user interaction with AI services on smartphones."}}
{"id": "2509.13880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13880", "abs": "https://arxiv.org/abs/2509.13880", "authors": ["Mingwei Zhang", "Zhenhao Gu", "Liangda Fang", "Cunjing Ge", "Ziliang Chen", "Zhao-Rong Lai", "Quanlong Guan"], "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "comment": null, "summary": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u7684MCILC\u65b9\u6cd5\uff0c\u91c7\u7528\u7a77\u4e3eDPLL\u67b6\u6784\uff0c\u5e76\u96c6\u6210\u4e86\u6df7\u5408\u6574\u6570\u89c4\u5212\u7684\u7b80\u5316\u6280\u672f\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u968f\u673a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8868\u73b0\u4f18\u79c0\uff0c\u4f18\u4e8e\u6240\u6709\u5176\u4ed6\u7cbe\u786e\u65b9\u6cd5\uff0c\u5e76\u4e14\u662f\u552f\u4e00\u80fd\u89e3\u51b3\u6240\u6709\u5e94\u7528\u5b9e\u4f8b\u7684\u65b9\u6cd5\u3002", "motivation": "\u7ebf\u6027\u7ea6\u675f\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u8fd0\u7b79\u5b66\u548c\u4f18\u5316\u7b49\u9886\u57df\u4e2d\u6700\u57fa\u672c\u7684\u7ea6\u675f\u4e4b\u4e00\u3002\u8bb8\u591a\u5e94\u7528\u90fd\u53ef\u4ee5\u5f52\u7ed3\u4e3a\u5728\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u4e0a\u8fdb\u884c\u6a21\u578b\u8ba1\u6570\u7684\u4efb\u52a1\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7cbe\u786e\u7684MCILC\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7a77\u4e3eDPLL\u67b6\u6784\uff0c\u5e76\u96c6\u6210\u4e86\u591a\u79cd\u6df7\u5408\u6574\u6570\u89c4\u5212\u7684\u6709\u6548\u7b80\u5316\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u672c\u6587\u65b9\u6cd5\u5728\u968f\u673a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u660e\u663e\u4f18\u4e8e\u6240\u6709\u7cbe\u786e\u65b9\u6cd5\uff0c\u5e76\u4e14\u662f\u552f\u4e00\u89e3\u51b3\u4e86\u6240\u6709\u5e94\u7528\u5b9e\u4f8b\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a77\u4e3eDPLL\u67b6\u6784\u7684\u7cbe\u786eMCILC\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5c06\u591a\u79cd\u6df7\u5408\u6574\u6570\u89c4\u5212\u7684\u6709\u6548\u7b80\u5316\u6280\u672f\u96c6\u6210\u5230\u67b6\u6784\u4e2d\u6765\u63d0\u9ad8\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u968f\u673a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u660e\u663e\u4f18\u4e8e\u6240\u6709\u7cbe\u786e\u65b9\u6cd5\uff0c\u5728\u89e3\u51b31718\u4e2a\u5b9e\u4f8b\uff0c\u800c\u76ee\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u53ea\u8ba1\u7b97\u4e861470\u4e2a\u5b9e\u4f8b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u662f\u552f\u4e00\u89e3\u51b3\u4e86\u6240\u67094131\u4e2a\u5e94\u7528\u5b9e\u4f8b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.13968", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13968", "abs": "https://arxiv.org/abs/2509.13968", "authors": ["Konstantinos Voudouris", "Andrew Barron", "Marta Halina", "Colin Klein", "Matishalin Patel"], "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "comment": null, "summary": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u4e86\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u53d1\u73b0\u4fe1\u606f\u6d41\u7684\u6539\u53d8\u53ef\u4ee5\u5bfc\u81f4\u8ba4\u77e5\u6027\u80fd\u7684\u8f6c\u53d8\u3002\u5faa\u73af\u7f51\u7edc\u5728\u5904\u7406\u4e0d\u540c\u8f93\u5165\u7c7b\u578b\u548c\u5b66\u4e60\u590d\u6742\u8bed\u6cd5\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8bad\u7ec3\u56f0\u96be\u53ef\u80fd\u4f1a\u963b\u788d\u6027\u80fd\u63d0\u5347\u3002\u603b\u4f53\u800c\u8a00\uff0c\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u4fe1\u606f\u6d41\u53d8\u5316\u5bf9\u8ba4\u77e5\u6027\u80fd\u8f6c\u53d8\u7684\u5f71\u54cd\u3002", "motivation": "\u6700\u8fd1\u7684\u7814\u7a76\u63d0\u51fa\u8ba4\u77e5\u4e5f\u53ef\u80fd\u7ecf\u5386\u4e00\u7cfb\u5217\u91cd\u8981\u8f6c\u53d8\uff0c\u6539\u53d8\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u5f71\u54cd\u4fe1\u606f\u6d41\u52a8\uff0c\u672c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u8fd9\u4e00\u89c2\u70b9\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u7406\u60f3\u5316\u7684\u4fe1\u606f\u6d41\u6a21\u578b\uff0c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANNs\uff09\uff0c\u6bd4\u8f83\u4e86\u5177\u6709\u524d\u9988\u3001\u5faa\u73af\u548c\u5c42\u72b6\u62d3\u6251\u7ed3\u6784\u7684\u7f51\u7edc\uff0c\u5728\u5b66\u4e60\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u4eba\u5de5\u8bed\u6cd5\u65f6\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5faa\u73af\u7f51\u7edc\u76f8\u5bf9\u4e8e\u524d\u5411\u7f51\u7edc\u80fd\u5904\u7406\u66f4\u591a\u7c7b\u578b\u7684\u8f93\u5165\uff0c\u5e76\u5728\u5b66\u4e60\u6700\u590d\u6742\u8bed\u6cd5\u65f6\u8868\u73b0\u66f4\u597d\u3002\u6b64\u5916\uff0c\u5faa\u73af\u7f51\u7edc\u8bad\u7ec3\u7684\u56f0\u96be\u9020\u6210\u4e86\u8f6c\u53d8\u969c\u788d\u4e0e\u6709\u6761\u4ef6\u7684\u4e0d\u53ef\u9006\u6027\uff0c\u4e5f\u5c55\u793a\u4e86\u4fe1\u606f\u6d41\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u8ba4\u77e5\u6027\u80fd\u7684\u8f6c\u53d8\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u4fe1\u606f\u6d41\u7684\u53d8\u5316\u53ef\u4ee5\u5bfc\u81f4\u8ba4\u77e5\u6027\u80fd\u7684\u8f6c\u53d8\uff0c\u900f\u8fc7\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u89c2\u70b9\u3002"}}
{"id": "2509.14030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14030", "abs": "https://arxiv.org/abs/2509.14030", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "comment": null, "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "AI": {"tldr": "CrowdAgent is a system that manages diverse annotation sources in NLP tasks effectively by integrating LLMs, SLMs, and human experts. It provides end-to-end process control through rational task assignment, demonstrated through experiments on multimodal classification tasks.", "motivation": "The motivation is to address the critical gap in managing diverse annotation sources effectively by providing holistic process control in NLP tasks. The paper aims to fill the gap in handling complex scheduling and quality-cost trade-offs in an integrated manner inspired by crowdsourcing companies.", "method": "Introduces CrowdAgent, a system inspired by real-world crowdsourcing companies, that integrates task assignment, data annotation, and quality/cost management. It implements a methodology for rational task assignment to enable LLMs, SLMs, and human experts to work collaboratively in an annotation workflow.", "result": "The paper demonstrates the effectiveness of CrowdAgent through experiments on six multimodal classification tasks, showcasing the benefits of synergistic collaboration among different annotation sources.", "conclusion": "CrowdAgent is a multi-agent system that provides end-to-end process control for managing diverse annotation sources in NLP tasks effectively. It demonstrates the effectiveness of integrating LLMs, SLMs, and human experts in a collaborative workflow through extensive experiments on multimodal classification tasks."}}
{"id": "2509.14195", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14195", "abs": "https://arxiv.org/abs/2509.14195", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "comment": "8 pages, 3 figures", "summary": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u7b2c\u4e8c\u9636\u5b66\u4e60\u5728\u53d1\u5c55\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5185\u90e8\u5fc3\u7406\u5730\u56fe\u65f6\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u4e86\u4f7f\u7528GCN\u548cMLP controller\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u5728\u672a\u89c1\u8fc7\u7684\u8ff7\u5bab\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6cdb\u5316\u548c\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u7814\u7a76\u8005\u8bd5\u56fe\u901a\u8fc7\u9a8c\u8bc1\u73b0\u6709\u7406\u8bba\u4e2d\u5173\u4e8e\u7b2c\u4e8c\u9636\u5b66\u4e60\u5bf9\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u6027\u4ea7\u751f\u4f5c\u7528\u7684\u5047\u8bbe\uff0c\u6765\u9a8c\u8bc1\u5fc3\u7406\u8868\u5f81\u7684\u91cd\u8981\u6027\u3002", "method": "\u91c7\u7528\u4e86Hierarchical Architecture\uff0c\u7ed3\u5408\u4e86Graph Convolutional Network (GCN)\u548cMLP controller\uff0cGCN\u7528\u4e8e\u7b2c\u4e00\u9636\u5b66\u4e60\u76f4\u63a5\u6620\u5c04\u8282\u70b9\u7ea7\u7279\u5f81\u5230\u6700\u4f73\u5bfc\u822a\u8def\u5f84\u7684\u9884\u6d4b\uff0c\u800cMLP\u5728\u9762\u5bf9\u7ed3\u6784\u65b0\u9896\u7684\u8ff7\u5bab\u73af\u5883\u65f6\u52a8\u6001\u8c03\u6574GCN\u7684\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u7b2c\u4e8c\u9636\u5b66\u4e60\u5728\u53d1\u5c55\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u5185\u90e8\u5fc3\u7406\u5730\u56fe\u65f6\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u672a\u89c1\u8fc7\u7684\u8ff7\u5bab\u4efb\u52a1\u4e2d\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u7b2c\u4e8c\u9636\u5b66\u4e60\u5bf9\u4e8e\u53d1\u5c55\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5185\u90e8\u5fc3\u7406\u5730\u56fe\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u5728\u672a\u89c1\u8fc7\u7684\u8ff7\u5bab\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9c81\u68d2\u6cdb\u5316\u3002"}}
