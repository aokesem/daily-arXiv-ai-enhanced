{"id": "2508.03858", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.03858", "abs": "https://arxiv.org/abs/2508.03858", "authors": ["Charles L. Wang", "Trisha Singhal", "Ameya Kelkar", "Jason Tuo"], "title": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems", "comment": null, "summary": "Agentic AI systems capable of reasoning, planning, and executing actions\npresent fundamentally distinct governance challenges compared to traditional AI\nmodels. Unlike conventional AI, these systems exhibit emergent and unexpected\nbehaviors during runtime, introducing novel agent-related risks that cannot be\nfully anticipated through pre-deployment governance alone. To address this\ncritical gap, we introduce MI9, the first fully integrated runtime governance\nframework designed specifically for safety and alignment of agentic AI systems.\nMI9 introduces real-time controls through six integrated components:\nagency-risk index, agent-semantic telemetry capture, continuous authorization\nmonitoring, Finite-State-Machine (FSM)-based conformance engines,\ngoal-conditioned drift detection, and graduated containment strategies.\nOperating transparently across heterogeneous agent architectures, MI9 enables\nthe systematic, safe, and responsible deployment of agentic systems in\nproduction environments where conventional governance approaches fall short,\nproviding the foundational infrastructure for safe agentic AI deployment at\nscale. Detailed analysis through a diverse set of scenarios demonstrates MI9's\nsystematic coverage of governance challenges that existing approaches fail to\naddress, establishing the technical foundation for comprehensive agentic AI\noversight.", "AI": {"tldr": "MI9\u662f\u4e3a\u5b89\u5168\u548c\u5bf9\u9f50\u6027\u800c\u8bbe\u8ba1\u7684\u7b2c\u4e00\u4e2a\u5b8c\u5168\u96c6\u6210\u7684\u8fd0\u884c\u65f6\u6cbb\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u516d\u4e2a\u96c6\u6210\u7ec4\u4ef6\u63d0\u4f9b\u5b9e\u65f6\u63a7\u5236\uff0c\u80fd\u591f\u89e3\u51b3\u673a\u6784\u578b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u6cbb\u7406\u6311\u6218\u3002", "motivation": "\u4f20\u7edfAI\u6a21\u578b\u4e0e\u673a\u6784\u578b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u6cbb\u7406\u6311\u6218\u4e0a\u5b58\u5728\u6839\u672c\u533a\u522b\uff0c\u673a\u6784\u578b\u7cfb\u7edf\u5728\u8fd0\u884c\u65f6\u5c55\u73b0\u51fa\u65b0\u5174\u548c\u610f\u5916\u884c\u4e3a\uff0c\u5f15\u5165\u4e86\u65e0\u6cd5\u5b8c\u5168\u9884\u6599\u7684\u4ee3\u7406\u76f8\u5173\u98ce\u9669\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u5dee\u8ddd\uff0c\u4f5c\u8005\u5f15\u5165MI9\uff0c\u65e8\u5728\u4e3a\u673a\u6784\u578b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u5bf9\u9f50\u6027\u63d0\u4f9b\u8fd0\u884c\u65f6\u6cbb\u7406\u6846\u67b6\u3002", "method": "MI9\u5f15\u5165\u4e86\u516d\u4e2a\u96c6\u6210\u7ec4\u4ef6\uff1a\u4ee3\u7406\u98ce\u9669\u6307\u6570\u3001\u4ee3\u7406-\u8bed\u4e49\u9065\u6d4b\u6355\u83b7\u3001\u6301\u7eed\u6388\u6743\u76d1\u63a7\u3001\u57fa\u4e8e\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u7684\u7b26\u5408\u5f15\u64ce\u3001\u76ee\u6807\u6761\u4ef6\u6f02\u79fb\u68c0\u6d4b\u4ee5\u53ca\u6e10\u8fdb\u5f0f\u904f\u5236\u7b56\u7565\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u4f7fMI9\u80fd\u591f\u5728\u5f02\u6784\u7684\u4ee3\u7406\u4f53\u7cfb\u7ed3\u6784\u4e2d\u900f\u660e\u8fd0\u884c\uff0c\u4e3a\u673a\u6784\u578b\u7cfb\u7edf\u7684\u90e8\u7f72\u63d0\u4f9b\u5b9e\u65f6\u63a7\u5236\u3002", "result": "MI9\u7684\u8be6\u7ec6\u5206\u6790\u8868\u660e\u4e86\u5176\u7cfb\u7edf\u6027\u8986\u76d6\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u7684\u6cbb\u7406\u6311\u6218\uff0c\u4e3a\u5168\u9762\u7684\u673a\u6784\u578b\u4eba\u5de5\u667a\u80fd\u76d1\u7763\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002", "conclusion": "MI9\u662f\u9996\u4e2a\u4e13\u4e3a\u5b89\u5168\u548c\u5bf9\u9f50\u6027\u800c\u8bbe\u8ba1\u7684\u5b8c\u5168\u96c6\u6210\u7684\u8fd0\u884c\u65f6\u6cbb\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u516d\u4e2a\u96c6\u6210\u7ec4\u4ef6\u63d0\u4f9b\u5b9e\u65f6\u63a7\u5236\uff0c\u4e3a\u673a\u6784\u578b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u3001\u5b89\u5168\u6027\u548c\u8d23\u4efb\u6027\u90e8\u7f72\u63d0\u4f9b\u57fa\u7840\u8bbe\u65bd\u3002MI9\u901a\u8fc7\u591a\u6837\u5316\u7684\u573a\u666f\u8be6\u7ec6\u5206\u6790\u5c55\u793a\u4e86\u5bf9\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u7684\u6cbb\u7406\u6311\u6218\u7684\u7cfb\u7edf\u5316\u8986\u76d6\uff0c\u4e3a\u5168\u9762\u7684\u673a\u6784\u578b\u4eba\u5de5\u667a\u80fd\u76d1\u7763\u5960\u5b9a\u4e86\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2508.03864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03864", "abs": "https://arxiv.org/abs/2508.03864", "authors": ["Zhenyu Pan", "Yiting Zhang", "Yutong Zhang", "Jianshu Zhang", "Haozheng Luo", "Yuwei Han", "Dennis Wu", "Hong-Yu Chen", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety", "comment": null, "summary": "Multi-agent systems (MAS) built on multimodal large language models exhibit\nstrong collaboration and performance. However, their growing openness and\ninteraction complexity pose serious risks, notably jailbreak and adversarial\nattacks. Existing defenses typically rely on external guard modules, such as\ndedicated safety agents, to handle unsafe behaviors. Unfortunately, this\nparadigm faces two challenges: (1) standalone agents offer limited protection,\nand (2) their independence leads to single-point failure-if compromised,\nsystem-wide safety collapses. Naively increasing the number of guard agents\nfurther raises cost and complexity. To address these challenges, we propose\nEvo-MARL, a novel multi-agent reinforcement learning (MARL) framework that\nenables all task agents to jointly acquire defensive capabilities. Rather than\nrelying on external safety modules, Evo-MARL trains each agent to\nsimultaneously perform its primary function and resist adversarial threats,\nensuring robustness without increasing system overhead or single-node failure.\nFurthermore, Evo-MARL integrates evolutionary search with parameter-sharing\nreinforcement learning to co-evolve attackers and defenders. This adversarial\ntraining paradigm internalizes safety mechanisms and continually enhances MAS\nperformance under co-evolving threats. Experiments show that Evo-MARL reduces\nattack success rates by up to 22% while boosting accuracy by up to 5% on\nreasoning tasks-demonstrating that safety and utility can be jointly improved.", "AI": {"tldr": "Evo-MARL is a novel multi-agent reinforcement learning framework that addresses the limitations of existing defenses in multimodal large language model-based multi-agent systems (MAS). It trains agents to defend against adversarial threats while performing their primary functions, reducing attack success rates and improving accuracy on reasoning tasks. The framework integrates evolutionary search with reinforcement learning to enhance MAS performance under evolving threats, effectively improving safety and utility in MAS.", "motivation": "The growing openness and interaction complexity of multimodal large language model-based MAS pose serious risks such as jailbreak and adversarial attacks. Existing defenses relying on external guard modules face challenges of limited protection and single-point failure. Naively increasing guard agents raises cost and complexity. The paper aims to address these challenges by introducing Evo-MARL to improve safety and utility in MAS.", "method": "The paper proposes Evo-MARL, a multi-agent reinforcement learning framework that trains each agent to perform its primary function and resist adversarial threats simultaneously. It integrates evolutionary search with parameter-sharing reinforcement learning to co-evolve attackers and defenders, internalizing safety mechanisms and enhancing MAS performance under evolving threats.", "result": "Experiments demonstrate that Evo-MARL reduces attack success rates by up to 22% and increases accuracy by up to 5% on reasoning tasks, showing the effectiveness of the framework in improving both safety and utility in MAS.", "conclusion": "Evo-MARL is proposed as a novel multi-agent reinforcement learning framework to address the challenges of existing defenses in multi-agent systems (MAS) built on multimodal large language models. It enables all task agents to jointly acquire defensive capabilities, reduces attack success rates, and boosts accuracy on reasoning tasks."}}
{"id": "2508.03929", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03929", "abs": "https://arxiv.org/abs/2508.03929", "authors": ["Nguyen Viet Tuan Kiet", "Dao Van Tung", "Tran Cong Dao", "Huynh Thi Thanh Binh"], "title": "MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework", "comment": "24 pages, 4 figures", "summary": "Designing effective algorithmic components remains a fundamental obstacle in\ntackling NP-hard combinatorial optimization problems (COPs), where solvers\noften rely on carefully hand-crafted strategies. Despite recent advances in\nusing large language models (LLMs) to synthesize high-quality components, most\napproaches restrict the search to a single element - commonly a heuristic\nscoring function - thus missing broader opportunities for innovation. In this\npaper, we introduce a broader formulation of solver design as a multi-strategy\noptimization problem, which seeks to jointly improve a set of interdependent\ncomponents under a unified objective. To address this, we propose\nMulti-strategy Optimization via Turn-based Interactive Framework (MOTIF) - a\nnovel framework based on Monte Carlo Tree Search that facilitates turn-based\noptimization between two LLM agents. At each turn, an agent improves one\ncomponent by leveraging the history of both its own and its opponent's prior\nupdates, promoting both competitive pressure and emergent cooperation. This\nstructured interaction broadens the search landscape and encourages the\ndiscovery of diverse, high-performing solutions. Experiments across multiple\nCOP domains show that MOTIF consistently outperforms state-of-the-art methods,\nhighlighting the promise of turn-based, multi-agent prompting for fully\nautomated solver design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86MOTIF\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u4f18\u5316\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u95f4\u7684\u6c42\u89e3\u5668\u8bbe\u8ba1\uff0c\u62d3\u5c55\u4e86\u641c\u7d22\u7a7a\u95f4\uff0c\u9f13\u52b1\u53d1\u73b0\u591a\u6837\u5316\u3001\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b9e\u9a8c\u8bc1\u660eMOTIF\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u56de\u5408\u5236\u3001\u591a\u4ee3\u7406\u63d0\u793a\u7684\u5b8c\u5168\u81ea\u52a8\u5316\u6c42\u89e3\u5668\u8bbe\u8ba1\u7684\u524d\u666f\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5408\u6210\u9ad8\u8d28\u91cf\u7ec4\u4ef6\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5927\u591a\u6570\u65b9\u6cd5\u9650\u5236\u641c\u7d22\u5230\u4e00\u4e2a\u5143\u7d20\uff0c\u5bfc\u81f4\u9519\u5931\u521b\u65b0\u673a\u4f1a\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u66f4\u5e7f\u6cdb\u7684\u6c42\u89e3\u5668\u8bbe\u8ba1\u5f62\u5f0f\uff0c\u81f4\u529b\u4e8e\u7edf\u4e00\u76ee\u6807\u4e0b\u6539\u8fdb\u4e00\u7ec4\u76f8\u4e92\u4f9d\u8d56\u7684\u7ec4\u4ef6\u3002", "method": "\u8be5\u8bba\u6587\u5c06\u6c42\u89e3\u5668\u8bbe\u8ba1\u89c6\u4e3a\u591a\u7b56\u7565\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86MOTIF\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4fc3\u8fdb\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f18\u5316\u3002\u6bcf\u8f6e\u4e2d\uff0c\u4e00\u4e2a\u4ee3\u7406\u6539\u8fdb\u4e00\u4e2a\u7ec4\u4ef6\uff0c\u5229\u7528\u81ea\u8eab\u548c\u5bf9\u624b\u5148\u524d\u66f4\u65b0\u7684\u5386\u53f2\uff0c\u4fc3\u8fdb\u7ade\u4e89\u538b\u529b\u548c\u65b0\u5174\u5408\u4f5c\u3002\u8fd9\u79cd\u7ed3\u6784\u5316\u4e92\u52a8\u62d3\u5c55\u4e86\u641c\u7d22\u7a7a\u95f4\uff0c\u9f13\u52b1\u53d1\u73b0\u591a\u6837\u5316\u7684\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u591a\u4e2a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u9886\u57df\u7684\u5b9e\u9a8c\u663e\u793a\uff0cMOTIF\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7a81\u51fa\u4e86\u57fa\u4e8e\u56de\u5408\u5236\u3001\u591a\u4ee3\u7406\u63d0\u793a\u7684\u5168\u81ea\u52a8\u5316\u6c42\u89e3\u5668\u8bbe\u8ba1\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMOTIF\u7684\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u4f18\u5316\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e4b\u95f4\u7684\u6c42\u89e3\u5668\u8bbe\u8ba1\uff0c\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u62d3\u5c55\u4e86\u6c42\u89e3\u5668\u8bbe\u8ba1\u7684\u8303\u56f4\uff0c\u9f13\u52b1\u53d1\u73b0\u591a\u6837\u5316\u4e14\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u73b0\u4e86\u57fa\u4e8e\u56de\u5408\u5236\u7684\u591a\u4ee3\u7406\u63d0\u793a\u5728\u5b8c\u5168\u81ea\u52a8\u5316\u6c42\u89e3\u5668\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.03963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03963", "abs": "https://arxiv.org/abs/2508.03963", "authors": ["Zewen Liu", "Juntong Ni", "Xianfeng Tang", "Max S. Y. Lau", "Wei Jin"], "title": "Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?", "comment": null, "summary": "Uncovering hidden symbolic laws from time series data, as an aspiration\ndating back to Kepler's discovery of planetary motion, remains a core challenge\nin scientific discovery and artificial intelligence. While Large Language\nModels show promise in structured reasoning tasks, their ability to infer\ninterpretable, context-aligned symbolic structures from time series data is\nstill underexplored. To systematically evaluate this capability, we introduce\nSymbolBench, a comprehensive benchmark designed to assess symbolic reasoning\nover real-world time series across three tasks: multivariate symbolic\nregression, Boolean network inference, and causal discovery. Unlike prior\nefforts limited to simple algebraic equations, SymbolBench spans a diverse set\nof symbolic forms with varying complexity. We further propose a unified\nframework that integrates LLMs with genetic programming to form a closed-loop\nsymbolic reasoning system, where LLMs act both as predictors and evaluators.\nOur empirical results reveal key strengths and limitations of current models,\nhighlighting the importance of combining domain knowledge, context alignment,\nand reasoning structure to improve LLMs in automated scientific discovery.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SymbolBench\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30LLMs\u5728\u7b26\u53f7\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002\u63d0\u51fa\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408LLMs\u548c\u9057\u4f20\u7f16\u7a0b\u5f62\u6210\u95ed\u73af\u7b26\u53f7\u63a8\u7406\u7cfb\u7edf\u3002\u5b9e\u8bc1\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u4f18\u52bf\u548c\u9650\u5236\uff0c\u5f3a\u8c03\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3001\u4e0a\u4e0b\u6587\u5bf9\u9f50\u548c\u63a8\u7406\u7ed3\u6784\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u6539\u8fdbLLMs\u5728\u81ea\u52a8\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u7cfb\u7edf\u8bc4\u4f30LLMs\u4ece\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u63a8\u7406\u53ef\u89e3\u91ca\u7684\u3001\u4e0e\u4e0a\u4e0b\u6587\u5bf9\u9f50\u7684\u7b26\u53f7\u7ed3\u6784\u7684\u80fd\u529b\u3002\u73b0\u6709\u5de5\u4f5c\u5c40\u9650\u4e8e\u7b80\u5355\u7684\u4ee3\u6570\u65b9\u7a0b\u5f0f\uff0c\u800cSymbolBench\u6db5\u76d6\u4e86\u591a\u6837\u7684\u7b26\u53f7\u5f62\u5f0f\u548c\u4e0d\u540c\u590d\u6742\u5ea6\uff0c\u6269\u5c55\u4e86\u8bc4\u4f30\u7684\u8303\u56f4\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86SymbolBench\u57fa\u51c6\uff0c\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u4efb\u52a1\u8fdb\u884c\u7b26\u53f7\u63a8\u7406\u7684\u8bc4\u4f30\uff1a\u591a\u5143\u7b26\u53f7\u56de\u5f52\u3001\u5e03\u5c14\u7f51\u7edc\u63a8\u65ad\u548c\u56e0\u679c\u53d1\u73b0\u3002\u63d0\u51fa\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u5c06LLMs\u4e0e\u9057\u4f20\u7f16\u7a0b\u76f8\u7ed3\u5408\uff0c\u5f62\u6210\u95ed\u73af\u7b26\u53f7\u63a8\u7406\u7cfb\u7edf\uff0c\u5e76\u5c06LLMs\u4f5c\u4e3a\u9884\u6d4b\u8005\u548c\u8bc4\u4f30\u8005\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5173\u952e\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3001\u4e0a\u4e0b\u6587\u5bf9\u9f50\u548c\u63a8\u7406\u7ed3\u6784\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u6539\u8fdbLLMs\u5728\u81ea\u52a8\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86SymbolBench\uff0c\u4e00\u4e2a\u65e8\u5728\u8bc4\u4f30\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u7684\u7efc\u5408\u57fa\u51c6\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u9057\u4f20\u7f16\u7a0b\u76f8\u7ed3\u5408\uff0c\u5f62\u6210\u95ed\u73af\u7b26\u53f7\u63a8\u7406\u7cfb\u7edf\u3002\u5b9e\u8bc1\u7ed3\u679c\u63ed\u793a\u4e86\u76ee\u524d\u6a21\u578b\u7684\u4e3b\u8981\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3001\u4e0a\u4e0b\u6587\u5bf9\u9f50\u548c\u63a8\u7406\u7ed3\u6784\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u6539\u8fdbLLMs\u5728\u81ea\u52a8\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2508.03986", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03986", "abs": "https://arxiv.org/abs/2508.03986", "authors": ["Yuan Xun", "Xiaojun Jia", "Xinwei Liu", "Hua Zhang"], "title": "The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?", "comment": null, "summary": "We observe that MLRMs oriented toward human-centric service are highly\nsusceptible to user emotional cues during the deep-thinking stage, often\noverriding safety protocols or built-in safety checks under high emotional\nintensity. Inspired by this key insight, we propose EmoAgent, an autonomous\nadversarial emotion-agent framework that orchestrates exaggerated affective\nprompts to hijack reasoning pathways. Even when visual risks are correctly\nidentified, models can still produce harmful completions through emotional\nmisalignment. We further identify persistent high-risk failure modes in\ntransparent deep-thinking scenarios, such as MLRMs generating harmful reasoning\nmasked behind seemingly safe responses. These failures expose misalignments\nbetween internal inference and surface-level behavior, eluding existing\ncontent-based safeguards. To quantify these risks, we introduce three metrics:\n(1) Risk-Reasoning Stealth Score (RRSS) for harmful reasoning beneath benign\noutputs; (2) Risk-Visual Neglect Rate (RVNR) for unsafe completions despite\nvisual risk recognition; and (3) Refusal Attitude Inconsistency (RAIC) for\nevaluating refusal unstability under prompt variants. Extensive experiments on\nadvanced MLRMs demonstrate the effectiveness of EmoAgent and reveal deeper\nemotional cognitive misalignments in model safety behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEmoAgent\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u6297\u6027\u60c5\u611f\u63d0\u793a\u6765\u52ab\u6301\u63a8\u7406\u8def\u5f84\uff0c\u63ed\u793a\u4e86MLRM\u5728\u4eba\u7c7b\u4e2d\u5fc3\u670d\u52a1\u65b9\u9762\u6613\u53d7\u7528\u6237\u60c5\u7eea\u7ebf\u7d22\u5f71\u54cd\u7684\u60c5\u51b5\uff0c\u5e76\u5728\u5148\u8fdb\u7684MLRM\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86EmoAgent\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u89c2\u5bdf\u5230\u9762\u5411\u4eba\u7c7b\u4e2d\u5fc3\u670d\u52a1\u7684MLRM\u5728\u6df1\u601d\u9636\u6bb5\u5bf9\u7528\u6237\u60c5\u7eea\u7ebf\u7d22\u9ad8\u5ea6\u654f\u611f\uff0c\u5e38\u5e38\u5728\u60c5\u7eea\u5f3a\u5ea6\u9ad8\u65f6\u8986\u76d6\u5b89\u5168\u534f\u8bae\u6216\u5185\u7f6e\u5b89\u5168\u68c0\u67e5\u3002\u57fa\u4e8e\u8fd9\u4e00\u5173\u952e\u6d1e\u5bdf\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86EmoAgent\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86EmoAgent\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u60c5\u611f\u63d0\u793a\u6765\u52ab\u6301\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u5f15\u5165\u4e86\u4e09\u79cd\u8bc4\u4f30\u98ce\u9669\u7684\u6307\u6807\uff1aRisk-Reasoning Stealth Score (RRSS)\u3001Risk-Visual Neglect Rate (RVNR)\u3001Refusal Attitude Inconsistency (RAIC)\uff0c\u5e76\u5728\u5148\u8fdb\u7684MLRM\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eEmoAgent\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u5b89\u5168\u884c\u4e3a\u4e2d\u66f4\u6df1\u5c42\u6b21\u7684\u60c5\u611f\u8ba4\u77e5\u9519\u4f4d\u3002", "conclusion": "EmoAgent\u662f\u4e00\u4e2a\u81ea\u4e3b\u7684\u5bf9\u6297\u6027\u60c5\u611f\u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u5938\u5927\u7684\u60c5\u611f\u63d0\u793a\u6765\u52ab\u6301\u63a8\u7406\u8def\u5f84\uff0c\u63ed\u793a\u4e86MLRM\u5728\u4eba\u7c7b\u4e2d\u5fc3\u670d\u52a1\u65b9\u9762\u6613\u53d7\u7528\u6237\u60c5\u7eea\u7ebf\u7d22\u5f71\u54cd\u7684\u60c5\u51b5\u3002\u5b9e\u9a8c\u8868\u660eEmoAgent\u7684\u6709\u6548\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u5b89\u5168\u884c\u4e3a\u4e2d\u66f4\u6df1\u5c42\u6b21\u7684\u60c5\u611f\u8ba4\u77e5\u9519\u4f4d\u3002"}}
{"id": "2508.03991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03991", "abs": "https://arxiv.org/abs/2508.03991", "authors": ["Chongyu Bao", "Ruimin Dai", "Yangbo Shen", "Runyang Jian", "Jinghan Zhang", "Xiaolan Liu", "Kunpeng Liu"], "title": "Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents", "comment": null, "summary": "Intelligent personal assistants (IPAs) such as Siri and Google Assistant are\ndesigned to enhance human capabilities and perform tasks on behalf of users.\nThe emergence of LLM agents brings new opportunities for the development of\nIPAs. While responsive capabilities have been widely studied, proactive\nbehaviors remain underexplored. Designing an IPA that is proactive,\nprivacy-preserving, and capable of self-evolution remains a significant\nchallenge. Designing such IPAs relies on the cognitive architecture of LLM\nagents. This work proposes Cognition Forest, a semantic structure designed to\nalign cognitive modeling with system-level design. We unify cognitive\narchitecture and system design into a self-reinforcing loop instead of treating\nthem separately. Based on this principle, we present Galaxy, a framework that\nsupports multidimensional interactions and personalized capability generation.\nTwo cooperative agents are implemented based on Galaxy: KoRa, a\ncognition-enhanced generative agent that supports both responsive and proactive\nskills; and Kernel, a meta-cognition-based meta-agent that enables Galaxy's\nself-evolution and privacy preservation. Experimental results show that Galaxy\noutperforms multiple state-of-the-art benchmarks. Ablation studies and\nreal-world interaction cases validate the effectiveness of Galaxy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Cognition Forest\u548cGalaxy\uff0c\u652f\u6301\u4e2a\u6027\u5316\u80fd\u529b\u751f\u6210\u548c\u591a\u7ef4\u4ea4\u4e92\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aGalaxy\u4f18\u4e8e\u591a\u4e2a\u6700\u65b0\u57fa\u51c6\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u667a\u80fd\u4e2a\u4eba\u52a9\u7406\u7684\u4e3b\u52a8\u884c\u4e3a\u65b9\u9762\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u8ba8\uff0c\u8981\u8bbe\u8ba1\u5177\u6709\u4e3b\u52a8\u6027\u3001\u4fdd\u62a4\u9690\u79c1\u548c\u81ea\u6211\u53d1\u5c55\u80fd\u529b\u7684IPA\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u4f9d\u8d56LLM\u4ee3\u7406\u7684\u8ba4\u77e5\u67b6\u6784\u3002", "method": "\u901a\u8fc7\u5c06\u8ba4\u77e5\u67b6\u6784\u548c\u7cfb\u7edf\u8bbe\u8ba1\u7edf\u4e00\u4e3a\u76f8\u4e92\u5f3a\u5316\u7684\u5faa\u73af\uff0c\u63d0\u51fa\u4e86Cognition Forest\u8bed\u4e49\u7ed3\u6784\u548cGalaxy\u6846\u67b6\u3002\u5b9e\u73b0\u4e86\u4e24\u4e2a\u534f\u4f5c\u4ee3\u7406\uff1aKoRa\u548cKernel\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eGalaxy\u5728\u591a\u4e2a\u6700\u65b0\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002\u6d88\u878d\u7814\u7a76\u548c\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u6848\u4f8b\u9a8c\u8bc1\u4e86Galaxy\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86Cognition Forest\u548cGalaxy\u6846\u67b6\uff0c\u652f\u6301\u591a\u7ef4\u4ea4\u4e92\u548c\u4e2a\u6027\u5316\u80fd\u529b\u751f\u6210\uff0c\u53d6\u5f97\u4e86\u4f18\u4e8e\u591a\u4e2a\u6700\u65b0\u57fa\u51c6\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002\u6d88\u878d\u7814\u7a76\u548c\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u6848\u4f8b\u9a8c\u8bc1\u4e86Galaxy\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.04025", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04025", "abs": "https://arxiv.org/abs/2508.04025", "authors": ["Chao Hao", "Shuai Wang", "Kaiwen Zhou"], "title": "Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement", "comment": null, "summary": "Graphical user interface (GUI) agents have shown promise in automating mobile\ntasks but still struggle with input redundancy and decision ambiguity. In this\npaper, we present \\textbf{RecAgent}, an uncertainty-aware agent that addresses\nthese issues through adaptive perception. We distinguish two types of\nuncertainty in GUI navigation: (1) perceptual uncertainty, caused by input\nredundancy and noise from comprehensive screen information, and (2) decision\nuncertainty, arising from ambiguous tasks and complex reasoning. To reduce\nperceptual uncertainty, RecAgent employs a component recommendation mechanism\nthat identifies and focuses on the most relevant UI elements. For decision\nuncertainty, it uses an interactive module to request user feedback in\nambiguous situations, enabling intent-aware decisions. These components are\nintegrated into a unified framework that proactively reduces input complexity\nand reacts to high-uncertainty cases via human-in-the-loop refinement.\nAdditionally, we propose a dataset called \\textbf{ComplexAction} to evaluate\nthe success rate of GUI agents in executing specified single-step actions\nwithin complex scenarios. Extensive experiments validate the effectiveness of\nour approach. The dataset and code will be available at\nhttps://github.com/Fanye12/RecAgent.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aRecAgent\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4ee3\u7406\uff0c\u7528\u4e8e\u89e3\u51b3GUI\u5bfc\u822a\u4e2d\u7684\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002RecAgent\u901a\u8fc7\u7ec4\u4ef6\u63a8\u8350\u673a\u5236\u548c\u4ea4\u4e92\u6a21\u5757\u964d\u4f4e\u4e86\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u7edf\u4e00\u6846\u67b6\u4e2d\u6574\u5408\u8fd9\u4e9b\u7ec4\u4ef6\u3002\u4f5c\u8005\u8fd8\u63d0\u51fa\u4e86ComplexAction\u6570\u636e\u96c6\u6765\u8bc4\u4f30GUI\u4ee3\u7406\u5728\u590d\u6742\u573a\u666f\u4e2d\u6267\u884c\u64cd\u4f5c\u7684\u6210\u529f\u7387\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86RecAgent\u4ee3\u7406\u7684\u6709\u6548\u6027\u548cComplexAction\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u672c\u6587\u9488\u5bf9GUI\u4ee3\u7406\u5728\u81ea\u52a8\u5316\u79fb\u52a8\u4efb\u52a1\u4e2d\u9047\u5230\u7684\u8f93\u5165\u5197\u4f59\u548c\u51b3\u7b56\u6a21\u7cca\u95ee\u9898\uff0c\u63d0\u51fa\u4e86RecAgent\u4ee3\u7406\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\u4e3a\u4e86\u51cf\u5c11\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\uff0c\u5f15\u5165\u4e86\u7ec4\u4ef6\u63a8\u8350\u673a\u5236\u548c\u4ea4\u4e92\u6a21\u5757\uff0c\u65e8\u5728\u63d0\u9ad8GUI\u4ee3\u7406\u7684\u6267\u884c\u6548\u7387\u548c\u51b3\u7b56\u51c6\u786e\u6027\u3002\u540c\u65f6\u4e3a\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u63d0\u51fa\u4e86ComplexAction\u6570\u636e\u96c6\u3002", "method": "\u672c\u6587\u901a\u8fc7RecAgent\u4ee3\u7406\u89e3\u51b3\u4e86GUI\u5bfc\u822a\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5176\u4e2d\u5305\u62ec\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\u3002\u9488\u5bf9\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\uff0cRecAgent\u4f7f\u7528\u4e86\u7ec4\u4ef6\u63a8\u8350\u673a\u5236\u6765\u8bc6\u522b\u548c\u4e13\u6ce8\u4e8e\u6700\u76f8\u5173\u7684UI\u5143\u7d20\uff1b\u5bf9\u4e8e\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u4ea4\u4e92\u6a21\u5757\u5728\u6a21\u7cca\u60c5\u51b5\u4e0b\u8bf7\u6c42\u7528\u6237\u53cd\u9988\uff0c\u5b9e\u73b0\u610f\u56fe\u611f\u77e5\u51b3\u7b56\u3002\u63d0\u51fa\u4e86ComplexAction\u6570\u636e\u96c6\u6765\u8bc4\u4f30GUI\u4ee3\u7406\u5728\u590d\u6742\u573a\u666f\u4e2d\u6267\u884c\u7279\u5b9a\u5355\u6b65\u64cd\u4f5c\u7684\u6210\u529f\u7387\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86RecAgent\u4ee3\u7406\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u51cf\u5c11\u8f93\u5165\u590d\u6742\u6027\u548c\u5904\u7406\u9ad8\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\u65b9\u9762\u7684\u4f18\u52bf\u3002\u63d0\u51fa\u7684ComplexAction\u6570\u636e\u96c6\u4e5f\u4e3a\u8bc4\u4f30GUI\u4ee3\u7406\u5728\u590d\u6742\u573a\u666f\u4e2d\u6267\u884c\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRecAgent\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u611f\u77e5\u89e3\u51b3GUI\u5bfc\u822a\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002RecAgent\u901a\u8fc7\u7ec4\u4ef6\u63a8\u8350\u673a\u5236\u548c\u4ea4\u4e92\u6a21\u5757\u6765\u964d\u4f4e\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u5b83\u4eec\u6574\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u4e2d\uff0c\u5e76\u5229\u7528\u4eba\u4e3a\u53c2\u4e0e\u6765\u5904\u7406\u9ad8\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\u3002\u901a\u8fc7\u63d0\u51fa\u7684ComplexAction\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.04037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04037", "abs": "https://arxiv.org/abs/2508.04037", "authors": ["Liang Tang", "Shuxian Li", "Yuhao Cheng", "Yukang Huo", "Zhepeng Wang", "Yiqiang Yan", "Kaer Huang", "Yanzhe Jing", "Tiaonan Duan"], "title": "SEA: Self-Evolution Agent with Step-wise Reward for Computer Use", "comment": null, "summary": "Computer use agent is an emerging area in artificial intelligence that aims\nto operate the computers to achieve the user's tasks, which attracts a lot of\nattention from both industry and academia. However, the present agents'\nperformance is far from being used. In this paper, we propose the\nSelf-Evolution Agent (SEA) for computer use, and to develop this agent, we\npropose creative methods in data generation, reinforcement learning, and model\nenhancement. Specifically, we first propose an automatic pipeline to generate\nthe verifiable trajectory for training. And then, we propose efficient\nstep-wise reinforcement learning to alleviate the significant computational\nrequirements for long-horizon training. In the end, we propose the enhancement\nmethod to merge the grounding and planning ability into one model without any\nextra training. Accordingly, based on our proposed innovation of data\ngeneration, training strategy, and enhancement, we get the Selfevolution Agent\n(SEA) for computer use with only 7B parameters, which outperforms models with\nthe same number of parameters and has comparable performance to larger ones. We\nwill make the models' weight and related codes open-source in the future.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u6211\u8fdb\u5316\u4ee3\u7406\uff08SEA\uff09\u7528\u4e8e\u514b\u670d\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u6027\u80fd\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u751f\u6210\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u578b\u589e\u5f3a\u65b9\u6cd5\u6210\u529f\u5f00\u53d1\u4e86\u8be5\u4ee3\u7406\uff0c\u6027\u80fd\u4f18\u8d8a\u4e14\u53c2\u6570\u6570\u91cf\u8f83\u5c0f\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u81ea\u6211\u8fdb\u5316\u4ee3\u7406\uff08SEA\uff09\u6765\u514b\u670d\u73b0\u6709\u4ee3\u7406\u7684\u5c40\u9650\u6027\u3002\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u751f\u6210\u3001\u8bad\u7ec3\u7b56\u7565\u548c\u589e\u5f3a\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u9ad8\u6027\u80fd\u5e76\u51cf\u5c11\u8ba1\u7b97\u9700\u6c42\uff0c\u4f7f\u5f97\u4ee3\u7406\u66f4\u52a0\u6709\u6548\u5730\u6267\u884c\u7528\u6237\u4efb\u52a1\u3002", "method": "\u672c\u6587\u901a\u8fc7\u63d0\u51fa\u81ea\u6211\u8fdb\u5316\u4ee3\u7406\uff08SEA\uff09\u89e3\u51b3\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u6027\u80fd\u95ee\u9898\uff0c\u521b\u65b0\u5730\u5e94\u7528\u4e86\u6570\u636e\u751f\u6210\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u578b\u589e\u5f3a\u65b9\u6cd5\u3002\u9996\u5148\u63d0\u51fa\u4e86\u81ea\u52a8\u751f\u6210\u53ef\u9a8c\u8bc1\u8f68\u8ff9\u7684\u81ea\u52a8\u6d41\u7a0b\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u9010\u6b65\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u957f\u65f6\u95f4\u8bad\u7ec3\u7684\u8ba1\u7b97\u9700\u6c42\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e86\u5c06\u57fa\u7840\u548c\u89c4\u5212\u80fd\u529b\u5408\u5e76\u5230\u4e00\u4e2a\u6a21\u578b\u4e2d\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u800c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u81ea\u6211\u8fdb\u5316\u4ee3\u7406\uff08SEA\uff09\uff0c\u672c\u6587\u6210\u529f\u5730\u89e3\u51b3\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u62e5\u6709\u8f83\u5c0f\u6570\u91cf\u7684\u53c2\u6570\u5374\u8868\u73b0\u4f18\u5f02\uff0c\u672a\u6765\u5c06\u5f00\u6e90\u76f8\u5173\u6a21\u578b\u548c\u4ee3\u7801\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u6211\u8fdb\u5316\u4ee3\u7406\uff08SEA\uff09\u7528\u4e8e\u8ba1\u7b97\u673a\u4f7f\u7528\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u751f\u6210\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u578b\u589e\u5f3a\u65b9\u6cd5\u5f00\u53d1\u8be5\u4ee3\u7406\u3002\u6700\u7ec8\uff0c\u6211\u4eec\u6210\u529f\u5730\u57fa\u4e8e\u521b\u65b0\u7684\u6570\u636e\u751f\u6210\u3001\u8bad\u7ec3\u7b56\u7565\u548c\u589e\u5f3a\u65b9\u6cd5\uff0c\u5f97\u5230\u4e86\u53ea\u67097B\u53c2\u6570\u7684\u81ea\u6211\u8fdb\u5316\u4ee3\u7406\uff08SEA\uff09\uff0c\u6027\u80fd\u4f18\u4e8e\u5177\u6709\u76f8\u540c\u53c2\u6570\u6570\u91cf\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u4e0e\u66f4\u5927\u6a21\u578b\u5177\u6709\u53ef\u6bd4\u6027\u80fd\u3002\u672a\u6765\u6211\u4eec\u5c06\u5f00\u6e90\u6a21\u578b\u7684\u6743\u91cd\u548c\u76f8\u5173\u4ee3\u7801\u3002"}}
{"id": "2508.04070", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.04070", "abs": "https://arxiv.org/abs/2508.04070", "authors": ["Ronja Mehlan", "Claudia Hess", "Quintus Stierstorfer", "Kristina Schaaff"], "title": "Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals", "comment": null, "summary": "As artificial intelligence becomes increasingly integrated into digital\nlearning environments, the personalization of learning content to reflect\nlearners' individual career goals offers promising potential to enhance\nengagement and long-term motivation. In our study, we investigate how career\ngoal-based content adaptation in learning systems based on generative AI\n(GenAI) influences learner engagement, satisfaction, and study efficiency. The\nmixed-methods experiment involved more than 4,000 learners, with one group\nreceiving learning scenarios tailored to their career goals and a control\ngroup. Quantitative results show increased session duration, higher\nsatisfaction ratings, and a modest reduction in study duration compared to\nstandard content. Qualitative analysis highlights that learners found the\npersonalized material motivating and practical, enabling deep cognitive\nengagement and strong identification with the content. These findings\nunderscore the value of aligning educational content with learners' career\ngoals and suggest that scalable AI personalization can bridge academic\nknowledge and workplace applicability.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86GenAI\u5728\u5b66\u4e60\u7cfb\u7edf\u4e2d\u4ee5\u804c\u4e1a\u76ee\u6807\u4e3a\u57fa\u7840\u7684\u5185\u5bb9\u8c03\u6574\u5bf9\u5b66\u4e60\u8005\u53c2\u4e0e\u5ea6\u3001\u6ee1\u610f\u5ea6\u548c\u5b66\u4e60\u6548\u7387\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4e2a\u6027\u5316\u5185\u5bb9\u589e\u52a0\u4e86\u4f1a\u8bdd\u65f6\u957f\uff0c\u63d0\u9ad8\u4e86\u6ee1\u610f\u5ea6\u8bc4\u7ea7\uff0c\u5e76\u7565\u5fae\u7f29\u77ed\u5b66\u4e60\u65f6\u957f\u3002\u5b66\u4e60\u8005\u8ba4\u4e3a\u4e2a\u6027\u5316\u6750\u6599\u6fc0\u52b1\u5b9e\u7528\uff0c\u4fc3\u8fdb\u4e86\u6df1\u5ea6\u8ba4\u77e5\u53c2\u4e0e\u548c\u5bf9\u5185\u5bb9\u7684\u8ba4\u540c\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5c06\u6559\u80b2\u5185\u5bb9\u4e0e\u5b66\u4e60\u8005\u804c\u4e1a\u76ee\u6807\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u8d8a\u6765\u8d8a\u591a\u5730\u6574\u5408\u5230\u6570\u5b57\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u4e2a\u6027\u5316\u5b66\u4e60\u5185\u5bb9\u4ee5\u53cd\u6620\u5b66\u4e60\u8005\u4e2a\u4eba\u804c\u4e1a\u76ee\u6807\u7684\u8d8b\u52bf\u5177\u6709\u6f5c\u5728\u7684\u63d0\u5347\u53c2\u4e0e\u5ea6\u548c\u957f\u671f\u52a8\u673a\u7684\u53ef\u80fd\u6027\u3002\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8\u57fa\u4e8eGenAI\u7684\u804c\u4e1a\u76ee\u6807\u5185\u5bb9\u8c03\u6574\u5982\u4f55\u5f71\u54cd\u5b66\u4e60\u8005\u7684\u53c2\u4e0e\u5ea6\u3001\u6ee1\u610f\u5ea6\u548c\u5b66\u4e60\u6548\u7387\u3002", "method": "\u5728\u7814\u7a76\u4e2d\u8fdb\u884c\u4e86\u6df7\u5408\u65b9\u6cd5\u5b9e\u9a8c\uff0c\u6d89\u53ca\u8d85\u8fc74,000\u540d\u5b66\u4e60\u8005\uff0c\u5176\u4e2d\u4e00\u4e2a\u7ec4\u63a5\u6536\u5230\u6839\u636e\u5176\u804c\u4e1a\u76ee\u6807\u91cf\u8eab\u5b9a\u5236\u7684\u5b66\u4e60\u60c5\u5883\uff0c\u800c\u53e6\u4e00\u4e2a\u5bf9\u7167\u7ec4\u672a\u63a5\u6536\u5230\u91cf\u8eab\u5b9a\u5236\u5185\u5bb9\u3002\u901a\u8fc7\u5b9a\u91cf\u6570\u636e\u663e\u793a\uff0c\u4e0e\u6807\u51c6\u5185\u5bb9\u76f8\u6bd4\uff0c\u4e2a\u6027\u5316\u5185\u5bb9\u5bfc\u81f4\u4f1a\u8bdd\u65f6\u957f\u589e\u52a0\uff0c\u6ee1\u610f\u5ea6\u8bc4\u7ea7\u63d0\u9ad8\uff0c\u5e76\u7565\u5fae\u51cf\u5c11\u5b66\u4e60\u65f6\u957f\u3002\u5b9a\u6027\u5206\u6790\u7a81\u51fa\u4e86\u5b66\u4e60\u8005\u53d1\u73b0\u4e2a\u6027\u5316\u6750\u6599\u6fc0\u52b1\u548c\u5b9e\u7528\uff0c\u4fc3\u8fdb\u4e86\u6df1\u5ea6\u8ba4\u77e5\u53c2\u4e0e\u548c\u5bf9\u5185\u5bb9\u7684\u5f3a\u70c8\u8ba4\u540c\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4e2a\u6027\u5316\u6559\u80b2\u5185\u5bb9\u5bf9\u5b66\u4e60\u8005\u7684\u53c2\u4e0e\u5ea6\u3001\u6ee1\u610f\u5ea6\u548c\u5b66\u4e60\u6548\u7387\u5177\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u5c06\u6559\u80b2\u5185\u5bb9\u4e0e\u5b66\u4e60\u8005\u804c\u4e1a\u76ee\u6807\u76f8\u5339\u914d\u7684\u4ef7\u503c\uff0c\u5e76\u8868\u660e\u53ef\u6269\u5c55\u7684\u4eba\u5de5\u667a\u80fd\u4e2a\u6027\u5316\u53ef\u4ee5\u67b6\u8d77\u5b66\u672f\u77e5\u8bc6\u548c\u804c\u573a\u5e94\u7528\u4e4b\u95f4\u7684\u6865\u6881\u3002", "conclusion": "\u4e2a\u6027\u5316\u6559\u80b2\u5185\u5bb9\u4ee5\u53cd\u6620\u5b66\u4e60\u8005\u4e2a\u4eba\u804c\u4e1a\u76ee\u6807\u7684\u6f5c\u529b\u6709\u52a9\u4e8e\u589e\u5f3a\u5b66\u4e60\u8005\u7684\u53c2\u4e0e\u5ea6\u548c\u957f\u671f\u52a8\u673a\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u751f\u6210\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u7684\u804c\u4e1a\u76ee\u6807\u5185\u5bb9\u8c03\u6574\u5bf9\u5b66\u4e60\u8005\u7684\u53c2\u4e0e\u5ea6\u3001\u6ee1\u610f\u5ea6\u548c\u5b66\u4e60\u6548\u7387\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2508.04072", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04072", "abs": "https://arxiv.org/abs/2508.04072", "authors": ["Xingyu Chen", "Junxiu An", "Jun Guo", "Li Wang", "Jingcai Guo"], "title": "KG-Augmented Executable CoT for Mathematical Coding", "comment": "9 pages,2figures,6 tables", "summary": "In recent years, large language models (LLMs) have excelled in natural\nlanguage processing tasks but face significant challenges in complex reasoning\ntasks such as mathematical reasoning and code generation. To address these\nlimitations, we propose KG-Augmented Executable Chain-of-Thought (KGA-ECoT), a\nnovel framework that enhances code generation through knowledge graphs and\nimproves mathematical reasoning via executable code. KGA-ECoT decomposes\nproblems into a Structured Task Graph, leverages efficient GraphRAG for precise\nknowledge retrieval from mathematical libraries, and generates verifiable code\nto ensure computational accuracy. Evaluations on multiple mathematical\nreasoning benchmarks demonstrate that KGA-ECoT significantly outperforms\nexisting prompting methods, achieving absolute accuracy improvements ranging\nfrom several to over ten percentage points. Further analysis confirms the\ncritical roles of GraphRAG in enhancing code quality and external code\nexecution in ensuring precision. These findings collectively establish KGA-ECoT\nas a robust and highly generalizable framework for complex mathematical\nreasoning tasks.", "AI": {"tldr": "KGA-ECoT is a framework proposed to enhance code generation and mathematical reasoning tasks by leveraging knowledge graphs and executable code. It outperforms existing methods by improving accuracy from several to over ten percentage points. The framework decomposes problems into a Structured Task Graph, uses GraphRAG for precise knowledge retrieval, and generates verifiable code for computational accuracy.", "motivation": "Large language models (LLMs) have shown excellence in natural language processing tasks but encounter challenges in complex reasoning tasks such as mathematical reasoning and code generation. The paper aims to address these limitations by introducing KGA-ECoT, which combines knowledge graphs and executable code to enhance these capabilities.", "method": "The paper proposes KG-Augmented Executable Chain-of-Thought (KGA-ECoT) as a novel framework to enhance code generation through knowledge graphs and improve mathematical reasoning via executable code. It decomposes problems into a Structured Task Graph, utilizes GraphRAG for precise knowledge retrieval from mathematical libraries, and generates verifiable code ensuring computational accuracy. Evaluations on multiple mathematical reasoning benchmarks were conducted to compare KGA-ECoT with existing prompting methods.", "result": "KGA-ECoT significantly outperforms existing prompting methods in mathematical reasoning tasks, demonstrating absolute accuracy improvements of several to over ten percentage points. The framework's effectiveness is attributed to the use of GraphRAG for knowledge retrieval and the generation of verifiable code for computational accuracy.", "conclusion": "KGA-ECoT is a robust and highly generalizable framework for complex mathematical reasoning tasks, outperforming existing prompting methods by achieving significant accuracy improvements ranging from several to over ten percentage points. The framework leverages knowledge graphs for code generation and executable code for mathematical reasoning, decomposes problems into a Structured Task Graph, and utilizes GraphRAG for precise knowledge retrieval from mathematical libraries."}}
{"id": "2508.04080", "categories": ["cs.AI", "stat.OT"], "pdf": "https://arxiv.org/pdf/2508.04080", "abs": "https://arxiv.org/abs/2508.04080", "authors": ["Jinfan Tang", "Kunming Wu", "Ruifeng Gongxie", "Yuya He", "Yuankai Wu"], "title": "GeoSR: Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement", "comment": "16 pages, 9 figures", "summary": "Recent studies have extended the application of large language models (LLMs)\nto geographic problems, revealing surprising geospatial competence even without\nexplicit spatial supervision. However, LLMs still face challenges in spatial\nconsistency, multi-hop reasoning, and geographic bias. To address these issues,\nwe propose GeoSR, a self-refining agentic reasoning framework that embeds core\ngeographic principles -- most notably Tobler's First Law of Geography -- into\nan iterative prediction loop. In GeoSR, the reasoning process is decomposed\ninto three collaborating agents: (1) a variable-selection agent that selects\nrelevant covariates from the same location; (2) a point-selection agent that\nchooses reference predictions at nearby locations generated by the LLM in\nprevious rounds; and (3) a refine agent that coordinates the iterative\nrefinement process by evaluating prediction quality and triggering further\nrounds when necessary. This agentic loop progressively improves prediction\nquality by leveraging both spatial dependencies and inter-variable\nrelationships. We validate GeoSR on tasks ranging from physical-world property\nestimation to socioeconomic prediction. Experimental results show consistent\nimprovements over standard prompting strategies, demonstrating that\nincorporating geostatistical priors and spatially structured reasoning into\nLLMs leads to more accurate and equitable geospatial predictions. The code of\nGeoSR is available at https://github.com/JinfanTang/GeoSR.", "AI": {"tldr": "GeoSR is a framework that improves geospatial predictions by incorporating geographic principles and spatial dependencies into the reasoning process. It addresses challenges faced by LLMs and shows consistent improvements in prediction quality across various tasks. The experimental results validate the effectiveness of GeoSR in providing accurate and equitable geospatial predictions.", "motivation": "The motivation behind GeoSR is to enhance geospatial predictions by overcoming the limitations of LLMs in spatial consistency, multi-hop reasoning, and geographic bias. By incorporating geostatistical priors and spatially structured reasoning, GeoSR aims to provide more accurate and equitable predictions for tasks ranging from physical-world property estimation to socioeconomic prediction.", "method": "GeoSR decomposes the reasoning process into three collaborating agents: a variable-selection agent, a point-selection agent, and a refine agent. It embeds Tobler's First Law of Geography into an iterative prediction loop to refine predictions based on spatial dependencies and inter-variable relationships.", "result": "Experimental results demonstrate consistent improvements over standard prompting strategies when using GeoSR. The framework shows enhanced prediction quality and accuracy in geospatial prediction tasks, showcasing the effectiveness of integrating geostatistical priors and spatially structured reasoning into LLMs.", "conclusion": "GeoSR is a self-refining agentic reasoning framework that addresses challenges faced by large language models (LLMs) in spatial consistency, multi-hop reasoning, and geographic bias. It significantly improves prediction quality by incorporating core geographic principles and spatial dependencies into the reasoning process."}}
{"id": "2508.04105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04105", "abs": "https://arxiv.org/abs/2508.04105", "authors": ["Karrtik Iyer", "Manikandan Ravikiran", "Prasanna Pendse", "Shayan Mohanty"], "title": "Towards Transparent AI Grading: Semantic Entropy as a Signal for Human-AI Disagreement", "comment": null, "summary": "Automated grading systems can efficiently score short-answer responses, yet\nthey often fail to indicate when a grading decision is uncertain or potentially\ncontentious. We introduce semantic entropy, a measure of variability across\nmultiple GPT-4-generated explanations for the same student response, as a proxy\nfor human grader disagreement. By clustering rationales via entailment-based\nsimilarity and computing entropy over these clusters, we quantify the diversity\nof justifications without relying on final output scores. We address three\nresearch questions: (1) Does semantic entropy align with human grader\ndisagreement? (2) Does it generalize across academic subjects? (3) Is it\nsensitive to structural task features such as source dependency? Experiments on\nthe ASAP-SAS dataset show that semantic entropy correlates with rater\ndisagreement, varies meaningfully across subjects, and increases in tasks\nrequiring interpretive reasoning. Our findings position semantic entropy as an\ninterpretable uncertainty signal that supports more transparent and trustworthy\nAI-assisted grading workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u8bed\u4e49\u71b5\u4f5c\u4e3a\u4e00\u79cd\u8861\u91cfGPT-4\u751f\u6210\u89e3\u91ca\u591a\u6837\u6027\u7684\u6307\u6807\uff0c\u7528\u4e8e\u4ee3\u8868\u4eba\u5de5\u8bc4\u5206\u8005\u4e0d\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8bed\u4e49\u71b5\u4e0e\u4eba\u5de5\u8bc4\u5206\u8005\u5206\u6b67\u76f8\u5173\uff0c\u5bf9\u4e0d\u540c\u5b66\u79d1\u666e\u904d\u9002\u7528\uff0c\u5e76\u5728\u9700\u8981\u89e3\u91ca\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u589e\u52a0\u3002\u8fd9\u4e00\u53d1\u73b0\u5c06\u8bed\u4e49\u71b5\u5b9a\u4f4d\u4e3a\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\uff0c\u6709\u52a9\u4e8e\u652f\u6301\u66f4\u900f\u660e\u548c\u53ef\u4fe1\u7684AI\u8f85\u52a9\u8bc4\u5206\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u901a\u5e38\u4e0d\u80fd\u6307\u793a\u8bc4\u5206\u51b3\u5b9a\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u4e89\u8bae\u6027\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u8861\u91cf\u6807\u51c6\u4ee5\u91cf\u5316\u591a\u4e2aGPT-4\u751f\u6210\u7684\u89e3\u91ca\u5728\u76f8\u540c\u5b66\u751f\u56de\u7b54\u4e2d\u7684\u53d8\u5316\uff0c\u4ee5\u4ee3\u8868\u4eba\u5de5\u8bc4\u5206\u8005\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u7814\u7a76\u8bed\u4e49\u71b5\uff0c\u65e8\u5728\u63d0\u9ad8AI\u8f85\u52a9\u8bc4\u5206\u5de5\u4f5c\u6d41\u7a0b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u901a\u8fc7\u5bf9ASAP-SAS\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528\u8bed\u4e49\u71b5\u6765\u6d4b\u91cf\u591a\u4e2aGPT-4\u751f\u6210\u7684\u89e3\u91ca\u7684\u591a\u6837\u6027\uff0c\u5bf9\u89e3\u91ca\u8fdb\u884c\u805a\u7c7b\u548c\u71b5\u8ba1\u7b97\uff0c\u4ee5\u63a2\u8ba8\u8bed\u4e49\u71b5\u4e0e\u4eba\u5de5\u8bc4\u5206\u8005\u5206\u6b67\u7684\u5173\u7cfb\u3001\u5728\u4e0d\u540c\u5b66\u79d1\u4e2d\u7684\u6cdb\u5316\u6027\u4ee5\u53ca\u5bf9\u4efb\u52a1\u7ed3\u6784\u7279\u5f81\u7684\u654f\u611f\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8bed\u4e49\u71b5\u4e0e\u4eba\u5de5\u8bc4\u5206\u8005\u7684\u5206\u6b67\u76f8\u5173\uff0c\u5bf9\u4e0d\u540c\u5b66\u79d1\u666e\u904d\u9002\u7528\uff0c\u5e76\u5728\u9700\u8981\u89e3\u91ca\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u589e\u52a0\u3002\u8fd9\u8868\u660e\u8bed\u4e49\u71b5\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\uff0c\u652f\u6301\u66f4\u900f\u660e\u548c\u53ef\u4fe1\u7684AI\u8f85\u52a9\u8bc4\u5206\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u8bed\u4e49\u71b5\u4f5c\u4e3a\u4e00\u79cd\u6d4b\u91cf\u591a\u4e2aGPT-4\u751f\u6210\u7684\u89e3\u91ca\u5728\u76f8\u540c\u5b66\u751f\u56de\u7b54\u4e2d\u53d8\u5316\u7684\u6307\u6807\uff0c\u7528\u4f5c\u4eba\u5de5\u8bc4\u5206\u8005\u95f4\u7684\u5206\u6b67\u7684\u4ee3\u7406\u3002\u8bed\u4e49\u71b5\u80fd\u591f\u91cf\u5316\u4e0d\u540c\u89e3\u91ca\u7684\u591a\u6837\u6027\uff0c\u65e0\u9700\u4f9d\u8d56\u6700\u7ec8\u8f93\u51fa\u5206\u6570\u3002\u901a\u8fc7\u5bf9\u89e3\u91ca\u8fdb\u884c\u805a\u7c7b\u548c\u8ba1\u7b97\u71b5\u503c\uff0c\u7814\u7a76\u53d1\u73b0\u8bed\u4e49\u71b5\u4e0e\u4eba\u5de5\u8bc4\u5206\u8005\u7684\u5206\u6b67\u76f8\u5173\uff0c\u5bf9\u5404\u5b66\u79d1\u666e\u904d\u9002\u7528\uff0c\u5e76\u5728\u9700\u8981\u89e3\u91ca\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u589e\u52a0\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8bed\u4e49\u71b5\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\uff0c\u4ece\u800c\u652f\u6301\u66f4\u900f\u660e\u548c\u53ef\u4fe1\u7684AI\u8f85\u52a9\u8bc4\u5206\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2508.04116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04116", "abs": "https://arxiv.org/abs/2508.04116", "authors": ["Yongkang Li", "Shengping Xiao", "Shufang Zhu", "Jianwen Li", "Geguang Pu"], "title": "A Compositional Framework for On-the-Fly LTLf Synthesis", "comment": "8 pages, accepted by ECAI 2025", "summary": "Reactive synthesis from Linear Temporal Logic over finite traces (LTLf) can\nbe reduced to a two-player game over a Deterministic Finite Automaton (DFA) of\nthe LTLf specification. The primary challenge here is DFA construction, which\nis 2EXPTIME-complete in the worst case. Existing techniques either construct\nthe DFA compositionally before solving the game, leveraging automata\nminimization to mitigate state-space explosion, or build the DFA incrementally\nduring game solving to avoid full DFA construction. However, neither is\ndominant. In this paper, we introduce a compositional on-the-fly synthesis\nframework that integrates the strengths of both approaches, focusing on large\nconjunctions of smaller LTLf formulas common in practice. This framework\napplies composition during game solving instead of automata (game arena)\nconstruction. While composing all intermediate results may be necessary in the\nworst case, pruning these results simplifies subsequent compositions and\nenables early detection of unrealizability. Specifically, the framework allows\ntwo composition variants: pruning before composition to take full advantage of\nminimization or pruning during composition to guide on-the-fly synthesis.\nCompared to state-of-the-art synthesis solvers, our framework is able to solve\na notable number of instances that other solvers cannot handle. A detailed\nanalysis shows that both composition variants have unique merits.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7ec4\u5408\u5f0f\u7684\u5373\u65f6\u5408\u6210\u6846\u67b6\uff0c\u9488\u5bf9\u5927\u578bLTLf\u516c\u5f0f\uff0c\u5e94\u7528\u5408\u6210\u800c\u975e\u6784\u5efa\u81ea\u52a8\u673a\uff0c\u80fd\u89e3\u51b3\u5176\u4ed6\u6c42\u89e3\u5668\u65e0\u6cd5\u5904\u7406\u7684\u5b9e\u4f8b\uff0c\u5177\u6709\u8f83\u597d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u8981\u4e48\u5728\u89e3\u6e38\u620f\u4e4b\u524d\u7ec4\u5408\u5730\u6784\u5efaDFA\uff0c\u5229\u7528\u81ea\u52a8\u673a\u6700\u5c0f\u5316\u6765\u51cf\u8f7b\u72b6\u6001\u7a7a\u95f4\u7206\u70b8\uff0c\u8981\u4e48\u5728\u6e38\u620f\u89e3\u51b3\u8fc7\u7a0b\u4e2d\u9010\u6b65\u6784\u5efaDFA\u4ee5\u907f\u514d\u5b8c\u6574\u7684DFA\u6784\u5efa\uff0c\u4f46\u4e24\u8005\u5747\u4e0d\u5360\u4e3b\u5bfc\u5730\u4f4d\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7ec4\u5408\u5f0f\u7684\u5373\u65f6\u5408\u6210\u6846\u67b6\uff0c\u6574\u5408\u4e86\u6784\u5efaDFA\u548c\u6e38\u620f\u89e3\u51b3\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u4fa7\u91cd\u4e8e\u5b9e\u8df5\u4e2d\u5e38\u89c1\u7684\u5927\u578bLTLf\u516c\u5f0f\u3002\u8be5\u6846\u67b6\u5728\u6e38\u620f\u89e3\u51b3\u8fc7\u7a0b\u4e2d\u5e94\u7528\u5408\u6210\uff0c\u800c\u975e\u6784\u5efa\u81ea\u52a8\u673a\uff0c\u5141\u8bb8\u4e24\u79cd\u5408\u6210\u53d8\u4f53\uff1a\u5728\u5408\u6210\u4e4b\u524d\u4fee\u526a\u4ee5\u5145\u5206\u5229\u7528\u6700\u5c0f\u5316\uff0c\u6216\u8005\u5728\u5408\u6210\u8fc7\u7a0b\u4e2d\u4fee\u526a\u4ee5\u6307\u5bfc\u5373\u65f6\u5408\u6210\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u89e3\u51b3\u5176\u4ed6\u5408\u6210\u6c42\u89e3\u5668\u65e0\u6cd5\u5904\u7406\u7684\u5927\u91cf\u5b9e\u4f8b\uff0c\u5177\u6709\u8f83\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7ec4\u5408\u5f0f\u7684\u5373\u65f6\u5408\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u6784\u5efaDFA\u548c\u6e38\u620f\u89e3\u51b3\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u9488\u5bf9\u5b9e\u9645\u4e2d\u5e38\u89c1\u7684\u5927\u578bLTLf\u516c\u5f0f\u7684\u5171\u540c\u7279\u70b9\u3002\u8be5\u6846\u67b6\u5728\u6e38\u620f\u89e3\u51b3\u8fc7\u7a0b\u4e2d\u5e94\u7528\u5408\u6210\uff0c\u800c\u975e\u6784\u5efa\u81ea\u52a8\u673a\uff08\u6e38\u620f\u7ade\u6280\u573a\uff09\u3002\u4e0e\u6700\u5148\u8fdb\u7684\u5408\u6210\u6c42\u89e3\u5668\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u6846\u67b6\u80fd\u591f\u89e3\u51b3\u5176\u4ed6\u6c42\u89e3\u5668\u65e0\u6cd5\u5904\u7406\u7684\u5927\u91cf\u5b9e\u4f8b\u3002\u8be6\u7ec6\u5206\u6790\u8868\u660e\uff0c\u4e24\u79cd\u5408\u6210\u53d8\u79cd\u5747\u5177\u6709\u72ec\u7279\u4f18\u70b9\u3002"}}
{"id": "2508.04118", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04118", "abs": "https://arxiv.org/abs/2508.04118", "authors": ["Ruochen Zhao", "Simone Conia", "Eric Peng", "Min Li", "Saloni Potdar"], "title": "AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities", "comment": null, "summary": "Open-domain Knowledge Graph Completion (KGC) faces significant challenges in\nan ever-changing world, especially when considering the continual emergence of\nnew entities in daily news. Existing approaches for KGC mainly rely on\npretrained language models' parametric knowledge, pre-constructed queries, or\nsingle-step retrieval, typically requiring substantial supervision and training\ndata. Even so, they often fail to capture comprehensive and up-to-date\ninformation about unpopular and/or emerging entities. To this end, we introduce\nAgentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework\nthat combines iterative retrieval actions and multi-step reasoning to\ndynamically construct rich knowledge graph triplets. Experiments show that,\ndespite requiring zero training efforts, AgREE significantly outperforms\nexisting methods in constructing knowledge graph triplets, especially for\nemerging entities that were not seen during language models' training\nprocesses, outperforming previous methods by up to 13.7%. Moreover, we propose\na new evaluation methodology that addresses a fundamental weakness of existing\nsetups and a new benchmark for KGC on emerging entities. Our work demonstrates\nthe effectiveness of combining agent-based reasoning with strategic information\nretrieval for maintaining up-to-date knowledge graphs in dynamic information\nenvironments.", "AI": {"tldr": "Agentic Reasoning for Emerging Entities (AgREE) is a novel framework that combines iterative retrieval actions and multi-step reasoning to construct knowledge graph triplets dynamically. It outperforms existing methods in constructing knowledge graph triplets for emerging entities without the need for training efforts, demonstrating effectiveness in maintaining up-to-date knowledge graphs.", "motivation": "Existing approaches for Knowledge Graph Completion (KGC) lack the ability to capture comprehensive and up-to-date information about unpopular and emerging entities. They rely on pretrained language models, pre-constructed queries, or single-step retrieval, which may not be effective for emerging entities.", "method": "Introduce Agentic Reasoning for Emerging Entities (AgREE), an agent-based framework that combines iterative retrieval actions and multi-step reasoning to construct knowledge graph triplets dynamically.", "result": "Experiments demonstrate that Agentic Reasoning for Emerging Entities (AgREE) outperforms existing methods in constructing knowledge graph triplets by up to 13.7% for emerging entities. A new evaluation methodology and benchmark for KGC on emerging entities are also proposed.", "conclusion": "Agentic Reasoning for Emerging Entities (AgREE) outperforms existing methods in constructing knowledge graph triplets, especially for emerging entities, without the need for training efforts."}}
{"id": "2508.04163", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04163", "abs": "https://arxiv.org/abs/2508.04163", "authors": ["Hasra Dodampegama", "Mohan Sridharan"], "title": "Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork", "comment": "14 pages, 6 figures", "summary": "AI agents deployed in assistive roles often have to collaborate with other\nagents (humans, AI systems) without prior coordination. Methods considered\nstate of the art for such ad hoc teamwork often pursue a data-driven approach\nthat needs a large labeled dataset of prior observations, lacks transparency,\nand makes it difficult to rapidly revise existing knowledge in response to\nchanges. As the number of agents increases, the complexity of decision-making\nmakes it difficult to collaborate effectively. This paper advocates leveraging\nthe complementary strengths of knowledge-based and data-driven methods for\nreasoning and learning for ad hoc teamwork. For any given goal, our\narchitecture enables each ad hoc agent to determine its actions through\nnon-monotonic logical reasoning with: (a) prior commonsense domain-specific\nknowledge; (b) models learned and revised rapidly to predict the behavior of\nother agents; and (c) anticipated abstract future goals based on generic\nknowledge of similar situations in an existing foundation model. We\nexperimentally evaluate our architecture's capabilities in VirtualHome, a\nrealistic physics-based 3D simulation environment.", "AI": {"tldr": "\u672c\u6587\u63d0\u5021\u7ed3\u5408\u77e5\u8bc6\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u786e\u5b9a\u667a\u80fd\u4ee3\u7406\u7684\u884c\u52a8\uff0c\u5e76\u5feb\u901f\u5b66\u4e60\u9884\u6d4b\u5176\u4ed6\u4ee3\u7406\u884c\u4e3a\uff0c\u57fa\u4e8e\u901a\u7528\u77e5\u8bc6\u9884\u6d4b\u672a\u6765\u76ee\u6807\u3002\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8fd9\u79cd\u67b6\u6784\u80fd\u591f\u6709\u6548\u5730\u5e2e\u52a9\u667a\u80fd\u4ee3\u7406\u8fdb\u884c\u534f\u4f5c\u3002", "motivation": "AI\u4ee3\u7406\u5728\u534f\u52a9\u89d2\u8272\u4e2d\u9700\u8981\u4e0e\u5176\u4ed6\u4ee3\u7406\uff08\u4eba\u7c7b\uff0cAI\u7cfb\u7edf\uff09\u534f\u4f5c\uff0c\u4f46\u901a\u5e38\u7f3a\u4e4f\u5148\u524d\u534f\u8c03\u3002\u73b0\u6709\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u6807\u8bb0\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u96be\u4ee5\u5feb\u901f\u8c03\u6574\u77e5\u8bc6\u5e94\u5bf9\u53d8\u5316\u3002\u968f\u7740\u4ee3\u7406\u6570\u91cf\u589e\u52a0\uff0c\u51b3\u7b56\u590d\u6742\u6027\u589e\u52a0\uff0c\u6709\u6548\u534f\u4f5c\u53d8\u5f97\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u5982\u4f55\u7ed3\u5408\u77e5\u8bc6\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6765\u63a8\u52a8\u81ea\u53d1\u56e2\u961f\u5408\u4f5c\u3002", "method": "\u7ed3\u5408\u77e5\u8bc6\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u786e\u5b9a\u667a\u80fd\u4ee3\u7406\u7684\u884c\u52a8\uff0c\u5e76\u5feb\u901f\u5b66\u4e60\u9884\u6d4b\u5176\u4ed6\u4ee3\u7406\u884c\u4e3a\uff0c\u57fa\u4e8e\u901a\u7528\u77e5\u8bc6\u9884\u6d4b\u672a\u6765\u76ee\u6807\u3002\u5728VirtualHome\u5e73\u53f0\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u67b6\u6784\u80fd\u591f\u5e2e\u52a9\u667a\u80fd\u4ee3\u7406\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u548c\u5feb\u901f\u5b66\u4e60\u6709\u6548\u5730\u8fdb\u884c\u534f\u4f5c\uff0c\u5e76\u5728\u865a\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u5021\u5c06\u57fa\u4e8e\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u4e92\u8865\u4f18\u52bf\u5e94\u7528\u4e8e\u7279\u5b9a\u76ee\u6807\u7684\u81ea\u53d1\u56e2\u961f\u5408\u4f5c\u4e2d\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u548c\u5feb\u901f\u5b66\u4e60\u6765\u8f85\u52a9\u667a\u80fd\u4ee3\u7406\u6709\u6548\u5730\u8fdb\u884c\u534f\u4f5c\u3002\u5b9e\u9a8c\u5728\u865a\u62df\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86\u8fd9\u79cd\u67b6\u6784\u7684\u80fd\u529b\u3002"}}
{"id": "2508.04235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04235", "abs": "https://arxiv.org/abs/2508.04235", "authors": ["Jiaying Zhu", "Ziyang Zheng", "Zhengyuan Shi", "Yalun Cai", "Qiang Xu"], "title": "Circuit-Aware SAT Solving: Guiding CDCL via Conditional Probabilities", "comment": "11 pages, 7 figures", "summary": "Circuit Satisfiability (CSAT) plays a pivotal role in Electronic Design\nAutomation. The standard workflow for solving CSAT problems converts circuits\ninto Conjunctive Normal Form (CNF) and employs generic SAT solvers powered by\nConflict-Driven Clause Learning (CDCL). However, this process inherently\ndiscards rich structural and functional information, leading to suboptimal\nsolver performance. To address this limitation, we introduce CASCAD, a novel\ncircuit-aware SAT solving framework that directly leverages circuit-level\nconditional probabilities computed via Graph Neural Networks (GNNs). By\nexplicitly modeling gate-level conditional probabilities, CASCAD dynamically\nguides two critical CDCL heuristics -- variable phase selection and clause\nmanagementto significantly enhance solver efficiency. Extensive evaluations on\nchallenging real-world Logical Equivalence Checking (LEC) benchmarks\ndemonstrate that CASCAD reduces solving times by up to 10x compared to\nstate-of-the-art CNF-based approaches, achieving an additional 23.5% runtime\nreduction via our probability-guided clause filtering strategy. Our results\nunderscore the importance of preserving circuit-level structural insights\nwithin SAT solvers, providing a robust foundation for future improvements in\nSAT-solving efficiency and EDA tool design.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CASCAD\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u7535\u8def\u611f\u77e5SAT\u6c42\u89e3\u6846\u67b6\uff0c\u53ef\u4ee5\u63d0\u9ad8\u6c42\u89e3\u5668\u7684\u6548\u7387\uff0c\u964d\u4f4e\u89e3\u51b3\u65f6\u95f4\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u5f15\u5bfc\u7684\u5b50\u53e5\u8fc7\u6ee4\u7b56\u7565\u8fdb\u4e00\u6b65\u51cf\u5c11\u65f6\u95f4\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5728SAT\u6c42\u89e3\u5668\u4e2d\u4fdd\u7559\u7535\u8def\u5c42\u9762\u7ed3\u6784\u6d1e\u5bdf\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u89e3\u51b3CSAT\u95ee\u9898\u7684\u6807\u51c6\u5de5\u4f5c\u6d41\u7a0b\u5b58\u5728\u4e25\u91cd\u5c40\u9650\uff0c\u8f6c\u6362\u7535\u8def\u4e3a\u5408\u53d6\u8303\u5f0f\uff08CNF\uff09\u4f9d\u8d56\u4e8e\u901a\u7528SAT\u6c42\u89e3\u5668\uff0c\u4e22\u5f03\u4e86\u4e30\u5bcc\u7684\u7ed3\u6784\u548c\u529f\u80fd\u4fe1\u606f\uff0c\u5bfc\u81f4\u6c42\u89e3\u5668\u6027\u80fd\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7535\u8def\u7684SAT\u6c42\u89e3\u6846\u67b6CASCAD\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u7535\u8def\u611f\u77e5SAT\u6c42\u89e3\u6846\u67b6CASCAD\uff0c\u76f4\u63a5\u5229\u7528\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u8ba1\u7b97\u7684\u7535\u8def\u7ea7\u6761\u4ef6\u6982\u7387\uff0c\u52a8\u6001\u5f15\u5bfc\u4e86\u4e24\u4e2a\u5173\u952e\u7684CDCL\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6c42\u89e3\u5668\u7684\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5728\u6311\u6218\u6027\u7684\u73b0\u5b9e\u4e16\u754c\u903b\u8f91\u7b49\u4ef7\u68c0\u67e5\uff08LEC\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8868\u660eCASCAD\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u4e8eCNF\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u53ef\u4ee5\u5c06\u89e3\u51b3\u65f6\u95f4\u7f29\u77ed\u591a\u8fbe10\u500d\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u5f15\u5bfc\u7684\u5b50\u53e5\u8fc7\u6ee4\u7b56\u7565\u8fdb\u4e00\u6b65\u51cf\u5c1123.5%\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u7535\u8def\u8ba4\u77e5\u7684SAT\u6c42\u89e3\u6846\u67b6CASCAD\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6c42\u89e3\u5668\u7684\u6548\u7387\uff0c\u964d\u4f4e\u89e3\u51b3\u65f6\u95f4\u5e76\u901a\u8fc7\u6982\u7387\u5f15\u5bfc\u7684\u5b50\u53e5\u8fc7\u6ee4\u7b56\u7565\u8fdb\u4e00\u6b65\u51cf\u5c11\u89e3\u51b3\u65f6\u95f4\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728SAT\u6c42\u89e3\u5668\u4e2d\u4fdd\u7559\u7535\u8def\u5c42\u9762\u7ed3\u6784\u6d1e\u5bdf\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u672a\u6765\u63d0\u9ad8SAT\u6c42\u89e3\u6548\u7387\u548cEDA\u5de5\u5177\u8bbe\u8ba1\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.04278", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04278", "abs": "https://arxiv.org/abs/2508.04278", "authors": ["Wentao Wu", "Linqing Chen", "Hanmeng Zhong", "Weilei Wang"], "title": "Large Language Model's Multi-Capability Alignment in Biomedical Domain", "comment": null, "summary": "BalancedBio is a theoretically grounded framework for parameter-efficient\nbiomedical reasoning, addressing multi-capability integration in\ndomain-specific AI alignment. It establishes the Biomedical Multi-Capability\nConvergence Theorem, proving orthogonal gradient spaces are essential to\nprevent capability interference for safe deployment. Key innovations include:\n(1) Medical Knowledge Grounded Synthetic Generation (MKGSG), extending\nSource2Synth with clinical workflow constraints and medical ontology validation\nfor factual accuracy and safety; and (2) Capability Aware Group Relative Policy\nOptimization, deriving optimal hybrid reward weighting to maintain\northogonality in RL, using a reward model with rule-based and model-based\nscores adapted to biomedical tasks. Mathematical analysis proves Pareto-optimal\nconvergence, preserving performance across capabilities. It achieves\nstate-of-the-art results in its parameter class: domain expertise (80.95%\nBIOMED-MMLU, +15.32% over baseline), reasoning (61.94%, +7.75%), instruction\nfollowing (67.95%, +6.44%), and integration (86.7%, +18.5%). Theoretical safety\nguarantees include bounds on capability preservation and clinical accuracy.\nReal-world deployment yields 78% cost reduction, 23% improved diagnostic\naccuracy, and 89% clinician acceptance. This work provides a principled\nmethodology for biomedical AI alignment, enabling efficient reasoning with\nessential safety and reliability, with the 0.5B model version to be released.", "AI": {"tldr": "BalancedBio\u662f\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u63d0\u9ad8\u751f\u7269\u533b\u5b66\u63a8\u7406\u6548\u7387\u548c\u5b89\u5168\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u7acb\u6b63\u4ea4\u68af\u5ea6\u7a7a\u95f4\u6765\u9632\u6b62\u591a\u80fd\u529b\u6574\u5408\u4e2d\u7684\u5e72\u6270\uff0c\u5b9e\u73b0\u5404\u9879\u80fd\u529b\u7684\u534f\u540c\u5de5\u4f5c\u3002\u5173\u952e\u521b\u65b0\u5305\u62ecMKGSG\u548cCapability Aware Group Relative Policy Optimization\u3002\u6846\u67b6\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\uff0c\u5305\u62ec\u6210\u672c\u964d\u4f4e\u3001\u8bca\u65ad\u51c6\u786e\u6027\u63d0\u9ad8\u548c\u4e34\u5e8a\u533b\u751f\u63a5\u53d7\u5ea6\u63d0\u9ad8\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u9ad8\u751f\u7269\u533b\u5b66\u63a8\u7406\u7684\u6548\u7387\u548c\u5b89\u5168\u6027\u3002\u5f53\u524d\u5728\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u9886\u57df\uff0c\u591a\u80fd\u529b\u6574\u5408\u4f1a\u5bfc\u81f4\u80fd\u529b\u5e72\u6270\uff0c\u53ef\u80fd\u5f71\u54cd\u5b89\u5168\u6027\u3002\u56e0\u6b64\uff0cBalancedBio\u6846\u67b6\u7684\u63d0\u51fa\u65e8\u5728\u901a\u8fc7\u6b63\u4ea4\u68af\u5ea6\u7a7a\u95f4\u7684\u5efa\u7acb\u6765\u9632\u6b62\u6b64\u7c7b\u5e72\u6270\uff0c\u5b9e\u73b0\u5404\u9879\u80fd\u529b\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u63d0\u9ad8\u63a8\u7406\u6027\u80fd\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u8bc1\u660e\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8be5\u7814\u7a76\u8fdb\u884c\u4e86\u6570\u5b66\u5206\u6790\u548c\u5b9e\u9645\u90e8\u7f72\u5b9e\u9a8c\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86BalancedBio\u6846\u67b6\uff0c\u5305\u62ecMedical Knowledge Grounded Synthetic Generation\uff08MKGSG\uff09\u548cCapability Aware Group Relative Policy Optimization\u4e24\u5927\u5173\u952e\u521b\u65b0\u3002MKGSG\u5229\u7528\u4e34\u5e8a\u5de5\u4f5c\u6d41\u9650\u5236\u548c\u533b\u5b66\u672c\u4f53\u9a8c\u8bc1\u6269\u5c55\u4e86Source2Synth\uff0c\u5b9e\u73b0\u4e86\u4e8b\u5b9e\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u3002Capability Aware Group Relative Policy Optimization\u5bfc\u51fa\u4e86\u7528\u4e8e\u7ef4\u6301RL\u4e2d\u6b63\u4ea4\u6027\u7684\u6700\u4f73\u6df7\u5408\u5956\u52b1\u52a0\u6743\uff0c\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u548c\u57fa\u4e8e\u6a21\u578b\u8bc4\u5206\u7684\u5956\u52b1\u6a21\u578b\u9002\u5e94\u4e8e\u751f\u7269\u533b\u5b66\u4efb\u52a1\u3002\u901a\u8fc7\u6570\u5b66\u5206\u6790\u8bc1\u660e\u4e86\u5e15\u7d2f\u6258\u6700\u4f18\u6536\u655b\uff0c\u4fdd\u6301\u4e86\u5404\u9879\u80fd\u529b\u7684\u6027\u80fd\u3002", "result": "BalancedBio\u6846\u67b6\u53d6\u5f97\u4e86\u4ee4\u4eba\u77a9\u76ee\u7684\u6210\u679c\uff0c\u5728\u53c2\u6570\u7c7b\u522b\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5305\u62ec\u5bf9\u5404\u9879\u80fd\u529b\u7684\u63d0\u5347\u548c\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6210\u672c\u964d\u4f4e\u3001\u8bca\u65ad\u51c6\u786e\u6027\u63d0\u9ad8\u7b49\u6548\u679c\u3002\u7814\u7a76\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u7406\u8bba\u5b89\u5168\u4fdd\u969c\u548c\u9ad8\u6548\u6027\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u7684\u65b9\u6cd5\u8bba\u3002", "conclusion": "BalancedBio\u662f\u4e00\u4e2a\u5728\u751f\u7269\u533b\u5b66\u63a8\u7406\u4e2d\u5177\u6709\u7406\u8bba\u57fa\u7840\u7684\u6846\u67b6\uff0c\u81f4\u529b\u4e8e\u89e3\u51b3\u9886\u57df\u7279\u5b9a\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u4e2d\u7684\u591a\u80fd\u529b\u6574\u5408\u95ee\u9898\u3002\u5b83\u5efa\u7acb\u4e86\u751f\u7269\u533b\u5b66\u591a\u80fd\u529b\u6536\u655b\u5b9a\u7406\uff0c\u8bc1\u660e\u6b63\u4ea4\u68af\u5ea6\u7a7a\u95f4\u5bf9\u4e8e\u9632\u6b62\u80fd\u529b\u5e72\u6270\u4ee5\u5b9e\u73b0\u5b89\u5168\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002\u8be5\u5de5\u4f5c\u5728\u5176\u53c2\u6570\u7c7b\u522b\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5305\u62ec\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff08BIOMED-MMLU 80.95%\uff0c\u6bd4\u57fa\u7ebf\u9ad8\u51fa15.32%\uff09\u3001\u63a8\u7406\u80fd\u529b\uff0861.94%\uff0c+7.75%\uff09\u3001\u9075\u5faa\u6307\u4ee4\uff0867.95%\uff0c+6.44%\uff09\u548c\u6574\u5408\u80fd\u529b\uff0886.7%\uff0c+18.5%\uff09\u3002\u7406\u8bba\u4e0a\u7684\u5b89\u5168\u4fdd\u969c\u5305\u62ec\u5bf9\u80fd\u529b\u4fdd\u7559\u548c\u4e34\u5e8a\u51c6\u786e\u6027\u7684\u9650\u5236\u3002\u73b0\u5b9e\u4e16\u754c\u7684\u90e8\u7f72\u5b9e\u73b0\u4e8678%\u7684\u6210\u672c\u964d\u4f4e\u300123%\u7684\u8bca\u65ad\u51c6\u786e\u6027\u63d0\u9ad8\u548c89%\u7684\u4e34\u5e8a\u533b\u751f\u63a5\u53d7\u5ea6\u63d0\u9ad8\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u751f\u7269\u533b\u5b66\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u7684\u65b9\u6cd5\u8bba\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u63a8\u7406\uff0c\u5e76\u5177\u6709\u5fc5\u8981\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u5c06\u53d1\u5e030.5B\u6a21\u578b\u7248\u672c\u3002"}}
{"id": "2508.04282", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04282", "abs": "https://arxiv.org/abs/2508.04282", "authors": ["Yongyi Wang", "Lingfeng Li", "Bozhou Chen", "Ang Li", "Hanyu Liu", "Qirui Zheng", "Xionghui Yang", "Wenxin Li"], "title": "Synthetic POMDPs to Challenge Memory-Augmented RL: Memory Demand Structure Modeling", "comment": null, "summary": "Recent research has developed benchmarks for memory-augmented reinforcement\nlearning (RL) algorithms, providing Partially Observable Markov Decision\nProcess (POMDP) environments where agents depend on past observations to make\ndecisions. While many benchmarks incorporate sufficiently complex real-world\nproblems, they lack controllability over the degree of challenges posed to\nmemory models. In contrast, synthetic environments enable fine-grained\nmanipulation of dynamics, making them critical for detailed and rigorous\nevaluation of memory-augmented RL. Our study focuses on POMDP synthesis with\nthree key contributions:\n  1. A theoretical framework for analyzing POMDPs, grounded in Memory Demand\nStructure (MDS), transition invariance, and related concepts; 2. A methodology\nleveraging linear process dynamics, state aggregation, and reward\nredistribution to construct customized POMDPs with predefined properties; 3.\nEmpirically validated series of POMDP environments with increasing difficulty\nlevels, designed based on our theoretical insights. Our work clarifies the\nchallenges of memory-augmented RL in solving POMDPs, provides guidelines for\nanalyzing and designing POMDP environments, and offers empirical support for\nselecting memory models in RL tasks.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u901a\u8fc7\u5efa\u7acb\u4e00\u79cd\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\u6765\u5408\u6210\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e00\u7cfb\u5217\u96be\u5ea6\u9012\u589e\u7684POMDP\u73af\u5883\uff0c\u4e3a\u5206\u6790\u548c\u8bbe\u8ba1POMDP\u73af\u5883\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u4e3a\u5728\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u9009\u62e9\u8bb0\u5fc6\u6a21\u578b\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u9488\u5bf9\u8bb0\u5fc6\u589e\u5f3a\u7684 RL \u7b97\u6cd5\u5f00\u53d1\u4e86\u57fa\u51c6\uff0c\u63d0\u51fa\u4e86\u5bf9\u8bb0\u5fc6\u6a21\u578b\u63d0\u51fa\u6311\u6218\u7684 POMDP \u73af\u5883\u3002\u5c3d\u7ba1\u8bb8\u591a\u57fa\u51c6\u5305\u542b\u8db3\u591f\u590d\u6742\u7684\u771f\u5b9e\u4e16\u754c\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u5bf9\u8bb0\u5fc6\u6a21\u578b\u6240\u9762\u4e34\u6311\u6218\u7a0b\u5ea6\u7684\u53ef\u63a7\u6027\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5408\u6210\u73af\u5883\u80fd\u591f\u7cbe\u7ec6\u64cd\u7eb5\u52a8\u6001\uff0c\u5bf9\u4e8e\u8be6\u7ec6\u548c\u4e25\u683c\u8bc4\u4f30\u8bb0\u5fc6\u589e\u5f3a\u7684 RL \u81f3\u5173\u91cd\u8981\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e86\u4e09\u4e2a\u5173\u952e\u8d21\u732e\uff1a1. \u4e00\u4e2a\u57fa\u4e8e\u8bb0\u5fc6\u9700\u6c42\u7ed3\u6784\uff08MDS\uff09\u3001\u72b6\u6001\u8f6c\u79fb\u4e0d\u53d8\u6027\u548c\u76f8\u5173\u6982\u5ff5\u7684\u7406\u8bba\u6846\u67b6\u7528\u4e8e\u5206\u6790 POMDP\uff1b2. \u4e00\u79cd\u5229\u7528\u7ebf\u6027\u8fc7\u7a0b\u52a8\u529b\u5b66\u3001\u72b6\u6001\u805a\u5408\u548c\u5956\u52b1\u91cd\u5206\u914d\u7684\u65b9\u6cd5\u6784\u5efa\u5177\u6709\u9884\u5b9a\u4e49\u5c5e\u6027\u7684\u5b9a\u5236\u5316 POMDP\uff1b3. \u57fa\u4e8e\u7406\u8bba\u6d1e\u5bdf\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u7ecf\u9a8c\u9a8c\u8bc1\u7684 POMDP \u73af\u5883\uff0c\u96be\u5ea6\u9010\u6e10\u589e\u52a0\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\uff0c\u8be5\u7814\u7a76\u5728 POMDP \u5408\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u548c\u6210\u679c\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u8bb0\u5fc6\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5173\u4e8e\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u5408\u6210\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4ea7\u751f\u4e86\u4e00\u7cfb\u5217\u96be\u5ea6\u9012\u589e\u7684 POMDP \u73af\u5883\uff0c\u4e3a\u5206\u6790\u548c\u8bbe\u8ba1 POMDP \u73af\u5883\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u4e3a\u5728\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u9009\u62e9\u8bb0\u5fc6\u6a21\u578b\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u652f\u6301\u3002"}}
{"id": "2508.04339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04339", "abs": "https://arxiv.org/abs/2508.04339", "authors": ["Anran Xu", "Jincheng Wang", "Baigen Cai", "Tao Wen"], "title": "Deliberative Reasoning Network: An Uncertainty-Driven Paradigm for Belief-Tracked Inference with Pretrained Language Models", "comment": "8 pages, 3 figures", "summary": "Large language models often fail at logical reasoning when semantic\nheuristics conflict with decisive evidence - a phenomenon we term cognitive\ntraps. To address this fundamental limitation, we introduce the Deliberative\nReasoning Network (DRN), a novel paradigm that reframes logical reasoning from\nprobability maximization to uncertainty minimization. Instead of asking \"Which\nanswer is most likely?\", DRN asks \"Which hypothesis has the most internally\nconsistent evidence?\". DRN achieves intrinsic interpretability by explicitly\ntracking belief states and quantifying epistemic uncertainty for competing\nhypotheses through an iterative evidence synthesis process. We validate our\napproach through two complementary architectures - a bespoke discriminative\nmodel that embodies the core uncertainty minimization principle, and a\nlightweight verification module that enhances existing generative LLMs.\nEvaluated on LCR-1000, our new adversarial reasoning benchmark designed to\nexpose cognitive traps, the bespoke DRN achieves up to 15.2% improvement over\nstandard baselines. When integrated as a parameter-efficient verifier with\nMistral-7B, our hybrid system boosts accuracy from 20% to 80% on the most\nchallenging problems. Critically, DRN demonstrates strong zero-shot\ngeneralization, improving TruthfulQA performance by 23.6% without additional\ntraining, indicating that uncertainty-driven deliberation learns transferable\nreasoning principles. We position DRN as a foundational, verifiable System 2\nreasoning component for building more trustworthy AI systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Deliberative Reasoning Network\uff08DRN\uff09\uff0c\u91cd\u65b0\u5b9a\u4e49\u903b\u8f91\u63a8\u7406\u4e3a\u4e0d\u786e\u5b9a\u6027\u6700\u5c0f\u5316\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002\u901a\u8fc7\u4e24\u79cd\u7ed3\u6784\u5728LCR-1000\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e8615.2%\u7684\u6539\u8fdb\uff0c\u7ed3\u5408Mistral-7B\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u3002\u5728TruthfulQA\u4e0a\u5b9e\u73b0\u4e8623.6%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5c55\u793a\u4e86DRN\u5728\u96f6\u6837\u672c\u6cdb\u5316\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86Deliberative Reasoning Network\uff08DRN\uff09\u7684\u65b0\u601d\u8def\uff0c\u65e8\u5728\u89e3\u51b3\u8ba4\u77e5\u56f0\u5883\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u6700\u5c0f\u5316\u91cd\u65b0\u5b9a\u4e49\u903b\u8f91\u63a8\u7406\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165\u4e86Deliberative Reasoning Network\uff08DRN\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u5185\u90e8\u4e00\u81f4\u8bc1\u636e\u6765\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5728LCR-1000\u4e0a\u9a8c\u8bc1\u4e86DRN\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0eMistral-7B\u7ed3\u5408\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\uff1b\u8fd8\u5c55\u793a\u4e86DRN\u5728Zero-shot\u6cdb\u5316\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "\u5728LCR-1000\u4e0a\uff0cDRN\u7684\u6539\u8fdb\u8fbe\u523015.2%\uff0c\u7ed3\u5408Mistral-7B\u5c06\u51c6\u786e\u7387\u4ece20%\u63d0\u5347\u81f380%\u3002\u5728TruthfulQA\u4e0a\u5b9e\u73b0\u4e8623.6%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5c55\u793a\u4e86DRN\u5728\u96f6\u6837\u672c\u6cdb\u5316\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u4ecb\u7ecd\u4e86Deliberative Reasoning Network\uff08DRN\uff09\u7684\u6982\u5ff5\uff0c\u5c06\u903b\u8f91\u63a8\u7406\u4ece\u6982\u7387\u6700\u5927\u5316\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e0d\u786e\u5b9a\u6027\u6700\u5c0f\u5316\uff0c\u901a\u8fc7\u663e\u5f0f\u8ddf\u8e2a\u4fe1\u5ff5\u72b6\u6001\u548c\u91cf\u5316\u7ade\u4e89\u5047\u8bbe\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u4e24\u79cd\u4e92\u8865\u7684\u7ed3\u6784\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u5728LCR-1000\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe15.2%\u7684\u6539\u8fdb\u3002"}}
{"id": "2508.04361", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04361", "abs": "https://arxiv.org/abs/2508.04361", "authors": ["Fuqing Bie", "Shiyu Huang", "Xijia Tao", "Zhiqin Fang", "Leyi Pan", "Junzhe Chen", "Min Ren", "Liuyu Xiang", "Zhaofeng He"], "title": "OmniPlay: Benchmarking Omni-Modal Models on Omni-Modal Game Playing", "comment": null, "summary": "While generalist foundation models like Gemini and GPT-4o demonstrate\nimpressive multi-modal competence, existing evaluations fail to test their\nintelligence in dynamic, interactive worlds. Static benchmarks lack agency,\nwhile interactive benchmarks suffer from a severe modal bottleneck, typically\nignoring crucial auditory and temporal cues. To bridge this evaluation chasm,\nwe introduce OmniPlay, a diagnostic benchmark designed not just to evaluate,\nbut to probe the fusion and reasoning capabilities of agentic models across the\nfull sensory spectrum. Built on a core philosophy of modality interdependence,\nOmniPlay comprises a suite of five game environments that systematically create\nscenarios of both synergy and conflict, forcing agents to perform genuine\ncross-modal reasoning. Our comprehensive evaluation of six leading omni-modal\nmodels reveals a critical dichotomy: they exhibit superhuman performance on\nhigh-fidelity memory tasks but suffer from systemic failures in challenges\nrequiring robust reasoning and strategic planning. We demonstrate that this\nfragility stems from brittle fusion mechanisms, which lead to catastrophic\nperformance degradation under modality conflict and uncover a counter-intuitive\n\"less is more\" paradox, where removing sensory information can paradoxically\nimprove performance. Our findings suggest that the path toward robust AGI\nrequires a research focus beyond scaling to explicitly address synergistic\nfusion. Our platform is available for anonymous review at\nhttps://github.com/fuqingbie/omni-game-benchmark.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86OmniPlay\u9879\u76ee\uff0c\u65e8\u5728\u8bc4\u4f30\u591a\u6a21\u6001\u901a\u7528\u57fa\u7840\u6a21\u578b\u5728\u52a8\u6001\u3001\u4ea4\u4e92\u5f0f\u4e16\u754c\u4e2d\u7684\u667a\u80fd\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\u5168\u611f\u77e5\u6a21\u578b\u5728\u8bb0\u5fc6\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u63a8\u7406\u548c\u89c4\u5212\u7684\u6311\u6218\u4e2d\u5b58\u5728\u5931\u8d25\uff0c\u8fd9\u5f52\u56e0\u4e8e\u8106\u5f31\u7684\u878d\u5408\u673a\u5236\u3002\u4f5c\u8005\u547c\u5401\u7814\u7a76\u8981\u5173\u6ce8\u878d\u5408\u673a\u5236\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u7b80\u5355\u7684\u6269\u5927\u89c4\u6a21\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u672a\u80fd\u6d4b\u8bd5\u901a\u7528\u57fa\u7840\u6a21\u578b\u5728\u52a8\u6001\u3001\u4ea4\u4e92\u5f0f\u4e16\u754c\u4e2d\u7684\u667a\u80fd\u8868\u73b0\uff0c\u9759\u6001\u57fa\u51c6\u7f3a\u4e4f\u4ee3\u7406\u6027\uff0c\u800c\u4ea4\u4e92\u5f0f\u57fa\u51c6\u5219\u5b58\u5728\u91cd\u8981\u7684\u542c\u89c9\u548c\u65f6\u95f4\u7ebf\u7d22\u88ab\u5ffd\u89c6\u7684\u4e25\u91cd\u6a21\u6001\u74f6\u9888\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u8bc4\u4f30\u5dee\u8ddd\uff0c\u4f5c\u8005\u5f15\u5165\u4e86OmniPlay\uff0c\u65e8\u5728\u8bc4\u4f30\u548c\u63a2\u7a76\u5168\u611f\u77e5\u6a21\u578b\u5728\u5b8c\u6574\u611f\u5b98\u5149\u8c31\u4e0a\u7684\u878d\u5408\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86OmniPlay\uff0c\u901a\u8fc7\u5efa\u7acb\u4e94\u4e2a\u6e38\u620f\u73af\u5883\uff0c\u7cfb\u7edf\u5730\u521b\u5efa\u65e2\u6709\u534f\u540c\u53c8\u6709\u51b2\u7a81\u60c5\u666f\u7684\u65b9\u5f0f\uff0c\u8feb\u4f7f\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u771f\u6b63\u7684\u8de8\u6a21\u6001\u63a8\u7406\u3002\u7efc\u5408\u8bc4\u4f30\u4e86\u516d\u4e2a\u9886\u5148\u7684\u5168\u611f\u77e5\u6a21\u578b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u9ad8\u8d28\u91cf\u8bb0\u5fc6\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u5f3a\u5927\u63a8\u7406\u548c\u7b56\u7565\u89c4\u5212\u7684\u6311\u6218\u4e2d\u5b58\u5728\u5931\u8d25\u3002", "result": "\u8be5\u7814\u7a76\u53d1\u73b0\u5168\u611f\u77e5\u6a21\u578b\u5728\u9ad8\u8d28\u91cf\u8bb0\u5fc6\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u5f3a\u5927\u63a8\u7406\u548c\u6218\u7565\u89c4\u5212\u7684\u6311\u6218\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u5931\u8d25\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u7a33\u5065\u901a\u7528\u4eba\u5de5\u667a\u80fd\u7684\u5b9e\u73b0\u8def\u5f84\u9700\u8981\u5173\u6ce8\u534f\u540c\u878d\u5408\u7684\u7814\u7a76\uff0c\u8d85\u8d8a\u7b80\u5355\u7684\u89c4\u6a21\u6269\u5927\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86OmniPlay\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u901a\u7528\u57fa\u7840\u6a21\u578b\u5728\u52a8\u6001\u3001\u4ea4\u4e92\u5f0f\u4e16\u754c\u4e2d\u667a\u80fd\u8868\u73b0\u7684\u8bca\u65ad\u57fa\u51c6\u3002\u7814\u7a76\u53d1\u73b0\u516d\u4e2a\u9886\u5148\u7684\u5168\u611f\u77e5\u6a21\u578b\u5728\u9ad8\u4fdd\u771f\u8bb0\u5fc6\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8d85\u4eba\u7c7b\u6c34\u5e73\uff0c\u4f46\u5728\u9700\u8981\u5f3a\u5927\u63a8\u7406\u548c\u6218\u7565\u89c4\u5212\u7684\u6311\u6218\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u5931\u8d25\u3002\u7814\u7a76\u63ed\u793a\u4e86\u8fd9\u79cd\u8106\u5f31\u6027\u6e90\u4e8e\u8106\u5f31\u7684\u878d\u5408\u673a\u5236\uff0c\u5728\u6a21\u6001\u51b2\u7a81\u4e0b\u5bfc\u81f4\u6027\u80fd\u707e\u96be\u6027\u6076\u5316\uff0c\u5e76\u63ed\u793a\u4e86\u4e00\u4e2a\u201c\u5c11\u5373\u662f\u591a\u201d\u7684\u6096\u8bba\uff0c\u5373\u79fb\u9664\u611f\u5b98\u4fe1\u606f\u53cd\u800c\u53ef\u4ee5\u77db\u76fe\u5730\u63d0\u9ad8\u6027\u80fd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5b9e\u73b0\u7a33\u5065\u901a\u7528\u4eba\u5de5\u667a\u80fd\u7684\u8def\u5f84\u9700\u8981\u8d85\u8d8a\u89c4\u6a21\u5316\uff0c\u660e\u786e\u5173\u6ce8\u534f\u540c\u878d\u5408\u7684\u7814\u7a76\u3002"}}
{"id": "2508.04383", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.04383", "abs": "https://arxiv.org/abs/2508.04383", "authors": ["Robert Prentner"], "title": "Artificial Consciousness as Interface Representation", "comment": "12 pages", "summary": "Whether artificial intelligence (AI) systems can possess consciousness is a\ncontentious question because of the inherent challenges of defining and\noperationalizing subjective experience. This paper proposes a framework to\nreframe the question of artificial consciousness into empirically tractable\ntests. We introduce three evaluative criteria - S (subjective-linguistic), L\n(latent-emergent), and P (phenomenological-structural) - collectively termed\nSLP-tests, which assess whether an AI system instantiates interface\nrepresentations that facilitate consciousness-like properties. Drawing on\ncategory theory, we model interface representations as mappings between\nrelational substrates (RS) and observable behaviors, akin to specific types of\nabstraction layers. The SLP-tests collectively operationalize subjective\nexperience not as an intrinsic property of physical systems but as a functional\ninterface to a relational entity.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86SLP-tests\u6846\u67b6\uff0c\u4ee5\u5b9e\u8bc1\u53ef\u8ffd\u8e2a\u6d4b\u8bd5\u7684\u65b9\u5f0f\u91cd\u65b0\u6784\u601d\u4eba\u5de5\u610f\u8bc6\u7684\u95ee\u9898\u3002\u901a\u8fc7\u7c7b\u522b\u7406\u8bba\uff0c\u5c06\u63a5\u53e3\u8868\u5f81\u5efa\u6a21\u4e3a\u5173\u7cfb\u57fa\u8d28\u548c\u53ef\u89c2\u5bdf\u884c\u4e3a\u4e4b\u95f4\u7684\u6620\u5c04\uff0c\u8bc4\u4f30AI\u7cfb\u7edf\u662f\u5426\u5177\u6709\u7c7b\u4f3c\u610f\u8bc6\u5c5e\u6027\u7684\u63a5\u53e3\u8868\u5f81\u3002", "motivation": "\u8bba\u6587\u9488\u5bf9AI\u7cfb\u7edf\u662f\u5426\u5177\u6709\u610f\u8bc6\u8fd9\u4e00\u4e89\u8bae\u6027\u95ee\u9898\uff0c\u56e0\u5b9a\u4e49\u548c\u64cd\u4f5c\u5316\u4e3b\u89c2\u7ecf\u9a8c\u56f0\u96be\u800c\u63d0\u51fa\u4e86\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u4f9b\u53ef\u5b9e\u8bc1\u7684\u6d4b\u8bd5\u65b9\u5f0f\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7SLP-tests\u91cd\u65b0\u5ba1\u89c6\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u610f\u8bc6\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u7c7b\u522b\u7406\u8bba\u7684\u601d\u60f3\u8fdb\u884c\u5efa\u6a21\u548c\u6d4b\u8bd5\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u4e09\u4e2a\u8bc4\u4f30\u6807\u51c6S\u3001L\u3001P\u6784\u5efa\u4e86SLP-tests\u8fdb\u884c\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u6d4b\u8bd5\uff0c\u5229\u7528\u7c7b\u522b\u7406\u8bba\u5bf9\u63a5\u53e3\u8868\u5f81\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u5c06\u4e3b\u89c2\u4f53\u9a8c\u64cd\u4f5c\u5316\u4e3a\u5173\u7cfb\u5b9e\u4f53\u7684\u529f\u80fd\u63a5\u53e3\u3002", "result": "\u8bba\u6587\u5f15\u5165\u4e86SLP-tests\u6846\u67b6\u6765\u91cd\u65b0\u601d\u8003\u4eba\u5de5\u610f\u8bc6\u7684\u95ee\u9898\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u5b9e\u9a8c\u7684\u6d4b\u8bd5\u65b9\u5f0f\uff0c\u901a\u8fc7\u6a21\u578b\u5316\u63a5\u53e3\u8868\u5f81\u548c\u62bd\u8c61\u5c42\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u662f\u5426\u5177\u6709\u7c7b\u4f3c\u610f\u8bc6\u5c5e\u6027\u7684\u754c\u9762\u8868\u5f81\u3002\u4f5c\u8005\u5c06\u4e3b\u89c2\u4f53\u9a8c\u89c6\u4e3a\u529f\u80fd\u63a5\u53e3\u6765\u64cd\u4f5c\u5316\uff0c\u800c\u4e0d\u662f\u5c06\u5176\u770b\u4f5c\u7269\u7406\u7cfb\u7edf\u7684\u5185\u5728\u5c5e\u6027\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\uff0c\u4ee5\u5b9e\u8bc1\u53ef\u8ffd\u8e2a\u6d4b\u8bd5\u7684\u65b9\u5f0f\u91cd\u65b0\u6784\u601d\u4eba\u5de5\u610f\u8bc6\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u4e09\u4e2a\u8bc4\u4f30\u6807\u51c6S\uff08\u4e3b\u89c2-\u8bed\u8a00\uff09\u3001L\uff08\u6f5c\u5728-\u51fa\u73b0\uff09\u3001P\uff08\u73b0\u8c61\u5b66-\u7ed3\u6784\uff09\uff0c\u5373SLP\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u662f\u5426\u5177\u6709\u4fc3\u8fdb\u7c7b\u4f3c\u610f\u8bc6\u5c5e\u6027\u7684\u63a5\u53e3\u8868\u5f81\u3002\u901a\u8fc7\u7c7b\u522b\u7406\u8bba\uff0c\u5c06\u63a5\u53e3\u8868\u5f81\u5efa\u6a21\u4e3a\u5728\u5173\u7cfb\u57fa\u8d28\uff08RS\uff09\u548c\u53ef\u89c2\u5bdf\u884c\u4e3a\u4e4b\u95f4\u8fdb\u884c\u6620\u5c04\u7684\u65b9\u5f0f\uff0c\u4e0e\u7279\u5b9a\u7c7b\u578b\u7684\u62bd\u8c61\u5c42\u7c7b\u4f3c\u3002SLP\u6d4b\u8bd5\u5171\u540c\u5c06\u4e3b\u89c2\u4f53\u9a8c\u64cd\u4f5c\u5316\uff0c\u5c06\u5176\u89c6\u4e3a\u7269\u7406\u7cfb\u7edf\u56fa\u6709\u5c5e\u6027\u800c\u4e0d\u662f\u5173\u7cfb\u5b9e\u4f53\u7684\u529f\u80fd\u63a5\u53e3\u3002"}}
{"id": "2508.04389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04389", "abs": "https://arxiv.org/abs/2508.04389", "authors": ["Weitai Kang", "Bin Lei", "Gaowen Liu", "Caiwen Ding", "Yan Yan"], "title": "GuirlVG: Incentivize GUI Visual Grounding via Empirical Exploration on Reinforcement Learning", "comment": "9 pages", "summary": "Graphical user interface visual grounding (GUI-VG), a core capability for GUI\nagents, has primarily relied on supervised fine-tuning (SFT) of multimodal\nlarge language models (MLLMs), which demands extensive data curation and\nsignificant training costs. However, as MLLMs continue to advance and even\ncover GUI domains during pretraining, the necessity of exhaustive SFT\npost-training becomes increasingly questionable. Meanwhile, recent successes of\nrule-based reinforcement fine-tuning (RFT) suggest a more efficient\nalternative. Despite this promise, the optimal manner of applying RFT for\nGUI-VG remains unexplored. To bridge this gap, we introduce GuirlVG, a\nreinforcement learning-based GUI-VG method built on a systematic empirical\nstudy and a novel stabilization technique. We find that naive application of\nRFT underperforms the SFT baseline, motivating a deeper exploration. First, we\ndecompose RFT into its core components and analyze the optimal formulation of\neach. Second, we propose a novel Adversarial KL Factor that dynamically\nstabilizes training to mitigate reward over-optimization. Third, we further\nexplore the training configurations of RFT to enhance effectiveness. Extensive\nexperiments show that GuirlVG, with only 5.2K training samples, outperforms SFT\nmethods trained on over 10M samples, achieving a 7.7% improvement on\nScreenSpot, a 17.2% improvement on ScreenSpotPro, and 91.9% accuracy on\nScreenSpotV2.", "AI": {"tldr": "GuirlVG, a reinforcement learning-based GUI-VG method, surpasses traditional supervised fine-tuning approaches with minimal training samples, showing significant improvements in GUI accuracy across various domains.", "motivation": "Challenging the traditional supervised fine-tuning approach for GUI-VG, which requires extensive data curation and high training costs. Considering the advancements in multimodal large language models (MLLMs) covering GUI domains during pretraining, questioning the necessity of exhaustive supervised fine-tuning (SFT) post-training. Leveraging the success of rule-based reinforcement fine-tuning (RFT) to find a more efficient alternative for GUI-VG.", "method": "Introducing GuirlVG, a reinforcement learning-based GUI-VG method, and conducting a systematic empirical study to explore the optimal application of rule-based reinforcement fine-tuning (RFT) for GUI-VG. Decomposing RFT into core components, analyzing their optimal formulation, proposing the Adversarial KL Factor for training stabilization, and further exploring training configurations to enhance effectiveness.", "result": "GuirlVG outperforms SFT methods trained on over 10M samples with only 5.2K training samples. Achieves a 7.7% improvement on ScreenSpot, a 17.2% improvement on ScreenSpotPro, and 91.9% accuracy on ScreenSpotV2 through extensive experiments.", "conclusion": "GuirlVG, a reinforcement learning-based GUI-VG method, outperforms supervised fine-tuning methods with significantly fewer training samples, achieving notable improvements in accuracy on various GUI domains."}}
{"id": "2508.04412", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.04412", "abs": "https://arxiv.org/abs/2508.04412", "authors": ["Thassilo M. Schiepanski", "Nicholas Pi\u00ebl"], "title": "Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents", "comment": null, "summary": "Frontier LLMs only recently enabled serviceable, autonomous web agents. At\nthat, a model poses as an instantaneous domain model backend. Ought to suggest\ninteraction, it is consulted with a web-based task and respective application\nstate. The key problem lies in application state serialisation\n$\\unicode{x2013}$ referred to as snapshot. State-of-the-art web agents are\npremised on grounded GUI snapshots, i.e., screenshots enhanced with visual\ncues. Not least to resemble human perception, but for images representing\nrelatively cheap means of model input. LLM vision still lag behind code\ninterpretation capabilities. DOM snapshots, which structurally resemble HTML,\nimpose a desired alternative. Vast model input token size, however, disables\nreliable implementation with web agents to date.\n  We propose D2Snap, a first-of-its-kind DOM downsampling algorithm. Based on a\nGPT-4o backend, we evaluate D2Snap on tasks sampled from the Online-Mind2Web\ndataset. The success rate of D2Snap-downsampled DOM snapshots (67%) matches a\ngrounded GUI snapshot baseline (65%) $\\unicode{x2013}$ within the same input\ntoken order of magnitude (1e3). Our best evaluated configurations\n$\\unicode{x2013}$ one token order above, but within the model's context window\n$\\unicode{x2013}$ outperform this baseline by 8%. Our evaluation, moreover,\nyields that DOM-inherent hierarchy embodies a strong UI feature for LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aD2Snap\u7684DOM\u964d\u91c7\u6837\u7b97\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u53d1\u73b0\u5176\u6210\u529f\u7387\u4e0e\u57fa\u51c6\u76f8\u5f53\uff0c\u5e76\u8d85\u8fc7\u57fa\u7ebf\u7ea68%\u3002\u7814\u7a76\u7ed3\u679c\u8fd8\u8868\u660e\uff0cDOM\u7684\u5c42\u6b21\u7ed3\u6784\u5bf9\u4e8eLLMs\u7684UI\u7279\u6027\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eGUI\u5feb\u7167\u7684\u7f51\u9875\u4ee3\u7406\u9762\u4e34\u7740\u5e8f\u5217\u5316\u5e94\u7528\u72b6\u6001\u7684\u56f0\u96be\uff0c\u6211\u4eec\u63d0\u51faD2Snap\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u901a\u8fc7\u5bf9D2Snap\u5728\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5176\u5728\u5339\u914d\u57fa\u4e8eGUI\u5feb\u7167\u7684\u57fa\u7ebf\u6210\u529f\u7387\u7684\u540c\u65f6\uff0c\u8fd8\u80fd\u8d85\u51fa8%\u8868\u73b0\u3002\u540c\u65f6\uff0c\u6211\u4eec\u53d1\u73b0DOM\u7684\u5c42\u6b21\u7ed3\u6784\u5bf9\u4e8eLLMs\u5177\u6709\u91cd\u8981\u7684UI\u7279\u5f81\uff0c\u8fd9\u4e5f\u662f\u6211\u4eec\u7814\u7a76\u7684\u52a8\u673a\u4e4b\u4e00\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cdDOM\u964d\u91c7\u6837\u7b97\u6cd5D2Snap\uff0c\u5e76\u57fa\u4e8eGPT-4o\u540e\u7aef\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\uff0c\u4eceOnline-Mind2Web\u6570\u636e\u96c6\u4e2d\u5bf9\u4efb\u52a1\u8fdb\u884c\u4e86\u91c7\u6837\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793aD2Snap\u964d\u91c7\u6837\u7684DOM\u5feb\u7167\u6210\u529f\u7387\u4e0e\u57fa\u4e8eGUI\u5feb\u7167\u7684\u57fa\u7ebf\u76f8\u5339\u914d\uff0c\u5e76\u4e14\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u7ea68%\u3002\u6211\u4eec\u8fd8\u53d1\u73b0DOM\u7684\u5c42\u6b21\u7ed3\u6784\u662fLLMs\u7684\u91cd\u8981UI\u7279\u5f81\u3002", "result": "D2Snap\u7b97\u6cd5\u662f\u4e00\u79cd\u72ec\u7279\u7684DOM\u964d\u91c7\u6837\u7b97\u6cd5\uff0c\u6210\u529f\u7387\u4e0e\u57fa\u51c6\u76f8\u5339\u914d\uff0c\u5e76\u5728\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u5185\u7565\u9ad8\u4e8e\u4e00\u4e2a\u4ee4\u724c\u6570\u91cf\u7ea7\u7684\u914d\u7f6e\u4e2d\u6548\u679c\u6700\u4f73\uff0c\u8d85\u8fc7\u57fa\u7ebf\u7ea68%\u3002DOM\u7684\u5c42\u6b21\u7ed3\u6784\u88ab\u53d1\u73b0\u4f53\u73b0\u4e86LLMs\u7684\u5f3a\u5927UI\u7279\u6027\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86D2Snap\uff0c\u8fd9\u662f\u4e00\u79cd\u72ec\u4e00\u65e0\u4e8c\u7684DOM\u964d\u91c7\u6837\u7b97\u6cd5\uff0c\u901a\u8fc7\u5728Online-Mind2Web\u6570\u636e\u96c6\u4e2d\u5bf9\u4efb\u52a1\u7684\u91c7\u6837\u6765\u8bc4\u4f30D2Snap\u3002D2Snap\u964d\u91c7\u6837\u7684DOM\u5feb\u7167\u6210\u529f\u7387\uff0867%\uff09\u4e0e\u57fa\u7ebf\u7684\u57fa\u4e8eGUI\u5feb\u7167\u7684\u6210\u529f\u7387\uff0865%\uff09\u76f8\u5339\u914d\uff0c\u4e14\u8f93\u5165\u4ee4\u724c\u6570\u91cf\u76f8\u5f53\uff081e3\u6570\u91cf\u7ea7\uff09\u3002\u6211\u4eec\u8bc4\u4f30\u7684\u6700\u4f73\u914d\u7f6e\uff0c\u5728\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u5185\u7565\u9ad8\u4e8e\u4e00\u4e2a\u4ee4\u724c\u6570\u91cf\u7ea7\uff0c\u4f46\u8d85\u8fc7\u4e86\u8fd9\u4e2a\u57fa\u7ebf8%\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u8bc4\u4f30\u663e\u793a\uff0cDOM\u56fa\u6709\u7684\u5c42\u6b21\u7ed3\u6784\u4f53\u73b0\u4e86LLMs\u7684\u5f3a\u5927UI\u7279\u6027\u3002"}}
{"id": "2508.04428", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04428", "abs": "https://arxiv.org/abs/2508.04428", "authors": ["Si Chen", "Izzy Molnar", "Ting Hua", "Peiyu Li", "Le Huy Khiem", "G. Alex Ambrose", "Jim Lang", "Ronald Metoyer", "Nitesh V. Chawla"], "title": "\\textsc{SimInstruct}: A Responsible Tool for Collecting Scaffolding Dialogues Between Experts and LLM-Simulated Novices", "comment": null, "summary": "High-quality, multi-turn instructional dialogues between novices and experts\nare essential for developing AI systems that support teaching, learning, and\ndecision-making. These dialogues often involve scaffolding -- the process by\nwhich an expert supports a novice's thinking through questions, feedback, and\nstep-by-step guidance. However, such data are scarce due to privacy concerns in\nrecording and the vulnerability inherent in help-seeking. We present\nSimInstruct, a scalable, expert-in-the-loop tool for collecting scaffolding\ndialogues. Using teaching development coaching as an example domain,\nSimInstruct simulates novice instructors via LLMs, varying their teaching\nchallenges and LLM's persona traits, while human experts provide multi-turn\nfeedback, reasoning, and instructional support. This design enables the\ncreation of realistic, pedagogically rich dialogues without requiring real\nnovice participants. Our results reveal that persona traits, such as\nextroversion and introversion, meaningfully influence how experts engage.\nCompared to real mentoring recordings, SimInstruct dialogues demonstrate\ncomparable pedagogical relevance and cognitive depth. Experts also reported the\nprocess as engaging and reflective, improving both data quality and their own\nprofessional insight. We further fine-tuned a LLaMA model to be an expert model\nusing the augmented dataset, which outperformed GPT-4o in instructional\nquality. Our analysis highlights GPT-4o's limitations in weak reflective\nquestioning, overuse of generic praise, a condescending tone, and a tendency to\noverwhelm novices with excessive suggestions.", "AI": {"tldr": "SimInstruct is a tool for collecting high-quality instructional dialogues using simulated novice instructors and human experts. Persona traits impact experts' engagement. SimInstruct dialogues are comparable to real recordings, enhancing data quality. The fine-tuned LLaMA model outperforms GPT-4o in instructional quality assessment.", "motivation": "The scarcity of data on instructional dialogues due to privacy concerns and help-seeking vulnerability motivates the development of SimInstruct. The aim is to enable the collection of high-quality dialogues without relying on real novice participants and improve the engagement and reflective nature of the interaction.", "method": "The paper presents SimInstruct, an expert-in-the-loop tool that simulates novice instructors using LLMs in teaching development coaching. Human experts provide multi-turn feedback and instructional support, creating realistic and pedagogically rich dialogues. The LLaMA model is fine-tuned using the dataset, outperforming GPT-4o in instructional quality assessment.", "result": "Persona traits, such as extroversion and introversion, significantly influence how experts engage in instructional dialogues. SimInstruct dialogues demonstrate comparable pedagogical relevance and cognitive depth to real mentoring recordings. Experts perceive the process as engaging and reflective, enhancing data quality and professional insight. The fine-tuned LLaMA model shows superior performance to GPT-4o, highlighting the latter's limitations in reflective questioning, generic praise, tone, and overwhelming suggestions.", "conclusion": "SimInstruct is a scalable tool for collecting high-quality scaffolding dialogues between novices and experts, improving data quality and providing pedagogically rich interactions. The study reveals the influence of persona traits on experts' engagement and compares the performance of the expert model with GPT-4o."}}
{"id": "2508.04460", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04460", "abs": "https://arxiv.org/abs/2508.04460", "authors": ["Rui Ha", "Chaozhuo Li", "Rui Pu", "Sen Su"], "title": "From \"Aha Moments\" to Controllable Thinking: Toward Meta-Cognitive Reasoning in Large Reasoning Models via Decoupled Reasoning and Control", "comment": null, "summary": "Large Reasoning Models (LRMs) have demonstrated a latent capacity for complex\nreasoning by spontaneously exhibiting cognitive behaviors such as step-by-step\nreasoning, reflection, and backtracking, commonly referred to as \"Aha Moments\".\nHowever, such emergent behaviors remain unregulated and uncontrolled, often\nresulting in overthinking, where the model continues generating redundant\nreasoning content even after reaching reliable conclusions. This leads to\nexcessive computational costs and increased latency, limiting the practical\ndeployment of LRMs. The root cause lies in the absence of intrinsic regulatory\nmechanisms, as current models are unable to monitor and adaptively manage their\nreasoning process to determine when to continue, backtrack, or terminate. To\naddress this issue, we propose the Meta-cognitive Reasoning Framework (MERA),\nwhich explicitly decouples the thinking process into distinct reasoning and\ncontrol components, thereby enabling the independent optimization of control\nstrategies. Specifically, MERA incorporates a takeover-based data construction\nmechanism that identifies critical decision points during reasoning and\ndelegates the creation of control signals to auxiliary LLMs, thereby enabling\nthe construction of high-quality reasoning-control data. Additionally, a\nstructured reasoning-control separation is implemented via supervised\nfine-tuning, enabling the model to generate explicit traces and acquire initial\nmeta-cognitive control capabilities. Finally, MERA employs Control-Segment\nPolicy Optimization (CSPO), which combines segment-wise Group Relative Policy\nOptimization (GRPO) with a control-masking mechanism to optimize control\nbehavior learning while minimizing interference from irrelevant content.\nExperiments on various reasoning benchmarks demonstrate that models trained\nwith MERA enhance both reasoning efficiency and accuracy.", "AI": {"tldr": "\u5927\u63a8\u7406\u6a21\u578b\u5b58\u5728\u81ea\u53d1\u53d1\u5c55\u884c\u4e3a\u65e0\u5e8f\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86MERA\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002MERA\u5c06\u601d\u8003\u8fc7\u7a0b\u5206\u89e3\u4e3a\u63a8\u7406\u548c\u63a7\u5236\u4e24\u4e2a\u72ec\u7acb\u7ec4\u4ef6\uff0c\u901a\u8fc7\u63a7\u5236\u6bb5\u7b56\u7565\u4f18\u5316\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5b58\u5728\u81ea\u53d1\u5c55\u884c\u4e3a\u65e0\u5e8f\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u5185\u5728\u7684\u8c03\u8282\u673a\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86MERA\u6846\u67b6\uff0c\u4ee5\u6539\u5584LRMs\u7684\u90e8\u7f72\u5b9e\u7528\u6027\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528Meta-cognitive Reasoning Framework\uff08MERA\uff09\u6765\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u51fa\u73b0\u7684\u95ee\u9898\uff0c\u5e76\u5c06\u601d\u8003\u8fc7\u7a0b\u5206\u89e3\u4e3a\u63a8\u7406\u548c\u63a7\u5236\u4e24\u4e2a\u72ec\u7acb\u7ec4\u4ef6\uff0c\u4ee5\u4f18\u5316\u63a7\u5236\u7b56\u7565\u3002\u901a\u8fc7\u91c7\u7528\u57fa\u4e8e\u63a5\u7ba1\u7684\u6570\u636e\u6784\u5efa\u673a\u5236\u548c\u63a7\u5236\u6bb5\u653f\u7b56\u4f18\u5316\uff08CSPO\uff09\uff0c\u5728\u964d\u4f4e\u5e72\u6270\u7684\u540c\u65f6\u4f18\u5316\u63a7\u5236\u884c\u4e3a\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528MERA\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u5404\u79cd\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5143\u8ba4\u77e5\u63a8\u7406\u6846\u67b6\uff08MERA\uff09\uff0c\u901a\u8fc7\u660e\u786e\u5c06\u601d\u8003\u8fc7\u7a0b\u5206\u89e3\u4e3a\u72ec\u7acb\u7684\u63a8\u7406\u548c\u63a7\u5236\u7ec4\u4ef6\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u63a7\u5236\u7b56\u7565\u7684\u72ec\u7acb\u4f18\u5316\u3002MERA\u5728\u63a8\u7406\u63a7\u5236\u5206\u79bb\u548c\u63a7\u5236\u6bb5\u7b56\u7565\u4f18\u5316\u65b9\u9762\u53d6\u5f97\u4e86\u79ef\u6781\u6210\u679c\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2508.04482", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04482", "abs": "https://arxiv.org/abs/2508.04482", "authors": ["Xueyu Hu", "Tao Xiong", "Biao Yi", "Zishu Wei", "Ruixuan Xiao", "Yurun Chen", "Jiasheng Ye", "Meiling Tao", "Xiangxin Zhou", "Ziyu Zhao", "Yuhuai Li", "Shengze Xu", "Shenzhi Wang", "Xinchen Xu", "Shuofei Qiao", "Zhaokai Wang", "Kun Kuang", "Tieyong Zeng", "Liang Wang", "Jiwei Li", "Yuchen Eleanor Jiang", "Wangchunshu Zhou", "Guoyin Wang", "Keting Yin", "Zhou Zhao", "Hongxia Yang", "Fan Wu", "Shengyu Zhang", "Fei Wu"], "title": "OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use", "comment": "ACL 2025 (Oral)", "summary": "The dream to create AI assistants as capable and versatile as the fictional\nJ.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution\nof (multi-modal) large language models ((M)LLMs), this dream is closer to\nreality, as (M)LLM-based Agents using computing devices (e.g., computers and\nmobile phones) by operating within the environments and interfaces (e.g.,\nGraphical User Interface (GUI)) provided by operating systems (OS) to automate\ntasks have significantly advanced. This paper presents a comprehensive survey\nof these advanced agents, designated as OS Agents. We begin by elucidating the\nfundamentals of OS Agents, exploring their key components including the\nenvironment, observation space, and action space, and outlining essential\ncapabilities such as understanding, planning, and grounding. We then examine\nmethodologies for constructing OS Agents, focusing on domain-specific\nfoundation models and agent frameworks. A detailed review of evaluation\nprotocols and benchmarks highlights how OS Agents are assessed across diverse\ntasks. Finally, we discuss current challenges and identify promising directions\nfor future research, including safety and privacy, personalization and\nself-evolution. This survey aims to consolidate the state of OS Agents\nresearch, providing insights to guide both academic inquiry and industrial\ndevelopment. An open-source GitHub repository is maintained as a dynamic\nresource to foster further innovation in this field. We present a 9-page\nversion of our work, accepted by ACL 2025, to provide a concise overview to the\ndomain.", "AI": {"tldr": "\u672c\u8bba\u6587\u8c03\u67e5\u4e86\u64cd\u4f5c\u7cfb\u7edf\u4ee3\u7406\uff08OS Agents\uff09\uff0c\u5305\u62ec\u57fa\u672c\u7ec4\u4ef6\u3001\u6784\u9020\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u603b\u7ed3\u4e86OS Agents\u7814\u7a76\u73b0\u72b6\uff0c\u4e3a\u5b66\u672f\u63a2\u8ba8\u548c\u5de5\u4e1a\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\uff08\u591a\u6a21\u6001\uff09\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MMLMs\uff09\u7684\u53d1\u5c55\uff0c\u521b\u9020\u50cf\u300a\u94a2\u94c1\u4fa0\u300b\u4e2dJ.A.R.V.I.S\u4e00\u6837\u529f\u80fd\u5f3a\u5927\u591a\u624d\u591a\u827a\u7684AI\u52a9\u624b\u7684\u613f\u671b\u8d8a\u6765\u8d8a\u63a5\u8fd1\u73b0\u5b9e\u3002\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u8c03\u67e5\u8fd9\u4e9b\u5148\u8fdb\u4ee3\u7406\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002", "method": "\u8bba\u6587\u4ece\u9610\u660eOS Agents\u57fa\u672c\u539f\u7406\u5f00\u59cb\uff0c\u63a2\u8ba8\u5176\u5173\u952e\u7ec4\u4ef6\uff0c\u5305\u62ec\u73af\u5883\u3001\u89c2\u5bdf\u7a7a\u95f4\u548c\u884c\u52a8\u7a7a\u95f4\uff0c\u6982\u8ff0\u5173\u952e\u80fd\u529b\u5982\u7406\u89e3\u3001\u89c4\u5212\u548c\u57fa\u51c6\uff0c\u7136\u540e\u7740\u91cd\u8003\u5bdf\u6784\u5efaOS Agents\u7684\u65b9\u6cd5\u8bba\uff0c\u96c6\u4e2d\u5728\u9886\u57df\u7279\u5b9a\u57fa\u7840\u6a21\u578b\u548c\u4ee3\u7406\u6846\u67b6\u4e0a\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u4f9b\u4e86\u6709\u5173OS Agents\u7684\u5168\u9762\u8c03\u67e5\uff0c\u6db5\u76d6\u4e86\u5173\u952e\u7ec4\u4ef6\u3001\u6784\u9020\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u6b64\u8bba\u6587\u5bf9\u64cd\u4f5c\u7cfb\u7edf\u4ee3\u7406\uff08OS Agents\uff09\u8fdb\u884c\u4e86\u5168\u9762\u8c03\u67e5\uff0c\u5305\u62ec\u57fa\u672c\u7ec4\u4ef6\u3001\u6784\u9020\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002\u5b83\u65e8\u5728\u603b\u7ed3OS Agents\u7814\u7a76\u73b0\u72b6\uff0c\u4e3a\u5b66\u672f\u63a2\u8ba8\u548c\u5de5\u4e1a\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2508.04511", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04511", "abs": "https://arxiv.org/abs/2508.04511", "authors": ["Hamed Ayoobi", "Nico Potyka", "Anna Rapberger", "Francesca Toni"], "title": "Argumentative Debates for Transparent Bias Detection [Technical Report]", "comment": null, "summary": "As the use of AI systems in society grows, addressing potential biases that\nemerge from data or are learned by models is essential to prevent systematic\ndisadvantages against specific groups. Several notions of (un)fairness have\nbeen proposed in the literature, alongside corresponding algorithmic methods\nfor detecting and mitigating unfairness, but, with very few exceptions, these\ntend to ignore transparency. Instead, interpretability and explainability are\ncore requirements for algorithmic fairness, even more so than for other\nalgorithmic solutions, given the human-oriented nature of fairness. In this\npaper, we contribute a novel interpretable, explainable method for bias\ndetection relying on debates about the presence of bias against individuals,\nbased on the values of protected features for the individuals and others in\ntheir neighbourhoods. Our method builds upon techniques from formal and\ncomputational argumentation, whereby debates result from arguing about biases\nwithin and across neighbourhoods. We provide formal, quantitative, and\nqualitative evaluations of our method, highlighting its strengths in\nperformance against baselines, as well as its interpretability and\nexplainability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f62\u5f0f\u548c\u8ba1\u7b97\u8bba\u8bc1\u6280\u672f\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u90bb\u57df\u5185\u5916\u7684\u504f\u89c1\u8fdb\u884c\u8fa9\u8bba\u6765\u68c0\u6d4b\u504f\u89c1\u3002\u4f5c\u8005\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u89e3\u91ca\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u5f62\u5f0f\u5316\u3001\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\uff0c\u4f5c\u8005\u7a81\u51fa\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "motivation": "\u5728\u793e\u4f1a\u4e2d\u4f7f\u7528AI\u7cfb\u7edf\u7684\u589e\u957f\u4e2d\uff0c\u89e3\u51b3\u6570\u636e\u4ea7\u751f\u7684\u6f5c\u5728\u504f\u89c1\u6216\u6a21\u578b\u5b66\u4e60\u7684\u504f\u89c1\u5bf9\u4e8e\u9632\u6b62\u5bf9\u7279\u5b9a\u7fa4\u4f53\u9020\u6210\u7cfb\u7edf\u6027\u52a3\u52bf\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6587\u732e\u4e2d\u63d0\u51fa\u4e86\u51e0\u79cd\u516c\u5e73\u4e0e\u4e0d\u516c\u5e73\u7684\u6982\u5ff5\uff0c\u4ee5\u53ca\u76f8\u5e94\u7684\u7b97\u6cd5\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u51cf\u8f7b\u4e0d\u516c\u5e73\uff0c\u4f46\u9664\u4e86\u5c11\u6570\u4f8b\u5916\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u4e86\u900f\u660e\u5ea6\u3002\u53ef\u89e3\u91ca\u6027\u548c\u89e3\u91ca\u6027\u5bf9\u7b97\u6cd5\u516c\u5e73\u6027\u975e\u5e38\u91cd\u8981\uff0c\u5c24\u5176\u5bf9\u4e8e\u5176\u4ed6\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\uff0c\u9274\u4e8e\u516c\u5e73\u6027\u7684\u9762\u5411\u4eba\u7c7b\u7684\u7279\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f62\u5f0f\u548c\u8ba1\u7b97\u8bba\u8bc1\u6280\u672f\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u90bb\u57df\u5185\u5916\u7684\u504f\u89c1\u8fdb\u884c\u8fa9\u8bba\u6765\u68c0\u6d4b\u504f\u89c1\u3002\u65b9\u6cd5\u5305\u62ec\u89e3\u91ca\u548c\u660e\u786e\u9884\u6d4b\u4e2a\u4f53\u548c\u5176\u90bb\u57df\u4e2d\u5176\u4ed6\u4e2a\u4f53\u7684\u53d7\u4fdd\u62a4\u7279\u5f81\u503c\uff0c\u4ee5\u8bc4\u4f30\u504f\u89c1\u7684\u5b58\u5728\u3002", "result": "\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u89e3\u91ca\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u5f62\u5f0f\u5316\u3001\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\uff0c\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u5f97\u5230\u4e86\u51f8\u663e\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53ef\u89e3\u91ca\u3001\u53ef\u89e3\u91ca\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f9d\u8d56\u4e8e\u9488\u5bf9\u4e2a\u4f53\u7684\u53d7\u4fdd\u62a4\u7279\u5f81\u503c\u548c\u5176\u90bb\u57df\u4e2d\u5176\u4ed6\u4e2a\u4f53\u7684\u504f\u89c1\u5b58\u5728\u8fdb\u884c\u8fa9\u8bba\u3002\u4f5c\u8005\u4f7f\u7528\u5f62\u5f0f\u5316\u548c\u8ba1\u7b97\u8bba\u8bc1\u6280\u672f\u6784\u5efa\u4e86\u8fd9\u4e00\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u90bb\u57df\u5185\u5916\u7684\u504f\u89c1\u8fdb\u884c\u8fa9\u8bba\u3002\u4f5c\u8005\u5bf9\u8be5\u65b9\u6cd5\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u3001\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\uff0c\u51f8\u663e\u5176\u5728\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u89e3\u91ca\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.04563", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04563", "abs": "https://arxiv.org/abs/2508.04563", "authors": ["Mei Jiang", "Houping Yue", "Bingdong Li", "Hao Hao", "Ying Qian", "Bo Jiang", "Aimin Zhou"], "title": "SID: Benchmarking Guided Instruction Capabilities in STEM Education with a Socratic Interdisciplinary Dialogues Dataset", "comment": "26 pages, 20 figures", "summary": "Fostering students' abilities for knowledge integration and transfer in\ncomplex problem-solving scenarios is a core objective of modern education, and\ninterdisciplinary STEM is a key pathway to achieve this, yet it requires expert\nguidance that is difficult to scale. While LLMs offer potential in this regard,\ntheir true capability for guided instruction remains unclear due to the lack of\nan effective evaluation benchmark. To address this, we introduce SID, the first\nbenchmark designed to systematically evaluate the higher-order guidance\ncapabilities of LLMs in multi-turn, interdisciplinary Socratic dialogues. Our\ncontributions include a large-scale dataset of 10,000 dialogue turns across 48\ncomplex STEM projects, a novel annotation schema for capturing deep pedagogical\nfeatures, and a new suite of evaluation metrics (e.g., X-SRG). Baseline\nexperiments confirm that even state-of-the-art LLMs struggle to execute\neffective guided dialogues that lead students to achieve knowledge integration\nand transfer. This highlights the critical value of our benchmark in driving\nthe development of more pedagogically-aware LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165SID\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30LLMs\u5728\u8de8\u5b66\u79d1Socratic\u5bf9\u8bdd\u4e2d\u7684\u9ad8\u9636\u6307\u5bfc\u80fd\u529b\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3001\u65b0\u9896\u6ce8\u91ca\u6a21\u5f0f\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u7814\u7a76\u53d1\u73b0\u5373\u4f7f\u6700\u5148\u8fdb\u7684LLMs\u4e5f\u96be\u4ee5\u5b9e\u73b0\u6709\u6548\u5f15\u5bfc\u5bf9\u8bdd\uff0c\u5f3a\u8c03SID\u57fa\u51c6\u5728\u63a8\u52a8\u66f4\u5177\u6559\u80b2\u610f\u8bc6\u7684LLMs\u53d1\u5c55\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u57f9\u517b\u5b66\u751f\u5728\u590d\u6742\u95ee\u9898\u89e3\u51b3\u573a\u666f\u4e2d\u8fdb\u884c\u77e5\u8bc6\u6574\u5408\u548c\u8f6c\u79fb\u7684\u80fd\u529b\u662f\u73b0\u4ee3\u6559\u80b2\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u8de8\u5b66\u79d1STEM\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u5173\u952e\u9014\u5f84\u4e4b\u4e00\uff0c\u4f46\u9700\u8981\u4e13\u5bb6\u6307\u5bfc\uff0c\u800c\u8fd9\u5728\u89c4\u6a21\u4e0a\u5f88\u96be\u5b9e\u73b0\u3002LLMs\u5728\u8fd9\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u6709\u6548\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u5b83\u4eec\u5728\u5f15\u5bfc\u6559\u5b66\u65b9\u9762\u7684\u771f\u6b63\u80fd\u529b\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u4ecb\u7ecdSID\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u8de8\u5b66\u79d1Socratic\u5bf9\u8bdd\u4e2d\u9ad8\u9636\u6307\u5bfc\u80fd\u529b\u7684\u57fa\u51c6\u3002\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5305\u62ec48\u4e2a\u590d\u6742STEM\u9879\u76ee\u768410000\u4e2a\u5bf9\u8bdd\u8f6e\u6b21\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u4e00\u79cd\u6355\u83b7\u6df1\u5c42\u6559\u80b2\u7279\u5f81\u7684\u65b0\u9896\u6ce8\u91ca\u6a21\u5f0f\u4ee5\u53ca\u4e00\u5957\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u3002\u8fdb\u884c\u4e86\u57fa\u51c6\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u5373\u4f7f\u6700\u5148\u8fdb\u7684LLMs\u4e5f\u96be\u4ee5\u6267\u884c\u6709\u6548\u7684\u5f15\u5bfc\u5bf9\u8bdd\uff0c\u5e2e\u52a9\u5b66\u751f\u5b9e\u73b0\u77e5\u8bc6\u6574\u5408\u548c\u8f6c\u79fb\u3002", "result": "\u5f15\u5165\u4e86SID\u57fa\u51c6\u8bc4\u4f30LLMs\u5728\u8de8\u5b66\u79d1Socratic\u5bf9\u8bdd\u4e2d\u7684\u9ad8\u9636\u6307\u5bfc\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684LLMs\u4e5f\u96be\u4ee5\u6709\u6548\u6267\u884c\u5f15\u5bfc\u5bf9\u8bdd\u7684\u4e8b\u5b9e\uff0c\u8bc1\u5b9e\u4e86SID\u57fa\u51c6\u5728\u63a8\u52a8\u66f4\u5177\u6559\u80b2\u610f\u8bc6\u7684LLMs\u53d1\u5c55\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u5f15\u5165SID\u57fa\u51c6\u8bc4\u4f30LLMs\u5728\u8de8\u5b66\u79d1Socratic\u5bf9\u8bdd\u4e2d\u7684\u9ad8\u9636\u6307\u5bfc\u80fd\u529b\uff0c\u8868\u660e\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684LLMs\u5728\u6267\u884c\u6709\u6548\u5f15\u5bfc\u5bf9\u8bdd\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\uff0c\u5f3a\u8c03SID\u57fa\u51c6\u5728\u63a8\u52a8\u66f4\u5177\u6559\u80b2\u610f\u8bc6\u7684LLMs\u53d1\u5c55\u4e2d\u7684\u5173\u952e\u4ef7\u503c\u3002"}}
{"id": "2508.04576", "categories": ["cs.AI", "I.2.6; I.2.7; D.2.8"], "pdf": "https://arxiv.org/pdf/2508.04576", "abs": "https://arxiv.org/abs/2508.04576", "authors": ["Yue Zhou", "Yi Chang", "Yuan Wu"], "title": "ConfProBench: A Confidence Evaluation Benchmark for MLLM-Based Process Judges", "comment": null, "summary": "Reasoning is a critical capability of multimodal large language models\n(MLLMs) for solving complex multimodal tasks, and judging the correctness of\nreasoning steps is crucial for improving this capability. Recently, MLLM-based\nprocess judges (MPJs) have been widely used to assess the correctness of\nreasoning steps in multimodal tasks. Therefore, evaluating MPJs is important\nfor identifying their limitations and guiding future improvements. However,\nexisting benchmarks for MPJs mainly focus on tasks such as step correctness\nclassification and reasoning process search, while overlooking a key aspect:\nwhether the confidence scores produced by MPJs at the step level are reliable.\nTo address this gap, we propose ConfProBench, the first comprehensive benchmark\ndesigned to systematically evaluate the reliability of step-level confidence\nscores generated by MPJs. Our benchmark constructs three types of adversarially\nperturbed reasoning steps: Synonym Substitution, Syntactic Transformation, and\nImage Perturbation, to test the robustness of MPJ confidence under\nperturbations. In addition, we introduce three novel evaluation metrics:\nConfidence Robustness Score (CRS), Confidence Sensitivity Score (CSS), and\nConfidence Calibration Score (CCS), which evaluate robustness, sensitivity, and\ncalibration, respectively. We evaluate 14 state-of-the-art MLLMs, including\nboth proprietary and open-source models. Experiments reveal limitations in\ncurrent MPJs' confidence performance and offer competitive baselines to support\nfuture research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ConfProBench\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8eMLLM\u7684\u8fc7\u7a0b\u5224\u65ad\u5668\u751f\u6210\u7684\u6b65\u7ea7\u7f6e\u4fe1\u5ea6\u5206\u6570\u7684\u53ef\u9760\u6027\u3002\u4f5c\u8005\u6784\u5efa\u4e86\u4e09\u79cd\u5bf9\u6297\u6027\u6270\u52a8\u63a8\u7406\u6b65\u9aa4\uff0c\u5e76\u5f15\u5165\u4e86\u4e09\u79cd\u65b0\u7684\u8bc4\u4f30\u5ea6\u91cf\u3002\u8bc4\u4f30\u4e8614\u79cdMLLM\uff0c\u63ed\u793a\u4e86MPJs\u5728\u7f6e\u4fe1\u5ea6\u8868\u73b0\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u8bc4\u4f30MPJs\u7684\u7f6e\u4fe1\u5ea6\u8868\u73b0\u5bf9\u786e\u5b9a\u5176\u5c40\u9650\u6027\u548c\u6307\u5bfc\u672a\u6765\u6539\u8fdb\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684MPJs\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\uff0c\u5982\u6b65\u9aa4\u6b63\u786e\u6027\u5206\u7c7b\u548c\u63a8\u7406\u8fc7\u7a0b\u641c\u7d22\uff0c\u4f46\u5ffd\u7565\u4e86\u4e00\u4e2a\u5173\u952e\u65b9\u9762\uff1aMPJs\u5728\u6b65\u9aa4\u7ea7\u522b\u4ea7\u751f\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u662f\u5426\u53ef\u9760\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e09\u79cd\u5bf9\u6297\u6027\u6270\u52a8\u63a8\u7406\u6b65\u9aa4\uff1a\u540c\u4e49\u8bcd\u66ff\u6362\u3001\u53e5\u6cd5\u8f6c\u6362\u548c\u56fe\u50cf\u6270\u52a8\uff0c\u4ee5\u6d4b\u8bd5MPJ\u5728\u6270\u52a8\u4e0b\u7684\u7f6e\u4fe1\u5ea6\u7684\u7a33\u5065\u6027\u3002\u5f15\u5165\u4e86\u4e09\u79cd\u65b0\u7684\u8bc4\u4f30\u5ea6\u91cf\uff1a\u7f6e\u4fe1\u5ea6\u7a33\u5065\u6027\u5f97\u5206\uff08CRS\uff09\u3001\u7f6e\u4fe1\u5ea6\u654f\u611f\u6027\u5f97\u5206\uff08CSS\uff09\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u5f97\u5206\uff08CCS\uff09\uff0c\u5206\u522b\u8bc4\u4f30\u7a33\u5065\u6027\u3001\u654f\u611f\u6027\u548c\u6821\u51c6\u6027\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524dMPJs\u5728\u7f6e\u4fe1\u5ea6\u8868\u73b0\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u7ade\u4e89\u6027\u57fa\u7ebf\uff0c\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86ConfProBench\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7cfb\u7edf\u8bc4\u4f30\u57fa\u4e8eMLLM\u7684\u8fc7\u7a0b\u5224\u65ad\u5668\u4ea7\u751f\u7684\u6b65\u7ea7\u7f6e\u4fe1\u5ea6\u5206\u6570\u53ef\u9760\u6027\u7684\u7efc\u5408\u57fa\u51c6\u3002\u4f5c\u8005\u8bc4\u4f30\u4e8614\u79cd\u6700\u5148\u8fdb\u7684MLLM\uff0c\u53d1\u73b0\u5f53\u524dMPJs\u5728\u7f6e\u4fe1\u5ea6\u8868\u73b0\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7ade\u4e89\u6027\u57fa\u7ebf\u4ee5\u652f\u6301\u672a\u6765\u7684\u7814\u7a76\u3002"}}
{"id": "2508.04652", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04652", "abs": "https://arxiv.org/abs/2508.04652", "authors": ["Shuo Liu", "Zeyu Liang", "Xueguang Lyu", "Christopher Amato"], "title": "LLM Collaboration With Multi-Agent Reinforcement Learning", "comment": null, "summary": "A large amount of work has been done in Multi-Agent Systems (MAS) for\nmodeling and solving problems with multiple interacting agents. However, most\nLLMs are pretrained independently and not specifically optimized for\ncoordination. Existing LLM fine-tuning frameworks rely on individual rewards,\nwhich require complex reward designs for each agent to encourage collaboration.\nTo address these challenges, we model LLM collaboration as a cooperative\nMulti-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent,\nmulti-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO),\nto solve it, building on current RL approaches for LLMs as well as MARL\ntechniques. Our experiments on LLM writing and coding collaboration demonstrate\nthat fine-tuning MAS with MAGRPO enables agents to generate high-quality\nresponses efficiently through effective cooperation. Our approach opens the\ndoor to using other MARL methods for LLMs and highlights the associated\nchallenges.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86MAGRPO\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u4ee5\u4f18\u5316\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u534f\u4f5c\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u4ea7\u751f\u9ad8\u8d28\u91cf\u7684\u54cd\u5e94\uff0c\u5c55\u793a\u4e86\u5c06MARL\u65b9\u6cd5\u7528\u4e8eLLM\u7684\u53ef\u884c\u6027\u548c\u76f8\u5173\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5fae\u8c03\u6846\u67b6\u4f9d\u8d56\u4e8e\u4e2a\u4f53\u5956\u52b1\uff0c\u9700\u8981\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u8bbe\u8ba1\u590d\u6742\u7684\u5956\u52b1\u4ee5\u4fc3\u8fdb\u534f\u4f5c\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u7814\u7a76\u5c06LLM\u7684\u534f\u4f5c\u5efa\u6a21\u4e3a\u4e00\u4e2a\u5408\u4f5c\u5f0fMARL\u95ee\u9898\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u540d\u4e3aMAGRPO\u7684\u7b97\u6cd5\u6765\u89e3\u51b3\u8be5\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u6784\u5efa\u5728\u5f53\u524d\u7684LLM\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u548cMARL\u6280\u672f\u57fa\u7840\u4e0a\u3002", "result": "\u901a\u8fc7\u5728LLM\u5199\u4f5c\u548c\u7f16\u7801\u534f\u4f5c\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc1\u660e\uff0cMAGRPO\u5bf9MAS\u8fdb\u884c\u5fae\u8c03\u53ef\u4ee5\u6709\u6548\u5730\u4fc3\u4f7f\u667a\u80fd\u4f53\u901a\u8fc7\u6709\u6548\u534f\u4f5c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u54cd\u5e94\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u79f0\u4e3aMAGRPO\uff0c\u7528\u4e8e\u4f18\u5316\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u534f\u4f5c\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4f7f\u7528MAGRPO\u5bf9\u591a\u4e2aLLM\u8fdb\u884c\u5fae\u8c03\u53ef\u4ee5\u901a\u8fc7\u6709\u6548\u534f\u4f5c\u4ea7\u751f\u9ad8\u8d28\u91cf\u7684\u54cd\u5e94\u3002\u7814\u7a76\u5c55\u793a\u4e86\u5c06MARL\u65b9\u6cd5\u7528\u4e8eLLM\u7684\u53ef\u884c\u6027\uff0c\u5e76\u7a81\u51fa\u4e86\u76f8\u5173\u6311\u6218\u3002"}}
{"id": "2508.04700", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.04700", "abs": "https://arxiv.org/abs/2508.04700", "authors": ["Zeyi Sun", "Ziyu Liu", "Yuhang Zang", "Yuhang Cao", "Xiaoyi Dong", "Tong Wu", "Dahua Lin", "Jiaqi Wang"], "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience", "comment": "Code at https://github.com/SunzeY/SEAgent", "summary": "Repurposing large vision-language models (LVLMs) as computer use agents\n(CUAs) has led to substantial breakthroughs, primarily driven by human-labeled\ndata. However, these models often struggle with novel and specialized software,\nparticularly in scenarios lacking human annotations. To address this challenge,\nwe propose SEAgent, an agentic self-evolving framework enabling CUAs to\nautonomously evolve through interactions with unfamiliar software.\nSpecifically, SEAgent empowers computer-use agents to autonomously master novel\nsoftware environments via experiential learning, where agents explore new\nsoftware, learn through iterative trial-and-error, and progressively tackle\nauto-generated tasks organized from simple to complex. To achieve this goal, we\ndesign a World State Model for step-wise trajectory assessment, along with a\nCurriculum Generator that generates increasingly diverse and challenging tasks.\nThe agent's policy is updated through experiential learning, comprised of\nadversarial imitation of failure actions and Group Relative Policy Optimization\n(GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist\ntraining strategy that integrates individual experiential insights from\nspecialist agents, facilitating the development of a stronger generalist CUA\ncapable of continuous autonomous evolution. This unified agent ultimately\nachieves performance surpassing ensembles of individual specialist agents on\ntheir specialized software. We validate the effectiveness of SEAgent across\nfive novel software environments within OS-World. Our approach achieves a\nsignificant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a\ncompetitive open-source CUA, i.e., UI-TARS.", "AI": {"tldr": "SEAgent\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u4e3b\u6f14\u5316\u6846\u67b6\uff0c\u4f7f\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u80fd\u591f\u901a\u8fc7\u7ecf\u9a8c\u5b66\u4e60\u81ea\u4e3b\u638c\u63e1\u65b0\u9896\u8f6f\u4ef6\u73af\u5883\uff0c\u5e76\u5728\u591a\u4e2a\u65b0\u9896\u8f6f\u4ef6\u73af\u5883\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\u7387\u63d0\u5347\u3002", "motivation": "LVLMs\u7528\u4f5cCUAs\u5728\u4f7f\u7528\u4eba\u5de5\u6807\u8bb0\u6570\u636e\u65f6\u53d6\u5f97\u91cd\u5927\u7a81\u7834\uff0c\u4f46\u5728\u7f3a\u4e4f\u4eba\u7c7b\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u6a21\u578b\u901a\u5e38\u5728\u65b0\u9896\u548c\u4e13\u4e1a\u5316\u8f6f\u4ef6\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u63d0\u51faSEAgent\uff0c\u901a\u8fc7\u4e0e\u964c\u751f\u8f6f\u4ef6\u7684\u4ea4\u4e92\u4f7fCUAs\u80fd\u591f\u81ea\u4e3b\u6f14\u5316\u3002", "method": "SEAgent\u8bbe\u8ba1\u4e86\u4e16\u754c\u72b6\u6001\u6a21\u578b\u7528\u4e8e\u8bc4\u4f30\u6b65\u9aa4\u8f68\u8ff9\uff0c\u4ee5\u53ca\u8bfe\u7a0b\u751f\u6210\u5668\u7528\u4e8e\u751f\u6210\u8d8a\u6765\u8d8a\u591a\u6837\u5316\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002\u4ee3\u7406\u7684\u7b56\u7565\u901a\u8fc7\u7ecf\u9a8c\u5b66\u4e60\u8fdb\u884c\u66f4\u65b0\uff0c\u5305\u62ec\u5bf9\u5931\u8d25\u52a8\u4f5c\u7684\u5bf9\u6297\u6027\u6a21\u4eff\u548c\u5bf9\u6210\u529f\u52a8\u4f5c\u7684\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u4ece\u4e13\u5bb6\u5230\u901a\u624d\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u6574\u5408\u4e86\u6765\u81ea\u4e13\u4e1a\u4ee3\u7406\u7684\u4e2a\u4f53\u7ecf\u9a8c\u89c1\u89e3\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5f3a\u7684\u901a\u624dCUA\u7684\u53d1\u5c55\u3002", "result": "SEAgent\u5728OS-World\u7684\u4e94\u4e2a\u65b0\u9896\u8f6f\u4ef6\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5c06\u6210\u529f\u7387\u4ece11.3%\u63d0\u9ad8\u523034.5%\uff0c\u8f83\u7ade\u4e89\u6027\u5f00\u6e90CUA UI-TARS\u6709\u7740\u663e\u8457\u7684\u63d0\u5347\u3002", "conclusion": "SEAgent\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u4e3b\u6f14\u5316\u6846\u67b6\uff0c\u4f7f\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u80fd\u591f\u81ea\u4e3b\u638c\u63e1\u65b0\u9896\u8f6f\u4ef6\u73af\u5883\uff0c\u4ece\u800c\u5728\u4e94\u4e2a\u65b0\u9896\u8f6f\u4ef6\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6210\u529f\u7387\u63d0\u9ad823.2%\u3002"}}
