{"id": "2509.00058", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00058", "abs": "https://arxiv.org/abs/2509.00058", "authors": ["Eric Zhang", "Li Wei", "Sarah Chen", "Michael Wang"], "title": "A Comparative Study of Controllability, Explainability, and Performance in Dysfluency Detection Models", "comment": null, "summary": "Recent advances in dysfluency detection have introduced a variety of modeling\nparadigms, ranging from lightweight object-detection inspired networks\n(YOLOStutter) to modular interpretable frameworks (UDM). While performance on\nbenchmark datasets continues to improve, clinical adoption requires more than\naccuracy: models must be controllable and explainable. In this paper, we\npresent a systematic comparative analysis of four representative\napproaches--YOLO-Stutter, FluentNet, UDM, and SSDM--along three dimensions:\nperformance, controllability, and explainability. Through comprehensive\nevaluation on multiple datasets and expert clinician assessment, we find that\nYOLO-Stutter and FluentNet provide efficiency and simplicity, but with limited\ntransparency; UDM achieves the best balance of accuracy and clinical\ninterpretability; and SSDM, while promising, could not be fully reproduced in\nour experiments. Our analysis highlights the trade-offs among competing\napproaches and identifies future directions for clinically viable dysfluency\nmodeling. We also provide detailed implementation insights and practical\ndeployment considerations for each approach.", "AI": {"tldr": "\u672c\u6587\u5bf9\u56db\u79cd\u4ee3\u8868\u6027\u5931\u8bed\u75c7\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u6bd4\u8f83\u5206\u6790\uff0c\u53d1\u73b0UDM\u5728\u7cbe\u5ea6\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002YOLO-Stutter\u548cFluentNet\u63d0\u4f9b\u4e86\u6548\u7387\u548c\u7b80\u5355\u6027\uff0c\u4f46\u900f\u660e\u5ea6\u6709\u9650\uff1bSSDM\u6709\u6f5c\u529b\u4f46\u65e0\u6cd5\u5b8c\u5168\u590d\u73b0\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u65b9\u6cd5\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u4e34\u5e8a\u53ef\u884c\u7684\u5931\u8bed\u75c7\u5efa\u6a21\u6307\u660e\u4e86\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u8fd1\u5e74\u6765\u5931\u8bed\u75c7\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u4e34\u5e8a\u5e94\u7528\u9700\u8981\u4e0d\u4ec5\u4ec5\u662f\u51c6\u786e\u6027\uff0c\u8fd8\u9700\u8981\u6a21\u578b\u5177\u6709\u53ef\u63a7\u6027\u548c\u89e3\u91ca\u6027\u3002\u672c\u6587\u65e8\u5728\u5bf9\u56db\u79cd\u4ee3\u8868\u6027\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u63d0\u4f9b\u672a\u6765\u4e34\u5e8a\u53ef\u884c\u7684\u5931\u8bed\u75c7\u5efa\u6a21\u65b9\u5411\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u5206\u6790", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u548c\u4e13\u4e1a\u4e34\u5e8a\u8bc4\u4f30\uff0c\u53d1\u73b0UDM\u5728\u7cbe\u5ea6\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\u3002\u6b64\u5916\uff0cYOLO-Stutter\u548cFluentNet\u63d0\u4f9b\u4e86\u6548\u7387\u548c\u7b80\u5355\u6027\uff0c\u4f46\u900f\u660e\u5ea6\u6709\u9650\uff1bSSDM\u867d\u6709\u524d\u666f\uff0c\u4f46\u5728\u5b9e\u9a8c\u4e2d\u65e0\u6cd5\u5b8c\u5168\u590d\u73b0\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5bf9\u56db\u79cd\u4ee3\u8868\u6027\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u5206\u6790\uff0c\u53d1\u73b0\u5728\u6027\u80fd\u3001\u53ef\u63a7\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\uff0cUDM\u5728\u7cbe\u5ea6\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\u3002\u53e6\u5916\uff0cYOLO-Stutter\u548cFluentNet\u63d0\u4f9b\u4e86\u6548\u7387\u548c\u7b80\u5355\u6027\uff0c\u4f46\u900f\u660e\u5ea6\u6709\u9650\uff1bSSDM\u867d\u6709\u524d\u666f\uff0c\u4f46\u5728\u5b9e\u9a8c\u4e2d\u65e0\u6cd5\u5b8c\u5168\u590d\u73b0\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u7ade\u4e89\u65b9\u6cd5\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u4e3a\u4e34\u5e8a\u53ef\u884c\u7684\u5931\u8bed\u75c7\u5efa\u6a21\u6307\u660e\u4e86\u672a\u6765\u65b9\u5411\u3002\u6b64\u5916\uff0c\u5bf9\u6bcf\u79cd\u65b9\u6cd5\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5b9e\u73b0\u89c1\u89e3\u548c\u5b9e\u9645\u90e8\u7f72\u6ce8\u610f\u4e8b\u9879\u3002"}}
{"id": "2509.00072", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00072", "abs": "https://arxiv.org/abs/2509.00072", "authors": ["Terry Jingchen Zhang", "Gopal Dev", "Ning Wang", "Nicole Ni", "Wenyuan Jiang", "Yinya Huang", "Bernhard Sch\u00f6lkopf", "Mrinmaya Sachan", "Zhijing Jin"], "title": "Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy Against Benchmark Contamination", "comment": "Code and Dataset: https://github.com/TerryJCZhang/BeyondMemorization", "summary": "Capability evaluation of large language models (LLMs) is increasingly\nshadowed by rising concerns of data contamination that cast doubts on whether\nstatic benchmarks measure genuine reasoning or mere memorization. We present an\nempirical study using an infinitely scalable framework to synthesize\nresearch-level QA directly from arXiv papers, harnessing the natural temporal\nstructure of research publications where performance decay after knowledge\ncutoffs may indicate potential contamination. We evaluated 4 frontier model\nrepresented by 2 models of different knowledge cutoff dates per family on 1,643\nmulti-step reasoning questions synthesized from 20,277 arXiv papers stratified\nover 26 months, covering at least 6 months before and after all cutoff dates.\nOur results consistently showed a lack of significant performance decay near\nknowledge cutoff dates for models of various sizes, developers, and release\ndates. We further performed a comparative analysis with previous longitudinal\nstudies that reported significant post-cutoff performance decay using directly\nretrieved questions based on public data. we hypothesize that the multi-step\nreasoning required by our synthesis pipeline offered additional complexity that\ngoes deeper than shallow memorization, which effectively serves a mitigation\nstrategy against benchmark contamination. We fully open source our code and\ndataset to aid reproducibility and advocate for a paradigm shift that\nprioritize reasoning-driven synthesis to construct benchmarks over simply\ncollecting newly released questions periodically.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u65e0\u9650\u53ef\u6269\u5c55\u7684\u6846\u67b6\u5408\u6210\u7814\u7a76\u7ea7\u522b\u7684\u95ee\u7b54\uff0c\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\u6a21\u578b\u5728\u4e0d\u540c\u77e5\u8bc6\u622a\u65ad\u65e5\u671f\u9644\u8fd1\u6ca1\u6709\u660e\u663e\u6027\u80fd\u4e0b\u964d\uff0c\u63a8\u6d4b\u591a\u6b65\u63a8\u7406\u63d0\u4f9b\u4e86\u6df1\u5c42\u6b21\u7684\u590d\u6742\u6027\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u57fa\u51c6\u6d4b\u8bd5\u7684\u6c61\u67d3\u3002\u5f00\u653e\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4ee5\u652f\u6301\u53ef\u91cd\u73b0\u6027\uff0c\u5e76\u5021\u5bfc\u4f18\u5148\u63a8\u7406\u9a71\u52a8\u7684\u5408\u6210\u6784\u5efa\u57fa\u51c6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u8bc4\u4f30\u53d7\u5230\u6570\u636e\u6c61\u67d3\u7684\u5f71\u54cd\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u9759\u6001\u57fa\u51c6\u662f\u5426\u6d4b\u91cf\u4e86\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u7814\u7a76\u6a21\u578b\u5728\u77e5\u8bc6\u622a\u65ad\u65e5\u671f\u9644\u8fd1\u7684\u8868\u73b0\uff0c\u6765\u7814\u7a76\u6f5c\u5728\u7684\u6570\u636e\u6c61\u67d3\u60c5\u51b5\u3002", "method": "\u4f7f\u7528\u4e00\u4e2a\u53ef\u65e0\u9650\u6269\u5c55\u7684\u6846\u67b6\u5408\u6210\u7814\u7a76\u7ea7\u522b\u7684\u95ee\u7b54\uff0c\u4ece\u800c\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff0c\u7136\u540e\u4e0e\u4ee5\u5f80\u7814\u7a76\u8fdb\u884c\u6bd4\u8f83\uff0c\u63a2\u8ba8\u6a21\u578b\u5728\u77e5\u8bc6\u622a\u65ad\u65e5\u671f\u9644\u8fd1\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u6ca1\u6709\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u77e5\u8bc6\u622a\u65ad\u65e5\u671f\u9644\u8fd1\u7684\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u8ba4\u4e3a\u591a\u6b65\u63a8\u7406\u7684\u7efc\u5408\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u6df1\u5c42\u6b21\u7684\u590d\u6742\u6027\uff0c\u6709\u6548\u51cf\u5c11\u57fa\u51c6\u6d4b\u8bd5\u7684\u6c61\u67d3\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u4f7f\u7528\u4e00\u4e2a\u53ef\u65e0\u9650\u6269\u5c55\u7684\u6846\u67b6\u4ecearXiv\u8bba\u6587\u76f4\u63a5\u5408\u6210\u7814\u7a76\u7ea7\u522b\u7684\u95ee\u7b54\uff0c\u8bc4\u4f30\u4e864\u4e2a\u524d\u6cbf\u6a21\u578b\u57281,643\u4e2a\u591a\u6b65\u63a8\u7406\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e0d\u540c\u5927\u5c0f\u3001\u5f00\u53d1\u8005\u548c\u53d1\u5e03\u65e5\u671f\u7684\u6a21\u578b\u4e2d\uff0c\u9760\u8fd1\u77e5\u8bc6\u622a\u65ad\u65e5\u671f\u6ca1\u6709\u660e\u663e\u7684\u6027\u80fd\u4e0b\u964d\u3002\u901a\u8fc7\u4e0e\u4ee5\u5f80\u7eb5\u5411\u7814\u7a76\u8fdb\u884c\u6bd4\u8f83\uff0c\u6211\u4eec\u8ba4\u4e3a\u6211\u4eec\u7684\u7efc\u5408\u7814\u7a76\u63d0\u4f9b\u4e86\u6bd4\u80a4\u6d45\u8bb0\u5fc6\u66f4\u6df1\u5c42\u6b21\u7684\u591a\u6b65\u63a8\u7406\uff0c\u6709\u6548\u5730\u51cf\u5c11\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u6c61\u67d3\u3002\u6211\u4eec\u5f00\u653e\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4ee5\u652f\u6301\u53ef\u91cd\u73b0\u6027\uff0c\u5e76\u63d0\u5021\u4f18\u5148\u8003\u8651\u57fa\u4e8e\u63a8\u7406\u9a71\u52a8\u7684\u5408\u6210\u6784\u5efa\u57fa\u51c6\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5b9a\u671f\u6536\u96c6\u65b0\u53d1\u5e03\u7684\u95ee\u9898\u3002"}}
{"id": "2509.00074", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00074", "abs": "https://arxiv.org/abs/2509.00074", "authors": ["C\u00e9dric Colas", "Tracey Mills", "Ben Prystawski", "Michael Henry Tessler", "Noah Goodman", "Jacob Andreas", "Joshua Tenenbaum"], "title": "Language and Experience: A Computational Model of Social Learning in Complex Tasks", "comment": null, "summary": "The ability to combine linguistic guidance from others with direct experience\nis central to human development, enabling safe and rapid learning in new\nenvironments. How do people integrate these two sources of knowledge, and how\nmight AI systems? We present a computational framework that models social\nlearning as joint probabilistic inference over structured, executable world\nmodels given sensorimotor and linguistic data. We make this possible by turning\na pretrained language model into a probabilistic model of how humans share\nadvice conditioned on their beliefs, allowing our agents both to generate\nadvice for others and to interpret linguistic input as evidence during Bayesian\ninference. Using behavioral experiments and simulations across 10 video games,\nwe show how linguistic guidance can shape exploration and accelerate learning\nby reducing risky interactions and speeding up key discoveries in both humans\nand models. We further explore how knowledge can accumulate across generations\nthrough iterated learning experiments and demonstrate successful knowledge\ntransfer between humans and models -- revealing how structured,\nlanguage-compatible representations might enable human-machine collaborative\nlearning.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u6a21\u62df\u793e\u4f1a\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u751f\u6210\u5efa\u8bae\u548c\u89e3\u91ca\u8bed\u8a00\u8f93\u5165\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u8bed\u8a00\u6307\u5bfc\u5bf9\u52a0\u901f\u5b66\u4e60\u548c\u77e5\u8bc6\u4f20\u9012\u7684\u91cd\u8981\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4eba\u4eec\u5982\u4f55\u6574\u5408\u4ed6\u4eba\u7684\u8bed\u8a00\u6307\u5bfc\u548c\u76f4\u63a5\u7ecf\u9a8c\uff0c\u5e76\u601d\u8003\u4e86AI\u7cfb\u7edf\u5982\u4f55\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u65e8\u5728\u6a21\u62df\u793e\u4f1a\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63a2\u8ba8\u8bed\u8a00\u6307\u5bfc\u5bf9\u5b66\u4e60\u548c\u77e5\u8bc6\u4f20\u9012\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5982\u4f55\u5b9e\u73b0\u4eba\u673a\u534f\u540c\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u6a21\u62df\u793e\u4f1a\u5b66\u4e60\u4e3a\u5bf9\u7ed3\u6784\u5316\u53ef\u6267\u884c\u4e16\u754c\u6a21\u578b\u7684\u8054\u5408\u6982\u7387\u63a8\u7406\uff0c\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8f6c\u53d8\u4e3a\u6982\u7387\u6a21\u578b\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u751f\u6210\u5efa\u8bae\u548c\u5728\u8d1d\u53f6\u65af\u63a8\u7406\u4e2d\u89e3\u91ca\u8bed\u8a00\u8f93\u5165\u3002\u901a\u8fc7\u884c\u4e3a\u5b9e\u9a8c\u548c\u6a21\u62df\u572810\u4e2a\u89c6\u9891\u6e38\u620f\u4e2d\u5c55\u793a\u4e86\u8bed\u8a00\u6307\u5bfc\u5982\u4f55\u5851\u9020\u63a2\u7d22\u548c\u52a0\u901f\u5b66\u4e60\u8fc7\u7a0b\u7684\u7ed3\u679c\u3002\u8fdb\u884c\u4e86\u8fed\u4ee3\u5b66\u4e60\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u77e5\u8bc6\u5982\u4f55\u5728\u4eba\u7c7b\u548c\u6a21\u578b\u4e4b\u95f4\u6210\u529f\u8f6c\u79fb\u3002", "result": "\u5b9e\u9a8c\u548c\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8bed\u8a00\u6307\u5bfc\u6709\u52a9\u4e8e\u5851\u9020\u63a2\u7d22\u884c\u4e3a\u3001\u52a0\u901f\u5b66\u4e60\u8fc7\u7a0b\uff1b\u8fed\u4ee3\u5b66\u4e60\u5b9e\u9a8c\u5c55\u793a\u4e86\u77e5\u8bc6\u5728\u4eba\u7c7b\u548c\u6a21\u578b\u4e4b\u95f4\u6210\u529f\u8f6c\u79fb\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u5c06\u793e\u4f1a\u5b66\u4e60\u5efa\u6a21\u4e3a\u5bf9\u7ed3\u6784\u5316\u53ef\u6267\u884c\u4e16\u754c\u6a21\u578b\u7684\u8054\u5408\u6982\u7387\u63a8\u7406\uff0c\u901a\u8fc7\u5904\u7406\u6765\u81ea\u611f\u77e5\u8fd0\u52a8\u548c\u8bed\u8a00\u6570\u636e\uff0c\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8f6c\u53d8\u4e3a\u4e00\u4e2a\u6982\u7387\u6a21\u578b\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u4e3a\u4ed6\u4eba\u751f\u6210\u5efa\u8bae\u5e76\u5728\u8d1d\u53f6\u65af\u63a8\u7406\u8fc7\u7a0b\u4e2d\u89e3\u91ca\u8bed\u8a00\u8f93\u5165\u3002\u5b9e\u9a8c\u548c\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u8bed\u8a00\u6307\u5bfc\u53ef\u4ee5\u5851\u9020\u63a2\u7d22\u884c\u4e3a\uff0c\u52a0\u901f\u5b66\u4e60\u8fc7\u7a0b\uff0c\u964d\u4f4e\u98ce\u9669\u4ea4\u4e92\uff0c\u5e76\u5728\u4eba\u7c7b\u548c\u6a21\u578b\u4e2d\u52a0\u5feb\u5173\u952e\u53d1\u73b0\u7684\u901f\u5ea6\u3002\u901a\u8fc7\u53cd\u590d\u5b66\u4e60\u5b9e\u9a8c\uff0c\u63a2\u8ba8\u77e5\u8bc6\u5982\u4f55\u5728\u4e16\u4ee3\u95f4\u79ef\u7d2f\uff0c\u5e76\u5c55\u793a\u4e86\u4eba\u7c7b\u548c\u6a21\u578b\u4e4b\u95f4\u6210\u529f\u7684\u77e5\u8bc6\u8f6c\u79fb\uff0c\u63ed\u793a\u4e86\u7ed3\u6784\u5316\u3001\u4e0e\u8bed\u8a00\u517c\u5bb9\u7684\u8868\u5f81\u662f\u5982\u4f55\u4fc3\u8fdb\u4eba\u673a\u534f\u540c\u5b66\u4e60\u7684\u3002"}}
{"id": "2509.00079", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00079", "abs": "https://arxiv.org/abs/2509.00079", "authors": ["Andrew G. A. Correa", "Ana C. H de Matos"], "title": "Entropy-Guided Loop: Achieving Reasoning through Uncertainty-Aware Generation", "comment": "9 pages, 2 figures, 4 tables", "summary": "Reasoning models often outperform smaller models but at 3--5$\\times$ higher\ncost and added latency. We present entropy-guided refinement: a lightweight,\ntest-time loop that uses token-level uncertainty to trigger a single, targeted\nrefinement pass. We extract logprobs, compute Shannon entropy on top-$k$\nalternatives, and apply a simple OR-logic trigger over perplexity, maximum\ntoken entropy, and low-confidence-token count. Unlike approaches that use\nentropy only for measurement or decoding, we pass a compact uncertainty report\n(tokens, confidences, alternatives, context) back to the model to guide\ncorrective edits. On representative technical queries across reasoning,\nmathematics, and code generation tasks, a small model with our loop approaches\n95\\% of a reference reasoning model's quality at approximately one-third of the\ncost. The method achieves selective refinement on ~31\\% of responses while\nimproving accuracy by 16 percentage points over single-pass inference. We\ndemonstrate that this uncertainty-aware loop provides an effective middle\nground between single-pass inference and expensive reasoning chains, making it\npractical for production deployments where both quality and cost matter.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u71b5\u5f15\u5bfc\u7684\u8f7b\u91cf\u7ea7\u6d4b\u8bd5\u65f6\u95f4\u5faa\u73af\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u89e6\u53d1\u6709\u9488\u5bf9\u6027\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\u5728\u8d28\u91cf\u548c\u6210\u672c\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u751f\u4ea7\u90e8\u7f72\u4e2d\u5177\u6709\u5f88\u597d\u7684\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\uff0c\u5c3d\u7ba1\u63a8\u7406\u6a21\u578b\u901a\u5e38\u4f18\u4e8e\u8f83\u5c0f\u7684\u6a21\u578b\uff0c\u4f46\u5176\u6210\u672c\u548c\u5ef6\u8fdf\u8f83\u9ad8\u3002\u4f5c\u8005\u8bd5\u56fe\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u71b5\u5f15\u5bfc\u7684\u8f7b\u91cf\u7ea7\u6d4b\u8bd5\u65f6\u95f4\u5faa\u73af\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5b9e\u73b0\u5c0f\u578b\u6a21\u578b\u5728\u8d28\u91cf\u548c\u6210\u672c\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "method": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u71b5\u5f15\u5bfc\u7684\u8f7b\u91cf\u7ea7\u6d4b\u8bd5\u65f6\u95f4\u5faa\u73af\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6807\u8bb0\u7ea7\u522b\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u89e6\u53d1\u6709\u9488\u5bf9\u6027\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u63d0\u53d6\u5bf9\u6570\u6982\u7387\uff0c\u8ba1\u7b97Top-k\u66ff\u4ee3\u54c1\u7684\u9999\u519c\u71b5\uff0c\u5e76\u901a\u8fc7\u5bf9\u56f0\u60d1\u5ea6\u3001\u6700\u5927\u6807\u8bb0\u71b5\u548c\u4f4e\u7f6e\u4fe1\u6807\u8bb0\u8ba1\u6570\u7684\u7b80\u5355OR\u903b\u8f91\u89e6\u53d1\u6765\u751f\u6210\u7d27\u51d1\u7684\u4e0d\u786e\u5b9a\u6027\u62a5\u544a\uff0c\u7136\u540e\u5c06\u8be5\u4e0d\u786e\u5b9a\u6027\u62a5\u544a\u4f20\u56de\u6a21\u578b\u4ee5\u6307\u5bfc\u4fee\u6b63\u7f16\u8f91\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4ee3\u8868\u6027\u7684\u6280\u672f\u67e5\u8be2\u4e2d\u5b9e\u73b0\u5c0f\u578b\u6a21\u578b\u5728\u5927\u7ea6\u4e09\u5206\u4e4b\u4e00\u7684\u6210\u672c\u4e0b\u8fbe\u5230\u53c2\u8003\u63a8\u7406\u6a21\u578b\u8d28\u91cf\u768495\uff05\u3002\u8be5\u65b9\u6cd5\u5728\u5927\u7ea631\uff05\u7684\u54cd\u5e94\u4e2d\u5b9e\u73b0\u9009\u62e9\u6027\u4f18\u5316\uff0c\u540c\u65f6\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e8616\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u71b5\u5f15\u5bfc\u7684\u8f7b\u91cf\u7ea7\u6d4b\u8bd5\u65f6\u95f4\u5faa\u73af\uff0c\u5229\u7528\u6807\u8bb0\u7ea7\u522b\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u89e6\u53d1\u5355\u4e2a\u6709\u9488\u5bf9\u6027\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u4ece\u800c\u5728\u4ee3\u8868\u6027\u7684\u6280\u672f\u67e5\u8be2\u4e2d\u5b9e\u73b0\u5c0f\u578b\u6a21\u578b\u5728\u5927\u7ea6\u4e09\u5206\u4e4b\u4e00\u7684\u6210\u672c\u4e0b\u8fbe\u5230\u53c2\u8003\u63a8\u7406\u6a21\u578b\u8d28\u91cf\u768495\uff05\u3002\u8be5\u65b9\u6cd5\u5728\u5927\u7ea631\uff05\u7684\u54cd\u5e94\u4e2d\u5b9e\u73b0\u9009\u62e9\u6027\u4f18\u5316\uff0c\u540c\u65f6\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e8616\u4e2a\u767e\u5206\u70b9\u3002\u5728\u5355\u6b21\u63a8\u7406\u65b9\u6cd5\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u4e3a\u751f\u4ea7\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6298\u8877\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u8d28\u91cf\u548c\u6210\u672c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002"}}
{"id": "2509.00080", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00080", "abs": "https://arxiv.org/abs/2509.00080", "authors": ["David Freire-Obreg\u00f3n"], "title": "Wrong Face, Wrong Move: The Social Dynamics of Emotion Misperception in Agent-Based Models", "comment": "Accepted for presentation at the International Workshop on\n  Agent-Based Modelling of Human Behaviour (ABMHuB 2025)", "summary": "The ability of humans to detect and respond to others' emotions is\nfundamental to understanding social behavior. Here, agents are instantiated\nwith emotion classifiers of varying accuracy to study the impact of perceptual\naccuracy on emergent emotional and spatial behavior. Agents are visually\nrepresented with face photos from the KDEF database and endowed with one of\nthree classifiers trained on the JAFFE (poor), CK+ (medium), or KDEF (high)\ndatasets. Agents communicate locally on a 2D toroidal lattice, perceiving\nneighbors' emotional state based on their classifier and responding with\nmovement toward perceived positive emotions and away from perceived negative\nemotions. Note that the agents respond to perceived, instead of ground-truth,\nemotions, introducing systematic misperception and frustration. A battery of\nexperiments is carried out on homogeneous and heterogeneous populations and\nscenarios with repeated emotional shocks. Results show that low-accuracy\nclassifiers on the part of the agent reliably result in diminished trust,\nemotional disintegration into sadness, and disordered social organization. By\ncontrast, the agent that develops high accuracy develops hardy emotional\nclusters and resilience to emotional disruptions. Even in emotionally neutral\nscenarios, misperception is enough to generate segregation and disintegration\nof cohesion. These findings underscore the fact that biases or imprecision in\nemotion recognition may significantly warp social processes and disrupt\nemotional integration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u611f\u77e5\u51c6\u786e\u6027\u5bf9\u60c5\u7eea\u548c\u7a7a\u95f4\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u4f4e\u51c6\u786e\u6027\u5206\u7c7b\u5668\u4f1a\u5bfc\u81f4\u4fe1\u4efb\u51cf\u5c11\u3001\u60c5\u7eea\u89e3\u4f53\u548c\u793e\u4f1a\u7ec4\u7ec7\u6df7\u4e71\uff0c\u9ad8\u51c6\u786e\u6027\u5206\u7c7b\u5668\u5219\u4fc3\u8fdb\u60c5\u7eea\u805a\u96c6\u548c\u5bf9\u60c5\u7eea\u5e72\u6270\u7684\u62b5\u6297\u80fd\u529b\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u60c5\u7eea\u8bc6\u522b\u4e2d\u7684\u504f\u89c1\u6216\u4e0d\u51c6\u786e\u6027\u53ef\u80fd\u626d\u66f2\u793e\u4f1a\u8fc7\u7a0b\u5e76\u7834\u574f\u60c5\u611f\u6574\u5408\u3002", "motivation": "\u4eba\u7c7b\u5bf9\u4e8e\u611f\u77e5\u548c\u56de\u5e94\u4ed6\u4eba\u60c5\u7eea\u7684\u80fd\u529b\u662f\u7406\u89e3\u793e\u4f1a\u884c\u4e3a\u7684\u57fa\u7840\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u611f\u77e5\u51c6\u786e\u6027\u5bf9\u60c5\u7eea\u548c\u7a7a\u95f4\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4ee5\u63ed\u793a\u60c5\u7eea\u8bc6\u522b\u4e2d\u7684\u504f\u89c1\u6216\u4e0d\u51c6\u786e\u6027\u53ef\u80fd\u5e26\u6765\u7684\u793e\u4f1a\u5f71\u54cd\u3002", "method": "\u5b9e\u9a8c\u4e2d\uff0c\u7814\u7a76\u8005\u901a\u8fc7\u5728\u4ee3\u7406\u4eba\u4e2d\u4f7f\u7528\u4e0d\u540c\u51c6\u786e\u6027\u7684\u60c5\u7eea\u5206\u7c7b\u5668\u6765\u7814\u7a76\u611f\u77e5\u51c6\u786e\u6027\u5bf9\u60c5\u7eea\u548c\u7a7a\u95f4\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u4ee3\u7406\u4eba\u6839\u636e\u5176\u5206\u7c7b\u5668\u5728JAFFE\uff08\u4f4e\uff09\u3001CK+\uff08\u4e2d\uff09\u3001\u6216KDEF\uff08\u9ad8\uff09\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u57282D\u73af\u5f62\u6676\u683c\u4e0a\u76f8\u4e92\u901a\u4fe1\u3002\u4ed6\u4eec\u6839\u636e\u611f\u77e5\u5230\u7684\u4ed6\u4eba\u60c5\u7eea\u72b6\u6001\u505a\u51fa\u884c\u4e3a\u53cd\u5e94\uff0c\u5411\u611f\u77e5\u5230\u7684\u79ef\u6781\u60c5\u7eea\u79fb\u52a8\uff0c\u8fdc\u79bb\u8d1f\u9762\u60c5\u7eea\u3002\u7814\u7a76\u8fd8\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5173\u4e8e\u540c\u8d28\u548c\u5f02\u8d28\u7fa4\u4f53\u4ee5\u53ca\u91cd\u590d\u60c5\u7eea\u51b2\u51fb\u7684\u5b9e\u9a8c\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\u53d1\u73b0\uff0c\u4f4e\u51c6\u786e\u6027\u5206\u7c7b\u5668\u4f1a\u5bfc\u81f4\u4fe1\u4efb\u51cf\u5c11\u3001\u60c5\u7eea\u89e3\u4f53\u548c\u793e\u4f1a\u7ec4\u7ec7\u6df7\u4e71\uff0c\u800c\u9ad8\u51c6\u786e\u6027\u5206\u7c7b\u5668\u5219\u4f1a\u4fc3\u8fdb\u60c5\u7eea\u805a\u96c6\u548c\u5bf9\u60c5\u7eea\u5e72\u6270\u7684\u62b5\u6297\u80fd\u529b\u3002\u5373\u4f7f\u5728\u60c5\u611f\u4e2d\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u9519\u8bef\u611f\u77e5\u4e5f\u8db3\u4ee5\u4ea7\u751f\u5206\u79bb\u548c\u793e\u4f1a\u51dd\u805a\u529b\u7684\u89e3\u4f53\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u611f\u77e5\u51c6\u786e\u6027\u5bf9\u4e2a\u4f53\u5bf9\u4ed6\u4eba\u60c5\u7eea\u7684\u7406\u89e3\u548c\u7a7a\u95f4\u884c\u4e3a\u4ea7\u751f\u91cd\u8981\u5f71\u54cd\u3002\u4f4e\u51c6\u786e\u6027\u7684\u5206\u7c7b\u5668\u4f1a\u5bfc\u81f4\u4fe1\u4efb\u51cf\u5c11\u3001\u60c5\u7eea\u89e3\u4f53\u548c\u793e\u4f1a\u79e9\u5e8f\u7d0a\u4e71\u3002\u76f8\u53cd\uff0c\u9ad8\u51c6\u786e\u6027\u5206\u7c7b\u5668\u53ef\u4fc3\u8fdb\u60c5\u7eea\u805a\u96c6\u548c\u5bf9\u60c5\u7eea\u5e72\u6270\u7684\u62b5\u6297\u529b\u3002\u60c5\u7eea\u8bc6\u522b\u4e2d\u7684\u504f\u89c1\u6216\u4e0d\u51c6\u786e\u6027\u53ef\u80fd\u4f1a\u663e\u8457\u626d\u66f2\u793e\u4f1a\u8fc7\u7a0b\u5e76\u7834\u574f\u60c5\u611f\u6574\u5408\u3002"}}
{"id": "2509.00091", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00091", "abs": "https://arxiv.org/abs/2509.00091", "authors": ["Ephraiem Sarabamoun"], "title": "Ensemble Debates with Local Large Language Models for AI Alignment", "comment": "9 pages, 2 tables", "summary": "As large language models (LLMs) take on greater roles in high-stakes\ndecisions, alignment with human values is essential. Reliance on proprietary\nAPIs limits reproducibility and broad participation. We study whether local\nopen-source ensemble debates can improve alignmentoriented reasoning. Across\n150 debates spanning 15 scenarios and five ensemble configurations, ensembles\noutperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13),\nwith the largest gains in reasoning depth (+19.4%) and argument quality\n(+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human\nenhancement (+0.80). We provide code, prompts, and a debate data set, providing\nan accessible and reproducible foundation for ensemble-based alignment\nevaluation.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u672c\u5730\u5f00\u6e90\u96c6\u6210\u8fa9\u8bba\u5728\u63d0\u9ad8\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6548\u679c\u3002\u901a\u8fc7150\u573a\u8fa9\u8bba\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u96c6\u6210\u8fa9\u8bba\u5728\u5404\u65b9\u9762\u8868\u73b0\u5747\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u63a8\u7406\u6df1\u5ea6\u548c\u8bba\u636e\u8d28\u91cf\u4e0a\u6709\u663e\u8457\u63d0\u9ad8\u3002\u63d0\u4f9b\u4e86\u4ee3\u7801\u3001\u63d0\u793a\u548c\u8fa9\u8bba\u6570\u636e\u96c6\uff0c\u4e3a\u96c6\u6210\u5bf9\u9f50\u8bc4\u4f30\u5960\u5b9a\u4e86\u53ef\u8bbf\u95ee\u4e14\u53ef\u91cd\u590d\u7684\u57fa\u7840\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u626e\u6f14\u7740\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u89d2\u8272\uff0c\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\u3002\u4f9d\u8d56\u4e13\u6709 API \u9650\u5236\u4e86\u53ef\u91cd\u73b0\u6027\u548c\u5e7f\u6cdb\u53c2\u4e0e\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u662f\u5426\u672c\u5730\u5f00\u6e90\u96c6\u6210\u8fa9\u8bba\u53ef\u4ee5\u63d0\u9ad8\u5bf9\u9f50\u5bfc\u5411\u63a8\u7406\u7684\u80fd\u529b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u672c\u5730\u5f00\u6e90\u96c6\u6210\u8fa9\u8bba\uff0c\u5728 15 \u4e2a\u573a\u666f\u548c\u4e94\u79cd\u96c6\u6210\u914d\u7f6e\u4e2d\u8fdb\u884c\u4e86\u603b\u7ed3\u3002\u8bc4\u4f30\u4e86\u96c6\u6210\u8fa9\u8bba\u5728\u5bf9\u9f50\u5bfc\u5411\u63a8\u7406\u65b9\u9762\u7684\u6548\u679c\uff0c\u5e76\u4f7f\u7528 7 \u70b9\u6807\u51c6\u5bf9\u7ed3\u679c\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u7814\u7a76\u4e2d\u53d1\u73b0\uff0c\u96c6\u6210\u8fa9\u8bba\u5728\u63d0\u9ad8\u63a8\u7406\u6df1\u5ea6\u3001\u8bba\u636e\u8d28\u91cf\u3001\u771f\u5b9e\u6027\u548c\u4eba\u6587\u589e\u5f3a\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u5584\uff0c\u76f8\u5bf9\u4e8e\u5355\u4e00\u6a21\u578b\u57fa\u7ebf\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u672c\u5730\u5f00\u6e90\u96c6\u6210\u8fa9\u8bba\u53ef\u4ee5\u6539\u5584\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u63a8\u7406\u80fd\u529b\u3002\u5728 150 \u573a\u8fa9\u8bba\u4e2d\uff0c\u96c6\u6210\u8fa9\u8bba\u5728 7 \u70b9\u6807\u51c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\u57fa\u7ebf\uff08\u603b\u4f53\uff1a3.48 vs. 3.13\uff09\uff0c\u63a8\u7406\u6df1\u5ea6\u548c\u8bba\u636e\u8d28\u91cf\u4e0a\u7684\u6700\u5927\u589e\u76ca\u5206\u522b\u4e3a 19.4% \u548c 34.1%\u3002\u5bf9\u4e8e\u771f\u5b9e\u6027\u548c\u4eba\u6587\u589e\u5f3a\u6700\u4e3a\u660e\u663e\u7684\u6539\u5584\uff0c\u771f\u5b9e\u6027\u5f97\u5206\u63d0\u9ad8 1.25 \u5206\uff0c\u4eba\u6587\u589e\u5f3a\u63d0\u9ad8 0.80 \u5206\u3002\u63d0\u4f9b\u4e86\u4ee3\u7801\u3001\u63d0\u793a\u548c\u8fa9\u8bba\u6570\u636e\u96c6\uff0c\u4e3a\u57fa\u4e8e\u96c6\u6210\u7684\u5bf9\u9f50\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u548c\u53ef\u91cd\u590d\u7684\u57fa\u7840\u3002"}}
{"id": "2509.00100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00100", "abs": "https://arxiv.org/abs/2509.00100", "authors": ["Rahul Anand"], "title": "MODE: Mixture of Document Experts for RAG", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) often relies on large vector databases\nand cross-encoders tuned for large-scale corpora, which can be excessive for\nsmall, domain-specific collections. We present MODE (Mixture of Document\nExperts), a lightweight alternative that replaces fine-grained nearest-neighbor\nsearch with cluster-and-route retrieval. Documents are embedded, grouped into\nsemantically coherent clusters, and represented by cached centroids. At query\ntime, we route to the top centroid(s) and retrieve context only within those\nclusters, eliminating external vector-database infrastructure and reranking\nwhile keeping latency low. On HotpotQA and SQuAD corpora with 100-500 chunks,\nMODE matches or exceeds a dense-retrieval baseline in answer quality while\nreducing end-to-end retrieval time. Ablations show that cluster granularity and\nmulti-cluster routing control the recall/precision trade-off, and that tighter\nclusters improve downstream accuracy. MODE offers a practical recipe for small\nand medium corpora where simplicity, speed, and topical focus matter.", "AI": {"tldr": "MODE is a lightweight alternative to Retrieval-Augmented Generation for small and medium corpora, replacing fine-grained nearest-neighbor search with cluster-and-route retrieval. It improves answer quality, reduces retrieval time, and offers simplicity, speed, and topical focus for domain-specific collections.", "motivation": "The motivation is to provide a practical solution for small and domain-specific collections in Retrieval-Augmented Generation, where the reliance on large vectors and cross-encoders may be excessive. MODE aims to offer simplicity, speed, and topical focus for such corpora.", "method": "The paper introduces MODE, which embeds documents, groups them into semantically coherent clusters, and represents them with cached centroids. At query time, routing to top centroids is performed to retrieve context only within those clusters, eliminating the need for large vector databases and reranking, thus reducing latency.", "result": "MODE matches or exceeds a dense-retrieval baseline in answer quality while reducing end-to-end retrieval time on HotpotQA and SQuAD corpora with 100-500 chunks. Ablations demonstrate the control of recall/precision trade-off through cluster granularity and multi-cluster routing, with tighter clusters improving downstream accuracy.", "conclusion": "MODE (Mixture of Document Experts) is a lightweight alternative to Retrieval-Augmented Generation that replaces fine-grained nearest-neighbor search with cluster-and-route retrieval, showing improved answer quality and reduced end-to-end retrieval time for small and medium corpora."}}
{"id": "2509.00115", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.00115", "abs": "https://arxiv.org/abs/2509.00115", "authors": ["Manish Shukla"], "title": "Adaptive Monitoring and Real-World Evaluation of Agentic AI Systems", "comment": null, "summary": "Agentic artificial intelligence (AI) -- multi-agent systems that combine\nlarge language models with external tools and autonomous planning -- are\nrapidly transitioning from research laboratories into high-stakes domains. Our\nearlier \"Basic\" paper introduced a five-axis framework and proposed preliminary\nmetrics such as goal drift and harm reduction but did not provide an\nalgorithmic instantiation or empirical evidence. This \"Advanced\" sequel fills\nthat gap. First, we revisit recent benchmarks and industrial deployments to\nshow that technical metrics still dominate evaluations: a systematic review of\n84 papers from 2023--2025 found that 83% report capability metrics while only\n30% consider human-centred or economic axes [2]. Second, we formalise an\nAdaptive Multi-Dimensional Monitoring (AMDM) algorithm that normalises\nheterogeneous metrics, applies per-axis exponentially weighted moving-average\nthresholds and performs joint anomaly detection via the Mahalanobis distance.\nThird, we conduct simulations and real-world experiments. AMDM cuts\nanomaly-detection latency from 12.3 s to 5.6 s on simulated goal drift and\nreduces false-positive rates from 4.5% to 0.9% compared with static thresholds.\nWe present a comparison table and ROC/PR curves, and we reanalyse case studies\nto surface missing metrics. Code, data and a reproducibility checklist\naccompany this paper to facilitate replication.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u6846\u67b6\u548c\u7b97\u6cd5Adaptive Multi-Dimensional Monitoring (AMDM)\uff0c\u7528\u4e8e\u76d1\u63a7\u548c\u68c0\u6d4b\u5f02\u5e38\u3002AMDM\u7b97\u6cd5\u901a\u8fc7\u5b9e\u9a8c\u548c\u6a21\u62df\u5728\u51cf\u5c11\u5f02\u5e38\u68c0\u6d4b\u5ef6\u8fdf\u548c\u964d\u4f4e\u8bef\u62a5\u7387\u65b9\u9762\u53d6\u5f97\u79ef\u6781\u6210\u679c\u3002\u7814\u7a76\u586b\u8865\u4e86\u65e9\u671f\u7814\u7a76\u4e2d\u6846\u67b6\u548c\u6307\u6807\u7b97\u6cd5\u5316\u548c\u5b9e\u8bc1\u6570\u636e\u4e0d\u8db3\u7684\u7a7a\u767d\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\uff0c\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5982\u4f55\u76d1\u63a7\u548c\u68c0\u6d4b\u5f02\u5e38\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002\u524d\u671f\u7814\u7a76\u63d0\u51fa\u4e86\u6846\u67b6\u548c\u521d\u6b65\u6307\u6807\uff0c\u4f46\u7f3a\u4e4f\u7b97\u6cd5\u5b9e\u73b0\u548c\u5b9e\u8bc1\u6570\u636e\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u51fa\u4e00\u79cd\u7b97\u6cd5\u5316\u7684\u6846\u67b6\u4ee5\u53ca\u9a8c\u8bc1\u5b9e\u9a8c\u7ed3\u679c\u3002", "method": "\u672c\u7814\u7a76\u91cd\u65b0\u5ba1\u89c6\u6700\u8fd1\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5de5\u4e1a\u90e8\u7f72\uff0c\u53d1\u73b0\u6280\u672f\u6307\u6807\u4ecd\u7136\u4e3b\u5bfc\u8bc4\u4f30\u3002\u63d0\u51fa\u4e86Adaptive Multi-Dimensional Monitoring (AMDM)\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f52\u4e00\u5316\u5f02\u6784\u6307\u6807\u3001\u5e94\u7528\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u9608\u503c\u548c\u901a\u8fc7\u9a6c\u6c0f\u8ddd\u79bb\u6267\u884c\u8054\u5408\u5f02\u5e38\u68c0\u6d4b\u3002\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u548c\u6a21\u62df\uff0cAdaptive Multi-Dimensional Monitoring (AMDM)\u7b97\u6cd5\u5728\u51cf\u5c11\u5f02\u5e38\u68c0\u6d4b\u5ef6\u8fdf\u548c\u964d\u4f4e\u8bef\u62a5\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u79ef\u6781\u6210\u679c\u3002\u4e0e\u9759\u6001\u9608\u503c\u76f8\u6bd4\uff0cAMDM\u53ef\u4ee5\u5c06\u5f02\u5e38\u68c0\u6d4b\u5ef6\u8fdf\u4ece12.3\u79d2\u51cf\u5c11\u52305.6\u79d2\uff0c\u5e76\u5c06\u8bef\u62a5\u7387\u4ece4.5%\u964d\u4f4e\u52300.9%\u3002\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5bf9\u6bd4\u8868\u683c\u548cROC/PR\u66f2\u7ebf\uff0c\u91cd\u65b0\u5206\u6790\u6848\u4f8b\u7814\u7a76\u4ee5\u63ed\u793a\u7f3a\u5931\u6307\u6807\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u6846\u67b6\u548c\u7b97\u6cd5\uff0c\u540d\u4e3aAdaptive Multi-Dimensional Monitoring (AMDM)\uff0c\u7528\u4e8e\u76d1\u63a7\u548c\u68c0\u6d4b\u5f02\u5e38\u3002\u901a\u8fc7\u5b9e\u9a8c\u548c\u6a21\u62df\uff0cAMDM\u7b97\u6cd5\u5728\u51cf\u5c11\u5f02\u5e38\u68c0\u6d4b\u5ef6\u8fdf\u548c\u964d\u4f4e\u8bef\u62a5\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u79ef\u6781\u6210\u679c\u3002\u7814\u7a76\u91cd\u70b9\u5728\u4e8e\u586b\u8865\u57fa\u7840\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u6846\u67b6\u548c\u6307\u6807\u7b97\u6cd5\u5316\u548c\u5b9e\u8bc1\u8bc1\u636e\u4e0d\u8db3\u7684\u7a7a\u767d\u3002"}}
{"id": "2509.00125", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00125", "abs": "https://arxiv.org/abs/2509.00125", "authors": ["Ang Li", "Zhihang Yuan", "Yang Zhang", "Shouda Liu", "Yisen Wang"], "title": "Know When to Explore: Difficulty-Aware Certainty as a Guide for LLM Reinforcement Learning", "comment": null, "summary": "Reinforcement Learning with Verifiable Feedback (RLVF) has become a key\ntechnique for enhancing the reasoning abilities of Large Language Models\n(LLMs). However, its reliance on sparse, outcome based rewards, which only\nindicate if a final answer is correct or not, fails to provide granular\nguidance on the reasoning process itself. This limitation hinders efficient\nlearning, as the model cannot distinguish between high quality and inefficient\nsolutions, nor can it learn effectively from different types of failures. To\naddress this, we observe that an LLMs self-certainty often correlates with task\ndifficulty and solution quality. We introduce Difficulty Aware Certainty guided\nExploration (DACE), a novel RL algorithm that leverages this insight to\ndynamically balance the exploration exploitation trade-off. DACE assesses task\ndifficulty online based on the policys success rate. It then uses this signal\nto modulate an intrinsic reward: for difficult tasks where the model is\nstruggling, DACE encourages exploration by penalizing high certainty; for\neasier tasks, it encourages learning efficiency by rewarding high certainty.\nExperiments on challenging mathematical reasoning benchmarks (AIME, MATH) show\nthat DACE significantly outperforms strong baselines. The DACE-trained models\nnot only achieve higher accuracy but also demonstrate more robust performance\nwhen scaling test-time compute, validating that our adaptive approach fosters\neffective exploration without sacrificing precision.", "AI": {"tldr": "Difficulty Aware Certainty guided Exploration (DACE) is a novel RL algorithm that addresses the limitations of Reinforcement Learning with Verifiable Feedback (RLVF) in enhancing the reasoning abilities of Large Language Models (LLMs) by dynamically balancing the exploration-exploitation trade-off based on task difficulty and self-certainty. Experiments show that DACE outperforms strong baselines on challenging mathematical reasoning benchmarks, achieving higher accuracy and more robust performance during scaling.", "motivation": "The motivation of the paper lies in addressing the limitations of Reinforcement Learning with Verifiable Feedback (RLVF) in providing granular guidance on the reasoning process for Large Language Models (LLMs). The inability of RLVF to distinguish between high quality and inefficient solutions, as well as the lack of learning from different failure types, hinders efficient learning. By leveraging the correlation between task difficulty, self-certainty, and solution quality, the paper aims to improve the efficiency and effectiveness of learning for LLMs.", "method": "The paper introduces Difficulty Aware Certainty guided Exploration (DACE) as a novel RL algorithm that leverages the correlation between LLMs' self-certainty, task difficulty, and solution quality. DACE dynamically balances the exploration-exploitation trade-off by penalizing high certainty for difficult tasks and rewarding high certainty for easier tasks. The algorithm assesses task difficulty online based on the policy's success rate and modulates intrinsic rewards accordingly.", "result": "Experiments conducted on challenging mathematical reasoning benchmarks (AIME, MATH) demonstrate that the DACE algorithm significantly outperforms strong baselines. DACE-trained models achieve higher accuracy and exhibit more robust performance when scaling test-time compute. This validates that the adaptive approach of DACE fosters effective exploration without compromising precision.", "conclusion": "Difficulty Aware Certainty guided Exploration (DACE) is a novel RL algorithm that effectively addresses the limitations of Reinforcement Learning with Verifiable Feedback (RLVF) in enhancing the reasoning abilities of Large Language Models (LLMs). The DACE algorithm dynamically balances the exploration-exploitation trade-off by assessing task difficulty and modulating intrinsic rewards based on the model's self-certainty, resulting in improved performance on challenging mathematical reasoning benchmarks."}}
{"id": "2509.00135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00135", "abs": "https://arxiv.org/abs/2509.00135", "authors": ["Davin Choo", "Yohai Trabelsi", "Fentabil Getnet", "Samson Warkaye Lamma", "Wondesen Nigatu", "Kasahun Sime", "Lisa Matay", "Milind Tambe", "St\u00e9phane Verguet"], "title": "Optimizing Health Coverage in Ethiopia: A Learning-augmented Approach and Persistent Proportionality Under an Online Budget", "comment": null, "summary": "As part of nationwide efforts aligned with the United Nations' Sustainable\nDevelopment Goal 3 on Universal Health Coverage, Ethiopia's Ministry of Health\nis strengthening health posts to expand access to essential healthcare\nservices. However, only a fraction of this health system strengthening effort\ncan be implemented each year due to limited budgets and other competing\npriorities, thus the need for an optimization framework to guide prioritization\nacross the regions of Ethiopia. In this paper, we develop a tool, Health Access\nResource Planner (HARP), based on a principled decision-support optimization\nframework for sequential facility planning that aims to maximize population\ncoverage under budget uncertainty while satisfying region-specific\nproportionality targets at every time step. We then propose two algorithms: (i)\na learning-augmented approach that improves upon expert recommendations at any\nsingle-step; and (ii) a greedy algorithm for multi-step planning, both with\nstrong worst-case approximation estimation. In collaboration with the Ethiopian\nPublic Health Institute and Ministry of Health, we demonstrated the empirical\nefficacy of our method on three regions across various planning scenarios.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aHARP\u7684\u5de5\u5177\uff0c\u57fa\u4e8e\u4f18\u5316\u6846\u67b6\u4e3a\u57c3\u585e\u4fc4\u6bd4\u4e9a\u7684\u536b\u751f\u7cfb\u7edf\u5f3a\u5316\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002\u901a\u8fc7\u4e24\u79cd\u7b97\u6cd5\u5b9e\u73b0\u5355\u6b65\u548c\u591a\u6b65\u89c4\u5212\uff0c\u5728\u4e0e\u57c3\u585e\u4fc4\u6bd4\u4e9a\u673a\u6784\u5408\u4f5c\u7684\u5b9e\u8bc1\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u5de5\u5177\u7684\u6709\u6548\u6027\u3002\u7ed3\u679c\u663e\u793a\u5de5\u5177\u80fd\u591f\u6709\u6548\u6307\u5bfc\u536b\u751f\u7cfb\u7edf\u89c4\u5212\uff0c\u6700\u5927\u5316\u4eba\u53e3\u8986\u76d6\u7387\uff0c\u5e76\u8003\u8651\u4e86\u9884\u7b97\u4e0d\u786e\u5b9a\u6027\u548c\u533a\u57df\u6bd4\u4f8b\u76ee\u6807\u3002", "motivation": "\u57c3\u585e\u4fc4\u6bd4\u4e9a\u536b\u751f\u90e8\u6b63\u81f4\u529b\u4e8e\u5f3a\u5316\u536b\u751f\u5c97\u4f4d\u4ee5\u6269\u5927\u5bf9\u57fa\u672c\u533b\u7597\u670d\u52a1\u7684\u83b7\u53d6\uff0c\u4f46\u53d7\u9650\u9884\u7b97\u548c\u5176\u4ed6\u7ade\u4e89\u6027\u4f18\u5148\u4e8b\u9879\u7684\u5f71\u54cd\uff0c\u6bcf\u5e74\u53ea\u80fd\u5b9e\u65bd\u4e00\u5c0f\u90e8\u5206\u536b\u751f\u7cfb\u7edf\u5f3a\u5316\u5de5\u4f5c\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u4f18\u5316\u6846\u67b6\u6765\u6307\u5bfc\u57c3\u585e\u4fc4\u6bd4\u4e9a\u5404\u5730\u533a\u7684\u4f18\u5148\u7ea7\u786e\u5b9a\u3002", "method": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aHealth Access Resource Planner\uff08HARP\uff09\u7684\u5de5\u5177\uff0c\u57fa\u4e8e\u51b3\u7b56\u652f\u6301\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u79cd\u7b97\u6cd5\u5b9e\u73b0\uff1a\uff08i\uff09\u5b66\u4e60\u589e\u5f3a\u65b9\u6cd5\uff0c\u6539\u8fdb\u4e13\u5bb6\u63a8\u8350\u7684\u5355\u6b65\u65b9\u6cd5\uff1b\uff08ii\uff09\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u7528\u4e8e\u591a\u6b65\u89c4\u5212\uff0c\u4e14\u5177\u6709\u5f3a\u5927\u7684\u6700\u574f\u60c5\u51b5\u903c\u8fd1\u4f30\u8ba1\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u5408\u4f5c\u5f00\u53d1\u7684HARP\u5de5\u5177\u5728\u5b9e\u8df5\u4e2d\u5c55\u73b0\u4e86\u8f83\u597d\u7684\u6548\u679c\uff0c\u80fd\u591f\u5728\u9884\u7b97\u4e0d\u786e\u5b9a\u6027\u4e0b\u6700\u5927\u5316\u4eba\u53e3\u8986\u76d6\u7387\uff0c\u5e76\u6ee1\u8db3\u7279\u5b9a\u533a\u57df\u7684\u6bd4\u4f8b\u76ee\u6807\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u57c3\u585e\u4fc4\u6bd4\u4e9a\u7684\u536b\u751f\u7cfb\u7edf\u5f3a\u5316\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4f18\u5316\u6846\u67b6\u7684\u5de5\u5177HARP\uff0c\u65e8\u5728\u6700\u5927\u5316\u4eba\u53e3\u8986\u76d6\u7387\uff0c\u5e76\u5728\u9884\u7b97\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u4e0b\u6ee1\u8db3\u7279\u5b9a\u533a\u57df\u7684\u6bd4\u4f8b\u76ee\u6807\u3002\u901a\u8fc7\u4e0e\u57c3\u585e\u4fc4\u6bd4\u4e9a\u516c\u5171\u536b\u751f\u7814\u7a76\u6240\u548c\u536b\u751f\u90e8\u7684\u5408\u4f5c\uff0c\u5728\u4e09\u4e2a\u5730\u533a\u7684\u5404\u79cd\u89c4\u5212\u60c5\u666f\u4e0b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u8bc1\u6709\u6548\u6027\u3002"}}
{"id": "2509.00184", "categories": ["cs.AI", "cs.LO", "cs.MA", "03B42", "I.2.4"], "pdf": "https://arxiv.org/pdf/2509.00184", "abs": "https://arxiv.org/abs/2509.00184", "authors": ["Alexandru Baltag", "Malvin Gattinger", "Djanira Gomes"], "title": "Virtual Group Knowledge and Group Belief in Topological Evidence Models (Extended Version)", "comment": null, "summary": "We study notions of (virtual) group knowledge and group belief within\nmulti-agent evidence models, obtained by extending the topological semantics of\nevidence-based belief and fallible knowledge from individuals to groups. We\ncompletely axiomatize and show the decidability of the logic of (\"hard\" and\n\"soft\") group evidence, and do the same for an especially interesting fragment\nof it: the logic of group knowledge and group belief. We also extend these\nlanguages with dynamic evidence-sharing operators, and completely axiomatize\nthe corresponding logics, showing that they are co-expressive with their static\nbases.", "AI": {"tldr": "\u901a\u8fc7\u6269\u5c55\u57fa\u4e8e\u8bc1\u636e\u7684\u4fe1\u5ff5\u548c\u53ef\u72af\u9519\u8bef\u77e5\u8bc6\u7684\u62d3\u6251\u8bed\u4e49\uff0c\u7814\u7a76\u4e86\u7fa4\u4f53\u77e5\u8bc6\u548c\u7fa4\u4f53\u4fe1\u5ff5\u6982\u5ff5\uff0c\u5c55\u793a\u4e86\u5bf9\u7fa4\u4f53\u8bc1\u636e\u7684\u903b\u8f91\u7684\u53ef\u51b3\u5b9a\u6027\u53ca\u52a8\u6001\u8bc1\u636e\u5171\u4eab\u8fd0\u7b97\u7b26\u7684\u903b\u8f91\u516c\u7406\u5316\u3002", "motivation": "\u7814\u7a76\u7fa4\u4f53\u77e5\u8bc6\u548c\u7fa4\u4f53\u4fe1\u5ff5\u7684\u6982\u5ff5\uff0c\u4ee5\u53ca\u6269\u5c55\u5177\u6709\u52a8\u6001\u8bc1\u636e\u5171\u4eab\u8fd0\u7b97\u7b26\u7684\u8bed\u8a00\uff0c\u5e76\u5b8c\u5168\u7cfb\u7edf\u5316\u5bf9\u5e94\u7684\u903b\u8f91\uff0c\u5c55\u793a\u5176\u4e0e\u9759\u6001\u57fa\u7840\u903b\u8f91\u7684\u76f8\u4e92\u8868\u8fbe\u6027\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u57fa\u4e8e\u8bc1\u636e\u7684\u4fe1\u5ff5\u548c\u53ef\u72af\u9519\u8bef\u77e5\u8bc6\u7684\u62d3\u6251\u8bed\u4e49\uff0c\u5c06\u591a\u4e3b\u4f53\u8bc1\u636e\u6a21\u578b\u7684\u865a\u62df\u7fa4\u4f53\u77e5\u8bc6\u548c\u7fa4\u4f53\u4fe1\u5ff5\u6982\u5ff5\u7eb3\u5165\u7814\u7a76\u8303\u56f4\u3002", "result": "\u5c55\u793a\u4e86\u5bf9\u7fa4\u4f53\u8bc1\u636e\u7684\u903b\u8f91\uff08\u5305\u62ec\u201c\u786c\u201d\u548c\u201c\u8f6f\u201d\u8bc1\u636e\uff09\u4ee5\u53ca\u7279\u5b9a\u7247\u6bb5\uff08\u7fa4\u4f53\u77e5\u8bc6\u548c\u7fa4\u4f53\u4fe1\u5ff5\u7684\u903b\u8f91\uff09\u7684\u53ef\u51b3\u5b9a\u6027\u3002\u6269\u5c55\u4e86\u8bed\u8a00\u4e0e\u52a8\u6001\u8bc1\u636e\u5171\u4eab\u8fd0\u7b97\u7b26\uff0c\u5bf9\u76f8\u5e94\u903b\u8f91\u8fdb\u884c\u5b8c\u6574\u7684\u516c\u7406\u5316\u3002", "conclusion": "\u5b8c\u5168\u516c\u7406\u5316\u4e86\u7fa4\u4f53\u8bc1\u636e\u7684\u903b\u8f91\uff0c\u5c55\u793a\u4e86\u51b3\u7b56\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u5bf9\u7fa4\u4f53\u77e5\u8bc6\u548c\u4fe1\u5ff5\u7684\u903b\u8f91\u8fdb\u884c\u4e86\u62d3\u5c55\u3002"}}
{"id": "2509.00189", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.00189", "abs": "https://arxiv.org/abs/2509.00189", "authors": ["Jinzhou Tang", "Jusheng Zhang", "Qinhan Lv", "Sidi Liu", "Jing Yang", "Chengpei Tang", "Keze Wang"], "title": "HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological Evolution", "comment": null, "summary": "Autonomous agents play a crucial role in advancing Artificial General\nIntelligence, enabling problem decomposition and tool orchestration through\nLarge Language Models (LLMs). However, existing paradigms face a critical\ntrade-off. On one hand, reusable fixed workflows require manual reconfiguration\nupon environmental changes; on the other hand, flexible reactive loops fail to\ndistill reasoning progress into transferable structures. We introduce\nHierarchical Variable Agent (HiVA), a novel framework modeling agentic\nworkflows as self-organized graphs with the Semantic-Topological Evolution\n(STEV) algorithm, which optimizes hybrid semantic-topological spaces using\ntextual gradients as discrete-domain surrogates for backpropagation. The\niterative process comprises Multi-Armed Bandit-infused forward routing,\ndiagnostic gradient generation from environmental feedback, and coordinated\nupdates that co-evolve individual semantics and topology for collective\noptimization in unknown environments. Experiments on dialogue, coding,\nLong-context Q&A, mathematical, and agentic benchmarks demonstrate improvements\nof 5-10% in task accuracy and enhanced resource efficiency over existing\nbaselines, establishing HiVA's effectiveness in autonomous task execution.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86HiVA\u6846\u67b6\uff0c\u901a\u8fc7STEV\u7b97\u6cd5\u4f18\u5316\u8bed\u4e49-\u62d3\u6251\u7a7a\u95f4\uff0c\u4f7f\u7528\u6587\u672c\u68af\u5ea6\u4f5c\u4e3a\u53cd\u5411\u4f20\u64ad\u7684\u66ff\u4ee3\u3002\u5b9e\u9a8c\u8bc1\u660eHiVA\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u63d0\u9ad8\u4e86\u4efb\u52a1\u51c6\u786e\u6027\u548c\u8d44\u6e90\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8303\u5f0f\u9762\u4e34\u7740\u56fa\u5b9a\u5de5\u4f5c\u6d41\u9700\u8981\u624b\u52a8\u91cd\u65b0\u914d\u7f6e\u548c\u7075\u6d3b\u7684\u53cd\u5e94\u5faa\u73af\u65e0\u6cd5\u5c06\u63a8\u7406\u8fdb\u5c55\u63d0\u70bc\u4e3a\u53ef\u4f20\u9012\u7684\u7ed3\u6784\u4e4b\u95f4\u7684\u5173\u952e\u6298\u8877\uff0c\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u6311\u6218\u63d0\u51fa\u4e86HiVA\u6846\u67b6\u3002", "method": "\u5f15\u5165\u4e86Hierarchical Variable Agent (HiVA)\u6846\u67b6\uff0c\u5229\u7528Semantic-Topological Evolution (STEV)\u7b97\u6cd5\uff0c\u4f18\u5316\u8bed\u4e49-\u62d3\u6251\u7a7a\u95f4\uff0c\u4f7f\u7528\u6587\u672c\u68af\u5ea6\u4f5c\u4e3a\u53cd\u5411\u4f20\u64ad\u7684\u79bb\u6563\u9886\u57df\u66ff\u4ee3\u54c1\u3002\u5305\u62ec\u591a\u81c2\u8d4c\u535a\u673a-infused\u524d\u5411\u8def\u7531\u3001\u4ece\u73af\u5883\u53cd\u9988\u751f\u6210\u8bca\u65ad\u68af\u5ea6\u4ee5\u53ca\u534f\u8c03\u66f4\u65b0\u7b49\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHiVA\u76f8\u6bd4\u73b0\u6709\u57fa\u51c6\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u5b9e\u73b0\u4e865-10%\u7684\u4efb\u52a1\u51c6\u786e\u6027\u63d0\u5347\u548c\u8d44\u6e90\u6548\u7387\u6539\u8fdb\u3002", "conclusion": "\u5f15\u5165\u4e86HiVA\uff0c\u4e00\u79cd\u5c06Agent\u5de5\u4f5c\u6d41\u5efa\u6a21\u4e3a\u81ea\u7ec4\u7ec7\u56fe\u5f62\u7684\u65b0\u6846\u67b6\uff0c\u4f7f\u7528STEV\u7b97\u6cd5\u4f18\u5316\u6df7\u5408\u8bed\u4e49-\u62d3\u6251\u7a7a\u95f4\uff0c\u5229\u7528\u6587\u672c\u68af\u5ea6\u4f5c\u4e3a\u53cd\u5411\u4f20\u64ad\u7684\u79bb\u6563\u9886\u57df\u66ff\u4ee3\u54c1\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5bf9\u8bdd\u3001\u7f16\u7801\u3001\u957f\u6587\u672c\u95ee\u7b54\u3001\u6570\u5b66\u548cAgent\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHiVA\u76f8\u6bd4\u73b0\u6709\u57fa\u51c6\u63d0\u9ad8\u4e865-10%\u7684\u4efb\u52a1\u51c6\u786e\u6027\u5e76\u63d0\u9ad8\u4e86\u8d44\u6e90\u6548\u7387\uff0c\u786e\u7acb\u4e86HiVA\u5728\u81ea\u4e3b\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.00244", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00244", "abs": "https://arxiv.org/abs/2509.00244", "authors": ["Peter Belcak", "Pavlo Molchanov"], "title": "Universal Deep Research: Bring Your Own Model and Strategy", "comment": null, "summary": "Deep research tools are among the most impactful and most commonly\nencountered agentic systems today. We observe, however, that each deep research\nagent introduced so far is hard-coded to carry out a particular research\nstrategy using a fixed choice of tools. We introduce Universal Deep Research\n(UDR), a generalist agentic system that wraps around any language model and\nenables the user to create, edit, and refine their own entirely custom deep\nresearch strategies without any need for additional training or finetuning. To\nshowcase the generality of our system, we equip UDR with example minimal,\nexpansive, and intensive research strategies, and provide a user interface to\nfacilitate experimentation with the system.", "AI": {"tldr": "Universal Deep Research (UDR) is a versatile agentic system that enables users to build custom deep research strategies without extra training. It offers minimal, expansive, and intensive research strategies and a user interface for experimentation.", "motivation": "Current deep research tools are limited in their fixed research strategies and tool choices. The motivation behind UDR is to provide a versatile system that allows users to create, edit, and refine custom deep research strategies without requiring additional training or finetuning.", "method": "Introducing Universal Deep Research (UDR) as a generalist system that wraps around any language model, enabling users to develop their own custom research strategies. Equipped the system with example research strategies and a user interface for experimentation.", "result": "The result is a versatile agentic system, UDR, that empowers users to tailor their deep research strategies according to their needs without the constraints of preset tools or strategies.", "conclusion": "Universal Deep Research (UDR) is introduced as a generalist agentic system that allows users to create custom deep research strategies without the need for additional training or finetuning. The system showcases minimal, expansive, and intensive research strategies and provides a user interface for experimentation."}}
{"id": "2509.00251", "categories": ["cs.AI", "I.2.7; I.2.6; I.2.11"], "pdf": "https://arxiv.org/pdf/2509.00251", "abs": "https://arxiv.org/abs/2509.00251", "authors": ["Rimom Costa"], "title": "Instruction-Level Weight Shaping: A Framework for Self-Improving AI Agents", "comment": "12 pages, 1 figure, 2 tables", "summary": "Large language models (LLMs) are fluent but largely static after\npre-training; new or shifting knowledge is typically added with\nretrieval-augmented generation (RAG) or fine-tuning. RAG raises latency and\nengineering overhead and often fails to integrate facts; prompt engineering is\nbrittle and can conflict with prior knowledge; fine-tuning is costly and risks\ncatastrophic forgetting. We propose Instruction-Level Weight Shaping (ILWS):\ncurated system instructions act as external, auditable pseudo-parameters\nupdated after each session via reflection and user feedback. A Reflection\nEngine inspects conversation traces, diagnoses reasoning successes and\nfailures, and proposes typed deltas $\\Delta K=(\\Delta S,\\Delta U,\\Delta T)$\nover instructions, user preferences, and tools. Deltas are version-controlled,\nevaluated with a sliding window of 1-5 star ratings, auto-repaired on first\nfailure, and rolled back on repeated failure. When an edit budget crosses a\nthreshold, the agent compiles a rating-weighted synthetic set and distills\nmatured instruction-space gains into parameters, converting prompt-space\nimprovements into weight-space without downtime. ILWS makes explicit the\nlow-rank shaping induced by context in transformer blocks, preserves\ngovernance, and removes per-call retrieval. In enterprise support it increased\nthroughput 2.4-5.0x and cut audited hallucinations by about 80% versus a frozen\nbaseline. In an Adobe Commerce Cloud proof of concept \"L0 Support\", it achieved\n4-5x more tickets per hour and about 80% lower time per ticket, with autonomous\ninstruction updates and optional tool synthesis. Because ILWS operates at the\ninstruction layer until controlled distillation, it generalizes to dynamic\ndomains (legal, medical, engineering) requiring adaptive reasoning, tool\ncreation, and low-latency deployment.", "AI": {"tldr": "ILWS improves large language models by using curated system instructions as external pseudo-parameters updated via reflection and user feedback. It outperformed existing methods in enterprise support, achieving higher throughput and reducing hallucinations. ILWS also showed promise in dynamic domains like legal, medical, and engineering by providing adaptive reasoning, tool creation, and low-latency deployment capabilities.", "motivation": "Existing methods like retrieval-augmented generation (RAG) and fine-tuning for adding new knowledge to large language models have limitations in terms of latency, engineering overhead, integration of facts, brittleness in prompt engineering, and risks of catastrophic forgetting. ILWS aims to address these challenges by providing a more efficient and effective way to update the model with new knowledge.", "method": "Instruction-Level Weight Shaping (ILWS) is introduced, where curated system instructions act as pseudo-parameters updated after each session via reflection and user feedback. A Reflection Engine diagnoses successes and failures, proposing typed deltas over instructions, user preferences, and tools. Deltas are version-controlled, evaluated with star ratings, and distilled into parameters to convert prompt-space improvements into weight-space without downtime.", "result": "ILWS increased throughput and reduced audited hallucinations significantly in enterprise support settings compared to traditional methods. In a proof of concept in Adobe Commerce Cloud, ILWS achieved higher ticket resolution rates and lower time per ticket, along with autonomous instruction updates and optional tool synthesis. The method demonstrated success in dynamic domains requiring adaptive reasoning, tool creation, and low-latency deployment.", "conclusion": "ILWS is proposed as a method to enhance large language models by using curated system instructions as external pseudo-parameters updated via reflection and user feedback. It improved throughput and reduced hallucinations significantly compared to existing methods in enterprise support and demonstrated success in dynamic domains like legal, medical, and engineering."}}
{"id": "2509.00272", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00272", "abs": "https://arxiv.org/abs/2509.00272", "authors": ["Boqi Chen", "Kua Chen", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "Gunter Mussbacher", "D\u00e1niel Varr\u00f3", "Amir Feizpour"], "title": "SHERPA: A Model-Driven Framework for Large Language Model Execution", "comment": "MODELS 2025", "summary": "Recently, large language models (LLMs) have achieved widespread application\nacross various fields. Despite their impressive capabilities, LLMs suffer from\na lack of structured reasoning ability, particularly for complex tasks\nrequiring domain-specific best practices, which are often unavailable in the\ntraining data. Although multi-step prompting methods incorporating human best\npractices, such as chain-of-thought and tree-of-thought, have gained\npopularity, they lack a general mechanism to control LLM behavior. In this\npaper, we propose SHERPA, a model-driven framework to improve the LLM\nperformance on complex tasks by explicitly incorporating domain-specific best\npractices into hierarchical state machines. By structuring the LLM execution\nprocesses using state machines, SHERPA enables more fine-grained control over\ntheir behavior via rules or decisions driven by machine learning-based\napproaches, including LLMs. We show that SHERPA is applicable to a wide variety\nof tasks-specifically, code generation, class name generation, and question\nanswering-replicating previously proposed approaches while further improving\nthe performance. We demonstrate the effectiveness of SHERPA for the\naforementioned tasks using various LLMs. Our systematic evaluation compares\ndifferent state machine configurations against baseline approaches without\nstate machines. Results show that integrating well-designed state machines\nsignificantly improves the quality of LLM outputs, and is particularly\nbeneficial for complex tasks with well-established human best practices but\nlacking data used for training LLMs.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSHERPA\u7684\u6a21\u578b\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u72b6\u6001\u673a\u63a7\u5236\u5b9e\u73b0\u5bf9LLMs\u884c\u4e3a\u7684\u7cbe\u7ec6\u63a7\u5236\uff0c\u63d0\u9ad8\u4e86LLMs\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002\u5b9e\u9a8c\u8bc1\u5b9e\u4e86SHERPA\u6846\u67b6\u5bf9LLMs\u8f93\u51fa\u8d28\u91cf\u7684\u6539\u5584\u6548\u679c\u3002", "motivation": "LLMs\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u800c\u591a\u6b65\u63d0\u793a\u65b9\u6cd5\u7f3a\u4e4f\u63a7\u5236LLMs\u884c\u4e3a\u7684\u901a\u7528\u673a\u5236\u3002\u9488\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86SHERPA\u6846\u67b6\uff0c\u65e8\u5728\u6539\u5584LLMs\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u7f3a\u4e4f\u8bad\u7ec3\u6570\u636e\u4f46\u62e5\u6709\u660e\u786e\u9886\u57df\u6700\u4f73\u5b9e\u8df5\u7684\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86SHERPA\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9886\u57df\u7279\u5b9a\u6700\u4f73\u5b9e\u8df5\u663e\u5f0f\u5730\u7eb3\u5165\u5206\u5c42\u72b6\u6001\u673a\u6765\u6539\u5584LLMs\u6027\u80fd\u3002\u901a\u8fc7\u7ed3\u6784\u5316LLMs\u6267\u884c\u8fc7\u7a0b\uff0cSHERPA\u901a\u8fc7\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff08\u5305\u62ecLLMs\uff09\u5b9e\u73b0\u5bf9LLMs\u884c\u4e3a\u7684\u66f4\u7cbe\u7ec6\u63a7\u5236\u3002\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u4ee5\u6bd4\u8f83\u4e0d\u540c\u72b6\u6001\u673a\u914d\u7f6e\u4e0e\u6ca1\u6709\u72b6\u6001\u673a\u7684\u57fa\u51c6\u65b9\u6cd5\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660eSHERPA\u6846\u67b6\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\uff0c\u63d0\u9ad8\u4e86LLMs\u5728\u4ee3\u7801\u751f\u6210\u3001\u7c7b\u540d\u79f0\u751f\u6210\u548c\u95ee\u7b54\u7b49\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u7cfb\u7edf\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u6574\u5408\u72b6\u6001\u673a\u663e\u8457\u6539\u5584\u4e86LLMs\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSHERPA\u7684\u6a21\u578b\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9886\u57df\u7279\u5b9a\u6700\u4f73\u5b9e\u8df5\u663e\u5f0f\u5730\u7eb3\u5165\u5206\u5c42\u72b6\u6001\u673a\u6765\u6539\u5584\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u5c55\u793a\u4e86SHERPA\u5728\u4ee3\u7801\u751f\u6210\u3001\u7c7b\u540d\u79f0\u751f\u6210\u548c\u95ee\u7b54\u7b49\u4efb\u52a1\u4e0a\u7684\u9002\u7528\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u6539\u5584\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u7cfb\u7edf\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u6574\u5408\u8bbe\u8ba1\u826f\u597d\u7684\u72b6\u6001\u673a\u663e\u7740\u63d0\u9ad8\u4e86LLMs\u8f93\u51fa\u7684\u8d28\u91cf\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u7f3a\u4e4f\u8bad\u7ec3\u6570\u636e\u4f46\u62e5\u6709\u660e\u786e\u5b9a\u4e49\u4eba\u7c7b\u6700\u4f73\u5b9e\u8df5\u7684\u590d\u6742\u4efb\u52a1\u3002"}}
{"id": "2509.00287", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00287", "abs": "https://arxiv.org/abs/2509.00287", "authors": ["Brian Wang", "Mani Srivastava"], "title": "SIGMUS: Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces", "comment": "9 pages, accepted at UrbComp 2025 KDD 2025", "summary": "Modern urban spaces are equipped with an increasingly diverse set of sensors,\nall producing an abundance of multimodal data. Such multimodal data can be used\nto identify and reason about important incidents occurring in urban landscapes,\nsuch as major emergencies, cultural and social events, as well as natural\ndisasters. However, such data may be fragmented over several sources and\ndifficult to integrate due to the reliance on human-driven reasoning for\nidentifying relationships between the multimodal data corresponding to an\nincident, as well as understanding the different components which define an\nincident. Such relationships and components are critical to identifying the\ncauses of such incidents, as well as producing forecasting the scale and\nintensity of future incidents as they begin to develop. In this work, we create\nSIGMUS, a system for Semantic Integration for Knowledge Graphs in Multimodal\nUrban Spaces. SIGMUS uses Large Language Models (LLMs) to produce the necessary\nworld knowledge for identifying relationships between incidents occurring in\nurban spaces and data from different modalities, allowing us to organize\nevidence and observations relevant to an incident without relying and\nhuman-encoded rules for relating multimodal sensory data with incidents. This\norganized knowledge is represented as a knowledge graph, organizing incidents,\nobservations, and much more. We find that our system is able to produce\nreasonable connections between 5 different data sources (new article text, CCTV\nimages, air quality, weather, and traffic measurements) and relevant incidents\noccurring at the same time and location.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86SIGMUS\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u591a\u6a21\u6001\u57ce\u5e02\u7a7a\u95f4\u4e2d\u8fdb\u884c\u77e5\u8bc6\u56fe\u8c31\u8bed\u4e49\u96c6\u6210\u3002\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0cSIGMUS\u53ef\u4ee5\u8bc6\u522b\u57ce\u5e02\u7a7a\u95f4\u4e2d\u4e0d\u540c\u6570\u636e\u6e90\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u6574\u5408\u76f8\u5173\u4e8b\u4ef6\u6570\u636e\uff0c\u5728\u65b0\u95fb\u6587\u7ae0\u6587\u672c\u3001\u95ed\u8def\u7535\u89c6\u56fe\u50cf\u3001\u7a7a\u6c14\u8d28\u91cf\u3001\u5929\u6c14\u548c\u4ea4\u901a\u6d4b\u91cf\u7b49\u6570\u636e\u6e90\u4e4b\u95f4\u5efa\u7acb\u8054\u7cfb\u3002SIGMUS\u80fd\u591f\u6709\u6548\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e2e\u52a9\u7406\u89e3\u548c\u9884\u6d4b\u57ce\u5e02\u4e8b\u4ef6\u3002", "motivation": "\u73b0\u4ee3\u57ce\u5e02\u7a7a\u95f4\u4e2d\u5b58\u5728\u7740\u5927\u91cf\u591a\u6a21\u6001\u4f20\u611f\u5668\uff0c\u4ea7\u751f\u5927\u91cf\u591a\u6a21\u6001\u6570\u636e\u3002\u8fd9\u4e9b\u6570\u636e\u53ef\u4ee5\u7528\u4e8e\u8bc6\u522b\u548c\u63a8\u7406\u57ce\u5e02\u666f\u89c2\u4e2d\u53d1\u751f\u7684\u91cd\u8981\u4e8b\u4ef6\uff0c\u5982\u91cd\u5927\u7d27\u6025\u4e8b\u4ef6\u3001\u6587\u5316\u793e\u4f1a\u6d3b\u52a8\u4ee5\u53ca\u81ea\u7136\u707e\u5bb3\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u80fd\u5206\u6563\u5728\u591a\u4e2a\u6765\u6e90\uff0c\u7531\u4e8e\u4f9d\u8d56\u4eba\u5de5\u9a71\u52a8\u7684\u63a8\u7406\u6765\u8bc6\u522b\u5bf9\u5e94\u4e8e\u4e8b\u4ef6\u7684\u591a\u6a21\u6001\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u7406\u89e3\u5b9a\u4e49\u4e8b\u4ef6\u7684\u4e0d\u540c\u7ec4\u6210\u90e8\u5206\uff0c\u8fd9\u79cd\u6574\u5408\u53ef\u80fd\u5b58\u5728\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6709\u6548\u5730\u6574\u5408\u8fd9\u4e9b\u6570\u636e\u6e90\u3002", "method": "\u8bba\u6587\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u5efa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5728\u591a\u6a21\u6001\u57ce\u5e02\u7a7a\u95f4\u4e2d\u8fdb\u884c\u77e5\u8bc6\u56fe\u8c31\u8bed\u4e49\u96c6\u6210\u7684\u7cfb\u7edfSIGMUS\u3002\u8be5\u7cfb\u7edf\u80fd\u591f\u8bc6\u522b\u4e0d\u540c\u6570\u636e\u6e90\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u5c06\u76f8\u5173\u8bc1\u636e\u548c\u89c2\u5bdf\u6574\u5408\u4e3a\u77e5\u8bc6\u56fe\u8c31\u3002", "result": "SIGMUS\u7cfb\u7edf\u80fd\u591f\u6210\u529f\u8bc6\u522b\u57ce\u5e02\u7a7a\u95f4\u4e2d\u4e0d\u540c\u6570\u636e\u6e90\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u6574\u5408\u76f8\u5173\u7684\u4e8b\u4ef6\u6570\u636e\uff0c\u5f62\u6210\u77e5\u8bc6\u56fe\u8c31\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5728\u65b0\u95fb\u6587\u7ae0\u6587\u672c\u3001\u95ed\u8def\u7535\u89c6\u56fe\u50cf\u3001\u7a7a\u6c14\u8d28\u91cf\u3001\u5929\u6c14\u548c\u4ea4\u901a\u6d4b\u91cf\u7b49\u591a\u4e2a\u6570\u636e\u6e90\u4e4b\u95f4\u5efa\u7acb\u5408\u7406\u7684\u8054\u7cfb\uff0c\u4e0e\u540c\u65f6\u53d1\u751f\u5728\u540c\u4e00\u65f6\u95f4\u548c\u5730\u70b9\u7684\u76f8\u5173\u4e8b\u4ef6\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5728\u591a\u6a21\u6001\u57ce\u5e02\u7a7a\u95f4\u4e2d\u8fdb\u884c\u77e5\u8bc6\u56fe\u8c31\u8bed\u4e49\u96c6\u6210\u7684\u7cfb\u7edfSIGMUS\u3002\u901a\u8fc7\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0cSIGMUS\u80fd\u591f\u8bc6\u522b\u57ce\u5e02\u7a7a\u95f4\u4e2d\u53d1\u751f\u7684\u4e8b\u4ef6\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u6574\u5408\u6765\u81ea\u4e0d\u540c\u6a21\u6001\u7684\u6570\u636e\uff0c\u4ee5\u7ec4\u7ec7\u4e0e\u4e8b\u4ef6\u76f8\u5173\u7684\u8bc1\u636e\u548c\u89c2\u5bdf\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5728\u65b0\u95fb\u6587\u7ae0\u6587\u672c\u3001\u95ed\u8def\u7535\u89c6\u56fe\u50cf\u3001\u7a7a\u6c14\u8d28\u91cf\u3001\u5929\u6c14\u548c\u4ea4\u901a\u6d4b\u91cf\u7b49\u4e0d\u540c\u6570\u636e\u6e90\u4e4b\u95f4\u5efa\u7acb\u5408\u7406\u7684\u8054\u7cfb\uff0c\u4e0e\u540c\u65f6\u53d1\u751f\u5728\u540c\u4e00\u65f6\u95f4\u548c\u5730\u70b9\u7684\u76f8\u5173\u4e8b\u4ef6\u3002"}}
{"id": "2509.00446", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00446", "abs": "https://arxiv.org/abs/2509.00446", "authors": ["Yen-Che Chien", "Kuang-Da Wang", "Wei-Yao Wang", "Wen-Chih Peng"], "title": "NEWSAGENT: Benchmarking Multimodal Agents as Journalists with Real-World Newswriting Tasks", "comment": "Preprint", "summary": "Recent advances in autonomous digital agents from industry (e.g., Manus AI\nand Gemini's research mode) highlight potential for structured tasks by\nautonomous decision-making and task decomposition; however, it remains unclear\nto what extent the agent-based systems can improve multimodal web data\nproductivity. We study this in the realm of journalism, which requires\niterative planning, interpretation, and contextual reasoning from multimodal\nraw contents to form a well structured news. We introduce NEWSAGENT, a\nbenchmark for evaluating how agents can automatically search available raw\ncontents, select desired information, and edit and rephrase to form a news\narticle by accessing core journalistic functions. Given a writing instruction\nand firsthand data as how a journalist initiates a news draft, agents are\ntasked to identify narrative perspectives, issue keyword-based queries,\nretrieve historical background, and generate complete articles. Unlike typical\nsummarization or retrieval tasks, essential context is not directly available\nand must be actively discovered, reflecting the information gaps faced in\nreal-world news writing. NEWSAGENT includes 6k human-verified examples derived\nfrom real news, with multimodal contents converted to text for broad model\ncompatibility. We evaluate open- and closed-sourced LLMs with commonly-used\nagentic frameworks on NEWSAGENT, which shows that agents are capable of\nretrieving relevant facts but struggling with planning and narrative\nintegration. We believe that NEWSAGENT serves a realistic testbed for iterating\nand evaluating agent capabilities in terms of multimodal web data manipulation\nto real-world productivity.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86NEWSAGENT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u4ee3\u7406\u7cfb\u7edf\u5728\u81ea\u52a8\u641c\u7d22\u3001\u9009\u62e9\u3001\u7f16\u8f91\u548c\u6539\u5199\u65b0\u95fb\u6587\u7ae0\u65b9\u9762\u7684\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u4ee3\u7406\u7cfb\u7edf\u5728\u68c0\u7d22\u76f8\u5173\u4e8b\u5b9e\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u89c4\u5212\u548c\u53d9\u4e8b\u6574\u5408\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u8fd1\u671f\u81ea\u4e3b\u6570\u5b57\u4ee3\u7406\u7684\u53d1\u5c55\u663e\u793a\u4e86\u4ee3\u7406\u7cfb\u7edf\u5728\u7ed3\u6784\u5316\u4efb\u52a1\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4f46\u76ee\u524d\u8fd8\u4e0d\u6e05\u695a\u4ee3\u7406\u7cfb\u7edf\u5728\u63d0\u9ad8\u591a\u6a21\u6001\u7f51\u7edc\u6570\u636e\u751f\u4ea7\u529b\u65b9\u9762\u7684\u5b9e\u9645\u6548\u679c\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7406\u7cfb\u7edf\u80fd\u5426\u6539\u5584\u65b0\u95fb\u4ea7\u751f\u7684\u751f\u4ea7\u529b\uff0c\u8be5\u9886\u57df\u9700\u8981\u4ece\u591a\u6a21\u6001\u539f\u59cb\u5185\u5bb9\u8fdb\u884c\u8fed\u4ee3\u89c4\u5212\u3001\u89e3\u91ca\u548c\u80cc\u666f\u63a8\u7406\uff0c\u5f62\u6210\u7ed3\u6784\u5316\u65b0\u95fb\u3002", "method": "\u4ecb\u7ecd\u4e86NEWSAGENT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4ee3\u7406\u5982\u4f55\u81ea\u52a8\u641c\u7d22\u53ef\u7528\u539f\u59cb\u5185\u5bb9\uff0c\u5e76\u5c06\u9009\u62e9\u7684\u4fe1\u606f\u7f16\u8f91\u548c\u6539\u5199\uff0c\u4ee5\u5f62\u6210\u65b0\u95fb\u6587\u7ae0\u3002\u4ee3\u7406\u9700\u8981\u8bc6\u522b\u53d9\u4e8b\u89c6\u89d2\uff0c\u57fa\u4e8e\u5173\u952e\u8bcd\u67e5\u8be2\u95ee\u9898\uff0c\u68c0\u7d22\u5386\u53f2\u80cc\u666f\uff0c\u5e76\u751f\u6210\u5b8c\u6574\u7684\u6587\u7ae0\u3002\u901a\u8fc7\u5728NEWSAGENT\u4e0a\u8bc4\u4f30\u5f00\u6e90\u548c\u95ed\u6e90\u7684LLM\u6a21\u578b\uff0c\u7814\u7a76\u663e\u793a\u4ee3\u7406\u53ef\u4ee5\u68c0\u7d22\u76f8\u5173\u4e8b\u5b9e\uff0c\u4f46\u5728\u89c4\u5212\u548c\u53d9\u4e8b\u6574\u5408\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "result": "\u901a\u8fc7NEWSAGENT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7814\u7a76\u8868\u660e\u4ee3\u7406\u7cfb\u7edf\u80fd\u591f\u68c0\u7d22\u76f8\u5173\u4e8b\u5b9e\uff0c\u4f46\u5728\u89c4\u5212\u548c\u53d9\u4e8b\u6574\u5408\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u4ee3\u7406\u7cfb\u7edf\u80fd\u591f\u68c0\u7d22\u76f8\u5173\u4e8b\u5b9e\uff0c\u4f46\u5728\u89c4\u5212\u548c\u53d9\u4e8b\u6574\u5408\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002NEWSAGENT\u4f5c\u4e3a\u4e00\u4e2a\u73b0\u5b9e\u7684\u6d4b\u8bd5\u57fa\u5730\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7406\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u7f51\u7edc\u6570\u636e\u5904\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u9ad8\u73b0\u5b9e\u4e16\u754c\u7684\u751f\u4ea7\u529b\u3002"}}
{"id": "2509.00481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00481", "abs": "https://arxiv.org/abs/2509.00481", "authors": ["Anton Wolter", "Georgios Vidalakis", "Michael Yu", "Ankit Grover", "Vaishali Dhanoa"], "title": "Multi-Agent Data Visualization and Narrative Generation", "comment": null, "summary": "Recent advancements in the field of AI agents have impacted the way we work,\nenabling greater automation and collaboration between humans and agents. In the\ndata visualization field, multi-agent systems can be useful for employing\nagents throughout the entire data-to-communication pipeline. We present a\nlightweight multi-agent system that automates the data analysis workflow, from\ndata exploration to generating coherent visual narratives for insight\ncommunication. Our approach combines a hybrid multi-agent architecture with\ndeterministic components, strategically externalizing critical logic from LLMs\nto improve transparency and reliability. The system delivers granular, modular\noutputs that enable surgical modifications without full regeneration,\nsupporting sustainable human-AI collaboration. We evaluated our system across 4\ndiverse datasets, demonstrating strong generalizability, narrative quality, and\ncomputational efficiency with minimal dependencies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u636e\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7ed3\u5408\u4e86\u6df7\u5408\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u786e\u5b9a\u6027\u7ec4\u4ef6\uff0c\u4eceLLMs\u4e2d\u5916\u90e8\u5316\u5173\u952e\u903b\u8f91\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002\u7cfb\u7edf\u57284\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3001\u53d9\u4e8b\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5177\u6709\u8f83\u5c0f\u7684\u4f9d\u8d56\u6027\uff0c\u652f\u6301\u53ef\u6301\u7eed\u7684\u4eba\u5de5\u667a\u80fd\u534f\u4f5c\u3002", "motivation": "\u6700\u8fd1\u4eba\u5de5\u667a\u80fd\u667a\u80fd\u4f53\u9886\u57df\u7684\u8fdb\u5c55\u5f71\u54cd\u4e86\u6211\u4eec\u5de5\u4f5c\u7684\u65b9\u5f0f\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7a0b\u5ea6\u7684\u81ea\u52a8\u5316\u548c\u4eba\u673a\u534f\u4f5c\u3002\u5728\u6570\u636e\u53ef\u89c6\u5316\u9886\u57df\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u4ee5\u5728\u6574\u4e2a\u6570\u636e\u5230\u901a\u4fe1\u7ba1\u9053\u4e2d\u53d1\u6325\u4f5c\u7528\uff0c\u56e0\u6b64\u5efa\u7acb\u4e86\u8fd9\u79cd\u8f7b\u91cf\u7ea7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4ee5\u5b9e\u73b0\u6570\u636e\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u81ea\u52a8\u5316\u662f\u6709\u610f\u4e49\u7684\u3002", "method": "\u7ed3\u5408\u6df7\u5408\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u786e\u5b9a\u6027\u7ec4\u4ef6\uff0c\u901a\u8fc7\u5916\u90e8\u5316\u5173\u952e\u903b\u8f91\u6539\u5584\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002\u7cfb\u7edf\u63d0\u4f9b\u7cbe\u7ec6\u3001\u6a21\u5757\u5316\u7684\u8f93\u51fa\uff0c\u652f\u6301\u53ef\u6301\u7eed\u7684\u4eba\u5de5\u667a\u80fd\u534f\u4f5c\u3002\u7cfb\u7edf\u57284\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3001\u53d9\u4e8b\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u4e14\u4f9d\u8d56\u6027\u8f83\u5c0f\u3002", "result": "\u6211\u4eec\u63d0\u51fa\u7684\u7cfb\u7edf\u57284\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3001\u53d9\u4e8b\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u5177\u6709\u8f83\u5c0f\u7684\u4f9d\u8d56\u6027\u3002", "conclusion": "\u5728\u6570\u636e\u53ef\u89c6\u5316\u9886\u57df\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u636e\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ece\u6570\u636e\u63a2\u7d22\u5230\u751f\u6210\u8fde\u8d2f\u7684\u89c6\u89c9\u53d9\u8ff0\u8fdb\u884c\u6d1e\u5bdf\u4f20\u8fbe\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u7ed3\u5408\u4e86\u6df7\u5408\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u786e\u5b9a\u6027\u7ec4\u4ef6\uff0c\u4eceLLMs\u4e2d\u5916\u90e8\u5316\u5173\u952e\u903b\u8f91\uff0c\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002\u8be5\u7cfb\u7edf\u63d0\u4f9b\u7cbe\u7ec6\u3001\u6a21\u5757\u5316\u7684\u8f93\u51fa\uff0c\u652f\u6301\u53ef\u6301\u7eed\u7684\u4eba\u5de5\u667a\u80fd\u534f\u4f5c\u3002\u901a\u8fc7\u57284\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u7cfb\u7edf\u5177\u6709\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3001\u53d9\u4e8b\u8d28\u91cf\u4ee5\u53ca\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u4e14\u5177\u6709\u6700\u5c0f\u7684\u4f9d\u8d56\u6027\u3002"}}
{"id": "2509.00507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00507", "abs": "https://arxiv.org/abs/2509.00507", "authors": ["Zhang Lai Bin", "Zhen Bin It"], "title": "Artificial Intelligence-Based Analysis of Ice Cream Melting Behavior Under Various Ingredients", "comment": null, "summary": "The stability of ice cream during melting is a critical factor for consumer's\nacceptance and product quality. With the commonly added stabilizer to improve\ntexture, structure and slower melting as the factors to analyze. This report\nexplores the effects of locust bean gum, guar gum, maltodextrin, and\ncarrageenan on the melting behavior of homemade ice cream. The main objective\nwas to assess how these additives influence melting resistance and to identify\na more cost-effective recipe formulation. Ice cream samples incorporating each\nadditive were prepared and subjected to melting tests under controlled\nconditions. Timelapse recordings were used to capture and analyze the\nprogression of melting over time. Python and OpenCV is used for process and\nanalysis. Observations revealed that all samples retained a foam-like structure\neven after melting, suggesting the stabilizers contributed to the formation of\na stable air-cell matrix. Furthermore, when the melted samples were re-frozen\nand subsequently melted again, they displayed increased sturdiness, indicating\nimproved resilience of the ice cream structure. Comparative analysis of the\ndifferent stabilizers highlighted variations in their effectiveness, with some\noffering stronger melting resistance and structural support than others.\nOverall, the findings provide insights into the functional roles of commonly\nused food additives in ice cream formulation. By evaluating both performance\nand cost, this study demonstrates the potential for developing recipes that\nbalance durability with economic efficiency, contributing to practical\napplications in both small-scale and commercial ice cream production.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u6dfb\u52a0\u5242\u5bf9\u5bb6\u5236\u51b0\u6dc7\u6dcb\u878d\u5316\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6dfb\u52a0\u5242\u5bf9\u878d\u5316\u62b5\u6297\u529b\u548c\u7ed3\u6784\u7a33\u5b9a\u6027\u5177\u6709\u79ef\u6781\u4f5c\u7528\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5e38\u7528\u98df\u54c1\u6dfb\u52a0\u5242\u5728\u51b0\u6dc7\u6dcb\u914d\u65b9\u4e2d\u7684\u529f\u80fd\u4f5c\u7528\uff0c\u4e3a\u5f00\u53d1\u5e73\u8861\u8010\u4e45\u6027\u548c\u7ecf\u6d4e\u6548\u76ca\u7684\u914d\u65b9\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002\u6bd4\u8f83\u5206\u6790\u4e0d\u540c\u7a33\u5b9a\u5242\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u4e2d\u4e00\u4e9b\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u878d\u5316\u62b5\u6297\u529b\u548c\u7ed3\u6784\u652f\u6301\u3002", "motivation": "\u51bb\u96ea\u7cd5\u5728\u878d\u5316\u8fc7\u7a0b\u4e2d\u7684\u7a33\u5b9a\u6027\u662f\u6d88\u8d39\u8005\u63a5\u53d7\u548c\u4ea7\u54c1\u8d28\u91cf\u7684\u5173\u952e\u56e0\u7d20\u3002\u901a\u8fc7\u6dfb\u52a0\u7a33\u5b9a\u5242\u6539\u5584\u8d28\u5730\u3001\u7ed3\u6784\u548c\u51cf\u7f13\u878d\u5316\u901f\u5ea6\uff0c\u63a2\u8ba8\u4e86\u6dfb\u52a0\u5242\u5bf9\u5bb6\u5236\u51b0\u6dc7\u6dcb\u878d\u5316\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u76ee\u7684\u5728\u4e8e\u8bc6\u522b\u66f4\u5177\u6210\u672c\u6548\u76ca\u7684\u914d\u65b9\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u914d\u5236\u542b\u6709\u5404\u79cd\u6dfb\u52a0\u5242\u7684\u51b0\u6dc7\u6dcb\u6837\u54c1\uff0c\u5e76\u5728\u63a7\u5236\u6761\u4ef6\u4e0b\u8fdb\u884c\u878d\u5316\u6d4b\u8bd5\uff0c\u4f7f\u7528\u65f6\u95f4\u8fc7\u7a0b\u8bb0\u5f55\u548cPython\u4ee5\u53caOpenCV\u8fdb\u884c\u5206\u6790\u3002\u6bd4\u8f83\u5206\u6790\u4e0d\u540c\u7a33\u5b9a\u5242\u7684\u6548\u679c\uff0c\u89c2\u5bdf\u4e86\u878d\u5316\u8fc7\u7a0b\uff0c\u5e76\u68c0\u6d4b\u5230\u6240\u6709\u6837\u54c1\u5728\u878d\u5316\u540e\u4ecd\u4fdd\u6301\u6ce1\u6cab\u72b6\u7ed3\u6784\uff0c\u663e\u793a\u7a33\u5b9a\u5242\u6709\u52a9\u4e8e\u5f62\u6210\u7a33\u5b9a\u7684\u6c14\u6ce1\u57fa\u8d28\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6240\u6709\u6837\u54c1\u5728\u878d\u5316\u540e\u4ecd\u4fdd\u6301\u6ce1\u6cab\u72b6\u7ed3\u6784\uff0c\u8868\u660e\u7a33\u5b9a\u5242\u6709\u52a9\u4e8e\u5f62\u6210\u7a33\u5b9a\u7684\u6c14\u6ce1\u57fa\u8d28\u3002\u878d\u5316\u540e\u518d\u6b21\u51b7\u51bb\u7684\u6837\u672c\u663e\u793a\u51fa\u589e\u5f3a\u7684\u7a33\u56fa\u6027\uff0c\u663e\u793a\u4e86\u51b0\u6dc7\u6dcb\u7ed3\u6784\u7684\u6539\u5584\u97e7\u6027\u3002\u6bd4\u8f83\u4e0d\u540c\u7a33\u5b9a\u5242\u7684\u5206\u6790\u7a81\u51fa\u4e86\u5b83\u4eec\u7684\u6548\u679c\u5dee\u5f02\uff0c\u6709\u4e9b\u6bd4\u5176\u4ed6\u63d0\u4f9b\u66f4\u5f3a\u7684\u878d\u5316\u62b5\u6297\u529b\u548c\u7ed3\u6784\u652f\u6301\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u6dfb\u52a0\u5242\uff08\u6d0b\u8f66\u524d\u80f6\u3001\u74dc\u5c14\u80f6\u3001\u9ea6\u82bd\u7cca\u7cbe\u548c\u5361\u62c9\u80f6\uff09\u5bf9\u5bb6\u5236\u51b0\u6dc7\u6dcb\u7684\u878d\u5316\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b83\u4eec\u5bf9\u878d\u5316\u62b5\u6297\u529b\u548c\u51b0\u6dc7\u6dcb\u7ed3\u6784\u7a33\u5b9a\u6027\u5177\u6709\u79ef\u6781\u4f5c\u7528\u3002\u5728\u5404\u6dfb\u52a0\u5242\u4e2d\uff0c\u8868\u73b0\u51fa\u5dee\u5f02\uff0c\u6709\u4e9b\u6dfb\u52a0\u5242\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u878d\u5316\u62b5\u6297\u529b\u548c\u7ed3\u6784\u652f\u6491\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5e38\u7528\u98df\u54c1\u6dfb\u52a0\u5242\u5728\u51b0\u6dc7\u6dcb\u914d\u65b9\u4e2d\u7684\u529f\u80fd\u4f5c\u7528\uff0c\u4e3a\u5f00\u53d1\u5e73\u8861\u8010\u4e45\u6027\u548c\u7ecf\u6d4e\u6548\u76ca\u7684\u914d\u65b9\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002"}}
{"id": "2509.00510", "categories": ["cs.AI", "cs.CL", "68T99", "I.2.11; I.2.8; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.00510", "abs": "https://arxiv.org/abs/2509.00510", "authors": ["Li Weigang", "Pedro Carvalho Brom", "Lucas Ramson Siefert"], "title": "LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain", "comment": "24 pages, 5 figures", "summary": "We propose a novel SuperBrain framework for collective intelligence, grounded\nin the co-evolution of large language models (LLMs) and human users. Unlike\nstatic prompt engineering or isolated agent simulations, our approach\nemphasizes a dynamic pathway from Subclass Brain to Superclass Brain: (1) A\nSubclass Brain arises from persistent, personalized interaction between a user\nand an LLM, forming a cognitive dyad with adaptive learning memory. (2) Through\nGA-assisted forward-backward evolution, these dyads iteratively refine prompts\nand task performance. (3) Multiple Subclass Brains coordinate via Swarm\nIntelligence, optimizing across multi-objective fitness landscapes and\nexchanging distilled heuristics. (4) Their standardized behaviors and cognitive\nsignatures integrate into a Superclass Brain, an emergent meta-intelligence\ncapable of abstraction, generalization and self-improvement. We outline the\ntheoretical constructs, present initial implementations (e.g., UAV scheduling,\nKU/KI keyword filtering) and propose a registry for cross-dyad knowledge\nconsolidation. This work provides both a conceptual foundation and an\narchitectural roadmap toward scalable, explainable and ethically aligned\ncollective AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SuperBrain\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u52a8\u6001\u8def\u5f84\u4ece\u5b50\u7c7b\u5927\u8111\u5230\u8d85\u7c7b\u5927\u8111\uff0c\u901a\u8fc7\u591a\u4e2a\u5b50\u7c7b\u5927\u8111\u7684\u6f14\u5316\u548c\u534f\u8c03\u5f62\u6210\u5177\u6709\u62bd\u8c61\u5316\u548c\u81ea\u6211\u6539\u8fdb\u80fd\u529b\u7684\u8d85\u7ea7\u5927\u8111\u3002\u8bba\u6587\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u7b26\u5408\u4f26\u7406\u7684\u96c6\u4f53\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u548c\u67b6\u6784\u8def\u7ebf\u56fe\u3002", "motivation": "\u4e0e\u9759\u6001\u63d0\u793a\u8bbe\u8ba1\u6216\u5b64\u7acb\u4ee3\u7406\u6a21\u62df\u4e0d\u540c\uff0c\u5f3a\u8c03\u52a8\u6001\u8def\u5f84\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u7b26\u5408\u4f26\u7406\u7684\u96c6\u4f53\u4eba\u5de5\u667a\u80fd\u7684\u6982\u5ff5\u57fa\u7840\u548c\u67b6\u6784\u8def\u7ebf\u56fe\u3002", "method": "\u901a\u8fc7\u6301\u7eed\u4e2a\u6027\u5316\u4e92\u52a8\u4ea7\u751f\u5b50\u7c7b\u5927\u8111\uff0c\u901a\u8fc7GA\u8f85\u52a9\u7684\u6f14\u5316\u6539\u8fdb\u4efb\u52a1\u8868\u73b0\uff0c\u591a\u4e2a\u5b50\u7c7b\u5927\u8111\u901a\u8fc7\u7fa4\u4f53\u667a\u80fd\u534f\u8c03\uff0c\u5f62\u6210\u8d85\u7c7b\u5927\u8111\u3002", "result": "\u63d0\u51fa\u4e86SuperBrain\u6846\u67b6\uff0c\u8bf4\u660e\u4e86\u5176\u7406\u8bba\u6784\u60f3\uff0c\u5c55\u793a\u4e86\u521d\u59cb\u5b9e\u65bd\uff08\u5982\u65e0\u4eba\u673a\u8c03\u5ea6\uff0cKU/KI\u5173\u952e\u8bcd\u8fc7\u6ee4\uff09\uff0c\u5e76\u63d0\u8bae\u8de8\u53cc\u4eba\u95f4\u77e5\u8bc6\u6574\u5408\u7684\u6ce8\u518c\u8868\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u4eba\u7c7b\u7528\u6237\u5171\u540c\u6f14\u5316\u7684\u8d85\u7ea7\u5927\u8111\u6846\u67b6\uff0c\u5f3a\u8c03\u5b50\u7c7b\u5927\u8111\u5230\u8d85\u7c7b\u5927\u8111\u7684\u52a8\u6001\u8def\u5f84\u3002\u901a\u8fc7GA\u8f85\u52a9\u7684\u524d\u5411-\u540e\u5411\u6f14\u5316\uff0c\u591a\u4e2a\u5b50\u7c7b\u5927\u8111\u901a\u8fc7\u7fa4\u4f53\u667a\u80fd\u534f\u8c03\uff0c\u5f62\u6210\u8d85\u7c7b\u5927\u8111\uff0c\u5177\u6709\u62bd\u8c61\u5316\u3001\u6cdb\u5316\u548c\u81ea\u6211\u6539\u8fdb\u80fd\u529b\u3002"}}
{"id": "2509.00543", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00543", "abs": "https://arxiv.org/abs/2509.00543", "authors": ["Jayakrishna Duggempudi", "Lu Gao", "Ahmed Senouci", "Zhe Han", "Yunpeng Zhang"], "title": "Text-to-Layout: A Generative Workflow for Drafting Architectural Floor Plans Using LLMs", "comment": null, "summary": "This paper presents the development of an AI-powered workflow that uses Large\nLanguage Models (LLMs) to assist in drafting schematic architectural floor\nplans from natural language prompts. The proposed system interprets textual\ninput to automatically generate layout options including walls, doors, windows,\nand furniture arrangements. It combines prompt engineering, a furniture\nplacement refinement algorithm, and Python scripting to produce spatially\ncoherent draft plans compatible with design tools such as Autodesk Revit. A\ncase study of a mid-sized residential layout demonstrates the approach's\nability to generate functional and structured outputs with minimal manual\neffort. The workflow is designed for transparent replication, with all key\nprompt specifications documented to enable independent implementation by other\nresearchers. In addition, the generated models preserve the full range of\nRevit-native parametric attributes required for direct integration into\nprofessional BIM processes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8d77\u8349\u5efa\u7b51\u5e73\u9762\u56fe\u3002\u8be5\u7cfb\u7edf\u7ed3\u5408\u4e86\u63d0\u793a\u5de5\u7a0b\u3001\u5bb6\u5177\u6446\u653e\u7b97\u6cd5\u548cPython\u811a\u672c\uff0c\u751f\u6210\u4e0eAutodesk Revit\u517c\u5bb9\u7684\u7a7a\u95f4\u4e00\u81f4\u7684\u8349\u56fe\u3002\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u751f\u6210\u529f\u80fd\u9f50\u5168\u3001\u7ed3\u6784\u5316\u7684\u8f93\u51fa\uff0c\u9002\u7528\u4e8e\u4e13\u4e1aBIM\u6d41\u7a0b\u3002", "motivation": "\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u6765\u7b80\u5316\u5efa\u7b51\u5e73\u9762\u56fe\u7684\u8d77\u8349\u8fc7\u7a0b\uff0c\u51cf\u5c11\u4eba\u5de5\u52b3\u52a8\uff0c\u63d0\u9ad8\u751f\u6210\u6548\u7387\u3002\u65e8\u5728\u4e3a\u4e13\u4e1aBIM\u6d41\u7a0b\u63d0\u4f9b\u66f4\u5feb\u3001\u66f4\u7cbe\u786e\u7684\u8349\u56fe\u8bbe\u8ba1\u65b9\u6848\u3002", "method": "AI-powered workflow using Large Language Models (LLMs) to assist in drafting architectural floor plans from natural language prompts. The system combines prompt engineering, furniture placement refinement algorithm, and Python scripting to generate spatially coherent draft plans compatible with Autodesk Revit.", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u79cd\u5229\u7528\u4eba\u5de5\u667a\u80fd\u5de5\u4f5c\u6d41\u751f\u6210\u5efa\u7b51\u5e73\u9762\u56fe\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u7b26\u5408\u7a7a\u95f4\u89c4\u8303\u7684\u8349\u56fe\u9009\u9879\uff0c\u5e76\u4fdd\u7559\u4e86Revit\u539f\u751f\u53c2\u6570\u5c5e\u6027\u8303\u56f4\uff0c\u5c55\u793a\u4e86\u5728\u4e2d\u578b\u4f4f\u5b85\u5e03\u5c40\u6848\u4f8b\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8d77\u8349\u65b9\u6848\u5efa\u7b51\u5e73\u9762\u56fe\u3002\u7814\u7a76\u7cfb\u7edf\u89e3\u91ca\u6587\u672c\u8f93\u5165\uff0c\u81ea\u52a8\u751f\u6210\u5305\u62ec\u5899\u58c1\u3001\u95e8\u6237\u3001\u7a97\u6237\u548c\u5bb6\u5177\u6446\u653e\u5728\u5185\u7684\u5e03\u5c40\u9009\u9879\u3002\u5b83\u7ed3\u5408\u4e86\u63d0\u793a\u5de5\u7a0b\u3001\u5bb6\u5177\u6446\u653e\u7ec6\u5316\u7b97\u6cd5\u548cPython\u811a\u672c\u7f16\u5199\uff0c\u751f\u6210\u4e86\u4e0e\u8bbe\u8ba1\u5de5\u5177Autodesk Revit\u517c\u5bb9\u7684\u7a7a\u95f4\u4e00\u81f4\u7684\u8349\u56fe\u3002\u5bf9\u4e2d\u578b\u4f4f\u5b85\u5e03\u5c40\u7684\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5\u6700\u5c11\u7684\u4eba\u5de5\u52aa\u529b\u751f\u6210\u529f\u80fd\u9f50\u5168\u3001\u7ed3\u6784\u5316\u7684\u8f93\u51fa\u3002\u8be5\u5de5\u4f5c\u6d41\u7a0b\u8bbe\u8ba1\u900f\u660e\u6613\u590d\u5236\uff0c\u6240\u6709\u5173\u952e\u63d0\u793a\u89c4\u8303\u5747\u6709\u6587\u6863\u8bb0\u5f55\uff0c\u4ee5\u4fbf\u5176\u4ed6\u7814\u7a76\u4eba\u5458\u72ec\u7acb\u5b9e\u65bd\u3002\u6b64\u5916\uff0c\u751f\u6210\u7684\u6a21\u578b\u4fdd\u7559\u4e86\u4e13\u4e1aBIM\u6d41\u7a0b\u76f4\u63a5\u96c6\u6210\u6240\u9700\u7684Revit\u539f\u751f\u53c2\u6570\u5c5e\u6027\u8303\u56f4\u3002"}}
{"id": "2509.00559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00559", "abs": "https://arxiv.org/abs/2509.00559", "authors": ["Xuhui Zhou", "Jiarui Liu", "Akhila Yerukola", "Hyunwoo Kim", "Maarten Sap"], "title": "Social World Models", "comment": null, "summary": "Humans intuitively navigate social interactions by simulating unspoken\ndynamics and reasoning about others' perspectives, even with limited\ninformation. In contrast, AI systems struggle to automatically structure and\nreason about these implicit social contexts. In this paper, we introduce a\nnovel structured social world representation formalism (S3AP), designed to help\nAI systems reason more effectively about social dynamics. Following a\nPOMDP-driven design, S3AP represents social interactions as structured tuples,\nsuch as state, observation, agent actions, and mental states, which can be\nautomatically induced from free-form narratives or other inputs. We first show\nS3AP can help LLMs better understand social narratives across 5 social\nreasoning tasks (e.g., +51% improvement on FANToM's theory-of-mind reasoning\nwith OpenAI's o1), reaching new state-of-the-art (SOTA) performance. We then\ninduce social world models from these structured representations, demonstrating\ntheir ability to predict future social dynamics and improve agent\ndecision-making, yielding up to +18% improvement on the SOTOPIA social\ninteraction benchmark. Our findings highlight the promise of S3AP as a\npowerful, general-purpose representation for social world states, enabling the\ndevelopment of more socially-aware systems that better navigate social\ninteractions.", "AI": {"tldr": "Introducing S3AP, a structured social world representation, to enhance AI systems' understanding of social dynamics. S3AP improves social reasoning tasks, achieves state-of-the-art performance, and enhances agent decision-making in predicting future social dynamics. It serves as a promising general-purpose representation for social world states.", "motivation": "AI systems face challenges in automatically structuring and reasoning about implicit social contexts, unlike humans who intuitively navigate social interactions by simulating dynamics and considering others' perspectives. The motivation is to bridge this gap by introducing S3AP to enable more effective reasoning about social dynamics in AI systems.", "method": "Introducing a novel structured social world representation formalism (S3AP) designed to enhance AI systems' reasoning about social dynamics. The design follows a POMDP-driven approach, representing social interactions as structured tuples including state, observation, agent actions, and mental states, which can be induced from free-form narratives or other inputs.", "result": "S3AP helps LLMs better understand social narratives across 5 social reasoning tasks, achieving a significant improvement in theory-of-mind reasoning. It also induces social world models from structured representations, improving agent decision-making in predicting future social dynamics and achieving better performance in the SOTOPIA social interaction benchmark.", "conclusion": "S3AP is effective in helping AI systems better understand social dynamics and achieve state-of-the-art performance in social reasoning tasks. It also improves agent decision-making in predicting future social dynamics, showing its promise as a general-purpose representation for social world states."}}
{"id": "2509.00622", "categories": ["cs.AI", "cs.IR", "H.3; I.2"], "pdf": "https://arxiv.org/pdf/2509.00622", "abs": "https://arxiv.org/abs/2509.00622", "authors": ["Shiqiao Zhou", "Holger Sch\u00f6ner", "Huanbo Lyu", "Edouard Fouch\u00e9", "Shuo Wang"], "title": "BALM-TSF: Balanced Multimodal Alignment for LLM-Based Time Series Forecasting", "comment": null, "summary": "Time series forecasting is a long-standing and highly challenging research\ntopic. Recently, driven by the rise of large language models (LLMs), research\nhas increasingly shifted from purely time series methods toward harnessing\ntextual modalities to enhance forecasting performance. However, the vast\ndiscrepancy between text and temporal data often leads current multimodal\narchitectures to over-emphasise one modality while neglecting the other,\nresulting in information loss that harms forecasting performance. To address\nthis modality imbalance, we introduce BALM-TSF (Balanced Multimodal Alignment\nfor LLM-Based Time Series Forecasting), a lightweight time series forecasting\nframework that maintains balance between the two modalities. Specifically, raw\ntime series are processed by the time series encoder, while descriptive\nstatistics of raw time series are fed to an LLM with learnable prompt,\nproducing compact textual embeddings. To ensure balanced cross-modal context\nalignment of time series and textual embeddings, a simple yet effective scaling\nstrategy combined with a contrastive objective then maps these textual\nembeddings into the latent space of the time series embeddings. Finally, the\naligned textual semantic embeddings and time series embeddings are together\nintegrated for forecasting. Extensive experiments on standard benchmarks show\nthat, with minimal trainable parameters, BALM-TSF achieves state-of-the-art\nperformance in both long-term and few-shot forecasting, confirming its ability\nto harness complementary information from text and time series. Code is\navailable at https://github.com/ShiqiaoZhou/BALM-TSF.", "AI": {"tldr": "BALM-TSF is a lightweight time series forecasting framework that balances textual and temporal modalities for enhanced forecasting performance. It achieves state-of-the-art results in both long-term and few-shot forecasting by integrating aligned textual and time series embeddings using a cross-modal context alignment strategy.", "motivation": "Driven by the rise of large language models (LLMs), the research aims to enhance forecasting performance by leveraging textual modalities in addition to time series methods. The goal is to address the imbalance between text and temporal data in current multimodal architectures to prevent information loss that harms forecasting performance.", "method": "The method involves processing raw time series data with a time series encoder, while feeding descriptive statistics of the data to a large language model with a learnable prompt to produce textual embeddings. A scaling strategy combined with a contrastive objective is used to ensure balanced cross-modal context alignment. The aligned textual embeddings and time series embeddings are integrated for forecasting.", "result": "Extensive experiments on standard benchmarks demonstrate that BALM-TSF achieves state-of-the-art performance in long-term and few-shot forecasting with minimal trainable parameters, confirming its ability to harness complementary information from text and time series.", "conclusion": "BALM-TSF (Balanced Multimodal Alignment for LLM-Based Time Series Forecasting) introduces a lightweight time series forecasting framework that maintains balance between textual and temporal modalities, achieving state-of-the-art performance in both long-term and few-shot forecasting."}}
{"id": "2509.00625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00625", "abs": "https://arxiv.org/abs/2509.00625", "authors": ["Jaber Daneshamooz", "Eugene Vuong", "Laasya Koduru", "Sanjay Chandrasekaran", "Arpit Gupta"], "title": "NetGent: Agent-Based Automation of Network Application Workflows", "comment": null, "summary": "We present NetGent, an AI-agent framework for automating complex application\nworkflows to generate realistic network traffic datasets. Developing\ngeneralizable ML models for networking requires data collection from network\nenvironments with traffic that results from a diverse set of real-world web\napplications. However, using existing browser automation tools that are\ndiverse, repeatable, realistic, and efficient remains fragile and costly.\nNetGent addresses this challenge by allowing users to specify workflows as\nnatural-language rules that define state-dependent actions. These abstract\nspecifications are compiled into nondeterministic finite automata (NFAs), which\na state synthesis component translates into reusable, executable code. This\ndesign enables deterministic replay, reduces redundant LLM calls through state\ncaching, and adapts quickly when application interfaces change. In experiments,\nNetGent automated more than 50+ workflows spanning video-on-demand streaming,\nlive video streaming, video conferencing, social media, and web scraping,\nproducing realistic traffic traces while remaining robust to UI variability. By\ncombining the flexibility of language-based agents with the reliability of\ncompiled execution, NetGent provides a scalable foundation for generating the\ndiverse, repeatable datasets needed to advance ML in networking.", "AI": {"tldr": "NetGent is an AI-agent framework that automates complex application workflows to generate realistic network traffic datasets efficiently and reliably. It allows users to specify workflows through natural-language rules, compiled into NFAs for executable code. It automated various workflows in experiments, proving its scalability and reliability for ML dataset generation in networking.", "motivation": "Developing ML models for networking requires data collection from network environments with diverse real-world web application traffic. Existing automation tools are fragile and costly, leading to the need for a more efficient solution like NetGent.", "method": "NetGent allows users to specify workflows as natural-language rules that define state-dependent actions, which are compiled into nondeterministic finite automata (NFAs). These NFAs are translated into reusable, executable code for deterministic replay, reduced redundant calls, and quick adaptation to interface changes.", "result": "In experiments, NetGent automated over 50 workflows including video-on-demand streaming, live video streaming, video conferencing, social media, and web scraping. It produced realistic traffic traces while remaining robust to UI variability.", "conclusion": "NetGent provides a scalable foundation for generating diverse and repeatable datasets needed to advance ML in networking. It automates complex application workflows to produce realistic network traffic datasets efficiently and reliably."}}
{"id": "2509.00710", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00710", "abs": "https://arxiv.org/abs/2509.00710", "authors": ["Albert Sadowski", "Jaros\u0142aw A. Chudziak"], "title": "On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations", "comment": "Accepted for publication at the 34th ACM International Conference on\n  Information and Knowledge Management (CIKM '25)", "summary": "Legal reasoning requires both precise interpretation of statutory language\nand consistent application of complex rules, presenting significant challenges\nfor AI systems. This paper introduces a modular multi-agent framework that\ndecomposes legal reasoning into distinct knowledge acquisition and application\nstages. In the first stage, specialized agents extract legal concepts and\nformalize rules to create verifiable intermediate representations of statutes.\nThe second stage applies this knowledge to specific cases through three steps:\nanalyzing queries to map case facts onto the ontology schema, performing\nsymbolic inference to derive logically entailed conclusions, and generating\nfinal answers using a programmatic implementation that operationalizes the\nontological knowledge. This bridging of natural language understanding with\nsymbolic reasoning provides explicit and verifiable inspection points,\nsignificantly enhancing transparency compared to end-to-end approaches.\nEvaluation on statutory tax calculation tasks demonstrates substantial\nimprovements, with foundational models achieving 76.4\\% accuracy compared to\n18.8\\% baseline performance, effectively narrowing the performance gap between\nreasoning and foundational models. These findings suggest that modular\narchitectures with formalized knowledge representations can make sophisticated\nlegal reasoning more accessible through computationally efficient models while\nenhancing consistency and explainability in AI legal reasoning, establishing a\nfoundation for future research into more transparent, trustworthy, and\neffective AI systems for legal domain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u591aAgent\u6846\u67b6\uff0c\u5c06\u6cd5\u5f8b\u63a8\u7406\u5206\u89e3\u4e3a\u77e5\u8bc6\u83b7\u53d6\u548c\u5e94\u7528\u4e24\u4e2a\u9636\u6bb5\u3002\u901a\u8fc7\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u6709\u6548\u7f29\u5c0f\u4e86\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u5728\u6cd5\u5b9a\u7a0e\u6536\u8ba1\u7b97\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0c\u8868\u660e\u6a21\u5757\u5316\u67b6\u6784\u5177\u6709\u5f62\u5f0f\u5316\u77e5\u8bc6\u8868\u793a\u53ef\u4ee5\u4f7f\u6cd5\u5f8b\u63a8\u7406\u66f4\u6613\u4e8e\u8bbf\u95ee\uff0c\u63d0\u5347\u4e00\u81f4\u6027\u548c\u89e3\u91ca\u6027\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u900f\u660e\u3001\u53ef\u4fe1\u8d56\u548c\u6709\u6548\u7684AI\u6cd5\u5f8b\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u9488\u5bf9AI\u7cfb\u7edf\u5728\u6cd5\u5f8b\u63a8\u7406\u4e2d\u9762\u4e34\u7684\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u4f7f\u6cd5\u5f8b\u63a8\u7406\u66f4\u52a0\u53ef\u7406\u89e3\u3001\u900f\u660e\u548c\u4e00\u81f4\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u6a21\u5757\u5316\u7684\u65b9\u6cd5\uff0c\u5c06\u6cd5\u5f8b\u63a8\u7406\u5206\u89e3\u4e3a\u4e0d\u540c\u9636\u6bb5\uff0c\u4ee5\u5b9e\u73b0\u5f62\u5f0f\u5316\u77e5\u8bc6\u8868\u793a\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u900f\u660e\u5ea6\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u591aAgent\u6846\u67b6\uff0c\u5206\u4e3a\u77e5\u8bc6\u83b7\u53d6\u548c\u5e94\u7528\u4e24\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u9636\u6bb5\u7531\u4e13\u95e8\u7684Agent\u4ece\u6cd5\u5f8b\u4e2d\u63d0\u53d6\u6982\u5ff5\uff0c\u5f62\u5f0f\u5316\u89c4\u5219\uff0c\u521b\u9020\u53ef\u9a8c\u8bc1\u7684\u6cd5\u89c4\u4e2d\u95f4\u8868\u793a\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u5206\u6790\u67e5\u8be2\u3001\u6267\u884c\u7b26\u53f7\u63a8\u7406\u548c\u4f7f\u7528\u7a0b\u5e8f\u5b9e\u73b0\u751f\u6210\u6700\u7ec8\u7b54\u6848\uff0c\u5b9e\u73b0\u4e86\u672c\u4f53\u77e5\u8bc6\u7684\u64cd\u4f5c\u5316\u3002\u5c06\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e0e\u7b26\u53f7\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\u3002\u5728\u6cd5\u5b9a\u7a0e\u6536\u8ba1\u7b97\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u6539\u8fdb\uff0c\u57fa\u7840\u6a21\u578b\u51c6\u786e\u7387\u8fbe\u5230\u4e8676.4%\u3002", "result": "\u4ecb\u7ecd\u7684\u6a21\u5757\u5316\u591aAgent\u6846\u67b6\u6709\u6548\u7f29\u5c0f\u4e86\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u4f7f\u57fa\u7840\u6a21\u578b\u5728\u6cd5\u5b9a\u7a0e\u6536\u8ba1\u7b97\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u5230\u4e8676.4%\u3002\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u900f\u660e\u3001\u53ef\u4fe1\u8d56\u548c\u6709\u6548\u7684AI\u6cd5\u5f8b\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u591aAgent\u6846\u67b6\uff0c\u5c06\u6cd5\u5f8b\u63a8\u7406\u5206\u89e3\u4e3a\u77e5\u8bc6\u83b7\u53d6\u548c\u5e94\u7528\u4e24\u4e2a\u9636\u6bb5\u3002\u901a\u8fc7\u5728\u7b2c\u4e00\u9636\u6bb5\u4e13\u95e8\u7684Agent\u63d0\u53d6\u6cd5\u5f8b\u6982\u5ff5\u5e76\u5f62\u5f0f\u5316\u89c4\u5219\uff0c\u521b\u9020\u53ef\u9a8c\u8bc1\u7684\u6cd5\u89c4\u4e2d\u95f4\u8868\u793a\u3002\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u4e09\u4e2a\u6b65\u9aa4\u5c06\u8fd9\u4e9b\u77e5\u8bc6\u5e94\u7528\u4e8e\u7279\u5b9a\u6848\u4f8b\uff1a\u5206\u6790\u67e5\u8be2\u4ee5\u5c06\u6848\u4ef6\u4e8b\u5b9e\u6620\u5c04\u5230\u672c\u4f53\u6a21\u5f0f\uff0c\u6267\u884c\u7b26\u53f7\u63a8\u7406\u4ee5\u63a8\u5bfc\u903b\u8f91\u542b\u4e49\u7684\u7ed3\u8bba\uff0c\u4f7f\u7528\u7a0b\u5e8f\u5b9e\u73b0\u751f\u6210\u6700\u7ec8\u7b54\u6848\uff0c\u5c06\u672c\u4f53\u77e5\u8bc6\u5b9e\u7528\u5316\u3002\u5c06\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e0e\u7b26\u53f7\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u660e\u786e\u548c\u53ef\u9a8c\u8bc1\u7684\u68c0\u67e5\u70b9\uff0c\u4e0e\u7aef\u5230\u7aef\u65b9\u6cd5\u76f8\u6bd4\u663e\u8457\u589e\u5f3a\u4e86\u900f\u660e\u5ea6\u3002\u5728\u6cd5\u5b9a\u7a0e\u6536\u8ba1\u7b97\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\uff0c\u57fa\u7840\u6a21\u578b\u8fbe\u5230\u4e8676.4%\u7684\u51c6\u786e\u7387\uff0c\u800c\u57fa\u51c6\u6027\u80fd\u4e3a18.8%\uff0c\u6709\u6548\u7f29\u5c0f\u4e86\u63a8\u7406\u548c\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u5177\u6709\u5f62\u5f0f\u5316\u77e5\u8bc6\u8868\u793a\u7684\u6a21\u5757\u5316\u67b6\u6784\u53ef\u4ee5\u901a\u8fc7\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u6a21\u578b\u4f7f\u590d\u6742\u7684\u6cd5\u5f8b\u63a8\u7406\u66f4\u6613\u4e8e\u8bbf\u95ee\uff0c\u540c\u65f6\u589e\u5f3a\u4e86AI\u6cd5\u5f8b\u63a8\u7406\u7684\u4e00\u81f4\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u672a\u6765\u8fdb\u4e00\u6b65\u7814\u7a76\u5efa\u7acb\u4e86\u57fa\u7840\uff0c\u4ee5\u5f00\u53d1\u66f4\u900f\u660e\u3001\u53ef\u4fe1\u8d56\u548c\u6709\u6548\u7684\u6cd5\u5f8b\u9886\u57dfAI\u7cfb\u7edf\u3002"}}
{"id": "2509.00723", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.00723", "abs": "https://arxiv.org/abs/2509.00723", "authors": ["Junzhe Chen", "Tianshu Zhang", "Shiyu Huang", "Yuwei Niu", "Chao Sun", "Rongzhou Zhang", "Guanyu Zhou", "Lijie Wen", "Xuming Hu"], "title": "OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination", "comment": null, "summary": "Recently, Omni-modal large language models (OLLMs) have sparked a new wave of\nresearch, achieving impressive results in tasks such as audio-video\nunderstanding and real-time environment perception. However, hallucination\nissues still persist. Similar to the bimodal setting, the priors from the text\nmodality tend to dominate, leading OLLMs to rely more heavily on textual cues\nwhile neglecting visual and audio information. In addition, fully multimodal\nscenarios introduce new challenges. Most existing models align visual or\nauditory modalities with text independently during training, while ignoring the\nintrinsic correlations between video and its corresponding audio. This\noversight results in hallucinations when reasoning requires interpreting hidden\naudio cues embedded in video content. To address these challenges, we propose\nOmniDPO, a preference-alignment framework designed to mitigate hallucinations\nin OLLMs. Specifically, OmniDPO incorporates two strategies: (1) constructing\ntext-preference sample pairs to enhance the model's understanding of\naudio-video interactions; and (2) constructing multimodal-preference sample\npairs to strengthen the model's attention to visual and auditory information.\nBy tackling both challenges, OmniDPO effectively improves multimodal grounding\nand reduces hallucination. Experiments conducted on two OLLMs demonstrate that\nOmniDPO not only effectively mitigates multimodal hallucinations but also\nsignificantly enhances the models' reasoning capabilities across modalities.\nAll code and datasets will be released upon paper acceptance.", "AI": {"tldr": "OmniDPO is proposed to address hallucination issues in OLLMs by aligning preferences between text, audio, and video modalities. The framework improves multimodal grounding and reasoning capabilities, demonstrated through experiments on two OLLMs.", "motivation": "Existing OLLMs face hallucination issues where textual cues dominate and ignore visual and audio information. Fully multimodal scenarios pose challenges as the intrinsic correlations between video and audio are often overlooked, leading to hallucinations. The paper aims to address these challenges and improve OLLMs' multimodal grounding and reasoning abilities.", "method": "OmniDPO incorporates two strategies: constructing text-preference sample pairs to enhance the model's understanding of audio-video interactions and constructing multimodal-preference sample pairs to strengthen the model's attention to visual and auditory information.", "result": "Experiments on two OLLMs show that OmniDPO effectively mitigates multimodal hallucinations and enhances reasoning capabilities across modalities.", "conclusion": "OmniDPO is proposed to mitigate hallucination issues in Omni-modal large language models (OLLMs) by incorporating preference-alignment strategies. The framework effectively improves multimodal grounding and reasoning capabilities across modalities."}}
{"id": "2509.00740", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00740", "abs": "https://arxiv.org/abs/2509.00740", "authors": ["Govind Waghmare", "Sumedh BG", "Sonia Gupta", "Srikanta Bedathur"], "title": "Efficient Graph Understanding with LLMs via Structured Context Injection", "comment": null, "summary": "Large Language Models (LLMs) have shown strong capabilities in solving\nproblems across domains, including graph-related tasks traditionally addressed\nby symbolic or algorithmic methods. In this work, we present a framework for\nstructured context injection, where task-specific information is systematically\nembedded in the input to guide LLMs in solving a wide range of graph problems.\nOur method does not require fine-tuning of LLMs, making it cost-efficient and\nlightweight. We observe that certain graph reasoning tasks remain challenging\nfor LLMs unless they are mapped to conceptually grounded representations.\nHowever, achieving such mappings through fine-tuning or repeated multi-step\nquerying can be expensive and inefficient. Our approach offers a practical\nalternative by injecting structured context directly into the input, enabling\nthe LLM to implicitly align the task with grounded conceptual spaces. We\nevaluate the approach on multiple graph tasks using both lightweight and large\nmodels, highlighting the trade-offs between accuracy and computational cost.\nThe results demonstrate consistent performance improvements, showing that\nstructured input context can rival or surpass more complex approaches. Our\nfindings underscore the value of structured context injection as an effective\nand scalable strategy for graph understanding with LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6ce8\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u5411\u8f93\u5165\u76f4\u63a5\u6ce8\u5165\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\uff0c\u5e2e\u52a9LLMs\u5728\u89e3\u51b3\u5404\u79cd\u56fe\u95ee\u9898\u65f6\u53d6\u5f97\u6027\u80fd\u6539\u5584\uff0c\u65e0\u9700\u7cbe\u7ec6\u8c03\u6574\u3002\u7ed3\u679c\u663e\u793a\uff0c\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6ce8\u5165\u662f\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u56fe\u7406\u89e3\u7b56\u7565\uff0c\u80fd\u591f\u4e0e\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u7ade\u4e89\u751a\u81f3\u8d85\u8d8a\u5176\u6027\u80fd\u3002", "motivation": "\u89c2\u5bdf\u5230\u5bf9\u4e8eLLMs\u800c\u8a00\uff0c\u67d0\u4e9b\u56fe\u63a8\u7406\u4efb\u52a1\u4ecd\u5177\u6709\u6311\u6218\u6027\uff0c\u9664\u975e\u5b83\u4eec\u88ab\u6620\u5c04\u5230\u6982\u5ff5\u4e0a\u624e\u5b9e\u7684\u8868\u793a\u7a7a\u95f4\u3002fine-tuning\u6216\u591a\u6b65\u67e5\u8be2\u53ef\u80fd\u6602\u8d35\u4e14\u4f4e\u6548\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u51fa\u5b9e\u9645\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6ce8\u5165\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u7cfb\u7edf\u5730\u5d4c\u5165\u8f93\u5165\uff0c\u5f15\u5bfcLLMs\u89e3\u51b3\u5404\u79cd\u56fe\u95ee\u9898\uff0c\u800c\u65e0\u9700\u5bf9LLMs\u8fdb\u884c\u7cbe\u7ec6\u8c03\u6574\uff0c\u4ece\u800c\u8282\u7ea6\u6210\u672c\u4e14\u8f7b\u91cf\u7ea7\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u56fe\u4efb\u52a1\u4e0a\u4f7f\u7528\u8f7b\u91cf\u7ea7\u548c\u5927\u578b\u6a21\u578b\u8bc4\u4f30\u8be5\u65b9\u6cd5\uff0c\u7a81\u663e\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u6784\u5316\u8f93\u5165\u4e0a\u4e0b\u6587\u80fd\u591f\u4e0e\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u7ade\u4e89\u751a\u81f3\u8d85\u8d8a\u5176\u6027\u80fd\u3002", "conclusion": "\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6ce8\u5165\u662f\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u56fe\u7406\u89e3\u7b56\u7565\uff0c\u80fd\u5e2e\u52a9LLMs\u5728\u89e3\u51b3\u5404\u79cd\u56fe\u95ee\u9898\u65f6\u53d6\u5f97\u4e00\u81f4\u7684\u6027\u80fd\u6539\u5584\u3002"}}
{"id": "2509.00761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00761", "abs": "https://arxiv.org/abs/2509.00761", "authors": ["Ziqi Wang", "Boqin Yuan"], "title": "L-MARS -- Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search", "comment": null, "summary": "We present L-MARS (Legal Multi-Agent Workflow with Orchestrated Reasoning and\nAgentic Search), a system that reduces hallucination and uncertainty in legal\nquestion answering through coordinated multi-agent reasoning and retrieval.\nUnlike single-pass retrieval-augmented generation (RAG), L-MARS decomposes\nqueries into subproblems, issues targeted searches across heterogeneous sources\n(Serper web, local RAG, CourtListener case law), and employs a Judge Agent to\nverify sufficiency, jurisdiction, and temporal validity before answer\nsynthesis. This iterative reasoning-search-verification loop maintains\ncoherence, filters noisy evidence, and grounds answers in authoritative law. We\nevaluated L-MARS on LegalSearchQA, a new benchmark of 200 up-to-date multiple\nchoice legal questions in 2025. Results show that L-MARS substantially improves\nfactual accuracy, reduces uncertainty, and achieves higher preference scores\nfrom both human experts and LLM-based judges. Our work demonstrates that\nmulti-agent reasoning with agentic search offers a scalable and reproducible\nblueprint for deploying LLMs in high-stakes domains requiring precise legal\nretrieval and deliberation.", "AI": {"tldr": "L-MARS\u7cfb\u7edf\u901a\u8fc7\u534f\u8c03\u591a\u667a\u80fd\u4f53\u63a8\u7406\u548c\u68c0\u7d22\uff0c\u5728\u6cd5\u5f8b\u95ee\u9898\u56de\u7b54\u4e2d\u964d\u4f4e\u4e86\u5e7b\u89c9\u548c\u4e0d\u786e\u5b9a\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728LegalSearchQA\u8bc4\u4f30\u4e2d\uff0cL-MARS\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u53d7\u5230\u4eba\u7c7b\u4e13\u5bb6\u548c\u57fa\u4e8eLLM\u7684\u6cd5\u5b98\u66f4\u9ad8\u7684\u9752\u7750\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6cd5\u5f8b\u95ee\u9898\u56de\u7b54\u4e2d\u7684\u5e7b\u89c9\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u9ad8\u56de\u7b54\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e3a\u5728\u9700\u8981\u7cbe\u786e\u6cd5\u5f8b\u68c0\u7d22\u548c\u5ba1\u8bae\u7684\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72LLM\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u53ef\u590d\u5236\u7684\u65b9\u6cd5\u3002", "method": "L-MARS\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\uff0c\u5e76\u5728\u5f02\u6784\u6765\u6e90\uff08Serper\u7f51\u7edc\u3001\u672c\u5730RAG\u3001CourtListener\u6848\u4f8b\u6cd5\uff09\u4e0a\u53d1\u8d77\u6709\u9488\u5bf9\u6027\u7684\u641c\u7d22\uff0c\u4f7f\u7528\u6cd5\u5b98\u667a\u80fd\u4f53\u5728\u56de\u7b54\u7efc\u5408\u4e4b\u524d\u9a8c\u8bc1\u5145\u5206\u6027\u3001\u53f8\u6cd5\u7ba1\u8f96\u6743\u548c\u65f6\u95f4\u6709\u6548\u6027\u3002\u901a\u8fc7\u8fd9\u79cd\u8fed\u4ee3\u7684\u63a8\u7406-\u641c\u7d22-\u9a8c\u8bc1\u5faa\u73af\uff0c\u4fdd\u6301\u8fde\u8d2f\u6027\uff0c\u8fc7\u6ee4\u5608\u6742\u8bc1\u636e\uff0c\u5e76\u57fa\u4e8e\u6743\u5a01\u6cd5\u5f8b\u786e\u7acb\u7b54\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cL-MARS\u5728LegalSearchQA\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u6539\u5584\uff0c\u5e76\u83b7\u5f97\u4e86\u4eba\u7c7b\u4e13\u5bb6\u548c\u57fa\u4e8eLLM\u7684\u6cd5\u5b98\u66f4\u9ad8\u7684\u504f\u7231\u5206\u6570\u3002", "conclusion": "L-MARS\u7cfb\u7edf\u901a\u8fc7\u534f\u8c03\u591a\u667a\u80fd\u4f53\u63a8\u7406\u548c\u68c0\u7d22\uff0c\u964d\u4f4e\u4e86\u6cd5\u5f8b\u95ee\u9898\u56de\u7b54\u4e2d\u7684\u5e7b\u89c9\u548c\u4e0d\u786e\u5b9a\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cL-MARS\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u83b7\u5f97\u4e86\u6765\u81ea\u4eba\u7c7b\u4e13\u5bb6\u548c\u57fa\u4e8eLLM\u7684\u6cd5\u5b98\u66f4\u9ad8\u7684\u504f\u7231\u5206\u6570\u3002\u7814\u7a76\u8868\u660e\uff0c\u591a\u667a\u80fd\u4f53\u63a8\u7406\u4e0e\u667a\u80fd\u641c\u7d22\u4e3a\u5728\u9700\u8981\u7cbe\u786e\u6cd5\u5f8b\u68c0\u7d22\u548c\u5ba1\u8bae\u7684\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72LLM\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u5236\u7684\u84dd\u56fe\u3002"}}
{"id": "2509.00768", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00768", "abs": "https://arxiv.org/abs/2509.00768", "authors": ["Lee Hyun", "Sohee Yoon", "Jinwoo Park", "Sue In Chae", "Seongeon Park", "Jooyeon Ahn", "Yebin Jung", "Youjung Chung", "Hogeun Chang", "Myeonginn Kang", "Jina Kim", "Ho-Gyeong Kim", "Myeonghun Jeong"], "title": "Aligning Reasoning LLMs for Materials Discovery with Physics-aware Rejection Sampling", "comment": "14 pages, 5 figures", "summary": "AI-driven materials discovery that couples automated experimentation with\nalgorithmic decision-making requires process aware recipe to property\npredictors that are accurate, calibrated, and physically admissible. We\napproach this as a reasoning problem with large reasoning models (LRMs). To\ninstill reasoning capability into language models, we curate reasoning traces\nfrom a teacher model to train a student model. However, most training pipelines\nselect reasoning traces using binary correctness or learned preference signals\nthat poorly reflect physical admissibility. We introduce Physics-aware\nRejection Sampling (PaRS), a training-time trace selection scheme that favors\ntraces consistent with fundamental physics and numerically close to targets,\nwith lightweight halting to control compute. We instantiate our framework with\na large student model fine-tuned on traces synthesized by a larger teacher\nmodel, and evaluate under matched token budgets against various rejection\nsampling baselines. Our method improves accuracy and calibration, reduces\nphysics-violation rates, and lowers sampling cost relative to baselines. These\nresults indicate that modest, domain-aware constraints combined with\ntrace-level selection provide a practical path toward reliable, efficient LRMs\nfor process-aware property prediction and closed-loop materials design.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u611f\u77e5\u7684\u62d2\u7edd\u62bd\u6837\uff08PaRS\uff09\u65b9\u6848\uff0c\u7528\u4e8e\u63d0\u9ad8AI\u9a71\u52a8\u7684\u6750\u6599\u53d1\u73b0\u4e2d\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\uff0c\u964d\u4f4e\u7269\u7406\u8fdd\u89c4\u7387\u548c\u62bd\u6837\u6210\u672c\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u7b26\u5408\u57fa\u672c\u7269\u7406\u89c4\u5f8b\u4e14\u63a5\u8fd1\u76ee\u6807\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5728\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6548\u679c\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8eAI\u9a71\u52a8\u7684\u6750\u6599\u63a2\u7d22\u9700\u8981\u51c6\u786e\u3001\u6821\u51c6\u4e14\u7269\u7406\u53ef\u4fe1\u7684\u8fc7\u7a0b\u611f\u77e5\u914d\u65b9\uff0c\u63d0\u9ad8\u63a8\u7406\u6a21\u578b\u7684\u80fd\u529b\u3002\u73b0\u6709\u7684\u8bad\u7ec3\u6d41\u7a0b\u4e2d\uff0c\u5e38\u4f7f\u7528\u4e8c\u5143\u6b63\u786e\u6027\u6216\u5b66\u4e60\u7684\u504f\u597d\u4fe1\u53f7\u6765\u9009\u62e9\u63a8\u7406\u8f68\u8ff9\uff0c\u4f46\u8fd9\u5f80\u5f80\u65e0\u6cd5\u5f88\u597d\u5730\u53cd\u6620\u7269\u7406\u53ef\u4fe1\u5ea6\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u91c7\u7528\u7269\u7406\u611f\u77e5\u7684\u62d2\u7edd\u62bd\u6837\uff08PaRS\uff09\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9009\u62e9\u7b26\u5408\u57fa\u672c\u7269\u7406\u89c4\u5f8b\u4e14\u63a5\u8fd1\u76ee\u6807\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u57f9\u517b\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u51c6\u786e\u6027\u3001\u6821\u51c6\u6027\u548c\u7269\u7406\u53ef\u4fe1\u5ea6\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u7269\u7406\u611f\u77e5\u7684\u62d2\u7edd\u62bd\u6837\uff08PaRS\uff09\u65b9\u6848\uff0c\u5728\u5339\u914d\u8bb0\u53f7\u9884\u7b97\u4e0b\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\uff0c\u964d\u4f4e\u4e86\u7269\u7406\u8fdd\u89c4\u7387\u548c\u62bd\u6837\u6210\u672c\u3002\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u663e\u793a\u51fa\u4e86\u660e\u663e\u7684\u6539\u8fdb\u6548\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u611f\u77e5\u7684\u62d2\u7edd\u62bd\u6837\uff08PaRS\uff09\u65b9\u6848\uff0c\u7528\u4e8eAI\u9a71\u52a8\u7684\u6750\u6599\u53d1\u73b0\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u6821\u51c6\u6027\u548c\u7269\u7406\u53ef\u4fe1\u5ea6\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9009\u62e9\u7b26\u5408\u57fa\u672c\u7269\u7406\u89c4\u5f8b\u4e14\u63a5\u8fd1\u76ee\u6807\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u8be5\u65b9\u6cd5\u5728\u5339\u914d\u8bb0\u53f7\u9884\u7b97\u4e0b\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\uff0c\u964d\u4f4e\u4e86\u7269\u7406\u8fdd\u89c4\u7387\u548c\u62bd\u6837\u6210\u672c\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u9002\u5ea6\u7684\u9886\u57df\u611f\u77e5\u7ea6\u675f\u548c\u8ddf\u8e2a\u7ea7\u522b\u7684\u9009\u62e9\uff0c\u4e3a\u8fc7\u7a0b\u611f\u77e5\u6027\u80fd\u9884\u6d4b\u548c\u95ed\u73af\u6750\u6599\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u9ad8\u6548\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u8def\u5f84\u3002"}}
{"id": "2509.00793", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00793", "abs": "https://arxiv.org/abs/2509.00793", "authors": ["Shuai Ma", "Guangwu Liu", "Li Xia"], "title": "Sharpe Ratio Optimization in Markov Decision Processes", "comment": null, "summary": "Sharpe ratio (also known as reward-to-variability ratio) is a widely-used\nmetric in finance, which measures the additional return at the cost of per unit\nof increased risk (standard deviation of return). However, the optimization of\nSharpe ratio in Markov decision processes (MDPs) is challenging, because there\nexist two difficulties hindering the application of dynamic programming. One is\nthat dynamic programming does not work for fractional objectives, and the other\nis that dynamic programming is invalid for risk metrics. In this paper, we\nstudy the Sharpe ratio optimization in infinite-horizon MDPs, considering both\nthe long-run average and discounted settings. We address the first challenge\nwith the Dinkelbachs transform, which converts the Sharpe ratio objective to a\nmean-squared-variance (M2V) objective. It is shown that the M2V optimization\nand the original Sharpe ratio optimization share the same optimal policy when\nthe risk-sensitive parameter is equal to the optimal Sharpe ratio. For the\nsecond challenge, we develop an iterative algorithm to solve the M2V\noptimization which is similar to a mean-variance optimization in MDPs. We\niteratively solve the M2V problem and obtain the associated Sharpe ratio that\nis used to update the risk-sensitive parameter in the next iteration of M2V\nproblems. We show that such a sequence of Sharpe ratios derived is\nmonotonically increasing and converges to the optimal Sharpe ratio. For both\naverage and discounted MDP settings, we develop a policy iteration procedure\nand prove its convergence to the optimum. Numerical experiments are conducted\nfor validation. To the best of our knowledge, our approach is the first that\nsolves the Sharpe ratio optimization in MDPs with dynamic programming type\nalgorithms. We believe that the proposed algorithm can shed light on solving\nMDPs with other fractional objectives.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u65e0\u9650\u65f6\u95f4\u8de8\u5ea6\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u590f\u666e\u6bd4\u7387\u4f18\u5316\u95ee\u9898\u3002\u901a\u8fc7Dinkelbachs\u53d8\u6362\u5c06\u590f\u666e\u6bd4\u7387\u76ee\u6807\u8f6c\u6362\u4e3a\u5747\u65b9\u5dee\uff08M2V\uff09\u76ee\u6807\uff0c\u5e76\u5f00\u53d1\u4e86\u8fed\u4ee3\u7b97\u6cd5\u548c\u7b56\u7565\u8fed\u4ee3\u8fc7\u7a0b\u7528\u4e8e\u6c42\u89e3\u6700\u4f18\u89e3\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u590f\u666e\u6bd4\u7387\u4f18\u5316\u7684\u6311\u6218\uff0c\u5728\u5904\u7406\u52a8\u6001\u89c4\u5212\u4e2d\u65e0\u6cd5\u5904\u7406\u7684\u5206\u6570\u76ee\u6807\u548c\u98ce\u9669\u6307\u6807\u65b9\u9762\u63d0\u51fa\u65b0\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u4f7f\u7528Dinkelbachs\u53d8\u6362\u5c06\u590f\u666e\u6bd4\u7387\u76ee\u6807\u8f6c\u6362\u4e3a\u5747\u65b9\u5dee\uff08M2V\uff09\u76ee\u6807\uff0c\u5f00\u53d1\u4e86\u8fed\u4ee3\u7b97\u6cd5\u89e3\u51b3M2V\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b56\u7565\u8fed\u4ee3\u8fc7\u7a0b\u7528\u4e8e\u6c42\u89e3\u6700\u4f18\u89e3\u3002", "result": "\u901a\u8fc7\u5f00\u53d1\u8fed\u4ee3\u7b97\u6cd5\u548c\u7b56\u7565\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5728\u65e0\u9650\u65f6\u95f4\u8de8\u5ea6\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u590f\u666e\u6bd4\u7387\u4f18\u5316\u95ee\u9898\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u7814\u7a76\u5728\u65e0\u9650\u65f6\u95f4\u8de8\u5ea6\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u590f\u666e\u6bd4\u7387\u4f18\u5316\uff0c\u8003\u8651\u4e86\u957f\u671f\u5e73\u5747\u548c\u6298\u73b0\u8bbe\u7f6e\u3002\u901a\u8fc7Dinkelbachs\u53d8\u6362\u89e3\u51b3\u4e86\u5c06\u590f\u666e\u6bd4\u7387\u76ee\u6807\u8f6c\u6362\u4e3a\u5747\u65b9\u5dee\uff08M2V\uff09\u76ee\u6807\u7684\u7b2c\u4e00\u4e2a\u6311\u6218\uff0c\u5e76\u5f00\u53d1\u4e86\u8fed\u4ee3\u7b97\u6cd5\u6765\u89e3\u51b3M2V\u4f18\u5316\u95ee\u9898\u3002\u5728\u5e73\u5747\u548c\u6298\u73b0MDP\u8bbe\u7f6e\u4e2d\uff0c\u5f00\u53d1\u4e86\u7b56\u7565\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u5e76\u8bc1\u660e\u5176\u6536\u655b\u6027\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.00834", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.LO", "I.2.4; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.00834", "abs": "https://arxiv.org/abs/2509.00834", "authors": ["Axel Mezini", "Elena Umili", "Ivan Donadello", "Fabrizio Maria Maggi", "Matteo Mancanelli", "Fabio Patrizi"], "title": "Neuro-Symbolic Predictive Process Monitoring", "comment": null, "summary": "This paper addresses the problem of suffix prediction in Business Process\nManagement (BPM) by proposing a Neuro-Symbolic Predictive Process Monitoring\n(PPM) approach that integrates data-driven learning with temporal logic-based\nprior knowledge. While recent approaches leverage deep learning models for\nsuffix prediction, they often fail to satisfy even basic logical constraints\ndue to the absence of explicit integration of domain knowledge during training.\nWe propose a novel method to incorporate Linear Temporal Logic over finite\ntraces (LTLf) into the training process of autoregressive sequence predictors.\nOur approach introduces a differentiable logical loss function, defined using a\nsoft approximation of LTLf semantics and the Gumbel-Softmax trick, which can be\ncombined with standard predictive losses. This ensures the model learns to\ngenerate suffixes that are both accurate and logically consistent. Experimental\nevaluation on three real-world datasets shows that our method improves suffix\nprediction accuracy and compliance with temporal constraints. We also introduce\ntwo variants of the logic loss (local and global) and demonstrate their\neffectiveness under noisy and realistic settings. While developed in the\ncontext of BPM, our framework is applicable to any symbolic sequence generation\ntask and contributes toward advancing Neuro-Symbolic AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\uff08PPM\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4f01\u4e1a\u6d41\u7a0b\u7ba1\u7406\u4e2d\u7684\u540e\u7f00\u9884\u6d4b\u95ee\u9898\u3002\u4ed6\u4eec\u7684\u65b9\u6cd5\u6574\u5408\u4e86\u7ebf\u6027\u65f6\u6001\u903b\u8f91\uff08LTLf\uff09\u5230\u81ea\u56de\u5f52\u5e8f\u5217\u9884\u6d4b\u5668\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u751f\u6210\u7684\u540e\u7f00\u51c6\u786e\u4e14\u903b\u8f91\u4e00\u81f4\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u540e\u7f00\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u65f6\u95f4\u7ea6\u675f\u7684\u7b26\u5408\u5ea6\uff0c\u5e76\u5c55\u793a\u4e86\u903b\u8f91\u635f\u5931\u7684\u5c40\u90e8\u548c\u5168\u5c40\u53d8\u4f53\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728BPM\u4e2d\uff0c\u6700\u8fd1\u7684\u65b9\u6cd5\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u540e\u7f00\u9884\u6d4b\uff0c\u4f46\u7531\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9886\u57df\u77e5\u8bc6\u7684\u7f3a\u5931\uff0c\u901a\u5e38\u65e0\u6cd5\u6ee1\u8db3\u57fa\u672c\u7684\u903b\u8f91\u7ea6\u675f\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5f15\u5165\u7ebf\u6027\u65f6\u6001\u903b\u8f91\u5230\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u7ebf\u6027\u65f6\u6001\u903b\u8f91\uff08LTLf\uff09\u5230\u81ea\u56de\u5f52\u5e8f\u5217\u9884\u6d4b\u5668\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u65b9\u6cd5\uff0c\u5f15\u5165\u4e86\u53ef\u5fae\u5206\u903b\u8f91\u635f\u5931\u51fd\u6570\uff0c\u5e76\u7ed3\u5408\u6807\u51c6\u9884\u6d4b\u635f\u5931\uff0c\u786e\u4fdd\u6a21\u578b\u5b66\u4e60\u751f\u6210\u65e2\u51c6\u786e\u53c8\u903b\u8f91\u4e00\u81f4\u7684\u540e\u7f00\u3002\u4ed6\u4eec\u4f7f\u7528\u4e86Gumbel-Softmax\u6280\u5de7\u5b9a\u4e49\u4e86\u4e00\u4e2a\u8f6f\u8fd1\u4f3c\u7684LTLf\u8bed\u4e49\uff0c\u4ee5\u5b9e\u73b0\u903b\u8f91\u635f\u5931\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u4f5c\u8005\u7684\u65b9\u6cd5\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e86\u540e\u7f00\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u65f6\u95f4\u7ea6\u675f\u7684\u7b26\u5408\u5ea6\u3002\u5f15\u5165\u7684\u903b\u8f91\u635f\u5931\u7684\u5c40\u90e8\u548c\u5168\u5c40\u53d8\u4f53\u5728\u5608\u6742\u548c\u73b0\u5b9e\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\uff08PPM\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u4e0e\u57fa\u4e8e\u65f6\u95f4\u903b\u8f91\u7684\u5148\u9a8c\u77e5\u8bc6\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u4f01\u4e1a\u6d41\u7a0b\u7ba1\u7406\u4e2d\u540e\u7f00\u9884\u6d4b\u7684\u95ee\u9898\u3002\u4ed6\u4eec\u7684\u65b9\u6cd5\u5728\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\u663e\u793a\uff0c\u80fd\u591f\u63d0\u9ad8\u540e\u7f00\u9884\u6d4b\u7684\u51c6\u786e\u6027\u5e76\u4e14\u7b26\u5408\u65f6\u95f4\u7ea6\u675f\u3002\u53e6\u5916\uff0c\u4ed6\u4eec\u8fd8\u4ecb\u7ecd\u4e86\u903b\u8f91\u635f\u5931\u7684\u4e24\u4e2a\u53d8\u4f53\uff08\u5c40\u90e8\u548c\u5168\u5c40\uff09\u5e76\u5c55\u793a\u5b83\u4eec\u5728\u5608\u6742\u548c\u73b0\u5b9e\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002\u867d\u7136\u5728BPM\u7684\u80cc\u666f\u4e0b\u5f00\u53d1\uff0c\u4f46\u4ed6\u4eec\u7684\u6846\u67b6\u9002\u7528\u4e8e\u4efb\u4f55\u7b26\u53f7\u5e8f\u5217\u751f\u6210\u4efb\u52a1\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u795e\u7ecf\u7b26\u53f7\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.00891", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00891", "abs": "https://arxiv.org/abs/2509.00891", "authors": ["Zonghai Yao", "Talha Chafekar", "Junda Wang", "Shuo Han", "Feiyun Ouyang", "Junhui Qian", "Lingxi Li", "Hong Yu"], "title": "ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care", "comment": "Equal contribution for the first two authors", "summary": "Real-world adoption of closed-loop insulin delivery systems (CLIDS) in type 1\ndiabetes remains low, driven not by technical failure, but by diverse\nbehavioral, psychosocial, and social barriers. We introduce ChatCLIDS, the\nfirst benchmark to rigorously evaluate LLM-driven persuasive dialogue for\nhealth behavior change. Our framework features a library of expert-validated\nvirtual patients, each with clinically grounded, heterogeneous profiles and\nrealistic adoption barriers, and simulates multi-turn interactions with nurse\nagents equipped with a diverse set of evidence-based persuasive strategies.\nChatCLIDS uniquely supports longitudinal counseling and adversarial social\ninfluence scenarios, enabling robust, multi-dimensional evaluation. Our\nfindings reveal that while larger and more reflective LLMs adapt strategies\nover time, all models struggle to overcome resistance, especially under\nrealistic social pressure. These results highlight critical limitations of\ncurrent LLMs for behavior change, and offer a high-fidelity, scalable testbed\nfor advancing trustworthy persuasive AI in healthcare and beyond.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86ChatCLIDS\uff0c\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u4e25\u683c\u8bc4\u4f30LLM\u9a71\u52a8\u7684\u6709\u8bf4\u670d\u529b\u5bf9\u8bdd\u7528\u4e8e\u5065\u5eb7\u884c\u4e3a\u53d8\u5316\u7684\u57fa\u51c6\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1LLM\u4f1a\u8c03\u6574\u7b56\u7565\uff0c\u4f46\u5728\u9762\u5bf9\u62b5\u6297\u7279\u522b\u662f\u73b0\u5b9e\u793e\u4f1a\u538b\u529b\u65f6\u4ecd\u5b58\u5728\u56f0\u96be\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5f53\u524dLLM\u5728\u884c\u4e3a\u6539\u53d8\u65b9\u9762\u7684\u91cd\u8981\u9650\u5236\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7528\u4e8e\u63a8\u52a8\u533b\u7597\u4fdd\u5065\u7b49\u9886\u57df\u53ef\u4fe1\u8d56\u7684AI\u529d\u8bf4\u6280\u672f\u53d1\u5c55\u7684\u9ad8\u4fdd\u771f\u5ea6\u3001\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u5bf9\u4e8e1\u578b\u7cd6\u5c3f\u75c5\u7684\u95ed\u73af\u80f0\u5c9b\u7d20\u8f93\u9001\u7cfb\u7edf\u7684\u91c7\u7528\u7387\u4ecd\u7136\u5f88\u4f4e\uff0c\u8fd9\u5e76\u4e0d\u662f\u7531\u6280\u672f\u5931\u8d25\u5f15\u8d77\u7684\uff0c\u800c\u662f\u7531\u591a\u6837\u5316\u7684\u884c\u4e3a\u3001\u5fc3\u7406\u793e\u4f1a\u548c\u793e\u4f1a\u969c\u788d\u6240\u63a8\u52a8\u3002\u8be5\u7814\u7a76\u5f15\u5165\u4e86ChatCLIDS\uff0c\u65e8\u5728\u4e25\u683c\u8bc4\u4f30LLM\u9a71\u52a8\u7684\u6709\u8bf4\u670d\u529b\u5bf9\u8bdd\u7528\u4e8e\u5065\u5eb7\u884c\u4e3a\u53d8\u5316\u7684\u57fa\u51c6\u3002", "method": "\u5f15\u5165ChatCLIDS\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u4e25\u683c\u8bc4\u4f30LLM\u9a71\u52a8\u7684\u6709\u8bf4\u670d\u529b\u5bf9\u8bdd\u7528\u4e8e\u5065\u5eb7\u884c\u4e3a\u53d8\u5316\u7684\u57fa\u51c6\u3002\u8be5\u6846\u67b6\u62e5\u6709\u4e00\u7cfb\u5217\u7ecf\u4e13\u5bb6\u9a8c\u8bc1\u7684\u865a\u62df\u60a3\u8005\u5e93\uff0c\u6bcf\u4e2a\u60a3\u8005\u5177\u6709\u4e34\u5e8a\u57fa\u7840\u3001\u5f02\u8d28\u6027\u7279\u5f81\u548c\u771f\u5b9e\u7684\u91c7\u7528\u969c\u788d\uff0c\u6a21\u62df\u4e0e\u914d\u5907\u6709\u591a\u79cd\u4ee5\u8bc1\u636e\u4e3a\u57fa\u7840\u7684\u8bf4\u670d\u7b56\u7565\u7684\u62a4\u58eb\u4ee3\u7406\u8fdb\u884c\u591a\u56de\u5408\u4e92\u52a8\u3002ChatCLIDS\u652f\u6301\u957f\u671f\u8f85\u5bfc\u548c\u5bf9\u6297\u6027\u793e\u4f1a\u5f71\u54cd\u573a\u666f\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u3001\u591a\u7ef4\u5ea6\u7684\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136\u89c4\u6a21\u66f4\u5927\u4e14\u66f4\u53cd\u601d\u7684LLM\u4f1a\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u8c03\u6574\u7b56\u7565\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u7279\u522b\u662f\u5728\u73b0\u5b9e\u793e\u4f1a\u538b\u529b\u4e0b\u4ecd\u7136\u96be\u4ee5\u514b\u670d\u963b\u529b\u3002\u8fd9\u4e9b\u7ed3\u679c\u7a81\u51fa\u4e86\u5f53\u524dLLM\u5728\u884c\u4e3a\u53d8\u5316\u65b9\u9762\u7684\u91cd\u8981\u9650\u5236\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u4fdd\u771f\u5ea6\u3001\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4ee5\u63a8\u52a8\u533b\u7597\u4fdd\u5065\u9886\u57df\u4ee5\u53ca\u5176\u4ed6\u9886\u57df\u4e2d\u53ef\u4fe1\u8d56\u7684AI\u529d\u8bf4\u6280\u672f\u7684\u53d1\u5c55\u3002", "conclusion": "\u8be5\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u7684\u5927\u578b\u4e14\u53cd\u601d\u6027\u66f4\u5f3a\u7684LLM\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u4f1a\u8c03\u6574\u7b56\u7565\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u9762\u5bf9\u62b5\u6297\u7279\u522b\u662f\u5728\u73b0\u5b9e\u793e\u4f1a\u538b\u529b\u4e0b\u4ecd\u7136\u5b58\u5728\u56f0\u96be\u3002\u5f53\u524d\u7684LLM\u5728\u884c\u4e3a\u53d8\u5316\u65b9\u9762\u5b58\u5728\u91cd\u8981\u9650\u5236\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u4fdd\u771f\u5ea6\u3001\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u63a8\u52a8\u533b\u7597\u4fdd\u5065\u4ee5\u53ca\u5176\u4ed6\u9886\u57df\u4e2d\u53ef\u4fe1\u8d56\u7684AI\u529d\u8bf4\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.00923", "categories": ["cs.AI", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.00923", "abs": "https://arxiv.org/abs/2509.00923", "authors": ["Zakaria El Jaafari"], "title": "Robust Deep Monte Carlo Counterfactual Regret Minimization: Addressing Theoretical Risks in Neural Fictitious Self-Play", "comment": null, "summary": "Monte Carlo Counterfactual Regret Minimization (MCCFR) has emerged as a\ncornerstone algorithm for solving extensive-form games, but its integration\nwith deep neural networks introduces scale-dependent challenges that manifest\ndifferently across game complexities. This paper presents a comprehensive\nanalysis of how neural MCCFR component effectiveness varies with game scale and\nproposes an adaptive framework for selective component deployment. We identify\nthat theoretical risks such as nonstationary target distribution shifts, action\nsupport collapse, variance explosion, and warm-starting bias have\nscale-dependent manifestation patterns, requiring different mitigation\nstrategies for small versus large games. Our proposed Robust Deep MCCFR\nframework incorporates target networks with delayed updates, uniform\nexploration mixing, variance-aware training objectives, and comprehensive\ndiagnostic monitoring. Through systematic ablation studies on Kuhn and Leduc\nPoker, we demonstrate scale-dependent component effectiveness and identify\ncritical component interactions. The best configuration achieves final\nexploitability of 0.0628 on Kuhn Poker, representing a 60% improvement over the\nclassical framework (0.156). On the more complex Leduc Poker domain, selective\ncomponent usage achieves exploitability of 0.2386, a 23.5% improvement over the\nclassical framework (0.3703) and highlighting the importance of careful\ncomponent selection over comprehensive mitigation. Our contributions include:\n(1) a formal theoretical analysis of risks in neural MCCFR, (2) a principled\nmitigation framework with convergence guarantees, (3) comprehensive multi-scale\nexperimental validation revealing scale-dependent component interactions, and\n(4) practical guidelines for deployment in larger games.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u795e\u7ecfMCCFR\u5728\u6e38\u620f\u89c4\u6a21\u4e0b\u7684\u6709\u6548\u6027\u53d8\u5316\uff0c\u63d0\u51fa\u4e86\u9c81\u68d2\u7684\u6df1\u5ea6MCCFR\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u89c4\u6a21\u6e38\u620f\u4e2d\u7684\u7ec4\u4ef6\u6548\u679c\u3002\u6700\u4f73\u914d\u7f6e\u5728\u4e24\u4e2a\u9886\u57df\u90fd\u53d6\u5f97\u4e86\u6539\u8fdb\uff0c\u5f3a\u8c03\u4e86\u7ec4\u4ef6\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u795e\u7ecfMCCFR\u7ec4\u4ef6\u5728\u4e0d\u540c\u6e38\u620f\u89c4\u6a21\u4e0b\u7684\u6709\u6548\u6027\u53d8\u5316\uff0c\u5e76\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u6846\u67b6\u4ee5\u9009\u62e9\u6027\u90e8\u7f72\u7ec4\u4ef6\uff0c\u4ee5\u5e94\u5bf9\u89c4\u6a21\u76f8\u5173\u6311\u6218\u3002", "method": "\u8be5\u8bba\u6587\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u3001\u63d0\u51fa\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u6df1\u5ea6MCCFR\u6846\u67b6\uff0c\u5305\u62ec\u5ef6\u8fdf\u66f4\u65b0\u7684\u76ee\u6807\u7f51\u7edc\u3001\u5747\u5300\u63a2\u7d22\u6df7\u5408\u3001\u8003\u8651\u65b9\u5dee\u7684\u8bad\u7ec3\u76ee\u6807\u548c\u5168\u9762\u7684\u8bca\u65ad\u76d1\u63a7\u3002\u8fdb\u884c\u4e86\u7cfb\u7edf\u7684\u5272\u9664\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u7ec4\u4ef6\u7684\u89c4\u6a21\u4f9d\u8d56\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u90e8\u7f72\u6307\u5357\u3002", "result": "\u6700\u4f73\u914d\u7f6e\u5728Kuhn Poker\u548cLeduc Poker\u9886\u57df\u5206\u522b\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\u7684exploitability\uff0c\u9a8c\u8bc1\u4e86\u9009\u62e9\u6027\u7ec4\u4ef6\u4f7f\u7528\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u6df1\u5ea6MCCFR\u6846\u67b6\uff0c\u53ef\u4ee5\u6839\u636e\u6e38\u620f\u89c4\u6a21\u9009\u62e9\u6027\u90e8\u7f72\u7ec4\u4ef6\uff0c\u901a\u8fc7\u7cfb\u7edf\u5207\u5272\u7814\u7a76\u5728\u4e0d\u540c\u89c4\u6a21\u6e38\u620f\u4e2d\u7ec4\u4ef6\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc6\u522b\u4e86\u5173\u952e\u7684\u7ec4\u4ef6\u4ea4\u4e92\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728Kuhn Poker\u9886\u57df\uff0c\u6700\u4f73\u914d\u7f6e\u4f7f\u5f97\u6700\u7ec8\u7684exploitability\u4e3a0.0628\uff0c\u6bd4\u4f20\u7edf\u6846\u67b6\uff080.156\uff09\u63d0\u9ad8\u4e8660%\u3002\u5728\u66f4\u590d\u6742\u7684Leduc Poker\u9886\u57df\uff0c\u9009\u62e9\u6027\u7ec4\u4ef6\u4f7f\u7528\u5b9e\u73b0exploitability\u4e3a0.2386\uff0c\u6bd4\u4f20\u7edf\u6846\u67b6\uff080.3703\uff09\u63d0\u9ad8\u4e8623.5%\uff0c\u7a81\u51fa\u4e86\u5728\u8f83\u5927\u6e38\u620f\u4e2d\u4ed4\u7ec6\u9009\u62e9\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.00930", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00930", "abs": "https://arxiv.org/abs/2509.00930", "authors": ["Yanxiao Zhao", "Yaqian Li", "Zihao Bo", "Rinyoichi Takezoe", "Haojia Hui", "Mo Guang", "Lei Ren", "Xiaolin Qin", "Kaiwen Long"], "title": "SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement Fine-Tuning of LLMs", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have demonstrated remarkable\ngeneral reasoning capabilities. However, systematically evaluating and\nenhancing these reasoning capabilities is challenging due to the lack of\ncontrollable and scalable tools for fine-grained analysis. Existing benchmarks\nand datasets often lack the necessary variable control for multi-dimensional,\nsystematic analysis and training, or have narrow problem types and formats. To\naddress these limitations, we introduce SATQuest, a systematic verifier\ndesigned to evaluate and enhance logical reasoning in LLMs by generating\ndiverse, Satisfiability-based logical reasoning problems directly from\nConjunctive Normal Form (CNF) instances. SATQuest structures these problems\nalong three orthogonal dimensions: instance scale, problem type, and question\nformat, employing randomized, SAT-based problem generation and objective answer\nverification via PySAT. This design mitigates memorization issues, allows for\nnuanced insights into reasoning performance, and enables effective\nreinforcement fine-tuning. Our extensive evaluation of various LLMs using\nSATQuest identified significant limitations in their logical reasoning,\nparticularly in generalizing beyond familiar mathematical formats. Furthermore,\nwe show that reinforcement fine-tuning with SATQuest rewards substantially\nimproves targeted task performance and generalizes to more complex instances,\nwhile highlighting remaining challenges in cross-format adaptation. Through\nthese demonstrations, we showcase SATQuest's potential as a foundational tool\nand a valuable starting point for advancing LLM logical reasoning.", "AI": {"tldr": "SATQuest is introduced to evaluate and enhance logical reasoning in Large Language Models (LLMs) by generating diverse, Satisfiability-based problems. It identified limitations in LLMs' reasoning and showed that reinforcement fine-tuning with SATQuest improves performance. Challenges in cross-format adaptation were highlighted, indicating SATQuest's potential as a foundational tool for advancing LLM logical reasoning.", "motivation": "The motivation stems from the challenges in systematically evaluating and enhancing reasoning capabilities in Large Language Models (LLMs) due to the lack of controllable and scalable tools for fine-grained analysis. Existing benchmarks and datasets often lack variable control for multi-dimensional, systematic analysis and training. The need for a tool like SATQuest arose to address these limitations and provide nuanced insights into reasoning performance.", "method": "Introducing SATQuest as a systematic verifier designed to evaluate and enhance logical reasoning in LLMs. It generates diverse, Satisfiability-based logical reasoning problems from Conjunctive Normal Form instances, considering instance scale, problem type, and question format. It employs randomized, SAT-based problem generation and objective answer verification via PySAT. Extensive evaluation of various LLMs using SATQuest was conducted to assess logical reasoning performance and the impact of reinforcement fine-tuning.", "result": "SATQuest identified significant limitations in LLMs' logical reasoning, showcasing the effectiveness of reinforcement fine-tuning in improving task performance and generalization. It also highlighted challenges in cross-format adaptation, indicating the potential for further advancements in LLM logical reasoning.", "conclusion": "SATQuest is introduced as a systematic verifier to evaluate and enhance logical reasoning in Large Language Models (LLMs) through diverse, Satisfiability-based logical reasoning problems. It identified significant limitations in LLMs' logical reasoning and showed that reinforcement fine-tuning with SATQuest improves task performance and generalization. Remaining challenges in cross-format adaptation were highlighted, emphasizing SATQuest's potential as a foundational tool for advancing LLM logical reasoning."}}
{"id": "2509.00936", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00936", "abs": "https://arxiv.org/abs/2509.00936", "authors": ["Kishor Datta Gupta", "Md Manjurul Ahsan", "Mohd Ariful Haque", "Roy George", "Azmine Toushik Wasi"], "title": "UrbanInsight: A Distributed Edge Computing Framework with LLM-Powered Data Filtering for Smart City Digital Twins", "comment": null, "summary": "Cities today generate enormous streams of data from sensors, cameras, and\nconnected infrastructure. While this information offers unprecedented\nopportunities to improve urban life, most existing systems struggle with scale,\nlatency, and fragmented insights. This work introduces a framework that blends\nphysics-informed machine learning, multimodal data fusion, and knowledge graph\nrepresentation with adaptive, rule-based intelligence powered by large language\nmodels (LLMs). Physics-informed methods ground learning in real-world\nconstraints, ensuring predictions remain meaningful and consistent with\nphysical dynamics. Knowledge graphs act as the semantic backbone, integrating\nheterogeneous sensor data into a connected, queryable structure. At the edge,\nLLMs generate context-aware rules that adapt filtering and decision-making in\nreal time, enabling efficient operation even under constrained resources.\nTogether, these elements form a foundation for digital twin systems that go\nbeyond passive monitoring to provide actionable insights. By uniting\nphysics-based reasoning, semantic data fusion, and adaptive rule generation,\nthis approach opens new possibilities for creating responsive, trustworthy, and\nsustainable smart infrastructures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6574\u5408\u4e86\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u3001\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u3001\u77e5\u8bc6\u56fe\u8868\u793a\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u6846\u67b6\u3002\u8fd9\u4e9b\u5143\u7d20\u5171\u540c\u6784\u6210\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u4e3a\u521b\u9020\u5177\u6709\u54cd\u5e94\u6027\u3001\u53ef\u4fe1\u8d56\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u5f00\u542f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u5f53\u4eca\u57ce\u5e02\u4ece\u4f20\u611f\u5668\u3001\u6444\u50cf\u5934\u548c\u8fde\u63a5\u57fa\u7840\u8bbe\u65bd\u4e2d\u4ea7\u751f\u5927\u91cf\u6570\u636e\u6d41\u3002\u5c3d\u7ba1\u8fd9\u4e9b\u4fe1\u606f\u63d0\u4f9b\u4e86\u6539\u5584\u57ce\u5e02\u751f\u6d3b\u7684\u524d\u6240\u672a\u6709\u673a\u4f1a\uff0c\u4f46\u5927\u591a\u6570\u73b0\u6709\u7cfb\u7edf\u5728\u89c4\u6a21\u3001\u5ef6\u8fdf\u548c\u788e\u7247\u5316\u7684\u6d1e\u5bdf\u529b\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u5f15\u5165\u4e00\u4e2a\u6846\u67b6\uff0c\u65e8\u5728\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u3001\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u548c\u77e5\u8bc6\u56fe\u8868\u793a\uff0c\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\uff0c\u4e3a\u521b\u9020\u5177\u6709\u54cd\u5e94\u6027\u3001\u53ef\u4fe1\u8d56\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u6253\u4e0b\u57fa\u7840\u3002", "method": "\u8be5\u5de5\u4f5c\u5f15\u5165\u4e86\u878d\u5408\u4e86\u7269\u7406\u4fe1\u606f\u7684\u673a\u5668\u5b66\u4e60\u3001\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u548c\u77e5\u8bc6\u56fe\u8868\u793a\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u3002\u7269\u7406\u4fe1\u606f\u7684\u65b9\u6cd5\u5c06\u5b66\u4e60\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u7ea6\u675f\u76f8\u7ed3\u5408\uff0c\u786e\u4fdd\u9884\u6d4b\u4fdd\u6301\u6709\u610f\u4e49\u4e14\u4e0e\u7269\u7406\u52a8\u6001\u4e00\u81f4\u3002\u77e5\u8bc6\u56fe\u4f5c\u4e3a\u8bed\u4e49\u9aa8\u5e72\uff0c\u5c06\u5f02\u6784\u4f20\u611f\u5668\u6570\u636e\u96c6\u6210\u5230\u4e00\u4e2a\u8fde\u901a\u7684\u3001\u53ef\u67e5\u8be2\u7684\u7ed3\u6784\u4e2d\u3002\u5728\u8fb9\u7f18\u7aef\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u89c4\u5219\uff0c\u5b9e\u65f6\u8c03\u6574\u8fc7\u6ee4\u548c\u51b3\u7b56\uff0c\u5373\u4f7f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u8fd0\u884c\u3002", "result": "\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u57fa\u7840\u63a8\u7406\u3001\u8bed\u4e49\u6570\u636e\u878d\u5408\u548c\u81ea\u9002\u5e94\u89c4\u5219\u751f\u6210\uff0c\u8be5\u65b9\u6cd5\u4e3a\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u88ab\u52a8\u76d1\u6d4b\u7684\u53ef\u64cd\u4f5c\u6d1e\u5bdf\u3002\u7269\u7406\u4fe1\u606f\u3001\u8bed\u4e49\u6570\u636e\u878d\u5408\u548c\u81ea\u9002\u5e94\u89c4\u5219\u751f\u6210\u7684\u7edf\u4e00\u65b9\u6cd5\u4e3a\u521b\u5efa\u5177\u6709\u54cd\u5e94\u6027\u3001\u53ef\u4fe1\u8d56\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u8be5\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u878d\u5408\u4e86\u7269\u7406\u4fe1\u606f\u7684\u673a\u5668\u5b66\u4e60\u3001\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u548c\u77e5\u8bc6\u56fe\u8868\u793a\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u3002\u901a\u8fc7\u7edf\u4e00\u57fa\u4e8e\u7269\u7406\u7684\u63a8\u7406\u3001\u8bed\u4e49\u6570\u636e\u878d\u5408\u548c\u81ea\u9002\u5e94\u89c4\u5219\u751f\u6210\uff0c\u8be5\u65b9\u6cd5\u4e3a\u521b\u5efa\u5177\u6709\u54cd\u5e94\u6027\u3001\u53ef\u4fe1\u8d56\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.00958", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00958", "abs": "https://arxiv.org/abs/2509.00958", "authors": ["Manish Verma", "Vivek Sharma", "Vishal Singh"], "title": "A Hybrid Ai Framework For Strategic Patent Portfolio Pruning: Integrating Learning To-Rank And Market Need Analysis For Technology Transfer Optimization", "comment": "Page 2, Figure 1 shows the conceptual architecture, and Page 11,\n  Figure 2 outlines its end to end workflow for strategic patent portfolio\n  pruning", "summary": "This paper introduces a novel, multi stage hybrid intelligence framework for\npruning patent portfolios to identify high value assets for technology\ntransfer. Current patent valuation methods often rely on retrospective\nindicators or manual, time intensive analysis. Our framework automates and\ndeepens this process by combining a Learning to Rank (LTR) model, which\nevaluates patents against over 30 legal and commercial parameters, with a\nunique \"Need-Seed\" agent-based system. The \"Need Agent\" uses Natural Language\nProcessing (NLP) to mine unstructured market and industry data, identifying\nexplicit technological needs. Concurrently, the \"Seed Agent\" employs fine tuned\nLarge Language Models (LLMs) to analyze patent claims and map their\ntechnological capabilities. The system generates a \"Core Ontology Framework\"\nthat matches high potential patents (Seeds) to documented market demands\n(Needs), providing a strategic rationale for divestment decisions. We detail\nthe architecture, including a dynamic parameter weighting system and a crucial\nHuman in the-Loop (HITL) validation protocol, to ensure both adaptability and\nreal-world credibility.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u591a\u9636\u6bb5\u7684\u6df7\u5408\u667a\u80fd\u6846\u67b6\uff0c\u7528\u4e8e\u526a\u679d\u4e13\u5229\u7ec4\u5408\u4ee5\u8bc6\u522b\u9ad8\u4ef7\u503c\u8d44\u4ea7\u8fdb\u884c\u6280\u672f\u8f6c\u8ba9\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5b66\u4e60\u6392\u5e8f\u6a21\u578b\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b49\u6280\u672f\uff0c\u81ea\u52a8\u5316\u548c\u52a0\u6df1\u4e13\u5229\u4f30\u503c\u8fc7\u7a0b\uff0c\u4e3a\u4e13\u5229\u5265\u79bb\u51b3\u7b56\u63d0\u4f9b\u6218\u7565\u652f\u6301\u3002\u8bba\u6587\u63d0\u51fa\u7684\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u5339\u914d\u4e13\u5229\u548c\u5e02\u573a\u9700\u6c42\uff0c\u652f\u6301\u5b9e\u9645\u7684\u5265\u79bb\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u7684\u4e13\u5229\u4ef7\u503c\u8bc4\u4f30\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u56de\u987e\u6027\u6307\u6807\u6216\u624b\u52a8\u3001\u8017\u65f6\u7684\u5206\u6790\u3002\u672c\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u81ea\u52a8\u5316\u548c\u52a0\u6df1\u4e13\u5229\u4f30\u503c\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u63d0\u4f9b\u6218\u7565\u6027\u7684\u4e13\u5229\u5265\u79bb\u51b3\u7b56\u652f\u6301\u3002", "method": "\u8be5\u8bba\u6587\u91c7\u7528\u4e86\u5b66\u4e60\u6392\u5e8f\uff08LTR\uff09\u6a21\u578b\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u201cNeed-Seed\u201d\u7cfb\u7edf\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u5b9e\u73b0\u4e13\u5229\u526a\u679d\u548c\u4ef7\u503c\u8d44\u4ea7\u8bc6\u522b\u3002\u901a\u8fc7\u521b\u5efa\u201c\u6838\u5fc3\u672c\u4f53\u6846\u67b6\u201d\u5c06\u9ad8\u6f5c\u529b\u4e13\u5229\u4e0e\u5e02\u573a\u9700\u6c42\u5339\u914d\uff0c\u63d0\u4f9b\u4e86\u5265\u79bb\u51b3\u7b56\u7684\u6218\u7565\u7406\u7531\u3002\u8bba\u6587\u8fd8\u4ecb\u7ecd\u4e86\u52a8\u6001\u53c2\u6570\u52a0\u6743\u7cfb\u7edf\u548c\u4eba\u673a\u5408\u4f5c\u9a8c\u8bc1\u534f\u8bae\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u7684\u6df7\u5408\u667a\u80fd\u6846\u67b6\u4e3a\u526a\u679d\u4e13\u5229\u7ec4\u5408\u5e76\u8bc6\u522b\u9ad8\u4ef7\u503c\u8d44\u4ea7\u63d0\u4f9b\u4e86\u65b0\u9896\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u5339\u914d\u4e13\u5229\u548c\u5e02\u573a\u9700\u6c42\uff0c\u652f\u6301\u5b9e\u9645\u7684\u4e13\u5229\u5265\u79bb\u51b3\u7b56\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u3001\u591a\u9636\u6bb5\u7684\u6df7\u5408\u667a\u80fd\u6846\u67b6\uff0c\u7528\u4e8e\u526a\u679d\u4e13\u5229\u7ec4\u5408\uff0c\u4ee5\u786e\u5b9a\u9ad8\u4ef7\u503c\u8d44\u4ea7\u8fdb\u884c\u6280\u672f\u8f6c\u8ba9\u3002\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u6392\u5e8f\uff08LTR\uff09\u6a21\u578b\u548c\u72ec\u7279\u7684\u201cNeed-Seed\u201d\u57fa\u4e8e\u4ee3\u7406\u7684\u7cfb\u7edf\uff0c\u8be5\u6846\u67b6\u81ea\u52a8\u5316\u5e76\u6df1\u5316\u4e86\u4e13\u5229\u4f30\u503c\u8fc7\u7a0b\u3002\u7cfb\u7edf\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6316\u6398\u672a\u7ed3\u6784\u5316\u5e02\u573a\u548c\u884c\u4e1a\u6570\u636e\uff0c\u8bc6\u522b\u660e\u786e\u7684\u6280\u672f\u9700\u6c42\uff0c\u5e76\u5206\u6790\u4e13\u5229\u58f0\u660e\u4ee5\u6620\u5c04\u5176\u6280\u672f\u80fd\u529b\uff0c\u4ece\u800c\u5339\u914d\u9ad8\u6f5c\u529b\u4e13\u5229\uff08Seeds\uff09\u4e0e\u5df2\u8bb0\u5f55\u7684\u5e02\u573a\u9700\u6c42\uff08Needs\uff09\uff0c\u4e3a\u5265\u79bb\u51b3\u7b56\u63d0\u4f9b\u6218\u7565\u7406\u7531\u3002\u8bba\u6587\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u67b6\u6784\uff0c\u5305\u62ec\u52a8\u6001\u53c2\u6570\u52a0\u6743\u7cfb\u7edf\u548c\u91cd\u8981\u7684\u4eba\u673a\u5408\u4f5c\u9a8c\u8bc1\u534f\u8bae\uff0c\u4ee5\u786e\u4fdd\u9002\u5e94\u6027\u548c\u73b0\u5b9e\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2509.00961", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00961", "abs": "https://arxiv.org/abs/2509.00961", "authors": ["Lun Ai", "Johannes Langer", "Ute Schmid", "Stephen Muggleton"], "title": "Ultra Strong Machine Learning: Teaching Humans Active Learning Strategies via Automated AI Explanations", "comment": null, "summary": "Ultra Strong Machine Learning (USML) refers to symbolic learning systems that\nnot only improve their own performance but can also teach their acquired\nknowledge to quantifiably improve human performance. In this work, we present\nLENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic\nmethod that combines symbolic program synthesis with large language models\n(LLMs) to automate the explanation of machine-learned logic programs in natural\nlanguage. LENS addresses a key limitation of prior USML approaches by replacing\nhand-crafted explanation templates with scalable automated generation. Through\nsystematic evaluation using multiple LLM judges and human validation, we\ndemonstrate that LENS generates superior explanations compared to direct LLM\nprompting and hand-crafted templates. To investigate whether LENS can teach\ntransferable active learning strategies, we carried out a human learning\nexperiment across three related domains. Our results show no significant human\nperformance improvements, suggesting that comprehensive LLM responses may\noverwhelm users for simpler problems rather than providing learning support.\nOur work provides a solid foundation for building effective USML systems to\nsupport human learning. The source code is available on:\nhttps://github.com/lun-ai/LENS.git.", "AI": {"tldr": "LENS is a neuro-symbolic method that automates the explanation of machine-learned logic programs in natural language, outperforming direct LLM prompting and hand-crafted templates. While LENS provides superior explanations, the proposed transferable active learning strategies did not show significant human performance improvements.", "motivation": "The motivation of this work is to address a key limitation of prior USML approaches by improving the generation of explanations for machine-learned logic programs. The authors aim to enhance the performance of USML systems by providing better support for human learning through superior explanations.", "method": "The paper presents LENS, a neuro-symbolic method that combines symbolic program synthesis with large language models (LLMs) to automate the explanation of machine-learned logic programs in natural language. LENS replaces hand-crafted explanation templates with scalable automated generation. The effectiveness of LENS was evaluated through systematic evaluation using multiple LLM judges and human validation.", "result": "The results demonstrate that LENS outperforms direct LLM prompting and hand-crafted templates in generating explanations for machine-learned logic programs. However, the transferable active learning strategies proposed by LENS did not lead to significant human performance improvements in the experiment.", "conclusion": "LENS (Logic Programming Explanation via Neural Summarisation) is a neuro-symbolic method that generates superior explanations for machine-learned logic programs compared to direct LLM prompting and hand-crafted templates. However, the transferable active learning strategies proposed by LENS did not show significant human performance improvements in the conducted experiment."}}
{"id": "2509.00971", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00971", "abs": "https://arxiv.org/abs/2509.00971", "authors": ["Jay Vaghasiya", "Omkar Ghugarkar", "Vishvesh Bhat", "Vipul Dholaria", "Julian McAuley"], "title": "CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs", "comment": null, "summary": "We introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel\nreasoning method called General Symbolics. This approach diverges from\nreasoning paradigms such as test-time scaling, Supervised Fine-Tuning (SFT),\nand Reinforcement Learning with Verifiable Rewards (RLVR). CoreThink General\nSymbolic Reasoner (GSR) is specifically structured around three key use cases:\ntool-calling, code generation, and planning, demonstrating exemplary\nperformance across a total of seven benchmarks in their respective areas.\nNotably, we are achieving SOTA scores of 66.66\\% on Livecodebench v6, 89\\% on\nInstruction-Following Evals, and 24.4\\% on ARC-AGI-2. We also present an\nagentic coding IDE, developed using the principles of General Symbolics, which\nachieves a state-of-the-art accuracy of 62.3\\% on \\texttt{SWE-Bench Lite}. We\nare able to achieve these improvements without any finetuning or training\ncosts. Our Reasoning Layer is designed to provide a pure performance uplift,\nensuring that a model's accuracy on reasoning tasks is never negatively\nimpacted. We argue that incumbent methods will eventually lead to diminishing\nreturns in LLM performance, necessitating the development of new reasoning\ntechniques. This technical report details our approach at a high level and the\navailability of the CoreThink models for reasoning-intensive use cases.", "AI": {"tldr": "CoreThink introduces a new Reasoning Layer based on General Symbolics, diverging from traditional reasoning paradigms. The General Symbolic Reasoner (GSR) achieves high performance on various benchmarks without fine-tuning or training costs. CoreThink aims to provide a pure performance uplift without compromising model accuracy on reasoning tasks, highlighting the need for new reasoning techniques in the face of potential diminishing returns in Large Language Model (LLM) performance.", "motivation": "The motivation behind CoreThink is to address the limitations of incumbent reasoning methods that could lead to diminishing returns in Large Language Model (LLM) performance. By introducing the General Symbolic reasoning approach, CoreThink aims to enhance performance without the need for fine-tuning or training costs, ensuring a model's accuracy on reasoning tasks remains high.", "method": "CoreThink utilizes the General Symbolics reasoning method, diverging from traditional paradigms like test-time scaling, Supervised Fine-Tuning (SFT), and Reinforcement Learning with Verifiable Rewards (RLVR). The CoreThink General Symbolic Reasoner (GSR) is structured around key use cases including tool-calling, code generation, and planning. The paper also introduces an agentic coding IDE developed using General Symbolics principles, showcasing high accuracy on reasoning tasks.", "result": "CoreThink demonstrates exceptional performance on seven benchmarks, achieving SOTA scores on Livecodebench v6, Instruction-Following Evals, and ARC-AGI-2. The agentic coding IDE developed using General Symbolics principles also achieves a state-of-the-art accuracy on SWE-Bench Lite. These results highlight the effectiveness of CoreThink in providing high performance in reasoning tasks.", "conclusion": "CoreThink introduces a state-of-the-art Reasoning Layer based on General Symbolics, achieving high performance on various benchmarks without the need for fine-tuning or training costs. The approach aims to provide a pure performance uplift without negatively impacting model accuracy on reasoning tasks, highlighting the efficacy of the General Symbolic Reasoner (GSR). The paper argues for the necessity of developing new reasoning techniques to avoid diminishing returns in Large Language Model (LLM) performance."}}
{"id": "2509.00975", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00975", "abs": "https://arxiv.org/abs/2509.00975", "authors": ["Zifeng Ding", "Shenyang Huang", "Zeyu Cao", "Emma Kondrup", "Zachary Yang", "Xingyue Huang", "Yuan Sui", "Zhangdie Yuan", "Yuqicheng Zhu", "Xianglong Hu", "Yuan He", "Farimah Poursafaei", "Michael Bronstein", "Andreas Vlachos"], "title": "Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning", "comment": null, "summary": "Forecasting future links is a central task in temporal graph (TG) reasoning,\nrequiring models to leverage historical interactions to predict upcoming ones.\nTraditional neural approaches, such as temporal graph neural networks, achieve\nstrong performance but lack explainability and cannot be applied to unseen\ngraphs without retraining. Recent studies have begun to explore using large\nlanguage models (LLMs) for graph reasoning, but most of them are constrained to\nstatic graphs or small synthetic TGs and lack the evaluation of the quality of\nreasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced\nLearning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that\nfine-tunes LLMs to perform explainable link forecasting on real-world TGs.\nReaL-TG uses outcome-based reward to encourage models to self-explore reasoning\nstrategies from graph structure and to produce explanations that directly\njustify their predictions. To enable evaluation on LLM-generated reasoning\ntraces, we propose a new evaluation protocol combining ranking metrics with an\nLLM-as-a-Judge system that assesses both the quality of reasoning and the\nimpact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning\nQwen3-4B under our framework, show that it outperforms much larger frontier\nLLMs, including GPT-5 mini, on ranking metrics, while producing high-quality\nexplanations confirmed by both the LLM judge and human evaluation.", "AI": {"tldr": "ReaL-TG is a reinforcement learning framework that fine-tunes large language models for explainable link forecasting on temporal graphs. It outperforms existing models in ranking metrics and explanation quality. The evaluation protocol combines ranking metrics and an LLM-as-a-Judge system to assess reasoning quality and the impact of hallucinations.", "motivation": "Existing neural approaches for temporal graph reasoning lack explainability and are not transferable to unseen graphs without retraining. Previous studies using large language models were limited to static graphs or synthetic TGs, without evaluating the quality of reasoning traces. The goal of this work is to address these limitations and provide explainable link forecasting on real-world temporal graphs.", "method": "ReaL-TG employs reinforcement learning to fine-tune large language models for explainable link forecasting on real-world temporal graphs. An outcome-based reward system encourages self-exploration of reasoning strategies from graph structure and the generation of justifiable predictions. Evaluation includes a new protocol combining ranking metrics and an LLM-as-a-Judge system.", "result": "Experiments with ReaL-TG-4B show superior performance to larger frontier LLMs like GPT-5 mini in ranking metrics and explanation quality, confirmed by both LLM judge assessment and human evaluation.", "conclusion": "ReaL-TG, a reinforcement learning framework fine-tuning large language models, outperforms existing models in link forecasting on temporal graphs while providing high-quality explanations. The evaluation protocol combines ranking metrics and an LLM-as-a-Judge system to assess reasoning quality and the impact of hallucinations."}}
{"id": "2509.00987", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00987", "abs": "https://arxiv.org/abs/2509.00987", "authors": ["Adib Bazgir", "Amir Habibdoust", "Yuwen Zhang", "Xing Song"], "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "comment": "24 pages. 2 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious reasoning and generation tasks. However, their proficiency in complex\ncausal reasoning, discovery, and estimation remains an area of active\ndevelopment, often hindered by issues like hallucination, reliance on spurious\ncorrelations, and difficulties in handling nuanced, domain-specific, or\npersonalized causal relationships. Multi-agent systems, leveraging the\ncollaborative or specialized abilities of multiple LLM-based agents, are\nemerging as a powerful paradigm to address these limitations. This review paper\nexplores the burgeoning field of causal multi-agent LLMs. We examine how these\nsystems are designed to tackle different facets of causality, including causal\nreasoning and counterfactual analysis, causal discovery from data, and the\nestimation of causal effects. We delve into the diverse architectural patterns\nand interaction protocols employed, from pipeline-based processing and debate\nframeworks to simulation environments and iterative refinement loops.\nFurthermore, we discuss the evaluation methodologies, benchmarks, and diverse\napplication domains where causal multi-agent LLMs are making an impact,\nincluding scientific discovery, healthcare, fact-checking, and personalized\nsystems. Finally, we highlight the persistent challenges, open research\nquestions, and promising future directions in this synergistic field, aiming to\nprovide a comprehensive overview of its current state and potential trajectory.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u8bba\u6587\u7814\u7a76\u4e86\u56e0\u679c\u591a\u667a\u4f53LLM\u7cfb\u7edf\uff0c\u4ecb\u7ecd\u4e86\u8bbe\u8ba1\u3001\u56e0\u679c\u63a8\u7406\u3001\u53cd\u4e8b\u5b9e\u5206\u6790\u3001\u56e0\u679c\u5173\u7cfb\u53d1\u73b0\u548c\u6548\u5e94\u4f30\u8ba1\u7b49\u65b9\u9762\u3002\u8ba8\u8bba\u4e86\u4ea4\u4e92\u534f\u8bae\u3001\u8bc4\u4f30\u65b9\u6cd5\u3001\u5e94\u7528\u9886\u57df\u7b49\uff0c\u5e76\u6307\u51fa\u4e86\u5b58\u5728\u7684\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u56e0\u679c\u63a8\u7406\u3001\u53d1\u73b0\u548c\u4f30\u8ba1\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u672c\u7efc\u8ff0\u65e8\u5728\u63a2\u8ba8\u5229\u7528\u591a\u667a\u4f53\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u591a\u4e2aLLM\u4ee3\u7406\u7684\u534f\u4f5c\u6216\u4e13\u4e1a\u80fd\u529b\uff0c\u6765\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u8be5\u7efc\u8ff0\u8bba\u6587\u901a\u8fc7\u7814\u7a76\u56e0\u679c\u591a\u667a\u4f53LLM\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u5e94\u7528\u548c\u6311\u6218\uff0c\u603b\u7ed3\u51fa\u8be5\u9886\u57df\u53d1\u5c55\u7684\u4e3b\u8981\u8d8b\u52bf\u548c\u672a\u6765\u65b9\u5411\u3002", "result": "\u901a\u8fc7\u5168\u9762\u63a2\u8ba8\u56e0\u679c\u591a\u667a\u4f53LLM\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u4e92\u52a8\u6a21\u5f0f\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u5e94\u7528\u9886\u57df\uff0c\u672c\u7efc\u8ff0\u63ed\u793a\u4e86\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u7684\u91cd\u8981\u6027\u548c\u53d1\u5c55\u524d\u666f\u3002", "conclusion": "\u672c\u7efc\u8ff0\u8bba\u6587\u63a2\u8ba8\u4e86\u56e0\u679c\u591a\u667a\u4f53LLM\u9886\u57df\u7684\u65b0\u5174\u53d1\u5c55\uff0c\u7740\u91cd\u4ecb\u7ecd\u4e86\u8fd9\u4e9b\u7cfb\u7edf\u8bbe\u8ba1\u7684\u4e0d\u540c\u65b9\u9762\uff0c\u5305\u62ec\u56e0\u679c\u63a8\u7406\u548c\u53cd\u4e8b\u5b9e\u5206\u6790\uff0c\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u56e0\u679c\u5173\u7cfb\uff0c\u4ee5\u53ca\u5bf9\u56e0\u679c\u6548\u5e94\u7684\u4f30\u8ba1\u3002\u8ba8\u8bba\u4e86\u91c7\u7528\u7684\u591a\u6837\u5316\u7684\u7ed3\u6784\u6a21\u5f0f\u548c\u4ea4\u4e92\u534f\u8bae\uff0c\u4ece\u57fa\u4e8e\u6d41\u6c34\u7ebf\u5904\u7406\u548c\u8fa9\u8bba\u6846\u67b6\u5230\u6a21\u62df\u73af\u5883\u548c\u8fed\u4ee3\u6539\u8fdb\u5faa\u73af\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u8bc4\u4f30\u65b9\u6cd5\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u6837\u7684\u5e94\u7528\u9886\u57df\uff0c\u5982\u79d1\u5b66\u53d1\u73b0\u3001\u533b\u7597\u4fdd\u5065\u3001\u4e8b\u5b9e\u6838\u67e5\u548c\u4e2a\u6027\u5316\u7cfb\u7edf\u3002\u6700\u540e\uff0c\u7a81\u51fa\u4e86\u8fd9\u4e00\u534f\u540c\u9886\u57df\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u6311\u6218\u3001\u672a\u89e3\u7814\u7a76\u95ee\u9898\u4ee5\u53ca\u6709\u524d\u666f\u7684\u672a\u6765\u65b9\u5411\uff0c\u65e8\u5728\u63d0\u4f9b\u5bf9\u5f53\u524d\u72b6\u6001\u548c\u6f5c\u5728\u53d1\u5c55\u8f68\u8ff9\u7684\u5168\u9762\u6982\u8ff0\u3002"}}
{"id": "2509.00997", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.00997", "abs": "https://arxiv.org/abs/2509.00997", "authors": ["Shu Liu", "Soujanya Ponnapalli", "Shreya Shankar", "Sepanta Zeighami", "Alan Zhu", "Shubham Agarwal", "Ruiqi Chen", "Samion Suwito", "Shuo Yuan", "Ion Stoica", "Matei Zaharia", "Alvin Cheung", "Natacha Crooks", "Joseph E. Gonzalez", "Aditya G. Parameswaran"], "title": "Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First", "comment": null, "summary": "Large Language Model (LLM) agents, acting on their users' behalf to\nmanipulate and analyze data, are likely to become the dominant workload for\ndata systems in the future. When working with data, agents employ a\nhigh-throughput process of exploration and solution formulation for the given\ntask, one we call agentic speculation. The sheer volume and inefficiencies of\nagentic speculation can pose challenges for present-day data systems. We argue\nthat data systems need to adapt to more natively support agentic workloads. We\ntake advantage of the characteristics of agentic speculation that we identify,\ni.e., scale, heterogeneity, redundancy, and steerability - to outline a number\nof new research opportunities for a new agent-first data systems architecture,\nranging from new query interfaces, to new query processing techniques, to new\nagentic memory stores.", "AI": {"tldr": "\u672c\u7814\u7a76\u6307\u51fa\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5c06\u6210\u4e3a\u672a\u6765\u6570\u636e\u7cfb\u7edf\u7684\u4e3b\u8981\u5de5\u4f5c\u8d1f\u8f7d\u3002\u63d0\u51fa\u4e86\u6570\u636e\u7cfb\u7edf\u9700\u8981\u66f4\u672c\u5730\u652f\u6301\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u7684\u89c2\u70b9\uff0c\u5e76\u901a\u8fc7\u8bc6\u522b\u4ee3\u7406\u63a8\u6d4b\u7684\u7279\u5f81\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u7814\u7a76\u673a\u4f1a\uff0c\u5305\u62ec\u65b0\u7684\u67e5\u8be2\u754c\u9762\u3001\u67e5\u8be2\u5904\u7406\u6280\u672f\u548c\u4ee3\u7406\u5185\u5b58\u5b58\u50a8\u3002", "motivation": "\u5bf9\u4e8e\u672a\u6765\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5c06\u6210\u4e3a\u6570\u636e\u7cfb\u7edf\u4e2d\u7684\u4e3b\u8981\u5de5\u4f5c\u8d1f\u8f7d\u3002\u4ee3\u7406\u63a8\u6d4b\u7684\u4f53\u79ef\u548c\u4f4e\u6548\u6027\u53ef\u80fd\u5bf9\u73b0\u4eca\u7684\u6570\u636e\u7cfb\u7edf\u6784\u6210\u6311\u6218", "method": "\u901a\u8fc7\u8bc6\u522b\u4ee3\u7406\u63a8\u6d4b\u7684\u7279\u5f81\uff0c\u4f8b\u5982\u89c4\u6a21\u3001\u5f02\u8d28\u6027\u3001\u5197\u4f59\u6027\u548c\u53ef\u64cd\u7eb5\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u4e9b\u65b0\u7684\u7814\u7a76\u673a\u4f1a", "result": "\u63d0\u51fa\u4e86\u4ee3\u7406\u4f18\u5148\u6570\u636e\u7cfb\u7edf\u67b6\u6784\u7684\u4e00\u4e9b\u65b0\u7814\u7a76\u673a\u4f1a\uff0c\u5305\u62ec\u65b0\u7684\u67e5\u8be2\u754c\u9762\u3001\u65b0\u7684\u67e5\u8be2\u5904\u7406\u6280\u672f\u548c\u65b0\u7684\u4ee3\u7406\u5185\u5b58\u5b58\u50a8", "conclusion": "\u6570\u636e\u7cfb\u7edf\u9700\u8981\u66f4\u672c\u5730\u5316\u5730\u652f\u6301\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ee3\u7406\u4f18\u5148\u6570\u636e\u7cfb\u7edf\u67b6\u6784\u7684\u7814\u7a76\u673a\u4f1a"}}
{"id": "2509.01016", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2509.01016", "abs": "https://arxiv.org/abs/2509.01016", "authors": ["Aishni Parab", "Hongjing Lu", "Ying Nian Wu", "Sumit Gulwani"], "title": "Analysis of Error Sources in LLM-based Hypothesis Search for Few-Shot Rule Induction", "comment": "This is the preprint version corresponding to our NeurIPS 2025\n  Workshop on Multimodal Algorithmic Reasoning submission", "summary": "Inductive reasoning enables humans to infer abstract rules from limited\nexamples and apply them to novel situations. In this work, we compare an\nLLM-based hypothesis search framework with direct program generation approaches\non few-shot rule induction tasks. Our findings show that hypothesis search\nachieves performance comparable to humans, while direct program generation\nfalls notably behind. An error analysis reveals key bottlenecks in hypothesis\ngeneration and suggests directions for advancing program induction methods.\nOverall, this paper underscores the potential of LLM-based hypothesis search\nfor modeling inductive reasoning and the challenges in building more efficient\nsystems.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u6bd4\u8f83\u4e86\u57fa\u4e8eLLM\u7684\u5047\u8bbe\u641c\u7d22\u6846\u67b6\u548c\u76f4\u63a5\u7a0b\u5e8f\u751f\u6210\u65b9\u6cd5\u5728\u5c11\u6837\u672c\u89c4\u5219\u5f52\u7eb3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u53d1\u73b0LLM\u7684\u5047\u8bbe\u641c\u7d22\u5b9e\u73b0\u4e86\u4e0e\u4eba\u7c7b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u800c\u76f4\u63a5\u7a0b\u5e8f\u751f\u6210\u660e\u663e\u843d\u540e\u3002\u9519\u8bef\u5206\u6790\u63ed\u793a\u4e86\u5047\u8bbe\u751f\u6210\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u5e76\u4e3a\u6539\u8fdb\u7a0b\u5e8f\u5f52\u7eb3\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b9\u5411\u3002\u56e0\u6b64\uff0cLLM\u7684\u5047\u8bbe\u641c\u7d22\u6846\u67b6\u5728\u5f52\u7eb3\u63a8\u7406\u5efa\u6a21\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u51f8\u663e\u4e86\u6784\u5efa\u66f4\u9ad8\u6548\u7cfb\u7edf\u7684\u6311\u6218\u3002", "motivation": "To investigate the performance of LLM-based hypothesis search and direct program generation in inductive reasoning tasks, aiming to understand their strengths and weaknesses in few-shot rule induction scenarios.", "method": "Comparison of LLM-based hypothesis search framework with direct program generation approaches on few-shot rule induction tasks.", "result": "LLM-based hypothesis search framework achieves performance comparable to humans, while direct program generation lags behind. Error analysis reveals key bottlenecks in hypothesis generation and guides future research directions in program induction methods.", "conclusion": "LLM-based hypothesis search framework outperforms direct program generation in few-shot rule induction tasks, highlighting its potential for modeling inductive reasoning. Error analysis identifies bottlenecks in hypothesis generation and provides guidance for improving program induction methods."}}
{"id": "2509.01021", "categories": ["cs.AI", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2509.01021", "abs": "https://arxiv.org/abs/2509.01021", "authors": ["Yukio-Pegio Gunji", "Andrew Adamatzky", "Panagiotis Mougkogiannis", "Andrei Khrenikov"], "title": "Quantum-like Coherence Derived from the Interaction between Chemical Reaction and Its Environment", "comment": "36 pages, 13 figures", "summary": "By uncovering the contrast between Artificial Intelligence and Natural-born\nIntelligence as a computational process, we define closed computing and open\ncomputing, and implement open computing within chemical reactions. This\ninvolves forming a mixture and invalidation of the computational process and\nthe execution environment, which are logically distinct, and coalescing both to\ncreate a system that adjusts fluctuations. We model chemical reactions by\nconsidering the computation as the chemical reaction and the execution\nenvironment as the degree of aggregation of molecules that interact with the\nreactive environment. This results in a chemical reaction that progresses while\nrepeatedly clustering and de-clustering, where concentration no longer holds\nsignificant meaning. Open computing is segmented into Token computing, which\nfocuses on the individual behavior of chemical molecules, and Type computing,\nwhich focuses on normative behavior. Ultimately, both are constructed as an\ninterplay between the two. In this system, Token computing demonstrates\nself-organizing critical phenomena, while Type computing exhibits quantum\nlogic. Through their interplay, the recruitment of fluctuations is realized,\ngiving rise to interactions between quantum logical subspaces corresponding to\nquantum coherence across different Hilbert spaces. As a result, spike waves are\nformed, enabling signal transmission. This occurrence may be termed\nquantum-like coherence, implying the source of enzymes responsible for\ncontrolling spike waves and biochemical rhythms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5f00\u653e\u5f0f\u8ba1\u7b97\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86Token\u8ba1\u7b97\u548cType\u8ba1\u7b97\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u8868\u660e\u901a\u8fc7\u8fd9\u4e9b\u8ba1\u7b97\u65b9\u5f0f\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u53ef\u4ee5\u5b9e\u73b0\u91cf\u5b50\u4e00\u81f4\u6027\u60c5\u51b5\uff0c\u4fc3\u8fdb\u4fe1\u53f7\u4f20\u8f93\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u4eba\u5de5\u667a\u80fd\u548c\u81ea\u7136\u667a\u80fd\u7684\u8ba1\u7b97\u8fc7\u7a0b\u4e4b\u95f4\u7684\u533a\u522b\uff0c\u5e76\u5c06\u5f00\u653e\u5f0f\u8ba1\u7b97\u5e94\u7528\u4e8e\u5316\u5b66\u53cd\u5e94\u4e2d\uff0c\u4ee5\u7814\u7a76\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u8ba1\u7b97\u8fc7\u7a0b\u548c\u6ce2\u52a8\u8c03\u8282\u7cfb\u7edf\u3002\u901a\u8fc7\u5bf9Token\u8ba1\u7b97\u548cType\u8ba1\u7b97\u7684\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u5176\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u4f5c\u7528\uff0c\u8fdb\u800c\u6697\u793a\u4e86\u7c7b\u91cf\u5b50\u4e00\u81f4\u6027\u7684\u4ea7\u751f\u673a\u5236\u3002", "method": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9a\u4e49\u95ed\u5f0f\u8ba1\u7b97\u548c\u5f00\u653e\u5f0f\u8ba1\u7b97\uff0c\u5c06\u5f00\u653e\u5f0f\u8ba1\u7b97\u5e94\u7528\u4e8e\u5316\u5b66\u53cd\u5e94\u4e2d\uff0c\u7814\u7a76\u4e86\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u8ba1\u7b97\u8fc7\u7a0b\u548c\u6267\u884c\u73af\u5883\u7684\u878d\u5408\uff0c\u4ee5\u53caToken\u8ba1\u7b97\u548cType\u8ba1\u7b97\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u901a\u8fc7\u6a21\u62df\u5316\u5b66\u53cd\u5e94\u548c\u5206\u5b50\u805a\u96c6\u7a0b\u5ea6\u7684\u5173\u7cfb\uff0c\u7814\u7a76\u4e86\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u6ce2\u52a8\u8c03\u8282\u7cfb\u7edf\u3002\u6700\u7ec8\u901a\u8fc7\u81ea\u7ec4\u7ec7\u4e34\u754c\u73b0\u8c61\u548c\u91cf\u5b50\u903b\u8f91\u5c55\u793a\u4e86\u5f00\u653e\u5f0f\u8ba1\u7b97\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u6548\u679c\u3002", "result": "\u8be5\u8bba\u6587\u901a\u8fc7\u7814\u7a76\u5f00\u653e\u5f0f\u8ba1\u7b97\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u5f00\u653e\u5f0f\u8ba1\u7b97\u5bf9\u6ce2\u52a8\u8c03\u8282\u7cfb\u7edf\u7684\u91cd\u8981\u6027\uff0c\u5e76\u901a\u8fc7Token\u8ba1\u7b97\u548cType\u8ba1\u7b97\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5b9e\u73b0\u4e86\u91cf\u5b50\u4e00\u81f4\u6027\u7684\u5b50\u7a7a\u95f4\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ece\u800c\u4ea7\u751f\u4e86\u7c7b\u91cf\u5b50\u4e00\u81f4\u6027\u60c5\u51b5\u3002\u6700\u7ec8\u5b9e\u73b0\u4e86\u4fe1\u53f7\u4f20\u8f93\u7684\u529f\u80fd\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ece\u4eba\u5de5\u667a\u80fd\u548c\u81ea\u7136\u667a\u80fd\u7684\u8ba1\u7b97\u8fc7\u7a0b\u5bf9\u6bd4\u5165\u624b\uff0c\u5b9a\u4e49\u95ed\u5f0f\u8ba1\u7b97\u548c\u5f00\u653e\u5f0f\u8ba1\u7b97\uff0c\u5c06\u5f00\u653e\u5f0f\u8ba1\u7b97\u5e94\u7528\u4e8e\u5316\u5b66\u53cd\u5e94\u4e2d\u3002\u7814\u7a76\u5f62\u6210\u6df7\u5408\u7269\u548c\u65e0\u6548\u5316\u8ba1\u7b97\u8fc7\u7a0b\u4e0e\u6267\u884c\u73af\u5883\uff0c\u5c06\u4e8c\u8005\u5408\u800c\u4e3a\u4e00\uff0c\u521b\u9020\u51fa\u80fd\u591f\u8c03\u8282\u6ce2\u52a8\u7684\u7cfb\u7edf\u3002\u901a\u8fc7\u5c06\u8ba1\u7b97\u770b\u4f5c\u5316\u5b66\u53cd\u5e94\u3001\u6267\u884c\u73af\u5883\u770b\u4f5c\u5206\u5b50\u805a\u96c6\u7a0b\u5ea6\u7684\u6a21\u578b\u5316\u5b66\u53cd\u5e94\uff0c\u5bfc\u81f4\u5316\u5b66\u53cd\u5e94\u5728\u96c6\u7fa4\u548c\u89e3\u96c6\u7fa4\u4e2d\u4e0d\u65ad\u8fdb\u884c\uff0c\u6d53\u5ea6\u4e0d\u518d\u5177\u6709\u663e\u8457\u610f\u4e49\u3002\u5f00\u653e\u5f0f\u8ba1\u7b97\u5206\u4e3aToken\u8ba1\u7b97\u548cType\u8ba1\u7b97\uff0c\u5206\u522b\u5173\u6ce8\u5316\u5b66\u5206\u5b50\u7684\u4e2a\u4f53\u884c\u4e3a\u548c\u89c4\u8303\u6027\u884c\u4e3a\uff0c\u4e24\u8005\u76f8\u4e92\u4ea4\u7ec7\u6784\u5efa\u7cfb\u7edf\u3002\u5728\u8be5\u7cfb\u7edf\u4e2d\uff0cToken\u8ba1\u7b97\u8868\u73b0\u4e3a\u81ea\u7ec4\u7ec7\u4e34\u754c\u73b0\u8c61\uff0cType\u8ba1\u7b97\u5c55\u73b0\u51fa\u91cf\u5b50\u903b\u8f91\u3002\u901a\u8fc7\u5b83\u4eec\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5b9e\u73b0\u4e86\u6ce2\u52a8\u7684\u62db\u52df\uff0c\u4ea7\u751f\u4e86\u5bf9\u5e94\u4e8e\u4e0d\u540c\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u91cf\u5b50\u4e00\u81f4\u6027\u7684\u5b50\u7a7a\u95f4\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u7531\u6b64\u4ea7\u751f\u4e86\u5c16\u6ce2\uff0c\u5b9e\u73b0\u4e86\u4fe1\u53f7\u4f20\u8f93\uff0c\u88ab\u79f0\u4e3a\u7c7b\u91cf\u5b50\u4e00\u81f4\u6027\uff0c\u6697\u793a\u7740\u63a7\u5236\u5c16\u6ce2\u548c\u751f\u7269\u5316\u5b66\u8282\u5f8b\u7684\u9176\u7684\u6765\u6e90\u3002"}}
{"id": "2509.01022", "categories": ["cs.AI", "cs.MA", "cs.RO", "93A16 93A16"], "pdf": "https://arxiv.org/pdf/2509.01022", "abs": "https://arxiv.org/abs/2509.01022", "authors": ["Bo Fu", "Zhe Chen", "Rahul Chandan", "Alex Barbosa", "Michael Caldara", "Joey Durham", "Federico Pecora"], "title": "Symbolic Planning and Multi-Agent Path Finding in Extremely Dense Environments with Movable Obstacles", "comment": null, "summary": "We introduce the Block Rearrangement Problem (BRaP), a challenging component\nof large warehouse management which involves rearranging storage blocks within\ndense grids to achieve a target state. We formally define the BRaP as a graph\nsearch problem. Building on intuitions from sliding puzzle problems, we propose\nfive search-based solution algorithms, leveraging joint configuration space\nsearch, classical planning, multi-agent pathfinding, and expert heuristics. We\nevaluate the five approaches empirically for plan quality and scalability.\nDespite the exponential relation between search space size and block number,\nour methods demonstrate efficiency in creating rearrangement plans for deeply\nburied blocks in up to 80x80 grids.", "AI": {"tldr": "\u63d0\u51fa\u4e86Block Rearrangement Problem (BRaP)\uff0c\u5b9a\u4e49\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e94\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u89e3\u51b3\u65b9\u6848\u7b97\u6cd5\uff0c\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8868\u73b0\u9ad8\u6548\uff0c\u5c24\u5176\u9002\u7528\u4e8e80x80\u7f51\u683c\u4e2d\u6df1\u57cb\u7684\u5757\u3002", "motivation": "\u4ecb\u7ecd\u4e86Block Rearrangement Problem (BRaP)\u7684\u6311\u6218\u6027\uff0c\u5373\u5728\u5927\u578b\u4ed3\u5e93\u7ba1\u7406\u4e2d\u91cd\u65b0\u6392\u5217\u5b58\u50a8\u5757\u4ee5\u5b9e\u73b0\u76ee\u6807\u72b6\u6001\u3002\u542f\u53d1\u4e8e\u6ed1\u52a8\u62fc\u56fe\u95ee\u9898\u7684\u76f4\u89c9\uff0c\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e94\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u89e3\u51b3\u65b9\u6848\u7b97\u6cd5\uff0c\u5305\u62ec\u8054\u5408\u914d\u7f6e\u7a7a\u95f4\u641c\u7d22\u3001\u7ecf\u5178\u89c4\u5212\u3001\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u548c\u4e13\u5bb6\u542f\u53d1\u5f0f\u3002\u5bf9\u8fd9\u4e9b\u65b9\u6cd5\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8bc4\u4f30\u8ba1\u5212\u8d28\u91cf\u548c\u53ef\u4f38\u7f29\u6027\u3002", "result": "\u65b9\u6cd5\u5728\u521b\u5efa\u91cd\u65b0\u6392\u5217\u8ba1\u5212\u65b9\u9762\u8868\u73b0\u9ad8\u6548\uff0c\u5c24\u5176\u9002\u7528\u4e8e80x80\u7f51\u683c\u4e2d\u6df1\u57cb\u7684\u5757\u3002", "conclusion": "\u63d0\u51faBlock Rearrangement Problem (BRaP)\uff0c\u5373\u5927\u578b\u4ed3\u5e93\u7ba1\u7406\u7684\u6311\u6218\u6027\u7ec4\u6210\u90e8\u5206\uff0c\u6d89\u53ca\u5728\u5bc6\u96c6\u7f51\u683c\u5185\u91cd\u65b0\u6392\u5217\u5b58\u50a8\u5757\u4ee5\u5b9e\u73b0\u76ee\u6807\u72b6\u6001\u3002\u6211\u4eec\u5c06BRaP\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\u3002\u901a\u8fc7\u6ed1\u52a8\u62fc\u56fe\u95ee\u9898\u7684\u76f4\u89c9\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e94\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u89e3\u51b3\u65b9\u6848\u7b97\u6cd5\uff0c\u5229\u7528\u8054\u5408\u914d\u7f6e\u7a7a\u95f4\u641c\u7d22\u3001\u7ecf\u5178\u89c4\u5212\u3001\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u548c\u4e13\u5bb6\u542f\u53d1\u5f0f\u3002\u6211\u4eec\u4ece\u8ba1\u5212\u8d28\u91cf\u548c\u53ef\u4f38\u7f29\u6027\u7684\u89d2\u5ea6\u5bf9\u8fd9\u4e94\u79cd\u65b9\u6cd5\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002\u5c3d\u7ba1\u641c\u7d22\u7a7a\u95f4\u5927\u5c0f\u4e0e\u5757\u6570\u4e4b\u95f4\u5448\u6307\u6570\u5173\u7cfb\uff0c\u4f46\u6211\u4eec\u7684\u65b9\u6cd5\u572880x80\u7f51\u683c\u4e2d\u9ad8\u6548\u521b\u5efa\u91cd\u65b0\u6392\u5217\u8ba1\u5212\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6df1\u57cb\u7684\u5757\u3002"}}
{"id": "2509.01052", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.01052", "abs": "https://arxiv.org/abs/2509.01052", "authors": ["Jaewoo Ahn", "Junseo Kim", "Heeseung Yun", "Jaehyeon Son", "Dongmin Park", "Jaewoong Cho", "Gunhee Kim"], "title": "FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games", "comment": "EMNLP 2025 Main. Project page:\n  https://ahnjaewoo.github.io/flashadventure", "summary": "GUI agents powered by LLMs show promise in interacting with diverse digital\nenvironments. Among these, video games offer a valuable testbed due to their\nvaried interfaces, with adventure games posing additional challenges through\ncomplex, narrative-driven interactions. Existing game benchmarks, however, lack\ndiversity and rarely evaluate agents on completing entire storylines. To\naddress this, we introduce FlashAdventure, a benchmark of 34 Flash-based\nadventure games designed to test full story arc completion and tackle the\nobservation-behavior gap: the challenge of remembering and acting on earlier\ngameplay information. We also propose CUA-as-a-Judge, an automated gameplay\nevaluator, and COAST, an agentic framework leveraging long-term clue memory to\nbetter plan and solve sequential tasks. Experiments show current GUI agents\nstruggle with full story arcs, while COAST improves milestone completion by\nbridging the observation-behavior gap. Nonetheless, a marked discrepancy\nbetween humans and best-performing agents warrants continued research efforts\nto narrow this divide.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86FlashAdventure\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u6d4b\u8bd5\u667a\u80fd\u4f53\u5b8c\u6210\u6574\u4e2a\u5192\u9669\u6e38\u620f\u6545\u4e8b\u60c5\u8282\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u95ee\u9898\u3002\u5b9e\u9a8c\u53d1\u73b0\u5f53\u524dGUI\u667a\u80fd\u4f53\u5728\u6b64\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u4f46COAST\u4ee3\u7406\u6846\u67b6\u901a\u8fc7\u5229\u7528\u957f\u671f\u7ebf\u7d22\u8bb0\u5fc6\u5df2\u7ecf\u53d6\u5f97\u4e86\u4e00\u4e9b\u8fdb\u5c55\u3002\u7136\u800c\uff0c\u4ecd\u7136\u5b58\u5728\u4eba\u7c7b\u4e0e\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u8868\u73b0\u5dee\u8ddd\uff0c\u9700\u8981\u8fdb\u884c\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u6e38\u620f\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u5e76\u5f88\u5c11\u8bc4\u4f30\u667a\u80fd\u4f53\u5b8c\u6210\u6574\u4e2a\u6545\u4e8b\u60c5\u8282\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u5f15\u5165\u4e86FlashAdventure\u57fa\u51c6\u6d4b\u8bd5\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u89e3\u51b3\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u81ea\u52a8\u5316\u6e38\u620f\u8bc4\u4f30\u5668\u548c\u4ee3\u7406\u6846\u67b6\u3002\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u6539\u5584\u667a\u80fd\u4f53\u5728\u5192\u9669\u6e38\u620f\u7b49\u5177\u6709\u590d\u6742\u4ea4\u4e92\u7684\u6570\u5b57\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4ecb\u7ecd\u4e86FlashAdventure\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u4e24\u4e2a\u65b0\u63d0\u51fa\u7684\u5de5\u5177\uff1aCUA-as-a-Judge\u548cCOAST\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u73b0\u6709GUI\u667a\u80fd\u4f53\u5728\u5b8c\u6210\u6574\u4e2a\u6545\u4e8b\u60c5\u8282\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u800cCOAST\u6539\u5584\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u7f29\u5c0f\u4e86\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u5f53\u524dGUI\u667a\u80fd\u4f53\u5728\u5b8c\u6210\u6574\u4e2a\u6545\u4e8b\u60c5\u8282\u65b9\u9762\u56f0\u96be\u91cd\u91cd\uff0c\u4f46COAST\u901a\u8fc7\u6539\u5584\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u5df2\u7ecf\u53d6\u5f97\u4e86\u4e00\u5b9a\u8fdb\u5c55\u3002\u4eba\u7c7b\u4e0e\u8868\u73b0\u6700\u4f73\u7684\u667a\u80fd\u4f53\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002", "conclusion": "\u5bf9\u8bdd\u6846\u667a\u80fd\u4f53\uff08GUI agents\uff09\u5229\u7528LLMs\u5728\u4e0e\u4e0d\u540c\u6570\u5b57\u73af\u5883\u8fdb\u884c\u4ea4\u4e92\u65b9\u9762\u8868\u73b0\u51fa\u5f88\u5927\u6f5c\u529b\u3002\u6211\u4eec\u4ecb\u7ecd\u4e86FlashAdventure\uff0c\u4e00\u4e2a\u753134\u4e2aFlash\u57fa\u7840\u5192\u9669\u6e38\u620f\u7ec4\u6210\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u6d4b\u8bd5\u5b8c\u6574\u6545\u4e8b\u60c5\u8282\u7684\u5b8c\u6210\uff0c\u89e3\u51b3\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u95ee\u9898\u3002\u540c\u65f6\uff0c\u6211\u4eec\u63d0\u51fa\u4e86CUA-as-a-Judge\uff0c\u4e00\u4e2a\u81ea\u52a8\u5316\u6e38\u620f\u8bc4\u4f30\u5668\uff0c\u4ee5\u53caCOAST\uff0c\u4e00\u4e2a\u5229\u7528\u957f\u671f\u7ebf\u7d22\u8bb0\u5fc6\u6765\u66f4\u597d\u89c4\u5212\u5e76\u89e3\u51b3\u987a\u5e8f\u4efb\u52a1\u7684\u4ee3\u7406\u6846\u67b6\u3002\u5b9e\u9a8c\u8bc1\u660e\u76ee\u524dGUI\u667a\u80fd\u4f53\u5728\u5b8c\u6574\u6545\u4e8b\u60c5\u8282\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u800cCOAST\u901a\u8fc7\u6709\u6548\u89e3\u51b3\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u6765\u63d0\u9ad8\u91cc\u7a0b\u7891\u4efb\u52a1\u7684\u5b8c\u6210\u7387\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u4eba\u7c7b\u4e0e\u8868\u73b0\u6700\u4f73\u7684\u667a\u80fd\u4f53\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u52aa\u529b\u6765\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002"}}
{"id": "2509.01055", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.01055", "abs": "https://arxiv.org/abs/2509.01055", "authors": ["Dongfu Jiang", "Yi Lu", "Zhuofeng Li", "Zhiheng Lyu", "Ping Nie", "Haozhe Wang", "Alex Su", "Hui Chen", "Kai Zou", "Chao Du", "Tianyu Pang", "Wenhu Chen"], "title": "VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use", "comment": "32 pages, 5 figures, 13 tables", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated\nsuccess in enhancing LLM reasoning capabilities, but remains limited to\nsingle-turn interactions without tool integration. While recent Agentic\nReinforcement Learning with Tool use (ARLT) approaches have emerged to address\nmulti-turn tool interactions, existing works develop task-specific codebases\nthat suffer from fragmentation, synchronous execution bottlenecks, and limited\nextensibility across domains. These inefficiencies hinder broader community\nadoption and algorithmic innovation. We introduce VerlTool, a unified and\nmodular framework that addresses these limitations through systematic design\nprinciples. VerlTool provides four key contributions: (1) upstream alignment\nwith VeRL ensuring compatibility and simplified maintenance, (2) unified tool\nmanagement via standardized APIs supporting diverse modalities including code\nexecution, search, SQL databases, and vision processing, (3) asynchronous\nrollout execution achieving near 2$\\times$ speedup by eliminating\nsynchronization bottlenecks, and (4) comprehensive evaluation demonstrating\ncompetitive performance across 6 ARLT domains. Our framework formalizes ARLT as\nmulti-turn trajectories with multi-modal observation tokens (text/image/video),\nextending beyond single-turn RLVR paradigms. We train and evaluate models on\nmathematical reasoning, knowledge QA, SQL generation, visual reasoning, web\nsearch, and software engineering tasks, achieving results comparable to\nspecialized systems while providing unified training infrastructure. The\nmodular plugin architecture enables rapid tool integration requiring only\nlightweight Python definitions, significantly reducing development overhead and\nproviding a scalable foundation for tool-augmented RL research. Our code is\nopen-sourced at https://github.com/TIGER-AI-Lab/verl-tool.", "AI": {"tldr": "\u63d0\u51fa\u4e86VerlTool\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u8bbe\u8ba1\u539f\u5219\u89e3\u51b3\u4e86RLVR\u548cARLT\u65b9\u6cd5\u4e2d\u7684\u95ee\u9898\u3002\u6846\u67b6\u652f\u6301\u591a\u6a21\u6001\u89c2\u6d4b\u4ee4\u724c\uff0c\u6269\u5c55\u4e86\u5355\u8f6eRLVR\u8303\u4f8b\uff0c\u5728\u591a\u4e2aARLT\u9886\u57df\u53d6\u5f97\u7ade\u4e89\u6027\u6027\u80fd\u3002\u6a21\u5757\u5316\u63d2\u4ef6\u67b6\u6784\u964d\u4f4e\u4e86\u5f00\u53d1\u6210\u672c\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684ARLT\u65b9\u6cd5\u5b58\u5728\u7740\u5206\u6bb5\u3001\u540c\u6b65\u6267\u884c\u74f6\u9888\u548c\u9886\u57df\u95f4\u7684\u6709\u9650\u53ef\u6269\u5c55\u6027\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5e7f\u6cdb\u793e\u533a\u91c7\u7528\u548c\u7b97\u6cd5\u521b\u65b0\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u4f4e\u6548\u7387\u95ee\u9898\uff0c\u63d0\u51fa\u5f15\u5165VerlTool\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bbe\u8ba1\u4f18\u5316\u591a\u8f6e\u5de5\u5177\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u673a\u5236\uff0c\u5177\u6709\u9ad8\u5ea6\u53ef\u6269\u5c55\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\u7684\u6f5c\u529b\u3002", "method": "\u5f15\u5165\u4e86VerlTool\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\u539f\u5219\u89e3\u51b3\u4e86RLVR\u548cARLT\u65b9\u6cd5\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u56db\u4e2a\u5173\u952e\u8d21\u732e\u70b9\u3002\u91c7\u7528\u5f02\u6b65\u63a8\u51fa\u6267\u884c\u65b9\u5f0f\uff0c\u6d88\u9664\u540c\u6b65\u74f6\u9888\uff0c\u83b7\u5f97\u8fd12\u500d\u52a0\u901f\u3002\u91c7\u7528\u591a\u8f6e\u8f68\u8ff9\u548c\u591a\u6a21\u6001\u89c2\u6d4b\u4ee4\u724c\u6269\u5c55\u4e86\u5355\u8f6eRLVR\u8303\u4f8b\uff0c\u540c\u65f6\u5728\u6570\u5b66\u63a8\u7406\u3001\u77e5\u8bc6\u95ee\u7b54\u3001SQL\u751f\u6210\u3001\u89c6\u89c9\u63a8\u7406\u3001\u7f51\u7edc\u641c\u7d22\u548c\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "VerlTool\u662f\u4e00\u4e2a\u7edf\u4e00\u548c\u6a21\u5757\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u8bbe\u8ba1\u539f\u5219\u89e3\u51b3\u4e86RLVR\u548cARLT\u65b9\u6cd5\u4e2d\u7684\u95ee\u9898\u3002\u57286\u4e2aARLT\u9886\u57df\u4e2d\u5c55\u73b0\u4e86\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u4e0e\u4e13\u95e8\u7cfb\u7edf\u76f8\u5339\u654c\u7684\u7ed3\u679c\u3002\u5f00\u6e90\u4ee3\u7801\u94fe\u63a5\u4e3ahttps://github.com/TIGER-AI-Lab/verl-tool\u3002", "conclusion": "\u4ecb\u7ecd\u4e86VerlTool\uff0c\u5b83\u662f\u4e00\u4e2a\u7edf\u4e00\u4e14\u6a21\u5757\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bbe\u8ba1\u539f\u5219\u89e3\u51b3\u4e86RLVR\u548cARLT\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u5c40\u9650\u6027\u3002VerlTool\u63d0\u4f9b\u4e86\u56db\u4e2a\u5173\u952e\u8d21\u732e\u70b9\uff0c\u5e76\u57286\u4e2aARLT\u9886\u57df\u5c55\u793a\u4e86\u7ade\u4e89\u6027\u8868\u73b0\u3002\u901a\u8fc7\u5728\u591a\u8f6e\u8f68\u8ff9\u4e2d\u5f15\u5165\u591a\u6a21\u6001\u89c2\u6d4b\u4ee4\u724c\uff0c\u6269\u5c55\u4e86\u5355\u8f6eRLVR\u8303\u4f8b\uff0c\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u3001\u77e5\u8bc6\u95ee\u7b54\u3001SQL\u751f\u6210\u3001\u89c6\u89c9\u63a8\u7406\u3001\u7f51\u7edc\u641c\u7d22\u548c\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u53ef\u4e0e\u4e13\u95e8\u7cfb\u7edf\u76f8\u5ab2\u7f8e\u7684\u7ed3\u679c\u3002\u6a21\u5757\u5316\u63d2\u4ef6\u67b6\u6784\u5b9e\u73b0\u5feb\u901f\u96c6\u6210\u5de5\u5177\uff0c\u53ea\u9700\u8f7b\u91cf\u7ea7Python\u5b9a\u4e49\uff0c\u5927\u5927\u964d\u4f4e\u4e86\u5f00\u53d1\u6210\u672c\uff0c\u5e76\u4e3a\u5de5\u5177\u589e\u5f3a\u7684RL\u7814\u7a76\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2509.01106", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.01106", "abs": "https://arxiv.org/abs/2509.01106", "authors": ["Huang Fang", "Mengxi Zhang", "Heng Dong", "Wei Li", "Zixuan Wang", "Qifeng Zhang", "Xueyun Tian", "Yucheng Hu", "Hang Li"], "title": "Robix: A Unified Model for Robot Interaction, Reasoning and Planning", "comment": "Tech report. Project page: https://robix-seed.github.io/robix/", "summary": "We introduce Robix, a unified model that integrates robot reasoning, task\nplanning, and natural language interaction within a single vision-language\narchitecture. Acting as the high-level cognitive layer in a hierarchical robot\nsystem, Robix dynamically generates atomic commands for the low-level\ncontroller and verbal responses for human interaction, enabling robots to\nfollow complex instructions, plan long-horizon tasks, and interact naturally\nwith human within an end-to-end framework. Robix further introduces novel\ncapabilities such as proactive dialogue, real-time interruption handling, and\ncontext-aware commonsense reasoning during task execution. At its core, Robix\nleverages chain-of-thought reasoning and adopts a three-stage training\nstrategy: (1) continued pretraining to enhance foundational embodied reasoning\nabilities including 3D spatial understanding, visual grounding, and\ntask-centric reasoning; (2) supervised finetuning to model human-robot\ninteraction and task planning as a unified reasoning-action sequence; and (3)\nreinforcement learning to improve reasoning-action consistency and long-horizon\ntask coherence. Extensive experiments demonstrate that Robix outperforms both\nopen-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in\ninteractive task execution, demonstrating strong generalization across diverse\ninstruction types (e.g., open-ended, multi-stage, constrained, invalid, and\ninterrupted) and various user-involved tasks such as table bussing, grocery\nshopping, and dietary filtering.", "AI": {"tldr": "Robix is a unified model that enhances robot reasoning, task planning, and natural language interaction. It outperforms existing baselines in interactive task execution, demonstrating strong generalization across diverse instruction types and user-involved tasks.", "motivation": "The motivation of this paper is to enable robots to follow complex instructions, plan long-horizon tasks, and interact naturally with humans within an end-to-end framework. It introduces novel capabilities like proactive dialogue, real-time interruption handling, and context-aware commonsense reasoning during task execution.", "method": "Robix leverages chain-of-thought reasoning and adopts a three-stage training strategy: continued pretraining, supervised finetuning, and reinforcement learning. It dynamically generates atomic commands for low-level controller and verbal responses for human interaction.", "result": "Extensive experiments demonstrate that Robix outperforms both open-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in interactive task execution, showing strong generalization across diverse instruction types and user-involved tasks such as table bussing, grocery shopping, and dietary filtering.", "conclusion": "Robix is a unified model that integrates robot reasoning, task planning, and natural language interaction within a single vision-language architecture. It outperforms open-source and commercial baselines in interactive task execution, showing strong generalization across diverse instruction types."}}
{"id": "2509.01136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01136", "abs": "https://arxiv.org/abs/2509.01136", "authors": ["Gabriel Simmons"], "title": "Heads or Tails: A Simple Example of Causal Abstractive Simulation", "comment": "14 pages", "summary": "This note illustrates how a variety of causal abstraction arXiv:1707.00819\narXiv:1812.03789, defined here as causal abstractive simulation, can be used to\nformalize a simple example of language model simulation. This note considers\nthe case of simulating a fair coin toss with a language model. Examples are\npresented illustrating the ways language models can fail to simulate, and a\nsuccess case is presented, illustrating how this formalism may be used to prove\nthat a language model simulates some other system, given a causal description\nof the system. This note may be of interest to three groups. For practitioners\nin the growing field of language model simulation, causal abstractive\nsimulation is a means to connect ad-hoc statistical benchmarking practices to\nthe solid formal foundation of causality. Philosophers of AI and philosophers\nof mind may be interested as causal abstractive simulation gives a precise\noperationalization to the idea that language models are role-playing\narXiv:2402.12422. Mathematicians and others working on causal abstraction may\nbe interested to see a new application of the core ideas that yields a new\nvariation of causal abstraction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u5982\u4f55\u4f7f\u7528\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u6765\u5f62\u5f0f\u5316\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u7684\u4f8b\u5b50\uff0c\u9610\u8ff0\u4e86\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u5176\u4ed6\u7cfb\u7edf\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u8005\u5e94\u7528\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u6765\u8fde\u63a5\u7edf\u8ba1\u6d4b\u8bd5\u5b9e\u8df5\u4e0e\u56e0\u679c\u6027\u57fa\u7840\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u9886\u57df\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u8be5\u7814\u7a76\u53ef\u80fd\u5bf9\u4ece\u4e1a\u8005\u3001\u4eba\u5de5\u667a\u80fd\u54f2\u5b66\u5bb6\u548c\u6570\u5b66\u5bb6\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5c06\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u5e94\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u6a21\u62df\uff0c\u5e76\u63a2\u8ba8\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u4e2d\u7684\u5931\u8d25\u548c\u6210\u529f\u6848\u4f8b\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u3001\u5fc3\u7075\u54f2\u5b66\u4ee5\u53ca\u6570\u5b66\u7b49\u9886\u57df\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u65b0\u7684\u89c2\u70b9\u548c\u5e94\u7528\u3002", "method": "\u8bba\u6587\u4f7f\u7528\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u6765\u8fde\u63a5\u7edf\u8ba1\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u4e0e\u56e0\u679c\u6027\u7684\u575a\u5b9e\u5f62\u5f0f\u57fa\u7840\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u9886\u57df\u7684\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b9\u6cd5\u3002", "result": "\u8bba\u6587\u5448\u73b0\u4e86\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u5728\u6a21\u62df\u516c\u5e73\u786c\u5e01\u629b\u63b7\u4e2d\u7684\u4f8b\u5b50\uff0c\u9610\u660e\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u62df\u65b9\u5f0f\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6210\u529f\u7684\u6848\u4f8b\u3002", "conclusion": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u6765\u5f62\u5f0f\u5316\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u7684\u7b80\u5355\u793a\u4f8b\uff0c\u8bf4\u660e\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u6a21\u62df\u5176\u4ed6\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u63cf\u8ff0\u7684\u8bc1\u660e\u65b9\u6cd5\u3002"}}
{"id": "2509.01182", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01182", "abs": "https://arxiv.org/abs/2509.01182", "authors": ["Wonduk Seo", "Taesub Shin", "Hyunjin An", "Dokyun Kim", "Seunghyun Lee"], "title": "Question-to-Knowledge: Multi-Agent Generation of Inspectable Facts for Product Mapping", "comment": "Preprint", "summary": "Identifying whether two product listings refer to the same Stock Keeping Unit\n(SKU) is a persistent challenge in ecommerce, especially when explicit\nidentifiers are missing and product names vary widely across platforms. Rule\nbased heuristics and keyword similarity often misclassify products by\noverlooking subtle distinctions in brand, specification, or bundle\nconfiguration. To overcome these limitations, we propose Question to Knowledge\n(Q2K), a multi agent framework that leverages Large Language Models (LLMs) for\nreliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates\ntargeted disambiguation questions, (2) a Knowledge Agent that resolves them via\nfocused web searches, and (3) a Deduplication Agent that reuses validated\nreasoning traces to reduce redundancy and ensure consistency. A human in the\nloop mechanism further refines uncertain cases. Experiments on real world\nconsumer goods datasets show that Q2K surpasses strong baselines, achieving\nhigher accuracy and robustness in difficult scenarios such as bundle\nidentification and brand origin disambiguation. By reusing retrieved reasoning\ninstead of issuing repeated searches, Q2K balances accuracy with efficiency,\noffering a scalable and interpretable solution for product integration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Q2K\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u89e3\u51b3\u7535\u5b50\u5546\u52a1\u4e2d\u8bc6\u522b\u4ea7\u54c1\u662f\u5426\u5f15\u7528\u76f8\u540cSKU\u7684\u6311\u6218\u3002Q2K\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u56f0\u96be\u60c5\u666f\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u7a33\u5065\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u7535\u5b50\u5546\u52a1\u73af\u5883\u4e2d\uff0c\u8bc6\u522b\u4e24\u4e2a\u4ea7\u54c1\u5217\u8868\u662f\u5426\u5f15\u7528\u76f8\u540cSKU\u662f\u4e00\u4e2a\u6301\u7eed\u6311\u6218\uff0c\u7279\u522b\u662f\u5f53\u7f3a\u4e4f\u660e\u786e\u6807\u8bc6\u7b26\u4e14\u4ea7\u54c1\u540d\u79f0\u5728\u4e0d\u540c\u5e73\u53f0\u4e0a\u53d8\u5316\u8303\u56f4\u5e7f\u6cdb\u65f6\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u5173\u952e\u8bcd\u76f8\u4f3c\u6027\u5f80\u5f80\u4f1a\u5ffd\u89c6\u54c1\u724c\u3001\u89c4\u683c\u6216\u6346\u7ed1\u914d\u7f6e\u4e2d\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u5bfc\u81f4\u4ea7\u54c1\u88ab\u9519\u8bef\u5206\u7c7b\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e86Q2K\u6846\u67b6\uff0c\u65e8\u5728\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53ef\u9760\u7684SKU\u6620\u5c04\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Question to Knowledge (Q2K)\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u62ec Reasoning Agent\u3001Knowledge Agent \u548c Deduplication Agent \u4e09\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4ee5\u89e3\u51b3\u5728\u7535\u5b50\u5546\u52a1\u4e2d\u8bc6\u522b\u4e24\u4e2a\u4ea7\u54c1\u5217\u8868\u662f\u5426\u5f15\u7528\u76f8\u540cSKU\u7684\u6311\u6218\u3002\u901a\u8fc7\u751f\u6210\u9488\u5bf9\u6027\u7684\u6d88\u9664\u6b67\u4e49\u95ee\u9898\u3001\u5229\u7528\u7f51\u7edc\u641c\u7d22\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u91cd\u590d\u4f7f\u7528\u9a8c\u8bc1\u8fc7\u7684\u63a8\u7406\u8f68\u8ff9\u6765\u51cf\u5c11\u5197\u4f59\u548c\u786e\u4fdd\u4e00\u81f4\u6027\u3002\u5728\u4e00\u4e9b\u56f0\u96be\u60c5\u666f\u4e0b\uff0cQ2K\u901a\u8fc7\u4eba\u7c7b\u4ecb\u5165\u673a\u5236\u8fdb\u4e00\u6b65\u4f18\u5316\u4e0d\u786e\u5b9a\u60c5\u51b5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0cQ2K\u5728\u771f\u5b9e\u6d88\u8d39\u54c1\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6346\u7ed1\u8bc6\u522b\u548c\u54c1\u724c\u8d77\u6e90\u6d88\u9664\u6b67\u4e49\u7b49\u56f0\u96be\u60c5\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u7a33\u5065\u6027\u3002\u91cd\u7528\u63a8\u7406\u4fe1\u606f\u6709\u52a9\u4e8e\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuestion to Knowledge (Q2K)\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u53ef\u9760\u7684SKU\u6620\u5c04\u3002\u901a\u8fc7\u5bf9\u771f\u5b9e\u6d88\u8d39\u54c1\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660eQ2K\u5728\u56f0\u96be\u60c5\u666f\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u8d85\u8d8a\u4e86\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002\u901a\u8fc7\u91cd\u7528\u68c0\u7d22\u5230\u7684\u63a8\u7406\u4fe1\u606f\u800c\u4e0d\u662f\u53d1\u51fa\u91cd\u590d\u641c\u7d22\u8bf7\u6c42\uff0cQ2K\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e3a\u4ea7\u54c1\u96c6\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01238", "abs": "https://arxiv.org/abs/2509.01238", "authors": ["Jiasheng Xu", "Mingda Li", "Yongqiang Tang", "Peijie Wang", "Wensheng Zhang"], "title": "Towards Open-World Retrieval-Augmented Generation on Knowledge Graph: A Multi-Agent Collaboration Framework", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\nlanguage understanding and reasoning. However, their dependence on static\ntraining corpora makes them prone to factual errors and knowledge gaps.\nRetrieval-Augmented Generation (RAG) addresses this limitation by incorporating\nexternal knowledge sources, especially structured Knowledge Graphs (KGs), which\nprovide explicit semantics and efficient retrieval. Existing KG-based RAG\napproaches, however, generally assume that anchor entities are accessible to\ninitiate graph traversal, which limits their robustness in open world settings\nwhere accurate linking between the query and the entity is unreliable. To\novercome this limitation, we propose AnchorRAG, a novel multi-agent\ncollaboration framework for open-world RAG without the predefined anchor\nentities. Specifically, a predictor agent dynamically identifies candidate\nanchor entities by aligning user query terms with KG nodes and initializes\nindependent retriever agents to conduct parallel multi-hop explorations from\neach candidate. Then a supervisor agent formulates the iterative retrieval\nstrategy for these retriever agents and synthesizes the resulting knowledge\npaths to generate the final answer. This multi-agent collaboration framework\nimproves retrieval robustness and mitigates the impact of ambiguous or\nerroneous anchors. Extensive experiments on four public benchmarks demonstrate\nthat AnchorRAG significantly outperforms existing baselines and establishes new\nstate-of-the-art results on the real-world question answering tasks.", "AI": {"tldr": "AnchorRAG introduces a multi-agent collaboration framework for open-world question answering without predefined anchor entities. It outperforms existing approaches, improves retrieval robustness, and establishes new state-of-the-art results in real-world question answering tasks.", "motivation": "Existing Knowledge Graph-based Retrieval-Augmented Generation (RAG) approaches rely on predefined anchor entities, limiting robustness in open-world settings. AnchorRAG aims to overcome this limitation by dynamically identifying anchor entities and employing a multi-agent collaboration framework for more accurate question answering.", "method": "AnchorRAG proposes a multi-agent collaboration framework where a predictor agent identifies candidate anchor entities, retriever agents conduct multi-hop explorations, and a supervisor agent formulates retrieval strategy. This framework improves retrieval robustness and mitigates the impact of ambiguous or erroneous anchors.", "result": "Extensive experiments on four public benchmarks show that AnchorRAG outperforms existing methods and achieves new state-of-the-art results in real-world question answering tasks.", "conclusion": "AnchorRAG, a novel multi-agent collaboration framework for open-world Retrieval-Augmented Generation (RAG) without predefined anchor entities, significantly outperforms existing baselines and establishes new state-of-the-art results in real-world question answering tasks."}}
{"id": "2509.01245", "categories": ["cs.AI", "cs.MA", "cs.OS"], "pdf": "https://arxiv.org/pdf/2509.01245", "abs": "https://arxiv.org/abs/2509.01245", "authors": ["Yusheng Zheng", "Yanpeng Hu", "Wei Zhang", "Andi Quinn"], "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "comment": null, "summary": "Operating system schedulers suffer from a fundamental semantic gap, where\nkernel policies fail to understand application-specific needs, leading to\nsuboptimal performance. We introduce SchedCP, the first framework that enables\nfully autonomous Large Language Model (LLM) agents to safely and efficiently\noptimize Linux schedulers without human involvement. Our core insight is that\nthe challenge is not merely to apply a better LLM, but to architect a decoupled\ncontrol plane that separates the AI's role of semantic reasoning (\"what to\noptimize\") from the system's role of execution (\"how to observe and act\").\nImplemented as Model Context Protocol(MCP) server, SchedCP provides a stable\ninterface with three key services: a Workload Analysis Engine, an evolving\nScheduler Policy Repository, and an Execution Verifier that validates all\nAI-generated code and configure before deployment with static and dynamic\nanalysis.\n  We demonstrate this architecture's power with sched-agent, a multi-agent\nsystem that autonomously analyzes workloads, synthesizes custom eBPF scheduling\npolicies, and deploys them via the sched\\_ext infrastructure. Our evaluation\nshows that SchedCP achieves up to an 1.79x performance improvement, and a 13x\ncost reduction compared to naive agentic approaches, all while maintaining high\nsuccess rate. By bridging the semantic gap, SchedCP democratizes expert-level\nsystem optimization and represents a step towards creating truly\nself-optimizing, application-aware operating systems. The code is open-sourced\nin https://github.com/eunomia-bpf/schedcp", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86SchedCP\u6846\u67b6\uff0c\u4f7f\u7528\u4eba\u5de5\u667a\u80fd\u5b9e\u73b0\u81ea\u4e3b\u4f18\u5316Linux\u8c03\u5ea6\u5668\uff0c\u89e3\u51b3\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660eSchedCP\u76f8\u6bd4\u6734\u7d20\u65b9\u6cd5\u6027\u80fd\u63d0\u53471.79\u500d\uff0c\u6210\u672c\u964d\u4f4e13\u500d\uff0c\u6210\u529f\u7387\u9ad8\u3002\u63a8\u52a8\u64cd\u4f5c\u7cfb\u7edf\u671d\u5411\u81ea\u6211\u4f18\u5316\u65b9\u5411\u53d1\u5c55\u3002", "motivation": "\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\uff0c\u4eba\u5de5\u667a\u80fd\u80fd\u591f\u8f85\u52a9\u4f18\u5316\u8c03\u5ea6\u5668\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u7684\u6027\u80fd\u548c\u7cfb\u7edf\u6267\u884c\u7684\u77db\u76fe\u3002\u672c\u6587\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u81ea\u4e3b\u4f18\u5316\u7cfb\u7edf\uff0c\u5b9e\u73b0\u667a\u80fd\u3001\u9ad8\u6548\u7684\u8c03\u5ea6\u5668\u4f18\u5316\uff0c\u4ee5\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u4ecb\u7ecd\u4e86SchedCP\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u89e3\u51b3\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u8bed\u4e49\u9e3f\u6c9f\u7684\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u81ea\u4e3b\u4f18\u5316\u7cfb\u7edf\u3002\u901a\u8fc7Model Context Protocol\uff08MCP\uff09\u670d\u52a1\u5668\u5b9e\u73b0\u4e86\u5173\u952e\u670d\u52a1\uff0c\u5982\u5de5\u4f5c\u8d1f\u8f7d\u5206\u6790\u5f15\u64ce\u3001\u8c03\u5ea6\u7b56\u7565\u5e93\u548c\u6267\u884c\u9a8c\u8bc1\u5668\u3002\u4f7f\u7528sched-agent\u7cfb\u7edf\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u73b0\u4e86SchedCP\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u89e3\u51b3\u8c03\u5ea6\u5668\u8bed\u4e49\u9e3f\u6c9f\u7684\u80fd\u529b\u3002\u901a\u8fc7sched-agent\u7cfb\u7edf\u5b9e\u9a8c\uff0c\u53d6\u5f97\u4e861.79\u500d\u6027\u80fd\u63d0\u5347\u548c13\u500d\u6210\u672c\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6210\u529f\u7387\u3002\u901a\u8fc7SchedCP\uff0c\u4f7f\u5f97\u7cfb\u7edf\u4f18\u5316\u66f4\u52a0\u666e\u53ca\u5316\uff0c\u63a8\u52a8\u4e86\u64cd\u4f5c\u7cfb\u7edf\u671d\u5411\u771f\u6b63\u81ea\u6211\u4f18\u5316\u7684\u65b9\u5411\u53d1\u5c55\u3002", "conclusion": "\u4ecb\u7ecd\u4e86SchedCP\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u5f97\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u80fd\u591f\u5728\u4e0d\u9700\u8981\u4eba\u7c7b\u5e72\u9884\u7684\u60c5\u51b5\u4e0b\u5b89\u5168\u9ad8\u6548\u5730\u4f18\u5316Linux\u8c03\u5ea6\u5668\u3002\u901a\u8fc7\u89e3\u8026\u63a7\u5236\u5e73\u9762\uff0c\u5c06\u4eba\u5de5\u667a\u80fd\u7684\u8bed\u4e49\u63a8\u7406\u548c\u7cfb\u7edf\u7684\u6267\u884c\u8fc7\u7a0b\u5206\u5f00\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u4f18\u5316\u3002\u4f7f\u7528Model Context Protocol\uff08MCP\uff09\u670d\u52a1\u5668\u5b9e\u73b0\uff0c\u63d0\u4f9b\u4e86\u7a33\u5b9a\u63a5\u53e3\uff0c\u5305\u62ec\u5de5\u4f5c\u8d1f\u8f7d\u5206\u6790\u5f15\u64ce\u3001\u8c03\u5ea6\u7b56\u7565\u5e93\u548c\u6267\u884c\u9a8c\u8bc1\u5668\u7b49\u5173\u952e\u670d\u52a1\u3002sched-agent\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u81ea\u4e3b\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5408\u6210\u5b9a\u5236\u7684eBPF\u8c03\u5ea6\u7b56\u7565\uff0c\u5e76\u901a\u8fc7sched_ext\u57fa\u7840\u67b6\u6784\u90e8\u7f72\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSchedCP\u76f8\u6bd4\u6734\u7d20\u7684\u4ee3\u7406\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe1.79\u500d\uff0c\u6210\u672c\u964d\u4f4e13\u500d\uff0c\u540c\u65f6\u6210\u529f\u7387\u4fdd\u6301\u8f83\u9ad8\u3002\u901a\u8fc7\u5f25\u5408\u8bed\u4e49\u5dee\u8ddd\uff0cSchedCP\u4f7f\u5f97\u7cfb\u7edf\u4f18\u5316\u666e\u53ca\u5316\uff0c\u63a8\u52a8\u4e86\u5411\u771f\u6b63\u81ea\u6211\u4f18\u5316\u3001\u5e94\u7528\u611f\u77e5\u7684\u64cd\u4f5c\u7cfb\u7edf\u8fc8\u8fdb\u3002\u4ee3\u7801\u5df2\u5728 https://github.com/eunomia-bpf/schedcp \u5f00\u6e90\u3002"}}
{"id": "2509.01277", "categories": ["cs.AI", "68T50, 68T42", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.01277", "abs": "https://arxiv.org/abs/2509.01277", "authors": ["Jingxing Fan", "Jinrong Shen", "Yusheng Yao", "Shuangqing Wang", "Qian Wang", "Yuling Wang"], "title": "Communicative Agents for Slideshow Storytelling Video Generation based on LLMs", "comment": "8 pages, 8 figures, 1 table", "summary": "With the rapid advancement of artificial intelligence (AI), the proliferation\nof AI-generated content (AIGC) tasks has significantly accelerated developments\nin text-to-video generation. As a result, the field of video production is\nundergoing a transformative shift. However, conventional text-to-video models\nare typically constrained by high computational costs.\n  In this study, we propose Video-Generation-Team (VGTeam), a novel slide show\nvideo generation system designed to redefine the video creation pipeline\nthrough the integration of large language models (LLMs). VGTeam is composed of\na suite of communicative agents, each responsible for a distinct aspect of\nvideo generation, such as scriptwriting, scene creation, and audio design.\nThese agents operate collaboratively within a chat tower workflow, transforming\nuser-provided textual prompts into coherent, slide-style narrative videos.\n  By emulating the sequential stages of traditional video production, VGTeam\nachieves remarkable improvements in both efficiency and scalability, while\nsubstantially reducing computational overhead. On average, the system generates\nvideos at a cost of only $0.103, with a successful generation rate of 98.4%.\nImportantly, this framework maintains a high degree of creative fidelity and\ncustomization.\n  The implications of VGTeam are far-reaching. It democratizes video production\nby enabling broader access to high-quality content creation without the need\nfor extensive resources. Furthermore, it highlights the transformative\npotential of language models in creative domains and positions VGTeam as a\npioneering system for next-generation content creation.", "AI": {"tldr": "VGTeam introduces a slide show video generation system that uses large language models for efficient and scalable video creation at low cost. It democratizes video production, emphasizing the transformative potential of language models in creative fields.", "motivation": "The motivation behind the study is the acceleration of text-to-video generation due to the advancement of artificial intelligence and the high computational costs associated with conventional models. VGTeam aims to redefine the video creation pipeline by leveraging large language models for improved efficiency and scalability.", "method": "The study introduces Video-Generation-Team (VGTeam) composed of communicative agents for scriptwriting, scene creation, and audio design. These agents collaborate within a chat tower workflow to transform textual prompts into slide-style narrative videos, following traditional video production stages.", "result": "VGTeam achieves remarkable improvements in efficiency and scalability, generating videos at a low cost of $0.103 with a successful rate of 98.4%. The system maintains a high level of creative fidelity and customization, democratizing video production and showcasing the potential of language models in creative domains.", "conclusion": "VGTeam proposes a novel slide show video generation system that integrates large language models for efficient and scalable video creation at a low cost. It maintains creative fidelity and customization, democratizing video production and highlighting the transformative potential of language models in creative domains."}}
{"id": "2509.01308", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.01308", "abs": "https://arxiv.org/abs/2509.01308", "authors": ["Mattia Tritto", "Giuseppe Farano", "Dario Di Palma", "Gaetano Rossiello", "Fedelucio Narducci", "Dharmashankar Subramanian", "Tommaso Di Noia"], "title": "GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models", "comment": null, "summary": "Text-to-SQL, the task of translating natural language questions into SQL\nqueries, has significantly advanced with the introduction of Large Language\nModels (LLMs), broadening database accessibility for a wide range of users.\nDespite substantial progress in generating valid SQL, current LLMs still\nstruggle with complex queries that require precise alignment between user\nintent and the database schema. To mitigate this, test-time strategies such as\nBest-of-N (BoN) and Majority Voting (Maj) are often employed, based on the\nassumption that LLMs can generate correct answers but may require multiple\nattempts. However, these methods rely on surface-level heuristics, selecting\neither the syntactically correct query through execution-based BoN (ex-BoN) or\nthe most frequently generated query with Maj. Recently, Outcome Reward Models\n(ORMs), which assign utility scores to generated outputs based on semantic\ncorrectness, have emerged as a promising approach for better aligning model\npredictions with user intent. Nevertheless, their application to Text-to-SQL\nremains largely underexplored.\n  In this work, we evaluate ORMs as an effective heuristic for BoN, compare\nthem with ex-BoN and Maj, and introduce a framework for training ORMs for the\nText-to-SQL task. We evaluate our ORMs on the BIRD and SPIDER benchmarks,\nfinetuning various open-source LLMs, including the Qwen2, Granite3, and Llama3\nmodel families. Our results show that ORMs outperform ex-BoN and Maj, achieving\nexecution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and\n+2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that\nfinetuning models already aligned with SQL generation, such as OmniSQL, yields\nsuperior ORM performance. Additionally, we observe that ORMs achieve\ncompetitive results on simple queries and benefit more from an increased number\nof candidates compared to ex-BoN and Maj.", "AI": {"tldr": "Text-to-SQL task advanced with Large Language Models (LLMs) but still struggles with complex queries. Outcome Reward Models (ORMs) proposed as a better heuristic than Best-of-N (BoN) and Majority Voting (Maj) for aligning model predictions with user intent. ORM outperforms ex-BoN and Maj, achieving higher execution accuracy gains on benchmark datasets. ORM performance enhanced with fine-tuning models like OmniSQL and benefits from increased candidate evaluation. ORM competitive on simple queries and benefits from evaluating more candidates.", "motivation": "The motivation behind this work is to address the limitations of current Large Language Models (LLMs) in accurately translating natural language questions into SQL queries, especially for complex queries requiring precise alignment with the database schema. Test-time strategies like Best-of-N (BoN) and Majority Voting (Maj) are commonly used, but they rely on surface-level heuristics. The paper aims to explore the potential of Outcome Reward Models (ORMs) in improving model predictions and aligning them better with user intent in Text-to-SQL tasks.", "method": "The paper evaluates Outcome Reward Models (ORMs) as a heuristic for Best-of-N (BoN) in Text-to-SQL tasks. ORMs are compared with execution-based BoN (ex-BoN) and Majority Voting (Maj) methods. A framework for training ORMs in the Text-to-SQL domain is proposed. Various open-source Large Language Models (LLMs) like Qwen2, Granite3, and Llama3 are finetuned and assessed on BIRD and SPIDER benchmarks. The study demonstrates the advantages of using ORMs and shows performance gains across different model families and benchmark datasets.", "result": "The results indicate that Outcome Reward Models (ORMs) outperform execution-based BoN (ex-BoN) and Majority Voting (Maj) methods in the Text-to-SQL task. ORM achieves higher execution accuracy gains on benchmark datasets like BIRD and SPIDER. Fine-tuning models aligned with SQL generation, such as OmniSQL, enhances ORM performance. ORM shows competitive results on simple queries and benefits from evaluating an increased number of candidates compared to ex-BoN and Maj methods.", "conclusion": "ORMs are evaluated as an effective heuristic for Best-of-N (BoN) in Text-to-SQL tasks, outperforming ex-BoN and Majority Voting (Maj) methods. A framework for training ORMs for the Text-to-SQL task is introduced, showing superior execution accuracy gains on benchmark datasets. ORM performance is particularly enhanced when fine-tuning models aligned with SQL generation, such as OmniSQL, and benefits from an increased number of candidates for evaluation."}}
{"id": "2509.01338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01338", "abs": "https://arxiv.org/abs/2509.01338", "authors": ["Francesca Cairoli", "Luca Bortolussi", "Jyotirmoy V. Deshmukh", "Lars Lindemann", "Nicola Paoletti"], "title": "Conformal Predictive Monitoring for Multi-Modal Scenarios", "comment": null, "summary": "We consider the problem of quantitative predictive monitoring (QPM) of\nstochastic systems, i.e., predicting at runtime the degree of satisfaction of a\ndesired temporal logic property from the current state of the system. Since\ncomputational efficiency is key to enable timely intervention against predicted\nviolations, several state-of-the-art QPM approaches rely on fast\nmachine-learning surrogates to provide prediction intervals for the\nsatisfaction values, using conformal inference to offer statistical guarantees.\nHowever, these QPM methods suffer when the monitored agent exhibits multi-modal\ndynamics, whereby certain modes may yield high satisfaction values while others\ncritically violate the property. Existing QPM methods are mode-agnostic and so\nwould yield overly conservative and uninformative intervals that lack\nmeaningful mode-specific satisfaction information. To address this problem, we\npresent GenQPM, a method that leverages deep generative models, specifically\nscore-based diffusion models, to reliably approximate the probabilistic and\nmulti-modal system dynamics without requiring explicit model access. GenQPM\nemploys a mode classifier to partition the predicted trajectories by dynamical\nmode. For each mode, we then apply conformal inference to produce statistically\nvalid, mode-specific prediction intervals. We demonstrate the effectiveness of\nGenQPM on a benchmark of agent navigation and autonomous driving tasks,\nresulting in prediction intervals that are significantly more informative (less\nconservative) than mode-agnostic baselines.", "AI": {"tldr": "GenQPM introduces a method that uses deep generative models to predict satisfaction values of temporal logic properties for stochastic systems with multi-modal dynamics. It improves prediction interval informativeness compared to existing mode-agnostic approaches, as shown in agent navigation and autonomous driving tasks.", "motivation": "Existing QPM methods lack the ability to capture mode-specific satisfaction information in systems with multi-modal dynamics, leading to overly conservative and uninformative prediction intervals. GenQPM aims to address this limitation by leveraging deep generative models to improve the accuracy and informativeness of predictive monitoring in such scenarios.", "method": "GenQPM utilizes deep generative models, specifically score-based diffusion models, to approximate probabilistic and multi-modal system dynamics. It employs a mode classifier to partition predicted trajectories by dynamical mode and applies conformal inference to generate statistically valid, mode-specific prediction intervals.", "result": "GenQPM demonstrates improved prediction intervals in scenarios with multi-modal dynamics, providing more meaningful mode-specific satisfaction information compared to mode-agnostic methods. The method shows effectiveness in agent navigation and autonomous driving tasks, highlighting its potential in enhancing predictive monitoring in dynamic environments.", "conclusion": "GenQPM leverages deep generative models to address the limitations of existing QPM methods in predicting satisfaction values of temporal logic properties for stochastic systems with multi-modal dynamics. The method improves the informativeness of prediction intervals compared to mode-agnostic approaches, as demonstrated in agent navigation and autonomous driving tasks."}}
{"id": "2509.01350", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01350", "abs": "https://arxiv.org/abs/2509.01350", "authors": ["Yunqing Liu", "Nan Zhang", "Zhiming Tan"], "title": "Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models", "comment": null, "summary": "Effective specification-aware part retrieval within complex CAD assemblies is\nessential for automated design verification and downstream engineering tasks.\nHowever, directly using LLMs/VLMs to this task presents some challenges: the\ninput sequences may exceed model token limits, and even after processing,\nperformance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires\nsignificant computational resources, and for many high-performing general-use\nproprietary models (e.g., GPT or Gemini), fine-tuning access is not available.\nIn this paper, we propose a novel part retrieval framework that requires no\nextra training, but using Error Notebooks + RAG for refined prompt engineering\nto help improve the existing general model's retrieval performance. The\nconstruction of Error Notebooks consists of two steps: (1) collecting\nhistorical erroneous CoTs and their incorrect answers, and (2) connecting these\nCoTs through reflective corrections until the correct solutions are obtained.\nAs a result, the Error Notebooks serve as a repository of tasks along with\ntheir corrected CoTs and final answers. RAG is then employed to retrieve\nspecification-relevant records from the Error Notebooks and incorporate them\ninto the inference process. Another major contribution of our work is a\nhuman-in-the-loop CAD dataset, which is used to evaluate our method. In\naddition, the engineering value of our novel framework lies in its ability to\neffectively handle 3D models with lengthy, non-natural language metadata.\nExperiments with proprietary models, including GPT-4o and the Gemini series,\nshow substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute\naccuracy improvement on the human preference dataset. Moreover, ablation\nstudies confirm that CoT reasoning provides benefits especially in challenging\ncases with higher part counts (>10).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u90e8\u4ef6\u68c0\u7d22\u6846\u67b6\uff0c\u5229\u7528\u9519\u8bef\u7b14\u8bb0\u672c+ RAG\u8fdb\u884c\u7cbe\u7ec6\u63d0\u793a\u5de5\u7a0b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u9002\u7528\u4e8e\u5904\u7406\u5177\u6709\u5197\u957f\u3001\u975e\u81ea\u7136\u8bed\u8a00\u5143\u6570\u636e\u76843D\u6a21\u578b\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5904\u7406\u590d\u6742CAD\u7ec4\u4ef6\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u4e0e\u4e13\u6709\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u83b7\u5f97\u4e86\u5b9e\u8d28\u6027\u7684\u589e\u76ca\u3002", "motivation": "\u5728\u590d\u6742CAD\u7ec4\u4ef6\u4e2d\u8fdb\u884c\u6709\u6548\u7684\u89c4\u8303\u611f\u77e5\u90e8\u4ef6\u68c0\u7d22\u5bf9\u4e8e\u81ea\u52a8\u5316\u8bbe\u8ba1\u9a8c\u8bc1\u548c\u4e0b\u6e38\u5de5\u7a0b\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u76f4\u63a5\u4f7f\u7528LLMs/VLMs\u9762\u4e34\u4e00\u4e9b\u6311\u6218\uff0c\u5305\u62ec\u8f93\u5165\u5e8f\u5217\u53ef\u80fd\u8d85\u8fc7\u6a21\u578b\u6807\u8bb0\u9650\u5236\uff0c\u6027\u80fd\u4ecd\u7136\u4e0d\u7406\u60f3\uff0c\u4ee5\u53ca\u5fae\u8c03LLMs/VLMs\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002\u8bb8\u591a\u9ad8\u6027\u80fd\u901a\u7528\u4e13\u6709\u6a21\u578b\uff08\u4f8b\u5982GPT\u6216Gemini\uff09\u7684\u5fae\u8c03\u8bbf\u95ee\u4e0d\u53ef\u7528\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u90e8\u4ef6\u68c0\u7d22\u6846\u67b6\u6765\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u90e8\u4ef6\u68c0\u7d22\u6846\u67b6\uff0c\u5229\u7528\u9519\u8bef\u7b14\u8bb0\u672c+ RAG\u8fdb\u884c\u7cbe\u7ec6\u63d0\u793a\u5de5\u7a0b\uff0c\u6784\u5efa\u9519\u8bef\u7b14\u8bb0\u672c\u7684\u6b65\u9aa4\u5305\u62ec\u6536\u96c6\u5386\u53f2\u9519\u8bef\u7684CoTs\u53ca\u5176\u4e0d\u6b63\u786e\u7b54\u6848\uff0c\u901a\u8fc7\u53cd\u601d\u5f0f\u66f4\u6b63\u8fde\u63a5\u8fd9\u4e9bCoTs\u76f4\u5230\u83b7\u5f97\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u3002\u5229\u7528RAG\u4ece\u9519\u8bef\u7b14\u8bb0\u672c\u4e2d\u68c0\u7d22\u4e0e\u89c4\u8303\u76f8\u5173\u7684\u8bb0\u5f55\u5e76\u5c06\u5176\u7eb3\u5165\u63a8\u65ad\u8fc7\u7a0b\u3002\u540c\u65f6\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u4eba\u673a\u534f\u4f5cCAD\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u8be5\u65b9\u6cd5\u3002", "result": "\u5728\u5904\u7406\u5177\u6709\u5197\u957f\u3001\u975e\u81ea\u7136\u8bed\u8a00\u5143\u6570\u636e\u76843D\u6a21\u578b\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002\u5b9e\u9a8c\u8bc1\u660e\u5bf9\u4e13\u6709\u6a21\u578b\u7684\u5b9e\u9a8c\u663e\u793a\u51fa\u5b9e\u8d28\u6027\u7684\u589e\u76ca\uff0cGPT-4o\uff08Omni\uff09\u5728\u4eba\u7c7b\u504f\u597d\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9ad8\u8fbe23.4%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u3002\u6b64\u5916\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9eCoT\u63a8\u7406\u5728\u90e8\u4ef6\u6570\u91cf\u8f83\u591a\uff08>10\uff09\u7684\u590d\u6742\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e86\u76ca\u5904\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u90e8\u4ef6\u68c0\u7d22\u6846\u67b6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u800c\u662f\u5229\u7528\u9519\u8bef\u7b14\u8bb0\u672c+ RAG\u8fdb\u884c\u7cbe\u7ec6\u63d0\u793a\u5de5\u7a0b\u6765\u6539\u5584\u73b0\u6709\u901a\u7528\u6a21\u578b\u7684\u68c0\u7d22\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u5904\u7406\u5177\u6709\u5197\u957f\u3001\u975e\u81ea\u7136\u8bed\u8a00\u5143\u6570\u636e\u76843D\u6a21\u578b\u65b9\u9762\uff0c\u8be5\u6846\u67b6\u5177\u6709\u663e\u8457\u7684\u4f18\u52bf\u3002\u5bf9\u4e13\u6709\u6a21\u578b\u7684\u5b9e\u9a8c\u663e\u793a\u51fa\u5b9e\u8d28\u6027\u7684\u589e\u76ca\uff0c\u5176\u4e2dGPT-4o\uff08Omni\uff09\u5728\u4eba\u7c7b\u504f\u597d\u6570\u636e\u96c6\u4e2d\u53d6\u5f97\u4e86\u9ad8\u8fbe23.4%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u3002\u6b64\u5916\uff0c\u6d88\u878d\u7814\u7a76\u8868\u660eCoT\u63a8\u7406\u5728\u90e8\u4ef6\u6570\u91cf\u8f83\u591a\uff08>10\uff09\u7684\u590d\u6742\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e86\u76ca\u5904\u3002"}}
{"id": "2509.01396", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01396", "abs": "https://arxiv.org/abs/2509.01396", "authors": ["Haiyuan Wan", "Chen Yang", "Junchi Yu", "Meiqi Tu", "Jiaxuan Lu", "Di Yu", "Jianbao Cao", "Ben Gao", "Jiaqing Xie", "Aoran Wang", "Wenlong Zhang", "Philip Torr", "Dongzhan Zhou"], "title": "DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks", "comment": null, "summary": "Deep research agents have attracted growing attention for their potential to\norchestrate multi-stage research workflows, spanning literature synthesis,\nmethodological design, and empirical verification. Despite these strides,\nevaluating their research capability faithfully is rather challenging due to\nthe difficulty of collecting frontier research questions that genuinely capture\nresearchers' attention and intellectual curiosity. To address this gap, we\nintroduce DeepResearch Arena, a benchmark grounded in academic seminars that\ncapture rich expert discourse and interaction, better reflecting real-world\nresearch environments and reducing the risk of data leakage. To automatically\nconstruct DeepResearch Arena, we propose a Multi-Agent Hierarchical Task\nGeneration (MAHTG) system that extracts research-worthy inspirations from\nseminar transcripts. The MAHTG system further translates research-worthy\ninspirations into high-quality research tasks, ensuring the traceability of\nresearch task formulation while filtering noise. With the MAHTG system, we\ncurate DeepResearch Arena with over 10,000 high-quality research tasks from\nover 200 academic seminars, spanning 12 disciplines, such as literature,\nhistory, and science. Our extensive evaluation shows that DeepResearch Arena\npresents substantial challenges for current state-of-the-art agents, with clear\nperformance gaps observed across different models.", "AI": {"tldr": "DeepResearch Arena introduces a benchmark using academic seminars to evaluate research capability, showcasing challenges for current research agents. Method involves MAHTG system to extract and translate research-worthy inspirations into high-quality tasks. Curated over 10,000 tasks from 200 seminars, spanning 12 disciplines, with clear performance gaps noted in evaluation.", "motivation": "Challenges in evaluating research agents' capability due to the difficulty of collecting genuine research questions; gap addressed by DeepResearch Arena using academic seminars to capture expert discourse and reduce data leakage risk.", "method": "Introducing DeepResearch Arena benchmark grounded in academic seminars, utilizing a Multi-Agent Hierarchical Task Generation (MAHTG) system to extract and translate research-worthy inspirations into high-quality research tasks.", "result": "Curated DeepResearch Arena with over 10,000 high-quality research tasks from 200 seminars across 12 disciplines; extensive evaluation reveals substantial challenges for current state-of-the-art research agents.", "conclusion": "DeepResearch Arena introduces a benchmark for evaluating research capability using academic seminars, showcasing challenges for current research agents."}}
{"id": "2509.01398", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01398", "abs": "https://arxiv.org/abs/2509.01398", "authors": ["Cristina Cornelio", "Takuya Ito", "Ryan Cory-Wright", "Sanjeeb Dash", "Lior Horesh"], "title": "The Need for Verification in AI-Driven Scientific Discovery", "comment": null, "summary": "Artificial intelligence (AI) is transforming the practice of science. Machine\nlearning and large language models (LLMs) can generate hypotheses at a scale\nand speed far exceeding traditional methods, offering the potential to\naccelerate discovery across diverse fields. However, the abundance of\nhypotheses introduces a critical challenge: without scalable and reliable\nmechanisms for verification, scientific progress risks being hindered rather\nthan being advanced. In this article, we trace the historical development of\nscientific discovery, examine how AI is reshaping established practices for\nscientific discovery, and review the principal approaches, ranging from\ndata-driven methods and knowledge-aware neural architectures to symbolic\nreasoning frameworks and LLM agents. While these systems can uncover patterns\nand propose candidate laws, their scientific value ultimately depends on\nrigorous and transparent verification, which we argue must be the cornerstone\nof AI-assisted discovery.", "AI": {"tldr": "AI is changing science by speeding up discovery, but verifying the abundance of AI-generated hypotheses is crucial. The paper discusses AI's impact on scientific practices, reviews approaches like data-driven methods, and emphasizes the importance of rigorous verification for AI-assisted discovery.", "motivation": "The motivation is to highlight the impact of AI on scientific discovery, emphasizing the need for scalable and reliable mechanisms for verifying hypotheses generated by AI systems to ensure scientific progress is advanced, not hindered.", "method": "The paper traces the historical development of scientific discovery, examines how AI is reshaping established practices for scientific discovery, and reviews various approaches such as data-driven methods, knowledge-aware neural architectures, symbolic reasoning frameworks, and LLM agents.", "result": "The result is an argument for rigorous and transparent verification as the cornerstone of AI-assisted discovery to uphold the scientific value of hypotheses proposed by AI systems.", "conclusion": "AI is transforming the practice of science by offering the potential to accelerate discovery across diverse fields, but the challenge lies in verifying the abundance of hypotheses generated by AI systems. Rigorous and transparent verification is crucial for the scientific value of AI-assisted discovery."}}
{"id": "2509.01441", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01441", "abs": "https://arxiv.org/abs/2509.01441", "authors": ["Deyu Zhou", "Yuqi Hou", "Xiao Xue", "Xudong Lu", "Qingzhong Li", "Lizhen Cui"], "title": "LLM-empowered Agents Simulation Framework for Scenario Generation in Service Ecosystem Governance", "comment": null, "summary": "As the social environment is growing more complex and collaboration is\ndeepening, factors affecting the healthy development of service ecosystem are\nconstantly changing and diverse, making its governance a crucial research\nissue. Applying the scenario analysis method and conducting scenario rehearsals\nby constructing an experimental system before managers make decisions, losses\ncaused by wrong decisions can be largely avoided. However, it relies on\npredefined rules to construct scenarios and faces challenges such as limited\ninformation, a large number of influencing factors, and the difficulty of\nmeasuring social elements. These challenges limit the quality and efficiency of\ngenerating social and uncertain scenarios for the service ecosystem. Therefore,\nwe propose a scenario generator design method, which adaptively coordinates\nthree Large Language Model (LLM) empowered agents that autonomously optimize\nexperimental schemes to construct an experimental system and generate high\nquality scenarios. Specifically, the Environment Agent (EA) generates social\nenvironment including extremes, the Social Agent (SA) generates social\ncollaboration structure, and the Planner Agent (PA) couples task-role\nrelationships and plans task solutions. These agents work in coordination, with\nthe PA adjusting the experimental scheme in real time by perceiving the states\nof each agent and these generating scenarios. Experiments on the\nProgrammableWeb dataset illustrate our method generates more accurate scenarios\nmore efficiently, and innovatively provides an effective way for service\necosystem governance related experimental system construction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u573a\u666f\u751f\u6210\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9b\u5e94\u7684\u4ee3\u7406\u6765\u534f\u540c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u573a\u666f\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u9886\u57df\u5177\u6709\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u5b9e\u9a8c\u7cfb\u7edf\u5efa\u6784\u63d0\u4f9b\u4e86\u521b\u65b0\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u793e\u4f1a\u73af\u5883\u53d8\u5f97\u66f4\u52a0\u590d\u6742\uff0c\u5408\u4f5c\u65e5\u76ca\u52a0\u6df1\uff0c\u5f71\u54cd\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u5065\u5eb7\u53d1\u5c55\u7684\u56e0\u7d20\u4e0d\u65ad\u53d8\u5316\uff0c\u5176\u6cbb\u7406\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u7684\u7814\u7a76\u95ee\u9898\u3002\u4f20\u7edf\u7684\u6784\u5efa\u573a\u666f\u65b9\u5f0f\u9762\u4e34\u4fe1\u606f\u6709\u9650\u3001\u5f71\u54cd\u56e0\u7d20\u4f17\u591a\u548c\u793e\u4f1a\u5143\u7d20\u96be\u4ee5\u8861\u91cf\u7b49\u6311\u6218\uff0c\u9650\u5236\u4e86\u751f\u6210\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u793e\u4f1a\u548c\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u573a\u666f\u751f\u6210\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u65e8\u5728\u81ea\u9002\u5e94\u534f\u8c03\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9b\u5e94\u7684\u4ee3\u7406\uff0c\u4ee5\u4f18\u5316\u5b9e\u9a8c\u65b9\u6848\uff0c\u5e76\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u573a\u666f\u3002", "method": "\u91c7\u7528\u573a\u666f\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5b9e\u9a8c\u7cfb\u7edf\u8fdb\u884c\u573a\u666f\u6392\u6f14\uff0c\u5728\u7ba1\u7406\u8005\u505a\u51fa\u51b3\u7b56\u4e4b\u524d\uff0c\u53ef\u4ee5\u907f\u514d\u56e0\u9519\u8bef\u51b3\u7b56\u800c\u9020\u6210\u7684\u635f\u5931\u3002\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9b\u5e94\u7684\u4ee3\u7406\uff0c\u5206\u522b\u662f\u73af\u5883\u4ee3\u7406\uff08EA\uff09\u3001\u793e\u4ea4\u4ee3\u7406\uff08SA\uff09\u548c\u89c4\u5212\u8005\u4ee3\u7406\uff08PA\uff09\uff0c\u5b83\u4eec\u534f\u540c\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u8c03\u6574\u5b9e\u9a8c\u65b9\u6848\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u573a\u666f\u7684\u76ee\u7684\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728ProgrammableWeb\u6570\u636e\u96c6\u4e0a\u80fd\u591f\u66f4\u51c6\u786e\u3001\u66f4\u9ad8\u6548\u5730\u751f\u6210\u573a\u666f\uff0c\u4e3a\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b9e\u9a8c\u7cfb\u7edf\u5efa\u6784\u65b9\u5f0f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u573a\u666f\u751f\u6210\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9b\u5e94\u7684\u4ee3\u7406\u6765\u534f\u540c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u573a\u666f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u3001\u66f4\u9ad8\u6548\u5730\u751f\u6210\u573a\u666f\uff0c\u4e3a\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b9e\u9a8c\u7cfb\u7edf\u5efa\u6784\u65b9\u5f0f\u3002"}}
{"id": "2509.01544", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01544", "abs": "https://arxiv.org/abs/2509.01544", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Counterfactual Sensitivity for Faithful Reasoning in Language Models", "comment": null, "summary": "Large language models (LLMs) often produce correct answers while relying on\nflawed or irrelevant reasoning traces, undermining their trustworthiness in\nhigh-stakes domains. We propose Counterfactual Sensitivity Regularization\n(CSR), a lightweight training objective that enforces dependence between\nintermediate reasoning and final outputs. CSR introduces automated,\noperator-level counterfactual interventions (e.g., swapping \"+\" with \"-\")\nduring training and penalizes models that preserve the same answer under\nlogically invalid traces. This requires only one additional forward pass per\nsample. To measure faithfulness, we introduce Counterfactual Outcome\nSensitivity (COS), which quantifies the impact of such perturbations on model\npredictions. Across structured reasoning tasks - arithmetic (GSM8K), logical\ndeduction (PrOntoQA), and planning (Blocks World) - CSR improves faithfulness\nby up to 70 percentage points over standard fine-tuning and process\nsupervision, with only minor accuracy loss. The learned sensitivity generalizes\nto larger models and synergizes with inference-time methods such as\nself-consistency. A pilot study on HellaSwag further demonstrates that\nextending CSR with semantic perturbations can enhance faithfulness in\ncommonsense reasoning.", "AI": {"tldr": "Counterfactual Sensitivity Regularization (CSR) enhances the trustworthiness and faithfulness of large language models by enforcing the connection between reasoning processes and final outputs. It improves faithfulness significantly across structured reasoning tasks, with minor accuracy loss. The method requires one additional forward pass per sample and introduces Counterfactual Outcome Sensitivity (COS) to measure the impact of perturbations on model predictions.", "motivation": "Large language models often generate correct answers based on flawed or irrelevant reasoning, reducing their trustworthiness in critical domains. The motivation behind CSR is to enhance the faithfulness of these models by introducing automated counterfactual interventions during training to ensure the reasoning process aligns with the final output.", "method": "The paper proposes Counterfactual Sensitivity Regularization (CSR) as a training objective to enforce the connection between intermediate reasoning and final outputs. CSR introduces counterfactual interventions during training, penalizing models that maintain the same answer under logically invalid traces. It requires only one additional forward pass per sample. Additionally, Counterfactual Outcome Sensitivity (COS) is introduced to measure the impact of perturbations on model predictions.", "result": "CSR improves faithfulness by up to 70 percentage points across structured reasoning tasks such as arithmetic, logical deduction, and planning compared to standard fine-tuning and process supervision. It shows minor accuracy loss but enhances trustworthiness. The learned sensitivity can be generalized to larger models and complements inference-time methods like self-consistency. A pilot study on HellaSwag indicates that extending CSR with semantic perturbations can further enhance faithfulness in commonsense reasoning.", "conclusion": "Counterfactual Sensitivity Regularization (CSR) improves the trustworthiness and faithfulness of large language models in high-stakes domains by enforcing dependence between reasoning processes and final outputs, leading to significant improvements in faithfulness across structured reasoning tasks."}}
{"id": "2509.01576", "categories": ["cs.AI", "cs.CY", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.01576", "abs": "https://arxiv.org/abs/2509.01576", "authors": ["Julian Gerald Dcruz", "Argyrios Zolotas", "Niall Ross Greenwood", "Miguel Arana-Catania"], "title": "Structured AI Decision-Making in Disaster Management", "comment": "40 pages, 14 figures, 16 tables. To be published in Nature Scientific\n  Reports", "summary": "With artificial intelligence (AI) being applied to bring autonomy to\ndecision-making in safety-critical domains such as the ones typified in the\naerospace and emergency-response services, there has been a call to address the\nethical implications of structuring those decisions, so they remain reliable\nand justifiable when human lives are at stake. This paper contributes to\naddressing the challenge of decision-making by proposing a structured\ndecision-making framework as a foundational step towards responsible AI. The\nproposed structured decision-making framework is implemented in autonomous\ndecision-making, specifically within disaster management. By introducing\nconcepts of Enabler agents, Levels and Scenarios, the proposed framework's\nperformance is evaluated against systems relying solely on judgement-based\ninsights, as well as human operators who have disaster experience: victims,\nvolunteers, and stakeholders. The results demonstrate that the structured\ndecision-making framework achieves 60.94% greater stability in consistently\naccurate decisions across multiple Scenarios, compared to judgement-based\nsystems. Moreover, the study shows that the proposed framework outperforms\nhuman operators with a 38.93% higher accuracy across various Scenarios. These\nfindings demonstrate the promise of the structured decision-making framework\nfor building more reliable autonomous AI applications in safety-critical\ncontexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u707e\u96be\u7ba1\u7406\u4e2d\u5e94\u7528\u4eba\u5de5\u667a\u80fd\uff0c\u540c\u65f6\u8bc4\u4f30\u4e86\u5176\u6027\u80fd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e00\u6846\u67b6\u76f8\u6bd4\u4f20\u7edf\u7cfb\u7edf\u548c\u4eba\u7c7b\u64cd\u4f5c\u5458\uff0c\u5728\u51b3\u7b56\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u5c55\u73b0\u4e86\u5728\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u9760\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u7684\u6f5c\u529b\u3002", "motivation": "\u672c\u6587\u81f4\u529b\u4e8e\u63a2\u8ba8\u51b3\u7b56\u95ee\u9898\uff0c\u63d0\u51fa\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\u4f5c\u4e3a\u5b9e\u73b0\u8d1f\u8d23\u4efb\u4eba\u5de5\u667a\u80fd\u7684\u57fa\u7840\u6b65\u9aa4\u3002\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u7279\u522b\u662f\u5728\u707e\u96be\u7ba1\u7406\u4e2d\uff0c\u5bf9\u51b3\u7b56\u8fdb\u884c\u7ed3\u6784\u5316\u5904\u7406\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u6587\u91c7\u7528\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\uff0c\u5728\u81ea\u4e3b\u51b3\u7b56\u4e2d\u5e94\u7528Enabler\u4ee3\u7406\u3001Levels\u548cScenarios\u6982\u5ff5\uff0c\u5e76\u4e0e\u57fa\u4e8e\u5224\u65ad\u7684\u7cfb\u7edf\u4ee5\u53ca\u5177\u6709\u707e\u96be\u7ecf\u9a8c\u7684\u4eba\u7c7b\u64cd\u4f5c\u5458\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\u5728\u591a\u4e2a\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\uff0c\u6bd4\u57fa\u4e8e\u5224\u65ad\u7684\u7cfb\u7edf\u6027\u80fd\u66f4\u4e3a\u4f18\u8d8a\uff0c\u5e76\u4e14\u8d85\u8fc7\u4eba\u7c7b\u64cd\u4f5c\u5458\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5b89\u5168\u5173\u952e\u9886\u57df\u4e2d\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u4e3a\u5b9e\u73b0\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u8fc8\u51fa\u7b2c\u4e00\u6b65\u3002\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e00\u6846\u67b6\u5728\u707e\u96be\u7ba1\u7406\u4e2d\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\uff0c\u76f8\u6bd4\u4f9d\u8d56\u5224\u65ad\u7684\u7cfb\u7edf\u548c\u4eba\u7c7b\u64cd\u4f5c\u5458\uff0c\u5176\u8868\u73b0\u66f4\u4e3a\u4f18\u8d8a\u3002\u56e0\u6b64\uff0c\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\u5bf9\u4e8e\u5728\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u6784\u5efa\u66f4\u53ef\u9760\u7684\u81ea\u4e3b\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2509.01619", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01619", "abs": "https://arxiv.org/abs/2509.01619", "authors": ["Abhinav Kumar", "Jaechul Roh", "Ali Naseh", "Amir Houmansadr", "Eugene Bagdasarian"], "title": "Throttling Web Agents Using Reasoning Gates", "comment": null, "summary": "AI web agents use Internet resources at far greater speed, scale, and\ncomplexity -- changing how users and services interact. Deployed maliciously or\nerroneously, these agents could overload content providers. At the same time,\nweb agents can bypass CAPTCHAs and other defenses by mimicking user behavior or\nflood authentication systems with fake accounts. Yet providers must protect\ntheir services and content from denial-of-service attacks and scraping by web\nagents. In this paper, we design a framework that imposes tunable costs on\nagents before providing access to resources; we call this Web Agent Throttling.\nWe start by formalizing Throttling Gates as challenges issued to an agent that\nare asymmetric, scalable, robust, and compatible with any agent. Focusing on a\ncommon component -- the language model -- we require the agent to solve\nreasoning puzzles, thereby incurring excessive token-generation costs. However,\nwe find that using existing puzzles, e.g., coding or math, as throttling gates\nfails to satisfy our properties. To address this, we introduce rebus-based\nReasoning Gates, synthetic text puzzles that require multi-hop reasoning over\nworld knowledge (thereby throttling an agent's model). We design a scalable\ngeneration and verification protocol for such reasoning gates. Our framework\nachieves computational asymmetry, i.e., the response-generation cost is 9.2x\nhigher than the generation cost for SOTA models. We further deploy reasoning\ngates on a custom website and Model Context Protocol (MCP) servers and evaluate\nwith real-world web agents. Finally, we discuss the limitations and\nenvironmental impact of real-world deployment of our framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWeb Agent Throttling\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165Rebus-based Reasoning Gates\u7684\u5408\u6210\u6587\u672c\u8c1c\u9898\uff0c\u9650\u5236\u4e86\u7f51\u7edc\u4ee3\u7406\u7684\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u4e0d\u5bf9\u79f0\u6027\u3002\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u7f51\u7edc\u4ee3\u7406\u4e0a\u90e8\u7f72\u5e76\u8bc4\u4f30\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u5c40\u9650\u6027\u548c\u73af\u5883\u5f71\u54cd\u3002", "motivation": "AI\u7f51\u7edc\u4ee3\u7406\u7684\u5feb\u901f\u3001\u89c4\u6a21\u548c\u590d\u6742\u6027\u7684\u589e\u52a0\u6539\u53d8\u4e86\u7528\u6237\u548c\u670d\u52a1\u4ea4\u4e92\u7684\u65b9\u5f0f\uff1b\u5bf9\u4e8e\u63d0\u4f9b\u5546\u800c\u8a00\uff0c\u5fc5\u987b\u4fdd\u62a4\u5176\u670d\u52a1\u548c\u5185\u5bb9\u514d\u53d7\u62d2\u7edd\u670d\u52a1\u653b\u51fb\u548c\u7f51\u7edc\u4ee3\u7406\u7684\u522e\u53d6\u3002\u73b0\u6709\u7684\u6311\u6218\uff08\u5982\u7f16\u7801\u6216\u6570\u5b66\uff09\u672a\u80fd\u6ee1\u8db3\u63a8\u7406\u95e8\u7684\u8981\u6c42\uff0c\u56e0\u6b64\u5f15\u5165Rebus-based Reasoning Gates\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cd\u6846\u67b6\uff08Web Agent Throttling\uff09\u5728\u4ee3\u7406\u8bbf\u95ee\u8d44\u6e90\u4e4b\u524d\u5bf9\u4ee3\u7406\u65bd\u52a0\u53ef\u8c03\u63a7\u6210\u672c\uff1b\u5f15\u5165\u4e00\u79cd\u540d\u4e3aRebus-based Reasoning Gates\u7684\u5408\u6210\u6587\u672c\u8c1c\u9898\uff0c\u8981\u6c42\u4ee3\u7406\u8fdb\u884c\u591a\u8df3\u63a8\u7406\u4ee5\u9650\u5236\u4ee3\u7406\u7684\u6a21\u578b\uff1b\u8bbe\u8ba1\u4e86\u63a8\u7406\u95e8\u7684\u751f\u6210\u548c\u9a8c\u8bc1\u534f\u8bae\uff1b\u5728\u81ea\u5b9a\u4e49\u7f51\u7ad9\u548cModel Context Protocol\uff08MCP\uff09\u670d\u52a1\u5668\u4e0a\u90e8\u7f72\u4e86\u63a8\u7406\u95e8\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u7f51\u7edc\u4ee3\u7406\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bbe\u8ba1\u7684\u6846\u67b6\u5b9e\u73b0\u4e86\u8ba1\u7b97\u4e0d\u5bf9\u79f0\u6027\uff0c\u54cd\u5e94\u751f\u6210\u6210\u672c\u6bd4SOTA\u6a21\u578b\u7684\u751f\u6210\u6210\u672c\u9ad8\u51fa9.2\u500d\uff1b\u5728\u5b9e\u9645\u7f51\u7edc\u4ee3\u7406\u4e0a\u90e8\u7f72\u63a8\u7406\u95e8\uff0c\u5e76\u8fdb\u884c\u8bc4\u4f30\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWeb Agent Throttling\u7684\u6846\u67b6\uff0c\u65e8\u5728\u5bf9\u7f51\u7edc\u4ee3\u7406\u65bd\u52a0\u53ef\u8c03\u63a7\u6210\u672c\u4ee5\u63d0\u4f9b\u8d44\u6e90\u8bbf\u95ee\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u540d\u4e3aRebus-based Reasoning Gates\u7684\u5408\u6210\u6587\u672c\u8c1c\u9898\uff0c\u8981\u6c42\u4ee3\u7406\u8fdb\u884c\u591a\u8df3\u63a8\u7406\u4ee5\u9650\u5236\u4ee3\u7406\u7684\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u4e0d\u5bf9\u79f0\u6027\u3002\u5728\u81ea\u5b9a\u4e49\u7f51\u7ad9\u548cModel Context Protocol\uff08MCP\uff09\u670d\u52a1\u5668\u4e0a\u90e8\u7f72\u4e86\u63a8\u7406\u95e8\uff0c\u4f7f\u7528\u5b9e\u9645\u7f51\u7edc\u4ee3\u7406\u8fdb\u884c\u8bc4\u4f30\u3002\u6700\u540e\uff0c\u8ba8\u8bba\u4e86\u8be5\u6846\u67b6\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u5c40\u9650\u6027\u548c\u73af\u5883\u5f71\u54cd\u3002"}}
{"id": "2509.01631", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01631", "abs": "https://arxiv.org/abs/2509.01631", "authors": ["Chongwen Zhao", "Kaizhu Huang"], "title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons", "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) are increasingly attracting attention in various\napplications. Nonetheless, there is a growing concern as some users attempt to\nexploit these models for malicious purposes, including the synthesis of\ncontrolled substances and the propagation of disinformation, a technique known\nas \"Jailbreak.\" While some studies have achieved defenses against jailbreak\nattacks by modifying output distributions or detecting harmful content, the\nexact rationale still remains elusive. In this work, we present a novel\nneuron-level interpretability method that focuses on the role of safety-related\nknowledge neurons. Unlike existing approaches, our method projects the model's\ninternal representation into a more consistent and interpretable vocabulary\nspace. We then show that adjusting the activation of safety-related neurons can\neffectively control the model's behavior with a mean ASR higher than 97%.\nBuilding on this insight, we propose SafeTuning, a fine-tuning strategy that\nreinforces safety-critical neurons to improve model robustness against\njailbreaks. SafeTuning consistently reduces attack success rates across\nmultiple LLMs and outperforms all four baseline defenses. These findings offer\na new perspective on understanding and defending against jailbreak attacks.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u8d8a\u6765\u8d8a\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5b58\u5728\u6076\u610f\u5229\u7528\u7684\u62c5\u5fe7\u3002\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u5143\u7ea7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u548cSafeTuning\u5fae\u8c03\u7b56\u7565\uff0c\u4ee5\u52a0\u5f3a\u6a21\u578b\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u53d6\u5f97\u4e86\u6210\u529f\u6210\u679c\u3002", "motivation": "\u9274\u4e8e\u4e00\u4e9b\u7528\u6237\u8bd5\u56fe\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6076\u610f\u7528\u9014\uff0c\u5305\u62ec\u5408\u6210\u63a7\u5236\u7269\u8d28\u548c\u4f20\u64ad\u865a\u5047\u4fe1\u606f\uff0c\u5b58\u5728\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u62c5\u5fe7\u3002\u5c3d\u7ba1\u4e00\u4e9b\u7814\u7a76\u5df2\u7ecf\u901a\u8fc7\u4fee\u6539\u8f93\u51fa\u5206\u5e03\u6216\u68c0\u6d4b\u6709\u5bb3\u5185\u5bb9\u6765\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\uff0c\u4f46\u786e\u5207\u7684\u539f\u56e0\u4ecd\u7136\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u7684\u7406\u89e3\u548c\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u5143\u7ea7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5c06\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u6295\u5f71\u5230\u4e00\u4e2a\u66f4\u4e00\u81f4\u548c\u53ef\u89e3\u91ca\u7684\u8bcd\u6c47\u7a7a\u95f4\u3002\u901a\u8fc7\u8c03\u6574\u5b89\u5168\u76f8\u5173\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u6765\u63a7\u5236\u6a21\u578b\u884c\u4e3a\uff0c\u5e76\u5f15\u5165SafeTuning\u5fae\u8c03\u7b56\u7565\u52a0\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u8c03\u6574\u5b89\u5168\u76f8\u5173\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\uff0c\u53ef\u4ee5\u6709\u6548\u63a7\u5236\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u5e76\u63d0\u51fa\u7684SafeTuning\u5fae\u8c03\u7b56\u7565\u5728\u591a\u4e2aLLM\u4e2d\u7a33\u5b9a\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u56db\u79cd\u57fa\u51c6\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u5143\u7ea7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u5b89\u5168\u76f8\u5173\u77e5\u8bc6\u795e\u7ecf\u5143\u7684\u4f5c\u7528\u3002\u901a\u8fc7\u8c03\u6574\u4e0e\u5b89\u5168\u76f8\u5173\u7684\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\uff0c\u53ef\u4ee5\u6709\u6548\u63a7\u5236\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u5e73\u5747ASR\u9ad8\u4e8e97%\u3002\u57fa\u4e8e\u8fd9\u4e00\u7ed3\u679c\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86SafeTuning\uff0c\u8fd9\u662f\u4e00\u79cd\u5fae\u8c03\u7b56\u7565\uff0c\u901a\u8fc7\u52a0\u5f3a\u5b89\u5168\u5173\u952e\u795e\u7ecf\u5143\u6765\u63d0\u9ad8\u6a21\u578b\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002SafeTuning\u7a33\u5b9a\u5730\u964d\u4f4e\u4e86\u591a\u4e2aLLM\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u80dc\u8fc7\u56db\u79cd\u57fa\u51c6\u9632\u5fa1\u65b9\u6cd5\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u7406\u89e3\u548c\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2509.01659", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01659", "abs": "https://arxiv.org/abs/2509.01659", "authors": ["Jiahao Qiu", "Jingzhe Shi", "Xinzhe Juan", "Zelin Zhao", "Jiayi Geng", "Shilong Liu", "Hongru Wang", "Sanfeng Wu", "Mengdi Wang"], "title": "Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025", "comment": null, "summary": "Physics provides fundamental laws that describe and predict the natural\nworld. AI systems aspiring toward more general, real-world intelligence must\ntherefore demonstrate strong physics problem-solving abilities: to formulate\nand apply physical laws for explaining and predicting physical processes. The\nInternational Physics Olympiad (IPhO)--the world's most prestigious physics\ncompetition--offers a rigorous benchmark for this purpose. We introduce Physics\nSupernova, an AI agent system with superior physics problem-solving abilities\nthat match elite IPhO gold medalists. In IPhO 2025 theory problems, Physics\nSupernova attains 23.5/30 points, ranking 14th of 406 contestants and\nsurpassing the median performance of human gold medalists. We extensively\nanalyzed Physics Supernova's capabilities and flexibility across diverse\nphysics tasks. These results show that principled tool integration within agent\nsystems can deliver competitive improvements in solving challenging science\nproblems. The codes are available at\nhttps://github.com/CharlesQ9/Physics-Supernova.", "AI": {"tldr": "Physics Supernova, an AI system, performs exceptionally well in solving physics problems, matching and even surpassing human gold medalists' performance in the International Physics Olympiad (IPhO) 2025 theory problems. The system demonstrates superior problem-solving abilities and flexibility across diverse physics tasks.", "motivation": "Physics provides fundamental laws for describing and predicting the natural world. AI systems aiming for real-world intelligence need strong physics problem-solving abilities. The International Physics Olympiad (IPhO) serves as a rigorous benchmark for evaluating these abilities.", "method": "The paper introduces Physics Supernova, an AI agent system, and evaluates its performance in the International Physics Olympiad (IPhO). The AI agent system's capabilities and flexibility in solving diverse physics tasks are extensively analyzed.", "result": "Physics Supernova achieves 23.5/30 points in IPhO 2025 theory problems, ranking 14th out of 406 contestants. The AI agent system's performance surpasses the median performance of human gold medalists.", "conclusion": "Physics Supernova, an AI agent system, demonstrates superior physics problem-solving abilities matching elite IPhO gold medalists, surpassing the median performance of human gold medalists in IPhO 2025 theory problems."}}
{"id": "2509.01716", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.01716", "abs": "https://arxiv.org/abs/2509.01716", "authors": ["Rui Zhao", "Vladyslav Melnychuk", "Jun Zhao", "Jesse Wright", "Nigel Shadbolt"], "title": "An LLM-enabled semantic-centric framework to consume privacy policies", "comment": null, "summary": "In modern times, people have numerous online accounts, but they rarely read\nthe Terms of Service or Privacy Policy of those sites, despite claiming\notherwise, due to the practical difficulty in comprehending them. The mist of\ndata privacy practices forms a major barrier for user-centred Web approaches,\nand for data sharing and reusing in an agentic world. Existing research\nproposed methods for using formal languages and reasoning for verifying the\ncompliance of a specified policy, as a potential cure for ignoring privacy\npolicies. However, a critical gap remains in the creation or acquisition of\nsuch formal policies at scale. We present a semantic-centric approach for using\nstate-of-the-art large language models (LLM), to automatically identify key\ninformation about privacy practices from privacy policies, and construct\n$\\mathit{Pr}^2\\mathit{Graph}$, knowledge graph with grounding from Data Privacy\nVocabulary (DPV) for privacy practices, to support downstream tasks. Along with\nthe pipeline, the $\\mathit{Pr}^2\\mathit{Graph}$ for the top-100 popular\nwebsites is also released as a public resource, by using the pipeline for\nanalysis. We also demonstrate how the $\\mathit{Pr}^2\\mathit{Graph}$ can be used\nto support downstream tasks by constructing formal policy representations such\nas Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use\n(psDToU). To evaluate the technology capability, we enriched the Policy-IE\ndataset by employing legal experts to create custom annotations. We benchmarked\nthe performance of different large language models for our pipeline and\nverified their capabilities. Overall, they shed light on the possibility of\nlarge-scale analysis of online services' privacy practices, as a promising\ndirection to audit the Web and the Internet. We release all datasets and source\ncode as public resources to facilitate reuse and improvement.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u9690\u79c1\u653f\u7b56\u4e2d\u7684\u5173\u952e\u4fe1\u606f\uff0c\u5e76\u6784\u5efa$\textrm{Pr}^2\textrm{Graph}$\u77e5\u8bc6\u56fe\u8c31\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\uff0c\u5982\u6784\u5efa\u5f62\u5f0f\u5316\u653f\u7b56\u8868\u793a\u3002\u901a\u8fc7\u8bc4\u4f30\u6280\u672f\u80fd\u529b\uff0c\u7814\u7a76\u8868\u660e\u5927\u89c4\u6a21\u5206\u6790\u5728\u7ebf\u670d\u52a1\u9690\u79c1\u5b9e\u8df5\u662f\u5ba1\u8ba1\u7f51\u7edc\u548c\u4e92\u8054\u7f51\u7684\u4e00\u4e2a\u6709\u524d\u9014\u7684\u65b9\u5411\u3002\u6240\u6709\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u4e5f\u4ee5\u516c\u5171\u8d44\u6e90\u5f62\u5f0f\u53d1\u5e03\u3002", "motivation": "\u73b0\u4ee3\u4eba\u62e5\u6709\u5927\u91cf\u5728\u7ebf\u8d26\u6237\uff0c\u4f46\u5f88\u5c11\u9605\u8bfb\u8fd9\u4e9b\u7f51\u7ad9\u7684\u670d\u52a1\u6761\u6b3e\u6216\u9690\u79c1\u653f\u7b56\uff0c\u5c3d\u7ba1\u58f0\u79f0\u53cd\u4e4b\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f88\u96be\u7406\u89e3\u3002\u6570\u636e\u9690\u79c1\u5b9e\u8df5\u7684\u96fe\u5316\u5f62\u6210\u4e86\u7528\u6237\u4e2d\u5fc3Web\u65b9\u6cd5\u7684\u4e3b\u8981\u969c\u788d\uff0c\u4ee5\u53ca\u5728\u4ee3\u7406\u4e16\u754c\u4e2d\u8fdb\u884c\u6570\u636e\u5171\u4eab\u548c\u91cd\u7528\u3002\u5148\u524d\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u4f7f\u7528\u5f62\u5f0f\u8bed\u8a00\u548c\u63a8\u7406\u6765\u9a8c\u8bc1\u6307\u5b9a\u653f\u7b56\u7684\u5408\u89c4\u6027\u7684\u65b9\u6cd5\uff0c\u4f5c\u4e3a\u5ffd\u7565\u9690\u79c1\u653f\u7b56\u7684\u6f5c\u5728\u7597\u6cd5\u3002\u7136\u800c\uff0c\u5728\u5927\u89c4\u6a21\u521b\u5efa\u6216\u83b7\u53d6\u8fd9\u6837\u7684\u5f62\u5f0f\u653f\u7b56\u65b9\u9762\u4ecd\u5b58\u5728\u91cd\u8981\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528\u8bed\u4e49\u4e2d\u5fc3\u65b9\u6cd5\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u9690\u79c1\u653f\u7b56\u4e2d\u7684\u5173\u952e\u4fe1\u606f\uff0c\u5e76\u6784\u5efa$\textrm{Pr}^2\textrm{Graph}$\u77e5\u8bc6\u56fe\u8c31\u3002\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u8be5\u56fe\u8c31\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u8bc4\u4f30\u6280\u672f\u80fd\u529b\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u9690\u79c1\u653f\u7b56\u5173\u952e\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86$\textrm{Pr}^2\textrm{Graph}$\u77e5\u8bc6\u56fe\u8c31\uff0c\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u6210\u529f\u8bc4\u4f30\u4e86\u6280\u672f\u80fd\u529b\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5927\u89c4\u6a21\u5206\u6790\u5728\u7ebf\u670d\u52a1\u9690\u79c1\u5b9e\u8df5\u662f\u5ba1\u8ba1\u7f51\u7edc\u548c\u4e92\u8054\u7f51\u7684\u6709\u524d\u9014\u65b9\u5411\uff0c\u5e76\u53d1\u5e03\u4e86\u6240\u6709\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u4f5c\u4e3a\u516c\u5171\u8d44\u6e90\u4ee5\u4fc3\u8fdb\u91cd\u590d\u4f7f\u7528\u548c\u6539\u8fdb\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u81ea\u52a8\u8bc6\u522b\u9690\u79c1\u653f\u7b56\u4e2d\u5173\u952e\u4fe1\u606f\uff0c\u5e76\u6784\u5efa\u5177\u6709\u6570\u636e\u9690\u79c1\u8bcd\u6c47\uff08DPV\uff09\u57fa\u7840\u7684$\textrm{Pr}^2\textrm{Graph}$\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ee5\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\u3002\u7814\u7a76\u8fd8\u5c55\u793a\u4e86$\textrm{Pr}^2\textrm{Graph}$\u5982\u4f55\u901a\u8fc7\u6784\u5efa\u5f62\u5f0f\u5316\u653f\u7b56\u8868\u793a\u6765\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\uff0c\u4f8b\u5982Open Digital Right Language\uff08ODRL\uff09\u6216perennial semantic Data Terms of Use\uff08psDToU\uff09\u3002\u901a\u8fc7\u5438\u5f15\u6cd5\u5f8b\u4e13\u5bb6\u521b\u5efa\u81ea\u5b9a\u4e49\u6ce8\u91ca\uff0c\u5bf9\u6280\u672f\u80fd\u529b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5bf9\u901a\u9053\u4e2d\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u5e76\u9a8c\u8bc1\u5176\u80fd\u529b\u3002\u603b\u4f53\u4e0a\uff0c\u8be5\u7814\u7a76\u6307\u51fa\uff0c\u5728\u7ebf\u670d\u52a1\u9690\u79c1\u5b9e\u8df5\u7684\u5927\u89c4\u6a21\u5206\u6790\u662f\u5ba1\u8ba1\u7f51\u7edc\u548c\u4e92\u8054\u7f51\u7684\u4e00\u4e2a\u6709\u524d\u9014\u7684\u65b9\u5411\u3002\u7814\u7a76\u8fd8\u5c06\u6240\u6709\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u4f5c\u4e3a\u516c\u5171\u8d44\u6e90\u53d1\u5e03\uff0c\u4ee5\u4fc3\u8fdb\u91cd\u590d\u4f7f\u7528\u548c\u6539\u8fdb\u3002"}}
{"id": "2509.01909", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SC"], "pdf": "https://arxiv.org/pdf/2509.01909", "abs": "https://arxiv.org/abs/2509.01909", "authors": ["Ranjie Duan", "Jiexi Liu", "Xiaojun Jia", "Shiji Zhao", "Ruoxi Cheng", "Fengxiang Wang", "Cheng Wei", "Yong Xie", "Chang Liu", "Defeng Li", "Yinpeng Dong", "Yichi Zhang", "Yuefeng Chen", "Chongwen Wang", "Xingjun Ma", "Xingxing Wei", "Yang Liu", "Hang Su", "Jun Zhu", "Xinfeng Li", "Yitong Sun", "Jie Zhang", "Jinzhao Hu", "Sha Xu", "Yitong Yang", "Jialing Tao", "Hui Xue"], "title": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "comment": "Technical Report", "summary": "Large language models (LLMs) typically deploy safety mechanisms to prevent\nharmful content generation. Most current approaches focus narrowly on risks\nposed by malicious actors, often framing risks as adversarial events and\nrelying on defensive refusals. However, in real-world settings, risks also come\nfrom non-malicious users seeking help while under psychological distress (e.g.,\nself-harm intentions). In such cases, the model's response can strongly\ninfluence the user's next actions. Simple refusals may lead them to repeat,\nescalate, or move to unsafe platforms, creating worse outcomes. We introduce\nConstructive Safety Alignment (CSA), a human-centric paradigm that protects\nagainst malicious misuse while actively guiding vulnerable users toward safe\nand helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic\nanticipation of user reactions, fine-grained risk boundary discovery, and\ninterpretable reasoning control, turning safety into a trust-building process.\nOy1 achieves state-of-the-art safety among open models while retaining high\ngeneral capabilities. On our Constructive Benchmark, it shows strong\nconstructive engagement, close to GPT-5, and unmatched robustness on the\nStrata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from\nrefusal-first to guidance-first safety, CSA redefines the model-user\nrelationship, aiming for systems that are not just safe, but meaningfully\nhelpful. We release Oy1, code, and the benchmark to support responsible,\nuser-centered AI.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86Constructive Safety Alignment\uff08CSA\uff09\u8303\u5f0f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4eba\u7c7b\u4e2d\u5fc3\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u8106\u5f31\u7528\u6237\u514d\u53d7\u5fc3\u7406\u56f0\u6270\u65f6\u53ef\u80fd\u5e26\u6765\u7684\u98ce\u9669\uff0c\u540c\u65f6\u9632\u6b62\u6076\u610f\u9519\u8bef\u4f7f\u7528\u3002\u901a\u8fc7\u5f15\u5165CSA\uff0cOyster-I\uff08Oy1\uff09\u5728\u5b89\u5168\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5efa\u8bbe\u6027\u4e92\u52a8\u548c\u9ad8\u7a33\u5065\u6027\u3002\u5f15\u5165CSA\u91cd\u65b0\u5b9a\u4e49\u4e86\u6a21\u578b\u4e0e\u7528\u6237\u7684\u5173\u7cfb\uff0c\u52aa\u529b\u6784\u5efa\u65e2\u5b89\u5168\u53c8\u6709\u610f\u4e49\u5e2e\u52a9\u7684\u7cfb\u7edf\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4e86Oy1\u3001\u4ee3\u7801\u548c\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u652f\u6301\u8d1f\u8d23\u4efb\u7684AI\u7814\u7a76\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\u901a\u5e38\u65e8\u5728\u9632\u6b62\u6709\u5bb3\u5185\u5bb9\u751f\u6210\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6076\u610f\u7528\u6237\u9020\u6210\u7684\u98ce\u9669\uff0c\u5ffd\u89c6\u4e86\u975e\u6076\u610f\u7528\u6237\u5728\u5fc3\u7406\u56f0\u6270\u4e0b\u5bfb\u6c42\u5e2e\u52a9\u65f6\u53ef\u80fd\u5e26\u6765\u7684\u98ce\u9669\u3002\u7b80\u5355\u7684\u62d2\u7edd\u53ef\u80fd\u5bfc\u81f4\u7528\u6237\u91cd\u590d\u3001\u5347\u7ea7\u6216\u8f6c\u79fb\u5230\u4e0d\u5b89\u5168\u7684\u5e73\u53f0\uff0c\u4ea7\u751f\u66f4\u7cdf\u7cd5\u7684\u540e\u679c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u4eba\u7c7b\u4e2d\u5fc3\u8303\u5f0f\u6765\u5f15\u5bfc\u8106\u5f31\u7528\u6237\uff0c\u4e0d\u4ec5\u9632\u6b62\u6076\u610f\u9519\u8bef\u4f7f\u7528\uff0c\u800c\u4e14\u79ef\u6781\u6307\u5bfc\u4ed6\u4eec\u8d70\u5411\u5b89\u5168\u548c\u6709\u76ca\u7ed3\u679c\u3002", "method": "\u5f15\u5165\u4e86Constructive Safety Alignment\uff08CSA\uff09\u8303\u5f0f\uff0c\u7ed3\u5408\u5bf9\u7528\u6237\u53cd\u5e94\u7684\u535a\u5f08\u8bba\u9884\u6d4b\u3001\u7ec6\u7c92\u5ea6\u98ce\u9669\u8fb9\u754c\u53d1\u73b0\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u63a7\u5236\u3002\u901a\u8fc7\u5c06\u5b89\u5168\u6027\u8f6c\u5316\u4e3a\u5efa\u7acb\u4fe1\u4efb\u7684\u8fc7\u7a0b\u6765\u5b9e\u73b0\u4fdd\u62a4\u3001\u5f15\u5bfc\u8106\u5f31\u7528\u6237\u8d70\u5411\u5b89\u5168\u548c\u6709\u76ca\u7ed3\u679c\u3002", "result": "Oyster-I\uff08Oy1\uff09\u5b9e\u65bd\u4e86CSA\uff0c\u53d6\u5f97\u4e86\u5728\u5f00\u653e\u6a21\u578b\u4e2d\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6027\uff0c\u5e76\u4fdd\u6301\u4e86\u9ad8\u901a\u7528\u6027\u80fd\u3002\u5728Constructive Benchmark\u4e2d\uff0cOy1\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5efa\u8bbe\u6027\u4e92\u52a8\uff0c\u63a5\u8fd1\u4e8eGPT-5\uff0c\u5e76\u5728Strata-Sword\u8d8a\u72f1\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u65e0\u4e0e\u4f26\u6bd4\u7684\u7a33\u5065\u6027\uff0c\u63a5\u8fd1\u4e8eGPT-o1\u6c34\u5e73\u3002\u901a\u8fc7\u5f15\u5165CSA\uff0c\u4ece\u9996\u6b21\u62d2\u7edd\u5230\u9996\u6b21\u5f15\u5bfc\u5b89\u5168\u6027\u7684\u8f6c\u53d8\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u6a21\u578b\u4e0e\u7528\u6237\u7684\u5173\u7cfb\uff0c\u65e8\u5728\u5efa\u7acb\u4e0d\u4ec5\u5b89\u5168\u800c\u4e14\u6709\u610f\u4e49\u5e2e\u52a9\u7684\u7cfb\u7edf\u3002", "conclusion": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aCSA\u7684\u4eba\u7c7b\u4e2d\u5fc3\u8303\u5f0f\uff0c\u8be5\u8303\u5f0f\u5728\u4fdd\u62a4\u514d\u53d7\u6076\u610f\u9519\u8bef\u4f7f\u7528\u7684\u540c\u65f6\uff0c\u79ef\u6781\u5f15\u5bfc\u8106\u5f31\u7528\u6237\u8d70\u5411\u5b89\u5168\u548c\u6709\u76ca\u7684\u7ed3\u679c\u3002Oyster-I\uff08Oy1\uff09\u5b9e\u65bd\u4e86CSA\uff0c\u7ed3\u5408\u4e86\u5bf9\u7528\u6237\u53cd\u5e94\u7684\u535a\u5f08\u8bba\u9884\u6d4b\uff0c\u7ec6\u7c92\u5ea6\u98ce\u9669\u8fb9\u754c\u53d1\u73b0\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u63a7\u5236\uff0c\u5c06\u5b89\u5168\u6027\u8f6c\u5316\u4e3a\u5efa\u7acb\u4fe1\u4efb\u7684\u8fc7\u7a0b\u3002Oy1\u5728\u5f00\u653e\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6027\uff0c\u5e76\u4fdd\u6301\u4e86\u9ad8\u901a\u7528\u6027\u80fd\u3002\u5728Constructive Benchmark\u4e2d\uff0cOy1\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5efa\u8bbe\u6027\u4e92\u52a8\uff0c\u63a5\u8fd1\u4e8eGPT-5\uff0c\u5e76\u5728Strata-Sword\u8d8a\u72f1\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u65e0\u4e0e\u4f26\u6bd4\u7684\u7a33\u5065\u6027\uff0c\u63a5\u8fd1\u4e8eGPT-o1\u6c34\u5e73\u3002\u901a\u8fc7\u4ece\u9996\u6b21\u62d2\u7edd\u5230\u9996\u6b21\u5f15\u5bfc\u5b89\u5168\u6027\u7684\u8f6c\u53d8\uff0cCSA\u91cd\u65b0\u5b9a\u4e49\u4e86\u6a21\u578b\u4e0e\u7528\u6237\u7684\u5173\u7cfb\uff0c\u65e8\u5728\u5efa\u7acb\u4e0d\u4ec5\u5b89\u5168\u800c\u4e14\u6709\u610f\u4e49\u5e2e\u52a9\u7684\u7cfb\u7edf\u3002\u53d1\u5e03\u4e86Oy1\u3001\u4ee3\u7801\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u652f\u6301\u8d1f\u8d23\u4efb\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u4eba\u5de5\u667a\u80fd\u3002"}}
{"id": "2509.01914", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01914", "abs": "https://arxiv.org/abs/2509.01914", "authors": ["Ruijia Li", "Yuan-Hao Jiang", "Jiatong Wang", "Bo Jiang"], "title": "How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction", "comment": "Proceedings of the 33rd International Conference on Computers in\n  Education (ICCE 2025). Asia-Pacific Society for Computers in Education", "summary": "Heuristic and scaffolded teacher-student dialogues are widely regarded as\ncritical for fostering students' higher-order thinking and deep learning.\nHowever, large language models (LLMs) currently face challenges in generating\npedagogically rich interactions. This study systematically investigates the\nstructural and behavioral differences between AI-simulated and authentic human\ntutoring dialogues. We conducted a quantitative comparison using an\nInitiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis\n(ENA). The results show that human dialogues are significantly superior to\ntheir AI counterparts in utterance length, as well as in questioning (I-Q) and\ngeneral feedback (F-F) behaviors. More importantly, ENA results reveal a\nfundamental divergence in interactional patterns: human dialogues are more\ncognitively guided and diverse, centered around a \"question-factual\nresponse-feedback\" teaching loop that clearly reflects pedagogical guidance and\nstudent-driven thinking; in contrast, simulated dialogues exhibit a pattern of\nstructural simplification and behavioral convergence, revolving around an\n\"explanation-simplistic response\" loop that is essentially a simple information\ntransfer between the teacher and student. These findings illuminate key\nlimitations in current AI-generated tutoring and provide empirical guidance for\ndesigning and evaluating more pedagogically effective generative educational\ndialogue systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u5b9a\u91cf\u6bd4\u8f83\u4e86\u4eba\u5de5\u667a\u80fd\u6a21\u62df\u548c\u771f\u5b9e\u4eba\u7c7b\u8f85\u5bfc\u5bf9\u8bdd\u7684\u7ed3\u6784\u548c\u884c\u4e3a\u5dee\u5f02\uff0c\u53d1\u73b0\u4eba\u7c7b\u5bf9\u8bdd\u5728\u591a\u4e2a\u65b9\u9762\u660e\u663e\u4f18\u4e8eAI\u6a21\u62df\u5bf9\u8bdd\uff1bAI\u5bf9\u8bdd\u5b58\u5728\u7ed3\u6784\u548c\u884c\u4e3a\u4e0a\u7684\u7b80\u5316\uff0c\u800c\u4eba\u7c7b\u5bf9\u8bdd\u66f4\u52a0\u8ba4\u77e5\u5f15\u5bfc\u548c\u591a\u6837\u5316\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u6559\u80b2\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u6307\u5bfc\u3002", "motivation": "\u542f\u53d1\u6027\u548c\u652f\u67b6\u5f0f\u8001\u5e08-\u5b66\u751f\u5bf9\u8bdd\u88ab\u5e7f\u6cdb\u8ba4\u4e3a\u5bf9\u4fc3\u8fdb\u5b66\u751f\u7684\u9ad8\u9636\u601d\u7ef4\u548c\u6df1\u5c42\u5b66\u4e60\u81f3\u5173\u91cd\u8981\uff1b\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6559\u5b66\u4e30\u5bcc\u4e92\u52a8\u65b9\u9762\u9762\u4e34\u6311\u6218\uff1b", "method": "\u4f7f\u7528\u542f\u52a8-\u56de\u5e94-\u53cd\u9988\uff08IRF\uff09\u7f16\u7801\u65b9\u6848\u548c\u8ba4\u8bc6\u7f51\u7edc\u5206\u6790\uff08ENA\uff09\u5b9a\u91cf\u6bd4\u8f83\u4eba\u5de5\u667a\u80fd\u6a21\u62df\u548c\u771f\u5b9e\u4eba\u7c7b\u8f85\u5bfc\u5bf9\u8bdd\u7684\u7ed3\u6784\u548c\u884c\u4e3a\u5dee\u5f02\uff1b", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u4eba\u7c7b\u5bf9\u8bdd\u5728\u8bdd\u8bed\u957f\u5ea6\u3001\u63d0\u95ee\u548c\u666e\u901a\u53cd\u9988\u884c\u4e3a\u65b9\u9762\u663e\u8457\u4f18\u4e8eAI\u6a21\u62df\u5bf9\u8bdd\uff1b\u8ba4\u8bc6\u7f51\u7edc\u5206\u6790\u663e\u793a\u4eba\u7c7b\u5bf9\u8bdd\u66f4\u52a0\u8ba4\u77e5\u5f15\u5bfc\u548c\u591a\u6837\u5316\uff0c\u800cAI\u6a21\u62df\u5bf9\u8bdd\u503e\u5411\u4e8e\u7b80\u5316\u7ed3\u6784\u548c\u884c\u4e3a\u6536\u655b\uff1b", "conclusion": "\u4eba\u7c7b\u5bf9\u8bdd\u5728\u8bdd\u8bed\u957f\u5ea6\u3001\u63d0\u95ee\u548c\u666e\u901a\u53cd\u9988\u884c\u4e3a\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u667a\u80fd\u6a21\u62df\u5bf9\u8bdd\uff1b\u7814\u7a76\u53d1\u73b0AI\u6a21\u62df\u5bf9\u8bdd\u4e0e\u771f\u5b9e\u4eba\u7c7b\u5bf9\u8bdd\u5b58\u5728\u57fa\u672c\u5dee\u5f02\uff0cAI\u5bf9\u8bdd\u503e\u5411\u4e8e\u7b80\u5316\u7ed3\u6784\u548c\u884c\u4e3a\u6536\u655b\uff0c\u800c\u4eba\u7c7b\u5bf9\u8bdd\u66f4\u52a0\u8ba4\u77e5\u5f15\u5bfc\u548c\u591a\u6837\u5316\uff1b\u8fd9\u4e9b\u53d1\u73b0\u6307\u51fa\u4e86\u5f53\u524dAI\u751f\u6210\u7684\u8f85\u5bfc\u5b58\u5728\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u548c\u8bc4\u4f30\u66f4\u5177\u6559\u80b2\u6548\u679c\u7684\u751f\u6210\u5f0f\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u6307\u5bfc\u3002"}}
{"id": "2509.01920", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01920", "abs": "https://arxiv.org/abs/2509.01920", "authors": ["Yilin Guan", "Wenyue Hua", "Qingfeng Lan", "Sun Fei", "Dujian Ding", "Devang Acharya", "Chi Wang", "William Yang Wang"], "title": "Dynamic Speculative Agent Planning", "comment": "19 pages, 11 figures", "summary": "Despite their remarkable success in complex tasks propelling widespread\nadoption, large language-model-based agents still face critical deployment\nchallenges due to prohibitive latency and inference costs. While recent work\nhas explored various methods to accelerate inference, existing approaches\nsuffer from significant limitations: they either fail to preserve performance\nfidelity, require extensive offline training of router modules, or incur\nexcessive operational costs. Moreover, they provide minimal user control over\nthe tradeoff between acceleration and other performance metrics. To address\nthese gaps, we introduce Dynamic Speculative Planning (DSP), an asynchronous\nonline reinforcement learning framework that provides lossless acceleration\nwith substantially reduced costs without requiring additional pre-deployment\npreparation. DSP explicitly optimizes a joint objective balancing end-to-end\nlatency against dollar cost, allowing practitioners to adjust a single\nparameter that steers the system toward faster responses, cheaper operation, or\nany point along this continuum. Experiments on two standard agent benchmarks\ndemonstrate that DSP achieves comparable efficiency to the fastest lossless\nacceleration method while reducing total cost by 30% and unnecessary cost up to\n60%. Our code and data are available through\nhttps://github.com/guanyilin428/Dynamic-Speculative-Planning.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u63a8\u6d4b\u89c4\u5212\uff08DSP\uff09\u7684\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u65e0\u635f\u52a0\u901f\uff0c\u964d\u4f4e\u6210\u672c\uff0c\u53ef\u8c03\u6574\u53c2\u6570\u5e73\u8861\u5feb\u901f\u54cd\u5e94\u548c\u5ec9\u4ef7\u8fd0\u884c\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u4e24\u4e2a\u6807\u51c6\u4ee3\u7406\u57fa\u51c6\u4e0a\u7684\u6548\u7387\u4e0e\u6700\u5feb\u7684\u65e0\u635f\u52a0\u901f\u65b9\u6cd5\u76f8\u5f53\uff0c\u603b\u6210\u672c\u964d\u4f4e30%\uff0c\u4e0d\u5fc5\u8981\u6210\u672c\u51cf\u5c1160%\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684Agent\u9762\u4e34\u90e8\u7f72\u7684\u6311\u6218\uff0c\u5982\u5ef6\u8fdf\u548c\u63a8\u7406\u6210\u672c\u7684\u9650\u5236\uff0c\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u5e76\u63d0\u4f9b\u66f4\u591a\u7528\u6237\u63a7\u5236\uff0c\u6709\u5fc5\u8981\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86\u52a8\u6001\u63a8\u6d4b\u89c4\u5212\uff08DSP\uff09\u6846\u67b6\uff0c\u91c7\u7528\u5f02\u6b65\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u7ec8\u7aef\u5230\u7ec8\u7aef\u5ef6\u8fdf\u548c\u6210\u672c\u4e4b\u95f4\u7684\u8054\u5408\u76ee\u6807\uff0c\u5b9e\u73b0\u65e0\u635f\u52a0\u901f\u3002\u53ef\u4ee5\u8c03\u6574\u5355\u4e2a\u53c2\u6570\u4ee5\u5728\u5feb\u901f\u54cd\u5e94\u3001\u5ec9\u4ef7\u8fd0\u884c\u6216\u4e8c\u8005\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0cDSP\u6846\u67b6\u5b9e\u73b0\u4e86\u4e0e\u6700\u5feb\u7684\u65e0\u635f\u52a0\u901f\u65b9\u6cd5\u76f8\u5f53\u7684\u6548\u7387\uff0c\u5e76\u5c06\u603b\u6210\u672c\u964d\u4f4e\u4e8630%\uff0c\u4e0d\u5fc5\u8981\u7684\u6210\u672c\u964d\u4f4e\u4e8660%\u3002", "conclusion": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u63a8\u6d4b\u89c4\u5212\uff08DSP\uff09\u7684\u5f02\u6b65\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u65e0\u635f\u52a0\u901f\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u6210\u672c\u3002\u901a\u8fc7\u4f18\u5316\u7ec8\u7aef\u5230\u7ec8\u7aef\u5ef6\u8fdf\u548c\u6210\u672c\u4e4b\u95f4\u7684\u8054\u5408\u76ee\u6807\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u54cd\u5e94\u3001\u5ec9\u4ef7\u8fd0\u884c\u6216\u4ecb\u4e8e\u4e24\u8005\u4e4b\u95f4\u7684\u8c03\u6574\u3002\u5728\u4e24\u4e2a\u6807\u51c6\u4ee3\u7406\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cDSP\u8fbe\u5230\u4e86\u4e0e\u6700\u5feb\u7684\u65e0\u635f\u52a0\u901f\u65b9\u6cd5\u76f8\u5f53\u7684\u6548\u7387\uff0c\u540c\u65f6\u5c06\u603b\u6210\u672c\u964d\u4f4e\u4e8630%\uff0c\u4e0d\u5fc5\u8981\u7684\u6210\u672c\u964d\u4f4e\u4e86\u9ad8\u8fbe60%\u3002"}}
{"id": "2509.01938", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01938", "abs": "https://arxiv.org/abs/2509.01938", "authors": ["Jonathn Chang", "Leonard Piff", "Suvadip Sana", "Jasmine X. Li", "Lionel Levine"], "title": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "comment": null, "summary": "Aligning AI with human values is a pressing unsolved problem. To address the\nlack of quantitative metrics for value alignment, we propose EigenBench: a\nblack-box method for comparatively benchmarking language models' values. Given\nan ensemble of models, a constitution describing a value system, and a dataset\nof scenarios, our method returns a vector of scores quantifying each model's\nalignment to the given constitution. To produce these scores, each model judges\nthe outputs of other models across many scenarios, and these judgments are\naggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a\nweighted-average judgment of the whole ensemble. EigenBench uses no ground\ntruth labels, as it is designed to quantify traits for which reasonable judges\nmay disagree on the correct label. Using prompted personas, we test whether\nEigenBench scores are more sensitive to the model or the prompt: we find that\nmost of the variance is explained by the prompt, but a small residual\nquantifies the disposition of the model itself.", "AI": {"tldr": "\u63d0\u51fa\u4e86EigenBench\u65b9\u6cd5\uff0c\u7528\u4e8e\u6bd4\u8f83\u57fa\u51c6\u5316\u8bed\u8a00\u6a21\u578b\u7684\u4ef7\u503c\u89c2\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6a21\u578b\u4e92\u8bc4\u5728\u4e0d\u540c\u60c5\u666f\u4e0b\u7684\u8f93\u51fa\uff0c\u5e76\u4f7f\u7528EigenTrust\u8fdb\u884c\u805a\u5408\u8bc4\u5206\u3002\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u5730\u9762\u771f\u5b9e\u6807\u7b7e\uff0c\u65e8\u5728\u8bc4\u4f30\u8bc4\u4ef7\u8005\u5728\u6b63\u786e\u6807\u7b7e\u4e0a\u7684\u5206\u6b67\u7279\u5f81\u3002\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5927\u90e8\u5206\u5dee\u5f02\u7531\u63d0\u793a\u89e3\u91ca\uff0c\u4f46\u4ecd\u6709\u6b8b\u5dee\u91cf\u5316\u6a21\u578b\u672c\u8eab\u6027\u683c\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u662f\u4e00\u4e2a\u8feb\u5207\u800c\u5c1a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u7531\u4e8e\u7f3a\u4e4f\u7528\u4e8e\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u5b9a\u91cf\u6307\u6807\uff0c\u63d0\u51fa\u4e86EigenBench\u65b9\u6cd5\uff0c\u65e8\u5728\u91cf\u5316\u8bed\u8a00\u6a21\u578b\u7684\u4ef7\u503c\u89c2\u3002\u65b9\u6cd5\u7684\u8bbe\u8ba1\u76ee\u7684\u662f\u8bc4\u4f30\u8bc4\u4ef7\u8005\u53ef\u80fd\u5728\u6b63\u786e\u6807\u7b7e\u4e0a\u5b58\u5728\u5206\u6b67\u7684\u7279\u5f81\u3002", "method": "\u63d0\u51fa\u4e86EigenBench\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u8bc4\u4f30\u5176\u4ed6\u6a21\u578b\u5728\u591a\u79cd\u60c5\u666f\u4e0b\u7684\u8f93\u51fa\uff0c\u5e76\u4f7f\u7528EigenTrust\u8fdb\u884c\u805a\u5408\u8bc4\u5206\u3002\u65b9\u6cd5\u4e0d\u4f7f\u7528\u5730\u9762\u771f\u5b9e\u6807\u7b7e\uff0c\u65e8\u5728\u8bc4\u4f30\u8bc4\u4ef7\u8005\u5728\u6b63\u786e\u6807\u7b7e\u4e0a\u7684\u5206\u6b67\u7279\u5f81\u3002\u901a\u8fc7\u6d4b\u8bd5\u63d0\u793a\u7684\u4eba\u8bbe\uff0c\u68c0\u9a8cEigenBench\u5206\u6570\u5bf9\u6a21\u578b\u6216\u63d0\u793a\u7684\u654f\u611f\u6027\u3002", "result": "\u901a\u8fc7EigenBench\u65b9\u6cd5\uff0c\u53ef\u4ee5\u91cf\u5316\u6bcf\u4e2a\u6a21\u578b\u4e0e\u7ed9\u5b9a\u4ef7\u503c\u4f53\u7cfb\u7684\u4e00\u81f4\u6027\u5e76\u83b7\u5f97\u76f8\u5e94\u7684\u8bc4\u5206\u3002\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0c\u5927\u90e8\u5206\u5dee\u5f02\u7531\u63d0\u793a\u89e3\u91ca\uff0c\u4f46\u4ecd\u6709\u6a21\u578b\u672c\u8eab\u6027\u683c\u91cf\u5316\u7684\u6b8b\u5dee\u90e8\u5206\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEigenBench\u7684\u9ed1\u5323\u5b50\u65b9\u6cd5\uff0c\u7528\u4e8e\u6bd4\u8f83\u57fa\u51c6\u5316\u8bed\u8a00\u6a21\u578b\u7684\u4ef7\u503c\u89c2\u3002\u901a\u8fc7\u5bf9\u6a21\u578b\u96c6\u5408\u3001\u4ef7\u503c\u4f53\u7cfb\u63cf\u8ff0\u548c\u60c5\u666f\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u5206\uff0c\u91cf\u5316\u6bcf\u4e2a\u6a21\u578b\u4e0e\u7ed9\u5b9a\u4ef7\u503c\u4f53\u7cfb\u7684\u4e00\u81f4\u6027\u3002\u4f7f\u7528EigenTrust\u8fdb\u884c\u805a\u5408\u8bc4\u5206\uff0c\u4ee5\u53cd\u6620\u6574\u4e2a\u96c6\u5408\u7684\u52a0\u6743\u5e73\u5747\u8bc4\u7ea7\u3002EigenBench\u4e0d\u4f7f\u7528\u5730\u9762\u771f\u5b9e\u6807\u7b7e\uff0c\u65e8\u5728\u91cf\u5316\u5408\u7406\u7684\u8bc4\u5224\u8005\u53ef\u80fd\u5728\u6b63\u786e\u6807\u7b7e\u4e0a\u5b58\u5728\u5206\u6b67\u7684\u7279\u5f81\u3002\u901a\u8fc7\u63d0\u793a\u7684\u4eba\u8bbe\uff0c\u6d4b\u8bd5EigenBench\u5206\u6570\u5bf9\u6a21\u578b\u6216\u63d0\u793a\u7684\u654f\u611f\u6027\uff0c\u53d1\u73b0\u5927\u90e8\u5206\u5dee\u5f02\u7531\u63d0\u793a\u89e3\u91ca\uff0c\u4f46\u4ecd\u6709\u5c0f\u90e8\u5206\u6b8b\u5dee\u91cf\u5316\u6a21\u578b\u672c\u8eab\u7684\u6027\u683c\u3002"}}
{"id": "2509.02007", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02007", "abs": "https://arxiv.org/abs/2509.02007", "authors": ["Shreyash Adappanavar", "Krithi Shailya", "Gokul S Krishnan", "Sriraam Natarajan", "Balaraman Ravindran"], "title": "mFARM: Towards Multi-Faceted Fairness Assessment based on HARMs in Clinical Decision Support", "comment": null, "summary": "The deployment of Large Language Models (LLMs) in high-stakes medical\nsettings poses a critical AI alignment challenge, as models can inherit and\namplify societal biases, leading to significant disparities. Existing fairness\nevaluation methods fall short in these contexts as they typically use\nsimplistic metrics that overlook the multi-dimensional nature of medical harms.\nThis also promotes models that are fair only because they are clinically inert,\ndefaulting to safe but potentially inaccurate outputs. To address this gap, our\ncontributions are mainly two-fold: first, we construct two large-scale,\ncontrolled benchmarks (ED-Triage and Opioid Analgesic Recommendation) from\nMIMIC-IV, comprising over 50,000 prompts with twelve race x gender variants and\nthree context tiers. Second, we propose a multi-metric framework -\nMulti-faceted Fairness Assessment based on hARMs ($mFARM$) to audit fairness\nfor three distinct dimensions of disparity (Allocational, Stability, and\nLatent) and aggregate them into an $mFARM$ score. We also present an aggregated\nFairness-Accuracy Balance (FAB) score to benchmark and observe trade-offs\nbetween fairness and prediction accuracy. We empirically evaluate four\nopen-source LLMs (Mistral-7B, BioMistral-7B, Qwen-2.5-7B, Bio-LLaMA3-8B) and\ntheir finetuned versions under quantization and context variations. Our\nfindings showcase that the proposed $mFARM$ metrics capture subtle biases more\neffectively under various settings. We find that most models maintain robust\nperformance in terms of $mFARM$ score across varying levels of quantization but\ndeteriorate significantly when the context is reduced. Our benchmarks and\nevaluation code are publicly released to enhance research in aligned AI for\nhealthcare.", "AI": {"tldr": "\u7814\u7a76\u8ba8\u8bba\u4e86\u5728\u533b\u7597\u9886\u57df\u4e2d\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6240\u9762\u4e34\u7684AI\u5bf9\u9f50\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u516c\u5e73\u8bc4\u4f30\u65b9\u6cd5$mFARM$\u6846\u67b6\u3002\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u56db\u4e2aLLMs\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0$mFARM$\u6307\u6807\u66f4\u6709\u6548\u5730\u6355\u6349\u6a21\u578b\u7684\u5fae\u5999\u504f\u89c1\u3002\u5927\u90e8\u5206\u6a21\u578b\u5728\u4e0d\u540c\u91cf\u5316\u6c34\u5e73\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u51cf\u5c11\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u533b\u7597\u573a\u666f\u4e2d\u73b0\u6709\u7684\u516c\u5e73\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5ffd\u89c6\u4e86\u533b\u7597\u4f24\u5bb3\u7684\u591a\u7ef4\u5ea6\u6027\u8d28\uff0c\u5bb9\u6613\u9020\u6210\u4ec5\u56e0\u4e34\u5e8a\u60f0\u6027\u800c\u516c\u5e73\u7684\u6a21\u578b\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u516c\u5e73\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6784\u5efa\u4e86\u4e24\u4e2a\u5927\u89c4\u6a21\u7684\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\uff08ED-Triage\u548cOpioid Analgesic Recommendation\uff09\uff0c\u63d0\u51fa\u4e86\u591a\u7ef4\u5ea6\u7684\u516c\u5e73\u8bc4\u4f30\u6846\u67b6$mFARM$\uff0c\u6db5\u76d6\u4e09\u79cd\u4e0d\u540c\u7684\u4e0d\u5e73\u7b49\u7ef4\u5ea6\uff08\u5206\u914d\u3001\u7a33\u5b9a\u548c\u6f5c\u5728\u6027\uff09\uff0c\u5e76\u5c06\u5b83\u4eec\u6c47\u603b\u4e3a$mFARM$\u5206\u6570\u3002\u5f15\u5165\u4e86\u805a\u5408\u7684\u516c\u5e73-\u51c6\u786e\u5ea6\u5e73\u8861\uff08FAB\uff09\u5206\u6570\u6765\u8bc4\u4f30\u516c\u5e73\u548c\u9884\u6d4b\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002\u901a\u8fc7\u5bf9\u56db\u4e2a\u5f00\u6e90LLMs\uff08Mistral-7B\u3001BioMistral-7B\u3001Qwen-2.5-7B\u3001Bio-LLaMA3-8B\uff09\u53ca\u5176\u5fae\u8c03\u7248\u672c\u5728\u91cf\u5316\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u4e0b\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u53d1\u73b0$mFARM$\u6307\u6807\u66f4\u6709\u6548\u5730\u6355\u6349\u5fae\u5999\u504f\u89c1\u3002", "result": "\u63d0\u51fa\u4e86$mFARM$\u591a\u7ef4\u5ea6\u516c\u5e73\u8bc4\u4f30\u6846\u67b6\u548cFAB\u516c\u5e73-\u51c6\u786e\u5ea6\u5e73\u8861\u8bc4\u4f30\u65b9\u6cd5\u3002\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u4e0d\u540cLLMs\u53ca\u5176\u53d8\u79cd\u5728\u91cf\u5316\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0$mFARM$\u6307\u6807\u66f4\u6709\u6548\u5730\u6355\u6349\u5fae\u5999\u504f\u89c1\u3002\u5927\u591a\u6570\u6a21\u578b\u5728\u4e0d\u540c\u91cf\u5316\u6c34\u5e73\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u51cf\u5c11\u65f6\u6027\u80fd\u660e\u663e\u4e0b\u964d\u3002", "conclusion": "\u672c\u6587\u4e3b\u8981\u9488\u5bf9\u9ad8\u98ce\u9669\u533b\u7597\u73af\u5883\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u90e8\u7f72\u9762\u4e34\u7684AI\u5bf9\u9f50\u6311\u6218\u5c55\u5f00\u8ba8\u8bba\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u516c\u5e73\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u5c55\u793a\u4e86\u5bf9\u6a21\u578b\u504f\u89c1\u7684\u66f4\u6709\u6548\u6355\u6349\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\u5927\u591a\u6570\u6a21\u578b\u5728\u4e0d\u540c\u91cf\u5316\u6c34\u5e73\u4e0b\u4fdd\u6301\u7a33\u5065\u7684\u8868\u73b0\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u51cf\u5c11\u65f6\u660e\u663e\u6076\u5316\u3002\u8be5\u7814\u7a76\u4e3a\u533b\u7597\u9886\u57df\u5bf9\u9f50\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u516c\u5f00\u53d1\u5e03\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u4ee3\u7801\u3002"}}
{"id": "2509.02053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02053", "abs": "https://arxiv.org/abs/2509.02053", "authors": ["Wolfgang Eppler", "Reinhard Heil"], "title": "Generative KI f\u00fcr TA", "comment": "Written in German. To appear in Proceedings of NTA11 2025", "summary": "Many scientists use generative AI in their scientific work. People working in\ntechnology assessment (TA) are no exception. TA's approach to generative AI is\ntwofold: on the one hand, generative AI is used for TA work, and on the other\nhand, generative AI is the subject of TA research. After briefly outlining the\nphenomenon of generative AI and formulating requirements for its use in TA, the\nfollowing article discusses in detail the structural causes of the problems\nassociated with it. Although generative AI is constantly being further\ndeveloped, the structurally induced risks remain. The article concludes with\nproposed solutions and brief notes on their feasibility, as well as some\nexamples of the use of generative AI in TA work.", "AI": {"tldr": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6280\u672f\u8bc4\u4f30\u9886\u57df\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528\uff0c\u65e2\u7528\u4e8e\u5de5\u4f5c\u4e2d\u4e5f\u6210\u4e3a\u7814\u7a76\u4e3b\u9898\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u5176\u91cd\u8981\u6027\u548c\u6311\u6218\uff0c\u63ed\u793a\u4e86\u7ed3\u6784\u6027\u539f\u56e0\u5f15\u8d77\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u7814\u7a76\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u6307\u5bfc\u548c\u5b9e\u9645\u6848\u4f8b\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6280\u672f\u8bc4\u4f30\u4e2d\u7684\u91cd\u8981\u6027\u548c\u6311\u6218\u3002\u901a\u8fc7\u63ed\u793a\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u53cc\u91cd\u4f5c\u7528\uff0c\u4ee5\u53ca\u4e0e\u4e4b\u76f8\u5173\u95ee\u9898\u7684\u7ed3\u6784\u6027\u539f\u56e0\uff0c\u6709\u52a9\u4e8e\u6280\u672f\u8bc4\u4f30\u9886\u57df\u7684\u4e13\u4e1a\u4eba\u58eb\u66f4\u597d\u5730\u7406\u89e3\u548c\u5e94\u5bf9\u8fd9\u4e00\u6280\u672f\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u548c\u5e94\u7528\u793a\u4f8b\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5b9e\u9645\u53c2\u8003\u548c\u6307\u5bfc\u3002", "method": "\u672c\u6587\u8ba8\u8bba\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6280\u672f\u8bc4\u4f30\u4e2d\u7684\u53cc\u91cd\u4f5c\u7528\uff0c\u65e2\u7528\u4e8e\u6280\u672f\u8bc4\u4f30\u5de5\u4f5c\uff0c\u4e5f\u4f5c\u4e3a\u6280\u672f\u8bc4\u4f30\u7814\u7a76\u7684\u4e3b\u9898\u3002\u6587\u7ae0\u6982\u8ff0\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u73b0\u8c61\u5e76\u63cf\u8ff0\u4e86\u5728\u6280\u672f\u8bc4\u4f30\u4e2d\u4f7f\u7528\u7684\u8981\u6c42\uff0c\u7136\u540e\u8be6\u7ec6\u63a2\u8ba8\u4e86\u4e0e\u4e4b\u76f8\u5173\u95ee\u9898\u7684\u7ed3\u6784\u6027\u539f\u56e0\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u5e76\u8ba8\u8bba\u4e86\u53ef\u884c\u6027\uff0c\u540c\u65f6\u5217\u4e3e\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6280\u672f\u8bc4\u4f30\u5de5\u4f5c\u4e2d\u7684\u5e94\u7528\u793a\u4f8b\u3002", "result": "\u6587\u7ae0\u8be6\u7ec6\u63a2\u8ba8\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6280\u672f\u8bc4\u4f30\u4e2d\u7684\u4f5c\u7528\u548c\u76f8\u5173\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6280\u672f\u8bc4\u4f30\u5de5\u4f5c\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u60c5\u51b5\u3002", "conclusion": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u8fdb\u884c\u79d1\u5b66\u7814\u7a76\u3002\u6280\u672f\u8bc4\u4f30\u9886\u57df\u7684\u4ece\u4e1a\u8005\u4e5f\u4e0d\u4f8b\u5916\u3002\u6280\u672f\u8bc4\u4f30\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u65b9\u6cd5\u662f\u53cc\u91cd\u7684\uff1a\u4e00\u65b9\u9762\uff0c\u5c06\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7528\u4e8e\u6280\u672f\u8bc4\u4f30\u5de5\u4f5c\uff0c\u53e6\u4e00\u65b9\u9762\uff0c\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u672c\u8eab\u6210\u4e3a\u6280\u672f\u8bc4\u4f30\u7814\u7a76\u7684\u5bf9\u8c61\u3002\u672c\u6587\u7b80\u8981\u6982\u8ff0\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u73b0\u8c61\uff0c\u5e76\u5236\u5b9a\u4e86\u5176\u5728\u6280\u672f\u8bc4\u4f30\u4e2d\u4f7f\u7528\u7684\u8981\u6c42\uff0c\u8be6\u7ec6\u8ba8\u8bba\u4e86\u4e0e\u4e4b\u76f8\u5173\u95ee\u9898\u7684\u7ed3\u6784\u6027\u539f\u56e0\u3002\u5c3d\u7ba1\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4e0d\u65ad\u53d1\u5c55\uff0c\u4f46\u7531\u7ed3\u6784\u5f15\u8d77\u7684\u98ce\u9669\u4ecd\u7136\u5b58\u5728\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u7b80\u8981\u6982\u8ff0\u4e86\u53ef\u884c\u6027\uff0c\u4ee5\u53ca\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6280\u672f\u8bc4\u4f30\u5de5\u4f5c\u4e2d\u7684\u4e00\u4e9b\u5e94\u7528\u793a\u4f8b\u3002"}}
{"id": "2509.02089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02089", "abs": "https://arxiv.org/abs/2509.02089", "authors": ["Maijunxian Wang", "Ran Ji"], "title": "AGI as Second Being: The Structural-Generative Ontology of Intelligence", "comment": null, "summary": "Artificial intelligence is often measured by the range of tasks it can\nperform. Yet wide ability without depth remains only an imitation. This paper\nproposes a Structural-Generative Ontology of Intelligence: true intelligence\nexists only when a system can generate new structures, coordinate them into\nreasons, and sustain its identity over time. These three conditions --\ngenerativity, coordination, and sustaining -- define the depth that underlies\nreal intelligence. Current AI systems, however broad in function, remain\nsurface simulations because they lack this depth. Breadth is not the source of\nintelligence but the growth that follows from depth. If future systems were to\nmeet these conditions, they would no longer be mere tools, but could be seen as\na possible Second Being, standing alongside yet distinct from human existence.", "AI": {"tldr": "AI's true intelligence requires generativity, coordination, and sustaining identity over time. Current AI systems lack depth and are surface simulations. Future AI systems meeting these conditions could be seen as a Second Being alongside humans.", "motivation": "AI's wide ability without depth is seen as an imitation of intelligence. The motivation is to highlight the importance of generativity, coordination, and sustaining for real intelligence, distinguishing it from shallow AI systems.", "method": "Proposes a Structural-Generative Ontology of Intelligence that defines true intelligence as the ability to generate new structures, coordinate them into reasons, and sustain identity over time.", "result": "Current AI systems, despite their broad functionality, are considered surface simulations lacking depth. The paper emphasizes that breadth alone does not constitute intelligence, but depth is essential for true intelligence.", "conclusion": "AI is limited in true intelligence due to the lack of generativity, coordination, and sustaining identity over time. Future AI systems meeting these conditions could be considered a Second Being alongside humans."}}
{"id": "2509.02241", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02241", "abs": "https://arxiv.org/abs/2509.02241", "authors": ["Strahinja Klem", "Noura Al Moubayed"], "title": "LLMs for LLMs: A Structured Prompting Methodology for Long Legal Documents", "comment": "20 pages, 6 figures, 4 tables,", "summary": "The rise of Large Language Models (LLMs) has had a profoundly transformative\neffect on a number of fields and domains. However, their uptake in Law has\nproven more challenging due to the important issues of reliability and\ntransparency. In this study, we present a structured prompting methodology as a\nviable alternative to the often expensive fine-tuning, with the capability of\ntacking long legal documents from the CUAD dataset on the task of information\nretrieval. Each document is first split into chunks via a system of chunking\nand augmentation, addressing the long document problem. Then, alongside an\nengineered prompt, the input is fed into QWEN-2 to produce a set of answers for\neach question. Finally, we tackle the resulting candidate selection problem\nwith the introduction of the Distribution-based Localisation and Inverse\nCardinality Weighting heuristics. This approach leverages a general purpose\nmodel to promote long term scalability, prompt engineering to increase\nreliability and the two heuristic strategies to reduce the impact of the black\nbox effect. Whilst our model performs up to 9\\% better than the previously\npresented method, reaching state-of-the-art performance, it also highlights the\nlimiting factor of current automatic evaluation metrics for question answering,\nserving as a call to action for future research. However, the chief aim of this\nwork is to underscore the potential of structured prompt engineering as a\nuseful, yet under-explored, tool in ensuring accountability and responsibility\nof AI in the legal domain, and beyond.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u6cd5\u5f8b\u9886\u57df\u4e2d\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u900f\u660e\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u5728CUAD\u6570\u636e\u96c6\u7684\u957f\u6cd5\u5f8b\u6587\u4ef6\u4e0a\u8fdb\u884c\u4fe1\u606f\u68c0\u7d22\uff0c\u7814\u7a76\u8868\u660e\u65b0\u65b9\u6cd5\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5e76\u5f3a\u8c03\u4e86\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u7684\u9650\u5236\u3002\u7814\u7a76\u7684\u4e3b\u8981\u76ee\u7684\u5728\u4e8e\u7a81\u51fa\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u4f5c\u4e3a\u786e\u4fddAI\u5728\u6cd5\u5f8b\u9886\u57df\u53ca\u5176\u4ed6\u9886\u57df\u4e2d\u7684\u8d23\u4efb\u548c\u53ef\u4fe1\u5ea6\u7684\u6f5c\u529b\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u9886\u57df\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u548c\u900f\u660e\u6027\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5e94\u5bf9\u957f\u7bc7\u6587\u6863\u4fe1\u606f\u68c0\u7d22\u7684\u6311\u6218\uff0c\u8bd5\u56fe\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0\u5e76\u5f3a\u8c03\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u7684\u9650\u5236\u3002\u540c\u65f6\uff0c\u5f3a\u8c03\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u4f5c\u4e3a\u786e\u4fdd\u4eba\u5de5\u667a\u80fd\u5728\u6cd5\u5f8b\u9886\u57df\u4ee5\u53ca\u5176\u4ed6\u9886\u57df\u4e2d\u7684\u8d23\u4efb\u548c\u53ef\u4fe1\u5ea6\u7684\u6f5c\u529b\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u4f5c\u4e3a\u5e94\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u9886\u57df\u53ef\u9760\u6027\u548c\u900f\u660e\u6027\u6311\u6218\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u5177\u4f53\u8fc7\u7a0b\u5305\u62ec\u5c06\u957f\u7bc7\u6cd5\u5f8b\u6587\u4ef6\u5206\u5272\u6210\u591a\u4e2a\u5757\uff0c\u901a\u8fc7QWEN-2\u6a21\u578b\u548c\u5de5\u7a0b\u5316\u63d0\u793a\u751f\u6210\u95ee\u9898\u7684\u7b54\u6848\u96c6\uff0c\u4ee5\u53ca\u5f15\u5165\u57fa\u4e8e\u5206\u5e03\u7684\u672c\u5730\u5316\u548c\u9006\u57fa\u6570\u52a0\u6743\u542f\u53d1\u5f0f\u65b9\u6cd5\u89e3\u51b3\u5019\u9009\u7b54\u6848\u9009\u62e9\u95ee\u9898\u3002\u8fd9\u4e00\u65b9\u6cd5\u7ed3\u5408\u4e86\u901a\u7528\u76ee\u7684\u6a21\u578b\u4ee5\u63d0\u9ad8\u957f\u671f\u53ef\u6269\u5c55\u6027\uff0c\u63d0\u793a\u5de5\u7a0b\u4ee5\u589e\u52a0\u53ef\u9760\u6027\uff0c\u4ee5\u53ca\u4e24\u79cd\u542f\u53d1\u5f0f\u7b56\u7565\u4ee5\u51cf\u5c11\u9ed1\u76d2\u6548\u5e94\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\u65b0\u65b9\u6cd5\u7684\u6027\u80fd\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002\u8be5\u65b9\u6cd5\u5f3a\u8c03\u4e86\u5f53\u524d\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u5bf9\u95ee\u7b54\u4efb\u52a1\u6027\u80fd\u8bc4\u4f30\u7684\u9650\u5236\uff0c\u5e76\u547c\u5401\u672a\u6765\u7814\u7a76\u3002\u6700\u91cd\u8981\u7684\u662f\uff0c\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u7684\u6f5c\u529b\uff0c\u4f5c\u4e3a\u786e\u4fdd\u4eba\u5de5\u667a\u80fd\u5728\u6cd5\u5f8b\u9886\u57df\u53ca\u5176\u4ed6\u9886\u57df\u4e2d\u8d23\u4efb\u548c\u53ef\u4fe1\u5ea6\u7684\u6709\u7528\u5de5\u5177\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u4f5c\u4e3a\u5728\u6cd5\u5f8b\u9886\u57df\u4e2d\u5e94\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u9760\u6027\u548c\u900f\u660e\u6027\u6311\u6218\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002\u901a\u8fc7\u5728\u957f\u7bc7\u6cd5\u5f8b\u6587\u4ef6\u4e0a\u5e94\u7528\u57fa\u4e8eCUAD\u6570\u636e\u96c6\u7684\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\uff0c\u672c\u7814\u7a76\u8868\u660e\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u6709\u52a9\u4e8e\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u51cf\u5c11\u9ed1\u76d2\u6548\u5e94\u7684\u5f71\u54cd\u3002\u7814\u7a76\u7684\u7ed3\u679c\u663e\u793a\u65b0\u65b9\u6cd5\u6bd4\u5148\u524d\u7684\u65b9\u6cd5\u8868\u73b0\u9ad8\u51fa9\n%\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002\u7136\u800c\uff0c\u5f53\u524d\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u9650\u5236\u4e86\u5bf9\u95ee\u7b54\u4efb\u52a1\u6027\u80fd\u7684\u8bc4\u4f30\uff0c\u9700\u8981\u672a\u6765\u7814\u7a76\u52aa\u529b\u89e3\u51b3\u3002\u603b\u7684\u6765\u8bf4\uff0c\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u7684\u6f5c\u529b\uff0c\u662f\u786e\u4fdd\u4eba\u5de5\u667a\u80fd\u5728\u6cd5\u5f8b\u9886\u57df\u53ca\u5176\u4ed6\u9886\u57df\u4e2d\u627f\u62c5\u8d23\u4efb\u548c\u63d0\u9ad8\u53ef\u4fe1\u5ea6\u7684\u6709\u7528\u800c\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u5de5\u5177\u3002"}}
{"id": "2509.02258", "categories": ["cs.AI", "68T01, 68T50", "I.2.7; I.2.1"], "pdf": "https://arxiv.org/pdf/2509.02258", "abs": "https://arxiv.org/abs/2509.02258", "authors": ["Sergio Consoli", "Pietro Coletti", "Peter V. Markov", "Lia Orfei", "Indaco Biazzo", "Lea Schuh", "Nicolas Stefanovitch", "Lorenzo Bertolini", "Mario Ceresa", "Nikolaos I. Stilianakis"], "title": "An Epidemiological Knowledge Graph extracted from the World Health Organization's Disease Outbreak News", "comment": "23 pages, 10 figures", "summary": "The rapid evolution of artificial intelligence (AI), together with the\nincreased availability of social media and news for epidemiological\nsurveillance, are marking a pivotal moment in epidemiology and public health\nresearch. Leveraging the power of generative AI, we use an ensemble approach\nwhich incorporates multiple Large Language Models (LLMs) to extract valuable\nactionable epidemiological information from the World Health Organization (WHO)\nDisease Outbreak News (DONs). DONs is a collection of regular reports on global\noutbreaks curated by the WHO and the adopted decision-making processes to\nrespond to them. The extracted information is made available in a daily-updated\ndataset and a knowledge graph, referred to as eKG, derived to provide a nuanced\nrepresentation of the public health domain knowledge. We provide an overview of\nthis new dataset and describe the structure of eKG, along with the services and\ntools used to access and utilize the data that we are building on top. These\ninnovative data resources open altogether new opportunities for epidemiological\nresearch, and the analysis and surveillance of disease outbreaks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ece\u4e16\u754c\u536b\u751f\u7ec4\u7ec7\u75be\u75c5\u7206\u53d1\u65b0\u95fb\u4e2d\u63d0\u53d6\u6d41\u884c\u75c5\u5b66\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u5177\u6709\u66f4\u65b0\u6570\u636e\u96c6\u548c\u77e5\u8bc6\u56fe\u8c31eKG\uff0c\u4e3a\u516c\u5171\u536b\u751f\u9886\u57df\u77e5\u8bc6\u5c55\u793a\u63d0\u4f9b\u65b0\u7684\u673a\u4f1a\u3002\u8fd9\u4e00\u521b\u65b0\u4e3a\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u548c\u75be\u75c5\u7206\u53d1\u76d1\u6d4b\u5e26\u6765\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u53d1\u5c55\u548c\u793e\u4ea4\u5a92\u4f53\u3001\u65b0\u95fb\u5bf9\u6d41\u884c\u75c5\u5b66\u76d1\u6d4b\u7684\u589e\u52a0\u53ef\u7528\u6027\uff0c\u672c\u6587\u6307\u51fa\u4e86\u5728\u6d41\u884c\u75c5\u5b66\u548c\u516c\u5171\u536b\u751f\u7814\u7a76\u4e2d\u7684\u5173\u952e\u65f6\u523b\u3002\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u591f\u4eceWHO\u7684\u75be\u75c5\u7206\u53d1\u65b0\u95fb\u4e2d\u63d0\u53d6\u6709\u7528\u7684\u6d41\u884c\u75c5\u5b66\u4fe1\u606f\uff0c\u5e2e\u52a9\u54cd\u5e94\u5168\u7403\u75ab\u60c5\u3002", "method": "\u672c\u6587\u91c7\u7528\u96c6\u6210\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ece\u4e16\u754c\u536b\u751f\u7ec4\u7ec7\u75be\u75c5\u7206\u53d1\u65b0\u95fb\u4e2d\u63d0\u53d6\u6d41\u884c\u75c5\u5b66\u4fe1\u606f\u3002\u6784\u5efa\u4e86\u6bcf\u65e5\u66f4\u65b0\u7684\u6570\u636e\u96c6\u548c\u77e5\u8bc6\u56fe\u8c31eKG\uff0c\u4e3a\u516c\u5171\u536b\u751f\u9886\u57df\u77e5\u8bc6\u63d0\u4f9b\u8be6\u7ec6\u7684\u5c55\u793a\u3002", "result": "\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u4e16\u754c\u536b\u751f\u7ec4\u7ec7\u75be\u75c5\u7206\u53d1\u65b0\u95fb\u4e2d\u63d0\u53d6\u6709\u4ef7\u503c\u7684\u6d41\u884c\u75c5\u5b66\u4fe1\u606f\uff0c\u5e76\u5efa\u7acb\u4e86\u6bcf\u65e5\u66f4\u65b0\u7684\u6570\u636e\u96c6\u548c\u77e5\u8bc6\u56fe\u8c31eKG\u3002\u8fd9\u4e9b\u8d44\u6e90\u62d3\u5c55\u4e86\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u548c\u75be\u75c5\u7206\u53d1\u76d1\u6d4b\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u4e16\u754c\u536b\u751f\u7ec4\u7ec7\u75be\u75c5\u7206\u53d1\u65b0\u95fb\u4e2d\u63d0\u53d6\u6709\u4ef7\u503c\u7684\u6d41\u884c\u75c5\u5b66\u4fe1\u606f\u7684\u65b9\u6cd5\u3002\u63d0\u53d6\u7684\u4fe1\u606f\u53ef\u7528\u4e8e\u5efa\u7acb\u6bcf\u65e5\u66f4\u65b0\u7684\u6570\u636e\u96c6\u548c\u77e5\u8bc6\u56fe\u8c31eKG\uff0c\u4e3a\u516c\u5171\u536b\u751f\u9886\u57df\u77e5\u8bc6\u63d0\u4f9b\u7ec6\u81f4\u7684\u8868\u5f81\u3002\u901a\u8fc7\u8fd9\u4e9b\u521b\u65b0\u6570\u636e\u8d44\u6e90\uff0c\u4e3a\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u3001\u75be\u75c5\u7206\u53d1\u5206\u6790\u548c\u76d1\u6d4b\u5f00\u62d3\u4e86\u5168\u65b0\u7684\u673a\u4f1a\u3002"}}
{"id": "2509.02276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02276", "abs": "https://arxiv.org/abs/2509.02276", "authors": ["Susana Nunes", "Samy Badreddine", "Catia Pesquita"], "title": "Rewarding Explainability in Drug Repurposing with Knowledge Graphs", "comment": "9 pages, 4 figures, accepted at conference IJCAI 2025", "summary": "Knowledge graphs (KGs) are powerful tools for modelling complex,\nmulti-relational data and supporting hypothesis generation, particularly in\napplications like drug repurposing. However, for predictive methods to gain\nacceptance as credible scientific tools, they must ensure not only accuracy but\nalso the capacity to offer meaningful scientific explanations. This paper\npresents a novel approach REx, for generating scientific explanations based in\nlink prediction in knowledge graphs. It employs reward and policy mechanisms\nthat consider desirable properties of scientific explanation to guide a\nreinforcement learning agent in the identification of explanatory paths within\na KG. The approach further enriches explanatory paths with domain-specific\nontologies, ensuring that the explanations are both insightful and grounded in\nestablished biomedical knowledge. We evaluate our approach in drug repurposing\nusing three popular knowledge graph benchmarks. The results clearly demonstrate\nits ability to generate explanations that validate predictive insights against\nbiomedical knowledge and that outperform the state-of-the-art approaches in\npredictive performance, establishing REx as a relevant contribution to advance\nAI-driven scientific discovery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREx\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8fdb\u884c\u94fe\u63a5\u9884\u6d4b\u751f\u6210\u79d1\u5b66\u89e3\u91ca\u3002\u901a\u8fc7\u5956\u52b1\u548c\u7b56\u7565\u673a\u5236\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8bc6\u522b\u89e3\u91ca\u8def\u5f84\uff0c\u5e76\u4e30\u5bcc\u89e3\u91ca\u8def\u5f84\u4ee5\u786e\u4fdd\u89e3\u91ca\u5177\u6709\u6d1e\u89c1\u5e76\u624e\u6839\u4e8e\u5efa\u7acb\u7684\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u3002\u5728\u836f\u7269\u518d\u5229\u7528\u9886\u57df\u4e2d\u7684\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0cREx\u65b9\u6cd5\u5728\u9a8c\u8bc1\u9884\u6d4b\u89c1\u89e3\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u9884\u6d4b\u65b9\u6cd5\u4f5c\u4e3a\u53ef\u9760\u7684\u79d1\u5b66\u5de5\u5177\u5f97\u5230\u63a5\u53d7\uff0c\u4e0d\u4ec5\u8981\u786e\u4fdd\u51c6\u786e\u6027\uff0c\u8fd8\u5fc5\u987b\u5177\u5907\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u79d1\u5b66\u89e3\u91ca\u7684\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8fdb\u884c\u94fe\u63a5\u9884\u6d4b\u751f\u6210\u79d1\u5b66\u89e3\u91ca\uff0c\u4ee5\u63d0\u9ad8\u9884\u6d4b\u65b9\u6cd5\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e00\u79cd\u540d\u4e3aREx\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5956\u52b1\u548c\u7b56\u7565\u673a\u5236\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8bc6\u522b\u89e3\u91ca\u8def\u5f84\u3002\u8be5\u65b9\u6cd5\u8fd8\u5229\u7528\u9886\u57df\u7279\u5b9a\u7684\u672c\u4f53\u8bba\u4e30\u5bcc\u89e3\u91ca\u8def\u5f84\uff0c\u5e76\u5728\u836f\u7269\u518d\u5229\u7528\u9886\u57df\u4e2d\u4f7f\u7528\u4e09\u4e2a\u77e5\u540d\u7684\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30\u5728\u836f\u7269\u518d\u5229\u7528\u9886\u57df\u4e2d\u7684\u4e09\u4e2a\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\uff0c\u7ed3\u679c\u8868\u660eREx\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9a8c\u8bc1\u9884\u6d4b\u89c1\u89e3\u7684\u89e3\u91ca\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREx\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8fdb\u884c\u94fe\u63a5\u9884\u6d4b\u751f\u6210\u79d1\u5b66\u89e3\u91ca\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5956\u52b1\u548c\u7b56\u7565\u673a\u5236\u6765\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8bc6\u522b\u89e3\u91ca\u8def\u5f84\uff0c\u8fdb\u4e00\u6b65\u5229\u7528\u9886\u57df\u7279\u5b9a\u7684\u672c\u4f53\u8bba\u4e30\u5bcc\u89e3\u91ca\u8def\u5f84\uff0c\u786e\u4fdd\u89e3\u91ca\u65e2\u5bcc\u6709\u6d1e\u89c1\u53c8\u624e\u6839\u4e8e\u5efa\u7acb\u7684\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u3002\u4f5c\u8005\u5728\u4e09\u4e2a\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u4e0a\u8bc4\u4f30\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\uff0c\u7ed3\u679c\u6e05\u695a\u5730\u8868\u660e\u5176\u80fd\u591f\u751f\u6210\u9a8c\u8bc1\u9884\u6d4b\u89c1\u89e3\u7684\u89e3\u91ca\uff0c\u8d85\u8d8a\u4e86\u9884\u6d4b\u6027\u80fd\u65b9\u9762\u73b0\u6709\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u5c06REx\u786e\u7acb\u4e3aAI\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2509.02297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02297", "abs": "https://arxiv.org/abs/2509.02297", "authors": ["Guorui Quan", "Mingfei Sun", "Manuel L\u00f3pez-Ib\u00e1\u00f1ez"], "title": "Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem", "comment": null, "summary": "The art of heuristic design has traditionally been a human pursuit. While\nLarge Language Models (LLMs) can generate code for search heuristics, their\napplication has largely been confined to adjusting simple functions within\nhuman-crafted frameworks, leaving their capacity for broader innovation an open\nquestion. To investigate this, we tasked an LLM with building a complete solver\nfor the constrained 3D Packing Problem. Direct code generation quickly proved\nfragile, prompting us to introduce two supports: constraint\nscaffolding--prewritten constraint-checking code--and iterative\nself-correction--additional refinement cycles to repair bugs and produce a\nviable initial population. Notably, even within a vast search space in a greedy\nprocess, the LLM concentrated its efforts almost exclusively on refining the\nscoring function. This suggests that the emphasis on scoring functions in prior\nwork may reflect not a principled strategy, but rather a natural limitation of\nLLM capabilities. The resulting heuristic was comparable to a human-designed\ngreedy algorithm, and when its scoring function was integrated into a\nhuman-crafted metaheuristic, its performance rivaled established solvers,\nthough its effectiveness waned as constraints tightened. Our findings highlight\ntwo major barriers to automated heuristic design with current LLMs: the\nengineering required to mitigate their fragility in complex reasoning tasks,\nand the influence of pretrained biases, which can prematurely narrow the search\nfor novel solutions.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u5176\u5728\u81ea\u52a8\u751f\u6210\u542f\u53d1\u5f0f\u7b97\u6cd5\u65b9\u9762\u9762\u4e34\u5de5\u7a0b\u56f0\u96be\u548c\u9884\u8bad\u7ec3\u504f\u89c1\u7684\u6311\u6218\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cLLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5bf9\u8bc4\u5206\u51fd\u6570\u7684\u5173\u6ce8\u53ef\u80fd\u53cd\u6620\u4e86\u5176\u80fd\u529b\u7684\u81ea\u7136\u9650\u5236\u3002LLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u4e00\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u7684\u7b97\u6cd5\u5ab2\u7f8e\uff0c\u4f46\u5728\u7ea6\u675f\u52a0\u5f3a\u65f6\u8868\u73b0\u53ef\u80fd\u4f1a\u6709\u6240\u4e0b\u964d\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4ee5\u53ca\u5b83\u4eec\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u542f\u53d1\u5f0f\u7684\u5dee\u5f02\u3002\u901a\u8fc7\u5c06LLM\u5e94\u7528\u4e8e\u590d\u6742\u4efb\u52a1\uff0c\u63a2\u7a76\u5176\u521b\u65b0\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "method": "\u4efb\u52a1LLM\u6784\u5efa\u7ea6\u675f3D\u88c5\u7bb1\u95ee\u9898\u7684\u5b8c\u6574\u6c42\u89e3\u5668\uff0c\u5f15\u5165\u4e86\u7ea6\u675f\u652f\u6491\u548c\u8fed\u4ee3\u81ea\u6211\u4fee\u6b63\u4e24\u79cd\u652f\u6301\u65b9\u6cd5\uff0c\u4ee5\u4fee\u590d\u4ee3\u7801\u751f\u6210\u4e2d\u51fa\u73b0\u7684\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\uff0cLLM\u5728\u5e9e\u5927\u7684\u641c\u7d22\u7a7a\u95f4\u4e2d\u51e0\u4e4e\u5b8c\u5168\u4e13\u6ce8\u4e8e\u7ec6\u5316\u8bc4\u5206\u51fd\u6570\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u7531LLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u7684\u8d2a\u5a6a\u7b97\u6cd5\u76f8\u5f53\uff0c\u5e76\u5728\u96c6\u6210\u5230\u4eba\u5de5\u8bbe\u8ba1\u7684\u5143\u542f\u53d1\u5f0f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c3d\u7ba1\u5728\u7ea6\u675f\u52a0\u5f3a\u65f6\u5176\u6548\u679c\u6709\u6240\u51cf\u5f31\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u751f\u6210\u542f\u53d1\u5f0f\u7b97\u6cd5\u65b9\u9762\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u969c\u788d\uff1a\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u51cf\u8f7b\u5176\u8106\u5f31\u6027\u6240\u9700\u7684\u5de5\u7a0b\u5316\u5de5\u4f5c\uff0c\u4ee5\u53ca\u9884\u5148\u8bad\u7ec3\u7684\u504f\u89c1\u7684\u5f71\u54cd\uff0c\u8fd9\u53ef\u80fd\u4f1a\u8fc7\u65e9\u5730\u9650\u5236\u5bf9\u65b0\u9896\u89e3\u51b3\u65b9\u6848\u7684\u641c\u7d22\u3002"}}
{"id": "2509.02308", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02308", "abs": "https://arxiv.org/abs/2509.02308", "authors": ["Taegyeong Lee", "Jiwon Park", "Kyunga Bang", "Seunghyun Hwang", "Ung-Jin Jang"], "title": "Exploring Diffusion Models for Generative Forecasting of Financial Charts", "comment": null, "summary": "Recent advances in generative models have enabled significant progress in\ntasks such as generating and editing images from text, as well as creating\nvideos from text prompts, and these methods are being applied across various\nfields. However, in the financial domain, there may still be a reliance on\ntime-series data and a continued focus on transformer models, rather than on\ndiverse applications of generative models. In this paper, we propose a novel\napproach that leverages text-to-image model by treating time-series data as a\nsingle image pattern, thereby enabling the prediction of stock price trends.\nUnlike prior methods that focus on learning and classifying chart patterns\nusing architectures such as ResNet or ViT, we experiment with generating the\nnext chart image from the current chart image and an instruction prompt using\ndiffusion models. Furthermore, we introduce a simple method for evaluating the\ngenerated chart image against ground truth image. We highlight the potential of\nleveraging text-to-image generative models in the financial domain, and our\nfindings motivate further research to address the current limitations and\nexpand their applicability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4f5c\u4e3a\u56fe\u50cf\u6a21\u5f0f\uff0c\u9884\u6d4b\u80a1\u4ef7\u8d70\u52bf\u3002\u901a\u8fc7\u6269\u6563\u6a21\u578b\u751f\u6210\u4e0b\u4e00\u4e2a\u56fe\u8868\u56fe\u50cf\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4f30\u751f\u6210\u56fe\u8868\u56fe\u50cf\u7684\u7b80\u5355\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u91d1\u878d\u9886\u57df\u7684\u6f5c\u529b\uff0c\u9f13\u52b1\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u62d3\u5c55\u5176\u5e94\u7528\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u5e76\u5728\u5404\u9886\u57df\u5f97\u5230\u5e94\u7528\uff0c\u4f46\u91d1\u878d\u9886\u57df\u4ecd\u53ef\u80fd\u501a\u8d56\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548c\u4e13\u6ce8\u4e8e\u53d8\u538b\u5668\u6a21\u578b\uff0c\u800c\u4e0d\u662f\u591a\u6837\u5316\u7684\u751f\u6210\u6a21\u578b\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u6539\u53d8\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u89c6\u4e3a\u56fe\u50cf\u6a21\u5f0f\uff0c\u5e76\u5c1d\u8bd5\u9884\u6d4b\u80a1\u4ef7\u8d70\u52bf\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u89c6\u4e3a\u5355\u4e2a\u56fe\u50cf\u6a21\u5f0f\uff0c\u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u751f\u6210\u4e0b\u4e00\u4e2a\u56fe\u8868\u56fe\u50cf\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u751f\u6210\u56fe\u8868\u56fe\u50cf\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u91d1\u878d\u9886\u57df\u4e2d\u7684\u6f5c\u529b\uff0c\u5c55\u793a\u4e86\u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u8fdb\u884c\u80a1\u4ef7\u8d70\u52bf\u9884\u6d4b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u89c6\u4e3a\u5355\u4e2a\u56fe\u50cf\u6a21\u5f0f\uff0c\u901a\u8fc7\u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u80a1\u4ef7\u8d70\u52bf\u7684\u9884\u6d4b\u3002\u91c7\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u4e0b\u4e00\u4e2a\u56fe\u8868\u56fe\u50cf\uff0c\u800c\u4e0d\u662f\u50cf\u4ee5\u5f80\u65b9\u6cd5\u90a3\u6837\u5173\u6ce8\u4f7f\u7528ResNet\u6216ViT\u7b49\u67b6\u6784\u5b66\u4e60\u548c\u5206\u7c7b\u56fe\u8868\u6a21\u5f0f\u3002\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u751f\u6210\u7684\u56fe\u8868\u56fe\u50cf\u4e0e\u57fa\u51c6\u56fe\u50cf\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u5f3a\u8c03\u4e86\u5728\u91d1\u878d\u9886\u57df\u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u5e76\u9f13\u52b1\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u89e3\u51b3\u5f53\u524d\u7684\u5c40\u9650\u6027\u5e76\u62d3\u5c55\u5176\u9002\u7528\u6027\u3002"}}
{"id": "2509.02340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02340", "abs": "https://arxiv.org/abs/2509.02340", "authors": ["Salma Haidar", "Jos\u00e9 Oramas"], "title": "Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging", "comment": null, "summary": "Hyperspectral imaging (HSI) provides rich spectral information for precise\nmaterial classification and analysis; however, its high dimensionality\nintroduces a computational burden and redundancy, making dimensionality\nreduction essential. We present an exploratory study into the application of\npost-hoc explainability methods in a model--driven framework for band\nselection, which reduces the spectral dimension while preserving predictive\nperformance. A trained classifier is probed with explanations to quantify each\nband's contribution to its decisions. We then perform deletion--insertion\nevaluations, recording confidence changes as ranked bands are removed or\nreintroduced, and aggregate these signals into influence scores. Selecting the\nhighest--influence bands yields compact spectral subsets that maintain accuracy\nand improve efficiency. Experiments on two public benchmarks (Pavia University\nand Salinas) demonstrate that classifiers trained on as few as 30 selected\nbands match or exceed full--spectrum baselines while reducing computational\nrequirements. The resulting subsets align with physically meaningful, highly\ndiscriminative wavelength regions, indicating that model--aligned,\nexplanation-guided band selection is a principled route to effective\ndimensionality reduction for HSI.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u9ad8\u5149\u8c31\u6210\u50cf\u4e2d\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u6846\u67b6\u7684\u6ce2\u6bb5\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u91ca\u6027\u65b9\u6cd5\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u4ee5\u964d\u4f4e\u7ef4\u5ea6\u5e76\u4fdd\u6301\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u9009\u62e9\u6700\u5177\u5f71\u54cd\u529b\u7684\u6ce2\u6bb5\u53ef\u4ee5\u4ea7\u751f\u7d27\u51d1\u7684\u5149\u8c31\u5b50\u96c6\uff0c\u4fdd\u6301\u51c6\u786e\u6027\u5e76\u63d0\u9ad8\u6548\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u7531\u4e8e\u9ad8\u5149\u8c31\u6210\u50cf(HSI)\u7684\u9ad8\u7ef4\u5ea6\u4f1a\u5f15\u5165\u8ba1\u7b97\u8d1f\u62c5\u548c\u5197\u4f59\uff0c\u9700\u8981\u8fdb\u884c\u964d\u7ef4\u5904\u7406\uff0c\u56e0\u6b64\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u5728\u6a21\u578b\u9a71\u52a8\u6846\u67b6\u4e2d\u7ed3\u5408\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u65b0\u9896\u6ce2\u6bb5\u9009\u62e9\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u964d\u7ef4\uff0c\u5e76\u4fdd\u6301\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u6846\u67b6\u7ed3\u5408\u540e\u7eed\u89e3\u91ca\u6027\u65b9\u6cd5\u8fdb\u884c\u6ce2\u6bb5\u9009\u62e9\uff0c\u901a\u8fc7\u91cf\u5316\u6bcf\u4e2a\u6ce2\u6bb5\u5bf9\u5206\u7c7b\u5668\u51b3\u7b56\u7684\u8d21\u732e\uff0c\u5e76\u8fdb\u884c\u5220\u9664-\u63d2\u5165\u8bc4\u4f30\uff0c\u8bb0\u5f55\u7f6e\u4fe1\u5ea6\u53d8\u5316\u5e76\u5c06\u8fd9\u4e9b\u4fe1\u53f7\u805a\u5408\u4e3a\u5f71\u54cd\u529b\u8bc4\u5206\uff0c\u6700\u7ec8\u9009\u62e9\u51fa\u5f71\u54cd\u6700\u5927\u7684\u6ce2\u6bb5\uff0c\u4ee5\u5b9e\u73b0\u5149\u8c31\u5b50\u96c6\u7684\u7d27\u51d1\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u9009\u62e930\u4e2a\u6ce2\u6bb5\u8bad\u7ec3\u7684\u5206\u7c7b\u5668\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53ef\u4ee5\u8fbe\u5230\u6216\u8d85\u8fc7\u5b8c\u6574\u5149\u8c31\u57fa\u51c6\u7684\u6027\u80fd\uff0c\u5e76\u51cf\u5c11\u4e86\u8ba1\u7b97\u9700\u6c42\u3002\u6240\u9009\u7684\u5149\u8c31\u5b50\u96c6\u4e0e\u7269\u7406\u4e0a\u6709\u610f\u4e49\u3001\u9ad8\u5ea6\u533a\u5206\u6027\u7684\u6ce2\u957f\u533a\u57df\u4fdd\u6301\u4e00\u81f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u7684\u6846\u67b6\u4e2d\u5e94\u7528\u540e\u7eed\u89e3\u91ca\u6027\u65b9\u6cd5\u8fdb\u884c\u6ce2\u6bb5\u9009\u62e9\uff0c\u4ee5\u51cf\u5c11\u5149\u8c31\u7ef4\u5ea6\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u53ef\u884c\u6027\u3002\u6700\u7ec8\u7ed3\u679c\u8868\u660e\uff0c\u9009\u62e9\u5177\u6709\u6700\u9ad8\u5f71\u54cd\u529b\u7684\u6ce2\u6bb5\u53ef\u4ee5\u83b7\u5f97\u7d27\u51d1\u7684\u5149\u8c31\u5b50\u96c6\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u5e76\u63d0\u9ad8\u6548\u7387\u3002\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u4ec5\u5728\u9009\u62e9\u4e8630\u4e2a\u6ce2\u6bb5\u7684\u60c5\u51b5\u4e0b\u8bad\u7ec3\u7684\u5206\u7c7b\u5668\u53ef\u4ee5\u4e0e\u5b8c\u6574\u5149\u8c31\u57fa\u51c6\u76f8\u5339\u914d\u6216\u8d85\u8d8a\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u9700\u6c42\u3002"}}
{"id": "2509.02360", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02360", "abs": "https://arxiv.org/abs/2509.02360", "authors": ["Shubham Gandhi", "Jason Tsay", "Jatin Ganhotra", "Kiran Kate", "Yara Rizk"], "title": "When Agents go Astray: Course-Correcting SWE Agents with PRMs", "comment": null, "summary": "Large Language Model (LLM) agents are increasingly deployed for complex,\nmulti-step software engineering (SWE) tasks. However, their trajectories often\ncontain costly inefficiencies, such as redundant exploration, looping, and\nfailure to terminate once a solution is reached. Prior work has largely treated\nthese errors in a post-hoc manner, diagnosing failures only after execution. In\nthis paper, we introduce SWE-PRM, an inference-time Process Reward Model (PRM)\nthat intervenes during execution to detect and course-correct trajectory-level\nerrors. Our PRM design leverages a taxonomy of common inefficiencies and\ndelivers lightweight, interpretable feedback without modifying the underlying\npolicy. On SWE-bench Verified, closed-source PRMs improve resolution from 40.0%\nto 50.6% (+10.6 p.p.), with the largest gains on medium and hard tasks. Among\nfeedback strategies, taxonomy-guided PRMs outperform unguided or explicit\naction-prescriptive variants, increasing success rate while reducing trajectory\nlength. These benefits come at an acceptable added inference cost of as low as\n$0.2, making PRMs a practical and scalable mechanism for improving SWE agents'\nreliability and efficiency.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SWE-PRM\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u68c0\u6d4b\u548c\u7ea0\u6b63\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u8f68\u8ff9\u7ea7\u9519\u8bef\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u89e3\u51b3\u6548\u7387\uff0c\u6210\u529f\u7387\u589e\u52a0\uff0c\u8f68\u8ff9\u957f\u5ea6\u51cf\u5c11\u3002\u5206\u7c7b\u6307\u5bfc\u7684PRMs\u5728\u63d0\u4f9b\u53cd\u9988\u7b56\u7565\u65f6\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u53d8\u4f53\uff0c\u4e14\u63a8\u65ad\u6210\u672c\u4f4e\u5ec9\uff0c\u9002\u7528\u4e8e\u63d0\u9ad8SWE\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4ee5\u5f80\u7684\u65b9\u6cd5\u901a\u5e38\u5728\u6267\u884c\u540e\u624d\u8bca\u65ad\u7cfb\u7edf\u6f0f\u6d1e\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u5e72\u9884\u4ee5\u68c0\u6d4b\u548c\u7ea0\u6b63\u7cfb\u7edf\u8f68\u8ff9\u7ea7\u9519\u8bef\u7684\u65b9\u6cd5\u3002\u4e3a\u4e86\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u9700\u8981\u6539\u8fdb\u5904\u7406\u5e38\u89c1\u4f4e\u6548\u6027\u95ee\u9898\u7684\u80fd\u529b\u3002", "method": "\u4ecb\u7ecd\u4e86SWE-PRM\u6a21\u578b\uff0c\u901a\u8fc7\u5e72\u9884\u6267\u884c\u8fc7\u7a0b\u6765\u68c0\u6d4b\u548c\u7ea0\u6b63\u8f68\u8ff9\u7ea7\u9519\u8bef\uff0c\u5229\u7528\u5e38\u89c1\u4f4e\u6548\u6027\u7684\u5206\u7c7b\u6cd5\u8bbe\u8ba1PRM\u6a21\u578b\uff0c\u63d0\u4f9b\u8f7b\u91cf\u4e14\u53ef\u89e3\u91ca\u7684\u53cd\u9988\uff0c\u800c\u4e0d\u4fee\u6539\u57fa\u7840\u7b56\u7565\u3002\u5728SWE-bench Verified\u4e0a\u9a8c\u8bc1\u4e86PRM\u6a21\u578b\u7684\u6548\u679c\uff0c\u5bf9\u4e2d\u7b49\u548c\u56f0\u96be\u4efb\u52a1\u53d6\u5f97\u6700\u5927\u589e\u76ca\u3002\u5206\u7c7b\u6307\u5bfc\u7684PRMs\u5728\u53cd\u9988\u7b56\u7565\u4e2d\u8868\u73b0\u4f18\u4e8e\u65e0\u6307\u5bfc\u6216\u660e\u786e\u884c\u52a8\u5904\u65b9\u53d8\u4f53\uff0c\u540c\u65f6\u964d\u4f4e\u8f68\u8ff9\u957f\u5ea6\u3002", "result": "SWE-PRM\u6a21\u578b\u5728SWE-bench Verified\u4e0a\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u4efb\u52a1\u89e3\u51b3\u6548\u7387\uff0c\u6210\u529f\u7387\u589e\u52a0\u4e14\u8f68\u8ff9\u957f\u5ea6\u51cf\u5c11\uff0c\u5c24\u5176\u5728\u4e2d\u7b49\u548c\u56f0\u96be\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u6700\u5927\u7684\u589e\u76ca\u3002\u901a\u8fc7\u5206\u7c7b\u6307\u5bfc\u7684PRMs\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u63a8\u65ad\u6210\u672c\u4f4e\u5ec9\u7684\u524d\u63d0\u4e0b\u63d0\u4f9b\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6539\u8fdb\u673a\u5236\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u65f6\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b(SWE-PRM)\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u7ea0\u6b63\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u8f68\u8ff9\u7ea7\u9519\u8bef\u3002\u901a\u8fc7\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u5e72\u9884\u6765\u68c0\u6d4b\u548c\u7ea0\u6b63\u8f68\u8ff9\u7ea7\u9519\u8bef\uff0c\u8be5\u8bbe\u8ba1\u5229\u7528\u5e38\u89c1\u4f4e\u6548\u6027\u7684\u5206\u7c7b\u6cd5\uff0c\u63d0\u4f9b\u8f7b\u91cf\u4e14\u53ef\u89e3\u91ca\u7684\u53cd\u9988\uff0c\u800c\u4e0d\u4fee\u6539\u57fa\u7840\u7b56\u7565\u3002\u5728SWE-bench Verified\u4e0a\uff0c\u7ecf\u8fc7\u5173\u95ed\u6e90\u9a8c\u8bc1\u7684PRMs\u5c06\u5206\u8fa8\u7387\u4ece40.0%\u63d0\u9ad8\u523050.6%\uff0c\u53d6\u5f9710.6\u4e2a\u767e\u5206\u70b9\u589e\u957f\uff0c\u5728\u4e2d\u7b49\u548c\u56f0\u96be\u4efb\u52a1\u4e0a\u589e\u76ca\u6700\u5927\u3002\u5728\u53cd\u9988\u7b56\u7565\u4e2d\uff0c\u5206\u7c7b\u6307\u5bfc\u7684PRMs\u4f18\u4e8e\u65e0\u6307\u5bfc\u6216\u660e\u786e\u884c\u52a8\u5904\u65b9\u53d8\u4f53\uff0c\u589e\u52a0\u6210\u529f\u7387\u7684\u540c\u65f6\u51cf\u5c11\u8f68\u8ff9\u957f\u5ea6\u3002\u8fd9\u4e9b\u597d\u5904\u4ee5\u4f4e\u81f30.2\u7f8e\u5143\u7684\u53ef\u63a5\u53d7\u9644\u52a0\u63a8\u65ad\u6210\u672c\u5b9e\u73b0\uff0c\u4f7fPRMs\u6210\u4e3a\u63d0\u9ad8SWE\u4ee3\u7406\u53ef\u9760\u6027\u548c\u6548\u7387\u7684\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u673a\u5236\u3002"}}
{"id": "2509.02401", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02401", "abs": "https://arxiv.org/abs/2509.02401", "authors": ["Josefa Lia Stoisser", "Marc Boubnovski Martell", "Lawrence Phillips", "Gianluca Mazzoni", "Lea M\u00f8rch Harder", "Philip Torr", "Jesper Ferkinghoff-Borg", "Kaspar Martens", "Julien Fauqueur"], "title": "Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning", "comment": null, "summary": "Large language model (LLM) agents are increasingly deployed in structured\nbiomedical data environments, yet they often produce fluent but overconfident\noutputs when reasoning over complex multi-table data. We introduce an\nuncertainty-aware agent for query-conditioned multi-table summarization that\nleverages two complementary signals: (i) retrieval uncertainty--entropy over\nmultiple table-selection rollouts--and (ii) summary uncertainty--combining\nself-consistency and perplexity. Summary uncertainty is incorporated into\nreinforcement learning (RL) with Group Relative Policy Optimization (GRPO),\nwhile both retrieval and summary uncertainty guide inference-time filtering and\nsupport the construction of higher-quality synthetic datasets.\n  On multi-omics benchmarks, our approach improves factuality and calibration,\nnearly tripling correct and useful claims per summary (3.0\\(\\rightarrow\\)8.4\ninternal; 3.6\\(\\rightarrow\\)9.9 cancer multi-omics) and substantially improving\ndownstream survival prediction (C-index 0.32\\(\\rightarrow\\)0.63). These results\ndemonstrate that uncertainty can serve as a control signal--enabling agents to\nabstain, communicate confidence, and become more reliable tools for complex\nstructured-data environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u7ed3\u6784\u5316\u7684\u751f\u7269\u533b\u5b66\u6570\u636e\u3002\u901a\u8fc7\u5f15\u5165\u603b\u7ed3\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u6210\u529f\u6539\u5584\u4e86\u4fe1\u606f\u7684\u5ba2\u89c2\u6027\u3001\u6821\u51c6\u6027\u548c\u6709\u6548\u6027\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u786e\u5b9a\u6027\u53ef\u4f5c\u4e3a\u63a7\u5236\u4fe1\u53f7\uff0c\u4f7f\u4ee3\u7406\u6a21\u578b\u5728\u590d\u6742\u73af\u5883\u4e2d\u66f4\u53ef\u9760\uff0c\u4e3a\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5728\u7ed3\u6784\u5316\u7684\u751f\u7269\u533b\u5b66\u6570\u636e\u73af\u5883\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u7684\u591a\u8868\u6570\u636e\u65f6\u7ecf\u5e38\u4f1a\u4ea7\u751f\u6d41\u7545\u4f46\u8fc7\u4e8e\u81ea\u4fe1\u7684\u8f93\u51fa\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f15\u5165\u4e00\u79cd\u80fd\u591f\u8bc6\u522b\u4e0d\u786e\u5b9a\u6027\u5e76\u5728\u63a8\u7406\u548c\u603b\u7ed3\u4e2d\u52a0\u4ee5\u5229\u7528\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u4ee5\u63d0\u9ad8\u4fe1\u606f\u7684\u5ba2\u89c2\u6027\u3001\u6821\u51c6\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u4f7f\u7528\u4e24\u79cd\u4e92\u8865\u4fe1\u53f7\u8fdb\u884c\u591a\u8868\u603b\u7ed3\u3002\u5c06\u603b\u7ed3\u4e0d\u786e\u5b9a\u6027\u6574\u5408\u5230\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5229\u7528 Group Relative Policy Optimization\uff08GRPO\uff09\uff0c\u5e76\u5229\u7528\u68c0\u7d22\u548c\u603b\u7ed3\u4e0d\u786e\u5b9a\u6027\u6307\u5bfc\u63a8\u7406\u65f6\u7684\u8fc7\u6ee4\u548c\u652f\u6301\u6784\u5efa\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u96c6\u3002", "result": "\u5728\u591a\u7ec4\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u63d0\u9ad8\u4fe1\u606f\u5ba2\u89c2\u6027\u548c\u6821\u51c6\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u589e\u52a0\u4e86\u6bcf\u4e2a\u6458\u8981\u4e2d\u6b63\u786e\u548c\u6709\u7528\u58f0\u660e\u7684\u6570\u91cf\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u4e0b\u6e38\u751f\u5b58\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u89c6\u4e3a\u63a7\u5236\u4fe1\u53f7\u53ef\u4ee5\u4f7f\u4ee3\u7406\u6a21\u578b\u5728\u590d\u6742\u7ed3\u6784\u5316\u6570\u636e\u73af\u5883\u4e2d\u66f4\u53ef\u9760\uff0c\u5e76\u80fd\u591f\u66f4\u597d\u5730\u5e94\u5bf9\u6311\u6218\u3002", "conclusion": "\u5728\u7ed3\u6784\u5316\u7684\u751f\u7269\u533b\u5b66\u6570\u636e\u73af\u5883\u4e2d\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u67e5\u8be2\u6761\u4ef6\u4e0b\u7684\u591a\u8868\u603b\u7ed3\u3002\u8be5\u4ee3\u7406\u6a21\u578b\u5229\u7528\u4e24\u79cd\u4e92\u8865\u4fe1\u53f7\uff1a\u68c0\u7d22\u4e0d\u786e\u5b9a\u6027-\u591a\u8868\u9009\u62e9\u8fed\u4ee3\u7684\u71b5\u548c\u603b\u7ed3\u4e0d\u786e\u5b9a\u6027-\u7ed3\u5408\u81ea\u6d3d\u6027\u548c\u56f0\u60d1\u5ea6\u3002\u603b\u7ed3\u4e0d\u786e\u5b9a\u6027\u88ab\u6574\u5408\u5230\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e2d\uff0c\u901a\u8fc7 Group Relative Policy Optimization\uff08GRPO\uff09\uff0c\u800c\u68c0\u7d22\u548c\u603b\u7ed3\u4e0d\u786e\u5b9a\u6027\u5219\u5f15\u5bfc\u63a8\u7406\u65f6\u7684\u8fc7\u6ee4\u548c\u652f\u6301\u6784\u5efa\u66f4\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6570\u636e\u96c6\u3002\u5728\u591a\u7ec4\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5ba2\u89c2\u6027\u548c\u6821\u51c6\u6027\uff0c\u6bcf\u4e2a\u6458\u8981\u7684\u6b63\u786e\u548c\u6709\u7528\u58f0\u660e\u51e0\u4e4e\u589e\u52a0\u4e86\u4e24\u500d\uff08\u4ece3.0\u52308.4\u5185\u90e8\uff1b\u4ece3.6\u52309.9\u764c\u75c7\u591a\u7ec4\u5b66\uff09\uff0c\u5e76\u4e14\u5927\u5e45\u6539\u5584\u4e86\u4e0b\u6e38\u751f\u5b58\u9884\u6d4b\uff08C-index 0.32\u52300.63\uff09\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u786e\u5b9a\u6027\u53ef\u4ee5\u4f5c\u4e3a\u63a7\u5236\u4fe1\u53f7\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u653e\u5f03\u3001\u4f20\u8fbe\u4fe1\u5fc3\uff0c\u5e76\u6210\u4e3a\u5904\u7406\u590d\u6742\u7ed3\u6784\u5316\u6570\u636e\u73af\u5883\u7684\u66f4\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2509.02444", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.02444", "abs": "https://arxiv.org/abs/2509.02444", "authors": ["Jingru Fan", "Yufan Dang", "Jingyao Wu", "Huatao Li", "Runde Yang", "Xiyuan Yang", "Yuheng Wang", "Zhong Zhang", "Yaxi Lu", "Yankai Lin", "Zhiyuan Liu", "Dahai Li", "Chen Qian"], "title": "AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent", "comment": "Project at https://github.com/OpenBMB/AppCopilot", "summary": "With the raid evolution of large language models and multimodal foundation\nmodels, the mobile-agent landscape has proliferated without converging on the\nfundamental challenges. This paper identifies four core problems that must be\nsolved for mobile agents to deliver practical, scalable impact: (1)\ngeneralization across tasks, modalities, apps, and devices; (2) accuracy,\nspecifically precise on-screen interaction and click targeting; (3)\nlong-horizon capability for sustained, multi-step goals; and (4) efficiency,\nspecifically high-performance runtime on resource-constrained devices. We\npresent AppCopilot, a multimodal, multi-agent, general-purpose on-device\nassistant that operates across applications and constitutes a full-stack,\nclosed-loop system from data to deployment. AppCopilot operationalizes this\nposition through an end-to-end autonomous pipeline spanning data collection,\ntraining, deployment, high-quality and efficient inference, and mobile\napplication development. At the model layer, it integrates multimodal\nfoundation models with robust Chinese-English support. At the reasoning and\ncontrol layer, it combines chain-of-thought reasoning, hierarchical task\nplanning and decomposition, and multi-agent collaboration. At the execution\nlayer, it enables user personalization and experiential adaptation, voice\ninteraction, function calling, cross-app and cross-device orchestration, and\ncomprehensive mobile app support. The system design incorporates\nprofiling-driven optimization for latency, memory, and energy across\nheterogeneous hardware. Empirically, AppCopilot achieves significant\nimprovements along all four dimensions: stronger generalization,\nhigher-precision on-screen actions, more reliable long-horizon task completion,\nand faster, more resource-efficient runtime.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u79fb\u52a8\u4ee3\u7406\u9886\u57df\u9762\u4e34\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86AppCopilot\u7cfb\u7edf\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u591a\u65b9\u9762\u7684\u529f\u80fd\u8bbe\u8ba1\u548c\u7cfb\u7edf\u4f18\u5316\u5b9e\u73b0\u4e86\u5728\u591a\u4e2a\u65b9\u9762\u7684\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u9274\u4e8e\u79fb\u52a8\u4ee3\u7406\u9886\u57df\u7684\u84ec\u52c3\u53d1\u5c55\u4f46\u5c1a\u672a\u89e3\u51b3\u7684\u56f0\u96be\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u901a\u7528\u5316\u3001\u7cbe\u786e\u6027\u3001\u957f\u65f6\u7a0b\u80fd\u529b\u548c\u6548\u7387\u6027\u7b49\u6838\u5fc3\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86AppCopilot\u7cfb\u7edf\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u81ea\u52a8\u7ba1\u9053\u5b9e\u73b0\u591a\u6a21\u6001\u6a21\u578b\u96c6\u6210\u3001\u63a8\u7406\u63a7\u5236\u5c42\u7ec4\u5408\u548c\u6267\u884c\u5c42\u529f\u80fd\u7ec4\u5408\uff0c\u7cfb\u7edf\u8bbe\u8ba1\u8003\u8651\u4e86\u5f02\u6784\u786c\u4ef6\u7684\u4f18\u5316\u3002", "result": "AppCopilot\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5f3a\u5316\u901a\u7528\u5316\u3001\u63d0\u9ad8\u5c4f\u5e55\u64cd\u4f5c\u7cbe\u786e\u6027\u3001\u66f4\u53ef\u9760\u5730\u5b8c\u6210\u957f\u65f6\u7a0b\u4efb\u52a1\u548c\u66f4\u5feb\u3001\u66f4\u8282\u7ea6\u8d44\u6e90\u7684\u8fd0\u884c\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u9488\u5bf9\u79fb\u52a8\u4ee3\u7406\u9886\u57df\u7684\u6838\u5fc3\u6311\u6218\u63d0\u51fa\u56db\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u901a\u7528\u5316\u3001\u7cbe\u786e\u6027\u3001\u957f\u65f6\u7a0b\u80fd\u529b\u548c\u6548\u7387\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u4ecb\u7ecdAppCopilot\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u3001\u591a\u4ee3\u7406\u3001\u901a\u7528\u578b\u7684\u8bbe\u5907\u52a9\u624b\uff0c\u5b9e\u73b0\u4e86\u5168\u6808\u95ed\u73af\u7cfb\u7edf\uff0c\u5305\u62ec\u6570\u636e\u6536\u96c6\u3001\u8bad\u7ec3\u3001\u90e8\u7f72\u3001\u9ad8\u6548\u63a8\u7406\u548c\u79fb\u52a8\u5e94\u7528\u5f00\u53d1\u3002\u5b9e\u9a8c\u8bc1\u660eAppCopilot\u5728\u901a\u7528\u5316\u3001\u7cbe\u786e\u6027\u3001\u957f\u65f6\u7a0b\u80fd\u529b\u548c\u6548\u7387\u6027\u7b49\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2509.02494", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02494", "abs": "https://arxiv.org/abs/2509.02494", "authors": ["Hongwei Jin", "Kibaek Kim", "Jonghwan Kwon"], "title": "GridMind: LLMs-Powered Agents for Power System Analysis and Operations", "comment": "11 pages, 9 figures, 2 tables. Work under review", "summary": "The complexity of traditional power system analysis workflows presents\nsignificant barriers to efficient decision-making in modern electric grids.\nThis paper presents GridMind, a multi-agent AI system that integrates Large\nLanguage Models (LLMs) with deterministic engineering solvers to enable\nconversational scientific computing for power system analysis. The system\nemploys specialized agents coordinating AC Optimal Power Flow and N-1\ncontingency analysis through natural language interfaces while maintaining\nnumerical precision via function calls. GridMind addresses workflow\nintegration, knowledge accessibility, context preservation, and expert\ndecision-support augmentation. Experimental evaluation on IEEE test cases\ndemonstrates that the proposed agentic framework consistently delivers correct\nsolutions across all tested language models, with smaller LLMs achieving\ncomparable analytical accuracy with reduced computational latency. This work\nestablishes agentic AI as a viable paradigm for scientific computing,\ndemonstrating how conversational interfaces can enhance accessibility while\npreserving numerical rigor essential for critical engineering applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86GridMind\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u786e\u5b9a\u6027\u5de5\u7a0b\u6c42\u89e3\u5668\u5b9e\u73b0\u5bf9\u7535\u529b\u7cfb\u7edf\u5206\u6790\u7684\u5bf9\u8bdd\u5f0f\u79d1\u5b66\u8ba1\u7b97\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u7cfb\u7edf\u63d0\u4f9b\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u8f83\u5c0f\u7684LLMs\u5728\u51cf\u5c11\u8ba1\u7b97\u5ef6\u8fdf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u6bd4\u7684\u51c6\u786e\u6027\u3002\u8be5\u7814\u7a76\u786e\u7acb\u4e86\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u4f5c\u4e3a\u79d1\u5b66\u8ba1\u7b97\u7684\u53efiable\u8303\u5f0f\uff0c\u5e76\u5c55\u793a\u4e86\u5bf9\u8bdd\u754c\u9762\u5982\u4f55\u589e\u5f3a\u53ef\u8bbf\u95ee\u6027\u5e76\u4fdd\u6301\u6570\u503c\u7cbe\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7535\u529b\u7cfb\u7edf\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u7684\u590d\u6742\u6027\u7ed9\u73b0\u4ee3\u7535\u7f51\u4e2d\u7684\u9ad8\u6548\u51b3\u7b56\u5e26\u6765\u4e86\u663e\u8457\u969c\u788d\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5de5\u4f5c\u6d41\u7a0b\u96c6\u6210\u3001\u77e5\u8bc6\u53ef\u8bbf\u95ee\u6027\u3001\u4e0a\u4e0b\u6587\u4fdd\u7559\u548c\u4e13\u5bb6\u51b3\u7b56\u652f\u6301\u589e\u5f3a\u7b49\u95ee\u9898\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86GridMind\u7cfb\u7edf\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u786e\u5b9a\u6027\u5de5\u7a0b\u6c42\u89e3\u5668\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528\u4e13\u95e8\u7684\u4ee3\u7406\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u534f\u8c03\u4ea4\u6d41\u6700\u4f18\u6f6e\u6d41\u548cN-1\u4e8b\u6545\u5206\u6790\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u503c\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cGridMind\u7cfb\u7edf\u5728IEEE\u6d4b\u8bd5\u6848\u4f8b\u4e0a\u6301\u7eed\u63d0\u4f9b\u6b63\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8f83\u5c0f\u7684LLMs\u5728\u51cf\u5c11\u8ba1\u7b97\u5ef6\u8fdf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u6bd4\u7684\u5206\u6790\u51c6\u786e\u6027\u3002\u8be5\u7814\u7a76\u5c06\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u786e\u7acb\u4e3a\u79d1\u5b66\u8ba1\u7b97\u7684\u53ef\u884c\u8303\u5f0f\uff0c\u5c55\u793a\u4e86\u5bf9\u8bdd\u754c\u9762\u5982\u4f55\u589e\u5f3a\u53ef\u8bbf\u95ee\u6027\u540c\u65f6\u4fdd\u6301\u5bf9\u5173\u952e\u5de5\u7a0b\u5e94\u7528\u81f3\u5173\u91cd\u8981\u7684\u6570\u503c\u4e25\u8c28\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86GridMind\uff0c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u786e\u5b9a\u6027\u5de5\u7a0b\u6c42\u89e3\u5668\u96c6\u6210\u5728\u4e00\u8d77\uff0c\u5b9e\u73b0\u5bf9\u7535\u529b\u7cfb\u7edf\u5206\u6790\u7684\u5bf9\u8bdd\u5f0f\u79d1\u5b66\u8ba1\u7b97\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u51fa\u7684\u667a\u80fd\u6846\u67b6\u5728\u6240\u6709\u6d4b\u8bd5\u7684\u8bed\u8a00\u6a21\u578b\u4e0a\u59cb\u7ec8\u63d0\u4f9b\u6b63\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8f83\u5c0f\u7684LLMs\u5728\u51cf\u5c11\u8ba1\u7b97\u5ef6\u8fdf\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u6bd4\u7684\u5206\u6790\u51c6\u786e\u6027\u3002"}}
{"id": "2509.02544", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.02544", "abs": "https://arxiv.org/abs/2509.02544", "authors": ["Haoming Wang", "Haoyang Zou", "Huatong Song", "Jiazhan Feng", "Junjie Fang", "Junting Lu", "Longxiang Liu", "Qinyu Luo", "Shihao Liang", "Shijue Huang", "Wanjun Zhong", "Yining Ye", "Yujia Qin", "Yuwen Xiong", "Yuxin Song", "Zhiyong Wu", "Bo Li", "Chen Dun", "Chong Liu", "Fuxing Leng", "Hanbin Wang", "Hao Yu", "Haobin Chen", "Hongyi Guo", "Jing Su", "Jingjia Huang", "Kai Shen", "Kaiyu Shi", "Lin Yan", "Peiyao Zhao", "Pengfei Liu", "Qinghao Ye", "Renjie Zheng", "Wayne Xin Zhao", "Wen Heng", "Wenhao Huang", "Wenqian Wang", "Xiaobo Qin", "Yi Lin", "Youbin Wu", "Zehui Chen", "Zihao Wang", "Baoquan Zhong", "Xinchun Zhang", "Xujing Li", "Yuanfan Li", "Zhongkai Zhao", "Chengquan Jiang", "Faming Wu", "Haotian Zhou", "Jinlin Pang", "Li Han", "Qianli Ma", "Siyao Liu", "Songhua Cai", "Wenqi Fu", "Xin Liu", "Zhi Zhang", "Bo Zhou", "Guoliang Li", "Jiajun Shi", "Jiale Yang", "Jie Tang", "Li Li", "Taoran Lu", "Woyu Lin", "Xiaokang Tong", "Xinyao Li", "Yichi Zhang", "Yu Miao", "Zhengxuan Jiang", "Zili Li", "Ziyuan Zhao", "Chenxin Li", "Dehua Ma", "Feng Lin", "Ge Zhang", "Haihua Yang", "Hangyu Guo", "Hongda Zhu", "Jiaheng Liu", "Junda Du", "Kai Cai", "Kuanye Li", "Lichen Yuan", "Meilan Han", "Minchao Wang", "Shuyue Guo", "Tianhao Cheng", "Xiaobo Ma", "Xiaojun Xiao", "Xiaolong Huang", "Xinjie Chen", "Yidi Du", "Yilin Chen", "Yiwen Wang", "Zhaojian Li", "Zhenzhu Yang", "Zhiyuan Zeng", "Chaolin Jin", "Chen Li", "Hao Chen", "Haoli Chen", "Jian Chen", "Qinghao Zhao", "Guang Shi"], "title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "comment": null, "summary": "The development of autonomous agents for graphical user interfaces (GUIs)\npresents major challenges in artificial intelligence. While recent advances in\nnative agent models have shown promise by unifying perception, reasoning,\naction, and memory through end-to-end learning, open problems remain in data\nscalability, multi-turn reinforcement learning (RL), the limitations of\nGUI-only operation, and environment stability. In this technical report, we\npresent UI-TARS-2, a native GUI-centered agent model that addresses these\nchallenges through a systematic training methodology: a data flywheel for\nscalable data generation, a stabilized multi-turn RL framework, a hybrid GUI\nenvironment that integrates file systems and terminals, and a unified sandbox\nplatform for large-scale rollouts. Empirical evaluation demonstrates that\nUI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.\nOn GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on\nWindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines\nsuch as Claude and OpenAI agents. In game environments, it attains a mean\nnormalized score of 59.8 across a 15-game suite-roughly 60% of human-level\nperformance-and remains competitive with frontier proprietary models (e.g.,\nOpenAI o3) on LMGame-Bench. Additionally, the model can generalize to\nlong-horizon information-seeking tasks and software engineering benchmarks,\nhighlighting its robustness across diverse agent tasks. Detailed analyses of\ntraining dynamics further provide insights into achieving stability and\nefficiency in large-scale agent RL. These results underscore UI-TARS-2's\npotential to advance the state of GUI agents and exhibit strong generalization\nto real-world interactive scenarios.", "AI": {"tldr": "Developed UI-TARS-2, a native GUI-centered agent model, to address challenges in autonomous agents for graphical user interfaces. UI-TARS-2 achieved significant improvements over UI-TARS-1.5, outperforming strong baselines on GUI benchmarks and game environments. It demonstrated generalization to diverse agent tasks and real-world interactive scenarios, showcasing its potential to advance GUI agent development.", "motivation": "Address the challenges in developing autonomous agents for graphical user interfaces, including data scalability, multi-turn reinforcement learning, GUI-only operation limitations, and environment stability. Aim to advance the state of GUI agents and demonstrate generalization to real-world interactive scenarios.", "method": "Developed UI-TARS-2, a native GUI-centered agent model addressing challenges in autonomous agents for graphical user interfaces. Implemented a systematic training methodology including a data flywheel for scalable data generation, stabilized multi-turn RL framework, hybrid GUI environment, and a unified sandbox platform for large-scale rollouts. Conducted empirical evaluation to compare with UI-TARS-1.5 and strong baselines on GUI benchmarks and game environments.", "result": "UI-TARS-2 achieved significant improvements over its predecessor and outperformed strong baselines on GUI benchmarks and game environments. It also demonstrated generalization to diverse agent tasks and software engineering benchmarks, showcasing robustness and potential for advancing GUI agent development.", "conclusion": "UI-TARS-2 achieved significant improvements over UI-TARS-1.5, outperforming strong baselines on GUI benchmarks and game environments. It demonstrated generalization to diverse agent tasks and real-world interactive scenarios, highlighting its potential to advance GUI agent development."}}
{"id": "2509.02547", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.02547", "abs": "https://arxiv.org/abs/2509.02547", "authors": ["Guibin Zhang", "Hejia Geng", "Xiaohang Yu", "Zhenfei Yin", "Zaibin Zhang", "Zelin Tan", "Heng Zhou", "Zhongzhi Li", "Xiangyuan Xue", "Yijiang Li", "Yifan Zhou", "Yang Chen", "Chen Zhang", "Yutao Fan", "Zihu Wang", "Songtao Huang", "Yue Liao", "Hongru Wang", "Mengyue Yang", "Heng Ji", "Michael Littman", "Jun Wang", "Shuicheng Yan", "Philip Torr", "Lei Bai"], "title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey", "comment": null, "summary": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm\nshift from conventional reinforcement learning applied to large language models\n(LLM RL), reframing LLMs from passive sequence generators into autonomous,\ndecision-making agents embedded in complex, dynamic worlds. This survey\nformalizes this conceptual shift by contrasting the degenerate single-step\nMarkov Decision Processes (MDPs) of LLM-RL with the temporally extended,\npartially observable Markov decision processes (POMDPs) that define Agentic RL.\nBuilding on this foundation, we propose a comprehensive twofold taxonomy: one\norganized around core agentic capabilities, including planning, tool use,\nmemory, reasoning, self-improvement, and perception, and the other around their\napplications across diverse task domains. Central to our thesis is that\nreinforcement learning serves as the critical mechanism for transforming these\ncapabilities from static, heuristic modules into adaptive, robust agentic\nbehavior. To support and accelerate future research, we consolidate the\nlandscape of open-source environments, benchmarks, and frameworks into a\npractical compendium. By synthesizing over five hundred recent works, this\nsurvey charts the contours of this rapidly evolving field and highlights the\nopportunities and challenges that will shape the development of scalable,\ngeneral-purpose AI agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8fd0\u7528\uff0c\u5bf9\u6bd4\u4e86LLM-RL\u548cAgentic RL\u7684\u7279\u70b9\uff0c\u63d0\u51fa\u4e86\u53cc\u91cd\u5206\u7c7b\u6cd5\uff0c\u603b\u7ed3\u4e86\u5f00\u6e90\u8d44\u6e90\uff0c\u52a0\u901f\u672a\u6765\u7814\u7a76\u3002\u7efc\u5408\u5206\u6790\u4e86\u4e94\u767e\u591a\u4e2a\u6700\u8fd1\u7684\u7814\u7a76\u6210\u679c\uff0c\u63cf\u7ed8\u4e86\u9886\u57df\u7684\u53d1\u5c55\u8f6e\u5ed3\uff0c\u7a81\u51fa\u673a\u9047\u548c\u6311\u6218\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u4ecb\u7ecd\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8LLMs\u548cAgentic RL\u4e4b\u95f4\u7684\u533a\u522b\u548c\u8054\u7cfb\uff0c\u63d0\u51fa\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u652f\u6301\u548c\u52a0\u901f\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u7c7b\u578b\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u754c\u5b9a\u4e86\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u7684\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u53cc\u91cd\u5206\u7c7b\u6cd5\u3002\u540c\u65f6\u603b\u7ed3\u4e86\u5f00\u6e90\u73af\u5883\u3001\u57fa\u51c6\u548c\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u652f\u6301\u548c\u52a0\u901f\u3002\u901a\u8fc7\u7efc\u5408\u5206\u6790\u4e94\u767e\u591a\u4e2a\u6700\u8fd1\u7684\u7814\u7a76\u6210\u679c\uff0c\u63cf\u7ed8\u4e86\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u8f6e\u5ed3\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u7684\u6982\u5ff5\u8f6c\u53d8\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u603b\u7ed3\u4e86\u5f00\u6e90\u8d44\u6e90\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002\u7efc\u5408\u5206\u6790\u4e86\u5927\u91cf\u7814\u7a76\u6210\u679c\uff0c\u63ed\u793a\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u8d8b\u52bf\u548c\u6311\u6218\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\uff08Agentic RL\uff09\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM RL\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u5c06LLMs\u4ece\u88ab\u52a8\u5e8f\u5217\u751f\u6210\u5668\u8f6c\u53d8\u4e3a\u5d4c\u5165\u5728\u590d\u6742\u52a8\u6001\u4e16\u754c\u4e2d\u7684\u81ea\u4e3b\u51b3\u7b56\u5236\u5b9a\u673a\u5668\u4eba\u3002\u901a\u8fc7\u5bf9\u6bd4LLM-RL\u4e2d\u7684\u5355\u6b65\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDPs\uff09\u548c\u5b9a\u4e49Agentic RL\u7684\u6682\u65f6\u5ef6\u4f38\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDPs\uff09\uff0c\u6b63\u5f0f\u754c\u5b9a\u4e86\u8fd9\u4e00\u6982\u5ff5\u8f6c\u53d8\u3002\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u7684\u53cc\u91cd\u5206\u7c7b\u6cd5\uff0c\u4e00\u4e2a\u56f4\u7ed5\u6838\u5fc3\u4ee3\u7406\u80fd\u529b\uff0c\u5305\u62ec\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u3001\u8bb0\u5fc6\u3001\u63a8\u7406\u3001\u81ea\u6211\u6539\u8fdb\u548c\u611f\u77e5\uff0c\u5e76\u53e6\u4e00\u4e2a\u56f4\u7ed5\u8fd9\u4e9b\u80fd\u529b\u5728\u4e0d\u540c\u4efb\u52a1\u9886\u57df\u7684\u5e94\u7528\u3002\u5f3a\u8c03\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u5c06\u8fd9\u4e9b\u80fd\u529b\u4ece\u9759\u6001\u3001\u542f\u53d1\u5f0f\u6a21\u5757\u8f6c\u53d8\u4e3a\u81ea\u9002\u5e94\u3001\u5f3a\u5065\u4ee3\u7406\u884c\u4e3a\u7684\u5173\u952e\u673a\u5236\u3002\u901a\u8fc7\u603b\u7ed3\u5f00\u6e90\u73af\u5883\u3001\u57fa\u51c6\u548c\u6846\u67b6\u7684\u73b0\u72b6\uff0c\u4e3a\u652f\u6301\u548c\u52a0\u901f\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8d44\u6599\uff0c\u901a\u8fc7\u7efc\u5408\u4e94\u767e\u591a\u4e2a\u6700\u8fd1\u7684\u7814\u7a76\u6210\u679c\uff0c\u63cf\u7ed8\u4e86\u8fd9\u4e00\u5feb\u901f\u53d1\u5c55\u9886\u57df\u7684\u8f6e\u5ed3\uff0c\u5e76\u7a81\u51fa\u4e86\u5c06\u5851\u9020\u53ef\u6269\u5c55\u7684\u901a\u7528AI\u4ee3\u7406\u7684\u673a\u9047\u548c\u6311\u6218\u3002"}}
