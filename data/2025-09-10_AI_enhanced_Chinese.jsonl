{"id": "2509.07011", "categories": ["cs.AI", "03E72, 94D05,"], "pdf": "https://arxiv.org/pdf/2509.07011", "abs": "https://arxiv.org/abs/2509.07011", "authors": ["Kirisci Murat"], "title": "Renewable Energy Sources Selection Analysis with the Maximizing Deviation Method", "comment": "25 pages, 5 figures, 6 Tables", "summary": "Multi-criteria decision-making methods provide decision-makers with\nappropriate tools to make better decisions in uncertain, complex, and\nconflicting situations. Fuzzy set theory primarily deals with the uncertainty\ninherent in human thoughts and perceptions and attempts to quantify this\nuncertainty. Fuzzy logic and fuzzy set theory are utilized with multi-criteria\ndecision-making methods because they effectively handle uncertainty and\nfuzziness in decision-makers' judgments, allowing for verbal judgments of the\nproblem. This study utilizes the Fermatean fuzzy environment, a generalization\nof fuzzy sets. An optimization model based on the deviation maximization method\nis proposed to determine partially known feature weights. This method is\ncombined with interval-valued Fermatean fuzzy sets. The proposed method was\napplied to the problem of selecting renewable energy sources. The reason for\nchoosing renewable energy sources is that meeting energy needs from renewable\nsources, balancing carbon emissions, and mitigating the effects of global\nclimate change are among the most critical issues of the recent period. Even\nthough selecting renewable energy sources is a technical issue, the managerial\nand political implications of this issue are also important, and are discussed\nin this study.", "AI": {"tldr": "\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u4e0eFuzzy set\u7406\u8bba\u76f8\u7ed3\u5408\uff0c\u5229\u7528Fermatean\u6a21\u7cca\u73af\u5883\u548c\u504f\u5dee\u6700\u5927\u5316\u65b9\u6cd5\u63d0\u51fa\u4f18\u5316\u6a21\u578b\uff0c\u5e94\u7528\u4e8e\u9009\u62e9\u53ef\u518d\u751f\u80fd\u6e90\u95ee\u9898\uff0c\u53d6\u5f97\u79ef\u6781\u6210\u6548\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u5904\u7406\u51b3\u7b56\u8005\u5728\u4e0d\u786e\u5b9a\u3001\u590d\u6742\u548c\u77db\u76fe\u60c5\u5883\u4e2d\u505a\u51fa\u66f4\u597d\u51b3\u7b56\u7684\u5de5\u5177\uff0cFuzzy set\u7406\u8bba\u5219\u4e3b\u8981\u5e94\u5bf9\u4eba\u7c7b\u601d\u60f3\u548c\u611f\u77e5\u4e2d\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u8bd5\u56fe\u91cf\u5316\u6b64\u4e0d\u786e\u5b9a\u6027\u3002Fuzzy logic\u548cFuzzy set\u7406\u8bba\u4e0e\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\u7ed3\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u5904\u7406\u51b3\u7b56\u8005\u5224\u65ad\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u6a21\u7cca\u6027\uff0c\u5141\u8bb8\u53e3\u5934\u5224\u65ad\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528Fermatean\u6a21\u7cca\u73af\u5883\u548c\u504f\u5dee\u6700\u5927\u5316\u65b9\u6cd5\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f18\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u786e\u5b9a\u90e8\u5206\u5df2\u77e5\u7279\u5f81\u6743\u91cd\uff0c\u5e76\u7ed3\u5408\u533a\u95f4\u503cFermatean\u6a21\u7cca\u96c6\u3002", "result": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9009\u62e9\u53ef\u518d\u751f\u80fd\u6e90\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u79ef\u6781\u6210\u6548\uff0c\u5e94\u5bf9\u80fd\u6e90\u9700\u6c42\u3001\u78b3\u6392\u653e\u548c\u5168\u7403\u6c14\u5019\u53d8\u5316\u7b49\u91cd\u8981\u95ee\u9898\u8d77\u5230\u4e86\u91cd\u8981\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u5229\u7528Fermatean\u6a21\u7cca\u73af\u5883\u548c\u57fa\u4e8e\u504f\u5dee\u6700\u5927\u5316\u65b9\u6cd5\u7684\u4f18\u5316\u6a21\u578b\u6765\u786e\u5b9a\u90e8\u5206\u5df2\u77e5\u7279\u5f81\u6743\u91cd\uff0c\u7ed3\u5408\u533a\u95f4\u503cFermatean\u6a21\u7cca\u96c6\u3002\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u9009\u62e9\u53ef\u518d\u751f\u80fd\u6e90\u95ee\u9898\uff0c\u4ee5\u6ee1\u8db3\u80fd\u6e90\u9700\u6c42\u3001\u5e73\u8861\u78b3\u6392\u653e\u548c\u7f13\u89e3\u5168\u7403\u6c14\u5019\u53d8\u5316\u7b49\u91cd\u8981\u95ee\u9898\u3002\u7814\u7a76\u8ba8\u8bba\u4e86\u9009\u62e9\u53ef\u518d\u751f\u80fd\u6e90\u7684\u6280\u672f\u3001\u7ba1\u7406\u548c\u653f\u6cbb\u5f71\u54cd\u3002"}}
{"id": "2509.07017", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.07017", "abs": "https://arxiv.org/abs/2509.07017", "authors": ["Andrew Kiruluta", "Priscilla Burity"], "title": "From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning", "comment": null, "summary": "We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning\nframework that embeds logical rules as spectral templates and performs\ninference directly in the graph spectral domain. By leveraging graph signal\nprocessing (GSP) and frequency-selective filters grounded in the Laplacian\neigenstructure of knowledge graphs, the architecture unifies the\ninterpretability of symbolic reasoning with the scalability and adaptability of\nspectral learning. Beyond the core formulation, we incorporate a comprehensive\nset of extensions, including dynamic graph and basis learning, rational and\ndiffusion filters for sharper spectral selectivity, mixture-of-spectral-experts\nfor modular specialization, proof-guided training with spectral curricula, and\nuncertainty quantification for calibrated confidence. Additional enhancements\nsuch as large language model coupling, co-spectral transfer alignment,\nadversarial robustness, efficient GPU kernels, generalized Laplacians, and\ncausal interventions further expand the versatility of the framework.\n  Empirical evaluation on state-of-the-art reasoning benchmarks such as\nProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior\naccuracy, faster inference, improved robustness to adversarial perturbations,\nand higher interpretability compared to leading baselines including\ntransformers, message-passing neural networks, and neuro-symbolic logic\nprogramming systems. Spectral attribution and proof-band agreement analyses\nconfirm that model decisions align closely with symbolic proof structures,\nwhile transfer experiments validate effective domain adaptation through\nco-spectral alignment. These results establish Spectral NSR as a scalable and\nprincipled foundation for the next generation of reasoning systems, offering\ntransparency, robustness, and generalization beyond conventional approaches.", "AI": {"tldr": "Spectral NSR is a neuro-symbolic reasoning framework that combines symbolic reasoning with spectral learning, achieving superior accuracy, faster inference, and higher interpretability. It offers transparency, robustness, and generalization beyond traditional approaches, validated through empirical evaluations on reasoning benchmarks.", "motivation": "To unify the interpretability of symbolic reasoning with the scalability and adaptability of spectral learning. Incorporating extensions like dynamic graph and basis learning, rational and diffusion filters, proof-guided training, and uncertainty quantification for improved performance.", "method": "Introducing Spectral NSR, a fully spectral neuro-symbolic reasoning framework that embeds logical rules as spectral templates and performs inference directly in the graph spectral domain. Leveraging graph signal processing and frequency-selective filters based on Laplacian eigenstructure of knowledge graphs.", "result": "Empirical evaluation showed that Spectral NSR achieves superior accuracy, faster inference, improved robustness, and higher interpretability compared to leading baselines. Model decisions align closely with symbolic proof structures, and domain adaptation is effective through co-spectral alignment.", "conclusion": "Spectral NSR is a scalable and principled foundation for the next generation of reasoning systems, offering transparency, robustness, and generalization beyond conventional approaches."}}
{"id": "2509.07054", "categories": ["cs.AI", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.07054", "abs": "https://arxiv.org/abs/2509.07054", "authors": ["Edgar Dobriban"], "title": "Statistical Methods in Generative AI", "comment": "Invited review paper for Annual Review of Statistics and Its\n  Application. Feedback welcome", "summary": "Generative Artificial Intelligence is emerging as an important technology,\npromising to be transformative in many areas. At the same time, generative AI\ntechniques are based on sampling from probabilistic models, and by default,\nthey come with no guarantees about correctness, safety, fairness, or other\nproperties. Statistical methods offer a promising potential approach to improve\nthe reliability of generative AI techniques. In addition, statistical methods\nare also promising for improving the quality and efficiency of AI evaluation,\nas well as for designing interventions and experiments in AI.\n  In this paper, we review some of the existing work on these topics,\nexplaining both the general statistical techniques used, as well as their\napplications to generative AI. We also discuss limitations and potential future\ndirections.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u73b0\u6709\u7684\u5de5\u4f5c\uff0c\u63a2\u8ba8\u4e86\u7edf\u8ba1\u65b9\u6cd5\u5728\u751f\u6210\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u5e94\u7528\u4ee5\u53ca\u5176\u6f5c\u5728\u5f71\u54cd\u3002\u8ba8\u8bba\u4e86\u6539\u5584\u53ef\u9760\u6027\u3001\u8bc4\u4f30\u8d28\u91cf\u548c\u8bbe\u8ba1\u5e72\u9884\u7b49\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u4e9b\u672a\u6765\u53d1\u5c55\u65b9\u5411\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u751f\u6210\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5174\u8d77\u4f7f\u5176\u5728\u8bb8\u591a\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u7f3a\u4e4f\u6b63\u786e\u6027\u3001\u5b89\u5168\u6027\u3001\u516c\u5e73\u6027\u7b49\u65b9\u9762\u7684\u4fdd\u8bc1\u3002\u7edf\u8ba1\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u6539\u5584\u751f\u6210\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53ef\u9760\u6027\u7684\u6f5c\u5728\u9014\u5f84\u3002\u6b64\u5916\uff0c\u7edf\u8ba1\u65b9\u6cd5\u4e5f\u80fd\u591f\u6539\u5584\u4eba\u5de5\u667a\u80fd\u8bc4\u4f30\u7684\u8d28\u91cf\u548c\u6548\u7387\uff0c\u4ee5\u53ca\u5728\u4eba\u5de5\u667a\u80fd\u5e72\u9884\u548c\u5b9e\u9a8c\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u901a\u8fc7\u56de\u987e\u73b0\u6709\u5de5\u4f5c\uff0c\u89e3\u91ca\u4e86\u4e00\u822c\u7edf\u8ba1\u6280\u672f\u4ee5\u53ca\u5b83\u4eec\u5728\u751f\u6210\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u901a\u8fc7\u56de\u987e\u73b0\u6709\u5de5\u4f5c\uff0c\u672c\u6587\u63ed\u793a\u4e86\u7edf\u8ba1\u65b9\u6cd5\u5bf9\u751f\u6210\u4eba\u5de5\u667a\u80fd\u7684\u6f5c\u5728\u5f71\u54cd\u548c\u5e94\u7528\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u4e00\u4e9b\u5c40\u9650\u6027\u548c\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u56de\u987e\u73b0\u6709\u5de5\u4f5c\uff0c\u63a2\u8ba8\u4e86\u7edf\u8ba1\u65b9\u6cd5\u5728\u6539\u5584\u751f\u6210\u4eba\u5de5\u667a\u80fd\u53ef\u9760\u6027\u4ee5\u53ca\u63d0\u9ad8\u8bc4\u4f30\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\u3002\u540c\u65f6\uff0c\u8fd8\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u8bbe\u8ba1\u5e72\u9884\u548c\u5b9e\u9a8c\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2509.07098", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.07098", "abs": "https://arxiv.org/abs/2509.07098", "authors": ["Yinheng Li", "Hailey Hultquist", "Justin Wagle", "Kazuhito Koishida"], "title": "Instruction Agent: Enhancing Agent with Expert Demonstration", "comment": null, "summary": "Graphical user interface (GUI) agents have advanced rapidly but still\nstruggle with complex tasks involving novel UI elements, long-horizon actions,\nand personalized trajectories. In this work, we introduce Instruction Agent, a\nGUI agent that leverages expert demonstrations to solve such tasks, enabling\ncompletion of otherwise difficult workflows. Given a single demonstration, the\nagent extracts step-by-step instructions and executes them by strictly\nfollowing the trajectory intended by the user, which avoids making mistakes\nduring execution. The agent leverages the verifier and backtracker modules\nfurther to improve robustness. Both modules are critical to understand the\ncurrent outcome from each action and handle unexpected interruptions(such as\npop-up windows) during execution. Our experiments show that Instruction Agent\nachieves a 60% success rate on a set of tasks in OSWorld that all top-ranked\nagents failed to complete. The Instruction Agent offers a practical and\nextensible framework, bridging the gap between current GUI agents and reliable\nreal-world GUI task automation.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Instruction Agent\uff0c\u5229\u7528\u4e13\u5bb6\u6f14\u793a\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff0c\u6210\u529f\u7387\u8fbe60%\uff0c\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u7684GUI\u4ee3\u7406\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u548c\u4e2a\u6027\u5316\u8f68\u8ff9\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u672c\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u63d0\u53d6\u9010\u6b65\u6307\u5357\u5e76\u4e25\u683c\u6267\u884c\u7528\u6237\u610f\u56fe\u8f68\u8ff9\uff0c\u907f\u514d\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\uff0c\u5229\u7528\u9a8c\u8bc1\u5668\u548c\u56de\u6eaf\u5668\u6a21\u5757\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "result": "Instruction Agent\u5728OSWorld\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e8660%\u7684\u6210\u529f\u7387\uff0c\u660e\u663e\u4f18\u4e8e\u5176\u4ed6\u9876\u7ea7\u4ee3\u7406\u3002\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5f25\u5408\u4e86\u5f53\u524dGUI\u4ee3\u7406\u548c\u53ef\u9760\u5b9e\u9645GUI\u4efb\u52a1\u81ea\u52a8\u5316\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u4e13\u5bb6\u6f14\u793a\u7684GUI\u4ee3\u7406Instruction Agent\uff0c\u80fd\u591f\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff0c\u63d0\u9ad8\u6210\u529f\u7387\u3002"}}
{"id": "2509.07122", "categories": ["cs.AI", "cs.CL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2509.07122", "abs": "https://arxiv.org/abs/2509.07122", "authors": ["Sania Sinha", "Tanawan Premsri", "Danial Kamali", "Parisa Kordjamshidi"], "title": "Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis", "comment": null, "summary": "Neurosymbolic (NeSy) frameworks combine neural representations and learning\nwith symbolic representations and reasoning. Combining the reasoning\ncapacities, explainability, and interpretability of symbolic processing with\nthe flexibility and power of neural computing allows us to solve complex\nproblems with more reliability while being data-efficient. However, this\nrecently growing topic poses a challenge to developers with its learning curve,\nlack of user-friendly tools, libraries, and unifying frameworks. In this paper,\nwe characterize the technical facets of existing NeSy frameworks, such as the\nsymbolic representation language, integration with neural models, and the\nunderlying algorithms. A majority of the NeSy research focuses on algorithms\ninstead of providing generic frameworks for declarative problem specification\nto leverage problem solving. To highlight the key aspects of Neurosymbolic\nmodeling, we showcase three generic NeSy frameworks - \\textit{DeepProbLog},\n\\textit{Scallop}, and \\textit{DomiKnowS}. We identify the challenges within\neach facet that lay the foundation for identifying the expressivity of each\nframework in solving a variety of problems. Building on this foundation, we aim\nto spark transformative action and encourage the community to rethink this\nproblem in novel ways.", "AI": {"tldr": "Neurosymbolic (NeSy) frameworks combine neural and symbolic reasoning for efficient problem-solving, facing challenges like the learning curve and lack of user-friendly tools. Existing NeSy frameworks focus more on algorithms than problem specifications. This paper characterizes NeSy frameworks, showcases DeepProbLog, Scallop, and DomiKnowS, and encourages innovative thinking in Neurosymbolic modeling.", "motivation": "To address the challenges and technical aspects of Neurosymbolic (NeSy) frameworks, provide insights into existing NeSy frameworks' strengths and limitations, and encourage the community to rethink approaches to Neurosymbolic modeling in more innovative ways.", "method": "Characterization of technical facets of existing NeSy frameworks, analysis of symbolic representation language, integration with neural models, and underlying algorithms. Showcase of three generic NeSy frameworks to demonstrate the expressivity in solving various problems.", "result": "Identification of challenges within existing NeSy frameworks, analysis of expressivity in problem-solving using DeepProbLog, Scallop, and DomiKnowS, and a call to action to stimulate transformative thinking in the NeSy research community.", "conclusion": "Neurosymbolic (NeSy) frameworks combine neural representations and symbolic reasoning to solve complex problems efficiently, but face challenges such as the learning curve and lack of user-friendly tools. Existing NeSy frameworks focus more on algorithms than providing declarative problem specifications. This paper characterizes technical aspects of NeSy frameworks and showcases three generic frameworks - DeepProbLog, Scallop, and DomiKnowS - to highlight key aspects of Neurosymbolic modeling."}}
{"id": "2509.07146", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07146", "abs": "https://arxiv.org/abs/2509.07146", "authors": ["Farnoush Baghestani", "Jihye Moon", "Youngsun Kong", "Ki Chon"], "title": "Autoencoder-Based Denoising of Muscle Artifacts in ECG to Preserve Skin Nerve Activity (SKNA) for Cognitive Stress Detection", "comment": "11 pages, 7 figures, 6 tables", "summary": "The sympathetic nervous system (SNS) plays a central role in regulating the\nbody's responses to stress and maintaining physiological stability. Its\ndysregulation is associated with a wide range of conditions, from\ncardiovascular disease to anxiety disorders. Skin nerve activity (SKNA)\nextracted from high-frequency electrocardiogram (ECG) recordings provides a\nnoninvasive window into SNS dynamics, but its measurement is highly susceptible\nto electromyographic (EMG) contamination. Traditional preprocessing based on\nbandpass filtering within a fixed range (e.g., 500--1000 Hz) is susceptible to\noverlapping EMG and SKNA spectral components, especially during sustained\nmuscle activity. We present a denoising approach using a lightweight\none-dimensional convolutional autoencoder with a long short-term memory (LSTM)\nbottleneck to reconstruct clean SKNA from EMG-contaminated recordings. Using\nclean ECG-derived SKNA data from cognitive stress experiments and EMG noise\nfrom chaotic muscle stimulation recordings, we simulated contamination at\nrealistic noise levels (--4 dB, --8 dB signal-to-noise ratio) and trained the\nmodel in the leave-one-subject-out cross-validation framework. The method\nimproved signal-to-noise ratio by up to 9.65 dB, increased cross correlation\nwith clean SKNA from 0.40 to 0.72, and restored burst-based SKNA features to\nnear-clean discriminability (AUROC $\\geq$ 0.96). Classification of baseline\nversus sympathetic stimulation (cognitive stress) conditions reached accuracies\nof 91--98\\% across severe noise levels, comparable to clean data. These results\ndemonstrate that deep learning--based reconstruction can preserve\nphysiologically relevant sympathetic bursts during substantial EMG\ninterference, enabling more robust SKNA monitoring in naturalistic,\nmovement-rich environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4f7f\u7528\u4e00\u7ef4\u5377\u79ef\u81ea\u7f16\u7801\u5668\u548cLSTM\u74f6\u9888\u6784\u5efa\u4e86\u4e00\u79cd\u53bb\u566a\u65b9\u6cd5\uff0c\u4ee5\u91cd\u5efa\u5e72\u51c0\u7684SKNA\u6570\u636e\u3002\u5728\u6a21\u62df\u4e86\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4fe1\u566a\u6bd4\uff0c\u589e\u52a0\u4e86\u4e0e\u5e72\u51c0SKNA\u7684\u76f8\u5173\u6027\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u7684\u6761\u4ef6\u5206\u7c7b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u91cd\u5efa\u65b9\u6cd5\u5bf9\u4e8e\u5728\u5b58\u5728EMG\u5e72\u6270\u65f6\u4fdd\u7559\u751f\u7406\u76f8\u5173\u7684\u4ea4\u611f\u7a81\u53d1\u975e\u5e38\u6709\u6548\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5e26\u901a\u6ee4\u6ce2\u7684\u9884\u5904\u7406\u65b9\u6cd5\u5728\u56fa\u5b9a\u8303\u56f4\u5185\uff08\u5982500-1000 Hz\uff09\u6613\u53d7\u91cd\u53e0\u7684EMG\u548cSKNA\u9891\u8c31\u5206\u91cf\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u5728\u6301\u7eed\u808c\u8089\u6d3b\u52a8\u671f\u95f4\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u79cd\u6311\u6218\uff0c\u4ee5\u6539\u5584SKNA\u76d1\u6d4b\u7684\u53ef\u9760\u6027\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u566a\u65b9\u6cd5\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4e00\u7ef4\u5377\u79ef\u81ea\u7f16\u7801\u5668\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u74f6\u9888\u6765\u4eceEMG\u6c61\u67d3\u7684\u8bb0\u5f55\u4e2d\u91cd\u5efa\u5e72\u51c0\u7684SKNA\u3002\u4ed6\u4eec\u5728\u8ba4\u77e5\u538b\u529b\u8bd5\u9a8c\u4e2d\u4f7f\u7528\u5e72\u51c0\u7684ECG\u884d\u751fSKNA\u6570\u636e\u548c\u6765\u81ea\u6df7\u6c8c\u808c\u8089\u523a\u6fc0\u5f55\u97f3\u7684EMG\u566a\u58f0\u8fdb\u884c\u4e86\u6a21\u62df\uff0c\u5e76\u5728\u7559\u4e00\u5b50\u4f53\u5916\u4ea4\u53c9\u9a8c\u8bc1\u6846\u67b6\u4e2d\u8bad\u7ec3\u4e86\u6a21\u578b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4fe1\u566a\u6bd4\u65b9\u9762\u63d0\u9ad8\u4e86\u957f\u8fbe9.65 dB\uff0c\u5728\u4e0e\u5e72\u51c0SKNA\u7684\u4ea4\u53c9\u76f8\u5173\u6027\u4ece0.40\u589e\u52a0\u81f30.72\uff0c\u5e76\u5c06\u57fa\u4e8e\u7a81\u53d1\u7684SKNA\u7279\u5f81\u6062\u590d\u5230\u63a5\u8fd1\u5e72\u51c0\u7684\u53ef\u533a\u5206\u6027\uff08AUROC \u2265 0.96\uff09\u3002\u5728\u4e25\u91cd\u566a\u58f0\u6c34\u5e73\u4e0b\uff0c\u57fa\u7ebf\u4e0e\u4ea4\u611f\u523a\u6fc0\u6761\u4ef6\u7684\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u5230\u4e8691-98\uff05\uff0c\u4e0e\u5e72\u51c0\u6570\u636e\u76f8\u5f53\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u91cd\u5efa\u65b9\u6cd5\u53ef\u4ee5\u5728\u5b58\u5728\u5927\u91cfEMG\u5e72\u6270\u7684\u60c5\u51b5\u4e0b\u4fdd\u7559\u751f\u7406\u76f8\u5173\u7684\u4ea4\u611f\u7a81\u53d1\uff0c\u4ece\u800c\u5b9e\u73b0\u5728\u81ea\u7136\u3001\u5145\u6ee1\u8fd0\u52a8\u7684\u73af\u5883\u4e2d\u66f4\u7a33\u5065\u7684\u76ae\u80a4\u795e\u7ecf\u6d3b\u52a8\uff08SKNA\uff09\u76d1\u6d4b\u3002"}}
{"id": "2509.07159", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07159", "abs": "https://arxiv.org/abs/2509.07159", "authors": ["Heng Hao", "Wenjun Hu", "Oxana Verkholyak", "Davoud Ataee Tarzanagh", "Baruch Gutow", "Sima Didari", "Masoud Faraki", "Hankyu Moon", "Seungjai Min"], "title": "PaVeRL-SQL: Text-to-SQL via Partial-Match Rewards and Verbal Reinforcement Learning", "comment": "10 pages", "summary": "Text-to-SQL models allow users to interact with a database more easily by\ngenerating executable SQL statements from natural-language questions. Despite\nrecent successes on simpler databases and questions, current Text-to-SQL\nmethods still suffer from low execution accuracy on industry-scale databases\nand complex questions involving domain-specific business logic. We present\n\\emph{PaVeRL-SQL}, a framework that combines \\emph{Partial-Match Rewards} and\n\\emph{Verbal Reinforcement Learning} to drive self-improvement in reasoning\nlanguage models (RLMs) for Text-to-SQL. To handle practical use cases, we adopt\ntwo pipelines: (1) a newly designed in-context learning framework with group\nself-evaluation (verbal-RL), using capable open- and closed-source large\nlanguage models (LLMs) as backbones; and (2) a chain-of-thought (CoT) RL\npipeline with a small backbone model (OmniSQL-7B) trained with a specially\ndesigned reward function and two-stage RL. These pipelines achieve\nstate-of-the-art (SOTA) results on popular Text-to-SQL benchmarks -- Spider,\nSpider 2.0, and BIRD. For the industrial-level Spider2.0-SQLite benchmark, the\nverbal-RL pipeline achieves an execution accuracy 7.4\\% higher than SOTA, and\nthe CoT pipeline is 1.4\\% higher. RL training with mixed SQL dialects yields\nstrong, threefold gains, particularly for dialects with limited training data.\nOverall, \\emph{PaVeRL-SQL} delivers reliable, SOTA Text-to-SQL under realistic\nindustrial constraints. The code is available at\nhttps://github.com/PaVeRL-SQL/PaVeRL-SQL.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86PaVeRL-SQL\u6846\u67b6\uff0c\u7ed3\u5408\u90e8\u5206\u5339\u914d\u5956\u52b1\u548c\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\uff0c\u7528\u4e8e\u6539\u5584Text-to-SQL\u6a21\u578b\u7684\u6267\u884c\u51c6\u786e\u6027\u3002\u901a\u8fc7\u4f7f\u7528\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\u6d41\u7a0b\u548c\u601d\u7ef4\u94feRL\u6d41\u7a0b\uff0c\u5728Spider\u3001Spider 2.0\u548cBIRD\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002\u5728\u5de5\u4e1a\u7ea7Spider2.0-SQLite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\u6d41\u7a0b\u6bd4SOTA\u9ad8\u51fa7.4\uff05\uff0cCoT\u6d41\u7a0b\u9ad8\u51fa1.4\uff05\u3002\u6df7\u5408SQL\u65b9\u8a00\u8bad\u7ec3\u53d6\u5f97\u4e86\u5f3a\u5927\u7684\u4e09\u500d\u589e\u76ca\u3002", "motivation": "\u5f53\u524d\u7684Text-to-SQL\u65b9\u6cd5\u5728\u5904\u7406\u5de5\u4e1a\u89c4\u6a21\u6570\u636e\u5e93\u548c\u6d89\u53ca\u9886\u57df\u7279\u5b9a\u4e1a\u52a1\u903b\u8f91\u7684\u590d\u6742\u95ee\u9898\u65f6\u6267\u884c\u51c6\u786e\u6027\u4e0d\u9ad8\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u9ad8Text-to-SQL\u6a21\u578b\u7684\u6267\u884c\u51c6\u786e\u6027\uff0c\u5e76\u9488\u5bf9\u5b9e\u9645\u7528\u4f8b\u91c7\u7528\u5408\u9002\u7684\u6d41\u7a0b\u548c\u80cc\u666f\u6a21\u578b\u3002", "method": "\u7ed3\u5408\u90e8\u5206\u5339\u914d\u5956\u52b1\u548c\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\u521b\u5efaPaVeRL-SQL\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u4e2a\u6d41\u7a0b\uff1a\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\uff08verbal-RL\uff09\u6d41\u7a0b\u548c\u601d\u7ef4\u94fe\uff08CoT\uff09RL\u6d41\u7a0b\u3002\u91c7\u7528\u80fd\u80cc\u666f\u6a21\u578b\uff08LLMs\uff09\u548c\u5c0f\u80cc\u666f\u6a21\u578b\uff08OmniSQL-7B\uff09\uff0c\u4f7f\u7528\u7279\u6b8a\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\u548c\u4e24\u9636\u6bb5RL\u8fdb\u884c\u8bad\u7ec3\u3002\u4f7f\u7528\u6df7\u5408SQL\u65b9\u8a00\u8fdb\u884cRL\u8bad\u7ec3\u3002", "result": "PaVeRL-SQL\u5728Spider\u3001Spider 2.0\u548cBIRD\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5728\u5de5\u4e1a\u7ea7Spider2.0-SQLite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\uff08verbal-RL\uff09\u6d41\u7a0b\u7684\u6267\u884c\u51c6\u786e\u5ea6\u6bd4SOTA\u9ad8\u51fa7.4\uff05\uff0c\u800cCoT\u6d41\u7a0b\u9ad8\u51fa1.4\uff05\u3002\u6df7\u5408SQL\u65b9\u8a00\u8bad\u7ec3\u53d6\u5f97\u4e86\u5f3a\u5927\u7684\u4e09\u500d\u589e\u76ca\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86PaVeRL-SQL\u6846\u67b6\uff0c\u7ed3\u5408\u90e8\u5206\u5339\u914d\u5956\u52b1\u548c\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\uff0c\u7528\u4e8e\u9a71\u52a8\u5728Text-to-SQL\u4e2d\u63a8\u7406\u8bed\u8a00\u6a21\u578b\uff08RLMs\uff09\u7684\u81ea\u6211\u6539\u8fdb\u3002\u901a\u8fc7\u91c7\u7528\u4e24\u79cd\u6d41\u7a0b\uff0c\u8be5\u6846\u67b6\u5728\u6d41\u884c\u7684Text-to-SQL\u57fa\u51c6\u6570\u636e\u96c6\uff08Spider\u3001Spider 2.0\u548cBIRD\uff09\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002\u5728\u5de5\u4e1a\u7ea7Spider2.0-SQLite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\uff08verbal-RL\uff09\u6d41\u7a0b\u7684\u6267\u884c\u51c6\u786e\u5ea6\u6bd4SOTA\u9ad8\u51fa7.4\uff05\uff0c\u800cCoT\u6d41\u7a0b\u9ad8\u51fa1.4\uff05\u3002\u4f7f\u7528\u6df7\u5408SQL\u65b9\u8a00\u8fdb\u884cRL\u8bad\u7ec3\u53d6\u5f97\u4e86\u5f3a\u5927\u7684\u4e09\u500d\u589e\u76ca\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u65b9\u8a00\u3002\u603b\u4f53\u800c\u8a00\uff0cPaVeRL-SQL\u5728\u73b0\u5b9e\u5de5\u4e1a\u7ea6\u675f\u6761\u4ef6\u4e0b\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u3001\u6700\u5148\u8fdb\u7684Text-to-SQL\u3002"}}
{"id": "2509.07170", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.07170", "abs": "https://arxiv.org/abs/2509.07170", "authors": ["Quinten Steenhuis"], "title": "That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral", "comment": "Submission to JURIX 2025", "summary": "Each year millions of people seek help for their legal problems by calling a\nlegal aid program hotline, walking into a legal aid office, or using a lawyer\nreferral service. The first step to match them to the right help is to identify\nthe legal problem the applicant is experiencing. Misdirection has consequences.\nApplicants may miss a deadline, experience physical abuse, lose housing or lose\ncustody of children while waiting to connect to the right legal help. We\nintroduce and evaluate the FETCH classifier for legal issue classification and\ndescribe two methods for improving accuracy: a hybrid LLM/ML ensemble\nclassification method, and the automatic generation of follow-up questions to\nenrich the initial problem narrative. We employ a novel data set of 419\nreal-world queries to a nonprofit lawyer referral service. Ultimately, we show\nclassification accuracy (hits@2) of 97.37\\% using a mix of inexpensive models,\nexceeding the performance of the current state-of-the-art GPT-5 model. Our\napproach shows promise in significantly reducing the cost of guiding users of\nthe legal system to the right resource for their problem while achieving high\naccuracy.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86FETCH\u5206\u7c7b\u5668\u7528\u4e8e\u6cd5\u5f8b\u95ee\u9898\u5206\u7c7b\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528419\u4e2a\u771f\u5b9e\u67e5\u8be2\u6570\u636e\u96c6\u5c55\u793a\u4e86\u9ad8\u8fbe97.37%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u7528\u6237\u5f15\u5bfc\u6210\u672c\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5728\u4e3a\u6cd5\u5f8b\u95ee\u9898\u60a3\u8005\u63d0\u4f9b\u5e2e\u52a9\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u95ee\u9898\uff0c\u5982\u9519\u5931\u622a\u6b62\u65e5\u671f\u3001\u906d\u53d7\u8eab\u4f53\u8650\u5f85\u3001\u5931\u53bb\u4f4f\u623f\u6216\u5931\u53bb\u76d1\u62a4\u6743\u3002\u6b63\u786e\u5206\u7c7b\u548c\u5f15\u5bfc\u7528\u6237\u5230\u5408\u9002\u7684\u8d44\u6e90\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u8fd9\u4e9b\u95ee\u9898\u7684\u53d1\u751f\uff0c\u5e76\u964d\u4f4e\u7528\u6237\u5f15\u5bfc\u6210\u672c\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528FETCH\u5206\u7c7b\u5668\u8fdb\u884c\u6cd5\u5f8b\u95ee\u9898\u5206\u7c7b\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6539\u8fdb\u51c6\u786e\u6027\u7684\u65b9\u6cd5\uff1aLLM/ML\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\u548c\u81ea\u52a8\u751f\u6210\u540e\u7eed\u95ee\u9898\u3002\u7814\u7a76\u4f7f\u7528\u4e86419\u4e2a\u771f\u5b9e\u67e5\u8be2\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5c55\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "result": "\u7814\u7a76\u901a\u8fc7\u6df7\u5408LLM/ML\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\u548c\u81ea\u52a8\u751f\u6210\u540e\u7eed\u95ee\u9898\uff0c\u5b9e\u73b0\u4e8697.37%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684GPT-5\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u548c\u8bc4\u4f30\u4e86\u7528\u4e8e\u6cd5\u5f8b\u95ee\u9898\u5206\u7c7b\u7684FETCH\u5206\u7c7b\u5668\uff0c\u5e76\u63cf\u8ff0\u4e86\u6539\u8fdb\u51c6\u786e\u6027\u7684\u4e24\u79cd\u65b9\u6cd5\uff1a\u6df7\u5408LLM/ML\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\u4ee5\u53ca\u81ea\u52a8\u751f\u6210\u540e\u7eed\u95ee\u9898\u4ee5\u4e30\u5bcc\u521d\u59cb\u95ee\u9898\u53d9\u8ff0\u3002\u7814\u7a76\u8868\u660e\uff0c\u5728\u975e\u8425\u5229\u5f8b\u5e08\u8f6c\u4ecb\u670d\u52a1\u7684419\u4e2a\u771f\u5b9e\u67e5\u8be2\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u5ec9\u4ef7\u6a21\u578b\u7684\u7ec4\u5408\u5b9e\u73b0\u4e8697.37%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff08hits@2\uff09\uff0c\u8d85\u8fc7\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684GPT-5\u6a21\u578b\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u663e\u793a\u4e86\u5728\u663e\u8457\u964d\u4f4e\u6cd5\u5f8b\u7cfb\u7edf\u7528\u6237\u5f15\u5bfc\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u7684\u524d\u666f\u3002"}}
{"id": "2509.07208", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07208", "abs": "https://arxiv.org/abs/2509.07208", "authors": ["Abdulhakim Alsaiari", "Mohammad Ilyas"], "title": "A Hybrid CNN-LSTM Deep Learning Model for Intrusion Detection in Smart Grid", "comment": null, "summary": "The evolution of the traditional power grid into the \"smart grid\" has\nresulted in a fundamental shift in energy management, which allows the\nintegration of renewable energy sources with modern communication technology.\nHowever, this interconnection has increased smart grids' vulnerability to\nattackers, which might result in privacy breaches, operational interruptions,\nand massive outages. The SCADA-based smart grid protocols are critical for\nreal-time data collection and control, but they are vulnerable to attacks like\nunauthorized access and denial of service (DoS). This research proposes a\nhybrid deep learning-based Intrusion Detection System (IDS) intended to improve\nthe cybersecurity of smart grids. The suggested model takes advantage of\nConvolutional Neural Networks' (CNN) feature extraction capabilities as well as\nLong Short-Term Memory (LSTM) networks' temporal pattern recognition skills.\nDNP3 and IEC104 intrusion detection datasets are employed to train and test our\nCNN-LSTM model to recognize and classify the potential cyber threats. Compared\nto other deep learning approaches, the results demonstrate considerable\nimprovements in accuracy, precision, recall, and F1-score, with a detection\naccuracy of 99.70%.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCNN\u548cLSTM\u7f51\u7edc\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u667a\u80fd\u7535\u7f51\u7684\u7f51\u7edc\u5b89\u5168\u6027\u3002\u901a\u8fc7\u8bad\u7ec3\u548c\u6d4b\u8bd5DNP3\u548cIEC104\u5165\u4fb5\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u8be5\u6a21\u578b\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u5584\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u65b9\u9762\u8fbe\u5230\u4e8699.70%\u3002", "motivation": "\u7531\u4e8e\u667a\u80fd\u7535\u7f51\u7684\u6f14\u53d8\u4f7f\u5f97\u5176\u9762\u4e34\u7740\u6765\u81ea\u653b\u51fb\u8005\u7684\u66f4\u5927\u5a01\u80c1\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u6765\u4fdd\u969c\u667a\u80fd\u7535\u7f51\u7684\u7f51\u7edc\u5b89\u5168\u6027\u3002\u4f20\u7edf\u7684SCADA\u667a\u80fd\u7535\u7f51\u534f\u8bae\u5bb9\u6613\u53d7\u5230\u672a\u7ecf\u6388\u6743\u8bbf\u95ee\u548c\u62d2\u7edd\u670d\u52a1\u7b49\u653b\u51fb\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u5e94\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u63d0\u9ad8\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5CNN\u548cLSTM\u7f51\u7edc\u4e3a\u57fa\u7840\uff0c\u5229\u7528DNP3\u548cIEC104\u7684\u5165\u4fb5\u68c0\u6d4b\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002\u6a21\u578b\u5229\u7528CNN\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548cLSTM\u8fdb\u884c\u65f6\u95f4\u6a21\u5f0f\u8bc6\u522b\uff0c\u4ee5\u8bc6\u522b\u548c\u5206\u7c7b\u6f5c\u5728\u7684\u7f51\u7edc\u5a01\u80c1\u3002", "result": "\u4e0e\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u7814\u7a76\u7ed3\u679c\u663e\u793a\u4e86\u5728\u51c6\u786e\u7387\u3001\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5f97\u5206\u7b49\u65b9\u9762\u7684\u663e\u8457\u6539\u5584\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u5230\u4e8699.70%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u65e8\u5728\u63d0\u9ad8\u667a\u80fd\u7535\u7f51\u7684\u7f51\u7edc\u5b89\u5168\u6027\u3002\u901a\u8fc7\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u7684\u4f18\u52bf\uff0c\u8be5\u6a21\u578b\u5728\u5b9e\u65f6\u6570\u636e\u5206\u7c7b\u548c\u6f5c\u5728\u7f51\u7edc\u5a01\u80c1\u8bc6\u522b\u65b9\u9762\u53d6\u5f97\u663e\u8457\u6539\u5584\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u523099.70%\u3002"}}
{"id": "2509.07209", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07209", "abs": "https://arxiv.org/abs/2509.07209", "authors": ["Nicholas Sung", "Steven Spreizer", "Mohamed Elrefaie", "Kaira Samuel", "Matthew C. Jones", "Faez Ahmed"], "title": "BlendedNet: A Blended Wing Body Aircraft Dataset and Surrogate Model for Aerodynamic Predictions", "comment": "Accepted at ASME IDETC/CIE 2025 (DETC2025-168977). Dataset\n  availability: BlendedNet dataset is openly available at Harvard Dataverse\n  (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VJT9EP)", "summary": "BlendedNet is a publicly available aerodynamic dataset of 999 blended wing\nbody (BWB) geometries. Each geometry is simulated across about nine flight\nconditions, yielding 8830 converged RANS cases with the Spalart-Allmaras model\nand 9 to 14 million cells per case. The dataset is generated by sampling\ngeometric design parameters and flight conditions, and includes detailed\npointwise surface quantities needed to study lift and drag. We also introduce\nan end-to-end surrogate framework for pointwise aerodynamic prediction. The\npipeline first uses a permutation-invariant PointNet regressor to predict\ngeometric parameters from sampled surface point clouds, then conditions a\nFeature-wise Linear Modulation (FiLM) network on the predicted parameters and\nflight conditions to predict pointwise coefficients Cp, Cfx, and Cfz.\nExperiments show low errors in surface predictions across diverse BWBs.\nBlendedNet addresses data scarcity for unconventional configurations and\nenables research on data-driven surrogate modeling for aerodynamic design.", "AI": {"tldr": "BlendedNet\u662f\u4e00\u4e2a\u5305\u542b999\u4e2a\u6df7\u5408\u7ffc\u4f53\u51e0\u4f55\u5f62\u6001\u7684\u822a\u7a7a\u52a8\u529b\u5b66\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u91c7\u6837\u53c2\u6570\u548c\u98de\u884c\u6761\u4ef6\u751f\u6210\u3002\u5f15\u5165\u4e86\u7aef\u5230\u7aef\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u4f7f\u7528PointNet\u56de\u5f52\u5668\u548cFiLM\u7f51\u7edc\u5bf9\u70b9\u9762\u7a7a\u6c14\u52a8\u529b\u5b66\u8fdb\u884c\u9884\u6d4b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u6027\u95ee\u9898\uff0c\u5bf9\u822a\u7a7a\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u89e3\u51b3\u975e\u4f20\u7edf\u7ffc\u578b\u6570\u636e\u7a00\u7f3a\u6027\u7684\u95ee\u9898\uff0c\u4fc3\u8fdb\u57fa\u4e8e\u6570\u636e\u7684\u4ee3\u7406\u5efa\u6a21\u7528\u4e8e\u822a\u7a7a\u8bbe\u8ba1\u3002", "method": "\u751f\u6210BlendedNet\u6570\u636e\u96c6\u662f\u901a\u8fc7\u91c7\u6837\u51e0\u4f55\u8bbe\u8ba1\u53c2\u6570\u548c\u98de\u884c\u6761\u4ef6\u8fdb\u884c\u6a21\u62df\uff0c\u91c7\u7528Spalart-Allmaras\u6a21\u578b\u8fdb\u884cRANS\u8ba1\u7b97\uff0c\u6bcf\u4e2a\u6848\u4f8b\u6709900\u81f31400\u4e07\u4e2a\u5355\u5143\u3002\u5f15\u5165\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u4f7f\u7528PointNet\u56de\u5f52\u5668\u548cFiLM\u7f51\u7edc\u5bf9\u70b9\u9762\u7a7a\u6c14\u52a8\u529b\u5b66\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eBlendedNet\u5728\u5404\u79cd\u6df7\u5408\u7ffc\u4f53\u4e0a\u5177\u6709\u8f83\u4f4e\u7684\u8868\u9762\u9884\u6d4b\u8bef\u5dee\uff0c\u5e76\u4e14\u6210\u529f\u89e3\u51b3\u4e86\u975e\u4f20\u7edf\u914d\u7f6e\u6570\u636e\u7a00\u7f3a\u6027\u7684\u95ee\u9898\u3002", "conclusion": "BlendedNet\u662f\u4e00\u4e2a\u5305\u542b999\u4e2a\u6df7\u5408\u7ffc\u4f53\u51e0\u4f55\u5f62\u6001\u7684\u822a\u7a7a\u52a8\u529b\u5b66\u6570\u636e\u96c6\u3002\u6570\u636e\u96c6\u901a\u8fc7\u5927\u7ea6\u4e5d\u79cd\u98de\u884c\u6761\u4ef6\u6a21\u62df\u6bcf\u4e2a\u51e0\u4f55\u5f62\u6001\uff0c\u5f97\u5230\u4e868830\u4e2a\u6536\u655b\u7684\u57fa\u4e8eSpalart-Allmaras\u6a21\u578b\u7684RANS\u6848\u4f8b\uff0c\u6bcf\u79cd\u60c5\u51b5\u6709900\u81f31400\u4e07\u4e2a\u5355\u5143\u3002\u8be5\u6570\u636e\u96c6\u901a\u8fc7\u91c7\u6837\u51e0\u4f55\u8bbe\u8ba1\u53c2\u6570\u548c\u98de\u884c\u6761\u4ef6\u800c\u751f\u6210\uff0c\u5305\u62ec\u7814\u7a76\u5347\u529b\u548c\u963b\u529b\u6240\u9700\u7684\u8be6\u7ec6\u70b9\u9762\u91cf\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u70b9\u9762\u7a7a\u6c14\u52a8\u529b\u5b66\u9884\u6d4b\u3002\u8be5\u6846\u67b6\u9996\u5148\u4f7f\u7528\u7f6e\u6362\u4e0d\u53d8\u7684PointNet\u56de\u5f52\u5668\u4ece\u91c7\u6837\u7684\u8868\u9762\u70b9\u4e91\u9884\u6d4b\u51e0\u4f55\u53c2\u6570\uff0c\u7136\u540e\u5728\u9884\u6d4b\u7684\u53c2\u6570\u548c\u98de\u884c\u6761\u4ef6\u4e0a\u6761\u4ef6\u5316\u7279\u5f81\u7ebf\u6027\u8c03\u5236\uff08FiLM\uff09\u7f51\u7edc\uff0c\u4ee5\u9884\u6d4b\u70b9\u72b6\u7cfb\u6570Cp\u3001Cfx\u548cCfz\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u5404\u79cd\u6df7\u5408\u7ffc\u4f53\u4e0a\u8868\u9762\u9884\u6d4b\u5177\u6709\u8f83\u4f4e\u7684\u8bef\u5dee\u3002BlendedNet\u89e3\u51b3\u4e86\u5bf9\u4e8e\u975e\u4f20\u7edf\u914d\u7f6e\u7684\u6570\u636e\u7a00\u7f3a\u6027\uff0c\u5e76\u4fc3\u8fdb\u4e86\u57fa\u4e8e\u6570\u636e\u7684\u4ee3\u7406\u5efa\u6a21\u7528\u4e8e\u822a\u7a7a\u8bbe\u8ba1\u7684\u7814\u7a76\u3002"}}
{"id": "2509.07220", "categories": ["cs.AI", "I.2.10; I.2.1; I.4.8"], "pdf": "https://arxiv.org/pdf/2509.07220", "abs": "https://arxiv.org/abs/2509.07220", "authors": ["Siddhant Karki", "Ethan Han", "Nadim Mahmud", "Suman Bhunia", "John Femiani", "Vaskar Raychoudhury"], "title": "OmniAcc: Personalized Accessibility Assistant Using Generative AI", "comment": "11 Pages, 9 Figures, Published in the 1st Workshop on AI for Urban\n  Planning, AAAI 2025 Workshop", "summary": "Individuals with ambulatory disabilities often encounter significant barriers\nwhen navigating urban environments due to the lack of accessible information\nand tools. This paper presents OmniAcc, an AI-powered interactive navigation\nsystem that utilizes GPT-4, satellite imagery, and OpenStreetMap data to\nidentify, classify, and map wheelchair-accessible features such as ramps and\ncrosswalks in the built environment. OmniAcc offers personalized route\nplanning, real-time hands-free navigation, and instant query responses\nregarding physical accessibility. By using zero-shot learning and customized\nprompts, the system ensures precise detection of accessibility features, while\nsupporting validation through structured workflows. This paper introduces\nOmniAcc and explores its potential to assist urban planners and mobility-aid\nusers, demonstrated through a case study on crosswalk detection. With a\ncrosswalk detection accuracy of 97.5%, OmniAcc highlights the transformative\npotential of AI in improving navigation and fostering more inclusive urban\nspaces.", "AI": {"tldr": "OmniAcc\u662f\u4e00\u4e2a\u5229\u7528AI\u6280\u672f\u7684\u4ea4\u4e92\u5f0f\u5bfc\u822a\u7cfb\u7edf\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u548c\u7ed8\u5236\u8f6e\u6905\u901a\u884c\u8bbe\u65bd\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u8def\u7ebf\u89c4\u5212\u548c\u5b9e\u65f6\u5bfc\u822a\uff0c\u5728\u4eba\u884c\u6a2a\u9053\u68c0\u6d4b\u65b9\u9762\u51c6\u786e\u7387\u9ad8\u8fbe97.5%\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u96f6-shot\u5b66\u4e60\u548c\u5b9a\u5236\u63d0\u793a\u786e\u4fdd\u51c6\u786e\u6027\uff0c\u5c55\u793a\u4e86AI\u5728\u4fc3\u8fdb\u66f4\u5177\u5305\u5bb9\u6027\u57ce\u5e02\u7a7a\u95f4\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u53ef\u8bbf\u95ee\u4fe1\u606f\u548c\u5de5\u5177\uff0c\u884c\u52a8\u4e0d\u4fbf\u7684\u4e2a\u4f53\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u5e38\u5e38\u9047\u5230\u91cd\u91cd\u969c\u788d\u3002\u672c\u8bba\u6587\u81f4\u529b\u4e8e\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528AI\u6280\u672f\u7684\u4ea4\u4e92\u5f0f\u5bfc\u822a\u7cfb\u7edfOmniAcc\uff0c\u65e8\u5728\u8bc6\u522b\u3001\u5206\u7c7b\u548c\u7ed8\u5236\u8f6e\u6905\u901a\u884c\u8bbe\u65bd\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u8def\u7ebf\u89c4\u5212\u548c\u5b9e\u65f6\u5bfc\u822a\uff0c\u4ee5\u53ca\u9488\u5bf9\u901a\u884c\u6027\u7684\u5373\u65f6\u67e5\u8be2\u54cd\u5e94\u3002", "method": "\u4f7f\u7528GPT-4\u3001\u536b\u661f\u56fe\u50cf\u548cOpenStreetMap\u6570\u636e\uff0c\u7ed3\u5408\u96f6-shot\u5b66\u4e60\u548c\u5b9a\u5236\u63d0\u793a\uff0c\u786e\u4fdd\u51c6\u786e\u68c0\u6d4b\u901a\u8fbe\u6027\u529f\u80fd\uff0c\u5e76\u652f\u6301\u901a\u8fc7\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u8fdb\u884c\u9a8c\u8bc1\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u7cfb\u7edf\u5728\u4eba\u884c\u6a2a\u9053\u68c0\u6d4b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "result": "OmniAcc\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5728\u4eba\u884c\u6a2a\u9053\u68c0\u6d4b\u65b9\u9762\u7684\u9ad8\u51c6\u786e\u7387\uff0897.5%\uff09\uff0c\u7a81\u51fa\u4e86AI\u5728\u6539\u5584\u57ce\u5e02\u5bfc\u822a\u548c\u4fc3\u8fdb\u66f4\u5177\u5305\u5bb9\u6027\u57ce\u5e02\u7a7a\u95f4\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "OmniAcc\u662f\u4e00\u79cdAI\u9a71\u52a8\u7684\u4ea4\u4e92\u5f0f\u5bfc\u822a\u7cfb\u7edf\uff0c\u5229\u7528GPT-4\u3001\u536b\u661f\u56fe\u50cf\u548cOpenStreetMap\u6570\u636e\u8bc6\u522b\u3001\u5206\u7c7b\u548c\u7ed8\u5236\u8f6e\u6905\u901a\u884c\u8bbe\u65bd\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u8def\u7ebf\u89c4\u5212\u3001\u5b9e\u65f6\u514d\u63d0\u5bfc\u822a\u4ee5\u53ca\u5173\u4e8e\u7269\u7406\u901a\u884c\u6027\u7684\u5373\u65f6\u67e5\u8be2\u54cd\u5e94\u3002\u901a\u8fc7\u96f6-shot\u5b66\u4e60\u548c\u5b9a\u5236\u63d0\u793a\uff0c\u7cfb\u7edf\u786e\u4fdd\u51c6\u786e\u68c0\u6d4b\u901a\u8fbe\u6027\u529f\u80fd\uff0c\u540c\u65f6\u901a\u8fc7\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u8fdb\u884c\u9a8c\u8bc1\u3002\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86OmniAcc\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u534f\u52a9\u57ce\u5e02\u89c4\u5212\u8005\u548c\u79fb\u52a8\u8f85\u52a9\u7528\u6237\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u4e00\u4e2a\u5173\u4e8e\u4eba\u884c\u6a2a\u9053\u68c0\u6d4b\u7684\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u529f\u80fd\u3002\u5728\u4eba\u884c\u6a2a\u9053\u68c0\u6d4b\u51c6\u786e\u7387\u4e3a97.5%\u7684\u60c5\u51b5\u4e0b\uff0cOmniAcc\u7a81\u663e\u4e86AI\u5728\u6539\u5584\u5bfc\u822a\u5e76\u4fc3\u8fdb\u66f4\u5177\u5305\u5bb9\u6027\u7684\u57ce\u5e02\u7a7a\u95f4\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.07260", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.07260", "abs": "https://arxiv.org/abs/2509.07260", "authors": ["Xin Wang", "Ting Dang", "Xinyu Zhang", "Vassilis Kostakos", "Michael J. Witbrock", "Hong Jia"], "title": "HealthSLM-Bench: Benchmarking Small Language Models for Mobile and Wearable Healthcare Monitoring", "comment": "9 pages, 6 tables, 6 figures", "summary": "Mobile and wearable healthcare monitoring play a vital role in facilitating\ntimely interventions, managing chronic health conditions, and ultimately\nimproving individuals' quality of life. Previous studies on large language\nmodels (LLMs) have highlighted their impressive generalization abilities and\neffectiveness in healthcare prediction tasks. However, most LLM-based\nhealthcare solutions are cloud-based, which raises significant privacy concerns\nand results in increased memory usage and latency. To address these challenges,\nthere is growing interest in compact models, Small Language Models (SLMs),\nwhich are lightweight and designed to run locally and efficiently on mobile and\nwearable devices. Nevertheless, how well these models perform in healthcare\nprediction remains largely unexplored. We systematically evaluated SLMs on\nhealth prediction tasks using zero-shot, few-shot, and instruction fine-tuning\napproaches, and deployed the best performing fine-tuned SLMs on mobile devices\nto evaluate their real-world efficiency and predictive performance in practical\nhealthcare scenarios. Our results show that SLMs can achieve performance\ncomparable to LLMs while offering substantial gains in efficiency and privacy.\nHowever, challenges remain, particularly in handling class imbalance and\nfew-shot scenarios. These findings highlight SLMs, though imperfect in their\ncurrent form, as a promising solution for next-generation, privacy-preserving\nhealthcare monitoring.", "AI": {"tldr": "SLMs were evaluated on health prediction tasks using various approaches and deployed on mobile devices for real-world testing. They showed comparable performance to LLMs with increased efficiency and privacy, making them promising for privacy-preserving healthcare monitoring.", "motivation": "Addressing challenges of privacy concerns, memory usage, and latency in LLM-based healthcare solutions. Exploring the performance of compact SLMs in healthcare prediction tasks.", "method": "Systematically evaluated SLMs on health prediction tasks using zero-shot, few-shot, and instruction fine-tuning approaches. Deployed the best performing fine-tuned SLMs on mobile devices for real-world efficiency and predictive performance evaluation.", "result": "SLMs showed comparable performance to LLMs with increased efficiency and privacy. Challenges remain in dealing with class imbalance and few-shot scenarios.", "conclusion": "SLMs can achieve performance comparable to LLMs while offering gains in efficiency and privacy. Challenges remain in handling class imbalance and few-shot scenarios. SLMs are promising for next-generation, privacy-preserving healthcare monitoring."}}
{"id": "2509.07339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07339", "abs": "https://arxiv.org/abs/2509.07339", "authors": ["Vardhan Palod", "Karthik Valmeekam", "Kaya Stechly", "Subbarao Kambhampati"], "title": "Performative Thinking? The Brittle Correlation Between CoT Length and Problem Complexity", "comment": null, "summary": "Intermediate token generation (ITG), where a model produces output before the\nsolution, has been proposed as a method to improve the performance of language\nmodels on reasoning tasks. While these reasoning traces or Chain of Thoughts\n(CoTs) are correlated with performance gains, the mechanisms underlying them\nremain unclear. A prevailing assumption in the community has been to\nanthropomorphize these tokens as \"thinking\", treating longer traces as evidence\nof higher problem-adaptive computation. In this work, we critically examine\nwhether intermediate token sequence length reflects or correlates with problem\ndifficulty. To do so, we train transformer models from scratch on derivational\ntraces of the A* search algorithm, where the number of operations required to\nsolve a maze problem provides a precise and verifiable measure of problem\ncomplexity. We first evaluate the models on trivial free-space problems,\nfinding that even for the simplest tasks, they often produce excessively long\nreasoning traces and sometimes fail to generate a solution. We then\nsystematically evaluate the model on out-of-distribution problems and find that\nthe intermediate token length and ground truth A* trace length only loosely\ncorrelate. We notice that the few cases where correlation appears are those\nwhere the problems are closer to the training distribution, suggesting that the\neffect arises from approximate recall rather than genuine problem-adaptive\ncomputation. This suggests that the inherent computational complexity of the\nproblem instance is not a significant factor, but rather its distributional\ndistance from the training data. These results challenge the assumption that\nintermediate trace generation is adaptive to problem difficulty and caution\nagainst interpreting longer sequences in systems like R1 as automatically\nindicative of \"thinking effort\".", "AI": {"tldr": "\u4e2d\u95f4\u6807\u8bb0\u751f\u6210(ITG)\u88ab\u63d0\u51fa\u4f5c\u4e3a\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u6027\u80fd\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u672c\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u4ea7\u751f\u7684\u4e2d\u95f4\u6807\u8bb0\u5e8f\u5217\u957f\u5ea6\u4e0e\u95ee\u9898\u96be\u5ea6\u7684\u5173\u8054\u8f83\u5f31\uff0c\u6311\u6218\u4e86\u8fd9\u4e00\u5047\u8bbe\uff0c\u5e76\u8b66\u544a\u4e0d\u8981\u8fc7\u4e8e\u89e3\u91ca\u957f\u5e8f\u5217\u4e3a\u601d\u8003\u52aa\u529b\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u6279\u5224\u6027\u5730\u63a2\u8ba8\u4e2d\u95f4\u6807\u8bb0\u5e8f\u5217\u957f\u5ea6\u662f\u5426\u53cd\u6620\u6216\u4e0e\u95ee\u9898\u96be\u5ea6\u76f8\u5173\uff0c\u6311\u6218\u4e1a\u754c\u5bf9\u8fd9\u4e9b\u6807\u8bb0\u7684\u201c\u601d\u8003\u201d\u548c\u95ee\u9898\u81ea\u9002\u5e94\u8ba1\u7b97\u4e4b\u95f4\u5173\u7cfb\u7684\u5047\u8bbe\u3002", "method": "\u5728A*\u641c\u7d22\u7b97\u6cd5\u7684\u63a8\u5bfc\u8e2a\u8ff9\u4e0a\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u53d8\u538b\u5668\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u5728\u81ea\u7531\u7a7a\u95f4\u95ee\u9898\u548c\u5206\u5e03\u5916\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5bf9\u4e2d\u95f4\u6807\u8bb0\u957f\u5ea6\u4e0eA*\u8e2a\u8ff9\u957f\u5ea6\u7684\u76f8\u5173\u6027\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u5373\u4f7f\u5bf9\u4e8e\u6700\u7b80\u5355\u7684\u4efb\u52a1\uff0c\u6a21\u578b\u4e5f\u7ecf\u5e38\u4ea7\u751f\u8fc7\u957f\u7684\u63a8\u7406\u75d5\u8ff9\uff0c\u5e76\u6709\u65f6\u65e0\u6cd5\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002\u4e2d\u95f4\u6807\u8bb0\u957f\u5ea6\u4e0e\u5b9e\u9645A*\u8e2a\u8ff9\u957f\u5ea6\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u6311\u6218\u4e86\u4e2d\u95f4\u8e2a\u8ff9\u751f\u6210\u9002\u5e94\u95ee\u9898\u96be\u5ea6\u7684\u5047\u8bbe\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6311\u6218\u4e86\u4e2d\u95f4\u6807\u8bb0\u751f\u6210\u4e0e\u95ee\u9898\u96be\u5ea6\u9002\u5e94\u6027\u76f8\u5173\u7684\u5047\u8bbe\uff0c\u5e76\u8b66\u544a\u6211\u4eec\u4e0d\u8981\u81ea\u52a8\u5c06\u50cfR1\u8fd9\u6837\u7684\u7cfb\u7edf\u4e2d\u7684\u8f83\u957f\u5e8f\u5217\u89e3\u91ca\u4e3a\u201c\u601d\u8003\u52aa\u529b\u201d\u3002"}}
{"id": "2509.07367", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.07367", "abs": "https://arxiv.org/abs/2509.07367", "authors": ["Cunxi Yu", "Rongjian Liang", "Chia-Tung Ho", "Haoxing Ren"], "title": "Autonomous Code Evolution Meets NP-Completeness", "comment": "31 pages, 11 figures", "summary": "Large language models (LLMs) have recently shown strong coding abilities,\nenabling not only static code generation but also iterative code self-evolving\nthrough agentic frameworks. Recently, AlphaEvolve \\cite{novikov2025alphaevolve}\ndemonstrated that LLM-based coding agents can autonomously improve algorithms\nand surpass human experts, with scopes limited to isolated kernels spanning\nhundreds of lines of code. Inspired by AlphaEvolve, we present SATLUTION, the\nfirst framework to extend LLM-based code evolution to the full repository\nscale, encompassing hundreds of files and tens of thousands of lines of C/C++\ncode. Targeting Boolean Satisfiability (SAT), the canonical NP-complete problem\nand a cornerstone of both theory and applications. SATLUTION orchestrates LLM\nagents to directly evolve solver repositories under strict correctness\nguarantees and distributed runtime feedback, while simultaneously self-evolving\nits own evolution policies and rules. Starting from SAT Competition 2024\ncodebases and benchmark, SATLUTION evolved solvers that decisively outperformed\nthe human-designed winners of the SAT Competition 2025, and also surpassed both\n2024 and 2025 champions on the 2024 benchmarks.", "AI": {"tldr": "SATLUTION builds on AlphaEvolve's concept to extend LLM-based code evolution to full repository scale for C/C++ code, achieving superior solver evolution for Boolean Satisfiability problems and outperforming human-designed solutions in SAT Competition performances.", "motivation": "Inspired by AlphaEvolve, the paper aims to scale up LLM-based code evolution from isolated kernels to full repository scale, addressing the NP-complete problem of SAT in theory and applications.", "method": "SATLUTION utilizes LLM agents to evolve solver repositories for NP-complete problems with correctness guarantees and distributed runtime feedback. The framework also self-evolves its own evolution policies and rules.", "result": "SATLUTION evolved solvers that outperformed human-designed winners of SAT Competition 2025 and surpassed champions of both 2024 and 2025 competitions on 2024 benchmarks.", "conclusion": "SATLUTION extends LLM-based code evolution to full repository scale for C/C++ code, demonstrating superior performance in evolving solvers for Boolean Satisfiability problems compared to human-designed solutions."}}
{"id": "2509.07414", "categories": ["cs.AI", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2509.07414", "abs": "https://arxiv.org/abs/2509.07414", "authors": ["Jakub Grudzien Kuba", "Mengting Gu", "Qi Ma", "Yuandong Tian", "Vijai Mohan"], "title": "Language Self-Play For Data-Free Training", "comment": null, "summary": "Large language models (LLMs) have advanced rapidly in recent years, driven by\nscale, abundant high-quality training data, and reinforcement learning. Yet\nthis progress faces a fundamental bottleneck: the need for ever more data from\nwhich models can continue to learn. In this work, we propose a reinforcement\nlearning approach that removes this dependency by enabling models to improve\nwithout additional data. Our method leverages a game-theoretic framework of\nself-play, where a model's capabilities are cast as performance in a\ncompetitive game and stronger policies emerge by having the model play against\nitself - a process we call Language Self-Play (LSP). Experiments with\nLlama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained\nmodels can not only enhance their performance on challenging tasks through\nself-play alone, but can also do so more effectively than data-driven\nbaselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u6211\u5bf9\u5f08\u7684\u65b9\u5f0f\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u6ca1\u6709\u989d\u5916\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u80fd\u591f\u66f4\u6709\u6548\u5730\u63d0\u5347\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u6570\u636e\u624d\u80fd\u7ee7\u7eed\u5b66\u4e60\u7684\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u6ca1\u6709\u989d\u5916\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u81ea\u6211\u63d0\u5347\u3002", "method": "\u8bba\u6587\u4f7f\u7528\u4e86\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u6211\u5bf9\u5f08\u7684\u6e38\u620f\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u6a21\u578b\u7684\u80fd\u529b\u8868\u73b0\u4e3a\u5728\u7ade\u4e89\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u6a21\u578b\u4e0e\u81ea\u8eab\u5bf9\u5f08\u6765\u4ea7\u751f\u66f4\u5f3a\u7684\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u8bed\u8a00\u81ea\u6211\u5bf9\u5f08\uff08Language Self-Play\uff0cLSP\uff09\u7684\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u5728\u6307\u4ee4\u9075\u5faa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e14\u6bd4\u4f9d\u8d56\u6570\u636e\u7684\u57fa\u7ebf\u65b9\u6cd5\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u7684\u65b9\u5f0f\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u6ca1\u6709\u989d\u5916\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u6307\u4ee4\u9075\u5faa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u6709\u6548\u5730\u63d0\u5347\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2509.07473", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07473", "abs": "https://arxiv.org/abs/2509.07473", "authors": ["Qin Chen", "Yuanyi Ren", "Xiaojun Ma", "Mugeng Liu", "Han Shi", "Dongmei Zhang"], "title": "SheetDesigner: MLLM-Powered Spreadsheet Layout Generation with Rule-Based and Vision-Based Reflection", "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Spreadsheets are critical to data-centric tasks, with rich, structured\nlayouts that enable efficient information transmission. Given the time and\nexpertise required for manual spreadsheet layout design, there is an urgent\nneed for automated solutions. However, existing automated layout models are\nill-suited to spreadsheets, as they often (1) treat components as axis-aligned\nrectangles with continuous coordinates, overlooking the inherently discrete,\ngrid-based structure of spreadsheets; and (2) neglect interrelated semantics,\nsuch as data dependencies and contextual links, unique to spreadsheets. In this\npaper, we first formalize the spreadsheet layout generation task, supported by\na seven-criterion evaluation protocol and a dataset of 3,326 spreadsheets. We\nthen introduce SheetDesigner, a zero-shot and training-free framework using\nMultimodal Large Language Models (MLLMs) that combines rule and vision\nreflection for component placement and content population. SheetDesigner\noutperforms five baselines by at least 22.6\\%. We further find that through\nvision modality, MLLMs handle overlap and balance well but struggle with\nalignment, necessitates hybrid rule and visual reflection strategies. Our codes\nand data is available at Github.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86SheetDesigner\u6846\u67b6\uff0c\u4f7f\u7528MLLMs\u8fdb\u884c\u7535\u5b50\u8868\u683c\u5e03\u5c40\u751f\u6210\u4efb\u52a1\uff0c\u4f18\u4e8e\u4e94\u79cd\u57fa\u51c6\u6a21\u578b\u81f3\u5c1122.6\uff05\u3002\u901a\u8fc7\u7814\u7a76\u53d1\u73b0\uff0cMLLMs\u5728\u5904\u7406\u91cd\u53e0\u548c\u5747\u8861\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u6df7\u5408\u89c4\u5219\u548c\u89c6\u89c9\u53cd\u5c04\u7b56\u7565\u3002", "motivation": "\u7531\u4e8e\u624b\u52a8\u7535\u5b50\u8868\u683c\u5e03\u5c40\u8bbe\u8ba1\u9700\u8981\u8017\u8d39\u5927\u91cf\u65f6\u95f4\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u81ea\u52a8\u5316\u5e03\u5c40\u6a21\u578b\u4e0d\u9002\u7528\u4e8e\u7535\u5b50\u8868\u683c\uff0c\u56e0\u4e3a\u5b83\u4eec\u7ecf\u5e38\uff081\uff09\u5c06\u7ec4\u4ef6\u89c6\u4e3a\u8fde\u7eed\u5750\u6807\u8f74\u65b9\u5411\u7684\u77e9\u5f62\uff0c\u5ffd\u7565\u4e86\u7535\u5b50\u8868\u683c\u56fa\u6709\u7684\u79bb\u6563\u3001\u57fa\u4e8e\u683c\u5b50\u7684\u7ed3\u6784\uff1b\uff082\uff09\u5ffd\u7565\u4e86\u4e0e\u7535\u5b50\u8868\u683c\u72ec\u7279\u76f8\u5173\u7684\u8bed\u4e49\uff0c\u5982\u6570\u636e\u4f9d\u8d56\u6027\u548c\u4e0a\u4e0b\u6587\u94fe\u63a5\u3002", "method": "\u8be5\u8bba\u6587\u9996\u5148\u5bf9\u7535\u5b50\u8868\u683c\u5e03\u5c40\u751f\u6210\u4efb\u52a1\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\uff0c\u652f\u6301\u4e03\u4e2a\u6807\u51c6\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5305\u542b3,326\u4e2a\u7535\u5b50\u8868\u683c\u7684\u6570\u636e\u96c6\u3002\u7136\u540e\u4ecb\u7ecd\u4e86SheetDesigner\uff0c\u8fd9\u662f\u4e00\u4e2a\u96f6\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5c06\u89c4\u5219\u548c\u89c6\u89c9\u53cd\u5c04\u7ed3\u5408\u8d77\u6765\uff0c\u7528\u4e8e\u7ec4\u4ef6\u653e\u7f6e\u548c\u5185\u5bb9\u586b\u5145\u3002", "result": "\u901a\u8fc7\u7814\u7a76\uff0c\u53d1\u73b0MLLMs\u5728\u5904\u7406\u91cd\u53e0\u548c\u5747\u8861\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u6df7\u5408\u89c4\u5219\u548c\u89c6\u89c9\u53cd\u5c04\u7b56\u7565\u3002SheetDesigner\u6846\u67b6\u4f18\u4e8e\u4e94\u79cd\u57fa\u51c6\u6a21\u578b\u81f3\u5c1122.6\uff05\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u8bad\u7ec3\u7684\u6846\u67b6SheetDesigner\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u8fdb\u884c\u7535\u5b50\u8868\u683c\u5e03\u5c40\u751f\u6210\u4efb\u52a1\uff0c\u4f18\u4e8e\u4e94\u79cd\u57fa\u51c6\u6a21\u578b\u81f3\u5c1122.6\uff05\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u89c6\u89c9\u6a21\u5f0f\uff0cMLLMs\u80fd\u5f88\u597d\u5904\u7406\u91cd\u53e0\u548c\u5747\u8861\uff0c\u4f46\u5728\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u6df7\u5408\u89c4\u5219\u548c\u89c6\u89c9\u53cd\u5c04\u7b56\u7565\u3002"}}
{"id": "2509.07577", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07577", "abs": "https://arxiv.org/abs/2509.07577", "authors": ["Riccardo DElia", "Alberto Termine", "Francesco Flammini"], "title": "Towards explainable decision support using hybrid neural models for logistic terminal automation", "comment": null, "summary": "The integration of Deep Learning (DL) in System Dynamics (SD) modeling for\ntransportation logistics offers significant advantages in scalability and\npredictive accuracy. However, these gains are often offset by the loss of\nexplainability and causal reliability $-$ key requirements in critical\ndecision-making systems. This paper presents a novel framework for\ninterpretable-by-design neural system dynamics modeling that synergizes DL with\ntechniques from Concept-Based Interpretability, Mechanistic Interpretability,\nand Causal Machine Learning. The proposed hybrid approach enables the\nconstruction of neural network models that operate on semantically meaningful\nand actionable variables, while retaining the causal grounding and transparency\ntypical of traditional SD models. The framework is conceived to be applied to\nreal-world case-studies from the EU-funded project AutoMoTIF, focusing on\ndata-driven decision support, automation, and optimization of multimodal\nlogistic terminals. We aim at showing how neuro-symbolic methods can bridge the\ngap between black-box predictive models and the need for critical decision\nsupport in complex dynamical environments within cyber-physical systems enabled\nby the industrial Internet-of-Things.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u6846\u67b6\uff0c\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u6982\u5ff5\u89e3\u91ca\u6027\u3001\u673a\u7406\u89e3\u91ca\u6027\u548c\u56e0\u679c\u673a\u5668\u5b66\u4e60\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u7684\u795e\u7ecf\u7cfb\u7edf\u52a8\u529b\u5b66\u5efa\u6a21\u3002\u8be5\u6846\u67b6\u65e8\u5728\u4fdd\u7559\u56e0\u679c\u57fa\u7840\u548c\u900f\u660e\u5ea6\uff0c\u5e94\u7528\u4e8e\u6b27\u76df\u9879\u76eeAutoMoTIF\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\uff0c\u4ee5\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3001\u81ea\u52a8\u5316\u548c\u4f18\u5316\u7269\u6d41\u7ad9\u70b9\u3002\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u8fde\u63a5\u9ed1\u5323\u5b50\u9884\u6d4b\u6a21\u578b\u548c\u590d\u6742\u51b3\u7b56\u652f\u6301\u9700\u6c42\u3002", "motivation": "\u5728\u8fd0\u8f93\u7269\u6d41\u9886\u57df\uff0c\u5c06\u6df1\u5ea6\u5b66\u4e60\u5f15\u5165\u7cfb\u7edf\u52a8\u529b\u5b66\u5efa\u6a21\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u7b49\u91cd\u8981\u4f18\u52bf\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u6280\u672f\u5e38\u5e38\u727a\u7272\u89e3\u91ca\u6027\u548c\u56e0\u679c\u53ef\u9760\u6027\uff0c\u8fd9\u5728\u5173\u952e\u51b3\u7b56\u7cfb\u7edf\u4e2d\u662f\u4e0d\u53ef\u53d6\u7684\u3002\u56e0\u6b64\uff0c\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4fdd\u7559\u56e0\u679c\u6027\u548c\u900f\u660e\u5ea6\u7684\u524d\u63d0\u4e0b\u878d\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u53ef\u89e3\u91ca\u6027\u7684\u795e\u7ecf\u7cfb\u7edf\u52a8\u529b\u5b66\u5efa\u6a21\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u6df1\u5ea6\u5b66\u4e60\u548c\u6982\u5ff5\u89e3\u91ca\u6027\u3001\u673a\u7406\u89e3\u91ca\u6027\u3001\u56e0\u679c\u673a\u5668\u5b66\u4e60\u6280\u672f\u3002\u901a\u8fc7\u8fd9\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u64cd\u4f5c\u5728\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u548c\u53ef\u884c\u52a8\u4f5c\u53d8\u91cf\u4e0a\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002\u8be5\u6846\u67b6\u65e8\u5728\u4fdd\u7559\u4f20\u7edf\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\u7684\u56e0\u679c\u57fa\u7840\u548c\u900f\u660e\u5ea6\uff0c\u540c\u65f6\u5e94\u7528\u4e8e\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u8bba\u6587\u7684\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u6027\u795e\u7ecf\u7cfb\u7edf\u52a8\u529b\u5b66\u5efa\u6a21\u6846\u67b6\u5728\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u7279\u522b\u662f\u5728\u6b27\u76df\u8d44\u52a9\u9879\u76eeAutoMoTIF\u4e2d\u7684\u5e94\u7528\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u8fde\u63a5\u9ed1\u5323\u5b50\u9884\u6d4b\u6a21\u578b\u548c\u590d\u6742\u51b3\u7b56\u652f\u6301\u9700\u6c42\u4e4b\u95f4\u7684\u6709\u6548\u9014\u5f84\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u6982\u5ff5\u89e3\u91ca\u6027\u3001\u673a\u7406\u89e3\u91ca\u6027\u548c\u56e0\u679c\u673a\u5668\u5b66\u4e60\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u7684\u795e\u7ecf\u7cfb\u7edf\u52a8\u529b\u5b66\u5efa\u6a21\u3002\u8fd9\u79cd\u6df7\u5408\u65b9\u6cd5\u4f7f\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u80fd\u591f\u5728\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u4e14\u53ef\u64cd\u4f5c\u7684\u53d8\u91cf\u4e0a\u8fd0\u884c\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u4f20\u7edf\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\u7684\u56e0\u679c\u57fa\u7840\u548c\u900f\u660e\u5ea6\u3002\u8bba\u6587\u81f4\u529b\u4e8e\u5e94\u7528\u8be5\u6846\u67b6\u4e8e\u6b27\u76df\u8d44\u52a9\u9879\u76eeAutoMoTIF\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u652f\u6301\u3001\u81ea\u52a8\u5316\u548c\u591a\u6a21\u5f0f\u7269\u6d41\u7ad9\u70b9\u7684\u4f18\u5316\u3002\u7814\u7a76\u65e8\u5728\u5c55\u793a\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5982\u4f55\u5f25\u5408\u9ed1\u5323\u5b50\u9884\u6d4b\u6a21\u578b\u4e0e\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u5173\u952e\u51b3\u7b56\u652f\u6301\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u5de5\u4e1a\u7269\u8054\u7f51\u652f\u6301\u7684\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2509.07617", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07617", "abs": "https://arxiv.org/abs/2509.07617", "authors": ["Minghui Li", "Hao Zhang", "Yechao Zhang", "Wei Wan", "Shengshan Hu", "pei Xiaobing", "Jing Wang"], "title": "Transferable Direct Prompt Injection via Activation-Guided MCMC Sampling", "comment": "Accepted to EMNLP 2025", "summary": "Direct Prompt Injection (DPI) attacks pose a critical security threat to\nLarge Language Models (LLMs) due to their low barrier of execution and high\npotential damage. To address the impracticality of existing white-box/gray-box\nmethods and the poor transferability of black-box methods, we propose an\nactivations-guided prompt injection attack framework. We first construct an\nEnergy-based Model (EBM) using activations from a surrogate model to evaluate\nthe quality of adversarial prompts. Guided by the trained EBM, we employ the\ntoken-level Markov Chain Monte Carlo (MCMC) sampling to adaptively optimize\nadversarial prompts, thereby enabling gradient-free black-box attacks.\nExperimental results demonstrate our superior cross-model transferability,\nachieving 49.6% attack success rate (ASR) across five mainstream LLMs and 34.6%\nimprovement over human-crafted prompts, and maintaining 36.6% ASR on unseen\ntask scenarios. Interpretability analysis reveals a correlation between\nactivations and attack effectiveness, highlighting the critical role of\nsemantic patterns in transferable vulnerability exploitation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6fc0\u6d3b\u5f15\u5bfc\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u6846\u67b6\uff0c\u5728\u4e3b\u6d41LLM\u4e0a\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u653b\u51fb\u6210\u529f\u7387\u548c\u7a33\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bc4\u4f30\u654c\u5bf9\u63d0\u793a\u8d28\u91cf\u548c\u4f18\u5316\u654c\u5bf9\u63d0\u793a\u5b9e\u73b0\u4e86\u68af\u5ea6\u81ea\u7531\u7684\u9ed1\u76d2\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u6fc0\u6d3b\u548c\u653b\u51fb\u6548\u679c\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5f3a\u8c03\u4e86\u8bed\u4e49\u6a21\u5f0f\u5728\u6f0f\u6d1e\u5f00\u53d1\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u767d\u76d2/\u7070\u76d2\u65b9\u6cd5\u7684\u4e0d\u5207\u5b9e\u9645\u6027\u548c\u9ed1\u76d2\u65b9\u6cd5\u7684\u4f4e\u4f20\u9012\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u6fc0\u6d3b\u5f15\u5bfc\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3DPI\u653b\u51fb\u5bf9LLM\u7684\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u6fc0\u6d3b\u7684\u6a21\u578b\u6765\u8bc4\u4f30\u654c\u5bf9\u63d0\u793a\u7684\u8d28\u91cf\uff0c\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u91c7\u6837\u6765\u4f18\u5316\u654c\u5bf9\u63d0\u793a\uff0c\u5b9e\u73b0\u57fa\u4e8e\u68af\u5ea6\u7684\u65e0\u68af\u5ea6\u9ed1\u76d2\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4e3b\u6d41LLM\u4e0a\u7684\u4f18\u8d8a\u8868\u73b0\uff0c\u5305\u62ec\u63d0\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\u548c\u5728\u672a\u89c1\u4efb\u52a1\u573a\u666f\u4e0a\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6fc0\u6d3b\u5f15\u5bfc\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u80fd\u91cf\u7684\u6a21\u578b\uff08EBM\uff09\u548c\u4f7f\u7528\u4ee4\u724c\u7ea7\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\uff08MCMC\uff09\u91c7\u6837\u6765\u4f18\u5316\u654c\u5bf9\u63d0\u793a\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u68af\u5ea6\u7684\u65e0\u68af\u5ea6\u9ed1\u76d2\u653b\u51fb\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e94\u4e2a\u4e3b\u6d41LLM\u4e0a\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u8de8\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\uff0c\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u8fbe\u523049.6\uff05\uff0c\u6bd4\u4eba\u5de5\u8bbe\u8ba1\u7684\u63d0\u793a\u63d0\u9ad8\u4e8634.6\uff05\uff0c\u5728\u672a\u89c1\u4efb\u52a1\u573a\u666f\u4e0a\u4fdd\u630136.6\uff05\u7684ASR\u3002\u53ef\u89e3\u91ca\u6027\u5206\u6790\u63ed\u793a\u4e86\u6fc0\u6d3b\u548c\u653b\u51fb\u6548\u679c\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u7a81\u663e\u4e86\u8bed\u4e49\u6a21\u5f0f\u5728\u53ef\u8f6c\u79fb\u6613\u53d7\u653b\u51fb\u6027\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2509.07642", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07642", "abs": "https://arxiv.org/abs/2509.07642", "authors": ["Sascha Kaltenpoth", "Oliver M\u00fcller"], "title": "Getting In Contract with Large Language Models -- An Agency Theory Perspective On Large Language Model Alignment", "comment": "Presented at the 19th International Conference on\n  Wirtschaftsinformatik 2024, W\\\"urzburg, Germany\n  https://aisel.aisnet.org/wi2024/91/", "summary": "Adopting Large language models (LLMs) in organizations potentially\nrevolutionizes our lives and work. However, they can generate off-topic,\ndiscriminating, or harmful content. This AI alignment problem often stems from\nmisspecifications during the LLM adoption, unnoticed by the principal due to\nthe LLM's black-box nature. While various research disciplines investigated AI\nalignment, they neither address the information asymmetries between\norganizational adopters and black-box LLM agents nor consider organizational AI\nadoption processes. Therefore, we propose LLM ATLAS (LLM Agency Theory-Led\nAlignment Strategy) a conceptual framework grounded in agency (contract)\ntheory, to mitigate alignment problems during organizational LLM adoption. We\nconduct a conceptual literature analysis using the organizational LLM adoption\nphases and the agency theory as concepts. Our approach results in (1) providing\nan extended literature analysis process specific to AI alignment methods during\norganizational LLM adoption and (2) providing a first LLM alignment\nproblem-solution space.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u57fa\u4e8e\u4ee3\u7406\u7406\u8bba\u7684\u6982\u5ff5\u6846\u67b6LLM ATLAS\uff0c\u7528\u4e8e\u89e3\u51b3\u7ec4\u7ec7LLM\u91c7\u7528\u8fc7\u7a0b\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u3002\u5bf9\u7ec4\u7ec7LLM\u91c7\u7528\u9636\u6bb5\u548c\u4ee3\u7406\u7406\u8bba\u8fdb\u884c\u6982\u5ff5\u6027\u6587\u732e\u5206\u6790\uff0c\u63d0\u4f9b\u4e86\u5bf9AI\u5bf9\u9f50\u65b9\u6cd5\u7684\u6269\u5c55\u5206\u6790\uff0c\u4e3a\u89e3\u51b3LLM\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7a7a\u95f4\u3002", "motivation": "LLM\u5728\u7ec4\u7ec7\u4e2d\u7684\u5e94\u7528\u53ef\u80fd\u4f1a\u6539\u53d8\u6211\u4eec\u7684\u751f\u6d3b\u548c\u5de5\u4f5c\uff0c\u4f46\u53ef\u80fd\u4f1a\u4ea7\u751f\u8131\u79bb\u4e3b\u9898\u3001\u6b67\u89c6\u6027\u6216\u6709\u5bb3\u5185\u5bb9\uff0c\u8fd9\u79cdAI\u5bf9\u9f50\u95ee\u9898\u901a\u5e38\u6e90\u4e8eLLM\u91c7\u7528\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u89c4\u8303\uff0c\u800c\u4e3b\u4f53\u5bf9\u6b64\u5e76\u4e0d\u4e86\u89e3\u7531\u4e8eLLM\u7684\u9ed1\u5323\u5b50\u7279\u6027\u3002\u73b0\u6709\u7814\u7a76\u672a\u89e3\u51b3\u7ec4\u7ec7\u91c7\u7528\u8005\u4e0e\u9ed1\u5323\u5b50LLM\u4ee3\u7406\u4e4b\u95f4\u7684\u4fe1\u606f\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u4e5f\u672a\u8003\u8651\u7ec4\u7ec7\u7684AI\u91c7\u7528\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u4ee3\u7406(\u5408\u540c)\u7406\u8bba\u4e3a\u57fa\u7840\u7684\u6982\u5ff5\u6846\u67b6LLM ATLAS\uff0c\u4ee5\u51cf\u8f7b\u7ec4\u7ec7LLM\u91c7\u7528\u8fc7\u7a0b\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u3002\u8fdb\u884c\u4e86\u6982\u5ff5\u6027\u6587\u732e\u5206\u6790\uff0c\u4f7f\u7528\u7ec4\u7ec7LLM\u91c7\u7528\u9636\u6bb5\u548c\u4ee3\u7406\u7406\u8bba\u4f5c\u4e3a\u6982\u5ff5\u3002", "result": "\u6839\u636e\u4ee3\u7406\u7406\u8bba\u5efa\u7acb\u4e86LLM ATLAS\u6982\u5ff5\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u5ff5\u6587\u732e\u5206\u6790\u63d0\u4f9b\u4e86\u6269\u5c55\u7684AI\u5bf9\u9f50\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u7ec4\u7ec7LLM\u91c7\u7528\u8fc7\u7a0b\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u3002\u63d0\u4f9b\u4e86\u9996\u4e2aLLM\u5bf9\u9f50\u95ee\u9898\u89e3\u51b3\u7a7a\u95f4\u3002", "conclusion": "\u63d0\u51fa\u4e86LLM ATLAS(\u57fa\u4e8e\u4ee3\u7406\u7406\u8bba\u7684LLM\u5bf9\u9f50\u7b56\u7565)\uff0c\u65e8\u5728\u7f13\u89e3\u5728\u7ec4\u7ec7LLM\u91c7\u7528\u8fc7\u7a0b\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u3002\u8fdb\u884c\u4e86\u6982\u5ff5\u6027\u6587\u732e\u5206\u6790\uff0c\u4f7f\u7528\u7ec4\u7ec7LLM\u91c7\u7528\u9636\u6bb5\u548c\u4ee3\u7406\u7406\u8bba\u4f5c\u4e3a\u6982\u5ff5\u3002\u901a\u8fc7\u8be5\u7814\u7a76\uff0c\u63d0\u4f9b\u4e86\u9488\u5bf9\u7ec4\u7ec7LLM\u91c7\u7528\u8fc7\u7a0b\u4e2dAI\u5bf9\u9f50\u65b9\u6cd5\u7684\u6269\u5c55\u6587\u732e\u5206\u6790\u8fc7\u7a0b\uff0c\u5e76\u63d0\u4f9b\u4e86\u9996\u4e2aLLM\u5bf9\u9f50\u95ee\u9898\u89e3\u51b3\u7a7a\u95f4\u3002"}}
{"id": "2509.07665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07665", "abs": "https://arxiv.org/abs/2509.07665", "authors": ["Adem Kikaj", "Giuseppe Marra", "Floris Geerts", "Robin Manhaeve", "Luc De Raedt"], "title": "DeepGraphLog for Layered Neurosymbolic AI", "comment": null, "summary": "Neurosymbolic AI (NeSy) aims to integrate the statistical strengths of neural\nnetworks with the interpretability and structure of symbolic reasoning.\nHowever, current NeSy frameworks like DeepProbLog enforce a fixed flow where\nsymbolic reasoning always follows neural processing. This restricts their\nability to model complex dependencies, especially in irregular data structures\nsuch as graphs. In this work, we introduce DeepGraphLog, a novel NeSy framework\nthat extends ProbLog with Graph Neural Predicates. DeepGraphLog enables\nmulti-layer neural-symbolic reasoning, allowing neural and symbolic components\nto be layered in arbitrary order. In contrast to DeepProbLog, which cannot\nhandle symbolic reasoning via neural methods, DeepGraphLog treats symbolic\nrepresentations as graphs, enabling them to be processed by Graph Neural\nNetworks (GNNs). We showcase the capabilities of DeepGraphLog on tasks in\nplanning, knowledge graph completion with distant supervision, and GNN\nexpressivity. Our results demonstrate that DeepGraphLog effectively captures\ncomplex relational dependencies, overcoming key limitations of existing NeSy\nsystems. By broadening the applicability of neurosymbolic AI to\ngraph-structured domains, DeepGraphLog offers a more expressive and flexible\nframework for neural-symbolic integration.", "AI": {"tldr": "DeepGraphLog introduces a flexible NeSy framework that enhances neural-symbolic integration in graph-structured domains, addressing limitations of current NeSy frameworks like DeepProbLog and showcasing its effectiveness in capturing complex dependencies in various tasks.", "motivation": "Current NeSy frameworks like DeepProbLog have limitations in modeling complex dependencies, especially in irregular data structures like graphs, due to fixed flow restricting the flexibility of neural and symbolic reasoning integration.", "method": "Introducing DeepGraphLog, a NeSy framework that extends ProbLog with Graph Neural Predicates to enable multi-layer neural-symbolic reasoning in arbitrary order.", "result": "The results demonstrate that DeepGraphLog effectively captures complex relational dependencies, showcasing its capabilities in planning, knowledge graph completion, and GNN expressivity, overcoming key limitations of existing NeSy systems.", "conclusion": "DeepGraphLog offers a more expressive and flexible framework for neural-symbolic integration, broadening the applicability of neurosymbolic AI to graph-structured domains."}}
{"id": "2509.07676", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07676", "abs": "https://arxiv.org/abs/2509.07676", "authors": ["Jipeng Li", "Zeyu Gao", "Yubin Qi", "Hande Dong", "Weijian Chen", "Qiang Lin"], "title": "Unleashing the True Potential of LLMs: A Feedback-Triggered Self-Correction with Long-Term Multipath Decoding", "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance across\ndiverse tasks, yet their susceptibility to generating incorrect content during\ninference remains a critical unsolved challenge. While self-correction methods\noffer potential solutions, their effectiveness is hindered by two inherent\nlimitations: (1) the absence of reliable guidance signals for error\nlocalization, and (2) the restricted reasoning depth imposed by conventional\nnext-token decoding paradigms. To address these issues, we propose\nFeedback-Triggered Regeneration (FTR), a novel framework that synergizes user\nfeedback with enhanced decoding dynamics. Specifically, FTR activates response\nregeneration only upon receiving negative user feedback, thereby circumventing\nerror propagation from faulty self-assessment while preserving originally\ncorrect outputs. Furthermore, we introduce Long-Term Multipath (LTM) decoding,\nwhich enables systematic exploration of multiple reasoning trajectories through\ndelayed sequence evaluation, effectively overcoming the myopic decision-making\ncharacteristic of standard next-token prediction. Extensive experiments on\nmathematical reasoning and code generation benchmarks demonstrate that our\nframework achieves consistent and significant improvements over\nstate-of-the-art prompt-based self-correction methods.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u751f\u6210\u9519\u8bef\u5185\u5bb9\u7684\u6311\u6218\u4ecd\u7136\u5b58\u5728\uff0c\u672c\u8bba\u6587\u63d0\u51fa\u4e86Feedback-Triggered Regeneration\uff08FTR\uff09\u6846\u67b6\u548cLong-Term Multipath\uff08LTM\uff09\u89e3\u7801\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002FTR\u901a\u8fc7\u7528\u6237\u53cd\u9988\u6fc0\u6d3b\u54cd\u5e94\u91cd\u751f\u6210\uff0c\u907f\u514d\u9519\u8bef\u4f20\u64ad\uff0c\u4fdd\u7559\u539f\u59cb\u6b63\u786e\u8f93\u51fa\uff1bLTM\u89e3\u7801\u5141\u8bb8\u7cfb\u7edf\u6027\u63a2\u7d22\u591a\u6761\u63a8\u7406\u8f68\u8ff9\uff0c\u514b\u670d\u77ed\u89c6\u51b3\u7b56\u7279\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u81ea\u6211\u6821\u6b63\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u53d6\u5f97\u5353\u8d8a\u8868\u73b0\uff0c\u4f46\u5176\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u751f\u6210\u4e0d\u6b63\u786e\u5185\u5bb9\u7684\u6613\u611f\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002\u81ea\u6211\u6821\u6b63\u65b9\u6cd5\u867d\u7136\u63d0\u4f9b\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u53d7\u5230\u4e24\u4e2a\u56fa\u6709\u9650\u5236\u7684\u5f71\u54cd\uff1a\uff081\uff09\u6ca1\u6709\u53ef\u9760\u7684\u6307\u5bfc\u4fe1\u53f7\u6765\u5b9a\u4f4d\u9519\u8bef\uff0c\uff082\uff09\u4f20\u7edf\u7684\u4e0b\u4e00\u4e2a\u6807\u8bb0\u89e3\u7801\u8303\u5f0f\u6240\u65bd\u52a0\u7684\u53d7\u9650\u63a8\u7406\u6df1\u5ea6\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86Feedback-Triggered Regeneration\uff08FTR\uff09\u6846\u67b6\u548cLong-Term Multipath\uff08LTM\uff09\u89e3\u7801\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Feedback-Triggered Regeneration\uff08FTR\uff09\u6846\u67b6\u548cLong-Term Multipath\uff08LTM\uff09\u89e3\u7801\u65b9\u6cd5\u3002FTR\u5728\u63a5\u6536\u5230\u8d1f\u9762\u7528\u6237\u53cd\u9988\u65f6\u6fc0\u6d3b\u54cd\u5e94\u91cd\u751f\u6210\uff0c\u4ee5\u907f\u514d\u4ece\u9519\u8bef\u7684\u81ea\u6211\u8bc4\u4f30\u4e2d\u4f20\u64ad\u9519\u8bef\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u6765\u7684\u6b63\u786e\u8f93\u51fa\u3002LTM\u89e3\u7801\u5141\u8bb8\u901a\u8fc7\u5ef6\u8fdf\u5e8f\u5217\u8bc4\u4f30\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u591a\u6761\u63a8\u7406\u8f68\u8ff9\uff0c\u4ece\u800c\u514b\u670d\u4e86\u6807\u51c6\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u4e2d\u7684\u77ed\u89c6\u51b3\u7b56\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684FTR\u6846\u67b6\u548cLTM\u89e3\u7801\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6539\u8fdb\u3002\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u81ea\u6211\u6821\u6b63\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFeedback-Triggered Regeneration\uff08FTR\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u7528\u6237\u53cd\u9988\u548c\u589e\u5f3a\u7684\u89e3\u7801\u52a8\u6001\uff0c\u4ee5\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u751f\u6210\u9519\u8bef\u5185\u5bb9\u7684\u6311\u6218\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86Long-Term Multipath\uff08LTM\uff09\u89e3\u7801\uff0c\u901a\u8fc7\u5ef6\u8fdf\u5e8f\u5217\u8bc4\u4f30\u5b9e\u73b0\u591a\u6761\u63a8\u7406\u8def\u5f84\u7684\u7cfb\u7edf\u6027\u63a2\u7d22\uff0c\u514b\u670d\u4e86\u6807\u51c6\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u4e2d\u7684\u77ed\u89c6\u51b3\u7b56\u7279\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u660e\u663e\u4e14\u6301\u7eed\u7684\u6539\u8fdb\uff0c\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u81ea\u6211\u4fee\u6b63\u65b9\u6cd5\u3002"}}
{"id": "2509.07706", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07706", "abs": "https://arxiv.org/abs/2509.07706", "authors": ["Yildiray Kabak", "Gokce B. Laleci Erturkmen", "Mert Gencturk", "Tuncay Namli", "A. Anil Sinaci", "Ruben Alcantud Corcoles", "Cristina Gomez Ballesteros", "Pedro Abizanda", "Asuman Dogac"], "title": "FHIR-RAG-MEDS: Integrating HL7 FHIR with Retrieval-Augmented Large Language Models for Enhanced Medical Decision Support", "comment": "31 pages, submitted to Journal of Biomedical Informatics, under\n  review", "summary": "In this study, we propose FHIR-RAG-MEDS system that aims to integrate Health\nLevel 7 Fast Healthcare Interoperability Resources (HL7 FHIR) with a\nRetrieval-Augmented Generation (RAG)-based system to improve personalized\nmedical decision support on evidence-based clinical guidelines, emphasizing the\nneed for research in practical applications. In the evolving landscape of\nmedical decision support systems, integrating advanced technologies such as RAG\nand HL7 FHIR can significantly enhance clinical decision-making processes.\nDespite the potential of these technologies, there is limited research on their\nintegration in practical applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6574\u5408HL7 FHIR\u548cRAG\u6280\u672f\u63d0\u51fa\u4e86FHIR-RAG-MEDS\u7cfb\u7edf\uff0c\u65e8\u5728\u6539\u5584\u4e2a\u6027\u5316\u533b\u5b66\u51b3\u7b56\u652f\u6301\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u7684\u7814\u7a76\u9700\u6c42\uff0c\u5e76\u6307\u51fa\u4e86\u6574\u5408\u8fd9\u4e9b\u5148\u8fdb\u6280\u672f\u7684\u6f5c\u5728\u76ca\u5904\u3002", "motivation": "\u5f3a\u8c03\u5728\u533b\u5b66\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u53d1\u5c55\u7684\u80cc\u666f\u4e0b\uff0c\u6574\u5408\u5148\u8fdb\u6280\u672f\u5982RAG\u548cHL7 FHIR\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4e34\u5e8a\u51b3\u7b56\u8fc7\u7a0b\u3002\u5f53\u524d\u5b58\u5728\u6709\u9650\u7814\u7a76\u5173\u4e8e\u8fd9\u4e9b\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6574\u5408\u3002", "method": "\u5c06HL7 FHIR\u4e0eRAG\u6280\u672f\u96c6\u6210\u4ee5\u6539\u5584\u4e2a\u6027\u5316\u533b\u5b66\u51b3\u7b56\u652f\u6301\uff0c\u4fa7\u91cd\u4e8e\u5b9e\u9645\u5e94\u7528\u7814\u7a76\u3002", "result": "\u901a\u8fc7\u5c06HL7 FHIR\u4e0eRAG\u6280\u672f\u96c6\u6210\uff0c\u63d0\u51fa\u4e86FHIR-RAG-MEDS\u7cfb\u7edf\u4ee5\u6539\u5584\u4e2a\u6027\u5316\u533b\u5b66\u51b3\u7b56\u652f\u6301\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86FHIR-RAG-MEDS\u7cfb\u7edf\uff0c\u65e8\u5728\u5c06HL7 FHIR\u4e0e\u57fa\u4e8eRetrieval-Augmented Generation (RAG)\u7684\u7cfb\u7edf\u96c6\u6210\uff0c\u4ee5\u6539\u5584\u57fa\u4e8e\u8bc1\u636e\u7684\u4e34\u5e8a\u6307\u5357\u7684\u4e2a\u6027\u5316\u533b\u5b66\u51b3\u7b56\u652f\u6301\uff0c\u5728\u7740\u91cd\u5f3a\u8c03\u5bf9\u5b9e\u9645\u5e94\u7528\u7684\u7814\u7a76\u9700\u6c42\u3002\u5c3d\u7ba1HL7 FHIR\u548cRAG\u7b49\u5148\u8fdb\u6280\u672f\u5728\u533b\u5b66\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u6f14\u53d8\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u96c6\u6210\u7814\u7a76\u6709\u9650\u3002"}}
{"id": "2509.07711", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07711", "abs": "https://arxiv.org/abs/2509.07711", "authors": ["Ziye Chen", "Chengwei Qin", "Yao Shu"], "title": "RIMO: An Easy-to-Evaluate, Hard-to-Solve Olympiad Benchmark for Advanced Mathematical Reasoning", "comment": null, "summary": "As large language models (LLMs) reach high scores on established mathematical\nbenchmarks, such as GSM8K and MATH, the research community has turned to\nInternational Mathematical Olympiad (IMO) problems to push the evaluation\nfrontier. However, existing Olympiad-level benchmarks suffer from practical\nconstraints that introduce grading noise and potential bias, such as\nheterogeneous answer formats requiring model-based judges and a reliance on\npotentially flawed solutions. We introduce RIMO, a two-track benchmark designed\nto preserve peak Olympiad difficulty while eliminating this evaluation noise.\nThe first track, RIMO-N, rewrites 335 IMO problems to admit a single, unique\ninteger answer, allowing for deterministic correctness checking. The second\ntrack, RIMO-P, features 456 proof problems with expert-checked solutions, which\nare decomposed into a sequence of sub-problems to evaluate the step-by-step\nreasoning process via an automated grading system. Our benchmarking of ten\nfrontier LLMs, including GPT-4o and Gemini 2.5 Flash, reveals that while these\nsystems excel on older benchmarks, their performance drops sharply on RIMO.\nThese results highlight a substantial gap between current LLM capabilities and\nactual Olympiad-level reasoning. By providing a challenging yet\neasy-to-evaluate suite, RIMO offers a high-resolution yardstick for future\nresearch, presenting a clear target for closing the profound reasoning gap our\nfindings expose.", "AI": {"tldr": "RIMO introduces a new benchmark with two tracks, RIMO-N and RIMO-P, to evaluate LLMs on IMO problems. LLMs show a significant decrease in performance on RIMO compared to older benchmarks, highlighting a gap in reasoning abilities. RIMO provides a challenging yet easy-to-evaluate benchmark for future research.", "motivation": "Existing Olympiad-level benchmarks suffer from practical constraints like grading noise and potential bias. RIMO aims to address these issues by providing a benchmark that preserves Olympiad difficulty while simplifying the evaluation process.", "method": "Introducing RIMO, a two-track benchmark with RIMO-N rewriting IMO problems to have a single integer answer and RIMO-P featuring expert-checked proof problems decomposed into sub-problems for step-by-step reasoning evaluation. Ten frontier LLMs, including GPT-4o and Gemini 2.5 Flash, were benchmarked on RIMO.", "result": "The performance of LLMs drops sharply on RIMO compared to older benchmarks, indicating a gap in reasoning abilities. RIMO sets a clear target for closing this reasoning gap and provides a comprehensive benchmark for future research.", "conclusion": "RIMO introduces a two-track benchmark, RIMO-N and RIMO-P, designed to preserve peak Olympiad difficulty while eliminating evaluation noise. The evaluation of ten frontier LLMs on RIMO reveals a substantial gap between current LLM capabilities and actual Olympiad-level reasoning. RIMO offers a challenging yet easy-to-evaluate suite, serving as a high-resolution yardstick for future research."}}
{"id": "2509.07723", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2509.07723", "abs": "https://arxiv.org/abs/2509.07723", "authors": ["Bo Yu", "Zhixiu Hua", "Bo Zhao"], "title": "BDPM: A Machine Learning-Based Feature Extractor for Parkinson's Disease Classification via Gut Microbiota Analysis", "comment": "11 pages, 7 figures", "summary": "Background: Parkinson's disease remains a major neurodegenerative disorder\nwith high misdiagnosis rates, primarily due to reliance on clinical rating\nscales. Recent studies have demonstrated a strong association between gut\nmicrobiota and Parkinson's disease, suggesting that microbial composition may\nserve as a promising biomarker. Although deep learning models based ongut\nmicrobiota show potential for early prediction, most approaches rely on single\nclassifiers and often overlook inter-strain correlations or temporal dynamics.\nTherefore, there is an urgent need for more robust feature extraction methods\ntailored to microbiome data. Methods: We proposed BDPM (A Machine\nLearning-Based Feature Extractor for Parkinson's Disease Classification via Gut\nMicrobiota Analysis). First, we collected gut microbiota profiles from 39\nParkinson's patients and their healthy spouses to identify differentially\nabundant taxa. Second, we developed an innovative feature selection framework\nnamed RFRE (Random Forest combined with Recursive Feature Elimination),\nintegrating ecological knowledge to enhance biological interpretability.\nFinally, we designed a hybrid classification model to capture temporal and\nspatial patterns in microbiome data.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBDPM\u7684\u673a\u5668\u5b66\u4e60\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u7528\u4e8e\u901a\u8fc7\u80a0\u9053\u83cc\u7fa4\u5206\u6790\u8fdb\u884c\u5e15\u91d1\u68ee\u75c5\u5206\u7c7b\u3002\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u6536\u96c6\u80a0\u9053\u83cc\u7fa4\u6570\u636e\u3001\u5f00\u53d1RFRE\u7279\u5f81\u9009\u62e9\u6846\u67b6\u4ee5\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u8bbe\u8ba1\u6df7\u5408\u5206\u7c7b\u6a21\u578b\u6765\u6355\u83b7\u65f6\u95f4\u548c\u7a7a\u95f4\u6a21\u5f0f\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\u8fd9\u4e00\u65b9\u6cd5\u5728\u5e15\u91d1\u68ee\u75c5\u65e9\u671f\u9884\u6d4b\u4e2d\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u7684\u5e15\u91d1\u68ee\u75c5\u8bca\u65ad\u4f9d\u8d56\u4e8e\u4e34\u5e8a\u8bc4\u5206\u8868\uff0c\u5bb9\u6613\u51fa\u73b0\u9ad8\u8bef\u8bca\u7387\u3002\u6700\u8fd1\u7684\u7814\u7a76\u663e\u793a\u80a0\u9053\u83cc\u7fa4\u4e0e\u5e15\u91d1\u68ee\u75c5\u4e4b\u95f4\u5b58\u5728\u5f3a\u70c8\u5173\u8054\uff0c\u63d0\u793a\u5fae\u751f\u7269\u7ec4\u6210\u53ef\u80fd\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u9014\u7684\u751f\u7269\u6807\u5fd7\u7269\u3002\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u7136\u5728\u80a0\u9053\u83cc\u7fa4\u4e0a\u8868\u73b0\u51fa\u65e9\u671f\u9884\u6d4b\u7684\u6f5c\u529b\uff0c\u4f46\u5927\u591a\u6570\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5355\u4e00\u5206\u7c7b\u5668\uff0c\u5e76\u7ecf\u5e38\u5ffd\u89c6\u83cc\u682a\u95f4\u7684\u76f8\u5173\u6027\u6216\u65f6\u95f4\u52a8\u6001\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u52a0\u5f3a\u5065\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u6765\u9002\u5e94\u5fae\u751f\u7269\u7ec4\u6570\u636e\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u6536\u96c6\u5e15\u91d1\u68ee\u75c5\u60a3\u8005\u548c\u5065\u5eb7\u914d\u5076\u7684\u80a0\u9053\u83cc\u7fa4\u6570\u636e\u6765\u8bc6\u522b\u5dee\u5f02\u4e30\u5ea6\u7684\u5fae\u751f\u7269\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aRFRE\u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\u4ee5\u589e\u5f3a\u751f\u7269\u5b66\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df7\u5408\u5206\u7c7b\u6a21\u578b\u6765\u6355\u83b7\u5fae\u751f\u7269\u7ec4\u6570\u636e\u4e2d\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86BDPM\u7279\u5f81\u63d0\u53d6\u5668\uff0cRFRE\u7279\u5f81\u9009\u62e9\u6846\u67b6\u4ee5\u53ca\u6df7\u5408\u5206\u7c7b\u6a21\u578b\uff0c\u5e76\u6210\u529f\u6355\u83b7\u5230\u5fae\u751f\u7269\u7ec4\u6570\u636e\u4e2d\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u6a21\u5f0f\u3002\u8be5\u65b9\u6cd5\u4e3a\u5e15\u91d1\u68ee\u75c5\u7684\u65e9\u671f\u9884\u6d4b\u63d0\u4f9b\u4e86\u6f5c\u5728\u673a\u4f1a\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7279\u5f81\u63d0\u53d6\u5668BDPM\uff0c\u7528\u4e8e\u5e15\u91d1\u68ee\u75c5\u5206\u7c7b\u7684\u80a0\u9053\u83cc\u7fa4\u5206\u6790\u3002\u901a\u8fc7\u6536\u96c6\u5e15\u91d1\u68ee\u75c5\u60a3\u8005\u548c\u5065\u5eb7\u914d\u5076\u7684\u80a0\u9053\u83cc\u7fa4\u6570\u636e\uff0c\u53d1\u73b0\u5dee\u5f02\u4e30\u5ea6\u7684\u5fae\u751f\u7269\u3002\u63d0\u51fa\u4e86\u540d\u4e3aRFRE\u7684\u521b\u65b0\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u7ed3\u5408\u751f\u6001\u77e5\u8bc6\u4ee5\u589e\u5f3a\u751f\u7269\u5b66\u53ef\u89e3\u91ca\u6027\u3002\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df7\u5408\u5206\u7c7b\u6a21\u578b\u6765\u6355\u83b7\u5fae\u751f\u7269\u7ec4\u6570\u636e\u4e2d\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u6a21\u5f0f\u3002\u8be5\u7814\u7a76\u4e3a\u5e15\u91d1\u68ee\u75c5\u65e9\u671f\u9884\u6d4b\u63d0\u4f9b\u4e86\u6f5c\u5728\u7684\u673a\u4f1a\u3002"}}
{"id": "2509.07733", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07733", "abs": "https://arxiv.org/abs/2509.07733", "authors": ["Mustafa Kaan Aslan", "Reinout Heijungs", "Filip Ilievski"], "title": "The Carbon Footprint Wizard: A Knowledge-Augmented AI Interface for Streamlining Food Carbon Footprint Analysis", "comment": null, "summary": "Environmental sustainability, particularly in relation to climate change, is\na key concern for consumers, producers, and policymakers. The carbon footprint,\nbased on greenhouse gas emissions, is a standard metric for quantifying the\ncontribution to climate change of activities and is often assessed using life\ncycle assessment (LCA). However, conducting LCA is complex due to opaque and\nglobal supply chains, as well as fragmented data. This paper presents a\nmethodology that combines advances in LCA and publicly available databases with\nknowledge-augmented AI techniques, including retrieval-augmented generation, to\nestimate cradle-to-gate carbon footprints of food products. We introduce a\nchatbot interface that allows users to interactively explore the carbon impact\nof composite meals and relate the results to familiar activities. A live web\ndemonstration showcases our proof-of-concept system with arbitrary food items\nand follow-up questions, highlighting both the potential and limitations - such\nas database uncertainties and AI misinterpretations - of delivering LCA\ninsights in an accessible format.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u5229\u7528LCA\u3001\u516c\u5f00\u6570\u636e\u5e93\u548cAI\u6280\u672f\u4f30\u8ba1\u98df\u54c1\u4ea7\u54c1\u7684\u78b3\u8db3\u8ff9\uff0c\u5e76\u901a\u8fc7\u804a\u5929\u673a\u5668\u4eba\u754c\u9762\u4ea4\u4e92\u5f0f\u5730\u5c55\u793a\u78b3\u5f71\u54cd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u6570\u636e\u5e93\u4e0d\u786e\u5b9a\u6027\u548cAI\u8bef\u89e3\u7b49\u9650\u5236\u3002", "motivation": "\u6d88\u8d39\u8005\u3001\u751f\u4ea7\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u5bf9\u4e8e\u73af\u5883\u53ef\u6301\u7eed\u6027\u7279\u522b\u662f\u4e0e\u6c14\u5019\u53d8\u5316\u76f8\u5173\u7684\u95ee\u9898\u975e\u5e38\u5173\u6ce8\u3002\u7814\u7a76\u901a\u8fc7\u5c06LCA\u4e0e\u516c\u5f00\u6570\u636e\u5e93\u548cAI\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u65e8\u5728\u4f30\u8ba1\u98df\u54c1\u4ea7\u54c1\u7684\u4ece\u6447\u7bee\u5230\u95e8\u811a\u7684\u78b3\u8db3\u8ff9\uff0c\u4ee5\u66f4\u76f4\u89c2\u5730\u5448\u73b0\u78b3\u5f71\u54cd\u5e76\u5c06\u5176\u4e0e\u65e5\u5e38\u6d3b\u52a8\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u8be5\u8bba\u6587\u7ed3\u5408LCA\u548c\u516c\u5f00\u6570\u636e\u5e93\u4ee5\u53caAI\u6280\u672f\uff0c\u5305\u62ec\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u4f30\u8ba1\u98df\u54c1\u4ea7\u54c1\u7684\u78b3\u8db3\u8ff9\u3002\u5f15\u5165\u4e86\u4e00\u4e2a\u804a\u5929\u673a\u5668\u4eba\u754c\u9762\uff0c\u5141\u8bb8\u7528\u6237\u4ea4\u4e92\u5f0f\u5730\u63a2\u7d22\u590d\u5408\u9910\u98df\u7684\u78b3\u5f71\u54cd\u3002\u901a\u8fc7\u5b9e\u65f6\u7f51\u7edc\u6f14\u793a\u5c55\u793a\u4e86\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u4f20\u9012LCA\u89c1\u89e3\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u4e00\u4e2a\u7ed3\u5408LCA\u548cAI\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u804a\u5929\u673a\u5668\u4eba\u754c\u9762\uff0c\u53ef\u4ee5\u4f30\u8ba1\u98df\u54c1\u4ea7\u54c1\u7684\u78b3\u8db3\u8ff9\u5e76\u5411\u7528\u6237\u4f20\u8fbe\u76f8\u5173\u89c1\u89e3\u3002\u5b9e\u65f6\u7f51\u7edc\u6f14\u793a\u5c55\u793a\u4e86\u8be5\u7cfb\u7edf\u7684\u6f5c\u529b\u548c\u9650\u5236\uff0c\u540c\u65f6\u7a81\u51fa\u4e86\u6570\u636e\u5e93\u4e0d\u786e\u5b9a\u6027\u548cAI\u8bef\u89e3\u7b49\u95ee\u9898\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u7ed3\u5408LCA\u7684\u8fdb\u5c55\u548c\u516c\u5f00\u6570\u636e\u5e93\u4ee5\u53ca\u77e5\u8bc6\u589e\u5f3a\u7684AI\u6280\u672f\uff0c\u4f30\u8ba1\u98df\u54c1\u4ea7\u54c1\u7684\u4ece\u6447\u7bee\u5230\u95e8\u811a\u7684\u78b3\u8db3\u8ff9\u3002\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u804a\u5929\u673a\u5668\u4eba\u754c\u9762\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u4ea4\u4e92\u5f0f\u5730\u63a2\u7d22\u590d\u5408\u9910\u98df\u7684\u78b3\u5f71\u54cd\uff0c\u5e76\u5c06\u7ed3\u679c\u4e0e\u719f\u6089\u7684\u6d3b\u52a8\u8054\u7cfb\u8d77\u6765\u3002\u901a\u8fc7\u5b9e\u65f6\u7f51\u7edc\u6f14\u793a\u5c55\u793a\u4e86\u8bba\u6587\u7684\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u7a81\u51fa\u4e86\u4ee5\u6613\u4e8e\u7406\u89e3\u7684\u65b9\u5f0f\u63d0\u4f9bLCA\u89c1\u89e3\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u5982\u6570\u636e\u5e93\u4e0d\u786e\u5b9a\u6027\u548cAI\u8bef\u89e3\u3002"}}
{"id": "2509.07820", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07820", "abs": "https://arxiv.org/abs/2509.07820", "authors": ["Jo\u00e3o Paulo Nogueira", "Wentao Sun", "Alonso Silva", "Laith Zumot"], "title": "Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach", "comment": null, "summary": "The rise of large reasoning language models (LRLMs) has unlocked new\npotential for solving complex tasks. These models operate with a thinking\nbudget, that is, a predefined number of reasoning tokens used to arrive at a\nsolution. We propose a novel approach, inspired by the generator/discriminator\nframework in generative adversarial networks, in which a critic model\nperiodically probes its own reasoning to assess whether it has reached a\nconfident conclusion. If not, reasoning continues until a target certainty\nthreshold is met. This mechanism adaptively balances efficiency and reliability\nby allowing early termination when confidence is high, while encouraging\nfurther reasoning when uncertainty persists. Through experiments on the\nAIME2024 and AIME2025 datasets, we show that Certainty-Guided Reasoning (CGR)\nimproves baseline accuracy while reducing token usage. Importantly, extended\nmulti-seed evaluations over 64 runs demonstrate that CGR is stable, reducing\nvariance across seeds and improving exam-like performance under penalty-based\ngrading. Additionally, our token savings analysis shows that CGR can eliminate\nmillions of tokens in aggregate, with tunable trade-offs between certainty\nthresholds and efficiency. Together, these findings highlight certainty as a\npowerful signal for reasoning sufficiency. By integrating confidence into the\nreasoning process, CGR makes large reasoning language models more adaptive,\ntrustworthy, and resource efficient, paving the way for practical deployment in\ndomains where both accuracy and computational cost matter.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5373\u57fa\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u4e2d\u7684\u751f\u6210\u5668/\u5224\u522b\u5668\u6846\u67b6\u7684\u542f\u53d1\uff0c\u901a\u8fc7\u5f15\u5165\u4e34\u754c\u6a21\u578b\u5b9a\u671f\u8bc4\u4f30\u81ea\u8eab\u63a8\u7406\uff0c\u4ee5\u786e\u5b9a\u662f\u5426\u8fbe\u5230\u81ea\u4fe1\u7ed3\u8bba\u3002\u63a8\u7406\u4f1a\u6301\u7eed\u8fdb\u884c\uff0c\u76f4\u5230\u8fbe\u5230\u76ee\u6807\u786e\u5b9a\u6027\u9608\u503c\uff0c\u6709\u6548\u5e73\u8861\u6548\u7387\u548c\u53ef\u9760\u6027\u3002\u7ecf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u786e\u5b9a\u6027\u5f15\u5bfc\u63a8\u7406\uff08CGR\uff09\u63d0\u9ad8\u4e86\u57fa\u51c6\u51c6\u786e\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u4ee4\u724c\u4f7f\u7528\u3002", "motivation": "The motivation behind this paper is to enhance the efficiency and reliability of large reasoning language models by incorporating certainty into the reasoning process. It aims to address the challenge of balancing accuracy and computational cost in complex tasks.", "method": "The paper proposes a novel approach inspired by the generator/discriminator framework in generative adversarial networks. It introduces a critic model that assesses its own reasoning periodically to determine if a confident conclusion is reached. The reasoning continues until a target certainty threshold is met, balancing efficiency and reliability effectively.", "result": "Experiments on AIME2024 and AIME2025 datasets demonstrate that CGR improves accuracy while reducing token usage. The stability of CGR is highlighted through extended multi-seed evaluations, showing reduced variance across seeds and improved exam-like performance under penalty-based grading. Token savings analysis reveals that CGR can eliminate millions of tokens with tunable trade-offs between certainty thresholds and efficiency.", "conclusion": "Certainty-Guided Reasoning (CGR) improves baseline accuracy and reduces token usage in large reasoning language models. It provides adaptive, trustworthy, and resource-efficient solutions for practical deployment in domains where accuracy and computational cost are crucial."}}
{"id": "2509.07846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07846", "abs": "https://arxiv.org/abs/2509.07846", "authors": ["Amay Jain", "Liu Cui", "Si Chen"], "title": "Aligning LLMs for the Classroom with Knowledge-Based Retrieval -- A Comparative RAG Study", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Large language models like ChatGPT are increasingly used in classrooms, but\nthey often provide outdated or fabricated information that can mislead\nstudents. Retrieval Augmented Generation (RAG) improves reliability of LLMs by\ngrounding responses in external resources. We investigate two accessible RAG\nparadigms, vector-based retrieval and graph-based retrieval to identify best\npractices for classroom question answering (QA). Existing comparative studies\nfail to account for pedagogical factors such as educational disciplines,\nquestion types, and practical deployment costs. Using a novel dataset,\nEduScopeQA, of 3,176 questions across academic subjects, we measure performance\non various educational query types, from specific facts to broad thematic\ndiscussions. We also evaluate system alignment with a dataset of systematically\naltered textbooks that contradict the LLM's latent knowledge. We find that\nOpenAI Vector Search RAG (representing vector-based RAG) performs well as a\nlow-cost generalist, especially for quick fact retrieval. On the other hand,\nGraphRAG Global excels at providing pedagogically rich answers to thematic\nqueries, and GraphRAG Local achieves the highest accuracy with the dense,\naltered textbooks when corpus integrity is critical. Accounting for the 10-20x\nhigher resource usage of GraphRAG (representing graph-based RAG), we show that\na dynamic branching framework that routes queries to the optimal retrieval\nmethod boosts fidelity and efficiency. These insights provide actionable\nguidelines for educators and system designers to integrate RAG-augmented LLMs\ninto learning environments effectively.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6bd4\u8f83\u57fa\u4e8e\u5411\u91cf\u548c\u57fa\u4e8e\u56fe\u7684RAG\uff0c\u5728\u6559\u80b2\u9886\u57df\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u53d1\u73b0\u4e0d\u540cRAG\u8303\u4f8b\u5728\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u4e0b\u8868\u73b0\u4f18\u52a3\u3002OpenAI Vector Search RAG\u9002\u5408\u5feb\u901f\u4e8b\u5b9e\u68c0\u7d22\uff0cGraphRAG Global\u9002\u5408\u63d0\u4f9b\u4e3b\u9898\u6027\u6559\u5b66\u7b54\u6848\uff0cGraphRAG Local\u5728\u5904\u7406\u4fee\u6539\u6559\u79d1\u4e66\u65f6\u8868\u73b0\u4f18\u5f02\u3002\u52a8\u6001\u5206\u652f\u6846\u67b6\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u662f\u8981\u6539\u5584\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u73af\u5883\u4e2d\u63d0\u4f9b\u8fc7\u65f6\u6216\u865a\u6784\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u901a\u8fc7RAG\u63d0\u9ad8LLMs\u7684\u53ef\u9760\u6027\u3002\u73b0\u6709\u7684\u6bd4\u8f83\u7814\u7a76\u672a\u8003\u8651\u5230\u6559\u80b2\u5b66\u56e0\u7d20\uff0c\u5982\u6559\u80b2\u5b66\u79d1\u3001\u95ee\u9898\u7c7b\u578b\u548c\u5b9e\u9645\u90e8\u7f72\u6210\u672c\u3002", "method": "\u4f7f\u7528\u4e86\u4e24\u79cdRAG\u8303\u4f8b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u522b\u662f\u57fa\u4e8e\u5411\u91cf\u7684\u68c0\u7d22\u548c\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u3002\u901a\u8fc7\u4f7f\u7528\u65b0\u6570\u636e\u96c6EduScopeQA\uff0c\u8bc4\u4f30\u4e86\u5728\u4e0d\u540c\u6559\u80b2\u67e5\u8be2\u7c7b\u578b\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u8bc4\u4f30\u4e86\u7cfb\u7edf\u4e0e\u7ecf\u8fc7\u7cfb\u7edf\u4fee\u6539\u7684\u6559\u79d1\u4e66\u7684\u4e00\u81f4\u6027\u3002\u9488\u5bf9GraphRAG\u8d44\u6e90\u4f7f\u7528\u8f83\u9ad8\u7684\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u52a8\u6001\u5206\u652f\u6846\u67b6\u7684\u91cd\u8981\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0OpenAI Vector Search RAG\u8868\u73b0\u826f\u597d\uff0c\u7279\u522b\u9002\u5408\u5feb\u901f\u4e8b\u5b9e\u68c0\u7d22\uff1bGraphRAG Global\u5728\u5bf9\u4e3b\u9898\u6027\u95ee\u9898\u63d0\u4f9b\u4e30\u5bcc\u6559\u5b66\u7b54\u6848\u65b9\u9762\u8868\u73b0\u4f18\u79c0\uff1bGraphRAG Local\u5728\u5904\u7406\u5bc6\u96c6\u4fee\u6539\u6559\u79d1\u4e66\u65f6\u51c6\u786e\u6027\u6700\u9ad8\u3002\u52a8\u6001\u5206\u652f\u6846\u67b6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0OpenAI Vector Search RAG\u5728\u5feb\u901f\u4e8b\u5b9e\u68c0\u7d22\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0cGraphRAG Global\u5728\u5bf9\u4e3b\u9898\u6027\u95ee\u9898\u63d0\u4f9b\u4e30\u5bcc\u6559\u5b66\u7b54\u6848\u65b9\u9762\u8868\u73b0\u4f18\u79c0\uff0cGraphRAG Local\u5728\u5904\u7406\u5bc6\u96c6\u4fee\u6539\u8fc7\u7684\u6559\u79d1\u4e66\u65f6\u83b7\u5f97\u6700\u9ad8\u51c6\u786e\u6027\u3002\u901a\u8fc7\u52a8\u6001\u5206\u652f\u6846\u67b6\u5c06\u67e5\u8be2\u8def\u7531\u5230\u6700\u4f73\u68c0\u7d22\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u6559\u80b2\u5de5\u4f5c\u8005\u548c\u7cfb\u7edf\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u6709\u6548\u5730\u5c06RAG\u589e\u5f3a\u7684LLMs\u6574\u5408\u5230\u5b66\u4e60\u73af\u5883\u4e2d\u3002"}}
{"id": "2509.07858", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07858", "abs": "https://arxiv.org/abs/2509.07858", "authors": ["Xinyu Zhang", "Changzhi Zhou", "Linmei Hu", "Luhao Zhang", "Xiancai Chen", "Haomin Fu", "Yang Yang", "Mengdi Zhang"], "title": "SCoder: Iterative Self-Distillation for Bootstrapping Small-Scale Data Synthesizers to Empower Code LLMs", "comment": null, "summary": "Existing code large language models (LLMs) often rely on large-scale\ninstruction data distilled from proprietary LLMs for fine-tuning, which\ntypically incurs high costs. In this paper, we explore the potential of\nsmall-scale open-source LLMs (e.g., 7B) as synthesizers for high-quality code\ninstruction data construction. We first observe that the data synthesis\ncapability of small-scale LLMs can be enhanced by training on a few superior\ndata synthesis samples from proprietary LLMs. Building on this, we propose a\nnovel iterative self-distillation approach to bootstrap small-scale LLMs,\ntransforming them into powerful synthesizers that reduce reliance on\nproprietary LLMs and minimize costs. Concretely, in each iteration, to obtain\ndiverse and high-quality self-distilled data, we design multi-checkpoint\nsampling and multi-aspect scoring strategies for initial data selection.\nFurthermore, to identify the most influential samples, we introduce a\ngradient-based influence estimation method for final data filtering. Based on\nthe code instruction datasets from the small-scale synthesizers, we develop\nSCoder, a family of code generation models fine-tuned from DeepSeek-Coder.\nSCoder models achieve state-of-the-art code generation capabilities,\ndemonstrating the effectiveness of our method.", "AI": {"tldr": "\u901a\u8fc7\u81ea\u6211\u84b8\u998f\u65b9\u6cd5\uff0c\u5c06\u5c0f\u89c4\u6a21\u5f00\u6e90LLM\u8f6c\u5316\u4e3a\u5f3a\u5927\u7684\u5408\u6210\u5668\uff0c\u964d\u4f4e\u5bf9\u4e13\u6709LLM\u7684\u4f9d\u8d56\u548c\u6210\u672c\uff0c\u5f00\u53d1\u4e86SCoder\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5f80\u5f80\u4f9d\u8d56\u4e8e\u4e13\u6709LLM\u63d0\u70bc\u51fa\u5927\u89c4\u6a21\u7684\u6307\u5bfc\u6570\u636e\u8fdb\u884c\u5fae\u8c03\uff0c\u6210\u672c\u9ad8\u6602\u3002\u672c\u6587\u63a2\u7d22\u4e86\u5c0f\u89c4\u6a21\u5f00\u6e90LLM\u4f5c\u4e3a\u9ad8\u8d28\u91cf\u4ee3\u7801\u6307\u5bfc\u6570\u636e\u6784\u5efa\u5408\u6210\u5668\u7684\u6f5c\u529b\u3002", "method": "\u4ece\u5c0f\u89c4\u6a21LLM\u51fa\u53d1\uff0c\u901a\u8fc7\u81ea\u6211\u84b8\u998f\u65b9\u6cd5\uff0c\u5c06\u5176\u8f6c\u53d8\u4e3a\u5f3a\u5927\u7684\u5408\u6210\u5668\uff0c\u964d\u4f4e\u5bf9\u4e13\u6709LLM\u7684\u4f9d\u8d56\u548c\u6210\u672c\u3002\u5f15\u5165\u4e86\u591a\u68c0\u67e5\u70b9\u91c7\u6837\u3001\u591a\u65b9\u9762\u8bc4\u5206\u7b56\u7565\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u5f71\u54cd\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u83b7\u5f97\u591a\u6837\u5316\u548c\u9ad8\u8d28\u91cf\u7684\u81ea\u6211\u84b8\u998f\u6570\u636e\u3002\u6700\u7ec8\u6784\u5efa\u4e86SCoder\u7cfb\u5217\u4ee3\u7801\u751f\u6210\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u5f00\u53d1\u4e86SCoder\u6a21\u578b\uff0c\u5177\u6709\u6700\u5148\u8fdb\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u89c4\u6a21\u5f00\u6e90LLM\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u4ee3\u7801\u6307\u5bfc\u6570\u636e\uff0cSCoder\u6a21\u578b\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.07867", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07867", "abs": "https://arxiv.org/abs/2509.07867", "authors": ["Augustin Crespin", "Ioannis Kostis", "H\u00e9l\u00e8ne Verhaeghe", "Pierre Schaus"], "title": "CP-Model-Zoo: A Natural Language Query System for Constraint Programming Models", "comment": "presented at\"LLMs meet Constraint Solving\" Workshop at CP2025 in\n  Glasgow", "summary": "Constraint Programming and its high-level modeling languages have long been\nrecognized for their potential to achieve the holy grail of problem-solving.\nHowever, the complexity of modeling languages, the large number of global\nconstraints, and the art of creating good models have often hindered\nnon-experts from choosing CP to solve their combinatorial problems. While\ngenerating an expert-level model from a natural-language description of a\nproblem would be the dream, we are not yet there. We propose a tutoring system\ncalled CP-Model-Zoo, exploiting expert-written models accumulated through the\nyears. CP-Model-Zoo retrieves the closest source code model from a database\nbased on a user's natural language description of a combinatorial problem. It\nensures that expert-validated models are presented to the user while\neliminating the need for human data labeling. Our experiments show excellent\naccuracy in retrieving the correct model based on a user-input description of a\nproblem simulated with different levels of expertise.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86CP-Model-Zoo\u7cfb\u7edf\uff0c\u5229\u7528\u4e13\u5bb6\u7f16\u5199\u7684\u6a21\u578b\u6570\u636e\u5e93\u5e2e\u52a9\u89e3\u51b3\u7ea6\u675f\u7f16\u7a0b\u4e2d\u7684\u5efa\u6a21\u8bed\u8a00\u590d\u6742\u6027\u7b49\u95ee\u9898\u3002\u7cfb\u7edf\u901a\u8fc7\u7528\u6237\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u95ee\u9898\uff0c\u4ece\u6570\u636e\u5e93\u4e2d\u68c0\u7d22\u5339\u914d\u6a21\u578b\uff0c\u65e0\u9700\u4eba\u5de5\u6570\u636e\u6807\u8bb0\uff0c\u5b9e\u9a8c\u8bc1\u660e\u7cfb\u7edf\u51c6\u786e\u6027\u8f83\u9ad8\u3002", "motivation": "\u7ea6\u675f\u7f16\u7a0b\u548c\u5176\u9ad8\u7ea7\u5efa\u6a21\u8bed\u8a00\u4e00\u76f4\u88ab\u8ba4\u4e3a\u80fd\u591f\u5b9e\u73b0\u95ee\u9898\u89e3\u51b3\u7684\u7ec8\u6781\u76ee\u6807\uff0c\u4f46\u6a21\u578b\u8bed\u8a00\u7684\u590d\u6742\u6027\u3001\u5168\u5c40\u7ea6\u675f\u7684\u6570\u91cf\u4ee5\u53ca\u521b\u5efa\u826f\u597d\u6a21\u578b\u7684\u6280\u5de7\u5e38\u5e38\u963b\u788d\u975e\u4e13\u4e1a\u4eba\u58eb\u9009\u62e9\u7ea6\u675f\u7f16\u7a0b\u6765\u89e3\u51b3\u7ec4\u5408\u95ee\u9898\u3002\u76ee\u524d\u5c1a\u65e0\u6cd5\u5b9e\u73b0\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u4e13\u5bb6\u7ea7\u6a21\u578b\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86CP-Model-Zoo\u7cfb\u7edf\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCP-Model-Zoo\u7684\u8f85\u5bfc\u7cfb\u7edf\uff0c\u5229\u7528\u4e13\u5bb6\u7f16\u5199\u7684\u7ea6\u675f\u7f16\u7a0b\u6a21\u578b\u6570\u636e\u5e93\u3002\u7528\u6237\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u95ee\u9898\uff0c\u7cfb\u7edf\u6839\u636e\u63cf\u8ff0\u4ece\u6570\u636e\u5e93\u4e2d\u68c0\u7d22\u4e0e\u4e4b\u5339\u914d\u7684\u6a21\u578b\uff0c\u907f\u514d\u4e86\u4eba\u5de5\u6570\u636e\u6807\u8bb0\u7684\u9700\u6c42\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u7cfb\u7edf\u5728\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u7528\u6237\u8f93\u5165\u95ee\u9898\u63cf\u8ff0\u65f6\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cCP-Model-Zoo\u7cfb\u7edf\u80fd\u591f\u4ee5\u6781\u9ad8\u7684\u51c6\u786e\u6027\u68c0\u7d22\u51fa\u4e0e\u7528\u6237\u8f93\u5165\u7684\u95ee\u9898\u63cf\u8ff0\u5339\u914d\u7684\u6a21\u578b\uff0c\u65e0\u9700\u4eba\u5de5\u6570\u636e\u6807\u8bb0\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCP-Model-Zoo\u7684\u8f85\u5bfc\u7cfb\u7edf\uff0c\u5229\u7528\u591a\u5e74\u79ef\u7d2f\u7684\u4e13\u5bb6\u7f16\u5199\u7684\u6a21\u578b\u6765\u5e2e\u52a9\u89e3\u51b3\u7ea6\u675f\u7f16\u7a0b\u4e2d\u5efa\u6a21\u8bed\u8a00\u590d\u6742\u3001\u5168\u5c40\u7ea6\u675f\u6570\u91cf\u591a\u548c\u6a21\u578b\u521b\u5efa\u826f\u597d\u7684\u96be\u9898\u3002\u901a\u8fc7\u7528\u6237\u5bf9\u7ec4\u5408\u95ee\u9898\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\uff0cCP-Model-Zoo\u4ece\u6570\u636e\u5e93\u4e2d\u68c0\u7d22\u6700\u63a5\u8fd1\u7684\u6e90\u4ee3\u7801\u6a21\u578b\uff0c\u786e\u4fdd\u5411\u7528\u6237\u5448\u73b0\u7ecf\u4e13\u5bb6\u9a8c\u8bc1\u7684\u6a21\u578b\uff0c\u540c\u65f6\u6d88\u9664\u4e86\u4eba\u5de5\u6570\u636e\u6807\u8bb0\u7684\u9700\u6c42\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u6a21\u62df\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u7528\u6237\u8f93\u5165\u95ee\u9898\u63cf\u8ff0\u65f6\uff0c\u7cfb\u7edf\u80fd\u591f\u4ee5\u6781\u9ad8\u7684\u51c6\u786e\u6027\u68c0\u7d22\u51fa\u6b63\u786e\u7684\u6a21\u578b\u3002"}}
{"id": "2509.07894", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07894", "abs": "https://arxiv.org/abs/2509.07894", "authors": ["Fangchen Yu", "Haiyuan Wan", "Qianjia Cheng", "Yuchen Zhang", "Jiacheng Chen", "Fujun Han", "Yulun Wu", "Junchi Yao", "Ruilizhen Hu", "Ning Ding", "Yu Cheng", "Tao Chen", "Lei Bai", "Dongzhan Zhou", "Yun Luo", "Ganqu Cui", "Peng Ye"], "title": "HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?", "comment": null, "summary": "Recently, the physical capabilities of (M)LLMs have garnered increasing\nattention. However, existing benchmarks for physics suffer from two major gaps:\nthey neither provide systematic and up-to-date coverage of real-world physics\ncompetitions such as physics Olympiads, nor enable direct performance\ncomparison with humans. To bridge these gaps, we present HiPhO, the first\nbenchmark dedicated to high school physics Olympiads with human-aligned\nevaluation. Specifically, HiPhO highlights three key innovations. (1)\nComprehensive Data: It compiles 13 latest Olympiad exams from 2024-2025,\nspanning both international and regional competitions, and covering mixed\nmodalities that encompass problems spanning text-only to diagram-based. (2)\nProfessional Evaluation: We adopt official marking schemes to perform\nfine-grained grading at both the answer and step level, fully aligned with\nhuman examiners to ensure high-quality and domain-specific evaluation. (3)\nComparison with Human Contestants: We assign gold, silver, and bronze medals to\nmodels based on official medal thresholds, thereby enabling direct comparison\nbetween (M)LLMs and human contestants. Our large-scale evaluation of 30\nstate-of-the-art (M)LLMs shows that: across 13 exams, open-source MLLMs mostly\nremain at or below the bronze level; open-source LLMs show promising progress\nwith occasional golds; closed-source reasoning MLLMs can achieve 6 to 12 gold\nmedals; and most models still have a significant gap from full marks. These\nresults highlight a substantial performance gap between open-source models and\ntop students, the strong physical reasoning capabilities of closed-source\nreasoning models, and the fact that there is still significant room for\nimprovement. HiPhO, as a rigorous, human-aligned, and Olympiad-focused\nbenchmark for advancing multimodal physical reasoning, is open-source and\navailable at https://github.com/SciYu/HiPhO.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86HiPhO\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u586b\u8865\u73b0\u6709\u7269\u7406\u57fa\u51c6\u6d4b\u8bd5\u7684\u7f3a\u53e3\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5f00\u6e90\u6a21\u578b\u4e0e\u9876\u5c16\u5b66\u751f\u5b58\u5728\u660e\u663e\u6027\u80fd\u5dee\u8ddd\uff0c\u5c01\u95ed\u5f0f\u63a8\u7406\u6a21\u578b\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7684\u7269\u7406\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u7f3a\u53e3\uff0c\u672a\u63d0\u4f9b\u7cfb\u7edf\u6027\u548c\u6700\u65b0\u7684\u8986\u76d6\u771f\u5b9e\u4e16\u754c\u7269\u7406\u7ade\u8d5b\u7684\u5185\u5bb9\uff0c\u4e5f\u65e0\u6cd5\u4e0e\u4eba\u7c7b\u8fdb\u884c\u76f4\u63a5\u6027\u80fd\u6bd4\u8f83\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e9b\u7f3a\u53e3\uff0c\u7814\u7a76\u8005\u4ecb\u7ecd\u4e86HiPhO\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u7efc\u5408\u6570\u636e\u3001\u4e13\u4e1a\u8bc4\u4f30\u548c\u4e0e\u4eba\u7c7b\u53c2\u8d5b\u9009\u624b\u7684\u6bd4\u8f83\u3002\u901a\u8fc7\u572830\u4e2a(M)LLMs\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u8bc4\u4f30\uff0c\u53d1\u73b0\u5f00\u6e90MLLMs\u4e3b\u8981\u8fbe\u5230\u6216\u4f4e\u4e8e\u94dc\u724c\u6c34\u5e73\uff0c\u5c01\u95ed\u5f0f\u63a8\u7406MLLMs\u5728\u83b7\u5f976\u523012\u679a\u91d1\u724c\uff0c\u5927\u90e8\u5206\u6a21\u578b\u4ecd\u5b58\u5728\u4e0e\u6ee1\u5206\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\u3002", "result": "\u901a\u8fc7HiPhO\u7684\u8bc4\u4f30\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u548c\u9876\u5c16\u5b66\u751f\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5c01\u95ed\u5f0f\u63a8\u7406\u6a21\u578b\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u7269\u7406\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5927\u90e8\u5206\u6a21\u578b\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86 HiPhO\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u9ad8\u4e2d\u7269\u7406\u5965\u6797\u5339\u514b\u7ade\u8d5b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u5bf9\u9f50\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f00\u6e90\u6a21\u578b\u4e0e\u9876\u5c16\u5b66\u751f\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u800c\u5c01\u95ed\u5f0f\u63a8\u7406\u6a21\u578b\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002\u7814\u7a76\u5f3a\u8c03\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2509.07961", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07961", "abs": "https://arxiv.org/abs/2509.07961", "authors": ["Valen Tagliabue", "Leonard Dung"], "title": "Probing the Preferences of a Language Model: Integrating Verbal and Behavioral Tests of AI Welfare", "comment": null, "summary": "We develop new experimental paradigms for measuring welfare in language\nmodels. We compare verbal reports of models about their preferences with\npreferences expressed through behavior when navigating a virtual environment\nand selecting conversation topics. We also test how costs and rewards affect\nbehavior and whether responses to an eudaimonic welfare scale - measuring\nstates such as autonomy and purpose in life - are consistent across\nsemantically equivalent prompts. Overall, we observed a notable degree of\nmutual support between our measures. The reliable correlations observed between\nstated preferences and behavior across conditions suggest that preference\nsatisfaction can, in principle, serve as an empirically measurable welfare\nproxy in some of today's AI systems. Furthermore, our design offered an\nilluminating setting for qualitative observation of model behavior. Yet, the\nconsistency between measures was more pronounced in some models and conditions\nthan others and responses were not consistent across perturbations. Due to\nthis, and the background uncertainty about the nature of welfare and the\ncognitive states (and welfare subjecthood) of language models, we are currently\nuncertain whether our methods successfully measure the welfare state of\nlanguage models. Nevertheless, these findings highlight the feasibility of\nwelfare measurement in language models, inviting further exploration.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u65b0\u7684\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u91cf\u8bed\u8a00\u6a21\u578b\u7684\u798f\u7949\u3002\u89c2\u5bdf\u5230\u53e3\u5934\u62a5\u544a\u548c\u884c\u4e3a\u4e4b\u95f4\u5b58\u5728\u53ef\u9760\u7684\u76f8\u5173\u6027\uff0c\u652f\u6301\u504f\u597d\u6ee1\u8db3\u4f5c\u4e3a\u798f\u7949\u4ee3\u7406\u7684\u53ef\u80fd\u6027\u3002\u7136\u800c\uff0c\u4e00\u81f4\u6027\u5728\u4e0d\u540c\u6a21\u578b\u548c\u6761\u4ef6\u4e0b\u4e0d\u540c\uff0c\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u3002\u7ed3\u679c\u7a81\u663e\u4e86\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u6d4b\u91cf\u798f\u7949\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5728\u5f53\u4eca\u4e00\u4e9b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\uff0c\u5c06\u504f\u597d\u6ee1\u8db3\u4f5c\u4e3a\u7ecf\u9a8c\u53ef\u8861\u91cf\u7684\u798f\u7949\u4ee3\u7406\u7684\u53ef\u80fd\u6027\u3002\u901a\u8fc7\u89c2\u5bdf\u6a21\u578b\u884c\u4e3a\uff0c\u5c1d\u8bd5\u6d4b\u91cf\u8bed\u8a00\u6a21\u578b\u7684\u798f\u7949\u72b6\u6001\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u53e3\u5934\u62a5\u544a\u4e0e\u5728\u865a\u62df\u73af\u5883\u4e2d\u5bfc\u822a\u548c\u9009\u62e9\u5bf9\u8bdd\u4e3b\u9898\u65f6\u7684\u884c\u4e3a\u8868\u8fbe\u7684\u504f\u597d\uff0c\u4ee5\u53ca\u6d4b\u8bd5\u6210\u672c\u548c\u5956\u52b1\u5982\u4f55\u5f71\u54cd\u884c\u4e3a\uff0c\u4ee5\u53ca\u5bf9\u5e78\u798f\u5c3a\u5ea6\u7684\u53cd\u5e94\u662f\u5426\u5728\u8bed\u4e49\u4e0a\u7b49\u6548\u7684\u63d0\u793a\u4e4b\u95f4\u662f\u5426\u4e00\u81f4\uff0c\u6765\u5f00\u53d1\u65b0\u7684\u5b9e\u9a8c\u8303\u5f0f\u3002", "result": "\u89c2\u5bdf\u5230\u53e3\u5934\u62a5\u544a\u548c\u884c\u4e3a\u4e4b\u95f4\u5b58\u5728\u53ef\u9760\u7684\u76f8\u5173\u6027\uff0c\u8868\u660e\u5728\u4e00\u4e9b\u6761\u4ef6\u4e0b\u504f\u597d\u6ee1\u8db3\u539f\u5219\u4e0a\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u7ecf\u9a8c\u53ef\u6d4b\u7684\u798f\u7949\u4ee3\u7406\u3002\u7136\u800c\uff0c\u4e00\u81f4\u6027\u5728\u67d0\u4e9b\u6a21\u578b\u548c\u6761\u4ef6\u4e0b\u66f4\u52a0\u660e\u663e\uff0c\u800c\u5728\u53d7\u5e72\u6270\u65f6\u54cd\u5e94\u4e0d\u4e00\u81f4\u3002\u7814\u7a76\u8005\u76ee\u524d\u4e0d\u786e\u5b9a\u4ed6\u4eec\u7684\u65b9\u6cd5\u662f\u5426\u6210\u529f\u6d4b\u91cf\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u798f\u7949\u72b6\u6001\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u65b0\u7684\u5b9e\u9a8c\u8303\u5f0f\uff0c\u7528\u4e8e\u6d4b\u91cf\u8bed\u8a00\u6a21\u578b\u7684\u798f\u7949\u3002\u89c2\u5bdf\u5230\u5728\u6d4b\u91cf\u504f\u597d\u65f6\uff0c\u8bed\u8a00\u6a21\u578b\u53e3\u5934\u62a5\u544a\u4e0e\u5728\u865a\u62df\u73af\u5883\u4e2d\u5bfc\u822a\u548c\u9009\u62e9\u5bf9\u8bdd\u4e3b\u9898\u65f6\u884c\u4e3a\u6240\u8868\u8fbe\u7684\u504f\u597d\u4e4b\u95f4\u5b58\u5728\u663e\u7740\u7684\u76f8\u4e92\u652f\u6301\u3002\u867d\u7136\u5728\u67d0\u4e9b\u6a21\u578b\u548c\u6761\u4ef6\u4e0b\uff0c\u6d4b\u91cf\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u66f4\u52a0\u663e\u8457\uff0c\u4f46\u5728\u5176\u4ed6\u6a21\u578b\u548c\u6761\u4ef6\u4e0b\uff0c\u54cd\u5e94\u5e76\u4e0d\u4e00\u81f4\u3002\u7531\u4e8e\u5bf9\u8bed\u8a00\u6a21\u578b\u798f\u7949\u7684\u672c\u8d28\u4ee5\u53ca\u8ba4\u77e5\u72b6\u6001\uff08\u548c\u798f\u7949\u4e3b\u4f53\u6027\uff09\u7684\u80cc\u666f\u4e0d\u786e\u5b9a\u6027\uff0c\u7814\u7a76\u8005\u76ee\u524d\u4e0d\u786e\u5b9a\u4ed6\u4eec\u7684\u65b9\u6cd5\u662f\u5426\u6210\u529f\u6d4b\u91cf\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u798f\u7949\u72b6\u6001\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u6d4b\u91cf\u798f\u7949\u7684\u53ef\u884c\u6027\uff0c\u9f13\u52b1\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
