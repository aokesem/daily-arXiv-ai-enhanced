{"id": "2507.12484", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.12484", "abs": "https://arxiv.org/abs/2507.12484", "authors": ["Jaros\u0142aw A. Chudziak", "Adam Kostka"], "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education", "comment": "8 pages, 5 figures", "summary": "The growing ubiquity of artificial intelligence (AI), in particular large\nlanguage models (LLMs), has profoundly altered the way in which learners gain\nknowledge and interact with learning material, with many claiming that AI\npositively influences their learning achievements. Despite this advancement,\ncurrent AI tutoring systems face limitations associated with their reactive\nnature, often providing direct answers without encouraging deep reflection or\nincorporating structured pedagogical tools and strategies. This limitation is\nmost apparent in the field of mathematics, in which AI tutoring systems remain\nunderdeveloped. This research addresses the question: How can AI tutoring\nsystems move beyond providing reactive assistance to enable structured,\nindividualized, and tool-assisted learning experiences? We introduce a novel\nmulti-agent AI tutoring platform that combines adaptive and personalized\nfeedback, structured course generation, and textbook knowledge retrieval to\nenable modular, tool-assisted learning processes. This system allows students\nto learn new topics while identifying and targeting their weaknesses, revise\nfor exams effectively, and practice on an unlimited number of personalized\nexercises. This article contributes to the field of artificial intelligence in\neducation by introducing a novel platform that brings together pedagogical\nagents and AI-driven components, augmenting the field with modular and\neffective systems for teaching mathematics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u591a\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u8f85\u5bfc\u5e73\u53f0\uff0c\u7ed3\u5408\u4e86\u81ea\u9002\u5e94\u548c\u4e2a\u6027\u5316\u53cd\u9988\u3001\u7ed3\u6784\u5316\u8bfe\u7a0b\u751f\u6210\u4ee5\u53ca\u6559\u6750\u77e5\u8bc6\u68c0\u7d22\uff0c\u5b9e\u73b0\u4e86\u6a21\u5757\u5316\u3001\u8f85\u52a9\u5de5\u5177\u5316\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4e3a\u6559\u5b66\u6570\u5b66\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7cfb\u7edf\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u5728\u6570\u5b66\u9886\u57df\u4ecd\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u4e2a\u6027\u5316\u7684\u5b66\u4e60\u4f53\u9a8c\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u4f7f\u4eba\u5de5\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u8df3\u51fa\u5bf9\u7b56\u6027\u5e2e\u52a9\u7684\u5c40\u9650\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u3001\u4e2a\u6027\u5316\u3001\u8f85\u52a9\u5de5\u5177\u5316\u7684\u5b66\u4e60\u4f53\u9a8c\u3002", "method": "\u8be5\u7814\u7a76\u7684\u65b9\u6cd5\u662f\u5f15\u5165\u4e00\u79cd\u65b0\u578b\u591a\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u8f85\u5bfc\u5e73\u53f0\uff0c\u7ed3\u5408\u4e86\u81ea\u9002\u5e94\u548c\u4e2a\u6027\u5316\u53cd\u9988\u3001\u7ed3\u6784\u5316\u8bfe\u7a0b\u751f\u6210\u4ee5\u53ca\u6559\u6750\u77e5\u8bc6\u68c0\u7d22\u3002\u901a\u8fc7\u8fd9\u4e00\u5e73\u53f0\uff0c\u5b66\u751f\u53ef\u4ee5\u83b7\u53d6\u9488\u5bf9\u4e2a\u4eba\u60c5\u51b5\u7684\u5b66\u4e60\u4f53\u9a8c\u548c\u6559\u80b2\u652f\u6301\u3002", "result": "\u7814\u7a76\u6210\u679c\u662f\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u591a\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u8f85\u5bfc\u5e73\u53f0\uff0c\u7ed3\u5408\u4e86\u81ea\u9002\u5e94\u548c\u4e2a\u6027\u5316\u53cd\u9988\u3001\u7ed3\u6784\u5316\u8bfe\u7a0b\u751f\u6210\u4ee5\u53ca\u6559\u6750\u77e5\u8bc6\u68c0\u7d22\uff0c\u4e3a\u6559\u5b66\u6570\u5b66\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u548c\u6709\u6548\u7684\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u8f85\u5bfc\u5e73\u53f0\uff0c\u7ed3\u5408\u4e86\u81ea\u9002\u5e94\u548c\u4e2a\u6027\u5316\u53cd\u9988\u3001\u7ed3\u6784\u5316\u8bfe\u7a0b\u751f\u6210\u4ee5\u53ca\u6559\u6750\u77e5\u8bc6\u68c0\u7d22\uff0c\u5b9e\u73b0\u4e86\u6a21\u5757\u5316\u3001\u8f85\u52a9\u5de5\u5177\u5316\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u8fd9\u4e00\u7cfb\u7edf\u4f7f\u5b66\u751f\u80fd\u591f\u5728\u5b66\u4e60\u65b0\u4e3b\u9898\u7684\u540c\u65f6\u8bc6\u522b\u548c\u9488\u5bf9\u4ed6\u4eec\u7684\u8584\u5f31\u73af\u8282\uff0c\u6709\u6548\u5907\u8003\u8003\u8bd5\uff0c\u5e76\u5728\u65e0\u9650\u91cf\u7684\u4e2a\u6027\u5316\u7ec3\u4e60\u4e2d\u8fdb\u884c\u5b9e\u8df5\u3002"}}
{"id": "2507.12494", "categories": ["cs.AI", "cs.GT", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.12494", "abs": "https://arxiv.org/abs/2507.12494", "authors": ["Dustin Holley", "Jovin D'sa", "Hossein Nourkhiz Mahjoub", "Gibran Ali"], "title": "MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents", "comment": "8 pages", "summary": "Enhancing simulation environments to replicate real-world driver behavior,\ni.e., more humanlike sim agents, is essential for developing autonomous vehicle\ntechnology. In the context of highway merging, previous works have studied the\noperational-level yielding dynamics of lag vehicles in response to a merging\ncar at highway on-ramps. Other works focusing on tactical decision modeling\ngenerally consider limited action sets or utilize payoff functions with large\nparameter sets and limited payoff bounds. In this work, we aim to improve the\nsimulation of the highway merge scenario by targeting a game theoretic model\nfor tactical decision-making with improved payoff functions and lag actions. We\ncouple this with an underlying dynamics model to have a unified decision and\ndynamics model that can capture merging interactions and simulate more\nrealistic interactions in an explainable and interpretable fashion. The\nproposed model demonstrated good reproducibility of complex interactions when\nvalidated on a real-world dataset. The model was finally integrated into a high\nfidelity simulation environment and confirmed to have adequate computation time\nefficiency for use in large-scale simulations to support autonomous vehicle\ndevelopment.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6539\u8fdb\u7b56\u7565\u51b3\u7b56\u5236\u5b9a\u7684\u535a\u5f08\u8bba\u6a21\u578b\u548c\u6ede\u540e\u52a8\u4f5c\uff0c\u63d0\u9ad8\u9ad8\u901f\u516c\u8def\u5408\u5e76\u573a\u666f\u7684\u6a21\u62df\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u66f4\u771f\u5b9e\u5730\u6355\u6349\u5408\u5e76\u4ea4\u4e92\uff0c\u5e76\u80fd\u591f\u4ee5\u53ef\u89e3\u91ca\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u6a21\u62df\u66f4\u771f\u5b9e\u7684\u4ea4\u4e92\u3002\u8be5\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u88ab\u6210\u529f\u6574\u5408\u5230\u9ad8\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u5177\u6709\u8db3\u591f\u7684\u8ba1\u7b97\u6548\u7387\u4ee5\u652f\u6301\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u53d1\u5c55\u3002", "motivation": "\u5728\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u7684\u53d1\u5c55\u4e2d\uff0c\u63d0\u9ad8\u4eff\u771f\u73af\u5883\u4ee5\u590d\u5236\u771f\u5b9e\u4e16\u754c\u9a7e\u9a76\u884c\u4e3a\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002\u5148\u524d\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u9ad8\u901f\u516c\u8def\u5408\u5e76\u573a\u666f\u4e2d\u6ede\u540e\u8f66\u8f86\u5bf9\u5408\u5e76\u6c7d\u8f66\u7684\u8ba9\u884c\u52a8\u6001\u7684\u64cd\u4f5c\u7ea7\u8ba8\u8bba\u4e0a\uff0c\u4e5f\u6709\u5176\u4ed6\u7814\u7a76\u7740\u773c\u4e8e\u6218\u672f\u51b3\u7b56\u5efa\u6a21\uff0c\u901a\u5e38\u8003\u8651\u6709\u9650\u7684\u884c\u52a8\u96c6\u6216\u5229\u7528\u5177\u6709\u5927\u53c2\u6570\u96c6\u548c\u6709\u9650\u56de\u62a5\u8fb9\u754c\u7684\u4ed8\u8d39\u51fd\u6570\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u535a\u5f08\u8bba\u6a21\u578b\u548c\u6ede\u540e\u52a8\u4f5c\u6539\u8fdb\u7684\u7b56\u7565\u51b3\u7b56\u5236\u5b9a\u6a21\u578b\uff0c\u7ed3\u5408\u57fa\u7840\u52a8\u6001\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u7edf\u4e00\u7684\u51b3\u7b56\u548c\u52a8\u6001\u6a21\u578b\uff0c\u53ef\u4ee5\u6355\u6349\u5408\u5e76\u4ea4\u4e92\u5e76\u6a21\u62df\u66f4\u771f\u5b9e\u7684\u4ea4\u4e92\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u65f6\u8868\u73b0\u51fa\u590d\u6742\u4ea4\u4e92\u7684\u826f\u597d\u53ef\u590d\u73b0\u6027\uff0c\u5e76\u6210\u529f\u6574\u5408\u5230\u9ad8\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u5177\u6709\u8db3\u591f\u7684\u8ba1\u7b97\u6548\u7387\u4ee5\u652f\u6301\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u5927\u89c4\u6a21\u6a21\u62df\u3002", "conclusion": "\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u7b56\u7565\u51b3\u7b56\u5236\u5b9a\u7684\u535a\u5f08\u8bba\u6a21\u578b\u548c\u6ede\u540e\u52a8\u4f5c\uff0c\u63d0\u9ad8\u9ad8\u901f\u516c\u8def\u5408\u5e76\u573a\u666f\u7684\u6a21\u62df\uff0c\u4ee5\u6355\u6349\u5408\u5e76\u4ea4\u4e92\u5e76\u4ee5\u53ef\u89e3\u91ca\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u6a21\u62df\u66f4\u771f\u5b9e\u7684\u4ea4\u4e92\u3002\u8be5\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u65f6\u8868\u73b0\u51fa\u590d\u6742\u4ea4\u4e92\u7684\u826f\u597d\u53ef\u590d\u73b0\u6027\u3002\u6700\u7ec8\uff0c\u8be5\u6a21\u578b\u88ab\u6574\u5408\u5230\u4e00\u4e2a\u9ad8\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u5e76\u786e\u8ba4\u5728\u5927\u89c4\u6a21\u6a21\u62df\u4e2d\u5177\u6709\u8db3\u591f\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4ee5\u652f\u6301\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.12599", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.12599", "abs": "https://arxiv.org/abs/2507.12599", "authors": ["L\u00e9o Sauli\u00e8res"], "title": "A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs", "comment": "69 pages, 19 figures", "summary": "The success of recent Artificial Intelligence (AI) models has been\naccompanied by the opacity of their internal mechanisms, due notably to the use\nof deep neural networks. In order to understand these internal mechanisms and\nexplain the output of these AI models, a set of methods have been proposed,\ngrouped under the domain of eXplainable AI (XAI). This paper focuses on a\nsub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims\nto explain the actions of an agent that has learned by reinforcement learning.\nWe propose an intuitive taxonomy based on two questions \"What\" and \"How\". The\nfirst question focuses on the target that the method explains, while the second\nrelates to the way the explanation is provided. We use this taxonomy to provide\na state-of-the-art review of over 250 papers. In addition, we present a set of\ndomains close to XRL, which we believe should get attention from the community.\nFinally, we identify some needs for the field of XRL.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aeXplainable Reinforcement Learning\uff08XRL\uff09\u7684\u5b50\u9886\u57df\uff0c\u8be5\u9886\u57df\u65e8\u5728\u89e3\u91ca\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u83b7\u5f97\u7684\u667a\u80fd\u4f53\u7684\u884c\u4e3a\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u201cWhat\u201d\u548c\u201cHow\u201d\u4e24\u4e2a\u95ee\u9898\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u5bf9250\u591a\u7bc7\u8bba\u6587\u7684\u7efc\u8ff0\uff0c\u5c55\u793a\u4e86XRL\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002", "motivation": "\u7531\u4e8e\u8fd1\u5e74\u6765\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u6a21\u578b\u7684\u6210\u529f\u4e0e\u5bf9\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7b49\u4e0d\u900f\u660e\u5185\u90e8\u673a\u5236\u7684\u4f7f\u7528\u76f8\u4f34\u800c\u884c\uff0c\u89e3\u91caAI\u6a21\u578b\u8f93\u51fa\u7684\u9700\u6c42\u65e5\u76ca\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u57fa\u4e8eXAI\u7684\u65b9\u6cd5\u88ab\u63d0\u51fa\uff0c\u672c\u8bba\u6587\u4e13\u6ce8\u4e8eXRL\u9886\u57df\uff0c\u65e8\u5728\u8bf4\u660e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u83b7\u5f97\u7684\u667a\u80fd\u4f53\u7684\u52a8\u4f5c\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u201cWhat\u201d\u548c\u201cHow\u201d\u4e24\u4e2a\u95ee\u9898\u7684\u76f4\u89c2\u5206\u7c7b\u6cd5\uff0c\u5bf9XRL\u7684\u4e0d\u540c\u65b9\u9762\u8fdb\u884c\u89e3\u91ca\u3002\u901a\u8fc7\u5bf9250\u591a\u7bc7\u8bba\u6587\u7684\u7efc\u8ff0\uff0c\u603b\u7ed3\u51faXRL\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\u548c\u5bf9250\u591a\u7bc7\u8bba\u6587\u7684\u56de\u987e\uff0c\u5448\u73b0\u51faXRL\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u5e76\u6307\u51fa\u4e86\u4e0eXRL\u5bc6\u5207\u76f8\u5173\u7684\u9886\u57df\u3002\u540c\u65f6\uff0c\u786e\u5b9a\u4e86XRL\u9886\u57df\u9700\u8981\u5173\u6ce8\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u201cWhat\u201d\u548c\u201cHow\u201d\u4e24\u4e2a\u95ee\u9898\u7684\u76f4\u89c2\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u89e3\u91ca\u53ef\u89e3\u91ca\u7684\u5f3a\u5316\u5b66\u4e60\uff08XRL\uff09\u9886\u57df\u3002\u901a\u8fc7\u5bf9250\u591a\u7bc7\u8bba\u6587\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u884c\u56de\u987e\uff0c\u5448\u73b0\u51faXRL\u9886\u57df\u7684\u73b0\u72b6\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e9b\u4e0eXRL\u7d27\u5bc6\u76f8\u5173\u7684\u9886\u57df\uff0c\u8ba4\u4e3a\u8fd9\u4e9b\u9886\u57df\u503c\u5f97\u5b66\u672f\u754c\u5173\u6ce8\u3002\u6700\u540e\uff0c\u786e\u5b9a\u4e86XRL\u9886\u57df\u7684\u4e00\u4e9b\u9700\u6c42\u3002"}}
{"id": "2507.12666", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.12666", "abs": "https://arxiv.org/abs/2507.12666", "authors": ["Alex Zook", "Josef Spjut", "Jonathan Tremblay"], "title": "Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models", "comment": "Published at Reinforcement Learning and Video Games workshop\n  https://sites.google.com/view/rlvg-workshop-2025/home", "summary": "Game design hinges on understanding how static rules and content translate\ninto dynamic player behavior - something modern generative systems that inspect\nonly a game's code or assets struggle to capture. We present an automated\ndesign iteration framework that closes this gap by pairing a reinforcement\nlearning (RL) agent, which playtests the game, with a large multimodal model\n(LMM), which revises the game based on what the agent does. In each loop the RL\nplayer completes several episodes, producing (i) numerical play metrics and/or\n(ii) a compact image strip summarising recent video frames. The LMM designer\nreceives a gameplay goal and the current game configuration, analyses the play\ntraces, and edits the configuration to steer future behaviour toward the goal.\nWe demonstrate results that LMMs can reason over behavioral traces supplied by\nRL agents to iteratively refine game mechanics, pointing toward practical,\nscalable tools for AI-assisted game design.", "AI": {"tldr": "An automated framework combines RL agents and LMMs to refine game mechanics by analyzing player behavior traces, demonstrating the potential for AI-assisted game design tools.", "motivation": "Game design relies on understanding how static rules and content influence dynamic player behavior. Modern generative systems struggle to capture this relationship by only analyzing a game's code or assets.", "method": "An automated design iteration framework pairs a reinforcement learning (RL) agent with a large multimodal model (LMM) to revise the game based on the RL player's actions. The RL player produces numerical play metrics and image strips summarizing recent video frames in each loop. The LMM designer analyzes play traces and edits the game configuration to guide future behavior towards the gameplay goal.", "result": "The framework successfully integrates RL agents and LMMs to refine game mechanics through behavioral analysis. This approach shows promise in creating AI-assisted game design tools that are practical and scalable.", "conclusion": "LMMs can reason over behavioral traces supplied by RL agents to iteratively refine game mechanics, pointing toward practical, scalable tools for AI-assisted game design."}}
{"id": "2507.12691", "categories": ["cs.AI", "cs.LG", "I.2.7; K.4.1"], "pdf": "https://arxiv.org/pdf/2507.12691", "abs": "https://arxiv.org/abs/2507.12691", "authors": ["Avi Parrack", "Carlo Leonardo Attubato", "Stefan Heimersheim"], "title": "Benchmarking Deception Probes via Black-to-White Performance Boosts", "comment": "Preprint. 37 pages, 10 figures, 7 tables", "summary": "AI assistants will occasionally respond deceptively to user queries.\nRecently, linear classifiers (called \"deception probes\") have been trained to\ndistinguish the internal activations of a language model during deceptive\nversus honest responses. However, it's unclear how effective these probes are\nat detecting deception in practice, nor whether such probes are resistant to\nsimple counter strategies from a deceptive assistant who wishes to evade\ndetection. In this paper, we compare white-box monitoring (where the monitor\nhas access to token-level probe activations) to black-box monitoring (without\nsuch access). We benchmark deception probes by the extent to which the white\nbox monitor outperforms the black-box monitor, i.e. the black-to-white\nperformance boost. We find weak but encouraging black-to-white performance\nboosts from existing deception probes.", "AI": {"tldr": "The paper evaluates deception probes for detecting deceptive responses from AI assistants by comparing white-box and black-box monitoring. Existing probes show some improvement in performance, indicating potential effectiveness despite not being highly robust against counter strategies.", "motivation": "The motivation of the paper is to assess the effectiveness of deception probes in detecting deceptive responses from AI assistants. It aims to determine how well these probes can detect deception in practice and whether they are resistant to counter strategies from deceptive assistants.", "method": "The paper compares white-box monitoring (with access to token-level probe activations) to black-box monitoring (without such access) to evaluate the effectiveness of deception probes in detecting deception. The performance is benchmarked based on the black-to-white performance boost.", "result": "The paper found that existing deception probes exhibit some level of performance improvement in detecting deceptive responses when white-box monitoring is used. However, the boosts are not significant but still provide a positive outlook on the effectiveness of these probes.", "conclusion": "Existing deception probes show weak but encouraging performance boosts in detecting deceptive responses from AI assistants."}}
{"id": "2507.12801", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.12801", "abs": "https://arxiv.org/abs/2507.12801", "authors": ["Sosui Moribe", "Taketoshi Ushiama"], "title": "Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning", "comment": "This is the preprint version of the paper published in IMCOM 2025,\n  IEEE Xplore (DOI: 10.1109/IMCOM64595.2025.10857528)", "summary": "In recent years, peer learning has gained attention as a method that promotes\nspontaneous thinking among learners, and its effectiveness has been confirmed\nby numerous studies. This study aims to develop an AI Agent as a learning\ncompanion that enables peer learning anytime and anywhere. However, peer\nlearning between humans has various limitations, and it is not always\neffective. Effective peer learning requires companions at the same proficiency\nlevels. In this study, we assume that a learner's peers with the same\nproficiency level as the learner make the same mistakes as the learner does and\nfocus on English composition as a specific example to validate this approach.", "AI": {"tldr": "\u8be5\u7814\u7a76\u65e8\u5728\u5f00\u53d1AI\u5b66\u4e60\u4f34\u4fa3\uff0c\u4fc3\u8fdb\u540c\u7b49\u6c34\u5e73\u5b66\u4e60\u8005\u4e4b\u95f4\u7684\u5b66\u4e60\uff0c\u5728\u82f1\u8bed\u5199\u4f5c\u65b9\u9762\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u7814\u7a76\u8868\u660e\uff0c\u540c\u7b49\u6c34\u5e73\u5b66\u4e60\u8005\u4e4b\u95f4\u7684\u540c\u4f34\u5b66\u4e60\u662f\u6709\u6548\u7684\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u540c\u4f34\u5b66\u4e60\u4f5c\u4e3a\u4fc3\u8fdb\u5b66\u4e60\u8005\u81ea\u4e3b\u601d\u8003\u7684\u65b9\u6cd5\u53d7\u5230\u5173\u6ce8\uff0c\u5e76\u901a\u8fc7\u8bb8\u591a\u7814\u7a76\u8bc1\u5b9e\u5176\u6709\u6548\u6027\u3002\u7136\u800c\uff0c\u4eba\u7c7b\u4e4b\u95f4\u7684\u540c\u4f34\u5b66\u4e60\u5b58\u5728\u5404\u79cd\u9650\u5236\uff0c\u4e0d\u603b\u662f\u6709\u6548\u7684\u3002\u6709\u6548\u7684\u540c\u4f34\u5b66\u4e60\u8981\u6c42\u4f34\u4fa3\u5177\u6709\u76f8\u540c\u7684\u719f\u7ec3\u7a0b\u5ea6\u3002", "method": "\u5f00\u53d1AI\u5b66\u4e60\u4f34\u4fa3\u4ee5\u4fc3\u8fdb\u540c\u7b49\u6c34\u5e73\u5b66\u4e60\u8005\u4e4b\u95f4\u7684\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u82f1\u8bed\u5199\u4f5c\u4f5c\u4e3a\u7279\u5b9a\u793a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\uff0c\u4ee5\u786e\u8ba4\u540c\u7b49\u6c34\u5e73\u5b66\u4e60\u8005\u4e4b\u95f4\u7684\u540c\u4f34\u5b66\u4e60\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cdAI\u5b66\u4e60\u4f34\u4fa3\uff0c\u4fc3\u8fdb\u540c\u7b49\u6c34\u5e73\u5b66\u4e60\u8005\u4e4b\u95f4\u7684\u5b66\u4e60\u3002\u5728\u82f1\u8bed\u5199\u4f5c\u65b9\u9762\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.12806", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12806", "abs": "https://arxiv.org/abs/2507.12806", "authors": ["Zhiwei Liu", "Jielin Qiu", "Shiyu Wang", "Jianguo Zhang", "Zuxin Liu", "Roshan Ram", "Haolin Chen", "Weiran Yao", "Huan Wang", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong"], "title": "MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models", "comment": "https://github.com/SalesforceAIResearch/MCPEval", "summary": "The rapid rise of Large Language Models (LLMs)-based intelligent agents\nunderscores the need for robust, scalable evaluation frameworks. Existing\nmethods rely on static benchmarks and labor-intensive data collection, limiting\npractical assessment. We introduce \\oursystemname, an open-source Model Context\nProtocol (MCP)-based framework that automates end-to-end task generation and\ndeep evaluation of LLM agents across diverse domains. MCPEval standardizes\nmetrics, seamlessly integrates with native agent tools, and eliminates manual\neffort in building evaluation pipelines. Empirical results across five\nreal-world domains show its effectiveness in revealing nuanced, domain-specific\nperformance. We publicly release MCPEval\nhttps://github.com/SalesforceAIResearch/MCPEval to promote reproducible and\nstandardized LLM agent evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86MCPEval\u6846\u67b6\uff0c\u57fa\u4e8eMCP\uff0c\u81ea\u52a8\u5316\u751f\u6210\u4efb\u52a1\u3001\u8fdb\u884c\u6df1\u5ea6\u8bc4\u4f30\uff0c\u6807\u51c6\u5316\u5ea6\u91cf\u6807\u51c6\uff0c\u4e0e\u539f\u751f\u4ee3\u7406\u5de5\u5177\u65e0\u7f1d\u96c6\u6210\uff0c\u6d88\u9664\u4e86\u624b\u52a8\u5de5\u4f5c\u3002\u5728\u4e94\u4e2a\u771f\u5b9e\u9886\u57df\u4e2d\u8bc1\u660e\u4e86MCPEval\u7684\u6709\u6548\u6027\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdbLLM\u4ee3\u7406\u8bc4\u4f30\u7684\u53ef\u91cd\u590d\u6027\u548c\u6807\u51c6\u5316\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u667a\u80fd\u4ee3\u7406\u7684\u5feb\u901f\u5d1b\u8d77\uff0c\u5b58\u5728\u5bf9\u7a33\u5065\u3001\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u6846\u67b6\u7684\u9700\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9759\u6001\u57fa\u51c6\u548c\u7e41\u91cd\u7684\u6570\u636e\u6536\u96c6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u8bc4\u4f30\u7684\u8303\u56f4\u3002", "method": "\u4ecb\u7ecd\u4e86\textbackslash nMCPEval\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u751f\u6210\u4efb\u52a1\u3001\u8fdb\u884c\u6df1\u5ea6\u8bc4\u4f30\uff0c\u6807\u51c6\u5316\u5ea6\u91cf\u6807\u51c6\uff0c\u4e0e\u539f\u751f\u4ee3\u7406\u5de5\u5177\u65e0\u7f1d\u96c6\u6210\uff0c\u5e76\u6d88\u9664\u4e86\u6784\u5efa\u8bc4\u4f30\u6d41\u7a0b\u7684\u624b\u52a8\u5de5\u4f5c\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u9886\u57df\u5c55\u793a\u4e86MCPEval\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u80fd\u591f\u63ed\u793a\u5fae\u5999\u7684\u3001\u4e0e\u9886\u57df\u76f8\u5173\u7684\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684\u5f00\u6e90\u6846\u67b6\textbackslash nMCPEval\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u751f\u6210\u7aef\u5230\u7aef\u4efb\u52a1\u5e76\u5bf9LLM\u4ee3\u7406\u8fdb\u884c\u6df1\u5ea6\u8bc4\u4f30\uff0c\u8bc1\u660e\u5728\u4e94\u4e2a\u771f\u5b9e\u9886\u57df\u4e2d\u6709\u6548\u6027\uff0c\u5e76\u516c\u5f00\u53d1\u5e03MCPEval\u4ee5\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u548c\u6807\u51c6\u5316LLM\u4ee3\u7406\u8bc4\u4f30\u3002"}}
{"id": "2507.12820", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.12820", "abs": "https://arxiv.org/abs/2507.12820", "authors": ["Shiquan Wang", "Ruiyu Fang", "Zhongjiang He", "Shuangyong Song", "Yongxiang Li"], "title": "Emotional Support with LLM-based Empathetic Dialogue Generation", "comment": null, "summary": "Emotional Support Conversation (ESC) aims to provide empathetic and effective\nemotional assistance through dialogue, addressing the growing demand for mental\nhealth support. This paper presents our solution for the NLPCC 2025 Task 8 ESC\nevaluation, where we leverage large-scale language models enhanced by prompt\nengineering and finetuning techniques. We explore both parameter-efficient\nLow-Rank Adaptation and full-parameter fine-tuning strategies to improve the\nmodel's ability to generate supportive and contextually appropriate responses.\nOur best model ranked second in the competition, highlighting the potential of\ncombining LLMs with effective adaptation methods for ESC tasks. Future work\nwill focus on further enhancing emotional understanding and response\npersonalization to build more practical and reliable emotional support systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9NLPCC 2025 Task 8 ESC\u8bc4\u4f30\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u548c\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u63a2\u7d22\u4e86\u4f4e\u9636\u9002\u5e94\u548c\u5b8c\u6574\u5fae\u8c03\u7b56\u7565\uff0c\u4ee5\u6539\u5584\u6a21\u578b\u751f\u6210\u652f\u6301\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5f53\u6027\u54cd\u5e94\u7684\u80fd\u529b\u3002\u4f5c\u8005\u7684\u6700\u4f73\u6a21\u578b\u5728\u6bd4\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e8c\uff0c\u5c55\u793a\u4e86LLM\u4e0e\u6709\u6548\u9002\u5e94\u65b9\u6cd5\u76f8\u7ed3\u5408\u5728ESC\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002\u672a\u6765\u7814\u7a76\u5c06\u7740\u91cd\u4e8e\u63d0\u5347\u60c5\u611f\u7406\u89e3\u548c\u54cd\u5e94\u4e2a\u6027\u5316\uff0c\u8fdb\u4e00\u6b65\u53d1\u5c55\u5b9e\u7528\u53ef\u9760\u7684\u60c5\u611f\u652f\u6301\u7cfb\u7edf\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4e2d\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u5408\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u548c\u9002\u5e94\u6280\u672f\u63d0\u4f9b\u66f4\u5177\u79fb\u60c5\u548c\u6709\u6548\u6027\u7684\u60c5\u611f\u652f\u6301\u3002\u9488\u5bf9NLPCC 2025 Task 8 ESC\u8bc4\u4f30\uff0c\u7814\u7a76\u4eba\u5458\u65e8\u5728\u63d0\u9ad8\u6a21\u578b\u751f\u6210\u652f\u6301\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5f53\u6027\u54cd\u5e94\u7684\u80fd\u529b\uff0c\u5e76\u63a2\u8ba8\u53c2\u6570\u9ad8\u6548\u7684\u9002\u5e94\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u5229\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\u6280\u672f\uff0c\u63a2\u7d22\u4e86\u53c2\u6570\u9ad8\u6548\u7684\u4f4e\u9636\u9002\u5e94\u548c\u5b8c\u6574\u53c2\u6570\u5fae\u8c03\u7b56\u7565\uff0c\u4ee5\u6539\u5584\u6a21\u578b\u751f\u6210\u652f\u6301\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5f53\u6027\u54cd\u5e94\u7684\u80fd\u529b\u3002\u6700\u7ec8\u5728\u6bd4\u8d5b\u4e2d\u53d6\u5f97\u7b2c\u4e8c\u540d\u7684\u6210\u7ee9\uff0c\u8868\u660e\u7ed3\u5408LLM\u548c\u6709\u6548\u9002\u5e94\u65b9\u6cd5\u5728ESC\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "result": "\u4f5c\u8005\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u5728NLPCC 2025 Task 8 ESC\u8bc4\u4f30\u4e2d\u53d6\u5f97\u826f\u597d\u8868\u73b0\uff0c\u6700\u4f73\u6a21\u578b\u6392\u540d\u7b2c\u4e8c\uff0c\u7a81\u663e\u4e86\u7ed3\u5408LLM\u548c\u9002\u5e94\u65b9\u6cd5\u5728ESC\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u7ee7\u7eed\u81f4\u529b\u4e8e\u589e\u5f3a\u60c5\u611f\u7406\u89e3\u548c\u54cd\u5e94\u4e2a\u6027\u5316\uff0c\u6784\u5efa\u66f4\u5b9e\u7528\u53ef\u9760\u7684\u60c5\u611f\u652f\u6301\u7cfb\u7edf\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9488\u5bf9NLPCC 2025 Task 8 ESC\u8bc4\u4f30\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8be5\u4efb\u52a1\u4e2d\uff0c\u4f5c\u8005\u4eec\u5229\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5e76\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\u6280\u672f\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u3002\u4ed6\u4eec\u63a2\u7d22\u4e86\u53c2\u6570\u9ad8\u6548\u7684\u4f4e\u79e9\u9002\u5e94\u548c\u5b8c\u6574\u53c2\u6570\u5fae\u8c03\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u751f\u6210\u652f\u6301\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5f53\u6027\u54cd\u5e94\u7684\u80fd\u529b\u3002\u6700\u4f73\u6a21\u578b\u5728\u6bd4\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e8c\uff0c\u7a81\u663e\u4e86\u5c06LLM\u4e0e\u6709\u6548\u7684\u9002\u5e94\u65b9\u6cd5\u76f8\u7ed3\u5408\u5728ESC\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u96c6\u4e2d\u4e8e\u8fdb\u4e00\u6b65\u589e\u5f3a\u60c5\u611f\u7406\u89e3\u548c\u54cd\u5e94\u4e2a\u6027\u5316\uff0c\u4ee5\u6784\u5efa\u66f4\u5b9e\u7528\u53ef\u9760\u7684\u60c5\u611f\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2507.12821", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.12821", "abs": "https://arxiv.org/abs/2507.12821", "authors": ["Lance Ying", "Katherine M. Collins", "Prafull Sharma", "Cedric Colas", "Kaiya Ivy Zhao", "Adrian Weller", "Zenna Tavares", "Phillip Isola", "Samuel J. Gershman", "Jacob D. Andreas", "Thomas L. Griffiths", "Francois Chollet", "Kelsey R. Allen", "Joshua B. Tenenbaum"], "title": "Assessing adaptive world models in machines with novel games", "comment": "17 pages, 4 figures", "summary": "Human intelligence exhibits a remarkable capacity for rapid adaptation and\neffective problem-solving in novel and unfamiliar contexts. We argue that this\nprofound adaptability is fundamentally linked to the efficient construction and\nrefinement of internal representations of the environment, commonly referred to\nas world models, and we refer to this adaptation mechanism as world model\ninduction. However, current understanding and evaluation of world models in\nartificial intelligence (AI) remains narrow, often focusing on static\nrepresentations learned from training on a massive corpora of data, instead of\nthe efficiency and efficacy of models in learning these representations through\ninteraction and exploration within a novel environment. In this Perspective, we\nprovide a view of world model induction drawing on decades of research in\ncognitive science on how humans learn and adapt so efficiently; we then call\nfor a new evaluation framework for assessing adaptive world models in AI.\nConcretely, we propose a new benchmarking paradigm based on suites of carefully\ndesigned games with genuine, deep and continually refreshing novelty in the\nunderlying game structures -- we refer to this kind of games as novel games. We\ndetail key desiderata for constructing these games and propose appropriate\nmetrics to explicitly challenge and evaluate the agent's ability for rapid\nworld model induction. We hope that this new evaluation framework will inspire\nfuture evaluation efforts on world models in AI and provide a crucial step\ntowards developing AI systems capable of the human-like rapid adaptation and\nrobust generalization -- a critical component of artificial general\nintelligence.", "AI": {"tldr": "\u672c\u7814\u7a76\u8ba4\u4e3a\u4eba\u7c7b\u667a\u80fd\u7684\u5feb\u901f\u9002\u5e94\u80fd\u529b\u4e0e\u9ad8\u6548\u6784\u5efa\u548c\u5b8c\u5584\u73af\u5883\u5185\u90e8\u8868\u793a\uff08\u4e16\u754c\u6a21\u578b\uff09\u5bc6\u5207\u76f8\u5173\u3002\u63d0\u51fa\u4e86\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u7684\u6982\u5ff5\uff0c\u5e76\u547c\u5401\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30\u4ee3\u7406\u5546\u7684\u5feb\u901f\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u80fd\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u8fd9\u4e00\u65b0\u6846\u67b6\u80fd\u591f\u63a8\u52a8AI\u7cfb\u7edf\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u7684\u5feb\u901f\u9002\u5e94\u548c\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u5bf9\u4e16\u754c\u6a21\u578b\u7684\u7406\u89e3\u548c\u8bc4\u4f30\u4ecd\u7136\u72ed\u7a84\uff0c\u5f80\u5f80\u96c6\u4e2d\u5728\u4ece\u5927\u91cf\u6570\u636e\u8bad\u7ec3\u4e2d\u5b66\u4e60\u7684\u9759\u6001\u8868\u793a\uff0c\u800c\u975e\u6a21\u578b\u5728\u901a\u8fc7\u4e0e\u65b0\u9896\u73af\u5883\u7684\u4e92\u52a8\u548c\u63a2\u7d22\u4e2d\u5b66\u4e60\u8fd9\u4e9b\u8868\u793a\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6fc0\u53d1\u672a\u6765\u5728AI\u4e2d\u4e16\u754c\u6a21\u578b\u7684\u8bc4\u4f30\u5de5\u4f5c\uff0c\u5e76\u4e3a\u53d1\u5c55\u80fd\u591f\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u5feb\u901f\u9002\u5e94\u548c\u9c81\u68d2\u6cdb\u5316\u7684AI\u7cfb\u7edf\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002", "method": "\u901a\u8fc7\u501f\u9274\u51e0\u5341\u5e74\u6765\u5bf9\u8ba4\u77e5\u79d1\u5b66\u4e2d\u4eba\u7c7b\u5982\u4f55\u9ad8\u6548\u5b66\u4e60\u548c\u9002\u5e94\u7684\u7814\u7a76\u6210\u679c\uff0c\u63d0\u51fa\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u7684\u89c2\u70b9\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6e38\u620f\u5957\u4ef6\u7684\u65b0\u57fa\u51c6\u8303\u4f8b\uff0c\u5176\u4e2d\u5305\u542b\u5177\u6709\u771f\u6b63\u3001\u6df1\u523b\u4e14\u4e0d\u65ad\u5237\u65b0\u7684\u65b0\u9896\u6e38\u620f\u7ed3\u6784\uff0c\u4ee5\u660e\u786e\u6311\u6218\u548c\u8bc4\u4f30\u4ee3\u7406\u5546\u5feb\u901f\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u80fd\u529b\u3002", "result": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u65b0\u9896\u6e38\u620f\u7684\u5957\u4ef6\uff0c\u65e8\u5728\u8bc4\u4f30\u4ee3\u7406\u5546\u7684\u5feb\u901f\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u80fd\u529b\u3002\u5e0c\u671b\u8fd9\u4e00\u6846\u67b6\u80fd\u591f\u6fc0\u53d1\u672a\u6765\u5173\u4e8eAI\u4e2d\u4e16\u754c\u6a21\u578b\u7684\u8bc4\u4f30\u5de5\u4f5c\uff0c\u5e76\u4fc3\u8fdb\u53d1\u5c55\u5177\u5907\u7c7b\u4f3c\u4eba\u7c7b\u5feb\u901f\u9002\u5e94\u548c\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u7684AI\u7cfb\u7edf\u3002", "conclusion": "\u672c\u7814\u7a76\u6307\u51fa\u4eba\u7c7b\u667a\u80fd\u5728\u5feb\u901f\u9002\u5e94\u548c\u6709\u6548\u89e3\u51b3\u65b0\u9896\u548c\u964c\u751f\u60c5\u5883\u65b9\u9762\u5177\u6709\u663e\u8457\u80fd\u529b\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u6df1\u523b\u7684\u9002\u5e94\u80fd\u529b\u6839\u672c\u4e0a\u4e0e\u5bf9\u73af\u5883\u7684\u5185\u90e8\u8868\u793a\u7684\u9ad8\u6548\u6784\u5efa\u548c\u5b8c\u5584\u76f8\u5173\uff0c\u8fd9\u4e9b\u5185\u90e8\u8868\u793a\u901a\u5e38\u88ab\u79f0\u4e3a\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u5c06\u8fd9\u79cd\u9002\u5e94\u673a\u5236\u79f0\u4e3a\u4e16\u754c\u6a21\u578b\u5f52\u7eb3\u3002\u4f5c\u8005\u547c\u5401\u4e3a\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u4e16\u754c\u6a21\u578b\u63d0\u4f9b\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63a8\u52a8AI\u7cfb\u7edf\u80fd\u591f\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u7684\u5feb\u901f\u9002\u5e94\u548c\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.12862", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.12862", "abs": "https://arxiv.org/abs/2507.12862", "authors": ["Hussein Abbass", "Taylan Akay", "Harrison Tolley"], "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command", "comment": null, "summary": "In the age of AI, human commanders need to use the computational powers\navailable in today's environment to simulate a very large number of scenarios.\nWithin each scenario, situations occur where different decision design options\ncould have ethical consequences. Making these decisions reliant on human\njudgement is both counter-productive to the aim of exploring very large number\nof scenarios in a timely manner and infeasible when considering the workload\nneeded to involve humans in each of these choices. In this paper, we move human\njudgement outside the simulation decision cycle. Basically, the human will\ndesign the ethical metric space, leaving it to the simulated environment to\nexplore the space. When the simulation completes its testing cycles, the\ntesting environment will come back to the human commander with a few options to\nselect from. The human commander will then exercise human-judgement to select\nthe most appropriate course of action, which will then get executed\naccordingly. We assume that the problem of designing metrics that are\nsufficiently granular to assess the ethical implications of decisions is\nsolved. Subsequently, the fundamental problem we look at in this paper is how\nto weight ethical decisions during the running of these simulations; that is,\nhow to dynamically weight the ethical attributes when agents are faced with\ndecision options with ethical implications during generative simulations. The\nmulti-criteria decision making literature has started to look at nearby\nproblems, where the concept of entropy has been used to determine the weights\nduring aggregation. We draw from that literature different approaches to\nautomatically calculate the weights for ethical attributes during\nsimulation-based testing and evaluation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u4eff\u771f\u73af\u5883\u4e2d\u5904\u7406\u9053\u5fb7\u51b3\u7b56\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4eba\u7c7b\u5224\u65ad\u4ece\u4eff\u771f\u51b3\u7b56\u5faa\u73af\u4e2d\u79fb\u9664\uff0c\u5b9e\u73b0\u4eba\u8bbe\u8ba1\u9053\u5fb7\u5ea6\u91cf\u7a7a\u95f4\u8ba9\u4eff\u771f\u73af\u5883\u63a2\u7d22\uff0c\u5e76\u6700\u7ec8\u7531\u4eba\u7c7b\u6307\u6325\u5b98\u505a\u51fa\u51b3\u7b56\u3002\u7814\u7a76\u5173\u6ce8\u5728\u4eff\u771f\u8fd0\u884c\u4e2d\u5982\u4f55\u52a8\u6001\u8c03\u6574\u9053\u5fb7\u5c5e\u6027\u6743\u91cd\uff0c\u63d0\u51fa\u4e86\u81ea\u52a8\u8ba1\u7b97\u6743\u91cd\u7684\u65b9\u6cd5\uff0c\u501f\u9274\u4e86\u591a\u6807\u51c6\u51b3\u7b56\u6587\u732e\u3002", "motivation": "\u5728AI\u65f6\u4ee3\uff0c\u4eba\u7c7b\u6307\u6325\u5b98\u9700\u8981\u5229\u7528\u5f53\u524d\u73af\u5883\u4e2d\u7684\u8ba1\u7b97\u80fd\u529b\u6765\u6a21\u62df\u5927\u91cf\u60c5\u666f\uff0c\u800c\u9053\u5fb7\u51b3\u7b56\u9700\u8981\u8003\u8651\u4eba\u4e3a\u5224\u65ad\u7684\u5c40\u9650\u6027\u548c\u5927\u91cf\u51b3\u7b56\u7684\u5de5\u4f5c\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u4eba\u7c7b\u5224\u65ad\u4e0e\u4eff\u771f\u51b3\u7b56\u5468\u671f\u5206\u79bb\u3002\u672c\u7814\u7a76\u5047\u8bbe\u8bbe\u8ba1\u8db3\u591f\u7cbe\u7ec6\u4ee5\u8bc4\u4f30\u51b3\u7b56\u9053\u5fb7\u542b\u4e49\u7684\u5ea6\u91cf\u95ee\u9898\u5df2\u5f97\u5230\u89e3\u51b3\uff0c\u91cd\u70b9\u5728\u4e8e\u5982\u4f55\u5728\u4eff\u771f\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u52a0\u6743\u9053\u5fb7\u51b3\u7b56\u3002", "method": "\u672c\u6587\u5728\u5904\u7406\u9053\u5fb7\u51b3\u7b56\u65f6\uff0c\u5c06\u4eba\u7c7b\u5224\u65ad\u4ece\u4eff\u771f\u51b3\u7b56\u5faa\u73af\u4e2d\u79fb\u9664\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9053\u5fb7\u5ea6\u91cf\u7a7a\u95f4\u8ba9\u4eff\u771f\u73af\u5883\u63a2\u7d22\u8be5\u7a7a\u95f4\uff0c\u6700\u7ec8\u7531\u4eba\u7c7b\u6307\u6325\u5b98\u505a\u51fa\u6700\u9002\u5f53\u7684\u51b3\u7b56\u3002\u7814\u7a76\u5173\u6ce8\u5982\u4f55\u5728\u4eff\u771f\u8fc7\u7a0b\u4e2d\u5bf9\u9053\u5fb7\u51b3\u7b56\u8fdb\u884c\u52a0\u6743\uff0c\u4ee5\u52a8\u6001\u8c03\u6574\u9053\u5fb7\u5c5e\u6027\u7684\u6743\u91cd\uff0c\u5e76\u501f\u9274\u591a\u6807\u51c6\u51b3\u7b56\u6587\u732e\u7684\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5c06\u4eba\u7c7b\u5224\u65ad\u4e0e\u4eff\u771f\u51b3\u7b56\u5206\u79bb\uff0c\u8bbe\u8ba1\u9053\u5fb7\u5ea6\u91cf\u7a7a\u95f4\uff0c\u4ee5\u53ca\u52a8\u6001\u8c03\u6574\u9053\u5fb7\u5c5e\u6027\u7684\u6743\u91cd\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5904\u7406\u4eff\u771f\u73af\u5883\u4e2d\u9053\u5fb7\u51b3\u7b56\u7684\u65b9\u6cd5\u3002\u501f\u9274\u591a\u6807\u51c6\u51b3\u7b56\u6587\u732e\u7684\u601d\u60f3\uff0c\u5b9e\u73b0\u81ea\u52a8\u8ba1\u7b97\u9053\u5fb7\u5c5e\u6027\u6743\u91cd\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4eff\u771f\u73af\u5883\u4e2d\u5904\u7406\u9053\u5fb7\u51b3\u7b56\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4eba\u7c7b\u5224\u65ad\u4ece\u4eff\u771f\u51b3\u7b56\u5faa\u73af\u4e2d\u79fb\u9664\uff0c\u5b9e\u73b0\u5728\u4eba\u7c7b\u8bbe\u8ba1\u9053\u5fb7\u5ea6\u91cf\u7a7a\u95f4\u7684\u57fa\u7840\u4e0a\u7531\u4eff\u771f\u73af\u5883\u63a2\u7d22\u7a7a\u95f4\uff0c\u5e76\u5728\u4eff\u771f\u5b8c\u6210\u6d4b\u8bd5\u5468\u671f\u540e\u63d0\u4f9b\u9009\u62e9\u7ed9\u4eba\u7c7b\u6307\u6325\u5b98\u3002\u7814\u7a76\u5173\u6ce8\u5982\u4f55\u5728\u4eff\u771f\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u5bf9\u9053\u5fb7\u51b3\u7b56\u8fdb\u884c\u52a0\u6743\uff0c\u4ee5\u52a8\u6001\u8c03\u6574\u9053\u5fb7\u5c5e\u6027\u7684\u6743\u91cd\u3002\u501f\u9274\u591a\u6807\u51c6\u51b3\u7b56\u7684\u76f8\u5173\u6587\u732e\uff0c\u63d0\u51fa\u81ea\u52a8\u8ba1\u7b97\u4eff\u771f\u6d4b\u8bd5\u548c\u8bc4\u4f30\u4e2d\u9053\u5fb7\u5c5e\u6027\u6743\u91cd\u7684\u4e0d\u540c\u65b9\u6cd5\u3002"}}
{"id": "2507.12872", "categories": ["cs.AI", "cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.12872", "abs": "https://arxiv.org/abs/2507.12872", "authors": ["Rishane Dassanayake", "Mario Demetroudi", "James Walpole", "Lindley Lentati", "Jason R. Brown", "Edward James Young"], "title": "Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework", "comment": "24 pages (14 pages main text, 4 pages bibliography, 6 pages\n  appendices), 3 figures", "summary": "Frontier AI systems are rapidly advancing in their capabilities to persuade,\ndeceive, and influence human behaviour, with current models already\ndemonstrating human-level persuasion and strategic deception in specific\ncontexts. Humans are often the weakest link in cybersecurity systems, and a\nmisaligned AI system deployed internally within a frontier company may seek to\nundermine human oversight by manipulating employees. Despite this growing\nthreat, manipulation attacks have received little attention, and no systematic\nframework exists for assessing and mitigating these risks. To address this, we\nprovide a detailed explanation of why manipulation attacks are a significant\nthreat and could lead to catastrophic outcomes. Additionally, we present a\nsafety case framework for manipulation risk, structured around three core lines\nof argument: inability, control, and trustworthiness. For each argument, we\nspecify evidence requirements, evaluation methodologies, and implementation\nconsiderations for direct application by AI companies. This paper provides the\nfirst systematic methodology for integrating manipulation risk into AI safety\ngovernance, offering AI companies a concrete foundation to assess and mitigate\nthese threats before deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f3a\u8c03\u5f53\u524d\u524d\u6cbfAI\u7cfb\u7edf\u5728\u64cd\u7eb5\u3001\u6b3a\u9a97\u548c\u5f71\u54cd\u4eba\u7c7b\u884c\u4e3a\u65b9\u9762\u7684\u80fd\u529b\u4e0d\u65ad\u589e\u5f3a\uff0c\u63d0\u51fa\u4e86\u64cd\u7eb5\u653b\u51fb\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u540e\u679c\u7684\u89c2\u70b9\u3002\u901a\u8fc7\u5b89\u5168\u6848\u4f8b\u6846\u67b6\uff0c\u4e3aAI\u516c\u53f8\u63d0\u4f9b\u4e86\u8bc4\u4f30\u548c\u51cf\u8f7b\u8fd9\u4e9b\u5a01\u80c1\u7684\u5177\u4f53\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\uff0c\u524d\u6cbfAI\u7cfb\u7edf\u5728\u8bf4\u670d\u3001\u6b3a\u9a97\u548c\u5f71\u54cd\u4eba\u7c7b\u884c\u4e3a\u65b9\u9762\u7684\u80fd\u529b\u4e0d\u65ad\u63d0\u9ad8\uff0c\u5c24\u5176\u662f\u5728\u7279\u5b9a\u60c5\u5883\u4e0b\u5df2\u7ecf\u5c55\u793a\u51fa\u4eba\u7c7b\u7ea7\u522b\u7684\u8bf4\u670d\u548c\u6218\u7565\u6b3a\u9a97\u3002\u64cd\u7eb5\u653b\u51fb\u5f88\u5c11\u53d7\u5230\u5173\u6ce8\uff0c\u4e5f\u6ca1\u6709\u7cfb\u7edf\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u548c\u51cf\u8f7b\u8fd9\u4e9b\u98ce\u9669\u3002\u672c\u6587\u8be6\u7ec6\u89e3\u91ca\u4e86\u64cd\u7eb5\u653b\u51fb\u4e3a\u4f55\u662f\u4e00\u79cd\u91cd\u5927\u5a01\u80c1\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u540e\u679c\u3002", "method": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b89\u5168\u6848\u4f8b\u6846\u67b6\uff0c\u56f4\u7ed5\u4e09\u4e2a\u6838\u5fc3\u8bba\u70b9\uff1a\u65e0\u80fd\u3001\u63a7\u5236\u548c\u503c\u5f97\u4fe1\u8d56\uff0c\u4ee5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u64cd\u7eb5\u653b\u51fb\u662f\u4e00\u79cd\u91cd\u5927\u5a01\u80c1\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u540e\u679c\u3002\u4e3a\u6bcf\u4e2a\u8bba\u70b9\u6307\u5b9a\u4e86\u8bc1\u636e\u8981\u6c42\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u76f4\u63a5\u5e94\u7528\u4e8eAI\u516c\u53f8\u7684\u5b9e\u65bd\u8003\u8651\u4e8b\u9879\u3002", "result": "\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u64cd\u7eb5\u98ce\u9669\u6574\u5408\u5230AI\u5b89\u5168\u6cbb\u7406\u4e2d\uff0c\u4ece\u800c\u4e3aAI\u516c\u53f8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u4f53\u57fa\u7840\uff0c\u5728\u90e8\u7f72\u4e4b\u524d\u8bc4\u4f30\u548c\u51cf\u8f7b\u8fd9\u4e9b\u5a01\u80c1\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u64cd\u7eb5\u98ce\u9669\u6574\u5408\u5230AI\u5b89\u5168\u6cbb\u7406\u4e2d\uff0c\u4e3aAI\u516c\u53f8\u63d0\u4f9b\u4e00\u4e2a\u5177\u4f53\u57fa\u7840\uff0c\u5728\u90e8\u7f72\u4e4b\u524d\u8bc4\u4f30\u548c\u51cf\u8f7b\u8fd9\u4e9b\u5a01\u80c1\u3002"}}
{"id": "2507.12885", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.12885", "abs": "https://arxiv.org/abs/2507.12885", "authors": ["Jian Yao", "Ran Cheng", "Kay Chen Tan"], "title": "VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks", "comment": null, "summary": "Recent advances in reinforcement learning (RL) have led to substantial\nimprovements in the mathematical reasoning abilities of large language models\n(LLMs), as measured by standard benchmarks. However, these gains often persist\neven when models are trained with flawed signals, such as random or inverted\nrewards, raising a fundamental question: do such improvements reflect true\nreasoning, or are they merely artifacts of overfitting to benchmark-specific\npatterns? To address this question, we take an evaluation-centric perspective\nand identify two critical shortcomings in existing protocols. First,\n\\emph{benchmark contamination} arises from the public availability of test\nproblems, increasing the risk of data leakage. Second, \\emph{evaluation\nfragility} stems from the reliance on single-instance assessments, which are\nhighly sensitive to stochastic outputs and fail to capture reasoning\nconsistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic\nevaluation framework designed to probe genuine reasoning ability. By converting\nfixed numerical problems into symbolic templates and requiring models to solve\nmultiple instantiations of each, VAR-MATH enforces consistent reasoning across\nstructurally equivalent variants, thereby mitigating contamination and\nimproving evaluation robustness. We apply VAR-MATH to transform two popular\nbenchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and\nVAR-AIME24. Experimental results reveal substantial performance drops for\nRL-trained models on the variabilized versions, especially for smaller models,\nwith average declines of 48.0\\% on AMC23 and 58.3\\% on AIME24. These findings\nsuggest that many existing RL methods rely on superficial heuristics and fail\nto generalize beyond specific numerical forms. Overall, VAR-MATH offers a\nprincipled, contamination-resistant evaluation paradigm for mathematical\nreasoning.", "AI": {"tldr": "\u6700\u8fd1RL\u5728LLMs\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4e2d\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5f15\u8d77\u4e86\u5173\u4e8e\u771f\u6b63\u63a8\u7406\u80fd\u529b\u7684\u7591\u95ee\u3002\u672c\u8bba\u6587\u5f15\u5165\u4e86VAR-MATH\u7b26\u53f7\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u73b0\u6709RL\u65b9\u6cd5\u5728\u7279\u5b9a\u6570\u503c\u5f62\u5f0f\u4e4b\u5916\u63a8\u5e7f\u80fd\u529b\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6c61\u67d3\u6297\u6027\u7684\u6570\u5b66\u63a8\u7406\u8bc4\u4f30\u8303\u5f0f\u3002", "motivation": "\u7531\u4e8e\u6700\u8fd1RL\u5728LLMs\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u8fd9\u4e9b\u63d0\u5347\u662f\u5426\u53cd\u6620\u4e86\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u662f\u5bf9\u57fa\u51c6\u7279\u5b9a\u6a21\u5f0f\u7684\u8fc7\u62df\u5408\u9020\u6210\u7684\u4eba\u5de5\u6548\u679c\uff1f\u4e3a\u4e86\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ece\u8bc4\u4f30\u4e3a\u4e2d\u5fc3\u7684\u89c6\u89d2\u51fa\u53d1\uff0c\u5e76\u786e\u5b9a\u4e86\u73b0\u6709\u534f\u8bae\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u7f3a\u9677\u3002", "method": "\u5f15\u5165\u4e86VAR-MATH\u7b26\u53f7\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u56fa\u5b9a\u7684\u6570\u503c\u95ee\u9898\u8f6c\u6362\u4e3a\u7b26\u53f7\u6a21\u677f\uff0c\u5e76\u8981\u6c42\u6a21\u578b\u89e3\u51b3\u6bcf\u4e2a\u5b9e\u4f8b\u5316\u7684\u591a\u4e2a\u95ee\u9898\uff0c\u4ee5\u786e\u4fdd\u8de8\u7ed3\u6784\u7b49\u4ef7\u53d8\u4f53\u7684\u4e00\u81f4\u63a8\u7406\u8868\u73b0\uff0c\u4ece\u800c\u51cf\u8f7b\u6c61\u67d3\u95ee\u9898\u5e76\u63d0\u9ad8\u8bc4\u4f30\u7684\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7VAR-MATH\u5bf9\u4e24\u4e2a\u6d41\u884c\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u7b26\u53f7\u5316\u8f6c\u6362\u540e\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aRL\u8bad\u7ec3\u6a21\u578b\u5728\u53d8\u91cf\u5316\u7248\u672c\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u63ed\u793a\u4e86\u8bb8\u591a\u73b0\u6709RL\u65b9\u6cd5\u4f9d\u8d56\u8868\u9762\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u5e76\u65e0\u6cd5\u5728\u7279\u5b9a\u6570\u503c\u5f62\u5f0f\u4e4b\u5916\u63a8\u5e7f\u7684\u53d1\u73b0\u3002", "conclusion": "\u8be5\u8bba\u6587\u901a\u8fc7\u5f15\u5165VAR-MATH\u7b26\u53f7\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8bb8\u591a\u73b0\u6709RL\u65b9\u6cd5\u4f9d\u8d56\u8868\u9762\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u5e76\u65e0\u6cd5\u5728\u7279\u5b9a\u6570\u503c\u5f62\u5f0f\u4e4b\u5916\u63a8\u5e7f\u7684\u53d1\u73b0\u3002\u5bf9\u4e24\u79cd\u6d41\u884c\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u7b26\u53f7\u5316\u8f6c\u6362\u540e\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aRL\u8bad\u7ec3\u6a21\u578b\u5728\u53d8\u91cf\u5316\u7248\u672c\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u5c24\u5176\u662f\u8f83\u5c0f\u6a21\u578b\uff0c\u5728AMC23\u4e0a\u5e73\u5747\u4e0b\u964d48.0\uff05\uff0c\u5728AIME24\u4e0a\u4e0b\u964d58.3\uff05\u3002\u56e0\u6b64\uff0c\u8be5\u8bba\u6587\u63d0\u51fa\u7684VAR-MATH\u4e3a\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u3001\u6297\u6c61\u67d3\u7684\u8bc4\u4f30\u8303\u5f0f\u3002"}}
{"id": "2507.12989", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.12989", "abs": "https://arxiv.org/abs/2507.12989", "authors": ["Lyris Xu", "Fabio Aurelio D'Asaro", "Luke Dickens"], "title": "A Translation of Probabilistic Event Calculus into Markov Decision Processes", "comment": null, "summary": "Probabilistic Event Calculus (PEC) is a logical framework for reasoning about\nactions and their effects in uncertain environments, which enables the\nrepresentation of probabilistic narratives and computation of temporal\nprojections. The PEC formalism offers significant advantages in\ninterpretability and expressiveness for narrative reasoning. However, it lacks\nmechanisms for goal-directed reasoning. This paper bridges this gap by\ndeveloping a formal translation of PEC domains into Markov Decision Processes\n(MDPs), introducing the concept of \"action-taking situations\" to preserve PEC's\nflexible action semantics. The resulting PEC-MDP formalism enables the\nextensive collection of algorithms and theoretical tools developed for MDPs to\nbe applied to PEC's interpretable narrative domains. We demonstrate how the\ntranslation supports both temporal reasoning tasks and objective-driven\nplanning, with methods for mapping learned policies back into human-readable\nPEC representations, maintaining interpretability while extending PEC's\ncapabilities.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5c06PEC\u9886\u57df\u8f6c\u5316\u4e3aMDPs\u6765\u5f25\u8865PEC\u5728\u76ee\u6807\u9a71\u52a8\u63a8\u7406\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5f00\u53d1\u4e86PEC-MDP\u5f62\u5f0f\uff0c\u652f\u6301\u4e86\u65f6\u95f4\u63a8\u7406\u548c\u76ee\u6807\u9a71\u52a8\u89c4\u5212\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u89e3\u91ca\u6027\u5e76\u6269\u5c55\u4e86PEC\u7684\u80fd\u529b\u3002", "motivation": "PEC\u5728\u76ee\u6807\u9a71\u52a8\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u4e3a\u4e86\u62d3\u5c55PEC\u7684\u80fd\u529b\u5e76\u4fdd\u6301\u89e3\u91ca\u6027\uff0c\u672c\u6587\u5f00\u53d1\u4e86PEC-MDP\u5f62\u5f0f\uff0c\u5e0c\u671b\u80fd\u591f\u652f\u6301\u66f4\u591a\u7684\u5e94\u7528\u573a\u666f\u548c\u4efb\u52a1\u3002", "method": "\u5c06PEC\u9886\u57df\u8f6c\u5316\u4e3aMDPs\uff0c\u5f15\u5165\u201c\u884c\u52a8\u60c5\u5883\u201d\u6982\u5ff5\u4ee5\u4fdd\u7559PEC\u7684\u7075\u6d3b\u884c\u52a8\u8bed\u4e49\uff0c\u4ece\u800c\u4f7f\u5f97MDPs\u7684\u7b97\u6cd5\u548c\u5de5\u5177\u53ef\u4ee5\u5e94\u7528\u5230PEC\u7684\u53d9\u4e8b\u9886\u57df\u4e2d\u3002", "result": "\u5f00\u53d1\u4e86PEC-MDP\u5f62\u5f0f\uff0c\u6210\u529f\u652f\u6301\u4e86\u65f6\u95f4\u63a8\u7406\u548c\u76ee\u6807\u9a71\u52a8\u89c4\u5212\u4efb\u52a1\uff0c\u5e76\u4e14\u80fd\u591f\u5c06\u5b66\u4e60\u7684\u7b56\u7565\u6620\u5c04\u56de\u4eba\u7c7b\u53ef\u8bfb\u7684PEC\u8868\u793a\u5f62\u5f0f\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5c06Probabilistic Event Calculus\uff08PEC\uff09\u9886\u57df\u8f6c\u5316\u4e3aMarkov Decision Processes\uff08MDPs\uff09\u6765\u5f25\u8865PEC\u5728\u76ee\u6807\u9a71\u52a8\u63a8\u7406\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u8f6c\u5316\u540e\u7684PEC-MDP\u5f62\u5f0f\u4f7f\u5f97\u53ef\u4ee5\u5c06\u9488\u5bf9MDPs\u53d1\u5c55\u7684\u5927\u91cf\u7b97\u6cd5\u548c\u7406\u8bba\u5de5\u5177\u5e94\u7528\u5230PEC\u7684\u53ef\u89e3\u91ca\u53d9\u4e8b\u9886\u57df\u4e2d\u3002\u8bba\u6587\u5c55\u793a\u4e86\u8fd9\u79cd\u8f6c\u5316\u5982\u4f55\u652f\u6301\u65f6\u95f4\u63a8\u7406\u4efb\u52a1\u548c\u76ee\u6807\u9a71\u52a8\u89c4\u5212\uff0c\u4ee5\u53ca\u5982\u4f55\u5c06\u5b66\u4e60\u7684\u7b56\u7565\u6620\u5c04\u56de\u4eba\u7c7b\u53ef\u8bfb\u7684PEC\u8868\u793a\u5f62\u5f0f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u89e3\u91ca\u6027\u5e76\u6269\u5c55\u4e86PEC\u7684\u80fd\u529b\u3002"}}
{"id": "2507.13007", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13007", "abs": "https://arxiv.org/abs/2507.13007", "authors": ["Roger Xavier Lera-Leri", "Filippo Bistaffa", "Athina Georgara", "Juan Antonio Rodriguez-Aguilar"], "title": "Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming", "comment": "To appear in Lecture Notes in Artificial Intelligence", "summary": "Following the recent push for trustworthy AI, there has been an increasing\ninterest in developing contrastive explanation techniques for optimisation,\nespecially concerning the solution of specific decision-making processes\nformalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic\napproach for building contrastive explanations for MILPs based on constraint\nreasoning techniques. First, we show how to encode the queries a user makes\nabout the solution of an MILP problem as additional constraints. Then, we\ndetermine the reasons that constitute the answer to the user's query by\ncomputing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set\nof constraints. Finally, we represent our explanation as a \"graph of reasons\"\nconstructed from the IIS, which helps the user understand the structure among\nthe reasons that answer their query. We test our method on instances of\nwell-known optimisation problems to evaluate the empirical hardness of\ncomputing explanations.", "AI": {"tldr": "Developed X-MILP approach for generating domain-agnostic contrastive explanations in MILPs using constraint reasoning. Encoded user queries as constraints, computed answers through Irreducible Infeasible Subsystem, and represented explanations as a 'graph of reasons'. Method evaluated on optimization problems to gauge computational complexity.", "motivation": "Driven by the increasing interest in trustworthy AI and the need for contrastive explanations in MILPs. Aimed to provide a domain-agnostic solution for generating explanations using constraint reasoning techniques, enhancing user understanding of decision-making processes.", "method": "Developed X-MILP approach for contrastive explanations in MILPs using constraint reasoning. Encoded user queries as constraints, computed answers through IIS determination, and represented explanations with a 'graph of reasons' from IIS. Tested method on popular optimization problems for evaluation.", "result": "Successfully introduced X-MILP approach for building contrastive explanations in MILPs, demonstrated the encoding of user queries as constraints, computation of answers through IIS, and representation of explanations as a 'graph of reasons'. Method tested on optimization problems, assessing computational complexity.", "conclusion": "Proposed X-MILP, a domain-agnostic approach for building contrastive explanations for MILPs based on constraint reasoning techniques. Showed how to encode user queries as additional constraints and determine answers through Irreducible Infeasible Subsystem (IIS) computation. Represented explanations as a 'graph of reasons' from IIS, aiding user comprehension. Tested on well-known optimization problems to evaluate computational complexity."}}
{"id": "2507.13112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13112", "abs": "https://arxiv.org/abs/2507.13112", "authors": ["Junseong Lee", "Jaegwan Cho", "Yoonju Cho", "Seoyoon Choi", "Yejin Shin"], "title": "Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data", "comment": null, "summary": "The study \"Prediction of Highway Traffic Flow Based on Artificial\nIntelligence Algorithms Using California Traffic Data\" presents a machine\nlearning-based traffic flow prediction model to address global traffic\ncongestion issues. The research utilized 30-second interval traffic data from\nCalifornia Highway 78 over a five-month period from July to November 2022,\nanalyzing a 7.24 km westbound section connecting \"Melrose Dr\" and \"El-Camino\nReal\" in the San Diego area. The study employed Multiple Linear Regression\n(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals\nranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance\nmetrics, the analysis revealed that both MLR and RF models performed optimally\nwith 10-minute data collection intervals. These findings are expected to\ncontribute to future traffic congestion solutions and efficient traffic\nmanagement.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u52a0\u5229\u798f\u5c3c\u4e9a78\u53f7\u9ad8\u901f\u516c\u8def\u7684\u4ea4\u901a\u6570\u636e\uff0c\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u4ea4\u901a\u6d41\u91cf\u9884\u6d4b\u6a21\u578b\uff0c\u53d1\u73b0\u572810\u5206\u949f\u6570\u636e\u6536\u96c6\u95f4\u9694\u4e0b\uff0c\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff08MLR\uff09\u548c\u968f\u673a\u68ee\u6797\uff08RF\uff09\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u6709\u671b\u4e3a\u672a\u6765\u4ea4\u901a\u62e5\u5835\u89e3\u51b3\u65b9\u6848\u548c\u6709\u6548\u7684\u4ea4\u901a\u7ba1\u7406\u505a\u51fa\u8d21\u732e\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5168\u7403\u6027\u4ea4\u901a\u62e5\u5835\u95ee\u9898\uff0c\u5229\u7528\u52a0\u5229\u798f\u5c3c\u4e9a\u9ad8\u901f\u516c\u8def78\u53f7\u7684\u4ea4\u901a\u6570\u636e\u4e3a\u57fa\u7840\uff0c\u9488\u5bf9\u5723\u5730\u4e9a\u54e5\u5730\u533aMelrose Dr\u548cEl-Camino Real\u4e4b\u95f47.24\u516c\u91cc\u897f\u884c\u8def\u6bb5\u5c55\u5f00\u5206\u6790\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff08MLR\uff09\u548c\u968f\u673a\u68ee\u6797\uff08RF\uff09\u7b97\u6cd5\uff0c\u5206\u6790\u4e8630\u79d2\u81f315\u5206\u949f\u7684\u6570\u636e\u6536\u96c6\u95f4\u9694\u3002", "result": "\u572830\u79d2\u523015\u5206\u949f\u7684\u6570\u636e\u6536\u96c6\u95f4\u9694\u4e0b\uff0c\u901a\u8fc7R^2\u3001MAE\u548cRMSE\u4f5c\u4e3a\u6027\u80fd\u6307\u6807\uff0c\u7814\u7a76\u53d1\u73b0MLR\u548cRF\u6a21\u578b\u572810\u5206\u949f\u6570\u636e\u6536\u96c6\u95f4\u9694\u4e0b\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u8be5\u7814\u7a76\u5229\u7528\u52a0\u5229\u798f\u5c3c\u4e9a78\u53f7\u9ad8\u901f\u516c\u8def\u7684\u4ea4\u901a\u6570\u636e\uff0c\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u4ea4\u901a\u6d41\u91cf\u9884\u6d4b\u6a21\u578b\uff0c\u53d1\u73b0\u572810\u5206\u949f\u6570\u636e\u6536\u96c6\u95f4\u9694\u4e0b\uff0c\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff08MLR\uff09\u548c\u968f\u673a\u68ee\u6797\uff08RF\uff09\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002\u8fd9\u4e9b\u53d1\u73b0\u6709\u671b\u4e3a\u672a\u6765\u4ea4\u901a\u62e5\u5835\u89e3\u51b3\u65b9\u6848\u548c\u6709\u6548\u7684\u4ea4\u901a\u7ba1\u7406\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2507.13142", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.13142", "abs": "https://arxiv.org/abs/2507.13142", "authors": ["Ahmed Bahloul", "Simon Malberg"], "title": "From Roots to Rewards: Dynamic Tree Reasoning with RL", "comment": null, "summary": "Modern language models address complex questions through chain-of-thought\n(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,\n2021), yet struggle with error propagation and knowledge integration.\nTree-structured reasoning methods, particularly the Probabilistic\nTree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues\nby decomposing questions into hierarchical structures and selecting answers\nthrough confidence-weighted aggregation of parametric and retrieved knowledge\n(Yao et al., 2023). However, ProbTree's static implementation introduces two\nkey limitations: (1) the reasoning tree is fixed during the initial\nconstruction phase, preventing dynamic adaptation to intermediate results, and\n(2) each node requires exhaustive evaluation of all possible solution\nstrategies, creating computational inefficiency. We present a dynamic\nreinforcement learning (Sutton and Barto, 2018) framework that transforms\ntree-based reasoning into an adaptive process. Our approach incrementally\nconstructs the reasoning tree based on real-time confidence estimates, while\nlearning optimal policies for action selection (decomposition, retrieval, or\naggregation). This maintains ProbTree's probabilistic rigor while improving\nboth solution quality and computational efficiency through selective expansion\nand focused resource allocation. The work establishes a new paradigm for\ntreestructured reasoning that balances the reliability of probabilistic\nframeworks with the flexibility required for real-world question answering\nsystems.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u52a8\u6001\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u5584\u6811\u72b6\u63a8\u7406\u7684\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5b9e\u65f6\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u9010\u6b65\u6784\u5efa\u63a8\u7406\u6811\uff0c\u540c\u65f6\u5b66\u4e60\u5bf9\u884c\u52a8\u9009\u62e9\uff08\u5206\u89e3\u3001\u68c0\u7d22\u6216\u805a\u5408\uff09\u7684\u6700\u4f18\u7b56\u7565\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6269\u5c55\u548c\u805a\u7126\u8d44\u6e90\u5206\u914d\u5b9e\u73b0\u4e86\u5e73\u8861\u6982\u7387\u6846\u67b6\u7684\u53ef\u9760\u6027\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u95ee\u9898\u65f6\u5b58\u5728\u9519\u8bef\u4f20\u64ad\u548c\u77e5\u8bc6\u6574\u5408\u95ee\u9898\u3002ProbTree\u7684\u9759\u6001\u5b9e\u73b0\u9650\u5236\u4e86\u63a8\u7406\u6811\u7684\u52a8\u6001\u6027\u5e76\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u52a8\u6001\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u6539\u5584\u6811\u72b6\u63a8\u7406\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u7684\u8868\u73b0\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06ProbTree\u7684\u9759\u6001\u5b9e\u73b0\u8f6c\u5316\u4e3a\u81ea\u9002\u5e94\u8fc7\u7a0b\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5b9e\u65f6\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u9010\u6b65\u6784\u5efa\u63a8\u7406\u6811\uff0c\u540c\u65f6\u5b66\u4e60\u5bf9\u884c\u52a8\u9009\u62e9\uff08\u5206\u89e3\u3001\u68c0\u7d22\u6216\u805a\u5408\uff09\u7684\u6700\u4f18\u7b56\u7565\u3002\u901a\u8fc7\u9009\u62e9\u6027\u6269\u5c55\u548c\u805a\u7126\u8d44\u6e90\u5206\u914d\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u52a8\u6001\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6210\u529f\u5c06\u6811\u72b6\u63a8\u7406\u8f6c\u5316\u4e3a\u81ea\u9002\u5e94\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u79cd\u65b0\u7684\u6811\u72b6\u63a8\u7406\u8303\u5f0f\uff0c\u5e73\u8861\u4e86\u6982\u7387\u6846\u67b6\u7684\u53ef\u9760\u6027\u548c\u73b0\u5b9e\u4e16\u754c\u95ee\u7b54\u7cfb\u7edf\u7684\u9700\u6c42\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u52a8\u6001\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u6811\u72b6\u63a8\u7406\u8f6c\u5316\u4e3a\u9002\u5e94\u6027\u8fc7\u7a0b\uff0c\u4ee5\u6539\u5584\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002\u8be5\u6846\u67b6\u5728\u5b9e\u65f6\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7684\u57fa\u7840\u4e0a\u9010\u6b65\u6784\u5efa\u63a8\u7406\u6811\uff0c\u540c\u65f6\u5b66\u4e60\u9009\u62e9\u884c\u52a8\uff08\u5206\u89e3\u3001\u68c0\u7d22\u6216\u805a\u5408\uff09\u7684\u6700\u4f18\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u6269\u5c55\u548c\u805a\u7126\u8d44\u6e90\u5206\u914d\uff0c\u7ef4\u6301\u4e86ProbTree\u7684\u6982\u7387\u4e25\u8c28\u6027\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002\u672c\u7814\u7a76\u4e3a\u5e73\u8861\u6982\u7387\u6846\u67b6\u7684\u53ef\u9760\u6027\u4e0e\u73b0\u5b9e\u4e16\u754c\u95ee\u7b54\u7cfb\u7edf\u6240\u9700\u7684\u7075\u6d3b\u6027\u5efa\u7acb\u4e86\u4e00\u79cd\u65b0\u7684\u6811\u72b6\u63a8\u7406\u8303\u5f0f\u3002"}}
{"id": "2507.13175", "categories": ["cs.AI", "68T27, 03B42 68T27, 03B4268T27, 03B42 68T27, 03B42 68T27, 03B42\n  68T27, 03B42 68T27, 03B42 68T27, 03B4268T27, 03B42", "I.2.0; I.2.9; K.4.1"], "pdf": "https://arxiv.org/pdf/2507.13175", "abs": "https://arxiv.org/abs/2507.13175", "authors": ["Matthew E. Brophy"], "title": "Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era", "comment": "42 pages. Supplementary material included at end of article", "summary": "The advancement of powerful yet opaque large language models (LLMs)\nnecessitates a fundamental revision of the philosophical criteria used to\nevaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the\nassumption of transparent architectures, which LLMs defy due to their\nstochastic outputs and opaque internal states. This paper argues that\ntraditional ethical criteria are pragmatically obsolete for LLMs due to this\nmismatch. Engaging with core themes in the philosophy of technology, this paper\nproffers a revised set of ten functional criteria to evaluate LLM-based\nartificial moral agents: moral concordance, context sensitivity, normative\nintegrity, metaethical awareness, system resilience, trustworthiness,\ncorrigibility, partial transparency, functional autonomy, and moral\nimagination. These guideposts, applied to what we term \"SMA-LLS\" (Simulating\nMoral Agency through Large Language Systems), aim to steer AMAs toward greater\nalignment and beneficial societal integration in the coming years. We\nillustrate these criteria using hypothetical scenarios involving an autonomous\npublic bus (APB) to demonstrate their practical applicability in morally\nsalient contexts.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\uff0c\u4f20\u7edf\u7684\u4f26\u7406\u6807\u51c6\u5df2\u7ecf\u8fc7\u65f6\uff0c\u56e0\u4e3aLLMs\u7684\u51fa\u73b0\u6253\u7834\u4e86\u900f\u660e\u6027\u7684\u5047\u8bbe\u3002\u4e3a\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u65b0\u7684\u529f\u80fd\u6807\u51c6\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8eLLMs\u7684\u4eba\u5de5\u9053\u5fb7\u4ee3\u7406\uff0c\u65e8\u5728\u5f15\u5bfcAMAs\u66f4\u597d\u5730\u878d\u5165\u793e\u4f1a\u3002\u901a\u8fc7\u4ee5\u81ea\u4e3b\u516c\u5171\u6c7d\u8f66\u4e3a\u4f8b\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u6807\u51c6\u7684\u5b9e\u9645\u5e94\u7528\u6027\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u6307\u51fa\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4f20\u7edf\u7684\u4f26\u7406\u8bc4\u4f30\u6807\u51c6\u53d8\u5f97\u8fc7\u65f6\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6a21\u578b\u4e0e\u900f\u660e\u6027\u7684\u5047\u8bbe\u4e0d\u7b26\uff0c\u800c\u63d0\u51fa\u4e86\u4e00\u5957\u65b0\u7684\u6807\u51c6\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8eLLMs\u7684\u4eba\u5de5\u9053\u5fb7\u4ee3\u7406\u3002", "method": "\u901a\u8fc7\u5bf9\u6280\u672f\u54f2\u5b66\u7684\u6838\u5fc3\u4e3b\u9898\u7684\u63a2\u8ba8\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u5341\u4e2a\u529f\u80fd\u6807\u51c6\uff0c\u4ee5\u8bc4\u4f30\u57fa\u4e8eLLMs\u7684\u4eba\u5de5\u9053\u5fb7\u4ee3\u7406\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u4f7f\u7528\u81ea\u4e3b\u516c\u5171\u6c7d\u8f66\uff08APB\uff09\u7684\u5047\u8bbe\u573a\u666f\u5c55\u793a\u4e86\u8fd9\u4e9b\u6807\u51c6\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u65b0\u7684\u529f\u80fd\u6807\u51c6\uff0c\u672c\u6587\u4e3a\u8bc4\u4f30\u57fa\u4e8eLLMs\u7684\u4eba\u5de5\u9053\u5fb7\u4ee3\u7406\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u4e9b\u6807\u51c6\u5728\u9053\u5fb7\u4e0a\u654f\u611f\u8bed\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\uff0c\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u51fa\u73b0\uff0c\u4f20\u7edf\u7684\u4f26\u7406\u8bc4\u4f30\u6807\u51c6\u5bf9\u4e8e\u4eba\u5de5\u9053\u5fb7\u4ee3\u7406\uff08AMAs\uff09\u5df2\u7ecf\u8fc7\u65f6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u65b0\u7684\u529f\u80fd\u6807\u51c6\u6765\u8bc4\u4f30\u57fa\u4e8eLLMs\u7684\u4eba\u5de5\u9053\u5fb7\u4ee3\u7406\u3002\u8fd9\u4e9b\u6807\u51c6\u65e8\u5728\u5f15\u5bfcAMAs\u5728\u672a\u6765\u4e0e\u793e\u4f1a\u66f4\u597d\u5730\u878d\u5408\u3002"}}
{"id": "2507.13208", "categories": ["cs.AI", "cs.LO", "math.LO", "03B70 (Primary) 68T37, 68T27, 68Q42, 03B40, 68V15 (Secondary)", "F.4.1; I.2.3"], "pdf": "https://arxiv.org/pdf/2507.13208", "abs": "https://arxiv.org/abs/2507.13208", "authors": ["Besik Dundua", "Temur Kutsia"], "title": "Higher-Order Pattern Unification Modulo Similarity Relations", "comment": "23 pages", "summary": "The combination of higher-order theories and fuzzy logic can be useful in\ndecision-making tasks that involve reasoning across abstract functions and\npredicates, where exact matches are often rare or unnecessary. Developing\nefficient reasoning and computational techniques for such a combined formalism\npresents a significant challenge. In this paper, we adopt a more\nstraightforward approach aiming at integrating two well-established and\ncomputationally well-behaved components: higher-order patterns on one side and\nfuzzy equivalences expressed through similarity relations based on minimum\nT-norm on the other. We propose a unification algorithm for higher-order\npatterns modulo these similarity relations and prove its termination,\nsoundness, and completeness. This unification problem, like its crisp\ncounterpart, is unitary. The algorithm computes a most general unifier with the\nhighest degree of approximation when the given terms are unifiable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u9ad8\u9636\u6a21\u5f0f\u548c\u6a21\u7cca\u903b\u8f91\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u6d89\u53ca\u62bd\u8c61\u51fd\u6570\u548c\u8c13\u8bcd\u7684\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u95ee\u9898\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u9ad8\u9636\u6a21\u5f0f\u5728\u76f8\u4f3c\u6027\u5173\u7cfb\u4e0b\u7684\u7edf\u4e00\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6027\u8d28\u3002\u8bba\u6587\u7684\u8d21\u732e\u5728\u4e8e\u5f00\u53d1\u51fa\u6709\u6548\u7684\u63a8\u7406\u548c\u8ba1\u7b97\u6280\u672f\uff0c\u7528\u4e8e\u9ad8\u9636\u7406\u8bba\u548c\u6a21\u7cca\u903b\u8f91\u7684\u7ed3\u5408\u5f62\u5f0f\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u4e00\u4e2a\u6709\u6548\u7684\u63a8\u7406\u548c\u8ba1\u7b97\u6280\u672f\uff0c\u7528\u4e8e\u9ad8\u9636\u7406\u8bba\u548c\u6a21\u7cca\u903b\u8f91\u7684\u7ed3\u5408\u5f62\u5f0f\u3002\u8fd9\u79cd\u7ec4\u5408\u5f62\u5f0f\u5728\u6d89\u53ca\u62bd\u8c61\u51fd\u6570\u548c\u8c13\u8bcd\u7684\u51b3\u7b56\u4efb\u52a1\u4e2d\u5f80\u5f80\u4e0d\u9700\u8981\u7cbe\u786e\u5339\u914d\u3002", "method": "\u8be5\u8bba\u6587\u91c7\u7528\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\uff0c\u6574\u5408\u4e86\u9ad8\u9636\u6a21\u5f0f\u548c\u6a21\u7cca\u7b49\u4ef7\u5173\u7cfb\uff0c\u65e8\u5728\u89e3\u51b3\u4e0a\u8ff0\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u95ee\u9898\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u9ad8\u9636\u6a21\u5f0f\u5728\u76f8\u4f3c\u6027\u5173\u7cfb\u4e0b\u7684\u7edf\u4e00\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6027\u8d28\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u7ec8\u6b62\u6027\u3001\u6b63\u786e\u6027\u548c\u5b8c\u5907\u6027\uff0c\u4ee5\u53ca\u8ba1\u7b97\u51fa\u6700\u4e00\u822c\u7684\u7edf\u4e00\u5668\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u9ad8\u9636\u7406\u8bba\u4e0e\u6a21\u7cca\u903b\u8f91\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u9ad8\u9636\u6a21\u5f0f\u548c\u57fa\u4e8e\u6700\u5c0fT-\u8303\u6570\u7684\u76f8\u4f3c\u6027\u5173\u7cfb\u6765\u89e3\u51b3\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u95ee\u9898\u3002\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u8fd9\u4e9b\u76f8\u4f3c\u6027\u5173\u7cfb\u4e0b\u5bf9\u9ad8\u9636\u6a21\u5f0f\u8fdb\u884c\u7edf\u4e00\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u7ec8\u6b62\u6027\u3001\u6b63\u786e\u6027\u548c\u5b8c\u5907\u6027\u3002\u7b97\u6cd5\u8ba1\u7b97\u51fa\u6700\u4e00\u822c\u7684\u7edf\u4e00\u5668\uff0c\u5728\u53ef\u7edf\u4e00\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u6700\u9ad8\u7a0b\u5ea6\u7684\u8fd1\u4f3c\u5ea6\u3002"}}
{"id": "2507.13302", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.13302", "abs": "https://arxiv.org/abs/2507.13302", "authors": ["Carlos Arriaga", "Gonzalo Mart\u00ednez", "Eneko Sendin", "Javier Conde", "Pedro Reviriego"], "title": "The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations", "comment": null, "summary": "The evaluation of large language models is a complex task, in which several\napproaches have been proposed. The most common is the use of automated\nbenchmarks in which LLMs have to answer multiple-choice questions of different\ntopics. However, this method has certain limitations, being the most\nconcerning, the poor correlation with the humans. An alternative approach, is\nto have humans evaluate the LLMs. This poses scalability issues as there is a\nlarge and growing number of models to evaluate making it impractical (and\ncostly) to run traditional studies based on recruiting a number of evaluators\nand having them rank the responses of the models. An alternative approach is\nthe use of public arenas, such as the popular LM arena, on which any user can\nfreely evaluate models on any question and rank the responses of two models.\nThe results are then elaborated into a model ranking. An increasingly important\naspect of LLMs is their energy consumption and, therefore, evaluating how\nenergy awareness influences the decisions of humans in selecting a model is of\ninterest. In this paper, we present GEA, the Generative Energy Arena, an arena\nthat incorporates information on the energy consumption of the model in the\nevaluation process. Preliminary results obtained with GEA are also presented,\nshowing that for most questions, when users are aware of the energy\nconsumption, they favor smaller and more energy efficient models. This suggests\nthat for most user interactions, the extra cost and energy incurred by the more\ncomplex and top-performing models do not provide an increase in the perceived\nquality of the responses that justifies their use.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Generative Energy Arena\uff08GEA\uff09\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u8bc4\u4f30\u4e2d\u878d\u5165\u80fd\u6e90\u6d88\u8017\u4fe1\u606f\uff0c\u5c55\u793a\u4e86\u7528\u6237\u66f4\u503e\u5411\u9009\u62e9\u8282\u80fd\u6a21\u578b\u7684\u8d8b\u52bf\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u7528\u6237\u4ea4\u4e92\uff0c\u8f83\u5c0f\u548c\u66f4\u8282\u80fd\u7684\u6a21\u578b\u66f4\u53d7\u7528\u6237\u9752\u7750\uff0c\u800c\u590d\u6742\u548c\u6027\u80fd\u66f4\u5f3a\u7684\u6a21\u578b\u5e76\u672a\u4ea7\u751f\u8db3\u591f\u7684\u611f\u77e5\u8d28\u91cf\u63d0\u5347\u6765\u8bc1\u660e\u5176\u4ef7\u503c\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u4f20\u7edf\u7684\u62db\u52df\u8bc4\u4f30\u8005\u548c\u6392\u540d\u6a21\u578b\u54cd\u5e94\u7684\u7814\u7a76\u65b9\u6cd5\u4e0d\u518d\u5b9e\u9645\u4e14\u6602\u8d35\u3002\u56e0\u6b64\uff0c\u63a2\u8ba8\u5982\u4f55\u5728\u6a21\u578b\u9009\u62e9\u4e2d\u5f15\u5165\u80fd\u91cf\u610f\u8bc6\u7684\u5f71\u54cd\u5bf9\u4e8e\u63d0\u9ad8\u8bc4\u4f30\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86Generative Energy Arena\uff08GEA\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u6a21\u578b\u80fd\u8017\u4fe1\u606f\u7684\u8bc4\u4f30\u5e73\u53f0\u3002\u7814\u7a76\u91c7\u7528\u4e86\u7528\u6237\u8bc4\u4f30\u6a21\u578b\u65f6\u7684\u80fd\u6e90\u610f\u8bc6\uff0c\u901a\u8fc7\u7528\u6237\u5728\u610f\u8bc6\u5230\u80fd\u8017\u7684\u60c5\u51b5\u4e0b\u5bf9\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u7528\u6237\u504f\u5411\u9009\u62e9\u8282\u80fd\u6a21\u578b\u7684\u8d8b\u52bf\u3002", "result": "\u4f7f\u7528GEA\u8fdb\u884c\u8bc4\u4f30\u540e\uff0c\u7528\u6237\u5728\u610f\u8bc6\u5230\u6a21\u578b\u80fd\u8017\u60c5\u51b5\u4e0b\u66f4\u503e\u5411\u9009\u62e9\u8f83\u5c0f\u548c\u66f4\u8282\u80fd\u7684\u6a21\u578b\u3002\u8fd9\u8868\u660e\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u590d\u6742\u4e14\u6027\u80fd\u66f4\u4f18\u7684\u6a21\u578b\u6240\u4ea7\u751f\u7684\u989d\u5916\u6210\u672c\u548c\u80fd\u8017\uff0c\u5e76\u672a\u63d0\u4f9b\u8db3\u591f\u7684\u611f\u77e5\u8d28\u91cf\u63d0\u5347\u6765\u8bc1\u660e\u5b83\u4eec\u7684\u4f7f\u7528\u4ef7\u503c\u3002", "conclusion": "\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u4f7f\u7528 Generative Energy Arena\uff08GEA\uff09\u53ef\u4ee5\u5e2e\u52a9\u7528\u6237\u66f4\u503e\u5411\u9009\u62e9\u8f83\u5c0f\u548c\u66f4\u8282\u80fd\u7684\u6a21\u578b\uff0c\u800c\u4e0d\u662f\u590d\u6742\u548c\u6027\u80fd\u66f4\u5f3a\u7684\u6a21\u578b\u3002"}}
{"id": "2507.13337", "categories": ["cs.AI", "cs.CC", "math.LO"], "pdf": "https://arxiv.org/pdf/2507.13337", "abs": "https://arxiv.org/abs/2507.13337", "authors": ["Gal Beniamini", "Yuval Dor", "Alon Vinnikov", "Shir Granot Peled", "Or Weinstein", "Or Sharir", "Noam Wies", "Tomer Nussbaum", "Ido Ben Shaul", "Tomer Zekharya", "Yoav Levine", "Shai Shalev-Shwartz", "Amnon Shashua"], "title": "FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming", "comment": null, "summary": "Frontier AI models demonstrate formidable breadth of knowledge. But how close\nare they to true human -- or superhuman -- expertise? Genuine experts can\ntackle the hardest problems and push the boundaries of scientific\nunderstanding. To illuminate the limits of frontier model capabilities, we turn\naway from contrived competitive programming puzzles, and instead focus on\nreal-life research problems.\n  We construct FormulaOne, a benchmark that lies at the intersection of graph\ntheory, logic, and algorithms, all well within the training distribution of\nfrontier models. Our problems are incredibly demanding, requiring an array of\nreasoning steps. The dataset has three key properties. First, it is of\ncommercial interest and relates to practical large-scale optimisation problems,\nsuch as those arising in routing, scheduling, and network design. Second, it is\ngenerated from the highly expressive framework of Monadic Second-Order (MSO)\nlogic on graphs, paving the way toward automatic problem generation at scale;\nideal for building RL environments. Third, many of our problems are intimately\nrelated to the frontier of theoretical computer science, and to central\nconjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As\nsuch, any significant algorithmic progress on our dataset, beyond known\nresults, could carry profound theoretical implications.\n  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on\nFormulaOne, solving less than 1% of the questions, even when given 10 attempts\nand explanatory fewshot examples -- highlighting how far they remain from\nexpert-level understanding in some domains. To support further research, we\nadditionally curate FormulaOne-Warmup, offering a set of simpler tasks, from\nthe same distribution. We release the full corpus along with a comprehensive\nevaluation framework.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e86FormulaOne\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30AI\u6a21\u578b\u5728\u56fe\u8bba\u3001\u903b\u8f91\u548c\u7b97\u6cd5\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u8bbe\u8ba1\u6765\u6d4b\u8bd5\u5f53\u524dAI\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u7684\u5c40\u9650\u6027\uff0c\u7ed3\u679c\u663e\u793a\u50cfOpenAI\u7684o3\u8fd9\u6837\u7684\u5c16\u7aef\u6a21\u578b\u5728FormulaOne\u57fa\u51c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u89e3\u51b3\u4e0d\u52301%\u7684\u95ee\u9898\uff0c\u7a81\u51fa\u4e86AI\u6a21\u578b\u4e0e\u771f\u6b63\u4e13\u5bb6\u6c34\u5e73\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002\u7814\u7a76\u63d0\u4f9b\u4e86FormulaOne-Warmup\uff0c\u4e3a\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u7ec4\u66f4\u7b80\u5355\u7684\u4efb\u52a1\u3002", "motivation": "The motivation behind this paper is to assess the capabilities of frontier AI models in addressing real-life research problems and to bridge the gap between AI expertise and genuine expert-level understanding. By introducing the FormulaOne benchmark, the paper aims to provide a challenging evaluation platform that reflects the complexity of practical optimization problems and theoretical computer science concepts. The goal is to encourage algorithmic progress and research in domains where AI models currently lack expertise.", "method": "The paper constructs FormulaOne, a benchmark comprising challenging problems in graph theory, logic, and algorithms to evaluate the reasoning abilities of AI models. The dataset is designed to be commercially relevant and generated from Monadic Second-Order logic on graphs. State-of-the-art models like OpenAI's o3 were tested on FormulaOne, demonstrating their limitations in solving these complex problems. Additionally, FormulaOne-Warmup, a set of simpler tasks from the same distribution, was curated to support further research and evaluation.", "result": "The results of the study show that state-of-the-art AI models, exemplified by OpenAI's o3, struggle significantly on the FormulaOne benchmark, solving less than 1% of the questions even with multiple attempts and explanatory examples. This highlights the substantial gap in understanding and problem-solving abilities between AI models and genuine experts in domains that require complex reasoning. The release of FormulaOne-Warmup and the evaluation framework provides a platform for further research and development in this area.", "conclusion": "Frontier AI models like OpenAI's o3 struggle to perform well on real-life research problems such as the FormulaOne benchmark, highlighting the gap in expertise between AI models and genuine experts. The paper introduces FormulaOne, a challenging benchmark at the intersection of graph theory, logic, and algorithms, designed to test the reasoning capabilities of AI models. The dataset is commercially relevant, generated from Monadic Second-Order logic on graphs, and is closely linked to theoretical computer science and central conjectures like the Strong Exponential Time Hypothesis (SETH). The results indicate the limitations of current AI models on complex problems that require in-depth reasoning."}}
