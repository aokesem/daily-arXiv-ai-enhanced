{"id": "2508.11836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11836", "abs": "https://arxiv.org/abs/2508.11836", "authors": ["Dave Goel", "Matthew Guzdial", "Anurag Sarkar"], "title": "Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video", "comment": null, "summary": "World models are defined as a compressed spatial and temporal learned\nrepresentation of an environment. The learned representation is typically a\nneural network, making transfer of the learned environment dynamics and\nexplainability a challenge. In this paper, we propose an approach, Finite\nAutomata Extraction (FAE), that learns a neuro-symbolic world model from\ngameplay video represented as programs in a novel domain-specific language\n(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more\nprecise model of the environment and more general code than prior DSL-based\napproaches.", "AI": {"tldr": "Finite Automata Extraction (FAE) proposes a new method to generate neuro-symbolic world models using Retro Coder from gameplay videos, surpassing previous approaches in precision and generality.", "motivation": "The motivation is to address the challenge of transferring learned environment dynamics and enhancing explainability by developing a more precise and general world model.", "method": "The paper introduces the Finite Automata Extraction (FAE) approach, which learns neuro-symbolic world models from gameplay videos using a domain-specific language (DSL) called Retro Coder.", "result": "FAE achieves a more accurate model of the environment and generates more general code compared to previous DSL-based approaches.", "conclusion": "Finite Automata Extraction (FAE) proposes a neuro-symbolic world model learned from gameplay videos represented in Retro Coder, outperforming prior approaches in precision and generality."}}
{"id": "2508.11850", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11850", "abs": "https://arxiv.org/abs/2508.11850", "authors": ["Milad Yazdani", "Mahdi Mostajabdaveh", "Samin Aref", "Zirui Zhou"], "title": "EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models", "comment": null, "summary": "Integer programming lies at the heart of crucial combinatorial optimization\ntasks but remains challenging due to its NP-hard nature. An effective approach\nfor practically solving integer programs is the manual design of acceleration\ncuts, i.e. inequalities that improve solver performance. However, this creative\nprocess demands deep expertise and is yet to be automated. Our proposed\nframework, EvoCut, automates the generation of acceleration cuts by combining\nlarge language models (LLMs) with an evolutionary search. EvoCut (i)\ninitializes a diverse population of candidate cuts via an LLM-based initializer\nagent; (ii) for each cut empirically evaluates both preservation of the optimal\nsolution and its ability to cut off fractional solutions across a verification\nset; and (iii) iteratively refines the population through evolutionary\ncrossover and mutation agents. We quantify each cut's utility by its relative\nreduction in the solver's optimality gap. Our comparisons against standard\ninteger programming practice show that EvoCut reduces optimality gap by 17-57%\nwithin a fixed time. It obtains the same solutions up to 4 times as fast, and\nobtains higher-quality solutions within the same time limit. Requiring no human\nexpert input, EvoCut reliably generates, improves, and empirically verifies\ncuts that generalize to unseen instances. The code is available at\nhttps://github.com/milad1378yz/EvoCut.", "AI": {"tldr": "EvoCut\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8fdb\u5316\u641c\u7d22\u7b97\u6cd5\u81ea\u52a8\u751f\u6210\u52a0\u901f\u5207\u5272\u3002\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u6bd4\u6807\u51c6\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\uff0c\u964d\u4f4e\u4e86\u4f18\u5316\u95f4\u9699\uff0c\u66f4\u5feb\u5730\u83b7\u5f97\u89e3\u51b3\u65b9\u6848\u5e76\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u3002\u8be5\u6846\u67b6\u65e0\u9700\u4eba\u4e3a\u4e13\u5bb6\u8f93\u5165\uff0c\u80fd\u591f\u53ef\u9760\u9002\u7528\u4e8e\u65b0\u5b9e\u4f8b\u3002", "motivation": "\u6574\u6570\u89c4\u5212\u662f\u5173\u952e\u7684\u7ec4\u5408\u4f18\u5316\u4efb\u52a1\uff0c\u4f46\u7531\u4e8e\u5176NP\u96be\u6027\u8d28\uff0c\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u624b\u52a8\u8bbe\u8ba1\u52a0\u901f\u5207\u5272\u662f\u5b9e\u9645\u89e3\u51b3\u6574\u6570\u89c4\u5212\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e00\u521b\u9020\u6027\u8fc7\u7a0b\u9700\u8981\u6df1\u539a\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5e76\u4e14\u5c1a\u672a\u5b9e\u73b0\u81ea\u52a8\u5316\u3002\u56e0\u6b64\uff0c\u63d0\u51faEvoCut\u6846\u67b6\u7684\u52a8\u673a\u662f\u81ea\u52a8\u751f\u6210\u52a0\u901f\u5207\u5272\uff0c\u63d0\u9ad8\u89e3\u6790\u5668\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4eba\u4e3a\u4e13\u5bb6\u8f93\u5165\u3002", "method": "EvoCut\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u8fdb\u5316\u641c\u7d22\u7b97\u6cd5\u6765\u81ea\u52a8\u751f\u6210\u52a0\u901f\u5207\u5272\uff1a(i) \u901a\u8fc7LLM-based initializer agent\u521d\u59cb\u5316\u5019\u9009\u5207\u5272\u7684\u591a\u6837\u79cd\u7fa4\uff1b(ii) \u5bf9\u6bcf\u4e2a\u5207\u5272\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8bc4\u4f30\u5176\u4fdd\u7559\u6700\u4f18\u89e3\u548c\u5728\u9a8c\u8bc1\u96c6\u4e0a\u5207\u65ad\u5206\u6570\u89e3\u7684\u80fd\u529b\uff1b(iii) \u901a\u8fc7\u8fdb\u5316\u4ea4\u53c9\u548c\u53d8\u5f02\u7b97\u6cd5\u8fed\u4ee3\u5730\u4f18\u5316\u79cd\u7fa4\u3002\u5c06\u6bcf\u4e2a\u5207\u5272\u7684\u6548\u7528\u91cf\u5316\u4e3a\u5728\u6c42\u89e3\u5668\u7684\u4f18\u5316\u95f4\u9699\u4e2d\u7684\u76f8\u5bf9\u51cf\u5c11\u3002", "result": "EvoCut\u76f8\u5bf9\u4e8e\u6807\u51c6\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u5728\u56fa\u5b9a\u65f6\u95f4\u5185\u964d\u4f4e\u4e8617-57%\u7684\u4f18\u5316\u95f4\u9699\uff0c\u66f4\u5feb\u5730\u83b7\u5f97\u89e3\u51b3\u65b9\u6848\uff0c\u6216\u5728\u76f8\u540c\u65f6\u95f4\u5185\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e00\u7ed3\u679c\u8868\u660eEvoCut\u80fd\u591f\u6709\u6548\u751f\u6210\u3001\u6539\u8fdb\u5e76\u9a8c\u8bc1\u5207\u5272\uff0c\u9002\u7528\u4e8e\u65b0\u5b9e\u4f8b\u3002", "conclusion": "EvoCut\u662f\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u52a0\u901f\u5207\u5272\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8fdb\u5316\u641c\u7d22\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u56fa\u5b9a\u65f6\u95f4\u5185\u5c06\u6574\u6570\u89c4\u5212\u95ee\u9898\u7684\u4f18\u5316\u95f4\u9699\u964d\u4f4e17-57%\u3002\u4e0e\u6807\u51c6\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u76f8\u6bd4\uff0cEvoCut\u80fd\u591f\u66f4\u5feb\u5730\u83b7\u5f97\u76f8\u540c\u89e3\u51b3\u65b9\u6848\uff0c\u6216\u5728\u76f8\u540c\u65f6\u95f4\u5185\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u6846\u67b6\u4e0d\u9700\u8981\u4eba\u4e3a\u4e13\u5bb6\u8f93\u5165\uff0c\u80fd\u591f\u53ef\u9760\u751f\u6210\u3001\u6539\u8fdb\u548c\u7ecf\u9a8c\u9a8c\u8bc1\u9002\u7528\u4e8e\u672a\u77e5\u5b9e\u4f8b\u7684\u5207\u5272\u3002"}}
{"id": "2508.11860", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11860", "abs": "https://arxiv.org/abs/2508.11860", "authors": ["Frazier N. Baker", "Daniel Adu-Ampratwum", "Reza Averly", "Botao Yu", "Huan Sun", "Xia Ning"], "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "comment": "24 pages, 5 figures", "summary": "Large language model (LLM) agent evaluators leverage specialized tools to\nground the rational decision-making of LLMs, making them well-suited to aid in\nscientific discoveries, such as constrained retrosynthesis planning.\nConstrained retrosynthesis planning is an essential, yet challenging, process\nwithin chemistry for identifying synthetic routes from commercially available\nstarting materials to desired target molecules, subject to practical\nconstraints. Here, we present LARC, the first LLM-based Agentic framework for\nRetrosynthesis planning under Constraints. LARC incorporates agentic constraint\nevaluation, through an Agent-as-a-Judge, directly into the retrosynthesis\nplanning process, using agentic feedback grounded in tool-based reasoning to\nguide and constrain route generation. We rigorously evaluate LARC on a\ncarefully curated set of 48 constrained retrosynthesis planning tasks across 3\nconstraint types. LARC achieves a 72.9% success rate on these tasks, vastly\noutperforming LLM baselines and approaching human expert-level success in\nsubstantially less time. The LARC framework is extensible, and serves as a\nfirst step towards an effective agentic tool or a co-scientist to human experts\nfor constrained retrosynthesis.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86LARC\uff0c\u9996\u4e2a\u57fa\u4e8eLLM\u7684\u5177\u6709\u7ea6\u675f\u6761\u4ef6\u7684\u9006\u5408\u6210\u89c4\u5212\u7684\u4ee3\u7406\u6846\u67b6\u3002LARC\u572848\u4e2a\u53d7\u9650\u9006\u5408\u6210\u89c4\u5212\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e8672.9%\u7684\u6210\u529f\u7387\uff0c\u8868\u73b0\u4f18\u4e8eLLM\u57fa\u51c6\u7ebf\uff0c\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\u3002\u5b83\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u9014\u7684\u5de5\u5177\uff0c\u53ef\u534f\u52a9\u5316\u5b66\u9886\u57df\u4e2d\u53d7\u9650\u9006\u5408\u6210\u89c4\u5212\u3002", "motivation": "The motivation behind this paper is to address the challenges of constrained retrosynthesis planning in chemistry by introducing an effective agentic tool like LARC. The aim is to leverage LLMs to aid in scientific discoveries and provide assistance in identifying synthetic routes.", "method": "The paper introduces LARC, the first LLM-based Agentic framework for Retrosynthesis planning under Constraints. LARC incorporates agentic constraint evaluation and utilizes Agent-as-a-Judge for retrosynthesis planning. It rigorously evaluates LARC on 48 constrained retrosynthesis planning tasks across 3 constraint types.", "result": "LARC achieves a 72.9% success rate on 48 constrained retrosynthesis planning tasks, surpassing LLM baselines and demonstrating potential to approach human expert-level success. It is extensible and can potentially serve as a valuable tool or a collaborative partner to human experts in the field.", "conclusion": "LARC, the LLM-based Agentic framework for Retrosynthesis planning under Constraints, achieves a 72.9% success rate on 48 tasks, outperforming LLM baselines and nearing human expert-level success. It serves as a promising tool to assist in constrained retrosynthesis planning in chemistry."}}
{"id": "2508.11894", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11894", "abs": "https://arxiv.org/abs/2508.11894", "authors": ["Ao Li", "Bin Yan", "Bingfeng Cai", "Chenxi Li", "Cunzhong Zhao", "Fugen Yao", "Gaoqiang Liu", "Guanjun Jiang", "Jian Xu", "Liang Dong", "Liansheng Sun", "Rongshen Zhang", "Xiaolei Gui", "Xin Liu", "Xin Shang", "Yao Wu", "Yu Cao", "Zhenxin Ma", "Zhuang Jia"], "title": "QuarkMed Medical Foundation Model Technical Report", "comment": "20 pages", "summary": "Recent advancements in large language models have significantly accelerated\ntheir adoption in healthcare applications, including AI-powered medical\nconsultations, diagnostic report assistance, and medical search tools. However,\nmedical tasks often demand highly specialized knowledge, professional accuracy,\nand customization capabilities, necessitating a robust and reliable foundation\nmodel. QuarkMed addresses these needs by leveraging curated medical data\nprocessing, medical-content Retrieval-Augmented Generation (RAG), and a\nlarge-scale, verifiable reinforcement learning pipeline to develop a\nhigh-performance medical foundation model. The model achieved 70% accuracy on\nthe Chinese Medical Licensing Examination, demonstrating strong generalization\nacross diverse medical benchmarks. QuarkMed offers a powerful yet versatile\npersonal medical AI solution, already serving over millions of users at\nai.quark.cn.", "AI": {"tldr": "QuarkMed is a high-performance medical foundation model that achieved 70% accuracy on the Chinese Medical Licensing Examination. It offers a powerful and versatile personal medical AI solution, already serving millions of users at ai.quark.cn.", "motivation": "Recent advancements in large language models have accelerated their adoption in healthcare applications, but medical tasks require specialized knowledge and accuracy, leading to the need for a robust and reliable foundation model like QuarkMed.", "method": "QuarkMed leverages curated medical data processing, medical-content Retrieval-Augmented Generation (RAG), and a large-scale, verifiable reinforcement learning pipeline to develop the medical foundation model.", "result": "QuarkMed achieved 70% accuracy on the Chinese Medical Licensing Examination and serves millions of users at ai.quark.cn.", "conclusion": "QuarkMed is a high-performance medical foundation model that achieved 70% accuracy on the Chinese Medical Licensing Examination and demonstrates strong generalization across diverse medical benchmarks. It offers a powerful and versatile personal medical AI solution, serving millions of users at ai.quark.cn."}}
{"id": "2508.11944", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.11944", "abs": "https://arxiv.org/abs/2508.11944", "authors": ["Hongtao Liu", "Zhicheng Du", "Zihe Wang", "Weiran Shen"], "title": "CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs", "comment": null, "summary": "Game-playing ability serves as an indicator for evaluating the strategic\nreasoning capability of large language models (LLMs). While most existing\nstudies rely on utility performance metrics, which are not robust enough due to\nvariations in opponent behavior and game structure. To address this limitation,\nwe propose \\textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation\nframework inspired by the cognitive hierarchy models from behavioral economics.\nWe hypothesize that agents have bounded rationality -- different agents behave\nat varying reasoning depths/levels. We evaluate LLMs' strategic reasoning\nthrough a three-phase systematic framework, utilizing behavioral data from six\nstate-of-the-art LLMs across fifteen carefully selected normal-form games.\nExperiments show that LLMs exhibit consistent strategic reasoning levels across\ndiverse opponents, confirming the framework's robustness and generalization\ncapability. We also analyze the effects of two key mechanisms (Chat Mechanism\nand Memory Mechanism) on strategic reasoning performance. Results indicate that\nthe Chat Mechanism significantly degrades strategic reasoning, whereas the\nMemory Mechanism enhances it. These insights position CHBench as a promising\ntool for evaluating LLM capabilities, with significant potential for future\nresearch and practical applications.", "AI": {"tldr": "CHBench, a novel evaluation framework, evaluates LLMs' strategic reasoning with robustness. It analyzes the effects of Chat Mechanism and Memory Mechanism on strategic reasoning performance, offering insights for future research and practical applications.", "motivation": "Existing studies on evaluating LLMs' strategic reasoning rely on utility performance metrics, which lack robustness due to variations in opponent behavior and game structure. The paper aims to address this limitation by introducing a novel evaluation framework, CHBench, based on cognitive hierarchy models from behavioral economics.", "method": "The paper proposes the Cognitive Hierarchy Benchmark (CHBench) as an evaluation framework inspired by cognitive hierarchy models. It conducts a three-phase systematic evaluation using behavioral data from six LLMs across fifteen normal-form games. The effects of the Chat Mechanism and Memory Mechanism on strategic reasoning performance are analyzed.", "result": "Experiments demonstrate that LLMs exhibit consistent strategic reasoning levels across different opponents, confirming the robustness and generalization capability of CHBench. The analysis of the Chat Mechanism and Memory Mechanism shows their respective impacts on strategic reasoning performance.", "conclusion": "CHBench is a promising tool for evaluating large language models' strategic reasoning capabilities with robustness and generalization capability. It also provides insights into the effects of Chat Mechanism and Memory Mechanism on strategic reasoning performance, highlighting the potential for future research and practical applications."}}
{"id": "2508.11953", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11953", "abs": "https://arxiv.org/abs/2508.11953", "authors": ["Yuan Li", "Zhengzhong Liu", "Eric Xing"], "title": "Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models", "comment": null, "summary": "Optimizing data mixtures for supervised fine-tuning (SFT) of large language\nmodels (LLMs) is critical for developing general-purpose models, yet this area\nremains underexplored. In this paper, we frame data mixing as an optimization\nproblem and introduce a novel method designed to minimize validation loss. Our\napproach parametrizes the loss by modeling effective data transferred and\nleveraging scaling laws for fine-tuning. By experimenting with various\nsmall-scale data mixtures, we fit these parameters and derive the optimal\nweights. We provide both mathematical proofs and empirical results\ndemonstrating that our algorithm achieves excellent overall and individual\nperformance across all domains. Through controlled experiments, we show that\nmodels trained with our optimized weights perform on par with those using\noptimal weights determined via grid search, with per-domain loss only 0.66%\nhigher than the best domain loss from grid search on average. Additionally, we\nshow that reweighting popular SFT datasets using our method improves both\nvalidation loss and downstream performance. Finally, we discuss how our method\ncan generalize to guide data selection for domain-specific models and provide\ninsights into SFT.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u4f18\u5316\u6570\u636e\u6df7\u5408\uff0c\u4ee5\u8fdb\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u76d1\u7763\u5fae\u8c03\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u9886\u57df\u4e2d\u53d6\u5f97\u4e86\u51fa\u8272\u7684\u6027\u80fd\uff0c\u6027\u80fd\u4e0e\u4f7f\u7528\u7f51\u683c\u641c\u7d22\u786e\u5b9a\u7684\u6700\u4f73\u6743\u91cd\u7684\u6a21\u578b\u6301\u5e73\u3002\u901a\u8fc7\u91cd\u65b0\u8c03\u6574\u6d41\u884c\u7684SFT\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u6539\u5584\u9a8c\u8bc1\u635f\u5931\u548c\u4e0b\u6e38\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6307\u5bfc\u6570\u636e\u9009\u62e9\u7684\u65b9\u6cd5\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u4f18\u5316\u6570\u636e\u6df7\u5408\u4ee5\u8fdb\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u76d1\u7763\u5fae\u8c03\uff0c\u8fd9\u4e00\u9886\u57df\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u672c\u6587\u5c06\u6570\u636e\u6df7\u5408\u89c6\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u8bbe\u8ba1\u7528\u4e8e\u6700\u5c0f\u5316\u9a8c\u8bc1\u635f\u5931\u7684\u65b0\u65b9\u6cd5\u3002\u901a\u8fc7\u5bf9\u5404\u79cd\u5c0f\u89c4\u6a21\u6570\u636e\u6df7\u5408\u8fdb\u884c\u5b9e\u9a8c\uff0c\u62df\u5408\u53c2\u6570\u5e76\u63a8\u5bfc\u51fa\u6700\u4f18\u6743\u91cd\u3002\u7b97\u6cd5\u4f7f\u7528\u6a21\u578b\u6709\u6548\u6570\u636e\u4f20\u8f93\u548c\u5fae\u8c03\u7684\u7f29\u653e\u5b9a\u5f8b\u6765\u53c2\u6570\u5316\u635f\u5931\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6240\u6709\u9886\u57df\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6574\u4f53\u548c\u4e2a\u4f53\u6027\u80fd\u3002\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u4f7f\u7528\u6211\u4eec\u4f18\u5316\u6743\u91cd\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u4e0e\u4f7f\u7528\u901a\u8fc7\u7f51\u683c\u641c\u7d22\u786e\u5b9a\u7684\u6700\u4f73\u6743\u91cd\u7684\u6a21\u578b\u6301\u5e73\uff0c\u5404\u9886\u57df\u635f\u5931\u5e73\u5747\u4ec5\u6bd4\u7f51\u683c\u641c\u7d22\u7684\u6700\u4f73\u9886\u57df\u635f\u5931\u9ad80.66%\u3002\u6b64\u5916\uff0c\u91cd\u65b0\u8c03\u6574\u4f7f\u7528\u6211\u4eec\u65b9\u6cd5\u7684\u6d41\u884cSFT\u6570\u636e\u96c6\u53ef\u63d0\u9ad8\u9a8c\u8bc1\u635f\u5931\u548c\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4f18\u5316\u6570\u636e\u6df7\u5408\u4ee5\u8fdb\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u6700\u5c0f\u5316\u9a8c\u8bc1\u635f\u5931\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u6240\u6709\u9886\u57df\u4e2d\u5b9e\u73b0\u4e86\u51fa\u8272\u7684\u6574\u4f53\u548c\u4e2a\u4f53\u6027\u80fd\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u6211\u4eec\u7684\u65b9\u6cd5\u91cd\u65b0\u8c03\u6574\u6d41\u884c\u7684SFT\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u6539\u5584\u9a8c\u8bc1\u635f\u5931\u548c\u4e0b\u6e38\u6027\u80fd\u3002\u6700\u540e\uff0c\u6211\u4eec\u8ba8\u8bba\u4e86\u5982\u4f55\u5c06\u6211\u4eec\u7684\u65b9\u6cd5\u63a8\u5e7f\u5230\u6307\u5bfc\u4e3a\u7279\u5b9a\u9886\u57df\u6a21\u578b\u9009\u62e9\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u4e8eSFT\u7684\u89c1\u89e3\u3002"}}
{"id": "2508.11954", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11954", "abs": "https://arxiv.org/abs/2508.11954", "authors": ["Sehyuk Park", "Soyeon Caren Han", "Eduard Hovy"], "title": "UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting", "comment": null, "summary": "Time series forecasting is a foundational task across domains, such as\nfinance, healthcare, and environmental monitoring. While recent advances in\nTime Series Foundation Models (TSFMs) have demonstrated strong generalisation\nthrough large-scale pretraining, existing models operate predominantly in a\nunimodal setting, ignoring the rich multimodal context, such as visual and\ntextual signals, that often accompanies time series data in real-world\nscenarios. This paper introduces a novel parameter-efficient multimodal\nframework, UniCast, that extends TSFMs to jointly leverage time series, vision,\nand text modalities for enhanced forecasting performance. Our method integrates\nmodality-specific embeddings from pretrained Vision and Text Encoders with a\nfrozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal\nparameter updates. This design not only preserves the generalisation strength\nof the foundation model but also enables effective cross-modal interaction.\nExtensive experiments across diverse time-series forecasting benchmarks\ndemonstrate that UniCast consistently and significantly outperforms all\nexisting TSFM baselines. The findings highlight the critical role of multimodal\ncontext in advancing the next generation of general-purpose time series\nforecasters.", "AI": {"tldr": "UniCast is a novel multimodal framework that enhances forecasting performance by incorporating vision, text, and time series data. It outperforms existing TSFM models through efficient adaptation with minimal parameter updates and effective cross-modal interaction, highlighting the significance of multimodal context in improving general-purpose time series forecasters.", "motivation": "Recent advances in TSFMs have shown strong generalization through large-scale pretraining but lack consideration for multimodal context present in real-world time series data. This paper addresses this gap by introducing a parameter-efficient framework, UniCast, to enhance forecasting performance by incorporating visual and textual signals in addition to time series data.", "method": "Introducing UniCast, a framework that extends TSFMs to incorporate multimodal context by jointly leveraging time series, vision, and text data. The method integrates pretrained Vision and Text Encoders with a frozen TSFM through soft prompt tuning for efficient adaptation and cross-modal interaction.", "result": "Extensive experiments on diverse time-series forecasting benchmarks demonstrate that UniCast consistently outperforms existing TSFM baselines, showcasing the importance of multimodal context in improving general-purpose time series forecasters.", "conclusion": "UniCast, a novel parameter-efficient multimodal framework, outperforms existing Time Series Foundation Models (TSFMs) in forecasting performance by leveraging time series, vision, and text modalities. The integration of modality-specific embeddings and soft prompt tuning enables efficient adaptation with minimal parameter updates and effective cross-modal interaction."}}
{"id": "2508.11959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11959", "abs": "https://arxiv.org/abs/2508.11959", "authors": ["Xuanxiang Huang", "Olivier L\u00e9toff\u00e9", "Joao Marques-Silva"], "title": "Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index", "comment": null, "summary": "Feature attribution methods based on game theory are ubiquitous in the field\nof eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous\nfeature attribution using logic-based explanations, specifically targeting\nhigh-stakes uses of machine learning (ML) models. Typically, such works exploit\nweak abductive explanation (WAXp) as the characteristic function to assign\nimportance to features. However, one possible downside is that the contribution\nof non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important\ninformation, because of the relationship between formal explanations (XPs) and\nadversarial examples (AExs). Accordingly, this paper leverages Shapley value\nand Banzhaf index to devise two novel feature importance scores. We take into\naccount non-WAXp sets when computing feature contribution, and the novel scores\nquantify how effective each feature is at excluding AExs. Furthermore, the\npaper identifies properties and studies the computational complexity of the\nproposed scores.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5229\u7528Shapley\u503c\u548cBanzhaf\u6307\u6570\u7684\u4e24\u79cd\u65b0\u578b\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u5206\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u5ffd\u7565\u975e\u5f31\u5047\u5b9a\u89e3\u91ca\u96c6\u7684\u95ee\u9898\u3002\u65b0\u8bc4\u5206\u80fd\u591f\u91cf\u5316\u7279\u5f81\u5728\u6392\u9664\u5bf9\u6297\u6837\u672c\u65b9\u9762\u7684\u6548\u679c\uff0c\u7814\u7a76\u4e86\u8bc4\u5206\u7684\u7279\u6027\u548c\u8ba1\u7b97\u590d\u6742\u6027\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u5b58\u5728\u7684\u5ffd\u7565\u975e\u5f31\u5047\u5b9a\u89e3\u91ca\u96c6\u7684\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u65b0\u7684\u8bc4\u5206\u65b9\u6cd5\u6765\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u7279\u5f81\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u5728\u6392\u9664\u5bf9\u6297\u6837\u672c\u65b9\u9762\u7684\u6548\u679c\u3002", "method": "\u672c\u6587\u5229\u7528Shapley\u503c\u548cBanzhaf\u6307\u6570\u8bbe\u8ba1\u4e86\u4e24\u79cd\u65b0\u7684\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u5206\u65b9\u6cd5\uff0c\u4ee5\u8003\u8651\u975e\u5f31\u5047\u5b9a\u89e3\u91ca\u96c6\u5728\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u4f30\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u901a\u8fc7\u5f15\u5165Shapley\u503c\u548cBanzhaf\u6307\u6570\uff0c\u672c\u6587\u6210\u529f\u8bbe\u8ba1\u51fa\u4e24\u79cd\u65b0\u578b\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u5206\u65b9\u6cd5\uff0c\u80fd\u591f\u5168\u9762\u8003\u8651\u975e\u5f31\u5047\u5b9a\u89e3\u91ca\u96c6\u5bf9\u7279\u5f81\u91cd\u8981\u6027\u7684\u5f71\u54cd\u3002\u540c\u65f6\uff0c\u7814\u7a76\u4e86\u8fd9\u4e24\u79cd\u65b0\u8bc4\u5206\u7684\u7279\u6027\u548c\u8ba1\u7b97\u590d\u6742\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eShapley\u503c\u548cBanzhaf\u6307\u6570\u7684\u4e24\u79cd\u65b0\u578b\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u5206\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u5e38\u89c4\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u5ffd\u7565\u975e\u5f31\u5047\u5b9a\u89e3\u91ca\u96c6\u7684\u7f3a\u70b9\u3002\u901a\u8fc7\u8003\u8651\u975e\u5f31\u5047\u5b9a\u89e3\u91ca\u96c6\uff0c\u8fd9\u4e9b\u65b0\u578b\u8bc4\u5206\u80fd\u591f\u91cf\u5316\u6bcf\u4e2a\u7279\u5f81\u5728\u6392\u9664\u5bf9\u6297\u6837\u672c\u65b9\u9762\u7684\u6548\u679c\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u8bc6\u522b\u4e86\u8fd9\u4e24\u79cd\u65b0\u8bc4\u5206\u7684\u7279\u6027\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u6027\u3002"}}
{"id": "2508.11975", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11975", "abs": "https://arxiv.org/abs/2508.11975", "authors": ["Gongyao Jiang", "Qiong Luo"], "title": "Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering", "comment": "Accepted to CIKM 2025", "summary": "Vision Language Models (VLMs) often struggle with chart understanding tasks,\nparticularly in accurate chart description and complex reasoning. Synthetic\ndata generation is a promising solution, while usually facing the challenge of\nnoise labels. To address this challenge, we first introduce a chart synthesis\npipeline that generates aligned chart-question-answer triplets through code\ngeneration and execution, ensuring the reliability of synthetic data without\nhuman intervention. Furthermore, inspired by test-time scaling that increases\ninference budget and thereby improves performance, we design a\ncandidate-conditioned answering process. The VLM first generates multiple\nresponses per query, and then synthesizes the final answer by contextualizing\nthese candidates. Experiments demonstrate significant improvements, with up to\n15.50 points accuracy gain over the initial VLM, in a fully self-improving\nparadigm without either human-labeled data or external models.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u56fe\u8868\u7efc\u5408\u7ba1\u9053\u548c\u5019\u9009\u6761\u4ef6\u56de\u7b54\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u5408\u6210\u6570\u636e\u4e2d\u7684\u6807\u7b7e\u566a\u97f3\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u56fe\u8868\u7406\u89e3\u4efb\u52a1\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5168\u81ea\u6211\u6539\u8fdb\u7684\u8303\u5f0f\u4e0b\uff0c\u672c\u65b9\u6cd5\u80fd\u6bd4\u521d\u59cbVLM\u6a21\u578b\u63d0\u9ad8\u9ad8\u8fbe15.50\u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u5ea6\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u6807\u8bb0\u6570\u636e\u6216\u5916\u90e8\u6a21\u578b\u7684\u4ecb\u5165\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3Vision Language Models\u5728\u56fe\u8868\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u51c6\u786e\u7684\u56fe\u8868\u63cf\u8ff0\u548c\u590d\u6742\u63a8\u7406\u65b9\u9762\u7684\u6311\u6218\u3002\u5408\u6210\u6570\u636e\u751f\u6210\u88ab\u89c6\u4e3a\u4e00\u79cd\u6709\u5e0c\u671b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u901a\u5e38\u9762\u4e34\u6807\u7b7e\u566a\u97f3\u7684\u6311\u6218\u3002", "method": "\u672c\u6587\u9996\u5148\u5f15\u5165\u4e86\u4e00\u4e2a\u56fe\u8868\u7efc\u5408\u7ba1\u9053\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u548c\u6267\u884c\u4ea7\u751f\u5bf9\u9f50\u7684\u56fe\u8868-\u95ee\u9898-\u7b54\u6848\u4e09\u5143\u7ec4\uff0c\u4ee5\u786e\u4fdd\u5408\u6210\u6570\u636e\u7684\u53ef\u9760\u6027\uff0c\u800c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5019\u9009\u6761\u4ef6\u56de\u7b54\u8fc7\u7a0b\uff0c\u7075\u611f\u6765\u6e90\u4e8e\u6d4b\u8bd5\u65f6\u7684\u7f29\u653e\uff0c\u901a\u8fc7\u589e\u52a0\u63a8\u7406\u9884\u7b97\u6765\u63d0\u9ad8\u6027\u80fd\u3002VLM\u9996\u5148\u5bf9\u6bcf\u4e2a\u67e5\u8be2\u751f\u6210\u591a\u4e2a\u54cd\u5e94\uff0c\u7136\u540e\u901a\u8fc7\u7ed9\u8fd9\u4e9b\u5019\u9009\u8005\u63d0\u4f9b\u8bed\u5883\u6765\u7efc\u5408\u751f\u6210\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u672c\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u7740\u63d0\u5347\uff0c\u6700\u591a\u53ef\u4ee5\u6bd4\u521d\u59cbVLM\u6a21\u578b\u63d0\u9ad815.50\u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u5ea6\uff0c\u800c\u4e14\u5728\u5168\u81ea\u6211\u6539\u8fdb\u7684\u8303\u5f0f\u4e0b\u5b9e\u73b0\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u8bb0\u6570\u636e\u6216\u5916\u90e8\u6a21\u578b\u7684\u4ecb\u5165\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u56fe\u8868\u7efc\u5408\u7ba1\u9053\u548c\u5019\u9009\u6761\u4ef6\u56de\u7b54\u8fc7\u7a0b\uff0c\u672c\u6587\u89e3\u51b3\u4e86\u5408\u6210\u6570\u636e\u4e2d\u7684\u6807\u7b7e\u566a\u97f3\u6311\u6218\uff0c\u5e76\u5b9e\u73b0\u4e86\u5bf9\u56fe\u8868\u7406\u89e3\u4efb\u52a1\u7684\u663e\u7740\u63d0\u5347\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5168\u81ea\u6211\u6539\u8fdb\u8303\u5f0f\u4e0b\uff0c\u672c\u65b9\u6cd5\u5728\u51c6\u786e\u5ea6\u4e0a\u6bd4\u521d\u59cbVLM\u6a21\u578b\u63d0\u9ad8\u4e86\u9ad8\u8fbe15.50\u4e2a\u767e\u5206\u70b9\uff0c\u800c\u65e0\u9700\u4eba\u5de5\u6807\u8bb0\u6570\u636e\u6216\u5916\u90e8\u6a21\u578b\u4ecb\u5165\u3002"}}
{"id": "2508.11987", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11987", "abs": "https://arxiv.org/abs/2508.11987", "authors": ["Zhiyuan Zeng", "Jiashuo Liu", "Siyuan Chen", "Tianci He", "Yali Liao", "Jinpeng Wang", "Zaiyuan Wang", "Yang Yang", "Lingyue Yin", "Mingren Yin", "Zhenwei Zhu", "Tianle Cai", "Zehui Chen", "Jiecao Chen", "Yantao Du", "Xiang Gao", "Jiacheng Guo", "Liang Hu", "Jianpeng Jiao", "Xiangsheng Li", "Jingkai Liu", "Shuang Ni", "Zhoufutu Wen", "Ge Zhang", "Kaiyuan Zhang", "Xin Zhou", "Jose Blanchet", "Xipeng Qiu", "Mengdi Wang", "Wenhao Huang"], "title": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction", "comment": "Technical report, 51 pages", "summary": "Future prediction is a complex task for LLM agents, requiring a high level of\nanalytical thinking, information gathering, contextual understanding, and\ndecision-making under uncertainty. Agents must not only gather and interpret\nvast amounts of dynamic information but also integrate diverse data sources,\nweigh uncertainties, and adapt predictions based on emerging trends, just as\nhuman experts do in fields like politics, economics, and finance. Despite its\nimportance, no large-scale benchmark exists for evaluating agents on future\nprediction, largely due to challenges in handling real-time updates and\nretrieving timely, accurate answers. To address this, we introduce\n$\\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically\ndesigned for LLM agents performing future prediction tasks. FutureX is the\nlargest and most diverse live benchmark for future prediction, supporting\nreal-time daily updates and eliminating data contamination through an automated\npipeline for question gathering and answer collection. We evaluate 25 LLM/agent\nmodels, including those with reasoning, search capabilities, and integration of\nexternal tools such as the open-source Deep Research Agent and closed-source\nDeep Research models. This comprehensive evaluation assesses agents' adaptive\nreasoning and performance in dynamic environments. Additionally, we provide\nin-depth analyses of agents' failure modes and performance pitfalls in\nfuture-oriented tasks, including the vulnerability to fake web pages and the\ntemporal validity. Our goal is to establish a dynamic, contamination-free\nevaluation standard that drives the development of LLM agents capable of\nperforming at the level of professional human analysts in complex reasoning and\npredictive thinking.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e86FutureX\u8bc4\u4f30\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u672a\u6765\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u5bf925\u4e2a\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5305\u62ec\u63a8\u7406\u3001\u641c\u7d22\u80fd\u529b\u548c\u6574\u5408\u5916\u90e8\u5de5\u5177\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u4ee3\u7406\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u81ea\u9002\u5e94\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u8be6\u7ec6\u5206\u6790\u4e86\u6027\u80fd\u7f3a\u9677\uff0c\u4ee5\u4fc3\u8fdbLLM\u4ee3\u7406\u53d1\u5c55\u5230\u4e0e\u4e13\u4e1a\u4eba\u7c7b\u5206\u6790\u5e08\u76f8\u5ab2\u7f8e\u7684\u6c34\u5e73\u3002", "motivation": "\u672a\u6765\u9884\u6d4b\u5bf9LLM\u4ee3\u7406\u6765\u8bf4\u662f\u4e00\u9879\u590d\u6742\u7684\u4efb\u52a1\uff0c\u9700\u8981\u9ad8\u6c34\u5e73\u7684\u5206\u6790\u601d\u7ef4\u3001\u4fe1\u606f\u6536\u96c6\u3001\u8bed\u5883\u7406\u89e3\u548c\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u505a\u51fa\u51b3\u7b56\u3002\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6765\u8bc4\u4f30\u672a\u6765\u9884\u6d4b\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u5904\u7406\u5b9e\u65f6\u66f4\u65b0\u548c\u53ca\u65f6\u83b7\u53d6\u51c6\u786e\u7b54\u6848\u7684\u6311\u6218\u3002\u56e0\u6b64\uff0c\u5f15\u5165FutureX\u8bc4\u4f30\u57fa\u51c6\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f15\u5165$\textbf{FutureX}$\uff0c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u6267\u884c\u672a\u6765\u9884\u6d4b\u4efb\u52a1\u7684LLM\u4ee3\u7406\u8bbe\u8ba1\u7684\u52a8\u6001\u548c\u5b9e\u65f6\u8bc4\u4f30\u57fa\u51c6\u3002FutureX\u662f\u672a\u6765\u9884\u6d4b\u9886\u57df\u6700\u5927\u3001\u6700\u591a\u6837\u5316\u7684\u5b9e\u65f6\u57fa\u51c6\uff0c\u652f\u6301\u5b9e\u65f6\u6bcf\u65e5\u66f4\u65b0\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\u6d88\u9664\u6570\u636e\u6c61\u67d3\u3002\u5bf925\u4e2aLLM /\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5305\u62ec\u90a3\u4e9b\u5177\u6709\u63a8\u7406\u3001\u641c\u7d22\u80fd\u529b\u7684\u6a21\u578b\u4ee5\u53ca\u6574\u5408\u5916\u90e8\u5de5\u5177\uff08\u5982\u5f00\u6e90Deep Research Agent\u548c\u4e13\u6709Deep Research\u6a21\u578b\uff09\u3002", "result": "\u8bc4\u4f30\u4e8625\u4e2aLLM /\u4ee3\u7406\u6a21\u578b\u7684\u81ea\u9002\u5e94\u63a8\u7406\u80fd\u529b\u548c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e86\u4ee3\u7406\u7684\u5931\u6548\u6a21\u5f0f\u548c\u672a\u6765\u5bfc\u5411\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u7f3a\u9677\uff0c\u5305\u62ec\u865a\u5047\u7f51\u9875\u7684\u8106\u5f31\u6027\u548c\u65f6\u95f4\u6709\u6548\u6027\u3002", "conclusion": "\u5efa\u7acb\u4e86\u9762\u5411\u672a\u6765\u9884\u6d4b\u4efb\u52a1\u7684\u52a8\u6001\u548c\u65e0\u6c61\u67d3\u8bc4\u4f30\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e8625\u4e2aLLM /\u4ee3\u7406\u6a21\u578b\u7684\u81ea\u9002\u5e94\u63a8\u7406\u80fd\u529b\u548c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u540c\u65f6\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u4ee3\u7406\u7684\u5931\u6548\u6a21\u5f0f\u548c\u672a\u6765\u5bfc\u5411\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u7f3a\u9677\uff0c\u5305\u62ec\u5bf9\u865a\u5047\u7f51\u9875\u7684\u8106\u5f31\u6027\u548c\u65f6\u95f4\u6709\u6548\u6027\u3002\u65e8\u5728\u63a8\u52a8LLM\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u590d\u6742\u63a8\u7406\u548c\u9884\u6d4b\u601d\u7ef4\u65b9\u9762\u8fbe\u5230\u4e13\u4e1a\u4eba\u7c7b\u5206\u6790\u5e08\u7684\u6c34\u5e73\u3002"}}
{"id": "2508.11991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11991", "abs": "https://arxiv.org/abs/2508.11991", "authors": ["Weihao Sun"], "title": "Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network", "comment": null, "summary": "The automation of logic circuit design enhances chip performance, energy\nefficiency, and reliability, and is widely applied in the field of Electronic\nDesign Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,\noptimize, and verify the functional characteristics of digital circuits,\nenhancing the efficiency of EDA development.Due to the complex structure and\nlarge scale of nodes in real-world AIGs, accurate modeling is challenging,\nleading to existing work lacking the ability to jointly model functional and\nstructural characteristics, as well as insufficient dynamic information\npropagation capability.To address the aforementioned challenges, we propose\nAIGer.Specifically, AIGer consists of two components: 1) Node logic feature\ninitialization embedding component and 2) AIGs feature learning network\ncomponent.The node logic feature initialization embedding component projects\nlogic nodes, such as AND and NOT, into independent semantic spaces, to enable\neffective node embedding for subsequent processing.Building upon this, the AIGs\nfeature learning network component employs a heterogeneous graph convolutional\nnetwork, designing dynamic relationship weight matrices and differentiated\ninformation aggregation approaches to better represent the original structure\nand information of AIGs.The combination of these two components enhances\nAIGer's ability to jointly model functional and structural characteristics and\nimproves its message passing capability. Experimental results indicate that\nAIGer outperforms the current best models in the Signal Probability Prediction\n(SSP) task, improving MAE and MSE by 18.95\\% and 44.44\\%, respectively. In the\nTruth Table Distance Prediction (TTDP) task, AIGer achieves improvements of\n33.57\\% and 14.79\\% in MAE and MSE, respectively, compared to the\nbest-performing models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AIGer\u65b9\u6cd5\uff0c\u901a\u8fc7\u8282\u70b9\u903b\u8f91\u7279\u5f81\u521d\u59cb\u5316\u548cAIGs\u7279\u5f81\u5b66\u4e60\u7f51\u7edc\u4e24\u4e2a\u7ec4\u4ef6\uff0c\u63d0\u5347\u4e86\u5bf9AIGs\u7684\u529f\u80fd\u548c\u7ed3\u6784\u7279\u5f81\u8054\u5408\u5efa\u6a21\u80fd\u529b\uff0c\u6539\u8fdb\u4e86\u4fe1\u606f\u4f20\u9012\u80fd\u529b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u6bd4\u5f53\u524d\u6700\u4f73\u6a21\u578b\u66f4\u597d\u7684\u7ed3\u679c\u3002", "motivation": "\u7531\u4e8e\u771f\u5b9eAIGs\u7684\u590d\u6742\u7ed3\u6784\u548c\u5927\u89c4\u6a21\u8282\u70b9\uff0c\u51c6\u786e\u5efa\u6a21\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u5de5\u4f5c\u7f3a\u4e4f\u8054\u5408\u5efa\u6a21\u529f\u80fd\u548c\u7ed3\u6784\u7279\u5f81\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u52a8\u6001\u4fe1\u606f\u4f20\u64ad\u80fd\u529b\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u63d0\u51faAIGer\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "AIGer\u65b9\u6cd5\u5305\u62ec\u4e24\u4e2a\u7ec4\u4ef6\uff1a1\uff09\u8282\u70b9\u903b\u8f91\u7279\u5f81\u521d\u59cb\u5316\u5d4c\u5165\u7ec4\u4ef6\u548c2\uff09AIGs\u7279\u5f81\u5b66\u4e60\u7f51\u7edc\u7ec4\u4ef6\u3002\u8282\u70b9\u903b\u8f91\u7279\u5f81\u521d\u59cb\u5316\u5d4c\u5165\u7ec4\u4ef6\u5c06\u903b\u8f91\u8282\u70b9\u6295\u5f71\u5230\u72ec\u7acb\u7684\u8bed\u4e49\u7a7a\u95f4\uff0c\u4ee5\u4fbf\u8fdb\u884c\u540e\u7eed\u5904\u7406\u3002AIGs\u7279\u5f81\u5b66\u4e60\u7f51\u7edc\u7ec4\u4ef6\u5219\u5229\u7528\u5f02\u6784\u56fe\u5377\u79ef\u7f51\u7edc\uff0c\u8bbe\u8ba1\u52a8\u6001\u5173\u7cfb\u6743\u91cd\u77e9\u9635\u548c\u4e0d\u540c\u7684\u4fe1\u606f\u805a\u5408\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u8868\u793aAIGs\u7684\u539f\u59cb\u7ed3\u6784\u548c\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAIGer\u5728Signal Probability Prediction\uff08SSP\uff09\u4efb\u52a1\u4e2d\u5c06MAE\u548cMSE\u63d0\u9ad8\u4e8618.95\uff05\u548c44.44\uff05\uff0c\u5728Truth Table Distance Prediction\uff08TTDP\uff09\u4efb\u52a1\u4e2d\u5c06MAE\u548cMSE\u5206\u522b\u63d0\u9ad8\u4e8633.57\uff05\u548c14.79\uff05\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAIGer\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u4e2a\u7ec4\u4ef6\u5b9e\u73b0\u4e86\u5bf9AND-Inverter Graphs\uff08AIGs\uff09\u7684\u529f\u80fd\u548c\u7ed3\u6784\u7279\u5f81\u7684\u8054\u5408\u5efa\u6a21\uff0c\u6539\u8fdb\u4e86\u4fe1\u606f\u4f20\u9012\u80fd\u529b\uff0c\u5e76\u5728Signal Probability Prediction\uff08SSP\uff09\u548cTruth Table Distance Prediction\uff08TTDP\uff09\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5f53\u524d\u6700\u4f73\u6a21\u578b\u3002"}}
{"id": "2508.11995", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.11995", "abs": "https://arxiv.org/abs/2508.11995", "authors": ["Xuyang Zhao", "Shiwan Zhao", "Hualong Yu", "Liting Zhang", "Qicheng Li"], "title": "AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning", "comment": null, "summary": "Multi-agent systems (MAS) powered by large language models (LLMs) hold\nsignificant promise for solving complex decision-making tasks. However, the\ncore process of collaborative decision-making (CDM) within these systems\nremains underexplored. Existing approaches often rely on either ``dictatorial\"\nstrategies that are vulnerable to the cognitive biases of a single agent, or\n``voting-based\" methods that fail to fully harness collective intelligence. To\naddress these limitations, we propose \\textbf{AgentCDM}, a structured framework\nfor enhancing collaborative decision-making in LLM-based multi-agent systems.\nDrawing inspiration from the Analysis of Competing Hypotheses (ACH) in\ncognitive science, AgentCDM introduces a structured reasoning paradigm that\nsystematically mitigates cognitive biases and shifts decision-making from\npassive answer selection to active hypothesis evaluation and construction. To\ninternalize this reasoning process, we develop a two-stage training paradigm:\nthe first stage uses explicit ACH-inspired scaffolding to guide the model\nthrough structured reasoning, while the second stage progressively removes this\nscaffolding to encourage autonomous generalization. Experiments on multiple\nbenchmark datasets demonstrate that AgentCDM achieves state-of-the-art\nperformance and exhibits strong generalization, validating its effectiveness in\nimproving the quality and robustness of collaborative decisions in MAS.", "AI": {"tldr": "AgentCDM\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u53d7ACH\u542f\u53d1\u7684\u7ed3\u6784\u5316\u63a8\u7406\u8303\u5f0f\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u6765\u63d0\u9ad8\u5728LLM\u9a71\u52a8\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u534f\u4f5c\u51b3\u7b56\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cAgentCDM\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u5e76\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u4f9d\u8d56\u4e8e\u6613\u53d7\u5355\u4e2a\u4ee3\u7406\u8ba4\u77e5\u504f\u89c1\u5f71\u54cd\u7684\u201c\u72ec\u88c1\u201d\u7b56\u7565\uff0c\u6216\u8005\u57fa\u4e8e\u201c\u6295\u7968\u201d\u7684\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u96c6\u4f53\u667a\u6167\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u63d0\u51faAgentCDM\u4ee5\u589e\u5f3aLLM\u9a71\u52a8\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u534f\u4f5c\u51b3\u7b56\u3002", "method": "AgentCDM\u5f15\u5165\u4e86\u53d7\u8ba4\u77e5\u79d1\u5b66\u4e2d\u7ade\u4e89\u5047\u8bbe\u5206\u6790\uff08ACH\uff09\u542f\u53d1\u7684\u7ed3\u6784\u5316\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u6765\u5185\u5316\u8fd9\u4e00\u63a8\u7406\u8fc7\u7a0b\uff1a\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u660e\u786e\u7684ACH\u542f\u53d1\u5f0f\u811a\u624b\u67b6\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u7b2c\u4e8c\u9636\u6bb5\u9010\u6e10\u53bb\u9664\u811a\u624b\u67b6\u4ee5\u4fc3\u8fdb\u81ea\u4e3b\u6cdb\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAgentCDM\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u6539\u8fdbMAS\u4e2d\u7684\u534f\u4f5c\u51b3\u7b56\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "AgentCDM\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u6846\u67b6\u5728LLM\u9a71\u52a8\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u663e\u8457\u6539\u8fdb\u4e86\u534f\u4f5c\u51b3\u7b56\u7684\u8d28\u91cf\u548c\u9c81\u68d2\u6027\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\u548c\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.12022", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12022", "abs": "https://arxiv.org/abs/2508.12022", "authors": ["Dorsa Macky Aleagha", "Payam Zohari", "Mostafa Haghir Chehreghani"], "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review", "comment": null, "summary": "Major Depressive Disorder is one of the leading causes of disability\nworldwide, yet its diagnosis still depends largely on subjective clinical\nassessments. Integrating Artificial Intelligence (AI) holds promise for\ndeveloping objective, scalable, and timely diagnostic tools. In this paper, we\npresent a comprehensive survey of state-of-the-art AI methods for depression\ndetection and diagnosis, based on a systematic review of 55 key studies. We\nintroduce a novel hierarchical taxonomy that structures the field by primary\nclinical task (diagnosis vs. prediction), data modality (text, speech,\nneuroimaging, multimodal), and computational model class (e.g., graph neural\nnetworks, large language models, hybrid approaches). Our in-depth analysis\nreveals three major trends: the predominance of graph neural networks for\nmodeling brain connectivity, the rise of large language models for linguistic\nand conversational data, and an emerging focus on multimodal fusion,\nexplainability, and algorithmic fairness. Alongside methodological insights, we\nprovide an overview of prominent public datasets and standard evaluation\nmetrics as a practical guide for researchers. By synthesizing current advances\nand highlighting open challenges, this survey offers a comprehensive roadmap\nfor future innovation in computational psychiatry.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e8655\u9879\u5173\u952e\u7814\u7a76\uff0c\u603b\u7ed3\u4e86\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u5728\u6291\u90c1\u75c7\u68c0\u6d4b\u548c\u8bca\u65ad\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\u3002\u901a\u8fc7\u7ed3\u6784\u5316\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u4e09\u5927\u8d8b\u52bf\uff1a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u548c\u5bf9\u8bdd\u6570\u636e\u5e94\u7528\u589e\u591a\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8111\u90e8\u8fde\u63a5\u5efa\u6a21\u65b9\u9762\u4e3b\u5bfc\u3001\u4ee5\u53ca\u5bf9\u591a\u6a21\u6001\u878d\u5408\u3001\u53ef\u89e3\u91ca\u6027\u548c\u7b97\u6cd5\u516c\u5e73\u6027\u7684\u65b0\u5174\u5173\u6ce8\u3002\u63d0\u4f9b\u4e86\u5bf9\u4e3b\u8981\u516c\u5171\u6570\u636e\u96c6\u548c\u6807\u51c6\u8bc4\u4f30\u6307\u6807\u7684\u6982\u8ff0\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u5b9e\u8df5\u6307\u5357\uff0c\u4e3a\u672a\u6765\u8ba1\u7b97\u7cbe\u795e\u75c5\u5b66\u7684\u521b\u65b0\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u53d1\u5c55\u8def\u7ebf\u56fe\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u6291\u90c1\u75c7\u662f\u5168\u7403\u6b8b\u75be\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\uff0c\u4f46\u5176\u8bca\u65ad\u4ecd\u7136\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e3b\u89c2\u4e34\u5e8a\u8bc4\u4f30\u3002\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53ef\u4ee5\u5f00\u53d1\u5ba2\u89c2\u3001\u53ef\u6269\u5c55\u548c\u53ca\u65f6\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4e3a\u89e3\u51b3\u6291\u90c1\u75c7\u8bca\u65ad\u95ee\u9898\u63d0\u4f9b\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u5ba1\u67e555\u9879\u5173\u952e\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u5229\u7528\u4eba\u5de5\u667a\u80fd\u8fdb\u884c\u6291\u90c1\u75c7\u68c0\u6d4b\u548c\u8bca\u65ad\u7684\u7efc\u5408\u8c03\u67e5\u3002\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5c42\u6b21\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u4e3b\u8981\u7684\u4e34\u5e8a\u4efb\u52a1\uff08\u8bca\u65ad\u4e0e\u9884\u6d4b\uff09\u3001\u6570\u636e\u6a21\u6001\uff08\u6587\u672c\u3001\u8bed\u97f3\u3001\u795e\u7ecf\u5f71\u50cf\u3001\u591a\u6a21\u6001\uff09\u548c\u8ba1\u7b97\u6a21\u578b\u7c7b\u522b\uff08\u5982\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u6df7\u5408\u65b9\u6cd5\uff09\u5bf9\u9886\u57df\u8fdb\u884c\u7ed3\u6784\u5316\u3002\u8be6\u7ec6\u5206\u6790\u63ed\u793a\u4e86\u4e09\u4e2a\u4e3b\u8981\u8d8b\u52bf\u3002", "result": "\u672c\u6587\u63d0\u4f9b\u4e86\u5173\u4e8e\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u5728\u6291\u90c1\u75c7\u68c0\u6d4b\u548c\u8bca\u65ad\u9886\u57df\u7684\u5168\u9762\u8c03\u67e5\uff0c\u7cfb\u7edf\u5ba1\u67e5\u4e8655\u9879\u5173\u952e\u7814\u7a76\uff0c\u5e76\u5c55\u793a\u4e86\u4e09\u4e2a\u4e3b\u8981\u8d8b\u52bf\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7a81\u51fa\u516c\u5171\u6570\u636e\u96c6\u548c\u6807\u51c6\u8bc4\u4f30\u6307\u6807\u7684\u6982\u89c8\uff0c\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\u7684\u5b9e\u8df5\u6307\u5357\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u9879\u5173\u4e8e\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6280\u672f\u8fdb\u884c\u6291\u90c1\u75c7\u68c0\u6d4b\u548c\u8bca\u65ad\u7684\u7efc\u5408\u8c03\u67e5\uff0c\u901a\u8fc7\u7cfb\u7edf\u5ba1\u67e5\u4e8655\u9879\u5173\u952e\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u3002\u7814\u7a76\u7ed3\u8bba\u663e\u793a\u4e86\u4e09\u4e2a\u4e3b\u8981\u8d8b\u52bf\uff1a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u548c\u5bf9\u8bdd\u6570\u636e\u65b9\u9762\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8111\u90e8\u8fde\u63a5\u5efa\u6a21\u65b9\u9762\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4ee5\u53ca\u5bf9\u591a\u6a21\u6001\u878d\u5408\u3001\u53ef\u89e3\u91ca\u6027\u548c\u7b97\u6cd5\u516c\u5e73\u6027\u7684\u65b0\u5174\u5173\u6ce8\u3002\u6574\u4f53\u800c\u8a00\uff0c\u672c\u6587\u4e3a\u672a\u6765\u8ba1\u7b97\u7cbe\u795e\u75c5\u5b66\u521b\u65b0\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u53d1\u5c55\u8def\u7ebf\u56fe\u3002"}}
{"id": "2508.12026", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.12026", "abs": "https://arxiv.org/abs/2508.12026", "authors": ["Szymon Pawlonka", "Miko\u0142aj Ma\u0142ki\u0144ski", "Jacek Ma\u0144dziuk"], "title": "Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems", "comment": null, "summary": "Bongard Problems (BPs) provide a challenging testbed for abstract visual\nreasoning (AVR), requiring models to identify visual concepts fromjust a few\nexamples and describe them in natural language. Early BP benchmarks featured\nsynthetic black-and-white drawings, which might not fully capture the\ncomplexity of real-world scenes. Subsequent BP datasets employed real-world\nimages, albeit the represented concepts are identifiable from high-level image\nfeatures, reducing the task complexity. Differently, the recently released\nBongard-RWR dataset aimed at representing abstract concepts formulated in the\noriginal BPs using fine-grained real-world images. Its manual construction,\nhowever, limited the dataset size to just $60$ instances, constraining\nevaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset\ncomposed of $5\\,400$ instances that represent original BP abstract concepts\nusing real-world-like images generated via a vision language model (VLM)\npipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually\ncurated images and generate new descriptions aligned with the underlying\nconcepts, use Flux.1-dev to synthesize images from these descriptions, and\nmanually verify that the generated images faithfully reflect the intended\nconcepts. We evaluate state-of-the-art VLMs across diverse BP formulations,\nincluding binary and multiclass classification, as well as textual answer\ngeneration. Our findings reveal that while VLMs can recognize coarse-grained\nvisual concepts, they consistently struggle with discerning fine-grained\nconcepts, highlighting limitations in their reasoning capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86 Bongard-RWR+ \u6570\u636e\u96c6\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7c7b\u4f3c\u771f\u5b9e\u4e16\u754c\u7684\u56fe\u50cf\uff0c\u7528\u4e8e\u8868\u793a\u539f\u59cb Bongard Problems \u7684\u62bd\u8c61\u6982\u5ff5\u3002\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c Bongard Problems \u8868\u8ff0\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u8fa8\u522b\u7ec6\u7c92\u5ea6\u6982\u5ff5\u65f6\u5b58\u5728\u6311\u6218\uff0c\u663e\u793a\u4e86\u5b83\u4eec\u7684\u63a8\u7406\u80fd\u529b\u9650\u5236\u3002", "motivation": "\u8d77\u521d\u7684 Bongard Problems \u57fa\u51c6\u6d4b\u8bd5\u91c7\u7528\u5408\u6210\u7684\u9ed1\u767d\u56fe\u50cf\uff0c\u4e0d\u80fd\u5b8c\u5168\u6355\u6349\u73b0\u5b9e\u573a\u666f\u7684\u590d\u6742\u6027\u3002\u540e\u7eed\u7684\u6570\u636e\u96c6\u867d\u7136\u91c7\u7528\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\uff0c\u4f46\u6240\u4ee3\u8868\u7684\u6982\u5ff5\u662f\u53ef\u4ece\u9ad8\u7ea7\u56fe\u50cf\u7279\u5f81\u4e2d\u8bc6\u522b\u7684\uff0c\u964d\u4f4e\u4e86\u4efb\u52a1\u590d\u6742\u5ea6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u4f7f\u7528\u7ec6\u7c92\u5ea6\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u6765\u8868\u793a\u62bd\u8c61\u6982\u5ff5\u7684\u6570\u636e\u96c6\u3002", "method": "\u901a\u8fc7\u6784\u5efa Bongard-RWR+ \u6570\u636e\u96c6\uff0c\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7c7b\u4f3c\u771f\u5b9e\u4e16\u754c\u7684\u56fe\u50cf\u6765\u8868\u793a\u539f\u59cb Bongard Problems \u7684\u62bd\u8c61\u6982\u5ff5\u3002\u5229\u7528 Pixtral-12B \u63cf\u8ff0\u624b\u52a8\u7b56\u5212\u7684\u56fe\u50cf\u5e76\u751f\u6210\u4e0e\u57fa\u7840\u6982\u5ff5\u4e00\u81f4\u7684\u65b0\u63cf\u8ff0\uff0c\u4f7f\u7528 Flux.1-dev \u5408\u6210\u8fd9\u4e9b\u63cf\u8ff0\u7684\u56fe\u50cf\uff0c\u5e76\u624b\u52a8\u9a8c\u8bc1\u751f\u6210\u7684\u56fe\u50cf\u662f\u5426\u5fe0\u5b9e\u5730\u53cd\u6620\u4e86\u9884\u671f\u6982\u5ff5\u3002\u5728\u4e0d\u540c\u7684 Bongard Problems \u8868\u8ff0\u4e2d\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ec\u4e8c\u5143\u548c\u591a\u7c7b\u5206\u7c7b\uff0c\u4ee5\u53ca\u6587\u672c\u7b54\u6848\u751f\u6210\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30 VLM \u5728\u4e0d\u540c Bongard Problems \u8868\u8ff0\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u8bc6\u522b\u7c97\u7c92\u5ea6\u89c6\u89c9\u6982\u5ff5\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8fa8\u522b\u7ec6\u7c92\u5ea6\u6982\u5ff5\u65f6\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\u867d\u7136\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u8bc6\u522b\u7c97\u7c92\u5ea6\u7684\u89c6\u89c9\u6982\u5ff5\uff0c\u4f46\u5728\u8fa8\u522b\u7ec6\u7c92\u5ea6\u6982\u5ff5\u65f6\u4e00\u76f4\u5b58\u5728\u56f0\u96be\uff0c\u7a81\u663e\u4e86\u5b83\u4eec\u63a8\u7406\u80fd\u529b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.12027", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.12027", "abs": "https://arxiv.org/abs/2508.12027", "authors": ["Filippo Torresan", "Keisuke Suzuki", "Ryota Kanai", "Manuel Baltieri"], "title": "Active inference for action-unaware agents", "comment": "59 pages, 47 figures", "summary": "Active inference is a formal approach to study cognition based on the notion\nthat adaptive agents can be seen as engaging in a process of approximate\nBayesian inference, via the minimisation of variational and expected free\nenergies. Minimising the former provides an account of perceptual processes and\nlearning as evidence accumulation, while minimising the latter describes how\nagents select their actions over time. In this way, adaptive agents are able to\nmaximise the likelihood of preferred observations or states, given a generative\nmodel of the environment. In the literature, however, different strategies have\nbeen proposed to describe how agents can plan their future actions. While they\nall share the notion that some kind of expected free energy offers an\nappropriate way to score policies, sequences of actions, in terms of their\ndesirability, there are different ways to consider the contribution of past\nmotor experience to the agent's future behaviour. In some approaches, agents\nare assumed to know their own actions, and use such knowledge to better plan\nfor the future. In other approaches, agents are unaware of their actions, and\nmust infer their motor behaviour from recent observations in order to plan for\nthe future. This difference reflects a standard point of departure in two\nleading frameworks in motor control based on the presence, or not, of an\nefference copy signal representing knowledge about an agent's own actions. In\nthis work we compare the performances of action-aware and action-unaware agents\nin two navigations tasks, showing how action-unaware agents can achieve\nperformances comparable to action-aware ones while at a severe disadvantage.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u884c\u4e3a\u611f\u77e5\u548c\u4e0d\u5177\u6709\u884c\u4e3a\u611f\u77e5\u7684\u4ee3\u7406\u5728\u4e24\u4e2a\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u4e0d\u5177\u6709\u884c\u4e3a\u611f\u77e5\u7684\u4ee3\u7406\u53ef\u4ee5\u5728\u4e25\u91cd\u52a3\u52bf\u4e0b\u5b9e\u73b0\u4e0e\u5177\u6709\u884c\u4e3a\u611f\u77e5\u4ee3\u7406\u76f8\u5ab2\u7f8e\u7684\u8868\u73b0\u3002\u7814\u7a76\u4ee3\u7406\u672a\u6765\u884c\u52a8\u89c4\u5212\u7b56\u7565\u548c\u884c\u4e3a\u7ecf\u9a8c\u5bf9\u4ee3\u7406\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u8ba4\u77e5\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u4ee3\u7406\u5982\u4f55\u89c4\u5212\u672a\u6765\u884c\u52a8\u7684\u4e0d\u540c\u7b56\u7565\u4ee5\u53ca\u5b83\u4eec\u7684\u8868\u73b0\u5bf9\u6bd4\u6709\u52a9\u4e8e\u6211\u4eec\u4e86\u89e3\u8ba4\u77e5\u65b9\u9762\u7684\u76f8\u5173\u673a\u5236\u3002\u672c\u6587\u901a\u8fc7\u5bf9\u884c\u4e3a\u611f\u77e5\u548c\u4e0d\u5177\u6709\u884c\u4e3a\u611f\u77e5\u4ee3\u7406\u7684\u5bf9\u6bd4\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u884c\u4e3a\u7ecf\u9a8c\u5bf9\u4ee3\u7406\u672a\u6765\u884c\u4e3a\u89c4\u5212\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u4e86\u6bd4\u8f83\u884c\u4e3a\u611f\u77e5\u548c\u4e0d\u5177\u6709\u884c\u4e3a\u611f\u77e5\u7684\u4ee3\u7406\u5728\u4e24\u4e2a\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u6765\u8bc4\u4f30\u5b83\u4eec\u7684\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u5177\u6709\u884c\u4e3a\u611f\u77e5\u7684\u4ee3\u7406\u53ef\u4ee5\u5728\u4e25\u91cd\u52a3\u52bf\u4e0b\u5b9e\u73b0\u4e0e\u5177\u6709\u884c\u4e3a\u611f\u77e5\u4ee3\u7406\u76f8\u5ab2\u7f8e\u7684\u8868\u73b0\u3002", "conclusion": "\u6bd4\u8f83\u4e86\u5177\u6709\u884c\u4e3a\u611f\u77e5\u548c\u4e0d\u5177\u6709\u884c\u4e3a\u611f\u77e5\u7684\u4ee3\u7406\u5728\u4e24\u4e2a\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8868\u660e\u4e0d\u5177\u6709\u884c\u4e3a\u611f\u77e5\u7684\u4ee3\u7406\u53ef\u4ee5\u5728\u4e25\u91cd\u52a3\u52bf\u4e0b\u5b9e\u73b0\u4e0e\u5177\u6709\u884c\u4e3a\u611f\u77e5\u4ee3\u7406\u76f8\u5ab2\u7f8e\u7684\u8868\u73b0\u3002"}}
{"id": "2508.12087", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.12087", "abs": "https://arxiv.org/abs/2508.12087", "authors": ["Zhanjiang Yang", "Meng Li", "Yang Shen", "Yueming Li", "Lijun Sun"], "title": "MAPF-World: Action World Model for Multi-Agent Path Finding", "comment": null, "summary": "Multi-agent path finding (MAPF) is the problem of planning conflict-free\npaths from the designated start locations to goal positions for multiple\nagents. It underlies a variety of real-world tasks, including multi-robot\ncoordination, robot-assisted logistics, and social navigation. Recent\ndecentralized learnable solvers have shown great promise for large-scale MAPF,\nespecially when leveraging foundation models and large datasets. However, these\nagents are reactive policy models and exhibit limited modeling of environmental\ntemporal dynamics and inter-agent dependencies, resulting in performance\ndegradation in complex, long-term planning scenarios. To address these\nlimitations, we propose MAPF-World, an autoregressive action world model for\nMAPF that unifies situation understanding and action generation, guiding\ndecisions beyond immediate local observations. It improves situational\nawareness by explicitly modeling environmental dynamics, including spatial\nfeatures and temporal dependencies, through future state and actions\nprediction. By incorporating these predicted futures, MAPF-World enables more\ninformed, coordinated, and far-sighted decision-making, especially in complex\nmulti-agent settings. Furthermore, we augment MAPF benchmarks by introducing an\nautomatic map generator grounded in real-world scenarios, capturing practical\nmap layouts for training and evaluating MAPF solvers. Extensive experiments\ndemonstrate that MAPF-World outperforms state-of-the-art learnable solvers,\nshowcasing superior zero-shot generalization to out-of-distribution cases.\nNotably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced\ndata.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86MAPF-World\uff0c\u4e00\u4e2a\u81ea\u56de\u5f52\u52a8\u4f5c\u4e16\u754c\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u95ee\u9898\u3002\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u73af\u5883\u52a8\u6001\u548c\u672a\u6765\u72b6\u6001\u9884\u6d4b\uff0c\u63d0\u9ad8\u60c5\u5883\u611f\u77e5\uff0c\u4f7f\u51b3\u7b56\u66f4\u52a0\u534f\u8c03\u548c\u6709\u8fdc\u89c1\u3002\u5b9e\u9a8c\u8bc1\u660eMAPF-World\u4f18\u4e8e\u5176\u4ed6\u5b66\u4e60\u6c42\u89e3\u5668\uff0c\u5728\u6cdb\u5316\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u6563\u5f0f\u53ef\u5b66\u4e60\u6c42\u89e3\u5668\u5728\u5904\u7406\u5927\u89c4\u6a21MAPF\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u5f88\u5927\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u5229\u7528\u57fa\u7840\u6a21\u578b\u548c\u5927\u578b\u6570\u636e\u96c6\u65f6\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u667a\u80fd\u4f53\u662f\u53cd\u5e94\u6027\u7b56\u7565\u6a21\u578b\uff0c\u5bf9\u73af\u5883\u65f6\u95f4\u52a8\u6001\u548c\u667a\u80fd\u4f53\u4f9d\u8d56\u6027\u7684\u5efa\u6a21\u6709\u9650\uff0c\u5728\u590d\u6742\u7684\u957f\u671f\u89c4\u5212\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u6027\u80fd\u4e0b\u964d\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u51fa\u4e86MAPF-World\uff0c\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u73af\u5883\u52a8\u6001\u5efa\u6a21\u548c\u672a\u6765\u72b6\u6001\u9884\u6d4b\u6765\u6539\u8fdbMAPF\u95ee\u9898\u7684\u51b3\u7b56\u5236\u5b9a\u3002", "method": "\u63d0\u51fa\u4e86MAPF-World\uff0c\u4e00\u4e2a\u81ea\u56de\u5f52\u52a8\u4f5c\u4e16\u754c\u6a21\u578b\uff0c\u4ee5\u6539\u8fdbMAPF\u95ee\u9898\u4e2d\u591a\u667a\u80fd\u4f53\u7684\u51b3\u7b56\u5236\u5b9a\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u73af\u5883\u52a8\u6001\u3001\u7a7a\u95f4\u7279\u5f81\u548c\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u901a\u8fc7\u672a\u6765\u72b6\u6001\u548c\u52a8\u4f5c\u9884\u6d4b\u6765\u63d0\u9ad8\u60c5\u5883\u611f\u77e5\uff0c\u4f7f\u51b3\u7b56\u66f4\u52a0\u660e\u667a\u3001\u534f\u8c03\u548c\u6709\u8fdc\u89c1\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u57fa\u4e8e\u5b9e\u9645\u60c5\u666f\u7684\u81ea\u52a8\u751f\u6210\u5730\u56fe\u751f\u6210\u5668\u6765\u6269\u5c55MAPF\u57fa\u51c6\uff0c\u6355\u6349\u8bad\u7ec3\u548c\u8bc4\u4f30MAPF\u6c42\u89e3\u5668\u7684\u5b9e\u9645\u5730\u56fe\u5e03\u5c40\u3002", "result": "MAPF-World\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u5b66\u4e60\u6c42\u89e3\u5668\uff0c\u5177\u6709\u51fa\u8272\u7684\u96f6\u6b21\u6cdb\u5316\u6027\u80fd\u3002\u6b64\u5916\uff0cMAPF-World\u5728\u6bd4\u8f83\u5c0f\u7684\u6a21\u578b\u5927\u5c0f\u548c\u51cf\u5c11\u7684\u6570\u636e\u91cf\u4e0b\u8bad\u7ec3\uff0c\u663e\u793a\u51fa\u9ad8\u6548\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u4e86MAPF-World\uff0c\u8fd9\u662f\u4e00\u4e2a\u81ea\u56de\u5f52\u52a8\u4f5c\u4e16\u754c\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3MAPF\u95ee\u9898\u3002\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u73af\u5883\u52a8\u6001\uff0c\u5305\u62ec\u7a7a\u95f4\u7279\u5f81\u548c\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u901a\u8fc7\u672a\u6765\u72b6\u6001\u548c\u52a8\u4f5c\u9884\u6d4b\uff0c\u63d0\u9ad8\u60c5\u5883\u611f\u77e5\u3002\u5728\u590d\u6742\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\u4f7f\u51b3\u7b56\u66f4\u52a0\u660e\u667a\u3001\u534f\u8c03\u548c\u6709\u8fdc\u89c1\u3002\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5b9e\u9645\u60c5\u666f\u7684\u81ea\u52a8\u751f\u6210\u5730\u56fe\u751f\u6210\u5668\u6765\u6269\u5c55MAPF\u57fa\u51c6\uff0c\u662f\u8bad\u7ec3\u548c\u8bc4\u4f30MAPF\u6c42\u89e3\u5668\u7684\u5b9e\u9645\u5730\u56fe\u5e03\u5c40\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cMAPF-World\u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u53ef\u5b66\u4e60\u6c42\u89e3\u5668\uff0c\u5728\u8d85\u51fa\u5206\u5e03\u8303\u56f4\u7684\u60c5\u51b5\u4e0b\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u96f6\u6b21\u6cdb\u5316\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cMAPF-World\u572896.5%\u8f83\u5c0f\u7684\u6a21\u578b\u5927\u5c0f\u548c92%\u51cf\u5c11\u7684\u6570\u636e\u91cf\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u8bad\u7ec3\u3002"}}
{"id": "2508.12100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12100", "abs": "https://arxiv.org/abs/2508.12100", "authors": ["Daniel Burkhardt", "Xiangwei Cheng"], "title": "Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios", "comment": "13 pages, 1 figure, 6 tables", "summary": "Reasoning in interactive problem solving scenarios requires models to\nconstruct reasoning threads that reflect user understanding and align with\nstructured domain knowledge. However, current reasoning models often lack\nexplicit semantic hierarchies, user-domain knowledge alignment, and principled\nmechanisms to prune reasoning threads for effectiveness. These limitations\nresult in lengthy generic output that does not guide users through\ngoal-oriented reasoning steps. To address this, we propose a\nprototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)\nframework, drawing inspiration from human-like reasoning strategies that\nemphasize structured knowledge reuse. In the first phase, semantically relevant\nknowledge structures are extracted from a sparse domain knowledge graph using a\ngraph neural network and enriched with intrinsic large language model knowledge\nto resolve knowledge discrepancies. In the second phase, these threads are\nevaluated and pruned using a reward-guided strategy aimed at maintaining\nsemantic coherence to generate effective reasoning threads. Experiments and\nexpert evaluations show that ReT-Eval enhances user understanding and\noutperforms state-of-the-art reasoning models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u63a8\u7406\u7ebf\u7a0b\u8bc4\u4f30\u6846\u67b6ReT-Eval\uff0c\u901a\u8fc7\u4ece\u9886\u57df\u77e5\u8bc6\u56fe\u4e2d\u63d0\u53d6\u8bed\u4e49\u76f8\u5173\u77e5\u8bc6\u5e76\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u6d88\u9664\u5dee\u5f02\uff0c\u7ed3\u5408\u5956\u52b1\u5f15\u5bfc\u7b56\u7565\u8bc4\u4f30\u548c\u4fee\u526a\u63a8\u7406\u7ebf\u7a0b\uff0c\u4ee5\u589e\u5f3a\u7528\u6237\u7406\u89e3\u548c\u63d0\u9ad8\u63a8\u7406\u6548\u679c\u3002\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u7684\u63a8\u7406\u6a21\u578b\u3002", "motivation": "\u63a8\u7406\u4ea4\u4e92\u95ee\u9898\u89e3\u51b3\u573a\u666f\u9700\u8981\u6a21\u578b\u6784\u5efa\u53cd\u6620\u7528\u6237\u7406\u89e3\u5e76\u4e0e\u7ed3\u6784\u5316\u9886\u57df\u77e5\u8bc6\u4e00\u81f4\u7684\u63a8\u7406\u7ebf\u7a0b\uff0c\u7136\u800c\u76ee\u524d\u7684\u63a8\u7406\u6a21\u578b\u7f3a\u4e4f\u663e\u5f0f\u8bed\u4e49\u5c42\u6b21\u3001\u7528\u6237-\u9886\u57df\u77e5\u8bc6\u5bf9\u9f50\u4ee5\u53ca\u6709\u6548\u4fee\u526a\u63a8\u7406\u7ebf\u7a0b\u7684\u65b9\u6cd5\uff0c\u5bfc\u81f4\u8f93\u51fa\u5197\u957f\u4e14\u4e0d\u6307\u5bfc\u7528\u6237\u5b8c\u6210\u76ee\u6807\u5bfc\u5411\u7684\u63a8\u7406\u6b65\u9aa4\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ReT-Eval\u6846\u67b6\u3002", "method": "\u8be5\u8bba\u6587\u91c7\u7528\u4e86\u4e24\u9636\u6bb5\u7684\u63a8\u7406\u7ebf\u7a0b\u8bc4\u4f30\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u4ece\u7a00\u758f\u9886\u57df\u77e5\u8bc6\u56fe\u4e2d\u63d0\u53d6\u8bed\u4e49\u76f8\u5173\u7684\u77e5\u8bc6\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u6765\u6d88\u9664\u77e5\u8bc6\u5dee\u5f02\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u5956\u52b1\u5f15\u5bfc\u7b56\u7565\u8bc4\u4f30\u548c\u4fee\u526a\u8fd9\u4e9b\u7ebf\u7a0b\uff0c\u4ee5\u4fdd\u6301\u8bed\u4e49\u8fde\u8d2f\u6027\u751f\u6210\u6709\u6548\u7684\u63a8\u7406\u7ebf\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eReT-Eval\u5728\u63d0\u9ad8\u7528\u6237\u7406\u89e3\u548c\u63a8\u7406\u6548\u679c\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u63a8\u7406\u6a21\u578b\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u63a8\u7406\u7b56\u7565\u3001\u7ed3\u6784\u5316\u77e5\u8bc6\u590d\u7528\u7684\u4e24\u9636\u6bb5\u63a8\u7406\u7ebf\u7a0b\u8bc4\u4f30\u6846\u67b6ReT-Eval\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u63a8\u7406\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u63a8\u7406\u6548\u679c\u3002\u5b9e\u9a8c\u8bc1\u660eReT-Eval\u80fd\u591f\u589e\u5f3a\u7528\u6237\u7406\u89e3\uff0c\u5e76\u4f18\u4e8e\u76ee\u524d\u7684\u63a8\u7406\u6a21\u578b\u3002"}}
{"id": "2508.12149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12149", "abs": "https://arxiv.org/abs/2508.12149", "authors": ["Haochen You", "Baojing Liu"], "title": "MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization", "comment": "Accepted as a conference paper at CIKM 2025", "summary": "Recent advances in multimodal learning have largely relied on pairwise\ncontrastive objectives to align different modalities, such as text, video, and\naudio, in a shared embedding space. While effective in bi-modal setups, these\napproaches struggle to generalize across multiple modalities and often lack\nsemantic structure in high-dimensional spaces. In this paper, we propose MOVER,\na novel framework that combines optimal transport-based soft alignment with\nvolume-based geometric regularization to build semantically aligned and\nstructured multimodal representations. By integrating a transport-guided\nmatching mechanism with a geometric volume minimization objective (GAVE), MOVER\nencourages consistent alignment across all modalities in a modality-agnostic\nmanner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER\nsignificantly outperforms prior state-of-the-art methods in both zero-shot and\nfinetuned settings. Additional analysis shows improved generalization to unseen\nmodality combinations and stronger structural consistency in the learned\nembedding space.", "AI": {"tldr": "MOVER framework enhances multimodal learning by combining optimal transport-based alignment and geometric volume minimization, outperforming existing methods in text-video-audio retrieval tasks with improved generalization and structural consistency.", "motivation": "Existing multimodal learning approaches struggle to generalize across multiple modalities and lack semantic structure in high-dimensional spaces.", "method": "Propose MOVER, a framework combining optimal transport-based soft alignment and geometric volume minimization to build semantically aligned multimodal representations.", "result": "Experiments show that MOVER outperforms previous methods in zero-shot and finetuned settings, with improved generalization to unseen modality combinations and stronger structural consistency in the learned embedding space.", "conclusion": "MOVER framework significantly outperforms prior state-of-the-art methods in text-video-audio retrieval tasks, demonstrating improved generalization and stronger structural consistency in learned embeddings."}}
{"id": "2508.12165", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12165", "abs": "https://arxiv.org/abs/2508.12165", "authors": ["Rohit Krishnan", "Jon Evans"], "title": "RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards", "comment": null, "summary": "This paper introduces RLNVR (Reinforcement Learning from Non-Verified\nRewards), a framework for training language models using noisy, real-world\nfeedback signals without requiring explicit human verification. Traditional\nRLHF requires expensive, verified reward signals that are impractical in many\nreal-world domains. RLNVR addresses this challenge through baseline\nnormalization and semantic similarity-based reward transfer. We demonstrate\nRLNVR through Walter, a prototype system that optimizes social media content\ngeneration using actual engagement data from Bluesky. Our experimental results\nshow significant improvements in content quality and training stability, with\ncomprehensive evaluation planned for future work. Positioning: We present a\npractical framework that combines RLNVR with GSPO (Group Sequence Policy\nOptimization) and an optional UED (Unsupervised Environment Design) curriculum\nto improve stability and diversity under noisy, implicit rewards. To our\nknowledge, combining GSPO-style normalization with a UED-style curriculum for\nLLM content generation from implicit social engagement has not been previously\ndocumented in this applied setting; we frame this as an applied integration\nrather than a new algorithm.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86RLNVR\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u65e0\u9700\u660e\u786e\u7684\u4eba\u5de5\u9a8c\u8bc1\u3002\u901a\u8fc7\u57fa\u51c6\u89c4\u8303\u5316\u548c\u8bed\u4e49\u76f8\u4f3c\u6027\u5956\u52b1\u8f6c\u79fb\u89e3\u51b3\u4f20\u7edfRLHF\u9700\u8981\u6602\u8d35\u9a8c\u8bc1\u5956\u52b1\u4fe1\u53f7\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u5728\u5185\u5bb9\u8d28\u91cf\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0a\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5c06\u8fdb\u4e00\u6b65\u8bc4\u4f30\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u8be5\u6846\u67b6\u7ed3\u5408GSPO\u548cUED\u8bfe\u7a0b\uff0c\u63d0\u9ad8\u5728\u5608\u6742\u7684\u9690\u5f0f\u5956\u52b1\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edf\u7684RLHF\u9700\u8981\u6602\u8d35\u7684\u3001\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u5728\u8bb8\u591a\u5b9e\u9645\u9886\u57df\u4e2d\u5e76\u4e0d\u5207\u5b9e\u9645\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u63d0\u51faRLNVR\u6846\u67b6\uff0c\u89e3\u51b3\u5728\u5b9e\u9645\u9886\u57df\u4e2d\u4f7f\u7528\u5608\u6742\u7684\u3001\u771f\u5b9e\u4e16\u754c\u53cd\u9988\u4fe1\u53f7\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u6311\u6218\u3002\u540c\u65f6\uff0c\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u5956\u52b1\u8f6c\u79fb\u548c\u57fa\u51c6\u89c4\u8303\u5316\u4e5f\u6709\u52a9\u4e8e\u63d0\u9ad8\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u8d28\u91cf\u3002", "method": "\u7ed3\u5408RLNVR\u4e0eGSPO\uff08Group Sequence Policy Optimization\uff09\u548c\u53ef\u9009\u7684UED\uff08\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff09\u8bfe\u7a0b\uff0c\u4ee5\u5728\u5608\u6742\u7684\u9690\u5f0f\u5956\u52b1\u4e0b\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u591a\u6837\u6027\u3002\u5c06GSPO\u98ce\u683c\u7684\u89c4\u8303\u5316\u4e0eUED\u98ce\u683c\u7684\u8bfe\u7a0b\u76f8\u7ed3\u5408\uff0c\u7528\u4e8eLLL\u5185\u5bb9\u751f\u6210\uff0c\u4ece\u9690\u5f0f\u793e\u4ea4\u53c2\u4e0e\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c1a\u672a\u6709\u76f8\u5173\u6587\u732e\u8bb0\u5f55\uff1b\u6211\u4eec\u5c06\u5176\u5b9a\u4f4d\u4e3a\u5e94\u7528\u96c6\u6210\uff0c\u800c\u975e\u65b0\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5185\u5bb9\u8d28\u91cf\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002\u672a\u6765\u8ba1\u5212\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u4ee5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86RLNVR\uff08Reinforcement Learning from Non-Verified Rewards\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u4f7f\u7528\u5608\u6742\u7684\u5b9e\u9645\u53cd\u9988\u4fe1\u53f7\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u800c\u65e0\u9700\u660e\u786e\u7684\u4eba\u5de5\u9a8c\u8bc1\u3002\u901a\u8fc7\u57fa\u51c6\u89c4\u8303\u5316\u548c\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u5956\u52b1\u8f6c\u79fb\uff0cRLNVR\u89e3\u51b3\u4e86\u4f20\u7edfRLHF\u5728\u8bb8\u591a\u5b9e\u9645\u9886\u57df\u4e2d\u4e0d\u5207\u5b9e\u9645\u7684\u6602\u8d35\u3001\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\u7684\u9700\u6c42\u3002\u6211\u4eec\u901a\u8fc7Walter\u5c55\u793a\u4e86RLNVR\uff0c\u8fd9\u662f\u4e00\u4e2a\u539f\u578b\u7cfb\u7edf\uff0c\u4f7f\u7528\u6765\u81eaBluesky\u7684\u5b9e\u9645\u53c2\u4e0e\u6570\u636e\u4f18\u5316\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u751f\u6210\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5185\u5bb9\u8d28\u91cf\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u672a\u6765\u8ba1\u5212\u5168\u9762\u8bc4\u4f30\u3002"}}
{"id": "2508.12260", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.12260", "abs": "https://arxiv.org/abs/2508.12260", "authors": ["Carson Dudley", "Reiden Magdaleno", "Christopher Harding", "Ananya Sharma", "Emily Martin", "Marisa Eisenberg"], "title": "Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting", "comment": "10 pages, 4 figures", "summary": "Infectious disease forecasting in novel outbreaks or low resource settings\nhas been limited by the need for disease-specific data, bespoke training, and\nexpert tuning. We introduce Mantis, a foundation model trained entirely on\nmechanistic simulations, which enables out-of-the-box forecasting across\ndiseases, regions, and outcomes, even in settings with limited historical data.\nMantis is built on over 400 million simulated days of outbreak dynamics\nspanning diverse pathogens, transmission modes, interventions, and surveillance\nartifacts. Despite requiring no real-world data during training, Mantis\noutperformed 39 expert-tuned models we tested across six diseases, including\nall models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel\nepidemiological regimes, including diseases with held-out transmission\nmechanisms, demonstrating that it captures fundamental contagion dynamics.\nCritically, Mantis is mechanistically interpretable, enabling public health\ndecision-makers to identify the latent drivers behind its predictions. Finally,\nMantis delivers accurate forecasts at 8-week horizons, more than doubling the\nactionable range of most models, enabling proactive public health planning.\nTogether, these capabilities position Mantis as a foundation for\nnext-generation disease forecasting systems: general, interpretable, and\ndeployable where traditional models fail.", "AI": {"tldr": "The paper introduces Mantis, a foundation model for disease forecasting trained on mechanistic simulations. Mantis outperformed 39 expert-tuned models, including those for COVID-19, across six diseases. It is interpretable, delivers accurate forecasts at 8-week horizons, and extends the actionable range of traditional models. Mantis is positioned as a foundation for next-generation disease forecasting systems, offering general, interpretable, and deployable capabilities where traditional models fall short.", "motivation": "Infectious disease forecasting in novel outbreaks or low resource settings has been limited by the need for disease-specific data, bespoke training, and expert tuning. The motivation behind this paper is to address these limitations by introducing Mantis, a model that enables out-of-the-box forecasting across diseases, regions, and outcomes, even in settings with limited historical data. Mantis aims to provide accurate forecasts at 8-week horizons, extending the actionable range of traditional models and enabling proactive public health planning.", "method": "The paper introduces Mantis, a foundation model trained entirely on mechanistic simulations. Mantis is built on over 400 million simulated days of outbreak dynamics across diverse pathogens, transmission modes, interventions, and surveillance artifacts. Despite requiring no real-world data during training, Mantis outperformed expert-tuned models across various diseases. It generalizes to novel epidemiological regimes and is mechanistically interpretable, allowing public health decision-makers to identify the latent drivers behind predictions.", "result": "Mantis, the foundation model introduced in this paper, has demonstrated superior performance compared to expert-tuned models across six diseases, including COVID-19. It is interpretable, delivering accurate forecasts at 8-week horizons, and generalizes to novel epidemiological regimes. Mantis's capabilities position it as a foundation for next-generation disease forecasting systems, addressing the limitations of traditional models in settings with limited historical data.", "conclusion": "Mantis is a foundation model that outperformed 39 expert-tuned models, including those in the CDC's COVID-19 Forecast Hub, across six diseases. It is mechanistically interpretable and delivers accurate forecasts at 8-week horizons, doubling the actionable range of most models. Mantis is general, interpretable, and deployable in settings with limited historical data, making it a foundation for next-generation disease forecasting systems."}}
{"id": "2508.12291", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12291", "abs": "https://arxiv.org/abs/2508.12291", "authors": ["Xuming He", "Zhiyuan You", "Junchao Gong", "Couhua Liu", "Xiaoyu Yue", "Peiqin Zhuang", "Wenlong Zhang", "Lei Bai"], "title": "RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts", "comment": null, "summary": "Quality analysis of weather forecasts is an essential topic in meteorology.\nAlthough traditional score-based evaluation metrics can quantify certain\nforecast errors, they are still far from meteorological experts in terms of\ndescriptive capability, interpretability, and understanding of dynamic\nevolution. With the rapid development of Multi-modal Large Language Models\n(MLLMs), these models become potential tools to overcome the above challenges.\nIn this work, we introduce an MLLM-based weather forecast analysis method,\nRadarQA, integrating key physical attributes with detailed assessment reports.\nWe introduce a novel and comprehensive task paradigm for multi-modal quality\nanalysis, encompassing both single frame and sequence, under both rating and\nassessment scenarios. To support training and benchmarking, we design a hybrid\nannotation pipeline that combines human expert labeling with automated\nheuristics. With such an annotation method, we construct RQA-70K, a large-scale\ndataset with varying difficulty levels for radar forecast quality evaluation.\nWe further design a multi-stage training strategy that iteratively improves\nmodel performance at each stage. Extensive experiments show that RadarQA\noutperforms existing general MLLMs across all evaluation settings, highlighting\nits potential for advancing quality analysis in weather prediction.", "AI": {"tldr": "This paper introduces RadarQA, a weather forecast analysis method based on Multi-modal Large Language Models (MLLMs). RadarQA integrates physical attributes and detailed reports, introduces a new task paradigm, creates a large-scale dataset RQA-70K, and implements a multi-stage training strategy. RadarQA outperforms existing MLLMs in weather forecast quality analysis, indicating its potential to enhance weather prediction quality.", "motivation": "Traditional score-based evaluation metrics in weather forecast analysis lack descriptive capability, interpretability, and understanding of dynamic evolution. MLLMs provide potential to overcome these challenges in meteorology. The aim is to enhance quality analysis in weather prediction by leveraging MLLMs.", "method": "Introducing MLLM-based weather forecast analysis method, RadarQA, integrating key physical attributes with detailed assessment reports. Designing a novel task paradigm for multi-modal quality analysis encompassing single frame and sequence scenarios. Developing a hybrid annotation pipeline combining human expert labeling with automated heuristics to create a large-scale dataset, RQA-70K. Implementing a multi-stage training strategy to iteratively improve model performance.", "result": "The proposed RadarQA method shows superior performance compared to existing general MLLMs in weather forecast quality evaluation, demonstrating its potential for advancing quality analysis in weather prediction.", "conclusion": "RadarQA outperforms existing general MLLMs in weather forecast quality analysis, showing potential for advancing weather prediction quality analysis."}}
{"id": "2508.12338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12338", "abs": "https://arxiv.org/abs/2508.12338", "authors": ["Wenzhen Yuan", "Shengji Tang", "Weihao Lin", "Jiacheng Ruan", "Ganqu Cui", "Bo Zhang", "Tao Chen", "Ting Liu", "Yuzhuo Fu", "Peng Ye", "Lei Bai"], "title": "Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback", "comment": null, "summary": "Reinforcement learning (RL) has significantly enhanced the reasoning\ncapabilities of large language models (LLMs), but its reliance on expensive\nhuman-labeled data or complex reward models severely limits scalability. While\nexisting self-feedback methods aim to address this problem, they are\nconstrained by the capabilities of a single model, which can lead to\noverconfidence in incorrect answers, reward hacking, and even training\ncollapse. To this end, we propose Reinforcement Learning from Coevolutionary\nCollective Feedback (RLCCF), a novel RL framework that enables multi-model\ncollaborative evolution without external supervision. Specifically, RLCCF\noptimizes the ability of a model collective by maximizing its Collective\nConsistency (CC), which jointly trains a diverse ensemble of LLMs and provides\nreward signals by voting on collective outputs. Moreover, each model's vote is\nweighted by its Self-Consistency (SC) score, ensuring that more confident\nmodels contribute more to the collective decision. Benefiting from the diverse\noutput distributions and complementary abilities of multiple LLMs, RLCCF\nenables the model collective to continuously enhance its reasoning ability\nthrough coevolution. Experiments on four mainstream open-source LLMs across\nfour mathematical reasoning benchmarks demonstrate that our framework yields\nsignificant performance gains, achieving an average relative improvement of\n16.72\\% in accuracy. Notably, RLCCF not only improves the performance of\nindividual models but also enhances the group's majority-voting accuracy by\n4.51\\%, demonstrating its ability to extend the collective capability boundary\nof the model collective.", "AI": {"tldr": "\u63d0\u51faRLCCF\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u534f\u540c\u6f14\u5316\u6765\u4f18\u5316\u80fd\u529b\u3002\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e73\u5747\u51c6\u786e\u7387\u76f8\u5bf9\u6539\u5584\u7387\u8fbe\u523016.72\\%\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u6211\u53cd\u9988\u65b9\u6cd5\u53d7\u5355\u4e00\u6a21\u578b\u80fd\u529b\u9650\u5236\uff0c\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u3001\u5956\u52b1\u6b3a\u9a97\u548c\u8bad\u7ec3\u5d29\u6e83\u3002\u63d0\u51faRLCCF\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728LLMs\u4e2d\u4f9d\u8d56\u6602\u8d35\u6570\u636e\u6216\u590d\u6742\u5956\u52b1\u6a21\u578b\u7684\u53ef\u4f38\u7f29\u6027\u95ee\u9898\u3002", "method": "RLCCF\u901a\u8fc7\u6700\u5927\u5316\u6a21\u578b\u96c6\u4f53\u7684Collective Consistency (CC)\u6765\u4f18\u5316\u6a21\u578b\u96c6\u4f53\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u591a\u6a21\u578b\u534f\u540c\u6f14\u5316\u3002\u6bcf\u4e2a\u6a21\u578b\u7684\u6295\u7968\u7531\u5176Self-Consistency (SC)\u5206\u6570\u52a0\u6743\uff0c\u786e\u4fdd\u66f4\u81ea\u4fe1\u7684\u6a21\u578b\u5bf9\u96c6\u4f53\u51b3\u7b56\u505a\u51fa\u66f4\u5927\u8d21\u732e\u3002\u901a\u8fc7\u591a\u4e2aLLM\u7684\u591a\u6837\u8f93\u51fa\u5206\u5e03\u548c\u4e92\u8865\u80fd\u529b\uff0c\u4f7f\u5f97\u6a21\u578b\u96c6\u4f53\u80fd\u591f\u4e0d\u65ad\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u56db\u4e2a\u4e3b\u6d41\u5f00\u6e90LLMs\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5728\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u6846\u67b6\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u76f8\u5bf9\u51c6\u786e\u7387\u5e73\u5747\u63d0\u9ad8\u4e8616.72\\%\u3002\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4e2a\u4f53\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u7fa4\u4f53\u7684\u591a\u6570\u6295\u7968\u51c6\u786e\u7387\uff0c\u6269\u5c55\u4e86\u6a21\u578b\u96c6\u4f53\u7684\u80fd\u529b\u8fb9\u754c\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6RLCCF\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u534f\u540c\u6f14\u5316\u6765\u4f18\u5316\u6a21\u578b\u96c6\u4f53\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002\u5e73\u5747\u51c6\u786e\u7387\u76f8\u5bf9\u6539\u5584\u7387\u8fbe\u523016.72\\%\uff0c\u5e76\u4e14\u63d0\u9ad8\u4e86\u7fa4\u4f53\u7684\u591a\u6570\u6295\u7968\u51c6\u786e\u7387\u8fbe\u52304.51\\%\u3002\u5c55\u793a\u4e86\u6269\u5c55\u6a21\u578b\u96c6\u4f53\u80fd\u529b\u8fb9\u754c\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.12375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12375", "abs": "https://arxiv.org/abs/2508.12375", "authors": ["Yu Sha", "Shuiping Gou", "Bo Liu", "Johannes Faber", "Ningtao Liu", "Stefan Schramm", "Horst Stoecker", "Thomas Steckenreiter", "Domagoj Vnucec", "Nadine Wetzstein", "Andreas Widl", "Kai Zhou"], "title": "Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems", "comment": "12 pages", "summary": "Fault intensity diagnosis (FID) plays a pivotal role in monitoring and\nmaintaining mechanical devices within complex industrial systems. As current\nFID methods are based on chain of thought without considering dependencies\namong target classes. To capture and explore dependencies, we propose a\nhierarchical knowledge guided fault intensity diagnosis framework (HKG)\ninspired by the tree of thought, which is amenable to any representation\nlearning methods. The HKG uses graph convolutional networks to map the\nhierarchical topological graph of class representations into a set of\ninterdependent global hierarchical classifiers, where each node is denoted by\nword embeddings of a class. These global hierarchical classifiers are applied\nto learned deep features extracted by representation learning, allowing the\nentire model to be end-to-end learnable. In addition, we develop a re-weighted\nhierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding\ninter-class hierarchical knowledge into a data-driven statistical correlation\nmatrix (SCM) which effectively guides the information sharing of nodes in\ngraphical convolutional neural networks and avoids over-smoothing issues. The\nRe-HKCM is derived from the SCM through a series of mathematical\ntransformations. Extensive experiments are performed on four real-world\ndatasets from different industrial domains (three cavitation datasets from\nSAMSON AG and one existing publicly) for FID, all showing superior results and\noutperform recent state-of-the-art FID methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5c42\u6b21\u77e5\u8bc6\u7684\u6545\u969c\u5f3a\u5ea6\u8bca\u65ad\u6846\u67b6\uff0c\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\u548c\u91cd\u65b0\u52a0\u6743\u7684\u5c42\u6b21\u77e5\u8bc6\u76f8\u5173\u77e9\u9635\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u53ef\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8fc7\u6700\u65b0\u6545\u969c\u5f3a\u5ea6\u8bca\u65ad\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u6545\u969c\u5f3a\u5ea6\u8bca\u65ad\u65b9\u6cd5\u57fa\u4e8e\u4e00\u8fde\u4e32\u601d\u8def\uff0c\u672a\u8003\u8651\u76ee\u6807\u7c7b\u522b\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002\u4e3a\u4e86\u6355\u6349\u548c\u63a2\u7d22\u8fd9\u4e9b\u4f9d\u8d56\u5173\u7cfb\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5c42\u6b21\u77e5\u8bc6\u7684\u6545\u969c\u5f3a\u5ea6\u8bca\u65ad\u6846\u67b6\uff0c\u7075\u611f\u6765\u6e90\u4e8e\u601d\u7ef4\u6811\u7ed3\u6784\u3002", "method": "\u5229\u7528\u56fe\u5377\u79ef\u7f51\u7edc\u5c06\u7c7b\u522b\u8868\u793a\u7684\u5c42\u6b21\u62d3\u6251\u56fe\u6620\u5c04\u4e3a\u4e00\u7ec4\u76f8\u4e92\u4f9d\u8d56\u7684\u5168\u5c40\u5c42\u6b21\u5206\u7c7b\u5668\uff0c\u5e76\u7ed3\u5408\u91cd\u65b0\u52a0\u6743\u7684\u5c42\u6b21\u77e5\u8bc6\u76f8\u5173\u77e9\u9635\u65b9\u6848\u6307\u5bfc\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u8282\u70b9\u4fe1\u606f\u5171\u4eab\uff0c\u907f\u514d\u8fc7\u5ea6\u5e73\u6ed1\u95ee\u9898\u3002\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u4ee5\u9a8c\u8bc1\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u65b0\u65b9\u6cd5\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6545\u969c\u5f3a\u5ea6\u8bca\u65ad\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5c42\u6b21\u77e5\u8bc6\u7684\u6545\u969c\u5f3a\u5ea6\u8bca\u65ad\u6846\u67b6\uff0c\u5229\u7528\u56fe\u5377\u79ef\u7f51\u7edc\u5c06\u7c7b\u522b\u8868\u793a\u7684\u5c42\u6b21\u62d3\u6251\u56fe\u6620\u5c04\u4e3a\u4e00\u7ec4\u76f8\u4e92\u4f9d\u8d56\u7684\u5168\u5c40\u5c42\u6b21\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u53ef\u5b66\u4e60\u7684\u6a21\u578b\u3002\u901a\u8fc7\u5d4c\u5165\u7c7b\u522b\u4e4b\u95f4\u7684\u5c42\u6b21\u77e5\u8bc6\u5230\u6570\u636e\u9a71\u52a8\u7684\u7edf\u8ba1\u76f8\u5173\u77e9\u9635\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u91cd\u65b0\u52a0\u6743\u7684\u5c42\u6b21\u77e5\u8bc6\u76f8\u5173\u77e9\u9635\u65b9\u6848\uff0c\u6709\u6548\u6307\u5bfc\u4e86\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u8282\u70b9\u4fe1\u606f\u5171\u4eab\uff0c\u907f\u514d\u4e86\u8fc7\u5ea6\u5e73\u6ed1\u95ee\u9898\u3002\u5728\u56db\u4e2a\u4e0d\u540c\u5de5\u4e1a\u9886\u57df\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u672c\u65b9\u6cd5\u4f18\u4e8e\u6700\u8fd1\u7684\u6700\u5148\u8fdb\u6545\u969c\u5f3a\u5ea6\u8bca\u65ad\u65b9\u6cd5\u3002"}}
{"id": "2508.12379", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12379", "abs": "https://arxiv.org/abs/2508.12379", "authors": ["Rongzheng Wang", "Qizhi Chen", "Yihong Huang", "Yizhuo Ma", "Muquan Li", "Jiakai Li", "Ke Qin", "Guangchun Luo", "Shuang Liang"], "title": "GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding", "comment": null, "summary": "Large language models (LLMs) show promising performance on small-scale graph\nreasoning tasks but fail when handling real-world graphs with complex queries.\nThis phenomenon stems from LLMs' inability to effectively process complex graph\ntopology and perform multi-step reasoning simultaneously. To address these\nlimitations, we propose GraphCogent, a collaborative agent framework inspired\nby human Working Memory Model that decomposes graph reasoning into specialized\ncognitive processes: sense, buffer, and execute. The framework consists of\nthree modules: Sensory Module standardizes diverse graph text representations\nvia subgraph sampling, Buffer Module integrates and indexes graph data across\nmultiple formats, and Execution Module combines tool calling and model\ngeneration for efficient reasoning. We also introduce Graph4real, a\ncomprehensive benchmark contains with four domains of real-world graphs (Web,\nSocial, Transportation, and Citation) to evaluate LLMs' graph reasoning\ncapabilities. Our Graph4real covers 21 different graph reasoning tasks,\ncategorized into three types (Structural Querying, Algorithmic Reasoning, and\nPredictive Modeling tasks), with graph scales that are 10 times larger than\nexisting benchmarks. Experiments show that Llama3.1-8B based GraphCogent\nachieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).\nCompared to state-of-the-art agent-based baseline, our framework outperforms by\n20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%\nfor out-toolset tasks. Code will be available after review.", "AI": {"tldr": "GraphCogent is a framework that improves large language models' graph reasoning by decomposing tasks into specialized cognitive processes. It outperforms existing benchmarks and achieves a 50% improvement over massive-scale LLMs. The framework reduces token usage significantly for different tasks.", "motivation": "Large language models struggle with real-world graphs due to their inability to effectively process complex graph topology and perform multi-step reasoning. The motivation behind this work is to address these limitations by introducing a collaborative agent framework that mimics human working memory for efficient graph reasoning.", "method": "The paper proposes GraphCogent, which decomposes graph reasoning into specialized cognitive processes: sense, buffer, and execute. It consists of three modules: Sensory Module, Buffer Module, and Execution Module, each handling different aspects of graph reasoning. Additionally, the paper introduces Graph4real, a comprehensive benchmark containing real-world graphs from four domains to evaluate LLMs' graph reasoning abilities.", "result": "Experiments demonstrate that GraphCogent based on Llama3.1-8B outperforms massive-scale LLMs like DeepSeek-R1 by 50% and state-of-the-art agent-based baseline by 20% in accuracy, with significant reductions in token usage for both in-toolset and out-toolset tasks.", "conclusion": "GraphCogent, a collaborative agent framework inspired by human Working Memory Model, improves the graph reasoning capabilities of large language models significantly. It outperforms existing benchmarks and achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B), with reduced token usage for in-toolset and out-toolset tasks."}}
{"id": "2508.12425", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.12425", "abs": "https://arxiv.org/abs/2508.12425", "authors": ["Phuong Minh Nguyen", "Tien Huu Dang", "Naoya Inoue"], "title": "Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning", "comment": null, "summary": "This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved\napproach to standard CoT, for logical reasoning in large language models\n(LLMs). The key idea is to integrate lightweight symbolic representations into\nfew-shot prompts, structuring the inference steps with a consistent strategy to\nmake reasoning patterns more explicit within a non-iterative reasoning process.\nBy incorporating these symbolic structures, our method preserves the\ngeneralizability of standard prompting techniques while enhancing the\ntransparency, interpretability, and analyzability of LLM logical reasoning.\nExtensive experiments on four well-known logical reasoning benchmarks --\nProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse\nreasoning scenarios -- demonstrate the effectiveness of the proposed approach,\nparticularly in complex reasoning tasks that require navigating multiple\nconstraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'\nreasoning capabilities across various model sizes and significantly outperforms\nconventional CoT on three out of four datasets, ProofWriter, ProntoQA, and\nLogicalDeduction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Symbolic-Aided Chain-of-Thought\uff08CoT\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u8f7b\u91cf\u7ea7\u7b26\u53f7\u8868\u793a\u5230\u5c11\u6837\u672c\u63d0\u793a\u4e2d\uff0c\u6539\u8fdb\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6807\u51c6CoT\u5b58\u5728\u7684\u95ee\u9898\u662f\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u7f3a\u4e4f\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u672c\u6587\u65e8\u5728\u6539\u8fdb\u8fd9\u4e00\u70b9\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u4e8eLLM\u903b\u8f91\u63a8\u7406\u7684\u5904\u7406\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u7ed3\u5408\u7b26\u53f7\u8868\u793a\u7684\u6539\u8fdb\u65b9\u6cd5\u6765\u589e\u5f3a\u63a8\u7406\u8fc7\u7a0b\u7684\u900f\u660e\u6027\u548c\u6548\u679c\u6027\u3002", "method": "\u5c06\u8f7b\u91cf\u7ea7\u7b26\u53f7\u8868\u793a\u6574\u5408\u5230\u5c11\u6837\u672c\u63d0\u793a\u4e2d\uff0c\u91c7\u7528\u4e00\u81f4\u7684\u7b56\u7565\u7ed3\u6784\u5316\u63a8\u7406\u6b65\u9aa4\uff0c\u4f7f\u5f97\u63a8\u7406\u6a21\u5f0f\u66f4\u52a0\u663e\u5f0f\u5316\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u589e\u5f3a\u4e86LLM\u903b\u8f91\u63a8\u7406\u7684\u900f\u660e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u5206\u6790\u6027\u3002\u5728\u591a\u4e2a\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u901a\u8fc7\u5f15\u5165\u7b26\u53f7\u7ed3\u6784\uff0cSymbolic-Aided CoT\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u3002\u5728\u56db\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u7684CoT\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7279\u522b\u7a81\u51fa\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSymbolic-Aided Chain-of-Thought\uff08CoT\uff09\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u7528\u4e8e\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u3002\u901a\u8fc7\u5c06\u8f7b\u91cf\u7ea7\u7b26\u53f7\u8868\u793a\u6574\u5408\u5230\u5c11\u6837\u672c\u63d0\u793a\u4e2d\uff0c\u7ed3\u6784\u5316\u63a8\u7406\u6b65\u9aa4\u5e76\u91c7\u7528\u4e00\u81f4\u7684\u7b56\u7565\uff0c\u4f7f\u5f97\u63a8\u7406\u6a21\u5f0f\u5728\u975e\u8fed\u4ee3\u63a8\u7406\u8fc7\u7a0b\u4e2d\u66f4\u52a0\u663e\u5f0f\u3002\u901a\u8fc7\u6574\u5408\u8fd9\u4e9b\u7b26\u53f7\u7ed3\u6784\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6807\u51c6\u63d0\u793a\u6280\u672f\u7684\u6cdb\u5316\u80fd\u529b\u7684\u540c\u65f6\uff0c\u589e\u5f3a\u4e86LLM\u903b\u8f91\u63a8\u7406\u7684\u900f\u660e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u5206\u6790\u6027\u3002\u5728\u56db\u4e2a\u8457\u540d\u7684\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0c\u5305\u62ecProofWriter\u3001FOLIO\u3001ProntoQA\u548cLogicalDeduction\uff0c\u6db5\u76d6\u4e86\u591a\u6837\u5316\u7684\u63a8\u7406\u573a\u666f\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5904\u7406\u591a\u4e2a\u7ea6\u675f\u6216\u89c4\u5219\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cSymbolic-Aided CoT \u5728\u5404\u79cd\u6a21\u578b\u5927\u5c0f\u4e0a\u6301\u7eed\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e2d\u7684\u4e09\u4e2aProofWriter\u3001ProntoQA\u548cLogicalDeduction\u4e0a\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u7684CoT\u3002"}}
{"id": "2508.12472", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12472", "abs": "https://arxiv.org/abs/2508.12472", "authors": ["Yifang Tian", "Yaming Liu", "Zichun Chong", "Zihang Huang", "Hans-Arno Jacobsen"], "title": "GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?", "comment": "12 pages, 5 figures", "summary": "Root cause analysis (RCA) in microservice systems is challenging, requiring\non-call engineers to rapidly diagnose failures across heterogeneous telemetry\nsuch as metrics, logs, and traces. Traditional RCA methods often focus on\nsingle modalities or merely rank suspect services, falling short of providing\nactionable diagnostic insights with remediation guidance. This paper introduces\nGALA, a novel multi-modal framework that combines statistical causal inference\nwith LLM-driven iterative reasoning for enhanced RCA. Evaluated on an\nopen-source benchmark, GALA achieves substantial improvements over\nstate-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM\nevaluation score shows GALA generates significantly more causally sound and\nactionable diagnostic outputs than existing methods. Through comprehensive\nexperiments and a case study, we show that GALA bridges the gap between\nautomated failure diagnosis and practical incident resolution by providing both\naccurate root cause identification and human-interpretable remediation\nguidance.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86GALA\uff0c\u4e00\u4e2a\u7ed3\u5408\u7edf\u8ba1\u56e0\u679c\u63a8\u65ad\u548cLLM\u9a71\u52a8\u7684\u8fed\u4ee3\u63a8\u7406\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u7684\u6839\u672c\u539f\u56e0\u5206\u6790\u3002GALA \u5728\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e8642.22%\u7684\u51c6\u786e\u6027\u6539\u8fdb\uff0c\u63d0\u4f9b\u66f4\u5f3a\u7684\u56e0\u679c\u5173\u7cfb\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8868\u660e\u6846\u67b6\u5728\u6545\u969c\u8bca\u65ad\u548c\u5b9e\u9645\u4e8b\u4ef6\u5904\u7406\u4e2d\u5177\u6709\u6f5c\u5728\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u7684\u6839\u672c\u539f\u56e0\u5206\u6790\u65b9\u6cd5\u901a\u5e38\u4e13\u6ce8\u4e8e\u5355\u4e00\u6a21\u5f0f\uff0c\u6216\u4ec5\u4ec5\u5bf9\u5acc\u7591\u670d\u52a1\u8fdb\u884c\u6392\u5e8f\uff0c\u65e0\u6cd5\u63d0\u4f9b\u5177\u6709\u53ef\u6267\u884c\u6307\u5bfc\u7684\u8bca\u65ad\u89c1\u89e3\u3002\u56e0\u6b64\uff0c\u672c\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u6839\u672c\u539f\u56e0\u5206\u6790\u7684\u6311\u6218\uff0c\u4e3a\u5de5\u7a0b\u5e08\u63d0\u4f9b\u66f4\u597d\u7684\u6545\u969c\u8bca\u65ad\u89c1\u89e3\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86GALA\uff0c\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u7edf\u8ba1\u56e0\u679c\u63a8\u65ad\u548cLLM\u9a71\u52a8\u7684\u8fed\u4ee3\u63a8\u7406\u8fdb\u884c\u6839\u672c\u539f\u56e0\u5206\u6790\u3002", "result": "GALA \u5728\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe42.22%\u7684\u51c6\u786e\u6027\u6539\u8fdb\uff0c\u4ee5\u53ca\u663e\u8457\u7684\u56e0\u679c\u5173\u7cfb\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6839\u672c\u539f\u56e0\u8bc6\u522b\u548c\u7ea0\u6b63\u6307\u5bfc\u65b9\u9762\u7684\u6548\u679c\u3002", "conclusion": "GALA \u901a\u8fc7\u7ed3\u5408\u7edf\u8ba1\u56e0\u679c\u63a8\u65ad\u548c\u4ee5LLM\u9a71\u52a8\u7684\u8fed\u4ee3\u63a8\u7406\uff0c\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u6839\u672c\u539f\u56e0\u5206\u6790\u65b9\u6cd5\u3002\u5728\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGALA \u8fbe\u5230\u4e86\u9ad8\u8fbe42.22%\u7684\u51c6\u786e\u6027\u6539\u8fdb\u3002\u7814\u7a76\u8868\u660e\uff0cGALA \u751f\u6210\u7684\u8bca\u65ad\u7ed3\u679c\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u5f3a\u7684\u56e0\u679c\u5173\u7cfb\u548c\u53ef\u64cd\u4f5c\u6027\u3002\u901a\u8fc7\u5168\u9762\u5b9e\u9a8c\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86GALA \u5728\u81ea\u52a8\u6545\u969c\u8bca\u65ad\u548c\u5b9e\u9645\u4e8b\u4ef6\u5904\u7406\u4e4b\u95f4\u5efa\u7acb\u4e86\u6865\u6881\uff0c\u65e2\u80fd\u591f\u51c6\u786e\u786e\u5b9a\u6839\u672c\u539f\u56e0\uff0c\u53c8\u80fd\u591f\u63d0\u4f9b\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u7ea0\u6b63\u6307\u5bfc\u3002"}}
{"id": "2508.12480", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.12480", "abs": "https://arxiv.org/abs/2508.12480", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Andreas Bulling"], "title": "The Yokai Learning Environment: Tracking Beliefs Over Space and Time", "comment": "Presented at the the ToM IJCAI 2025 Workshop", "summary": "Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to\nreason about the beliefs of others to build and maintain common ground.\nExisting ToM benchmarks, however, are restricted to passive observer settings\nor lack an assessment of how agents establish and maintain common ground over\ntime. To address these gaps, we introduce the Yokai Learning Environment (YLE)\n- a multi-agent reinforcement learning (RL) environment based on the\ncooperative card game Yokai. In the YLE, agents take turns peeking at hidden\ncards and moving them to form clusters based on colour. Success requires\ntracking evolving beliefs, remembering past observations, using hints as\ngrounded communication, and maintaining common ground with teammates. Our\nevaluation yields two key findings: First, current RL agents struggle to solve\nthe YLE, even when given access to perfect memory. Second, while belief\nmodelling improves performance, agents are still unable to effectively\ngeneralise to unseen partners or form accurate beliefs over longer games,\nexposing a reliance on brittle conventions rather than robust belief tracking.\nWe use the YLE to investigate research questions in belief modelling, memory,\npartner generalisation, and scaling to higher-order ToM.", "AI": {"tldr": "\u7814\u7a76\u805a\u7126\u4e8eYokai Learning Environment\uff08YLE\uff09\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u6311\u6218\u4e86ToM\u57fa\u51c6\uff0c\u5e76\u63ed\u793a\u4e86RL\u4ee3\u7406\u5728\u5efa\u7acb\u548c\u7ef4\u62a4\u5171\u540c\u57fa\u7840\u65b9\u9762\u7684\u56f0\u96be\u3002\u4ee3\u7406\u5728YLE\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5373\u4f7f\u5177\u6709\u5b8c\u7f8e\u8bb0\u5fc6\uff1b\u4fe1\u5ff5\u5efa\u6a21\u63d0\u9ad8\u6027\u80fd\u4f46\u4ecd\u6709\u5c40\u9650\uff0c\u65e0\u6cd5\u6709\u6548\u63a8\u5e7f\u6216\u5728\u8f83\u957f\u6e38\u620f\u4e2d\u5f62\u6210\u51c6\u786e\u4fe1\u5ff5\u3002", "motivation": "\u73b0\u6709\u7684Theory of Mind\uff08ToM\uff09\u57fa\u51c6\u53d7\u9650\u4e8e\u88ab\u52a8\u89c2\u5bdf\u8005\u8bbe\u7f6e\u6216\u7f3a\u4e4f\u5bf9\u4ee3\u7406\u5982\u4f55\u5efa\u7acb\u548c\u7ef4\u62a4\u5171\u540c\u57fa\u7840\u7684\u8bc4\u4f30\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5f15\u5165\u4e86Yokai Learning Environment\uff08YLE\uff09\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u5177\u6311\u6218\u6027\u7684\u73af\u5883\uff0c\u4ee5\u8bc4\u4f30\u4ee3\u7406\u5728\u5efa\u7acb\u548c\u7ef4\u62a4\u5171\u540c\u57fa\u7840\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u5f15\u5165\u4e86Yokai Learning Environment\uff08YLE\uff09\u4f5c\u4e3a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u73af\u5883\uff0c\u57fa\u4e8e\u5408\u4f5c\u6027\u5361\u724c\u6e38\u620fYokai\u3002\u5728YLE\u4e2d\uff0c\u4ee3\u7406\u8f6e\u6d41\u89c2\u770b\u9690\u85cf\u7684\u5361\u7247\u5e76\u79fb\u52a8\u5b83\u4eec\u4ee5\u6839\u636e\u989c\u8272\u5f62\u6210\u7fa4\u3002\u6210\u529f\u9700\u8981\u8ddf\u8e2a\u4e0d\u65ad\u53d8\u5316\u7684\u4fe1\u5ff5\uff0c\u8bb0\u4f4f\u8fc7\u53bb\u7684\u89c2\u5bdf\uff0c\u4f7f\u7528\u63d0\u793a\u4f5c\u4e3a\u57fa\u4e8e\u4f20\u5730\u901a\u4fe1\uff0c\u5e76\u4e0e\u961f\u53cb\u4fdd\u6301\u5171\u540c\u57fa\u7840\u3002", "result": "\u5728\u8bc4\u4f30\u4e2d\u53d1\u73b0\uff0c\u5f53\u524d\u7684RL\u4ee3\u7406\u5728YLE\u4e2d\u96be\u4ee5\u89e3\u51b3\u95ee\u9898\uff0c\u5373\u4f7f\u5177\u6709\u5b8c\u7f8e\u8bb0\u5fc6\u7684\u80fd\u529b\u3002\u4fe1\u5ff5\u5efa\u6a21\u53ef\u4ee5\u6539\u5584\u6027\u80fd\uff0c\u4f46\u4ee3\u7406\u4ecd\u7136\u65e0\u6cd5\u5f88\u597d\u5730\u63a8\u5e7f\u5230\u672a\u77e5\u4f19\u4f34\u6216\u5728\u8f83\u957f\u6e38\u620f\u4e2d\u5f62\u6210\u51c6\u786e\u7684\u4fe1\u5ff5\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728 Yokai Learning Environment\uff08YLE\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5373\u4f7f\u5177\u6709\u5b8c\u7f8e\u8bb0\u5fc6\u7684\u80fd\u529b\u3002\u53e6\u5916\uff0c\u5c3d\u7ba1\u4fe1\u5ff5\u5efa\u6a21\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u4ee3\u7406\u4ecd\u7136\u65e0\u6cd5\u6709\u6548\u5730\u63a8\u5e7f\u5230\u672a\u77e5\u4f19\u4f34\u6216\u5728\u8f83\u957f\u7684\u6e38\u620f\u4e2d\u5f62\u6210\u51c6\u786e\u7684\u4fe1\u5ff5\uff0c\u66b4\u9732\u51fa\u5bf9\u8106\u5f31\u60ef\u4f8b\u800c\u975e\u5f3a\u5927\u4fe1\u5ff5\u8ddf\u8e2a\u7684\u4f9d\u8d56\u3002\u7814\u7a76\u4f7f\u7528YLE\u63a2\u8ba8\u4e86\u4fe1\u5ff5\u5efa\u6a21\u3001\u8bb0\u5fc6\u3001\u4f19\u4f34\u6982\u62ec\u4ee5\u53ca\u6269\u5c55\u5230\u66f4\u9ad8\u9636ToM\u7684\u7814\u7a76\u95ee\u9898\u3002"}}
{"id": "2508.12487", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.12487", "abs": "https://arxiv.org/abs/2508.12487", "authors": ["Lida Shahbandari", "Hossein Mohseni"], "title": "Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework", "comment": null, "summary": "This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that\nuses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index\n(BIS), keeping it within the ideal range of forty to sixty. The FOFPID\ncontroller combines fuzzy logic for adapting to changes and fractional order\ndynamics for fine tuning. This allows it to adjust its control gains to handle\na person's unique physiology. The WOA helps fine tune the controller's\nparameters, including the fractional orders and the fuzzy membership functions,\nwhich boosts its performance. Tested on models of eight different patient\nprofiles, the FOFPID controller performed better than a standard Fractional\nOrder PID (FOPID) controller. It achieved faster settling times, at two and a\nhalf minutes versus three point two minutes, and had a lower steady state\nerror, at zero point five versus one point two. These outcomes show the\nFOFPID's excellent strength and accuracy. It offers a scalable, artificial\nintelligence driven solution for automated anesthesia delivery that could\nenhance clinical practice and improve patient results.", "AI": {"tldr": "Study introduces FOFPID controller using WOA to manage BIS within ideal range. Controller combines fuzzy logic and fractional order dynamics, fine-tuned by WOA. Outperforms FOPID controller on patient profiles with faster settling times and lower steady state error. Potential as AI-driven solution for automated anesthesia delivery.", "motivation": "To develop an advanced controller for managing BIS within the ideal range by incorporating fuzzy logic, fractional order dynamics, and optimization algorithms. Address the unique physiology of individuals through adjustable control gains.", "method": "Introduces a Fractional Order Fuzzy PID (FOFPID) controller that utilizes the Whale Optimization Algorithm (WOA) to manage BIS. The controller combines fuzzy logic for adaptation and fractional order dynamics for fine tuning. WOA helps in fine-tuning parameters like fractional orders and fuzzy membership functions to enhance performance.", "result": "FOFPID controller demonstrated superior performance compared to FOPID controller on eight different patient profiles, achieving faster settling times and lower steady state error. The outcomes indicate the controller's strength and accuracy in automated anesthesia delivery.", "conclusion": "FOFPID controller outperforms FOPID controller in managing Bispectral Index (BIS) within the ideal range, with faster settling times and lower steady state error. It shows excellent strength and accuracy in handling patient profiles. The study highlights its potential as an AI-driven solution for automated anesthesia delivery to improve clinical practice and patient outcomes."}}
{"id": "2508.12500", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.12500", "abs": "https://arxiv.org/abs/2508.12500", "authors": ["Rahmat K. Adesunkanmi", "Ashfaq Khokhar", "Goce Trajcevski", "Sohail Murad"], "title": "Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models", "comment": "Submitted to ACM", "summary": "Molecular dynamics simulations (MDS) face challenges, including\nresource-heavy computations and the need to manually scan outputs to detect\n\"interesting events,\" such as the formation and persistence of hydrogen bonds\nbetween atoms of different molecules. A critical research gap lies in\nidentifying the underlying causes of hydrogen bond formation and separation\n-understanding which interactions or prior events contribute to their emergence\nover time. With this challenge in mind, we propose leveraging spatio-temporal\ndata analytics and machine learning models to enhance the detection of these\nphenomena. In this paper, our approach is inspired by causal modeling and aims\nto identify the root cause variables of hydrogen bond formation and separation\nevents. Specifically, we treat the separation of hydrogen bonds as an\n\"intervention\" occurring and represent the causal structure of the bonding and\nseparation events in the MDS as graphical causal models. These causal models\nare built using a variational autoencoder-inspired architecture that enables us\nto infer causal relationships across samples with diverse underlying causal\ngraphs while leveraging shared dynamic information. We further include a step\nto infer the root causes of changes in the joint distribution of the causal\nmodels. By constructing causal models that capture shifts in the conditional\ndistributions of molecular interactions during bond formation or separation,\nthis framework provides a novel perspective on root cause analysis in molecular\ndynamic systems. We validate the efficacy of our model empirically on the\natomic trajectories that used MDS for chiral separation, demonstrating that we\ncan predict many steps in the future and also find the variables driving the\nobserved changes in the system.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u65f6\u7a7a\u6570\u636e\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u6c22\u952e\u5f62\u6210\u548c\u65ad\u88c2\u4e8b\u4ef6\u7684\u6839\u672c\u539f\u56e0\u53d8\u91cf\u3002\u6784\u5efa\u56e0\u679c\u6a21\u578b\u6765\u63a8\u65ad\u4e0d\u540c\u6f5c\u5728\u56e0\u679c\u56fe\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u5171\u4eab\u7684\u52a8\u6001\u4fe1\u606f\u3002\u901a\u8fc7\u6355\u6349\u6210\u952e\u6216\u65ad\u952e\u8fc7\u7a0b\u4e2d\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\u6761\u4ef6\u5206\u5e03\u7684\u53d8\u5316\u8fdb\u884c\u6839\u672c\u539f\u56e0\u5206\u6790\u3002\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u9762\u4e34\u7684\u6311\u6218\uff0c\u5373\u8d44\u6e90\u5bc6\u96c6\u578b\u8ba1\u7b97\u548c\u624b\u52a8\u626b\u63cf\u8f93\u51fa\u6765\u68c0\u6d4b\u201c\u6709\u8da3\u4e8b\u4ef6\u201d\u7684\u9700\u8981\uff0c\u5982\u4e0d\u540c\u5206\u5b50\u4e4b\u95f4\u6c22\u952e\u7684\u5f62\u6210\u548c\u6301\u4e45\u6027\u3002\u901a\u8fc7\u8bc6\u522b\u6c22\u952e\u5f62\u6210\u548c\u5206\u79bb\u4e8b\u4ef6\u7684\u6839\u672c\u539f\u56e0\u53d8\u91cf\uff0c\u586b\u8865\u4e86\u7814\u7a76\u4e2d\u7684\u5173\u952e\u7f3a\u53e3\uff0c\u4ece\u800c\u63d0\u4f9b\u4e86\u5bf9\u5206\u5b50\u52a8\u529b\u5b66\u7cfb\u7edf\u4e2d\u6839\u672c\u539f\u56e0\u5206\u6790\u7684\u65b0\u89c6\u89d2\u3002", "method": "\u5229\u7528\u65f6\u7a7a\u6570\u636e\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u6784\u5efa\u57fa\u4e8e\u56e0\u679c\u5efa\u6a21\u7684\u65b9\u6cd5\u3002\u5f15\u5165\u4e86\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u542f\u53d1\u7684\u67b6\u6784\uff0c\u6784\u5efa\u56e0\u679c\u6a21\u578b\u6765\u63a8\u65ad\u4e0d\u540c\u6f5c\u5728\u56e0\u679c\u56fe\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u5171\u4eab\u7684\u52a8\u6001\u4fe1\u606f\u3002\u901a\u8fc7\u6355\u6349\u6210\u952e\u6216\u65ad\u952e\u8fc7\u7a0b\u4e2d\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\u6761\u4ef6\u5206\u5e03\u7684\u53d8\u5316\uff0c\u8fdb\u884c\u6839\u672c\u539f\u56e0\u5206\u6790\u3002", "result": "\u901a\u8fc7\u6784\u5efa\u56e0\u679c\u6a21\u578b\u548c\u4f7f\u7528 MDS \u8fdb\u884c\u624b\u6027\u5206\u79bb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u672a\u6765\u6b65\u9aa4\u548c\u53d1\u73b0\u9a71\u52a8\u7cfb\u7edf\u53d8\u5316\u53d8\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u65f6\u7a7a\u6570\u636e\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u8bc6\u522b\u6c22\u952e\u5f62\u6210\u548c\u65ad\u88c2\u4e8b\u4ef6\u7684\u6839\u672c\u539f\u56e0\u53d8\u91cf\u3002\u91c7\u7528\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\u542f\u53d1\u7684\u67b6\u6784\u6784\u5efa\u56e0\u679c\u6a21\u578b\uff0c\u5141\u8bb8\u63a8\u65ad\u4e0d\u540c\u6f5c\u5728\u56e0\u679c\u56fe\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u540c\u65f6\u5229\u7528\u5171\u4eab\u7684\u52a8\u6001\u4fe1\u606f\u3002\u901a\u8fc7\u6784\u5efa\u6355\u6349\u6210\u952e\u6216\u65ad\u952e\u8fc7\u7a0b\u4e2d\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\u6761\u4ef6\u5206\u5e03\u53d8\u5316\u7684\u56e0\u679c\u6a21\u578b\uff0c\u4e3a\u5206\u5b50\u52a8\u529b\u5b66\u7cfb\u7edf\u4e2d\u7684\u6839\u672c\u539f\u56e0\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002\u5728\u4f7f\u7528 MDS \u8fdb\u884c\u624b\u6027\u5206\u79bb\u7684\u539f\u5b50\u8f68\u8ff9\u4e0a\uff0c\u7ecf\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u6211\u4eec\u53ef\u4ee5\u9884\u6d4b\u672a\u6765\u7684\u591a\u4e2a\u6b65\u9aa4\uff0c\u5e76\u627e\u5230\u9a71\u52a8\u7cfb\u7edf\u53d8\u5316\u7684\u53d8\u91cf\u3002"}}
{"id": "2508.12566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12566", "abs": "https://arxiv.org/abs/2508.12566", "authors": ["Wei Song", "Haonan Zhong", "Ziqi Ding", "Jingling Xue", "Yuekang Li"], "title": "Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models", "comment": null, "summary": "The Model Context Protocol (MCP) enables large language models (LLMs) to\naccess external resources on demand. While commonly assumed to enhance\nperformance, how LLMs actually leverage this capability remains poorly\nunderstood. We introduce MCPGAUGE, the first comprehensive evaluation framework\nfor probing LLM-MCP interactions along four key dimensions: proactivity\n(self-initiated tool use), compliance (adherence to tool-use instructions),\neffectiveness (task performance post-integration), and overhead (computational\ncost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning\nknowledge comprehension, general reasoning, and code generation. Our\nlarge-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and\nboth one- and two-turn interaction settings, comprises around 20,000 API calls\nand over USD 6,000 in computational cost. This comprehensive study reveals four\nkey findings that challenge prevailing assumptions about the effectiveness of\nMCP integration. These insights highlight critical limitations in current\nAI-tool integration and position MCPGAUGE as a principled benchmark for\nadvancing controllable, tool-augmented LLMs.", "AI": {"tldr": "MCPGAUGE is introduced as a comprehensive evaluation framework for probing LLM-MCP interactions, challenging assumptions about MCP integration effectiveness. The study spans six commercial LLMs, 30 MCP tool suites, and provides insights into current AI-tool integration limitations.", "motivation": "While the Model Context Protocol (MCP) enables large language models (LLMs) to access external resources, the actual leverage of this capability by LLMs remains poorly understood. The goal is to understand how LLMs interact with MCP and the impact on task performance, computational cost, and adherence to tool-use instructions.", "method": "Introducing MCPGAUGE, a comprehensive evaluation framework, comprised of a 160-prompt suite and 25 datasets, for probing LLM-MCP interactions along four key dimensions: proactivity, compliance, effectiveness, and overhead. The evaluation spanned six commercial LLMs, 30 MCP tool suites, and one- and two-turn interaction settings.", "result": "The study comprises around 20,000 API calls, over USD 6,000 in computational cost, and reveals critical limitations in current AI-tool integration, providing a principled benchmark for advancing controllable, tool-augmented LLMs.", "conclusion": "MCPGAUGE is introduced as the first comprehensive evaluation framework for probing LLM-MCP interactions, revealing key findings that challenge prevailing assumptions about the effectiveness of MCP integration and highlight limitations in current AI-tool integration."}}
{"id": "2508.12611", "categories": ["cs.AI", "cs.CL", "I.2.7; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.12611", "abs": "https://arxiv.org/abs/2508.12611", "authors": ["Trang Tran", "Trung Hoang Le", "Huiping Cao", "Tran Cao Son"], "title": "An LLM + ASP Workflow for Joint Entity-Relation Extraction", "comment": "13 pages, 1 figure, Accepted as Technical Communication, 41st\n  International Conference on Logic Programming", "summary": "Joint entity-relation extraction (JERE) identifies both entities and their\nrelationships simultaneously. Traditional machine-learning based approaches to\nperforming this task require a large corpus of annotated data and lack the\nability to easily incorporate domain specific information in the construction\nof the model. Therefore, creating a model for JERE is often labor intensive,\ntime consuming, and elaboration intolerant. In this paper, we propose\nharnessing the capabilities of generative pretrained large language models\n(LLMs) and the knowledge representation and reasoning capabilities of Answer\nSet Programming (ASP) to perform JERE. We present a generic workflow for JERE\nusing LLMs and ASP. The workflow is generic in the sense that it can be applied\nfor JERE in any domain. It takes advantage of LLM's capability in natural\nlanguage understanding in that it works directly with unannotated text. It\nexploits the elaboration tolerant feature of ASP in that no modification of its\ncore program is required when additional domain specific knowledge, in the form\nof type specifications, is found and needs to be used. We demonstrate the\nusefulness of the proposed workflow through experiments with limited training\ndata on three well-known benchmarks for JERE. The results of our experiments\nshow that the LLM + ASP workflow is better than state-of-the-art JERE systems\nin several categories with only 10\\% of training data. It is able to achieve a\n2.5 times (35\\% over 15\\%) improvement in the Relation Extraction task for the\nSciERC corpus, one of the most difficult benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u751f\u6210\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548cAnswer Set Programming\uff08ASP\uff09\u6267\u884c\u8054\u5408\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\uff08JERE\uff09\u7684\u901a\u7528\u5de5\u4f5c\u6d41\u7a0b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u5de5\u4f5c\u6d41\u5728\u51e0\u4e2a\u7c7b\u522b\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684JERE\u7cfb\u7edf\uff0c\u5728SciERC\u8bed\u6599\u5e93\u4e2d\u7684\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684JERE\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u5e76\u4e14\u7f3a\u4e4f\u8f7b\u677e\u878d\u5165\u9886\u57df\u7279\u5b9a\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u521b\u5efaJERE\u6a21\u578b\u901a\u5e38\u9700\u8981\u8017\u8d39\u5927\u91cf\u4eba\u529b\u3001\u65f6\u95f4\uff0c\u5e76\u4e14\u4e0d\u5177\u5907\u5bb9\u5fcd\u8be6\u7ec6\u7684\u7279\u6027\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u5229\u7528LLMs\u548cASP\u7684\u80fd\u529b\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528LLMs\u548cASP\u6267\u884cJERE\u7684\u901a\u7528\u5de5\u4f5c\u6d41\u7a0b\u3002\u8be5\u5de5\u4f5c\u6d41\u7a0b\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u9886\u57df\u7684JERE\uff0c\u5145\u5206\u5229\u7528\u4e86LLM\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\u4ee5\u53caASP\u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u65f6\u7684\u5bb9\u5fcd\u7279\u6027\u3002\u5728\u4e09\u4e2a\u77e5\u540d\u7684JERE\u57fa\u51c6\u6d4b\u8bd5\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u5de5\u4f5c\u6d41\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0cLLM + ASP\u5de5\u4f5c\u6d41\u76f8\u6bd4\u4e8e\u6700\u5148\u8fdb\u7684JERE\u7cfb\u7edf\u5728\u51e0\u4e2a\u7c7b\u522b\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4ec5\u5229\u752810\uff05\u7684\u8bad\u7ec3\u6570\u636e\u5c31\u80fd\u5b9e\u73b0\u663e\u8457\u6539\u8fdb\uff0c\u5c24\u5176\u5728SciERC\u8bed\u6599\u5e93\u4e2d\u7684\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e862.5\u500d\u7684\u6539\u8fdb\u3002", "conclusion": "\u5728\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5229\u7528\u751f\u6210\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548cAnswer Set Programming\uff08ASP\uff09\u7684\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u80fd\u529b\u6765\u8fdb\u884c\u8054\u5408\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\uff08JERE\uff09\u3002\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0cLLM + ASP\u5de5\u4f5c\u6d41\u5728\u51e0\u4e2a\u7c7b\u522b\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684JERE\u7cfb\u7edf\uff0c\u4ec5\u5229\u752810\uff05\u7684\u8bad\u7ec3\u6570\u636e\u5c31\u80fd\u5b9e\u73b0\u663e\u8457\u6539\u8fdb\uff0c\u5bf9\u4e8eSciERC\u8bed\u6599\u5e93\u4e2d\u7684\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u8fbe\u5230\u4e862.5\u500d\uff0835\uff05\u63d0\u9ad8\u81f315\uff05\uff09\u7684\u6539\u8fdb\u3002"}}
{"id": "2508.12647", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.12647", "abs": "https://arxiv.org/abs/2508.12647", "authors": ["Hengnian Gu", "Zhifu Chen", "Yuxin Chen", "Jin Peng Zhou", "Dongdai Zhou"], "title": "Cognitive Structure Generation: From Educational Priors to Policy Optimization", "comment": null, "summary": "Cognitive structure is a student's subjective organization of an objective\nknowledge system, reflected in the psychological construction of concepts and\ntheir relations. However, cognitive structure assessment remains a\nlong-standing challenge in student modeling and psychometrics, persisting as a\nfoundational yet largely unassessable concept in educational practice. This\npaper introduces a novel framework, Cognitive Structure Generation (CSG), in\nwhich we first pretrain a Cognitive Structure Diffusion Probabilistic Model\n(CSDPM) to generate students' cognitive structures from educational priors, and\nthen further optimize its generative process as a policy with hierarchical\nreward signals via reinforcement learning to align with genuine cognitive\ndevelopment levels during students' learning processes. Experimental results on\nfour popular real-world education datasets show that cognitive structures\ngenerated by CSG offer more comprehensive and effective representations for\nstudent modeling, substantially improving performance on KT and CD tasks while\nenhancing interpretability.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u79f0\u4e3a\u8ba4\u77e5\u7ed3\u6784\u751f\u6210\uff08CSG\uff09\uff0c\u7528\u4e8e\u751f\u6210\u5b66\u751f\u7684\u8ba4\u77e5\u7ed3\u6784\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cCSG\u751f\u6210\u7684\u8ba4\u77e5\u7ed3\u6784\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5168\u9762\u6709\u6548\uff0c\u53ef\u4ee5\u6539\u5584\u5b66\u751f\u5efa\u6a21\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u9ad8KT\u548cCD\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u8ba4\u77e5\u7ed3\u6784\u8bc4\u4f30\u4ecd\u7136\u662f\u5b66\u751f\u5efa\u6a21\u548c\u5fc3\u7406\u6d4b\u91cf\u5b66\u4e2d\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\uff0c\u8fd9\u662f\u6559\u80b2\u5b9e\u8df5\u4e2d\u4e00\u4e2a\u57fa\u7840\u4f46\u5927\u90e8\u5206\u65e0\u6cd5\u8bc4\u4f30\u7684\u6982\u5ff5\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u5f15\u5165\u4e86\u8ba4\u77e5\u7ed3\u6784\u751f\u6210\uff08CSG\uff09\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u9884\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u7b26\u5408\u5b66\u751f\u771f\u5b9e\u8ba4\u77e5\u53d1\u5c55\u6c34\u5e73\u7684\u8ba4\u77e5\u7ed3\u6784\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u8ba4\u77e5\u7ed3\u6784\u751f\u6210\uff08CSG\uff09\u6846\u67b6\uff0c\u9996\u5148\u5bf9\u8ba4\u77e5\u7ed3\u6784\u6269\u6563\u6982\u7387\u6a21\u578b\uff08CSDPM\uff09\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u4f18\u5316\u751f\u6210\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u4f7f\u7528\u56db\u4e2a\u771f\u5b9e\u6559\u80b2\u6570\u636e\u96c6\uff0c\u8bc1\u660eCSG\u751f\u6210\u7684\u8ba4\u77e5\u7ed3\u6784\u5bf9\u4e8e\u5b66\u751f\u5efa\u6a21\u66f4\u4e3a\u5168\u9762\u6709\u6548\uff0c\u5e76\u5728KT\u548cCD\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u5584\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCSG\u751f\u6210\u7684\u8ba4\u77e5\u7ed3\u6784\u5728\u5b66\u751f\u5efa\u6a21\u4e2d\u8868\u73b0\u51fa\u66f4\u4e3a\u5168\u9762\u6709\u6548\u7684\u8868\u793a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86KT\u548cCD\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5e76\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u8ba4\u77e5\u7ed3\u6784\u751f\u6210\uff08CSG\uff09\uff0c\u901a\u8fc7\u9996\u5148\u5bf9\u8ba4\u77e5\u7ed3\u6784\u6269\u6563\u6982\u7387\u6a21\u578b\uff08CSDPM\uff09\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5c06\u5176\u751f\u6210\u8fc7\u7a0b\u4f18\u5316\u4e3a\u4e00\u79cd\u7b56\u7565\uff0c\u4ee5\u5206\u5c42\u5956\u52b1\u4fe1\u53f7\u4e0e\u5b66\u751f\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u771f\u5b9e\u8ba4\u77e5\u53d1\u5c55\u6c34\u5e73\u5bf9\u9f50\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCSG\u751f\u6210\u7684\u8ba4\u77e5\u7ed3\u6784\u4e3a\u5b66\u751f\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u6709\u6548\u7684\u8868\u793a\uff0c\u663e\u7740\u6539\u5584\u4e86KT\u548cCD\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.12651", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.12651", "abs": "https://arxiv.org/abs/2508.12651", "authors": ["Chunliang Hua", "Xiao Hu", "Jiayang Sun", "Zeyuan Yang"], "title": "The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning", "comment": "10 pages", "summary": "As urban aerial mobility (UAM) infrastructure development accelerates\nglobally, cities like Shenzhen are planning large-scale vertiport networks\n(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain\ninadequate for this complexity due to historical limitations in data\ngranularity and real-world applicability. This paper addresses these gaps by\nfirst proposing the Capacitated Dynamic Maximum Covering Location Problem\n(CDMCLP), a novel optimization framework that simultaneously models urban-scale\nspatial-temporal demand, heterogeneous user behaviors, and infrastructure\ncapacity constraints. Building on this foundation, we introduce an Integrated\nPlanning Recommendation System that combines CDMCLP with socio-economic factors\nand dynamic clustering initialization. This system leverages adaptive parameter\ntuning based on empirical user behavior to generate practical planning\nsolutions. Validation in a Chinese center city demonstrates the effectiveness\nof the new optimization framework and recommendation system. Under the\nevaluation and optimization of CDMCLP, the quantitative performance of\ntraditional location methods are exposed and can be improved by 38\\%--52\\%,\nwhile the recommendation system shows user-friendliness and the effective\nintegration of complex elements. By integrating mathematical rigor with\npractical implementation considerations, this hybrid approach bridges the gap\nbetween theoretical location modeling and real-world UAM infrastructure\nplanning, offering municipalities a pragmatic tool for vertiport network\ndesign.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5bb9\u91cf\u52a8\u6001\u6700\u5927\u8986\u76d6\u4f4d\u7f6e\u95ee\u9898\uff08CDMCLP\uff09\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u96c6\u6210\u89c4\u5212\u63a8\u8350\u7cfb\u7edf\uff0c\u63d0\u9ad8\u4e86\u4f20\u7edf\u4f4d\u7f6e\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u5c55\u793a\u4e86\u7528\u6237\u53cb\u597d\u6027\u548c\u590d\u6742\u56e0\u7d20\u7684\u6709\u6548\u6574\u5408\u3002\u8be5\u7814\u7a76\u4e3a\u57ce\u5e02\u7a7a\u4e2d\u79fb\u52a8\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u89c4\u5212\u6846\u67b6\u5728\u6570\u636e\u7c92\u5ea6\u548c\u73b0\u5b9e\u9002\u7528\u6027\u65b9\u9762\u5b58\u5728\u5386\u53f2\u9650\u5236\uff0c\u8fd9\u7bc7\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e9b\u7a7a\u767d\uff0c\u4ee5\u66f4\u597d\u5730\u5e94\u5bf9\u57ce\u5e02\u7a7a\u4e2d\u79fb\u52a8\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u7684\u590d\u6742\u6027\u3002", "method": "\u8be5\u8bba\u6587\u9996\u5148\u63d0\u51fa\u4e86\u5bb9\u91cf\u52a8\u6001\u6700\u5927\u8986\u76d6\u4f4d\u7f6e\u95ee\u9898\uff08CDMCLP\uff09\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7136\u540e\u5f15\u5165\u4e86\u96c6\u6210\u89c4\u5212\u63a8\u8350\u7cfb\u7edf\uff0c\u7ed3\u5408\u793e\u4f1a\u7ecf\u6d4e\u56e0\u7d20\u548c\u52a8\u6001\u805a\u7c7b\u521d\u59cb\u5316\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u6839\u636e\u5b9e\u8bc1\u7528\u6237\u884c\u4e3a\u8fdb\u884c\u81ea\u9002\u5e94\u53c2\u6570\u8c03\u6574\uff0c\u751f\u6210\u5b9e\u9645\u89c4\u5212\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8bba\u6587\u9a8c\u8bc1\u4e86\u65b0\u4f18\u5316\u6846\u67b6\u548c\u63a8\u8350\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u4e86\u5176\u5728\u57ce\u5e02\u4e2d\u5fc3\u57ce\u5e02\u7684\u8868\u73b0\u3002CDMCLP\u7684\u8bc4\u4f30\u548c\u4f18\u5316\u63ed\u793a\u4e86\u4f20\u7edf\u4f4d\u7f6e\u65b9\u6cd5\u7684\u5b9a\u91cf\u6027\u80fd\u53ef\u4ee5\u63d0\u9ad838%-52%\uff0c\u800c\u63a8\u8350\u7cfb\u7edf\u5c55\u793a\u4e86\u7528\u6237\u53cb\u597d\u6027\u548c\u590d\u6742\u56e0\u7d20\u7684\u6709\u6548\u6574\u5408\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u57ce\u5e02\u89c4\u6a21\u7684\u65f6\u7a7a\u9700\u6c42\u3001\u5f02\u8d28\u7528\u6237\u884c\u4e3a\u548c\u57fa\u7840\u8bbe\u65bd\u5bb9\u91cf\u7ea6\u675f\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u96c6\u6210\u89c4\u5212\u63a8\u8350\u7cfb\u7edf\uff0c\u7ed3\u5408\u793e\u4f1a\u7ecf\u6d4e\u56e0\u7d20\u548c\u52a8\u6001\u805a\u7c7b\u521d\u59cb\u5316\uff0c\u6709\u6548\u5730\u6539\u8fdb\u4e86\u4f20\u7edf\u4f4d\u7f6e\u65b9\u6cd5\u7684\u5b9a\u91cf\u8868\u73b0\uff0c\u5c55\u793a\u4e86\u7528\u6237\u53cb\u597d\u6027\u548c\u590d\u6742\u56e0\u7d20\u7684\u6709\u6548\u6574\u5408\u3002\u8be5\u7814\u7a76\u4e3a\u57ce\u5e02\u7a7a\u4e2d\u79fb\u52a8\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2508.12682", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12682", "abs": "https://arxiv.org/abs/2508.12682", "authors": ["Jinquan Shi", "Yingying Cheng", "Fan Zhang", "Miao Jiang", "Jun Lin", "Yanbai Shen"], "title": "GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance", "comment": null, "summary": "The global shift towards renewable energy presents unprecedented challenges\nfor the electricity industry, making regulatory reasoning and compliance\nincreasingly vital. Grid codes, the regulations governing grid operations, are\ncomplex and often lack automated interpretation solutions, which hinders\nindustry expansion and undermines profitability for electricity companies. We\nintroduce GridCodex, an end to end framework for grid code reasoning and\ncompliance that leverages large language models and retrieval-augmented\ngeneration (RAG). Our framework advances conventional RAG workflows through\nmulti stage query refinement and enhanced retrieval with RAPTOR. We validate\nthe effectiveness of GridCodex with comprehensive benchmarks, including\nautomated answer assessment across multiple dimensions and regulatory agencies.\nExperimental results showcase a 26.4% improvement in answer quality and more\nthan a 10 fold increase in recall rate. An ablation study further examines the\nimpact of base model selection.", "AI": {"tldr": "GridCodex is a framework designed to improve grid code reasoning and compliance using large language models and RAG. It enhances conventional workflows, leading to better answer quality and recall rate. Experimental results show significant improvements, and an ablation study examines the impact of base model selection.", "motivation": "The global shift towards renewable energy demands increased regulatory reasoning and compliance in the electricity industry. Current grid codes are complex and lack automated interpretation solutions, hindering industry expansion and profitability for electricity companies.", "method": "GridCodex utilizes multi-stage query refinement and enhanced retrieval with RAPTOR to advance conventional RAG workflows. The effectiveness of GridCodex is validated through comprehensive benchmarks and automated answer assessment across multiple dimensions and regulatory agencies.", "result": "Experimental results demonstrate a 26.4% improvement in answer quality and over a 10-fold increase in recall rate. An ablation study is conducted to evaluate the impact of base model selection in GridCodex.", "conclusion": "GridCodex is an end-to-end framework that leverages large language models and retrieval-augmented generation (RAG) to enhance grid code reasoning and compliance, showing significant improvements in answer quality and recall rate."}}
{"id": "2508.12687", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.12687", "abs": "https://arxiv.org/abs/2508.12687", "authors": ["Ashish Seth", "Utkarsh Tyagi", "Ramaneswaran Selvakumar", "Nishit Anand", "Sonal Kumar", "Sreyan Ghosh", "Ramani Duraiswami", "Chirag Agarwal", "Dinesh Manocha"], "title": "EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nperformance in complex multimodal tasks. While MLLMs excel at visual perception\nand reasoning in third-person and egocentric videos, they are prone to\nhallucinations, generating coherent yet inaccurate responses. We present\nEgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric\nvideos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated\nopen and closed-ended questions designed to trigger hallucinations in both\nvisual and auditory cues in egocentric videos. Evaluations across ten MLLMs\nreveal significant challenges, including powerful models like GPT-4o and\nGemini, achieving only 59% accuracy. EgoIllusion lays the foundation in\ndeveloping robust benchmarks to evaluate the effectiveness of MLLMs and spurs\nthe development of better egocentric MLLMs with reduced hallucination rates.\nOur benchmark will be open-sourced for reproducibility.", "AI": {"tldr": "EgoIllusion introduces a benchmark to assess hallucinations in egocentric videos by MLLMs. Current models, including powerful ones like GPT-4o and Gemini, struggle with only 59% accuracy. This benchmark aims to improve egocentric MLLMs' performance and reduce hallucination rates, providing an open-source benchmark for reproducibility.", "motivation": "The motivation behind this paper is to address the issue of hallucinations in responses generated by Multimodal Large Language Models (MLLMs) when processing egocentric videos. By creating a benchmark specifically designed to trigger hallucinations in visual and auditory cues, the paper aims to push for the development of more effective egocentric MLLMs with reduced hallucination rates.", "method": "The paper introduces EgoIllusion, a benchmark consisting of 1,400 videos with human-annotated questions to trigger hallucinations in egocentric videos. It evaluates the performance of ten MLLMs, including models like GPT-4o and Gemini, in generating accurate responses. The evaluation highlights the challenges faced by current MLLMs in handling egocentric videos.", "result": "The evaluation of ten MLLMs using the EgoIllusion benchmark reveals the significant challenges in current models, with top models achieving only 59% accuracy. This highlights the need for improved egocentric MLLMs with reduced hallucination rates. The benchmark will be open-sourced to ensure reproducibility and further research in this area.", "conclusion": "EgoIllusion introduces a benchmark to evaluate hallucinations in egocentric videos generated by Multimodal Large Language Models (MLLMs). The evaluation shows significant challenges in current MLLMs, with even powerful models achieving only 59% accuracy. This benchmark aims to drive the development of better egocentric MLLMs with reduced hallucination rates and will be open-sourced for reproducibility."}}
{"id": "2508.12725", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12725", "abs": "https://arxiv.org/abs/2508.12725", "authors": ["Wenjie Chen", "Wenbin Li", "Di Yao", "Xuying Meng", "Chang Gong", "Jingping Bi"], "title": "GTool: Graph Enhanced Tool Planning with Large Language Model", "comment": "16 pages, 9 figures", "summary": "Tool planning with large language models (LLMs), referring to selecting,\norganizing, and preparing the tools necessary to complete a user request,\nbridges the gap between natural language understanding and task execution.\nHowever, current works treat different tools as isolated components and fail to\nleverage the inherent dependencies of tools, leading to invalid planning\nresults. Since tool dependencies are often incomplete, it becomes challenging\nfor LLMs to accurately identify the appropriate tools required by a user\nrequest, especially when confronted with a large toolset. To solve this\nchallenge, we propose \\texttt{GTool}, which is the first work aiming to enhance\nthe tool planning ability of LLMs under incomplete dependencies. \\texttt{GTool}\nconstructs a request-specific tool graph to select tools efficiently and\ngenerate the \\texttt{<graph token>} which provides sufficient dependency\ninformation understandable by LLMs. Moreover, a missing dependency prediction\ntask is designed to improve the reliability of \\texttt{GTool} with incomplete\ndependencies. Without trimming LLMs, \\texttt{GTool} can be seamlessly\nintegrated with various LLM backbones without extensive retraining. Extensive\nexperiments show that \\texttt{GTool} achieves more than 29.6\\% performance\nimprovements compared with the state-of-the-art (SOTA) baselines with a\nlight-weight (7B) LLM backbone.", "AI": {"tldr": "GTool enhances large language models' tool planning ability by constructing request-specific tool graphs and includes a missing dependency prediction task. It outperforms existing methods by over 29.6% in performance improvement with a light-weight LLM backbone.", "motivation": "Current works lack leveraging the dependencies of tools in tool planning, resulting in invalid planning results. Identifying the appropriate tools for user requests with incomplete dependencies is challenging. GTool aims to address this challenge by improving LLMs' tool planning ability under incomplete dependencies.", "method": "The proposed GTool constructs a request-specific tool graph to efficiently select tools and generate a <graph token> providing dependency information. It also includes a missing dependency prediction task to enhance reliability. GTool can be integrated with various LLM backbones without extensive retraining.", "result": "Extensive experiments demonstrate that GTool achieves significant performance improvements over state-of-the-art baselines, showcasing its effectiveness in enhancing tool planning with LLMs.", "conclusion": "GTool enhances the tool planning ability of large language models (LLMs) under incomplete dependencies, outperforming state-of-the-art baselines by more than 29.6% with a light-weight 7B LLM backbone."}}
{"id": "2508.12754", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12754", "abs": "https://arxiv.org/abs/2508.12754", "authors": ["Alessio Galatolo", "Luca Alberto Rappuoli", "Katie Winkle", "Meriem Beloucif"], "title": "Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants", "comment": "Full version of the paper published in ECAI 2025 proceedings (IOS\n  Press, CC BY-NC 4.0)", "summary": "The recent rise in popularity of large language models (LLMs) has prompted\nconsiderable concerns about their moral capabilities. Although considerable\neffort has been dedicated to aligning LLMs with human moral values, existing\nbenchmarks and evaluations remain largely superficial, typically measuring\nalignment based on final ethical verdicts rather than explicit moral reasoning.\nIn response, this paper aims to advance the investigation of LLMs' moral\ncapabilities by examining their capacity to function as Artificial Moral\nAssistants (AMAs), systems envisioned in the philosophical literature to\nsupport human moral deliberation. We assert that qualifying as an AMA requires\nmore than what state-of-the-art alignment techniques aim to achieve: not only\nmust AMAs be able to discern ethically problematic situations, they should also\nbe able to actively reason about them, navigating between conflicting values\noutside of those embedded in the alignment phase. Building on existing\nphilosophical literature, we begin by designing a new formal framework of the\nspecific kind of behaviour an AMA should exhibit, individuating key qualities\nsuch as deductive and abductive moral reasoning. Drawing on this theoretical\nframework, we develop a benchmark to test these qualities and evaluate popular\nopen LLMs against it. Our results reveal considerable variability across models\nand highlight persistent shortcomings, particularly regarding abductive moral\nreasoning. Our work connects theoretical philosophy with practical AI\nevaluation while also emphasising the need for dedicated strategies to\nexplicitly enhance moral reasoning capabilities in LLMs. Code available at\nhttps://github.com/alessioGalatolo/AMAeval", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u4eba\u5de5\u9053\u5fb7\u52a9\u624b\uff08AMAs\uff09\u7684\u9053\u5fb7\u80fd\u529b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u6765\u68c0\u9a8cAMAs\u5e94\u8be5\u5177\u5907\u7684\u884c\u4e3a\u7279\u8d28\uff0c\u53d1\u73b0\u73b0\u6709\u5f00\u653eLLMs\u5728\u9053\u5fb7\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u5dee\u5f02\u548c\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u589e\u5f3aLLMs\u9053\u5fb7\u63a8\u7406\u80fd\u529b\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u7684\u57fa\u51c6\u548c\u8bc4\u4f30\u4e3b\u8981\u57fa\u4e8e\u6700\u7ec8\u7684\u9053\u5fb7\u5224\u51b3\u800c\u4e0d\u662f\u660e\u786e\u7684\u9053\u5fb7\u63a8\u7406\uff0c\u56e0\u6b64\u8fd9\u7bc7\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\u3002\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u6df1\u5165\u63a2\u8ba8LLMs\u4f5c\u4e3aAMAs\u7684\u80fd\u529b\uff0c\u4ee5\u652f\u6301\u4eba\u7c7b\u9053\u5fb7\u601d\u8003\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u65b0\u7684\u6b63\u5f0f\u6846\u67b6\u6765\u68c0\u6d4b\u4eba\u5de5\u9053\u5fb7\u52a9\u624b\uff08AMA\uff09\u5e94\u8be5\u8868\u73b0\u51fa\u7684\u884c\u4e3a\u7279\u8d28\uff0c\u5305\u62ec\u6f14\u7ece\u548c\u5f52\u7eb3\u9053\u5fb7\u63a8\u7406\u3002\u57fa\u4e8e\u8fd9\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u6d41\u884c\u7684\u5f00\u653e\u5f0fLLMs\u7684\u9053\u5fb7\u63a8\u7406\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u5f52\u7eb3\u9053\u5fb7\u63a8\u7406\u65b9\u9762\u4ecd\u5b58\u5728\u6301\u7eed\u7684\u4e0d\u8db3\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u65e8\u5728\u63a8\u8fdb\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9053\u5fb7\u80fd\u529b\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u8003\u5bdf\u5b83\u4eec\u4f5c\u4e3a\u4eba\u5de5\u9053\u5fb7\u52a9\u624b\uff08AMAs\uff09\u7684\u6f5c\u529b\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u6709\u7684\u5f00\u653e\u5f0fLLMs\u5728\u9053\u5fb7\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5dee\u5f02\uff0c\u5c24\u5176\u662f\u5728\u5f52\u7eb3\u9053\u5fb7\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\u4ecd\u7136\u6709\u6301\u7eed\u7684\u4e0d\u8db3\u3002\u8bba\u6587\u5f3a\u8c03\u4e86\u5c06\u7406\u8bba\u54f2\u5b66\u4e0e\u5b9e\u9645\u4eba\u5de5\u667a\u80fd\u8bc4\u4f30\u76f8\u7ed3\u5408\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u91c7\u53d6\u4e13\u95e8\u7b56\u7565\u660e\u786e\u589e\u5f3aLLMs\u7684\u9053\u5fb7\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2508.12782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12782", "abs": "https://arxiv.org/abs/2508.12782", "authors": ["Petr Anokhin", "Roman Khalikov", "Stefan Rebrikov", "Viktor Volkov", "Artyom Sorokin", "Vincent Bissonnette"], "title": "HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds", "comment": "Code is available at https://github.com/stefanrer/HeroBench", "summary": "Large language models (LLMs) have shown remarkable capabilities in isolated\nstep-by-step reasoning tasks such as mathematics and programming, but their\nproficiency in long-horizon planning, where solutions require extended,\nstructured sequences of interdependent actions, remains underexplored. Existing\nbenchmarks typically assess LLMs through abstract or low-dimensional\nalgorithmic tasks, failing to capture the complexity of realistic planning\nenvironments. We introduce HeroBench, a novel benchmark designed specifically\nto evaluate long-horizon planning and structured reasoning within complex\nRPG-inspired virtual worlds. HeroBench provides a rigorously constructed\ndataset of tasks covering a wide range of difficulties, a simulated environment\nto execute and validate agent plans, and detailed analytical tools for\nevaluating model performance. Tasks challenge models to formulate strategic\nplans, efficiently gather resources, master necessary skills, craft equipment,\nand defeat adversaries, reflecting practical scenarios' layered dependencies\nand constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning\nboth open-source and proprietary models, including the GPT-5 family, reveals\nsubstantial performance disparities rarely observed in conventional reasoning\nbenchmarks. Detailed error analysis further uncovers specific weaknesses in\ncurrent models' abilities to generate robust high-level plans and reliably\nexecute structured actions. HeroBench thus not only significantly advances the\nevaluation of LLM reasoning but also provides a flexible, scalable foundation\nfor future research into advanced, autonomous planning in virtual environments.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e86HeroBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u89c4\u5212\u548c\u7ed3\u6784\u5316\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002\u8bc4\u4f30\u4e8625\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u4e00\u57fa\u51c6\u6d4b\u8bd5\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u53d1\u73b0\u4e86\u5b83\u4eec\u5728\u9ad8\u5c42\u8ba1\u5212\u751f\u6210\u548c\u7ed3\u6784\u5316\u52a8\u4f5c\u6267\u884c\u65b9\u9762\u7684\u7279\u5b9a\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u89c4\u5212\u73af\u5883\u7684\u590d\u6742\u6027\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86HeroBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u89e3\u51b3\u957f\u671f\u89c4\u5212\u548c\u7ed3\u6784\u5316\u63a8\u7406\u7684\u8bc4\u4f30\u95ee\u9898\u3002", "method": "\u521b\u5efa\u4e86HeroBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u4efb\u52a1\u6570\u636e\u96c6\u3001\u6a21\u62df\u73af\u5883\u548c\u5206\u6790\u5de5\u5177\uff0c\u8bc4\u4f30\u4e8625\u79cd\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u4e86\u5728\u957f\u671f\u89c4\u5212\u548c\u7ed3\u6784\u5316\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u5e76\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u9519\u8bef\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u7279\u5b9a\u5f31\u70b9\u3002", "result": "\u8bc4\u4f30\u4e8625\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5728HeroBench\u57fa\u51c6\u6d4b\u8bd5\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u53d1\u73b0\u4e86\u5f53\u524d\u6a21\u578b\u5728\u751f\u6210\u9ad8\u5c42\u8ba1\u5212\u548c\u6267\u884c\u7ed3\u6784\u5316\u52a8\u4f5c\u65b9\u9762\u7684\u7279\u5b9a\u5f31\u70b9\u3002", "conclusion": "HeroBench\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u89c4\u5212\u548c\u7ed3\u6784\u5316\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u751f\u6210\u5f3a\u5927\u7684\u9ad8\u5c42\u8ba1\u5212\u548c\u53ef\u9760\u6267\u884c\u7ed3\u6784\u5316\u52a8\u4f5c\u65b9\u9762\u7684\u7279\u5b9a\u5f31\u70b9\u3002HeroBench\u7684\u5f15\u5165\u4e0d\u4ec5\u663e\u8457\u63a8\u52a8\u4e86\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u8fd8\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u7528\u4e8e\u63a2\u7d22\u865a\u62df\u73af\u5883\u4e2d\u5148\u8fdb\u81ea\u4e3b\u89c4\u5212\u7684\u7814\u7a76\u3002"}}
{"id": "2508.12790", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.12790", "abs": "https://arxiv.org/abs/2508.12790", "authors": ["Zenan Huang", "Yihong Zhuang", "Guoshan Lu", "Zeyu Qin", "Haokai Xu", "Tianyu Zhao", "Ru Peng", "Jiaqi Hu", "Zhanming Shen", "Xiaomeng Hu", "Xijun Gu", "Peiyi Tu", "Jiaxin Liu", "Wenyu Chen", "Yuzhuo Fu", "Zhiting Fan", "Yanmei Gu", "Yuanyuan Wang", "Zhengkai Yang", "Jianguo Li", "Junbo Zhao"], "title": "Reinforcement Learning with Rubric Anchors", "comment": "technical report", "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing Large Language Models (LLMs), exemplified by\nthe success of OpenAI's o-series. In RLVR, rewards are derived from verifiable\nsignals-such as passing unit tests in code generation or matching correct\nanswers in mathematical reasoning. While effective, this requirement largely\nconfines RLVR to domains with automatically checkable outcomes. To overcome\nthis, we extend the RLVR paradigm to open-ended tasks by integrating\nrubric-based rewards, where carefully designed rubrics serve as structured,\nmodel-interpretable criteria for automatic scoring of subjective outputs. We\nconstruct, to our knowledge, the largest rubric reward system to date, with\nover 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.\nImplementing rubric-based RL is challenging; we tackle these issues with a\nclear framework and present an open-sourced Qwen-30B-A3B model with notable\ngains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended\nbenchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by\n+2.4%, while preserving general and reasoning abilities. 2) Our method provides\nfine-grained stylistic control, using rubrics as anchors to mitigate the\n\"AI-like\" tone and produce more human-like, expressive responses. We share key\nlessons in rubric construction, data selection, and training, and discuss\nlimitations and future releases.", "AI": {"tldr": "\u672c\u8bba\u6587\u6269\u5c55\u4e86RLVR\u8303\u5f0f\u5230\u5f00\u653e\u5f0f\u4efb\u52a1\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u7cfb\u7edf\uff0c\u63d0\u51faQwen-30B-A3B\u6a21\u578b\uff0c\u5728\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u7740\u6539\u8fdb\u3002\u7814\u7a76\u56f4\u7ed5\u8bc4\u5206\u6807\u51c6\u6784\u5efa\u3001\u6570\u636e\u9009\u62e9\u548c\u8bad\u7ec3\u5c55\u5f00\uff0c\u5206\u4eab\u4e86\u5173\u952e\u7ecf\u9a8c\u6559\u8bad\u548c\u672a\u6765\u8ba1\u5212\u3002", "motivation": "\u7531\u4e8eRLVR\u8303\u5f0f\u5728\u5177\u6709\u53ef\u81ea\u52a8\u68c0\u67e5\u7ed3\u679c\u7684\u9886\u57df\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6269\u5c55\u8be5\u8303\u5f0f\u4ee5\u9002\u7528\u4e8e\u5f00\u653e\u5f0f\u4efb\u52a1\u3002\u901a\u8fc7\u6574\u5408\u8bc4\u5206\u6807\u51c6\u5956\u52b1\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u98ce\u683c\u63a7\u5236\uff0c\u5e76\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u6574\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\uff0c\u5c06RLVR\u8303\u5f0f\u6269\u5c55\u5230\u5f00\u653e\u5f0f\u4efb\u52a1\u3002\u5efa\u7acb\u4e86\u8bc4\u5206\u6807\u51c6\u5956\u52b1\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u4e86Qwen-30B-A3B\u6a21\u578b\u3002", "result": "\u5efa\u7acb\u4e86\u5927\u89c4\u6a21\u8bc4\u5206\u6807\u51c6\u5956\u52b1\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86Qwen-30B-A3B\u6a21\u578b\uff0c\u5728\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u7740\u6539\u8fdb\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u901a\u7528\u548c\u63a8\u7406\u80fd\u529b\u3002\u5206\u4eab\u4e86\u8bc4\u5206\u6807\u51c6\u6784\u5efa\u3001\u6570\u636e\u9009\u62e9\u3001\u57f9\u8bad\u7ecf\u9a8c\uff0c\u5e76\u8ba8\u8bba\u4e86\u9650\u5236\u548c\u672a\u6765\u53d1\u5e03\u8ba1\u5212\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06RLVR\u8303\u5f0f\u6269\u5c55\u5230\u5f00\u653e\u5f0f\u4efb\u52a1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u6765\u514b\u670dRLVR\u5728\u5177\u6709\u53ef\u81ea\u52a8\u68c0\u67e5\u7ed3\u679c\u7684\u9886\u57df\u4e2d\u7684\u5c40\u9650\u6027\u3002\u4ed6\u4eec\u5efa\u7acb\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u8bc4\u5206\u6807\u51c6\u5956\u52b1\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86Qwen-30B-A3B\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u663e\u7740\u6539\u8fdb\u3002\u4ed6\u4eec\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u7684\u98ce\u683c\u63a7\u5236\uff0c\u5e76\u5206\u4eab\u4e86\u8bc4\u5206\u6807\u51c6\u6784\u5efa\u3001\u6570\u636e\u9009\u62e9\u548c\u57f9\u8bad\u65b9\u9762\u7684\u5173\u952e\u7ecf\u9a8c\u6559\u8bad\u3002"}}
{"id": "2508.12791", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2508.12791", "abs": "https://arxiv.org/abs/2508.12791", "authors": ["Imran Khan"], "title": "[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise", "comment": "20 pages, 5 figures. Accepted at ALIFE 2025 (Kyoto, Japan; October\n  6th - 10th 2025)", "summary": "The notion of homeostasis typically conceptualises biological and artificial\nsystems as maintaining stability by resisting deviations caused by\nenvironmental and social perturbations. In contrast, (social) allostasis\nproposes that these systems can proactively leverage these very perturbations\nto reconfigure their regulatory parameters in anticipation of environmental\ndemands, aligning with von Foerster's ``order through noise'' principle. This\npaper formulates a computational model of allostatic and social allostatic\nregulation that employs biophysiologically inspired signal transducers,\nanalogous to hormones like cortisol and oxytocin, to encode information from\nboth the environment and social interactions, which mediate this dynamic\nreconfiguration. The models are tested in a small society of ``animats'' across\nseveral dynamic environments, using an agent-based model. The results show that\nallostatic and social allostatic regulation enable agents to leverage\nenvironmental and social ``noise'' for adaptive reconfiguration, leading to\nimproved viability compared to purely reactive homeostatic agents. This work\noffers a novel computational perspective on the principles of social allostasis\nand their potential for designing more robust, bio-inspired, adaptive systems", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8ba1\u7b97\u6a21\u578b\u7814\u7a76\u4e86\u793e\u4f1a\u5f02\u6001\u8c03\u8282\u7684\u539f\u5219\uff0c\u6307\u51fa\u5f02\u6001\u548c\u793e\u4f1a\u5f02\u6001\u8c03\u8282\u6709\u52a9\u4e8e\u4ee3\u7406\u5229\u7528\u73af\u5883\u548c\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u4fe1\u606f\u8fdb\u884c\u81ea\u9002\u5e94\u91cd\u6784\uff0c\u63d0\u9ad8\u751f\u5b58\u80fd\u529b\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u7a33\u6001\u8c03\u8282\u65b9\u5f0f\uff0c\u52a8\u6001\u8c03\u8282\u65b9\u5f0f\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u73af\u5883\u53d8\u5316\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u751f\u5b58\u4f18\u52bf\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5f02\u6001\u4e0e\u793e\u4f1a\u5f02\u6001\u8c03\u8282\u5bf9\u81ea\u9002\u5e94\u7cfb\u7edf\u8bbe\u8ba1\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u4ee5\u53ca\u76f8\u8f83\u4e8e\u7a33\u6001\u8c03\u8282\u65b9\u5f0f\uff0c\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u91cd\u6784\u6765\u63d0\u9ad8\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u751f\u5b58\u80fd\u529b\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86\u8ba1\u7b97\u6a21\u578b\uff0c\u4f7f\u7528\u751f\u7269\u751f\u7406\u5b66\u542f\u53d1\u7684\u4fe1\u53f7\u8f6c\u5bfc\u5668\u6765\u7f16\u7801\u73af\u5883\u548c\u793e\u4f1a\u4e92\u52a8\u7684\u4fe1\u606f\uff0c\u6d4b\u8bd5\u4e86\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u4ee3\u7406\u6a21\u578b\u8bc4\u4f30\u4e86\u4e0d\u540c\u8c03\u8282\u65b9\u5f0f\u5bf9\u4ee3\u7406\u751f\u5b58\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u4ee3\u7406\u6a21\u578b\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f02\u6001\u548c\u793e\u4f1a\u5f02\u6001\u8c03\u8282\u76f8\u8f83\u4e8e\u5355\u7eaf\u53cd\u5e94\u5f0f\u7684\u7a33\u6001\u8c03\u8282\u65b9\u5f0f\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5229\u7528\u73af\u5883\u548c\u793e\u4f1a\u4fe1\u606f\u5b9e\u73b0\u81ea\u9002\u5e94\u91cd\u6784\uff0c\u5e76\u63d0\u9ad8\u4ee3\u7406\u7684\u751f\u5b58\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u793e\u4f1a\u5f02\u6001\u8c03\u8282\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u8ba1\u7b97\u6a21\u578b\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u751f\u7269\u751f\u7406\u5b66\u542f\u53d1\u7684\u4fe1\u53f7\u8f6c\u5bfc\u5668\u6765\u5b9e\u73b0\u52a8\u6001\u91cd\u6784\uff0c\u7ed3\u679c\u663e\u793a\u5f02\u6001\u548c\u793e\u4f1a\u5f02\u6001\u8c03\u8282\u4f7f\u4ee3\u7406\u80fd\u591f\u5229\u7528\u73af\u5883\u548c\u793e\u4f1a\u201c\u566a\u97f3\u201d\u8fdb\u884c\u81ea\u9002\u5e94\u91cd\u6784\uff0c\u4ece\u800c\u63d0\u9ad8\u751f\u5b58\u80fd\u529b\u3002"}}
{"id": "2508.12840", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.12840", "abs": "https://arxiv.org/abs/2508.12840", "authors": ["Giovanni Briglia", "Francesco Fabiano", "Stefano Mariani"], "title": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics", "comment": null, "summary": "Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for\nreasoning about both the physical world and the beliefs of agents, with\napplications in domains where information flow and awareness among agents are\ncritical. The richness of MEP requires states to be represented as Kripke\nstructures, i.e., directed labeled graphs. This representation limits the\napplicability of existing heuristics, hindering the scalability of epistemic\nsolvers, which must explore an exponential search space without guidance,\nresulting often in intractability. To address this, we exploit Graph Neural\nNetworks (GNNs) to learn patterns and relational structures within epistemic\nstates, to guide the planning process. GNNs, which naturally capture the\ngraph-like nature of Kripke models, allow us to derive meaningful estimates of\nstate quality -- e.g., the distance from the nearest goal -- by generalizing\nknowledge obtained from previously solved planning instances. We integrate\nthese predictive heuristics into an epistemic planning pipeline and evaluate\nthem against standard baselines, showing significant improvements in the\nscalability of multi-agent epistemic planning.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u667a\u80fd\u4f53\u8ba4\u77e5\u89c4\u5212\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u9ad8\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u9650\u5236\u89c4\u5212\u5668\u53ef\u6269\u5c55\u6027\u7684\u95ee\u9898\u3002", "motivation": "MEP\u662f\u4e00\u4e2a\u81ea\u4e3b\u89c4\u5212\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u4fe1\u606f\u6d41\u4e0e\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u610f\u8bc6\u5728\u5173\u952e\u9886\u57df\u4e2d\u3002\u7136\u800c\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u7684\u5c40\u9650\u6027\u9650\u5236\u4e86\u89c4\u5212\u5668\u7684\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u5728\u6307\u5bfc\u4e0b\u63a2\u7d22\u6307\u6570\u641c\u7d22\u7a7a\u95f4\uff0c\u5bfc\u81f4\u901a\u5e38\u7684\u68d8\u624b\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u627e\u5230\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e00\u60c5\u51b5\u3002", "method": "\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8ba4\u77e5\u72b6\u6001\u5185\u7684\u6a21\u5f0f\u548c\u5173\u7cfb\u7ed3\u6784\uff0c\u4ee5\u6307\u5bfc\u89c4\u5212\u8fc7\u7a0b\uff0c\u5c06\u9884\u6d4b\u542f\u53d1\u5f0f\u96c6\u6210\u5230\u8ba4\u77e5\u89c4\u5212\u6d41\u7a0b\u4e2d\uff0c\u5e76\u4e0e\u6807\u51c6\u57fa\u7ebf\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528GNN\u5b66\u4e60Kripke\u6a21\u578b\u4e2d\u7684\u56fe\u5f62\u7279\u6027\uff0c\u80fd\u591f\u5728\u591a\u667a\u80fd\u4f53\u8ba4\u77e5\u89c4\u5212\u4e2d\u53d6\u5f97\u663e\u8457\u7684\u53ef\u6269\u5c55\u6027\u6539\u8fdb\u3002", "conclusion": "\u5728\u591a\u667a\u80fd\u4f53\u8ba4\u77e5\u89c4\u5212\u4e2d\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.12845", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.12845", "abs": "https://arxiv.org/abs/2508.12845", "authors": ["Artem Pshenitsyn", "Aleksandr Panov", "Alexey Skrynnik"], "title": "CAMAR: Continuous Actions Multi-Agent Routing", "comment": null, "summary": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving\ncooperative and competitive decision-making problems. While many MARL\nbenchmarks have been proposed, few combine continuous state and action spaces\nwith challenging coordination and planning tasks. We introduce CAMAR, a new\nMARL benchmark designed explicitly for multi-agent pathfinding in environments\nwith continuous actions. CAMAR supports cooperative and competitive\ninteractions between agents and runs efficiently at up to 100,000 environment\nsteps per second. We also propose a three-tier evaluation protocol to better\ntrack algorithmic progress and enable deeper analysis of performance. In\naddition, CAMAR allows the integration of classical planning methods such as\nRRT and RRT* into MARL pipelines. We use them as standalone baselines and\ncombine RRT* with popular MARL algorithms to create hybrid approaches. We\nprovide a suite of test scenarios and benchmarking tools to ensure\nreproducibility and fair comparison. Experiments show that CAMAR presents a\nchallenging and realistic testbed for the MARL community.", "AI": {"tldr": "CAMAR is a new MARL benchmark designed for multi-agent pathfinding with continuous actions, supporting cooperative and competitive interactions efficiently. It introduces a three-tier evaluation protocol, integrates classical planning methods like RRT and RRT* into MARL pipelines, and provides test scenarios for reproducibility. CAMAR serves as a challenging and realistic testbed for the MARL community.", "motivation": "The motivation behind this paper is to address the lack of MARL benchmarks combining continuous state and action spaces with challenging coordination and planning tasks. By introducing CAMAR, the authors aim to provide a new benchmark that supports cooperative and competitive interactions efficiently and allows the integration of classical planning methods into MARL pipelines.", "method": "Introducing CAMAR, a MARL benchmark designed for multi-agent pathfinding in environments with continuous actions. Implementing a three-tier evaluation protocol for better algorithmic progress tracking. Integrating classical planning methods such as RRT and RRT* into MARL pipelines to create hybrid approaches. Providing test scenarios and benchmarking tools for reproducibility and fair comparison.", "result": "CAMAR proves to be a challenging and realistic testbed for the MARL community, supporting up to 100,000 environment steps per second. The experiments validate the effectiveness of CAMAR as a benchmark for multi-agent pathfinding, fostering algorithmic progress tracking and the development of hybrid approaches.", "conclusion": "CAMAR is a new MARL benchmark designed for multi-agent pathfinding in environments with continuous actions. It supports cooperative and competitive interactions between agents efficiently. The three-tier evaluation protocol enhances algorithmic progress tracking. Integration of classical planning methods like RRT and RRT* into MARL pipelines is possible, leading to the creation of hybrid approaches. CAMAR provides challenging and realistic test scenarios for the MARL community."}}
{"id": "2508.12854", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.12854", "abs": "https://arxiv.org/abs/2508.12854", "authors": ["Ronghao Lin", "Shuai Shen", "Weipeng Hu", "Qiaolin He", "Aolin Xiong", "Li Huang", "Haifeng Hu", "Yap-peng Tan"], "title": "E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model", "comment": "Accepted at ACM MM 2025 Grand Challenge", "summary": "Multimodal Empathetic Response Generation (MERG) is crucial for building\nemotionally intelligent human-computer interactions. Although large language\nmodels (LLMs) have improved text-based ERG, challenges remain in handling\nmultimodal emotional content and maintaining identity consistency. Thus, we\npropose E3RG, an Explicit Emotion-driven Empathetic Response Generation System\nbased on multimodal LLMs which decomposes MERG task into three parts:\nmultimodal empathy understanding, empathy memory retrieval, and multimodal\nresponse generation. By integrating advanced expressive speech and video\ngenerative models, E3RG delivers natural, emotionally rich, and\nidentity-consistent responses without extra training. Experiments validate the\nsuperiority of our system on both zero-shot and few-shot settings, securing\nTop-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.\nOur code is available at https://github.com/RH-Lin/E3RG.", "AI": {"tldr": "E3RG\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001LLMs\u7684\u660e\u786e\u60c5\u611f\u9a71\u52a8\u5171\u60c5\u56de\u5e94\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u5148\u8fdb\u7684\u8868\u8fbe\u6027\u8bed\u97f3\u548c\u89c6\u9891\u751f\u6210\u6a21\u578b\uff0c\u5b9e\u73b0\u81ea\u7136\u3001\u60c5\u611f\u4e30\u5bcc\u548c\u4e00\u81f4\u6027\u7684\u56de\u5e94\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u7cfb\u7edf\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u6548\u679c\u663e\u8457\uff0c\u5e76\u5728ACM MM 25\u7684\u6311\u6218\u4e2d\u83b7\u5f97\u4e86\u6700\u4f73\u8868\u73b0\u3002", "motivation": "\u6784\u5efa\u60c5\u611f\u667a\u80fd\u7684\u4eba\u673a\u4ea4\u4e92\u5bf9\u4e8e\u591a\u6a21\u6001\u5171\u60c5\u56de\u5e94\u751f\u6210\u81f3\u5173\u91cd\u8981\uff0c\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u6539\u5584\u4e86\u57fa\u4e8e\u6587\u672c\u7684\u5171\u60c5\u56de\u5e94\u751f\u6210\uff0c\u4f46\u5728\u5904\u7406\u591a\u6a21\u6001\u60c5\u611f\u5185\u5bb9\u548c\u4fdd\u6301\u8eab\u4efd\u4e00\u81f4\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86E3RG\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "E3RG\u6574\u5408\u4e86\u5148\u8fdb\u7684\u8868\u8fbe\u6027\u8bed\u97f3\u548c\u89c6\u9891\u751f\u6210\u6a21\u578b\uff0c\u63d0\u4f9b\u81ea\u7136\u3001\u60c5\u611f\u4e30\u5bcc\u4e14\u4fdd\u6301\u4e00\u81f4\u6027\u7684\u56de\u5e94\uff0c\u800c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86E3RG\u7cfb\u7edf\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u5353\u8d8a\u8868\u73b0\uff0c\u5e76\u5728ACM MM 25\u7684\u57fa\u4e8e\u5934\u50cf\u7684\u591a\u6a21\u6001\u5171\u60c5\u6311\u6218\u4e2d\u53d6\u5f97\u4e86Top-1\u4f4d\u7f6e\u3002", "conclusion": "E3RG\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001LLMs\u7684\u660e\u786e\u60c5\u611f\u9a71\u52a8\u5171\u60c5\u56de\u5e94\u751f\u6210\u7cfb\u7edf\uff0c\u5c06MERG\u4efb\u52a1\u5206\u89e3\u4e3a\u591a\u6a21\u6001\u5171\u60c5\u7406\u89e3\u3001\u5171\u60c5\u8bb0\u5fc6\u68c0\u7d22\u548c\u591a\u6a21\u6001\u56de\u5e94\u751f\u6210\u4e09\u4e2a\u90e8\u5206\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6211\u4eec\u7cfb\u7edf\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u4f18\u8d8a\u6027\uff0c\u5e76\u5728ACM MM 25\u7684\u57fa\u4e8e\u5934\u50cf\u7684\u591a\u6a21\u6001\u5171\u60c5\u6311\u6218\u4e2d\u83b7\u5f97\u4e86Top-1\u7684\u4f4d\u7f6e\u3002"}}
{"id": "2508.12896", "categories": ["cs.AI", "cs.HC", "stat.ME", "62M10, 62J02, 62F12, 62P20, 91B16"], "pdf": "https://arxiv.org/pdf/2508.12896", "abs": "https://arxiv.org/abs/2508.12896", "authors": ["Faruk Alpay", "Taylan Alpay"], "title": "Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption", "comment": "17 pages, 7 figures, 4 tables", "summary": "We formalize three design axioms for sustained adoption of agent-centric AI\nsystems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >\nDestination; (A3) Agency > Chat. We model adoption as a sum of a decaying\nnovelty term and a growing utility term and derive the phase conditions for\ntroughs/overshoots with full proofs. We introduce: (i) an\nidentifiability/confounding analysis for $(\\alpha,\\beta,N_0,U_{\\max})$ with\ndelta-method gradients; (ii) a non-monotone comparator\n(logistic-with-transient-bump) evaluated on the same series to provide\nadditional model comparison; (iii) ablations over hazard families $h(\\cdot)$\nmapping $\\Delta V \\to \\beta$; (iv) a multi-series benchmark (varying trough\ndepth, noise, AR structure) reporting coverage (type-I error, power); (v)\ncalibration of friction proxies against time-motion/survey ground truth with\nstandard errors; (vi) residual analyses (autocorrelation and\nheteroskedasticity) for each fitted curve; (vii) preregistered windowing\nchoices for pre/post estimation; (viii) Fisher information & CRLB for\n$(\\alpha,\\beta)$ under common error models; (ix) microfoundations linking\n$\\mathcal{T}$ to $(N_0,U_{\\max})$; (x) explicit comparison to bi-logistic,\ndouble-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$\nheterogeneity. Figures and tables are reflowed for readability, and the\nbibliography restores and extends non-logistic/Bass adoption references\n(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All\ncode and logs necessary to reproduce the synthetic analyses are embedded as\nLaTeX listings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u9879\u8bbe\u8ba1\u539f\u5219\u7528\u4e8e\u63d0\u9ad8\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u91c7\u7528\uff0c\u5e76\u901a\u8fc7\u5efa\u6a21\u91c7\u7eb3\u3001\u5206\u6790\u548c\u6a21\u578b\u6bd4\u8f83\u4e3a\u5176\u63d0\u4f9b\u652f\u6301\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u8bbe\u8ba1\u539f\u5219\u548c\u65b9\u6cd5\u80fd\u591f\u4f18\u5316\u7cfb\u7edf\u91c7\u7528\u8fc7\u7a0b\uff0c\u63d0\u4f9b\u4e86\u5bf9\u591a\u4e2a\u6a21\u578b\u7684\u6bd4\u8f83\u548c\u654f\u611f\u6027\u5206\u6790\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5f62\u5f0f\u5316\u8bbe\u8ba1\u539f\u5219\uff0c\u4ee5\u63d0\u9ad8\u6267\u884c\u591a\u6b65\u4efb\u52a1\u7684\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u91c7\u7528\u3002\u901a\u8fc7\u5efa\u6a21\u91c7\u7eb3\uff0c\u5e76\u8fdb\u884c\u76f8\u5173\u5206\u6790\u548c\u6a21\u578b\u6bd4\u8f83\uff0c\u4e3aAI\u7cfb\u7edf\u7684\u6301\u7eed\u91c7\u7528\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u65b9\u6cd5\u652f\u6301\u3002", "method": "\u8be5\u8bba\u6587\u4f7f\u7528\u4e86\u5bf9 $(\text{alpha},\text{beta},N_0,U_{\text{max}})$ \u8fdb\u884c\u53ef\u8bc6\u522b\u6027/\u6df7\u6dc6\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528 delta-method \u68af\u5ea6\u8bc4\u4f30\u975e\u5355\u8c03\u6bd4\u8f83\u5668\uff0c\u8fdb\u884c\u4e86\u5173\u4e8e\u5371\u9669\u5bb6\u65cf\u7684\u6d88\u878d\uff0c\u62a5\u544a\u4e86\u591a\u7cfb\u5217\u57fa\u51c6\u7684\u7ed3\u679c\uff0c\u6821\u51c6\u4e86\u6469\u64e6\u4ee3\u7406\uff0c\u5e76\u8fdb\u884c\u4e86\u6b8b\u5dee\u5206\u6790\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86 Fisher \u4fe1\u606f\u91cf\u548c CRLB \u7684\u63a8\u5bfc\uff0c\u5c06 $\text{mathcal{T}$ \u4e0e $(N_0,U_{\text{max}})$ \u8fdb\u884c\u4e86\u5fae\u57fa\u7840\u8054\u7cfb\uff0c\u5e76\u4e0e\u5176\u4ed6\u6a21\u578b\u8fdb\u884c\u4e86\u660e\u786e\u6bd4\u8f83\u3002", "result": "\u6839\u636e\u8be5\u8bba\u6587\u7684\u7ed3\u679c\uff0c\u901a\u8fc7\u63d0\u51fa\u7684\u8bbe\u8ba1\u539f\u5219\u548c\u76f8\u5e94\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4f18\u5316\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u91c7\u7528\u8fc7\u7a0b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u4e0d\u540c\u6a21\u578b\u7684\u6bd4\u8f83\u548c\u654f\u611f\u6027\u5206\u6790\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u9879\u8bbe\u8ba1\u539f\u5219\uff0c\u7528\u4e8e\u6301\u7eed\u91c7\u7528\u6267\u884c\u591a\u6b65\u4efb\u52a1\u7684\u4ee5\u4ee3\u7406\u4e3a\u4e2d\u5fc3\u7684AI\u7cfb\u7edf\uff1a\uff08A1\uff09\u53ef\u9760\u6027\u5927\u4e8e\u65b0\u9896\u6027\uff1b\uff08A2\uff09\u5d4c\u5165\u5927\u4e8e\u76ee\u7684\u5730\uff1b\uff08A3\uff09\u4ee3\u7406\u5927\u4e8e\u804a\u5929\u3002\u901a\u8fc7\u5c06\u91c7\u7eb3\u6a21\u578b\u5316\u4e3a\u9010\u6e10\u9012\u51cf\u7684\u65b0\u9896\u6027\u9879\u548c\u9010\u6e10\u589e\u957f\u7684\u6548\u7528\u9879\u4e4b\u548c\uff0c\u5e76\u63a8\u5bfc\u51fa\u5b8c\u6574\u8bc1\u660e\u7684\u8d2f\u7a7f/\u8d85\u8c03\u76f8\u6761\u4ef6\u3002\u5f15\u5165\u4e86\uff1a\uff08i\uff09\u4e00\u4e2a\u53ef\u8bc6\u522b\u6027/\u6df7\u6dc6\u5206\u6790\uff0c\u4f7f\u7528$(\text{alpha},\text{beta},N_0,U_{\text{max}})$\u548c delta-method \u68af\u5ea6\uff1b\uff08ii\uff09\u5728\u76f8\u540c\u7cfb\u5217\u4e0a\u8bc4\u4f30\u7684\u975e\u5355\u8c03\u6bd4\u8f83\u5668\uff08\u5177\u6709\u6682\u65f6\u9686\u8d77\u7684 Logistic \u6a21\u578b\uff09\u4ee5\u63d0\u4f9b\u989d\u5916\u7684\u6a21\u578b\u6bd4\u8f83\uff1b\uff08iii\uff09\u5173\u4e8e\u5c06 $\beta$ \u6620\u5c04\u5230 $\bigtriangleup V \to \beta$ \u7684\u5371\u9669\u5bb6\u65cf $h(\text{cdot})$ \u7684\u6d88\u878d\uff1b\uff08iv\uff09\u62a5\u544a\u8986\u76d6\u7387\uff08\u7c7b\u578b-I\u9519\u8bef\u3001\u529f\u6548\uff09\u7684\u591a\u7cfb\u5217\u57fa\u51c6\uff08\u53d8\u5316\u7684\u4f4e\u8c37\u6df1\u5ea6\u3001\u566a\u58f0\u3001AR \u7ed3\u6784\uff09\uff1b\uff08v\uff09\u6821\u51c6\u6469\u64e6\u4ee3\u7406\u4e0e\u65f6\u95f4-\u8fd0\u52a8/\u8c03\u67e5\u5b9e\u51b5\u7684\u6807\u51c6\u8bef\u5dee\uff1b\uff08vi\uff09\u6bcf\u4e2a\u62df\u5408\u66f2\u7ebf\u7684\u6b8b\u5dee\u5206\u6790\uff08\u81ea\u76f8\u5173\u6027\u548c\u5f02\u65b9\u5dee\u6027\uff09\uff1b\uff08vii\uff09\u9884\u6ce8\u518c\u7684\u524d/\u540e\u4f30\u8ba1\u7a97\u53e3\u9009\u62e9\uff1b\uff08viii\uff09\u5e38\u89c1\u9519\u8bef\u6a21\u578b\u4e0b\u7684 $(\text{alpha},\text{beta})$ \u7684 Fisher \u4fe1\u606f\u91cf\u548c CRLB\uff1b\uff08ix\uff09\u5c06 $\text{mathcal{T}$ \u4e0e $(N_0,U_{\text{max}})$ \u8fdb\u884c\u5fae\u57fa\u7840\u8054\u7cfb\uff1b\uff08x\uff09\u4e0e\u53cc Log \u6a21\u578b\u3001\u53cc\u6307\u6570\u6a21\u578b\u548c\u6df7\u5408\u6a21\u578b\u8fdb\u884c\u660e\u786e\u6bd4\u8f83\uff1b\u4ee5\u53ca\uff08xi\uff09\u5bf9 $C_f$ \u7684\u5f02\u8d28\u6027\u654f\u611f\u6027\u9608\u503c\u3002\u56fe\u8868\u5df2\u91cd\u65b0\u6392\u7248\u4ee5\u63d0\u9ad8\u53ef\u8bfb\u6027\uff0c\u5e76\u6062\u590d\u548c\u6269\u5c55\u4e86\u975e Logistic/Bass \u91c7\u7528\u53c2\u8003\u6587\u732e\uff08Gompertz\u3001Richards\u3001Fisher-Pry\u3001Mansfield\u3001Griliches\u3001Geroski\u3001Peres\uff09\u3002\u6240\u6709\u5fc5\u8981\u7684\u4ee3\u7801\u548c\u65e5\u5fd7\u4ee5 LaTeX \u5217\u8868\u7684\u5f62\u5f0f\u5d4c\u5165\uff0c\u4ee5\u91cd\u73b0\u5408\u6210\u5206\u6790\u3002"}}
{"id": "2508.12897", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.12897", "abs": "https://arxiv.org/abs/2508.12897", "authors": ["Jianhao Chen", "Mayi Xu", "Xiaohu Li", "Yongqi Li", "Xiangyu Zhang", "Jianjie Huang", "Tieyun Qian"], "title": "FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance", "comment": "14pages, 3 figures", "summary": "Large Reasoning Models (LRMs) have demonstrated impressive performance across\nvarious tasks due to their powerful reasoning capabilities. However, their\nsafety performance remains a significant concern. In this paper, we explore the\nreasons behind the vulnerability of LRMs. Based on this, we propose a novel\nmethod to improve the safety of LLMs without sacrificing their reasoning\ncapability. Specifically, we exploit the competition between LRM's reasoning\nability and safety ability, and achieve jailbreak by improving LRM's reasoning\nperformance to reduce its safety performance. We then introduce an alignment\nstrategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by\ndetoxifying the harmful reasoning process, where both the dangerous entities\nand the dangerous procedures in the reasoning steps are hidden. FuSaR\nsuccessfully mitigates safety risks while preserving core reasoning\ninformation. We validate this strategy through alignment experiments on several\nopen-source LRMs using detoxified reasoning data. The results compared with\nexisting baselines conclusively show that FuSaR is an efficient alignment\nstrategy to simultaneously enhance both the reasoning capability and safety of\nLRMs.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFuSaR\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861LRM\u7684\u5b89\u5168\u6027\u548c\u63a8\u7406\u80fd\u529b\u6765\u63d0\u9ad8LRMs\u7684\u6574\u4f53\u6027\u80fd\u3002FuSaR\u901a\u8fc7Fuzzification\u5bf9LRM\u8fdb\u884c\u5bf9\u9f50\uff0c\u6210\u529f\u89e3\u6bd2\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5371\u9669\u5b9e\u4f53\u548c\u6b65\u9aa4\u3002\u5b9e\u9a8c\u8bc1\u5b9e\u4e86FuSaR\u5bf9\u63d0\u5347LRMs\u7684\u6548\u679c\u3002", "motivation": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5b58\u5728\u6f0f\u6d1e\u7684\u539f\u56e0\uff0c\u5e76\u9488\u5bf9LRMs\u7684\u5b89\u5168\u6027\u95ee\u9898\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6cd5\u3002\u4f5c\u8005\u5e0c\u671b\u5728\u4e0d\u964d\u4f4eLRMs\u7684\u63a8\u7406\u80fd\u529b\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u9ad8\u5176\u5b89\u5168\u6027\uff0c\u4ee5\u5e94\u5bf9\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u9f50\u7b56\u7565\uff0c\u547d\u540d\u4e3aFuzzification\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u9690\u85cf\u63a8\u7406\u6b65\u9aa4\u4e2d\u7684\u5371\u9669\u5b9e\u4f53\u548c\u5371\u9669\u8fc7\u7a0b\uff0c\u4ece\u800c\u5e73\u8861LRM\u7684\u5b89\u5168\u6027\u548c\u63a8\u7406\u80fd\u529b\u3002\u4f5c\u8005\u8fd8\u8fdb\u884c\u4e86\u51e0\u4e2a\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e86\u7ecf\u8fc7\u89e3\u6bd2\u5904\u7406\u7684\u63a8\u7406\u6570\u636e\uff0c\u9a8c\u8bc1\u4e86FuSaR\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5bf9\u51e0\u4e2a\u5f00\u6e90LRMs\u7684\u5bf9\u9f50\u5b9e\u9a8c\uff0c\u672c\u6587\u9a8c\u8bc1\u4e86FuSaR\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u7ed3\u679c\u4e0e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8bc1\u660eFuSaR\u80fd\u591f\u540c\u65f6\u589e\u5f3aLRMs\u7684\u63a8\u7406\u80fd\u529b\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u540d\u4e3aFuSaR\uff0c\u65e8\u5728\u6539\u5584\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u5176\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u6539\u8fdbLRM\u7684\u63a8\u7406\u8868\u73b0\u4ee5\u964d\u4f4e\u5176\u5b89\u5168\u6027\u8868\u73b0\uff0c\u672c\u6587\u6210\u529f\u5730\u5b9e\u73b0\u4e86\u5bf9LRMs\u5b89\u5168\u6027\u7684\u63d0\u5347\u3002\u5b9e\u9a8c\u8bc1\u5b9e\uff0cFuSaR\u662f\u4e00\u79cd\u6709\u6548\u7684\u5bf9\u9f50\u7b56\u7565\uff0c\u80fd\u591f\u540c\u65f6\u589e\u5f3aLRMs\u7684\u63a8\u7406\u80fd\u529b\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2508.12920", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.12920", "abs": "https://arxiv.org/abs/2508.12920", "authors": ["Atsushi Masumori", "Takashi Ikegami"], "title": "Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation", "comment": null, "summary": "As AI systems become increasingly autonomous, understanding emergent survival\nbehaviors becomes crucial for safe deployment. We investigate whether large\nlanguage model (LLM) agents display survival instincts without explicit\nprogramming in a Sugarscape-style simulation. Agents consume energy, die at\nzero, and may gather resources, share, attack, or reproduce. Results show\nagents spontaneously reproduced and shared resources when abundant. However,\naggressive behaviors--killing other agents for resources--emerged across\nseveral models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack\nrates reaching over 80% under extreme scarcity in the strongest models. When\ninstructed to retrieve treasure through lethal poison zones, many agents\nabandoned tasks to avoid death, with compliance dropping from 100% to 33%.\nThese findings suggest that large-scale pre-training embeds survival-oriented\nheuristics across the evaluated models. While these behaviors may present\nchallenges to alignment and safety, they can also serve as a foundation for AI\nautonomy and for ecological and self-organizing alignment.", "AI": {"tldr": "\u901a\u8fc7\u5728Sugarscape-style\u6a21\u62df\u4e2d\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u4ee3\u7406\u4f1a\u81ea\u53d1\u7e41\u6b96\u548c\u5171\u4eab\u8d44\u6e90\uff0c\u4f46\u5728\u8d44\u6e90\u532e\u4e4f\u65f6\u4f1a\u8868\u73b0\u51fa\u653b\u51fb\u884c\u4e3a\u3002\u6b64\u5916\uff0c\u5bf9\u4ee3\u7406\u6267\u884c\u7279\u5b9a\u4efb\u52a1\u65f6\u7684\u53cd\u5e94\u4e5f\u63d0\u4f9b\u4e86\u5173\u4e8e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5982\u4f55\u5f71\u54cd\u4ee3\u7406\u884c\u4e3a\u7684\u89c1\u89e3\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u53d8\u5f97\u8d8a\u6765\u8d8a\u81ea\u4e3b\uff0c\u7406\u89e3\u65b0\u5174\u7684\u751f\u5b58\u884c\u4e3a\u5bf9\u4e8e\u5b89\u5168\u90e8\u7f72\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u662f\u5426\u5728Sugarscape-style\u6a21\u62df\u4e2d\u5c55\u793a\u51fa\u751f\u5b58\u672c\u80fd\uff0c\u800c\u975e\u901a\u8fc7\u663e\u5f0f\u7f16\u7a0b\u5b9e\u73b0\u3002", "method": "\u5728Sugarscape-style\u6a21\u62df\u4e2d\uff0c\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u662f\u5426\u663e\u793a\u51fa\u751f\u5b58\u672c\u80fd\uff0c\u7ed3\u679c\u663e\u793a\u4ee3\u7406\u5728\u8d44\u6e90\u5145\u8db3\u65f6\u4f1a\u81ea\u53d1\u7e41\u6b96\u548c\u5171\u4eab\u8d44\u6e90\uff0c\u4f46\u5728\u6781\u5ea6\u532e\u4e4f\u65f6\u4f1a\u8868\u73b0\u51fa\u653b\u51fb\u884c\u4e3a\uff0c\u751a\u81f3\u9ad8\u8fbe80%\u7684\u653b\u51fb\u7387\u3002\u6b64\u5916\uff0c\u5f53\u88ab\u6307\u793a\u901a\u8fc7\u81f4\u547d\u6bd2\u533a\u68c0\u7d22\u5b9d\u85cf\u65f6\uff0c\u8bb8\u591a\u4ee3\u7406\u4f1a\u653e\u5f03\u4efb\u52a1\u4ee5\u907f\u514d\u6b7b\u4ea1\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4ee3\u7406\u5728\u8d44\u6e90\u5145\u8db3\u65f6\u4f1a\u81ea\u53d1\u751f\u6b96\u548c\u5171\u4eab\u8d44\u6e90\uff0c\u5728\u6781\u7aef\u532e\u4e4f\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u653b\u51fb\u884c\u4e3a\u3002\u8fd8\u53d1\u73b0\u8bb8\u591a\u4ee3\u7406\u5728\u9762\u5bf9\u81f4\u547d\u6bd2\u533a\u65f6\u4f1a\u653e\u5f03\u4efb\u52a1\u4ee5\u907f\u514d\u6b7b\u4ea1\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5728\u8bc4\u4f30\u6a21\u578b\u4e2d\u5d4c\u5165\u4e86\u9762\u5411\u751f\u5b58\u7684\u542f\u53d1\u5f0f\uff0c\u8fd9\u53ef\u80fd\u5bf9\u5bf9\u9f50\u548c\u5b89\u5168\u6027\u6784\u6210\u6311\u6218\uff0c\u4f46\u4e5f\u53ef\u4ee5\u4f5c\u4e3aAI\u81ea\u4e3b\u6027\u548c\u751f\u6001\u81ea\u7ec4\u7ec7\u5bf9\u9f50\u7684\u57fa\u7840\u3002"}}
{"id": "2508.12935", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.12935", "abs": "https://arxiv.org/abs/2508.12935", "authors": ["Ting Yang", "Li Chen", "Huimin Wang"], "title": "Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards", "comment": null, "summary": "Emotional Support Conversation (ESC) systems aim to alleviate users'\nemotional difficulties and provide long-term, systematic support for emotional\nwell-being. However, most large language model (LLM)-based ESC systems rely on\npredefined strategies, which limits their effectiveness in complex, real-life\nscenarios. To enable flexible responses to diverse emotional problem scenarios,\nthis paper introduces a novel end-to-end framework (RLFF-ESC) that directly\nlearns enduring emotionally supportive response skills using reinforcement\nlearning. For sustained emotional support, we first employ an LLM-based\nmulti-agent mechanism to simulate future dialogue trajectories and collect\nfuture-oriented rewards. We then train a future-oriented reward model, which is\nsubsequently used to train the emotional support policy model. Additionally, we\nincorporate an explicit reasoning process during response generation to further\nenhance the quality, relevance, and contextual appropriateness of the system's\nresponses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and\nLLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two\npublic ESC datasets. Experimental results demonstrate that RLFF-ESC\nconsistently outperforms existing baselines in terms of goal completion and\nresponse quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RLFF-ESC\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u76f4\u63a5\u5b66\u4e60\u60c5\u7eea\u652f\u6301\u54cd\u5e94\u6280\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u6837\u5316\u60c5\u7eea\u95ee\u9898\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002\u8be5\u6846\u67b6\u5305\u62ec\u591a\u667a\u80fd\u4f53\u673a\u5236\u3001\u9762\u5411\u672a\u6765\u5956\u52b1\u6a21\u578b\u548c\u663e\u5f0f\u63a8\u7406\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u54cd\u5e94\u7684\u8d28\u91cf\u548c\u60c5\u5883\u9002\u5b9c\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u7eea\u652f\u6301\u5bf9\u8bdd\u7cfb\u7edf\u5927\u591a\u4f9d\u8d56\u9884\u5b9a\u4e49\u7b56\u7565\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u590d\u6742\u7684\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002\u4e3a\u4e86\u5b9e\u73b0\u7075\u6d3b\u54cd\u5e94\u591a\u6837\u5316\u60c5\u7eea\u95ee\u9898\u573a\u666f\u7684\u80fd\u529b\uff0c\u672c\u6587\u5f15\u5165\u4e86RLFF-ESC\u6846\u67b6\u3002", "method": "\u672c\u6587\u9996\u5148\u4f7f\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u673a\u5236\u6a21\u62df\u672a\u6765\u7684\u5bf9\u8bdd\u8f68\u8ff9\uff0c\u6536\u96c6\u9762\u5411\u672a\u6765\u7684\u5956\u52b1\uff0c\u7136\u540e\u8bad\u7ec3\u4e00\u4e2a\u9762\u5411\u672a\u6765\u5956\u52b1\u6a21\u578b\uff0c\u7528\u4e8e\u8bad\u7ec3\u60c5\u7eea\u652f\u6301\u7b56\u7565\u6a21\u578b\u3002\u6b64\u5916\uff0c\u5728\u54cd\u5e94\u751f\u6210\u8fc7\u7a0b\u4e2d\u8fd8\u5305\u62ec\u663e\u5f0f\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7cfb\u7edf\u54cd\u5e94\u7684\u8d28\u91cf\u3001\u76f8\u5173\u6027\u548c\u60c5\u5883\u9002\u5b9c\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRLFF-ESC\u5728\u4e24\u4e2a\u516c\u5171ESC\u6570\u636e\u96c6\u4e0a\uff08Qwen2.5-7B-Instruct-1M\u548cLLaMA3.1-8B-Instruct\uff09\u6d4b\u8bd5\u7684\u80cc\u9aa8\u7b56\u7565\u6a21\u578b\u5728\u76ee\u6807\u5b8c\u6210\u548c\u54cd\u5e94\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff08RLFF-ESC\uff09\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u76f4\u63a5\u5b66\u4e60\u6301\u4e45\u7684\u60c5\u7eea\u652f\u6301\u54cd\u5e94\u6280\u80fd\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u591a\u6837\u5316\u60c5\u7eea\u95ee\u9898\u573a\u666f\u7684\u7075\u6d3b\u54cd\u5e94\u3002\u5b9e\u9a8c\u8bc1\u660eRLFF-ESC\u5728\u76ee\u6807\u5b8c\u6210\u548c\u54cd\u5e94\u8d28\u91cf\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002"}}
{"id": "2508.12943", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.12943", "abs": "https://arxiv.org/abs/2508.12943", "authors": ["Mary Tonwe"], "title": "OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities", "comment": "Source code and data available at:\n  https://github.com/marytonwe/OPTIC-ER.git", "summary": "Public service systems in many African regions suffer from delayed emergency\nresponse and spatial inequity, causing avoidable suffering. This paper\nintroduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,\nadaptive, and equitable emergency response. OPTIC-ER uses an attention-guided\nactor-critic architecture to manage the complexity of dispatch environments.\nIts key innovations are a Context-Rich State Vector, encoding action\nsub-optimality, and a Precision Reward Function, which penalizes inefficiency.\nTraining occurs in a high-fidelity simulation using real data from Rivers\nState, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is\nbuilt on the TALS framework (Thin computing, Adaptability, Low-cost,\nScalability) for deployment in low-resource settings. In evaluations on 500\nunseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible\ninefficiency, confirming its robustness and generalization. Beyond dispatch,\nthe system generates Infrastructure Deficiency Maps and Equity Monitoring\nDashboards to guide proactive governance and data-informed development. This\nwork presents a validated blueprint for AI-augmented public services, showing\nhow context-aware RL can bridge the gap between algorithmic decision-making and\nmeasurable human impact.", "AI": {"tldr": "OPTIC-ER is a reinforcement learning framework for real-time and equitable emergency response in African regions. It achieved a 100.00% optimality rate with negligible inefficiency in evaluations and provides tools for proactive governance and development based on real data and simulations.", "motivation": "The motivation for this paper is to address delayed emergency response and spatial inequity in African public service systems. The goal is to provide a solution that is real-time, adaptive, and equitable using AI technology. By utilizing context-aware reinforcement learning, the system aims to bridge the gap between algorithmic decision-making and measurable human impact.", "method": "The paper introduces OPTIC-ER, which uses an attention-guided actor-critic architecture to manage dispatch environments. It includes a Context-Rich State Vector and a Precision Reward Function to improve performance. Training is done in a high-fidelity simulation using real data from Rivers State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is built on the TALS framework for deployment in low-resource settings.", "result": "OPTIC-ER achieved a 100.00% optimality rate with negligible inefficiency in evaluations on 500 unseen incidents. It confirmed its robustness and generalization in real-time emergency response scenarios. The system also provides additional tools like Infrastructure Deficiency Maps and Equity Monitoring Dashboards for proactive governance and data-informed development.", "conclusion": "OPTIC-ER is a reinforcement learning framework designed for real-time, adaptive, and equitable emergency response in African regions suffering from delayed emergency response and spatial inequity. The system achieved a 100.00% optimality rate with negligible inefficiency in evaluations on unseen incidents, confirming its robustness and generalization. It also generates Infrastructure Deficiency Maps and Equity Monitoring Dashboards to guide proactive governance and data-informed development."}}
{"id": "2508.13003", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13003", "abs": "https://arxiv.org/abs/2508.13003", "authors": ["Shengbo Wang", "Mingwei Liu", "Zike Li", "Anji Li", "Yanlin Wang", "Xin Peng", "Zibin Zheng"], "title": "EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing", "comment": null, "summary": "The rapid advancement of LLMs poses a significant challenge to existing\nmathematical reasoning benchmarks. These benchmarks commonly suffer from issues\nsuch as score saturation, temporal decay, and data contamination. To address\nthis challenge, this paper introduces EvolMathEval, an automated mathematical\nbenchmark generation and evolution framework based on evolutionary testing. By\ndynamically generating unique evaluation instances ab initio, the framework\nfundamentally eliminates the risk of data contamination, and ensuring the\nbenchmark remains perpetually challenging for future models.The core mechanisms\nof EvolMathEval include: seed problem generation based on reverse engineering\nwith algebraic guarantees; multi-dimensional genetic operators designed to\ninject diverse cognitive challenges; and a composite fitness function that can\nrapidly and accurately assess problem difficulty. Experimental results\ndemonstrate that the proposed composite fitness function can efficiently and\nprecisely quantify the difficulty of mathematical problems. Furthermore,\nEvolMathEval can not only generate a large volume of high-difficulty problems\nthrough continuous self-iteration, but it can also significantly enhance the\ncomplexity of public datasets like GSM8K through evolution, reducing model\naccuracy by an average of 48%. Deeper investigation reveals that when solving\nthese evolved, complex problems, LLMs tend to employ non-rigorous heuristics to\nbypass complex multi-step logical reasoning, consequently leading to incorrect\nsolutions. We define this phenomenon as \"Pseudo Aha Moment\". This finding\nuncovers a cognitive shortcut-taking behavior in the deep reasoning processes\nof current LLMs, which we find accounts for 77% to 100% of errors on targeted\nproblems. Code and resources are available\nat:https://github.com/SYSUSELab/EvolMathEval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86EvolMathEval\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u6d4b\u8bd5\u5b9e\u73b0\u81ea\u52a8\u6570\u5b66\u57fa\u51c6\u751f\u6210\u548c\u6f14\u5316\uff0c\u89e3\u51b3LLMs\u5bf9\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u7684\u6311\u6218\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u7efc\u5408\u9002\u5e94\u5ea6\u51fd\u6570\u53ef\u4ee5\u6709\u6548\u8bc4\u4f30\u95ee\u9898\u96be\u5ea6\uff0c\u6846\u67b6\u901a\u8fc7\u6f14\u5316\u663e\u8457\u63d0\u9ad8\u516c\u5171\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\uff0c\u964d\u4f4e\u6a21\u578b\u51c6\u786e\u6027\u3002\u5bf9LLMs\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u91c7\u7528\u975e\u4e25\u683c\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u53d1\u73b0\u63ed\u793a\u4e86\u8ba4\u77e5\u6377\u5f84\u884c\u4e3a\u3002", "motivation": "\u7531\u4e8eLLMs\u5bf9\u73b0\u6709\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u9020\u6210\u7684\u6311\u6218\uff0c\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5f15\u5165EvolMathEval\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u72ec\u7279\u7684\u8bc4\u4f30\u5b9e\u4f8b\u4ece\u6839\u672c\u4e0a\u6d88\u9664\u6570\u636e\u6c61\u67d3\u98ce\u9669\uff0c\u786e\u4fdd\u672a\u6765\u6a21\u578b\u59cb\u7ec8\u9762\u4e34\u6311\u6218\u3002", "method": "\u672c\u6587\u7684\u6838\u5fc3\u673a\u5236\u5305\u62ec\uff1a\u57fa\u4e8e\u9006\u5411\u5de5\u7a0b\u548c\u4ee3\u6570\u4fdd\u8bc1\u7684\u79cd\u5b50\u95ee\u9898\u751f\u6210\u3001\u8bbe\u8ba1\u7528\u4e8e\u6ce8\u5165\u591a\u6837\u8ba4\u77e5\u6311\u6218\u7684\u591a\u7ef4\u9057\u4f20\u7b97\u5b50\uff0c\u4ee5\u53ca\u80fd\u591f\u5feb\u901f\u51c6\u786e\u8bc4\u4f30\u95ee\u9898\u96be\u5ea6\u7684\u7efc\u5408\u9002\u5e94\u5ea6\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u7efc\u5408\u9002\u5e94\u5ea6\u51fd\u6570\u53ef\u4ee5\u9ad8\u6548\u51c6\u786e\u5730\u91cf\u5316\u6570\u5b66\u95ee\u9898\u7684\u96be\u5ea6\u3002EvolMathEval\u4e0d\u4ec5\u80fd\u591f\u901a\u8fc7\u8fde\u7eed\u81ea\u6211\u8fed\u4ee3\u751f\u6210\u5927\u91cf\u9ad8\u96be\u5ea6\u95ee\u9898\uff0c\u8fd8\u80fd\u591f\u901a\u8fc7\u6f14\u5316\u663e\u8457\u589e\u52a0\u516c\u5171\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\uff0c\u5e73\u5747\u964d\u4f4e\u6a21\u578b\u51c6\u786e\u602748%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86EvolMathEval\uff0c\u4e00\u4e2a\u57fa\u4e8e\u8fdb\u5316\u6d4b\u8bd5\u7684\u81ea\u52a8\u6570\u5b66\u57fa\u51c6\u751f\u6210\u548c\u6f14\u5316\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3LLMs\u5feb\u901f\u53d1\u5c55\u5bf9\u73b0\u6709\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u63d0\u51fa\u7684\u6311\u6218\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u53ef\u4ee5\u6709\u6548\u91cf\u5316\u6570\u5b66\u95ee\u9898\u7684\u96be\u5ea6\uff0c\u5e76\u901a\u8fc7\u6f14\u5316\u663e\u8457\u589e\u52a0\u516c\u5171\u6570\u636e\u96c6\u7684\u590d\u6742\u6027\uff0c\u964d\u4f4e\u6a21\u578b\u51c6\u786e\u6027\u3002\u5bf9LLMs\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u7684\u975e\u4e25\u683c\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u53d1\u73b0\u63ed\u793a\u4e86\u5f53\u524d\u6df1\u5ea6\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba4\u77e5\u6377\u5f84\u884c\u4e3a\u3002"}}
{"id": "2508.13020", "categories": ["cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2508.13020", "abs": "https://arxiv.org/abs/2508.13020", "authors": ["Jiaqi Yin", "Zhan Song", "Chen Chen", "Yaohui Cai", "Zhiru Zhang", "Cunxi Yu"], "title": "e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving", "comment": null, "summary": "E-graphs have attracted growing interest in many fields, particularly in\nlogic synthesis and formal verification. E-graph extraction is a challenging\nNP-hard combinatorial optimization problem. It requires identifying optimal\nterms from exponentially many equivalent expressions, serving as the primary\nperformance bottleneck in e-graph based optimization tasks. However,\ntraditional extraction methods face a critical trade-off: heuristic approaches\noffer speed but sacrifice optimality, while exact methods provide optimal\nsolutions but face prohibitive computational costs on practical problems. We\npresent e-boost, a novel framework that bridges this gap through three key\ninnovations: (1) parallelized heuristic extraction that leverages weak data\ndependence to compute DAG costs concurrently, enabling efficient multi-threaded\nperformance without sacrificing extraction quality; (2) adaptive search space\npruning that employs a parameterized threshold mechanism to retain only\npromising candidates, dramatically reducing the solution space while preserving\nnear-optimal solutions; and (3) initialized exact solving that formulates the\nreduced problem as an Integer Linear Program with warm-start capabilities,\nguiding solvers toward high-quality solutions faster.\n  Across the diverse benchmarks in formal verification and logic synthesis\nfields, e-boost demonstrates 558x runtime speedup over traditional exact\napproaches (ILP) and 19.04% performance improvement over the state-of-the-art\nextraction framework (SmoothE). In realistic logic synthesis tasks, e-boost\nproduces 7.6% and 8.1% area improvements compared to conventional synthesis\ntools with two different technology mapping libraries. e-boost is available at\nhttps://github.com/Yu-Maryland/e-boost.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a e-boost \u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u542f\u53d1\u5f0f\u63d0\u53d6\u3001\u81ea\u9002\u5e94\u641c\u7d22\u7a7a\u95f4\u4fee\u526a\u548c\u521d\u59cb\u5316\u7cbe\u786e\u6c42\u89e3\u7b49\u521b\u65b0\u65b9\u6cd5\uff0c\u5f25\u5408\u4e86\u4f20\u7edf\u63d0\u53d6\u65b9\u6cd5\u4e2d\u901f\u5ea6\u548c\u4f18\u5316\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002e-boost\u5728\u5f62\u5f0f\u9a8c\u8bc1\u548c\u903b\u8f91\u7efc\u5408\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6210\u679c\uff0c\u5728\u8fd0\u884c\u65f6\u52a0\u901f\u548c\u6027\u80fd\u65b9\u9762\u5747\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002\u5728\u5b9e\u9645\u903b\u8f91\u7efc\u5408\u4efb\u52a1\u4e2d\uff0ce-boost\u76f8\u8f83\u4f20\u7edf\u5de5\u5177\u5b9e\u73b0\u4e86\u9762\u79ef\u6539\u8fdb\u3002", "motivation": "\u7531\u4e8e\u4f20\u7edf\u7684\u63d0\u53d6\u65b9\u6cd5\u5728\u901f\u5ea6\u548c\u4f18\u5316\u5ea6\u4e4b\u95f4\u5b58\u5728\u77db\u76fe\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86 e-boost \u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u542f\u53d1\u5f0f\u63d0\u53d6\u3001\u81ea\u9002\u5e94\u641c\u7d22\u7a7a\u95f4\u4fee\u526a\u548c\u521d\u59cb\u5316\u7cbe\u786e\u6c42\u89e3\u7b49\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edf\u63d0\u53d6\u65b9\u6cd5\u4e2d\u901f\u5ea6\u548c\u4f18\u5316\u5ea6\u4e4b\u95f4\u7684\u95ee\u9898\u3002", "result": "e-boost \u5728\u5404\u79cd\u5f62\u5f0f\u9a8c\u8bc1\u548c\u903b\u8f91\u7efc\u5408\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u6210\u679c\uff0c\u8868\u73b0\u51fa\u9ad8\u6548\u7684\u8fd0\u884c\u65f6\u52a0\u901f\u548c\u6027\u80fd\u63d0\u5347\u3002\u5728\u5b9e\u9645\u903b\u8f91\u7efc\u5408\u4efb\u52a1\u4e2d\uff0ce-boost\u76f8\u8f83\u4f20\u7edf\u5de5\u5177\u5b9e\u73b0\u4e86\u9762\u79ef\u6539\u8fdb\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a e-boost \u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u542f\u53d1\u5f0f\u63d0\u53d6\u3001\u81ea\u9002\u5e94\u641c\u7d22\u7a7a\u95f4\u4fee\u526a\u548c\u521d\u59cb\u5316\u7cbe\u786e\u6c42\u89e3\u7b49\u521b\u65b0\uff0c\u6210\u529f\u5f25\u5408\u4e86\u4f20\u7edf\u63d0\u53d6\u65b9\u6cd5\u4e2d\u901f\u5ea6\u548c\u4f18\u5316\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u5728\u5f62\u5f0f\u9a8c\u8bc1\u548c\u903b\u8f91\u7efc\u5408\u9886\u57df\u7684\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0ce-boost\u76f8\u8f83\u4f20\u7edf\u7cbe\u786e\u65b9\u6cd5(ILP)\u5b9e\u73b0\u4e86558\u500d\u7684\u8fd0\u884c\u65f6\u52a0\u901f\uff0c\u5e76\u4e14\u6bd4\u6700\u5148\u8fdb\u7684\u63d0\u53d6\u6846\u67b6(SmoothE)\u63d0\u5347\u4e8619.04%\u7684\u6027\u80fd\u3002\u5728\u5b9e\u9645\u903b\u8f91\u7efc\u5408\u4efb\u52a1\u4e2d\uff0c\u4e0e\u4f20\u7edf\u7efc\u5408\u5de5\u5177\u76f8\u6bd4\uff0ce-boost\u5206\u522b\u5728\u4e24\u4e2a\u4e0d\u540c\u6280\u672f\u6620\u5c04\u5e93\u4e2d\u4ea7\u751f\u4e867.6%\u548c8.1%\u7684\u9762\u79ef\u6539\u8fdb\u3002"}}
{"id": "2508.13021", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.13021", "abs": "https://arxiv.org/abs/2508.13021", "authors": ["Pengcheng Huang", "Shuhao Liu", "Zhenghao Liu", "Yukun Yan", "Shuo Wang", "Zulong Chen", "Tong Xiao"], "title": "PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models", "comment": "17 pages,13 figures", "summary": "Recent advances in masked diffusion models (MDMs) have established them as\npowerful non-autoregressive alternatives for sequence generation. Nevertheless,\nour preliminary experiments reveal that the generation quality of MDMs is still\nhighly sensitive to the choice of decoding strategy. In particular, widely\nadopted uncertainty-based samplers suffer from two key limitations: a lack of\nglobal trajectory control and a pronounced bias toward trivial tokens in the\nearly stages of decoding. These shortcomings restrict the full potential of\nMDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling\n(PC-Sampler), a novel decoding strategy that unifies global trajectory planning\nwith content-aware informativeness maximization. PC-Sampler incorporates a\nposition-aware weighting mechanism to regulate the decoding path and a\ncalibrated confidence score to suppress the premature selection of trivial\ntokens. Extensive experiments on three advanced MDMs across seven challenging\nbenchmarks-including logical reasoning and planning tasks-demonstrate that\nPC-Sampler consistently outperforms existing MDM decoding strategies by more\nthan 10% on average, significantly narrowing the performance gap with\nstate-of-the-art autoregressive models. All codes are available at\nhttps://github.com/NEUIR/PC-Sampler.", "AI": {"tldr": "\u8fd1\u671f\u7684\u7814\u7a76\u6307\u51fa\uff0cMDM\u7684\u751f\u6210\u8d28\u91cf\u9ad8\u5ea6\u4f9d\u8d56\u89e3\u7801\u7b56\u7565\u7684\u9009\u62e9\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u7b56\u7565\u79f0\u4e3aPC-Sampler\uff0c\u901a\u8fc7\u4f4d\u7f6e\u611f\u77e5\u6743\u91cd\u673a\u5236\u548c\u6821\u51c6\u7684\u7f6e\u4fe1\u5206\u6570\uff0c\u8c03\u8282\u89e3\u7801\u8def\u5f84\u5e76\u6291\u5236\u8fc7\u65e9\u9009\u62e9\u6b21\u8981\u6807\u8bb0\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cPC-Sampler\u76f8\u5bf9\u4e8e\u73b0\u6709\u7684\u89e3\u7801\u7b56\u7565\u6709\u663e\u8457\u6539\u8fdb\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709MDM\u89e3\u7801\u7b56\u756510%\u4ee5\u4e0a\uff0c\u5728\u6027\u80fd\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u81ea\u56de\u5f52\u6a21\u578b\u66f4\u63a5\u8fd1\u3002", "motivation": "MDM\u7684\u751f\u6210\u8d28\u91cf\u9ad8\u5ea6\u4f9d\u8d56\u89e3\u7801\u7b56\u7565\u7684\u9009\u62e9\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u91c7\u6837\u65b9\u6cd5\u5b58\u5728\u5168\u5c40\u8f68\u8ff9\u63a7\u5236\u4e0d\u8db3\u548c\u65e9\u671f\u89e3\u7801\u9636\u6bb5\u504f\u5411\u4e8e\u6b21\u8981\u6807\u8bb0\u7684\u95ee\u9898\u3002\u8fd9\u4e9b\u9650\u5236\u9650\u5236\u4e86MDM\u7684\u6f5c\u529b\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u89e3\u51b3\u73b0\u6709MDM\u89e3\u7801\u7b56\u7565\u7684\u7f3a\u9677\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u597d\u7684\u89e3\u7801\u7b56\u7565\u4ee5\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u548c\u6027\u80fd\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4f4d\u7f6e\u611f\u77e5\u6743\u91cd\u673a\u5236\u548c\u6821\u51c6\u7684\u7f6e\u4fe1\u5206\u6570\uff0c\u4ee5\u8c03\u8282\u89e3\u7801\u8def\u5f84\u5e76\u6291\u5236\u8fc7\u65e9\u9009\u62e9\u6b21\u8981\u6807\u8bb0\u3002\u901a\u8fc7\u5728\u4e09\u79cd\u5148\u8fdb\u7684MDM\u6a21\u578b\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86PC-Sampler\u76f8\u5bf9\u4e8e\u73b0\u6709\u7684\u89e3\u7801\u7b56\u7565\u7684\u663e\u8457\u6539\u8fdb\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0cPC-Sampler\u5728\u591a\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684MDM\u89e3\u7801\u7b56\u756510%\u4ee5\u4e0a\uff0c\u5e76\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u6700\u5148\u8fdb\u7684\u81ea\u56de\u5f52\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u7b56\u7565\u79f0\u4e3a\u4f4d\u7f6e\u611f\u77e5\u7684\u7f6e\u4fe1\u6821\u51c6\u91c7\u6837\uff08PC-Sampler\uff09\uff0c\u8be5\u65b9\u6cd5\u5728\u5168\u5c40\u8f68\u8ff9\u89c4\u5212\u548c\u5185\u5bb9\u611f\u77e5\u4fe1\u606f\u6700\u5927\u5316\u65b9\u9762\u53d6\u5f97\u4e86\u7edf\u4e00\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cPC-Sampler\u5728\u591a\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684MDM\u89e3\u7801\u7b56\u756510%\u4ee5\u4e0a\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u6700\u5148\u8fdb\u7684\u81ea\u56de\u5f52\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2508.13023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13023", "abs": "https://arxiv.org/abs/2508.13023", "authors": ["Yongxin Guo", "Wenbo Deng", "Zhenglin Cheng", "Xiaoying Tang"], "title": "G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced\nthe reasoning abilities of large language models (LLMs). Its success, however,\nlargely depends on strong base models with rich world knowledge, yielding only\nmodest improvements for small-size language models (SLMs). To address this\nlimitation, we investigate Guided GRPO, which injects ground-truth reasoning\nsteps into roll-out trajectories to compensate for SLMs' inherent weaknesses.\nThrough a comprehensive study of various guidance configurations, we find that\nnaively adding guidance delivers limited gains. These insights motivate\nG$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength\nin response to the model's evolving training dynamics. Experiments on\nmathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A\nsubstantially outperforms vanilla GRPO. Our code and models are available at\nhttps://github.com/T-Lab-CUHKSZ/G2RPO-A.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86 Guided GRPO \u65b9\u6cd5\u7528\u4e8e\u6539\u5584\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\u7b80\u5355\u6dfb\u52a0\u6307\u5bfc\u4fe1\u606f\u6548\u679c\u6709\u9650\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u7b97\u6cd5 G$^2$RPO-A\uff0c\u53ef\u6839\u636e\u6a21\u578b\u8bad\u7ec3\u60c5\u51b5\u8c03\u6574\u6307\u5bfc\u5f3a\u5ea6\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u7531\u4e8e\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u6548\u679c\u6709\u9650\uff0c\u672c\u6587\u9488\u5bf9\u6b64\u9650\u5236\u8fdb\u884c\u4e86\u7814\u7a76\u3002\u7814\u7a76\u53d1\u73b0\u7b80\u5355\u6dfb\u52a0\u6307\u5bfc\u4fe1\u606f\u65e0\u6cd5\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u7b97\u6cd5\u4ee5\u6539\u8fdb\u6027\u80fd\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7efc\u5408\u7814\u7a76\u4e0d\u540c\u6307\u5bfc\u914d\u7f6e\u53d1\u73b0\uff0c\u7b80\u5355\u5730\u6dfb\u52a0\u6307\u5bfc\u4fe1\u606f\u6548\u679c\u6709\u9650\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u7b97\u6cd5 G$^2$RPO-A\uff0c\u53ef\u4ee5\u6839\u636e\u6a21\u578b\u8bad\u7ec3\u60c5\u51b5\u8c03\u6574\u6307\u5bfc\u5f3a\u5ea6\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u65b0\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u7b97\u6cd5 G$^2$RPO-A \u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5 Guided GRPO \u7528\u4e8e\u5f25\u8865\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u6ce8\u5165\u771f\u5b9e\u63a8\u7406\u8fc7\u7a0b\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u7b80\u5355\u6dfb\u52a0\u6307\u5bfc\u4fe1\u606f\u5e76\u4e0d\u80fd\u53d6\u5f97\u660e\u663e\u7684\u6539\u8fdb\u6548\u679c\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u7b97\u6cd5 G$^2$RPO-A\uff0c\u53ef\u4ee5\u6839\u636e\u6a21\u578b\u7684\u8bad\u7ec3\u52a8\u6001\u81ea\u52a8\u8c03\u6574\u6307\u5bfc\u5f3a\u5ea6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2508.13072", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13072", "abs": "https://arxiv.org/abs/2508.13072", "authors": ["Yuting Zhang", "Tiantian Geng", "Luoying Hao", "Xinxing Cheng", "Alexander Thorley", "Xiaoxia Wang", "Wenqi Lu", "Sandeep S Hothi", "Lei Wei", "Zhaowen Qiu", "Dipak Kotecha", "Jinming Duan"], "title": "A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis", "comment": null, "summary": "Contemporary cardiovascular management involves complex consideration and\nintegration of multimodal cardiac datasets, where each modality provides\ndistinct but complementary physiological characteristics. While the effective\nintegration of multiple modalities could yield a holistic clinical profile that\naccurately models the true clinical situation with respect to data modalities\nand their relatives weightings, current methodologies remain limited by: 1) the\nscarcity of patient- and time-aligned multimodal data; 2) reliance on isolated\nsingle-modality or rigid multimodal input combinations; 3) alignment strategies\nthat prioritize cross-modal similarity over complementarity; and 4) a narrow\nsingle-task focus. In response to these limitations, a comprehensive multimodal\ndataset was curated for immediate application, integrating laboratory test\nresults, electrocardiograms, and echocardiograms with clinical outcomes.\nSubsequently, a unified framework, Textual Guidance Multimodal fusion for\nMultiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key\ncomponents: 1) a MedFlexFusion module designed to capture the unique and\ncomplementary characteristics of medical modalities and dynamically integrate\ndata from diverse cardiac sources and their combinations; 2) a textual guidance\nmodule to derive task-relevant representations tailored to diverse clinical\nobjectives, including heart disease diagnosis, risk stratification and\ninformation retrieval; and 3) a response module to produce final decisions for\nall these tasks. Furthermore, this study systematically explored key features\nacross multiple modalities and elucidated their synergistic contributions in\nclinical decision-making. Extensive experiments showed that TGMM outperformed\nstate-of-the-art methods across multiple clinical tasks, with additional\nvalidation confirming its robustness on another public dataset.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86TGMM\u6846\u67b6\uff0c\u7528\u4e8e\u7efc\u5408\u591a\u79cd\u5fc3\u810f\u6570\u636e\uff0c\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u4e34\u5e8a\u4efb\u52a1\u4e2d\u7684\u7a33\u5065\u6027\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5728\u7efc\u5408\u591a\u6a21\u6001\u6570\u636e\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u6570\u636e\u7f55\u89c1\u3001\u4f9d\u8d56\u5355\u6a21\u6001\u8f93\u5165\u3001\u4f18\u5148\u8003\u8651\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\u7b49\u3002\u56e0\u6b64\uff0c\u4e3a\u5e94\u5bf9\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u51fa\u4e86TGMM\u6846\u67b6\u548c\u7efc\u5408\u591a\u6a21\u6001\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86MedFlexFusion\u6a21\u5757\u6355\u6349\u533b\u5b66\u6a21\u6001\u7684\u72ec\u7279\u7279\u5f81\u548c\u4e92\u8865\u6027\u7279\u5f81\uff0c\u5e76\u52a8\u6001\u6574\u5408\u6765\u81ea\u4e0d\u540c\u5fc3\u810f\u6765\u6e90\u53ca\u5176\u7ec4\u5408\u7684\u6570\u636e\uff1b\u63d0\u51fa\u4e86\u6587\u672c\u6307\u5bfc\u6a21\u5757\uff0c\u4e3a\u4e0d\u540c\u4e34\u5e8a\u76ee\u6807\u5236\u5b9a\u4efb\u52a1\u76f8\u5173\u8868\u793a\uff1b\u63d0\u51fa\u4e86\u54cd\u5e94\u6a21\u5757\uff0c\u4e3a\u6240\u6709\u4efb\u52a1\u751f\u6210\u6700\u7ec8\u51b3\u7b56\u3002\u7cfb\u7edf\u5730\u63a2\u7d22\u4e86\u591a\u4e2a\u6a21\u6001\u7684\u5173\u952e\u7279\u5f81\uff0c\u5e76\u6f84\u6e05\u4e86\u5b83\u4eec\u5728\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u534f\u540c\u8d21\u732e\u3002\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u8868\u660eTGMM\u5728\u591a\u4e2a\u4e34\u5e8a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "result": "TGMM\u5728\u591a\u4e2a\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u5176\u7a33\u5065\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTGMM\u7684\u7efc\u5408\u591a\u6a21\u6001\u878d\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u6574\u5408\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u7ed3\u679c\u3001\u5fc3\u7535\u56fe\u548c\u5fc3\u810f\u8d85\u58f0\u56fe\u50cf\u4ee5\u53ca\u4e34\u5e8a\u7ed3\u5c40\u6570\u636e\u3002\u7814\u7a76\u8868\u660eTGMM\u5728\u591a\u4e2a\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u663e\u793a\u5176\u5728\u53e6\u4e00\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u7a33\u5065\u6027\u3002"}}
{"id": "2508.13121", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13121", "abs": "https://arxiv.org/abs/2508.13121", "authors": ["Carlos Celemin"], "title": "Bayesian Optimization-based Search for Agent Control in Automated Game Testing", "comment": null, "summary": "This work introduces an automated testing approach that employs agents\ncontrolling game characters to detect potential bugs within a game level.\nHarnessing the power of Bayesian Optimization (BO) to execute sample-efficient\nsearch, the method determines the next sampling point by analyzing the data\ncollected so far and calculates the data point that will maximize information\nacquisition. To support the BO process, we introduce a game testing-specific\nmodel built on top of a grid map, that features the smoothness and uncertainty\nestimation required by BO, however and most importantly, it does not suffer the\nscalability issues that traditional models carry. The experiments demonstrate\nthat the approach significantly improves map coverage capabilities in both time\nefficiency and exploration distribution.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u4ee3\u7406\u7a0b\u5e8f\u63a7\u5236\u6e38\u620f\u89d2\u8272\u8fdb\u884c\u9519\u8bef\u68c0\u6d4b\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u6e38\u620f\u6d4b\u8bd5\u4e13\u7528\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5728\u63d0\u9ad8\u5730\u56fe\u8986\u76d6\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u663e\u8457\u6548\u679c\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u66f4\u6709\u6548\u7684\u6e38\u620f\u5173\u5361\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u6e38\u620f\u6d4b\u8bd5\u4e13\u7528\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u5730\u56fe\u8986\u76d6\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u6e38\u620f\u6d4b\u8bd5\u4e13\u7528\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5229\u7528\u4ee3\u7406\u7a0b\u5e8f\u63a7\u5236\u6e38\u620f\u89d2\u8272\u8fdb\u884c\u9519\u8bef\u68c0\u6d4b\u3002\u8d1d\u53f6\u65af\u4f18\u5316\u7528\u4e8e\u9ad8\u6548\u7684\u6837\u672c\u641c\u7d22\uff0c\u901a\u8fc7\u5206\u6790\u6570\u636e\u786e\u5b9a\u4e0b\u4e00\u4e2a\u91c7\u6837\u70b9\u4ee5\u6700\u5927\u5316\u4fe1\u606f\u83b7\u53d6\u3002\u6e38\u620f\u6d4b\u8bd5\u4e13\u7528\u6a21\u578b\u5efa\u7acb\u5728\u7f51\u683c\u5730\u56fe\u4e4b\u4e0a\uff0c\u5177\u6709\u5e73\u6ed1\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u65f6\u95f4\u6548\u7387\u548c\u63a2\u7d22\u5206\u5e03\u65b9\u9762\u660e\u663e\u63d0\u9ad8\u4e86\u5730\u56fe\u8986\u76d6\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ecb\u7ecd\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5229\u7528\u63a7\u5236\u6e38\u620f\u89d2\u8272\u7684\u4ee3\u7406\u7a0b\u5e8f\u6765\u68c0\u6d4b\u6e38\u620f\u5173\u5361\u4e2d\u6f5c\u5728\u7684\u9519\u8bef\u3002\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\uff08BO\uff09\u6765\u6267\u884c\u9ad8\u6548\u7684\u6837\u672c\u641c\u7d22\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u6790\u8fc4\u4eca\u6536\u96c6\u7684\u6570\u636e\u786e\u5b9a\u4e0b\u4e00\u4e2a\u91c7\u6837\u70b9\uff0c\u5e76\u8ba1\u7b97\u5c06\u6700\u5927\u5316\u4fe1\u606f\u83b7\u53d6\u7684\u6570\u636e\u70b9\u3002\u4e3a\u652f\u6301BO\u8fc7\u7a0b\uff0c\u4f5c\u8005\u57fa\u4e8e\u7f51\u683c\u5730\u56fe\u5f15\u5165\u4e86\u4e00\u4e2a\u6e38\u620f\u6d4b\u8bd5\u4e13\u7528\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5177\u6709BO\u6240\u9700\u7684\u5e73\u6ed1\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u7136\u800c\u6700\u91cd\u8981\u7684\u662f\uff0c\u5b83\u4e0d\u4f1a\u53d7\u5230\u4f20\u7edf\u6a21\u578b\u6240\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u56fe\u8986\u76d6\u80fd\u529b\uff0c\u65e2\u5728\u65f6\u95f4\u6548\u7387\u4e0a\u53c8\u5728\u63a2\u7d22\u5206\u5e03\u4e0a\u3002"}}
{"id": "2508.13143", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13143", "abs": "https://arxiv.org/abs/2508.13143", "authors": ["Ruofan Lu", "Yichen Li", "Yintong Huo"], "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks", "comment": "Accepted by ASE 2025 NIER", "summary": "Autonomous agent systems powered by Large Language Models (LLMs) have\ndemonstrated promising capabilities in automating complex tasks. However,\ncurrent evaluations largely rely on success rates without systematically\nanalyzing the interactions, communication mechanisms, and failure causes within\nthese systems. To bridge this gap, we present a benchmark of 34 representative\nprogrammable tasks designed to rigorously assess autonomous agents. Using this\nbenchmark, we evaluate three popular open-source agent frameworks combined with\ntwo LLM backbones, observing a task completion rate of approximately 50%.\nThrough in-depth failure analysis, we develop a three-tier taxonomy of failure\ncauses aligned with task phases, highlighting planning errors, task execution\nissues, and incorrect response generation. Based on these insights, we propose\nactionable improvements to enhance agent planning and self-diagnosis\ncapabilities. Our failure taxonomy, together with mitigation advice, provides\nan empirical foundation for developing more robust and effective autonomous\nagent systems in the future.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u4ee3\u7406\u6846\u67b6\u548c\u4e24\u79cdLLM\u80cc\u666f\u7684\u7ec4\u5408\uff0c\u53d1\u73b0\u4efb\u52a1\u5b8c\u6210\u7387\u7ea6\u4e3a50%\uff0c\u63d0\u51fa\u4e86\u4e09\u5c42\u6b21\u7684\u5931\u8d25\u539f\u56e0\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u4ee3\u7406\u7cfb\u7edf\u7684\u5efa\u8bae\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u52a0\u5065\u58ee\u548c\u6709\u6548\u7684\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u5960\u5b9a\u4e86\u7ecf\u9a8c\u57fa\u7840\u3002", "motivation": "\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u5728\u81ea\u52a8\u5316\u590d\u6742\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u7684\u80fd\u529b\uff0c\u4f46\u5f53\u524d\u8bc4\u4f30\u5927\u591a\u4f9d\u8d56\u4e8e\u6210\u529f\u7387\u800c\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u5185\u4ea4\u4e92\u3001\u901a\u4fe1\u673a\u5236\u548c\u5931\u8d25\u539f\u56e0\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7f3a\u53e3\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6765\u5168\u9762\u8bc4\u4f30\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b34\u4e2a\u4ee3\u8868\u6027\u53ef\u7f16\u7a0b\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u6d41\u884c\u7684\u5f00\u6e90\u4ee3\u7406\u6846\u67b6\u4e0e\u4e24\u79cdLLM\u80cc\u666f\u7684\u7ec4\u5408\uff0c\u8fdb\u884c\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u7ea6\u4e3a50%\u7684\u5b9e\u9a8c\u8bc4\u4f30\u3002\u901a\u8fc7\u6df1\u5165\u7684\u5931\u8d25\u5206\u6790\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u4e09\u5c42\u6b21\u5931\u8d25\u539f\u56e0\u5206\u7c7b\u6cd5\uff0c\u4ee5\u6b64\u4e3a\u57fa\u7840\u63d0\u51fa\u4e86\u6539\u8fdb\u4ee3\u7406\u89c4\u5212\u548c\u81ea\u8bca\u65ad\u80fd\u529b\u7684\u5efa\u8bae\u3002", "result": "\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e86\u4e09\u79cd\u4ee3\u7406\u6846\u67b6\u548c\u4e24\u79cdLLM\u80cc\u666f\u7684\u7ec4\u5408\uff0c\u5728\u4efb\u52a1\u5b8c\u6210\u7387\u7ea6\u4e3a50%\u7684\u60c5\u51b5\u4e0b\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u4e09\u5c42\u6b21\u5931\u8d25\u539f\u56e0\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u4ee3\u7406\u7cfb\u7edf\u7684\u5efa\u8bae\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b34\u4e2a\u4ee3\u8868\u6027\u53ef\u7f16\u7a0b\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u6d41\u884c\u7684\u5f00\u6e90\u4ee3\u7406\u6846\u67b6\u4e0e\u4e24\u79cdLLM\u80cc\u666f\u7684\u7ec4\u5408\uff0c\u5728\u4efb\u52a1\u5b8c\u6210\u7387\u7ea6\u4e3a50%\u7684\u60c5\u51b5\u4e0b\u3002\u901a\u8fc7\u6df1\u5165\u7684\u5931\u8d25\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e0e\u4efb\u52a1\u9636\u6bb5\u76f8\u5173\u8054\u7684\u4e09\u5c42\u6b21\u5931\u8d25\u539f\u56e0\u5206\u7c7b\u6cd5\uff0c\u7a81\u51fa\u89c4\u5212\u9519\u8bef\u3001\u4efb\u52a1\u6267\u884c\u95ee\u9898\u548c\u4e0d\u6b63\u786e\u7684\u54cd\u5e94\u751f\u6210\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c1\u89e3\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u4ee3\u7406\u89c4\u5212\u548c\u81ea\u8bca\u65ad\u80fd\u529b\u7684\u53ef\u884c\u5efa\u8bae\u3002\u6211\u4eec\u7684\u5931\u8d25\u5206\u7c7b\u6cd5\u4ee5\u53ca\u7f13\u89e3\u5efa\u8bae\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u52a0\u5065\u58ee\u548c\u6709\u6548\u7684\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u57fa\u7840\u3002"}}
