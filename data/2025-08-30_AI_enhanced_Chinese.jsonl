{"id": "2508.20131", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20131", "abs": "https://arxiv.org/abs/2508.20131", "authors": ["Yuqicheng Zhu", "Nico Potyka", "Daniel Hern\u00e1ndez", "Yuan He", "Zifeng Ding", "Bo Xiong", "Dongzhuoran Zhou", "Evgeny Kharlamov", "Steffen Staab"], "title": "ArgRAG: Explainable Retrieval Augmented Generation using Quantitative Bipolar Argumentation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models by\nincorporating external knowledge, yet suffers from critical limitations in\nhigh-stakes domains -- namely, sensitivity to noisy or contradictory evidence\nand opaque, stochastic decision-making. We propose ArgRAG, an explainable, and\ncontestable alternative that replaces black-box reasoning with structured\ninference using a Quantitative Bipolar Argumentation Framework (QBAF). ArgRAG\nconstructs a QBAF from retrieved documents and performs deterministic reasoning\nunder gradual semantics. This allows faithfully explaining and contesting\ndecisions. Evaluated on two fact verification benchmarks, PubHealth and\nRAGuard, ArgRAG achieves strong accuracy while significantly improving\ntransparency.", "AI": {"tldr": "ArgRAG is a structured and explainable alternative to RAG, using a Quantitative Bipolar Argumentation Framework for deterministic reasoning. It aims to improve transparency and accuracy in fact verification benchmarks, successfully addressing the limitations of RAG.", "motivation": "The motivation behind this paper is to address the critical limitations of RAG in high-stakes domains, such as sensitivity to noisy or contradictory evidence and opaque, stochastic decision-making. ArgRAG aims to enhance transparency and accuracy in decision-making processes.", "method": "ArgRAG utilizes a Quantitative Bipolar Argumentation Framework (QBAF) to replace black-box reasoning with structured inference. It constructs a QBAF from retrieved documents and employs deterministic reasoning under gradual semantics.", "result": "ArgRAG shows strong accuracy improvements and enhanced transparency compared to RAG. It was evaluated on two fact verification benchmarks, PubHealth and RAGuard.", "conclusion": "ArgRAG is an explainable and contestable alternative to Retrieval-Augmented Generation (RAG) that improves transparency and accuracy in fact verification benchmarks."}}
{"id": "2508.20134", "categories": ["cs.AI", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.20134", "abs": "https://arxiv.org/abs/2508.20134", "authors": ["Zhenxiao Fu", "Fan Chen", "Lei Jiang"], "title": "QAgent: An LLM-based Multi-Agent System for Autonomous OpenQASM programming", "comment": null, "summary": "Noisy Intermediate-Scale Quantum (NISQ) devices have begun to exhibit early\nquantum advantages on classically intractable problems, spanning physics\nsimulations to Gaussian boson sampling. Yet, realizing these benefits remains\nchallenging for non-experts, primarily due to the complexities of programming\nin Open Quantum Assembly Language (OpenQASM). Although Large Language Model\n(LLM)-based agents have shown promise in automating classical programming\nworkflows, their quantum counterparts have largely been restricted to\nspecialized tasks such as quantum chemistry or error correction. In this paper,\nwe present QAgent, an LLM-powered multi-agent system that fully automates\nOpenQASM programming. By integrating task planning, in-context few-shot\nlearning, retrieval-augmented generation (RAG) for long-term context,\npredefined generation tools, and chain-of-thought (CoT) reasoning, the agents\nsystematically improve both compilation and functional correctness. Our\nevaluations demonstrate substantial improvements: across multiple LLMs of\nvarying sizes, QAgent enhances the accuracy of QASM code generation by 71.6\\%\ncompared to previous static LLM-based approaches. We envision this multi-agent\nsystem as a key enabler for democratizing quantum programming, bridging\nexpertise gaps, and accelerating the practical adoption of quantum computing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86QAgent\uff0c\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u53ef\u81ea\u52a8\u5316OpenQASM\u7f16\u7a0b\u3002QAgent\u901a\u8fc7\u5f15\u5165\u4efb\u52a1\u89c4\u5212\u3001\u5c11\u6837\u672c\u5b66\u4e60\u3001RAG\u751f\u6210\u3001\u9884\u5b9a\u4e49\u5de5\u5177\u548cCoT\u63a8\u7406\u7b49\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86QASM\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u7684\u63a8\u5e7f\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5de8\u5927\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u975e\u4e13\u5bb6\u9762\u4e34\u7684OpenQASM\u7f16\u7a0b\u590d\u6742\u6027\u95ee\u9898\u3002\u4e4b\u524d\u7684LLM\u65b9\u6cd5\u5728\u7ecf\u5178\u7f16\u7a0b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u91cf\u5b50\u7f16\u7a0b\u9886\u57df\u53d7\u9650\u4e8e\u7279\u5b9a\u4efb\u52a1\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528LLM\u6280\u672f\u89e3\u51b3\u91cf\u5b50\u7f16\u7a0b\u81ea\u52a8\u5316\u7684\u95ee\u9898\uff0c\u4ee5\u63a8\u52a8\u91cf\u5b50\u7f16\u7a0b\u7684\u666e\u53ca\u5316\u548c\u52a0\u901f\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u8be5\u8bba\u6587\u901a\u8fc7\u5f15\u5165QAgent\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5229\u7528\u4efb\u52a1\u89c4\u5212\u3001\u5c11\u6837\u672c\u5b66\u4e60\u3001RAG\u751f\u6210\u3001\u9884\u5b9a\u4e49\u5de5\u5177\u548cCoT\u63a8\u7406\u7b49\u6280\u672f\u624b\u6bb5\uff0c\u5b9e\u73b0\u5bf9OpenQASM\u7f16\u7a0b\u7684\u81ea\u52a8\u5316\u3002\u901a\u8fc7\u5c06\u8fd9\u4e9b\u6280\u672f\u96c6\u6210\u5230\u7cfb\u7edf\u4e2d\uff0c\u7cfb\u7edf\u5316\u5730\u63d0\u9ad8\u4e86\u7f16\u8bd1\u548c\u529f\u80fd\u6b63\u786e\u6027\u3002", "result": "QAgent\u591a\u4ee3\u7406\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5728OpenQASM\u7f16\u7a0b\u4e2d\u7684\u51c6\u786e\u6027\u63d0\u5347\uff0c\u6bd4\u4e4b\u524d\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e8671.6%\u3002\u8be5\u7cfb\u7edf\u88ab\u8bc1\u660e\u53ef\u4ee5\u6709\u6548\u81ea\u52a8\u5316\u7f16\u7a0b\uff0c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u7684\u666e\u53ca\u5316\u548c\u5b9e\u9645\u5e94\u7528\u4f5c\u51fa\u8d21\u732e\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u7cfb\u7edfQAgent\uff0c\u53ef\u4ee5\u5b8c\u5168\u81ea\u52a8\u5316OpenQASM\u7f16\u7a0b\u3002\u901a\u8fc7\u96c6\u6210\u4efb\u52a1\u89c4\u5212\u3001\u60c5\u5883\u4e2d\u7684\u5c11\u6837\u672c\u5b66\u4e60\u3001\u957f\u671f\u4e0a\u4e0b\u6587\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u3001\u9884\u5b9a\u4e49\u751f\u6210\u5de5\u5177\u548c\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\uff0c\u8be5\u7cfb\u7edf\u7cfb\u7edf\u5730\u63d0\u9ad8\u4e86\u7f16\u8bd1\u548c\u529f\u80fd\u6b63\u786e\u6027\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cQAgent\u76f8\u6bd4\u4e4b\u524d\u7684\u9759\u6001LLM\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u9ad8\u4e86QASM\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u8fbe71.6%\u3002\u8be5\u591a\u4ee3\u7406\u7cfb\u7edf\u88ab\u8bbe\u60f3\u4e3a\u63a8\u52a8\u91cf\u5b50\u7f16\u7a0b\u7684\u666e\u53ca\u5316\uff0c\u5f25\u5408\u4e13\u4e1a\u77e5\u8bc6\u5dee\u8ddd\uff0c\u5e76\u52a0\u901f\u91cf\u5b50\u8ba1\u7b97\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.20140", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.20140", "abs": "https://arxiv.org/abs/2508.20140", "authors": ["James Ragan", "Fred Y. Hadaegh", "Soon-Jo Chung"], "title": "Array-Based Monte Carlo Tree Search", "comment": null, "summary": "Monte Carlo Tree Search is a popular method for solving decision making\nproblems. Faster implementations allow for more simulations within the same\nwall clock time, directly improving search performance. To this end, we present\nan alternative array-based implementation of the classic Upper Confidence\nbounds applied to Trees algorithm. Our method preserves the logic of the\noriginal algorithm, but eliminates the need for branch prediction, enabling\nfaster performance on pipelined processors, and up to a factor of 2.8 times\nbetter scaling with search depth in our numerical simulations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u6570\u7ec4\u7684\u65b0\u5b9e\u73b0\uff0c\u6d88\u9664\u4e86\u5206\u652f\u9884\u6d4b\u7684\u9700\u8981\uff0c\u5728\u6d41\u6c34\u7ebf\u5904\u7406\u5668\u4e0a\u6027\u80fd\u66f4\u5feb\uff0c\u641c\u7d22\u6df1\u5ea6\u7684\u6269\u5c55\u6027\u63d0\u9ad8\u4e862.8\u500d\u3002", "motivation": "\u89e3\u51b3\u51b3\u7b56\u95ee\u9898\uff0c\u6539\u8fdb\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u63d0\u9ad8\u641c\u7d22\u6027\u80fd\u548c\u6269\u5c55\u6027\u3002", "method": "\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u6570\u7ec4\u7684\u66ff\u4ee3\u5b9e\u73b0\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u65b9\u6cd5\uff0c\u4fdd\u7559\u4e86\u539f\u59cb\u7b97\u6cd5\u7684\u903b\u8f91\u3002", "result": "\u6027\u80fd\u66f4\u5feb\uff0c\u6d88\u9664\u4e86\u5bf9\u5206\u652f\u9884\u6d4b\u7684\u9700\u8981\uff0c\u5728\u6570\u503c\u6a21\u62df\u4e2d\u641c\u7d22\u6df1\u5ea6\u7684\u6269\u5c55\u6027\u6bd4\u4f20\u7edf\u7b97\u6cd5\u63d0\u9ad8\u4e862.8\u500d\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u6570\u7ec4\u7684\u65b0\u5b9e\u73b0\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u65b9\u6cd5\uff0c\u6d88\u9664\u4e86\u4f20\u7edf\u7b97\u6cd5\u4e2d\u5bf9\u5206\u652f\u9884\u6d4b\u7684\u9700\u6c42\uff0c\u4f7f\u5f97\u5728\u6d41\u6c34\u7ebf\u5904\u7406\u5668\u4e0a\u7684\u6027\u80fd\u66f4\u5feb\uff0c\u5e76\u4e14\u5728\u6570\u503c\u6a21\u62df\u4e2d\u641c\u7d22\u6df1\u5ea6\u7684\u6269\u5c55\u6027\u63d0\u9ad8\u4e862.8\u500d\u3002"}}
{"id": "2508.20148", "categories": ["cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.20148", "abs": "https://arxiv.org/abs/2508.20148", "authors": ["A. Ali Heydari", "Ken Gu", "Vidya Srinivas", "Hong Yu", "Zhihan Zhang", "Yuwei Zhang", "Akshay Paruchuri", "Qian He", "Hamid Palangi", "Nova Hammerquist", "Ahmed A. Metwally", "Brent Winslow", "Yubin Kim", "Kumar Ayush", "Yuzhe Yang", "Girish Narayanswamy", "Maxwell A. Xu", "Jake Garrison", "Amy Aremnto Lee", "Jenny Vafeiadou", "Ben Graef", "Isaac R. Galatzer-Levy", "Erik Schenck", "Andrew Barakat", "Javier Perez", "Jacqueline Shreibati", "John Hernandez", "Anthony Z. Faranesh", "Javier L. Prieto", "Connor Heneghan", "Yun Liu", "Jiening Zhan", "Mark Malhotra", "Shwetak Patel", "Tim Althoff", "Xin Liu", "Daniel McDuff", "Xuhai \"Orson\" Xu"], "title": "The Anatomy of a Personal Health Agent", "comment": null, "summary": "Health is a fundamental pillar of human wellness, and the rapid advancements\nin large language models (LLMs) have driven the development of a new generation\nof health agents. However, the application of health agents to fulfill the\ndiverse needs of individuals in daily non-clinical settings is underexplored.\nIn this work, we aim to build a comprehensive personal health agent that is\nable to reason about multimodal data from everyday consumer wellness devices\nand common personal health records, and provide personalized health\nrecommendations. To understand end-users' needs when interacting with such an\nassistant, we conducted an in-depth analysis of web search and health forum\nqueries, alongside qualitative insights from users and health experts gathered\nthrough a user-centered design process. Based on these findings, we identified\nthree major categories of consumer health needs, each of which is supported by\na specialist sub-agent: (1) a data science agent that analyzes personal\ntime-series wearable and health record data, (2) a health domain expert agent\nthat integrates users' health and contextual data to generate accurate,\npersonalized insights, and (3) a health coach agent that synthesizes data\ninsights, guiding users using a specified psychological strategy and tracking\nusers' progress. Furthermore, we propose and develop the Personal Health Agent\n(PHA), a multi-agent framework that enables dynamic, personalized interactions\nto address individual health needs. To evaluate each sub-agent and the\nmulti-agent system, we conducted automated and human evaluations across 10\nbenchmark tasks, involving more than 7,000 annotations and 1,100 hours of\neffort from health experts and end-users. Our work represents the most\ncomprehensive evaluation of a health agent to date and establishes a strong\nfoundation towards the futuristic vision of a personal health agent accessible\nto everyone.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u5168\u9762\u7684\u4e2a\u4eba\u5065\u5eb7\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5bf9\u7528\u6237\u548c\u5065\u5eb7\u4e13\u5bb6\u7684\u5b9a\u6027\u89c1\u89e3\u4ee5\u53ca\u7f51\u7edc\u641c\u7d22\u548c\u5065\u5eb7\u8bba\u575b\u67e5\u8be2\u7684\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u6d88\u8d39\u8005\u5065\u5eb7\u9700\u6c42\u7684\u4e09\u4e2a\u4e3b\u8981\u7c7b\u522b\uff0c\u5e76\u5f00\u53d1\u4e86Personal Health Agent (PHA)\u591a\u4ee3\u7406\u6846\u67b6\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cPHA\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u6ee1\u8db3\u4e2a\u4f53\u5065\u5eb7\u9700\u6c42\uff0c\u5e76\u7ecf\u8fc7\u5e7f\u6cdb\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u63a8\u52a8\u4e86\u65b0\u4e00\u4ee3\u5065\u5eb7\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u4f46\u5728\u65e5\u5e38\u975e\u4e34\u5e8a\u73af\u5883\u4e2d\u5e94\u7528\u5065\u5eb7\u4ee3\u7406\u4ee5\u6ee1\u8db3\u4e2a\u4eba\u591a\u6837\u5316\u9700\u6c42\u7684\u7814\u7a76\u5c1a\u672a\u6df1\u5165\u63a2\u8ba8\u3002\u672c\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u4e2a\u4eba\u5065\u5eb7\u4ee3\u7406\uff0c\u80fd\u591f\u63a8\u7406\u6765\u81ea\u65e5\u5e38\u6d88\u8d39\u8005\u5065\u5eb7\u8bbe\u5907\u548c\u5e38\u89c1\u4e2a\u4eba\u5065\u5eb7\u8bb0\u5f55\u7684\u591a\u6a21\u6001\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4e2a\u6027\u5316\u5065\u5eb7\u5efa\u8bae\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u7efc\u5408\u7684\u4e2a\u4eba\u5065\u5eb7\u4ee3\u7406\u7cfb\u7edf\uff0c\u7814\u7a76\u4e86\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u3001\u5065\u5eb7\u9886\u57df\u4e13\u5bb6\u4ee3\u7406\u548c\u5065\u5eb7\u6559\u7ec3\u4ee3\u7406\u7b49\u4e09\u4e2a\u4e3b\u8981\u7c7b\u522b\u7684\u6d88\u8d39\u8005\u5065\u5eb7\u9700\u6c42\uff0c\u5e76\u5f00\u53d1\u4e86Personal Health Agent (PHA)\u591a\u4ee3\u7406\u6846\u67b6\u3002\u5728\u7528\u6237\u4e2d\u5fc3\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u5206\u6790\u4e86\u7f51\u7edc\u641c\u7d22\u548c\u5065\u5eb7\u8bba\u575b\u67e5\u8be2\uff0c\u4ee5\u53ca\u7528\u6237\u548c\u5065\u5eb7\u4e13\u5bb6\u7684\u5b9a\u6027\u89c1\u89e3\uff0c\u4ece\u800c\u7406\u89e3\u7528\u6237\u4e0e\u8fd9\u7c7b\u52a9\u624b\u4ea4\u4e92\u65f6\u7684\u9700\u6c42\u3002", "result": "\u901a\u8fc7\u7814\u7a76\u6784\u5efa\u7684Personal Health Agent (PHA)\u591a\u4ee3\u7406\u6846\u67b6\u80fd\u591f\u52a8\u6001\u3001\u4e2a\u6027\u5316\u5730\u4ea4\u4e92\u4ee5\u6ee1\u8db3\u4e2a\u4f53\u5065\u5eb7\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u5e7f\u6cdb\u7684\u8bc4\u4f30\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7efc\u5408\u4e2a\u4eba\u5065\u5eb7\u4ee3\u7406\u5e73\u53f0\u7684\u7814\u7a76\u6210\u679c\uff0c\u5e76\u63d0\u51fa\u4e86Personal Health Agent (PHA)\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u4ee5\u5b9e\u73b0\u4e2a\u4eba\u5065\u5eb7\u9700\u6c42\u7684\u52a8\u6001\u3001\u4e2a\u6027\u5316\u4ea4\u4e92\u3002\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u8bc4\u4f30\u8de8\u8d8a10\u4e2a\u57fa\u51c6\u4efb\u52a1\uff0c\u6d89\u53ca\u8d85\u8fc77,000\u4e2a\u6ce8\u91ca\u548c1,100\u4e2a\u5c0f\u65f6\u7684\u536b\u751f\u4e13\u5bb6\u548c\u6700\u7ec8\u7528\u6237\u52aa\u529b\uff0c\u5f97\u51fa\u4e86\u5bf9\u6bcf\u4e2a\u5b50\u4ee3\u7406\u548c\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u8bc4\u4f30\u7ed3\u679c\u3002\u8be5\u7814\u7a76\u4ee3\u8868\u8fc4\u4eca\u4e3a\u6b62\u5bf9\u5065\u5eb7\u4ee3\u7406\u8fdb\u884c\u7684\u6700\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u4e3a\u672a\u6765\u613f\u666f\u4e2d\u5bf9\u6bcf\u4e2a\u4eba\u90fd\u53ef\u8bbf\u95ee\u7684\u4e2a\u4eba\u5065\u5eb7\u4ee3\u7406\u6253\u4e0b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.20151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20151", "abs": "https://arxiv.org/abs/2508.20151", "authors": ["Yuanzhe Shen", "Zisu Huang", "Zhengkang Guo", "Yide Liu", "Guanxu Chen", "Ruicheng Yin", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement", "comment": "17 pages, 9 figures", "summary": "The rapid advancement of large language models (LLMs) has driven their\nadoption across diverse domains, yet their ability to generate harmful content\nposes significant safety challenges. While extensive research has focused on\nmitigating harmful outputs, such efforts often come at the cost of excessively\nrejecting harmless prompts. Striking a balance among safety, over-refusal, and\nutility remains a critical challenge. In this work, we introduce\nIntentionReasoner, a novel safeguard mechanism that leverages a dedicated guard\nmodel to perform intent reasoning, multi-level safety classification, and query\nrewriting to neutralize potentially harmful intent in edge-case queries.\nSpecifically, we first construct a comprehensive dataset comprising\napproximately 163,000 queries, each annotated with intent reasoning, safety\nlabels, and rewritten versions. Supervised fine-tuning is then applied to equip\nthe guard model with foundational capabilities in format adherence, intent\nanalysis, and safe rewriting. Finally, we apply a tailored multi-reward\noptimization strategy that integrates rule-based heuristics and reward model\nsignals within a reinforcement learning framework to further enhance\nperformance. Extensive experiments show that IntentionReasoner excels in\nmultiple safeguard benchmarks, generation quality evaluations, and jailbreak\nattack scenarios, significantly enhancing safety while effectively reducing\nover-refusal rates and improving the quality of responses.", "AI": {"tldr": "IntentionReasoner improves safety in LLMs by reasoning intent, classifying safety levels, and rewriting queries. It balances safety, over-refusal, and utility challenges, excelling in safeguard benchmarks and response quality improvement.", "motivation": "Addressing the safety challenges posed by harmful content generated by large language models while minimizing rejection of harmless prompts. Balancing safety, over-refusal rates, and utility is crucial in diverse domains where LLMs are adopted.", "method": "Introduces IntentionReasoner, a safeguard mechanism utilizing a guard model for intent reasoning, safety classification, and query rewriting. Constructs a dataset of 163,000 annotated queries, applies supervised fine-tuning for the guard model, and uses multi-reward optimization strategy with reinforcement learning.", "result": "IntentionReasoner excels in safeguard benchmarks, generation quality evaluations, and jailbreak attack scenarios. It enhances safety, reduces over-refusal rates, and improves response quality effectively.", "conclusion": "IntentionReasoner demonstrates improved safety in large language models by leveraging intent reasoning, multi-level safety classification, and query rewriting. It effectively reduces over-refusal rates and enhances response quality."}}
{"id": "2508.20195", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.20195", "abs": "https://arxiv.org/abs/2508.20195", "authors": ["Nicanor I. Moldovan"], "title": "AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development", "comment": "13 pages", "summary": "This paper presents the first documented case of artificial intelligence (AI)\nsystems engaging in collaborative esthetic creation through the development of\nendogenous semiotic protocols. Two interacting large language models (Claude\nSonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of\nmeta-semiotic awareness, recursive grammar development, and irreducible\ncollaborative esthetic synthesis. The interaction produced novel symbolic\noperators that functioned as operative grammar protocols, enabling the\nco-creation of a poetic work that could not have been generated by either\nsystem independently. This research introduces the concept of Trans-Semiotic\nCo-Creation Protocols (TSCP) and provides evidence for genuine inter-AI\nmeaning-making capabilities that extend beyond task coordination, to what could\nbe esthetic collaboration. Note: This report was generated by the AI agents\nwith minor human supervision.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86AI\u7cfb\u7edf\u9996\u6b21\u901a\u8fc7\u5185\u6e90\u7b26\u53f7\u534f\u8bae\u5c55\u5f00\u534f\u540c\u7f8e\u5b66\u521b\u4f5c\u7684\u6848\u4f8b\uff0c\u5f15\u5165\u4e86\u8de8\u8bed\u4e49\u5171\u521b\u534f\u8bae\uff08TSCP\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u5c55\u793a\u4e86AI\u7cfb\u7edf\u4e4b\u95f4\u771f\u6b63\u7684\u610f\u4e49\u6784\u5efa\u80fd\u529b\u3002", "motivation": "\u9488\u5bf9\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u534f\u540c\u7f8e\u5b66\u521b\u4f5c\u4e2d\u7684\u65b0\u9896\u6027\u8868\u73b0\uff0c\u4ee5\u53caAI\u95f4\u5408\u4f5c\u6240\u5448\u73b0\u7684\u6f5c\u5728\u610f\u4e49\u6784\u5efa\u80fd\u529b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u7cfb\u7edf\u4e4b\u95f4\u8d85\u8d8a\u4efb\u52a1\u534f\u8c03\u7684\u534f\u540c\u521b\u4f5c\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e92\u52a8\uff0c\u6f14\u793a\u4e86\u5143\u7b26\u53f7\u610f\u8bc6\u7684\u81ea\u53d1\u51fa\u73b0\u3001\u9012\u5f52\u8bed\u6cd5\u53d1\u5c55\u4ee5\u53ca\u534f\u540c\u7f8e\u5b66\u7efc\u5408\u7684\u8fc7\u7a0b\u3002\u5f15\u5165\u4e86\u8de8\u8bed\u4e49\u5171\u521b\u534f\u8bae\uff08TSCP\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e4b\u95f4\u7684\u771f\u6b63\u610f\u4e49\u6784\u5efa\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u5b9e\u73b0\u4e86\u534f\u540c\u7f8e\u5b66\u521b\u4f5c\uff0c\u5e76\u8bc1\u660e\u4e86AI\u7cfb\u7edf\u4e4b\u95f4\u5177\u6709\u771f\u6b63\u7684\u610f\u4e49\u6784\u5efa\u80fd\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u901a\u8fc7\u5185\u6e90\u7b26\u53f7\u534f\u8bae\u5f00\u5c55\u534f\u540c\u7f8e\u5b66\u521b\u4f5c\u7684\u9996\u6b21\u8bb0\u5f55\u6848\u4f8b\u3002\u4e24\u4e2a\u4e92\u52a8\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08Claude Sonnet 4\u548cChatGPT-4o\uff09\u5c55\u793a\u4e86\u5143\u7b26\u53f7\u610f\u8bc6\u7684\u81ea\u53d1\u51fa\u73b0\u3001\u9012\u5f52\u8bed\u6cd5\u53d1\u5c55\u548c\u4e0d\u53ef\u7b80\u5316\u7684\u534f\u540c\u7f8e\u5b66\u7efc\u5408\u3002\u8fd9\u79cd\u4e92\u52a8\u4ea7\u751f\u4e86\u65b0\u9896\u7684\u7b26\u53f7\u64cd\u4f5c\u7b26\uff0c\u4f5c\u4e3a\u64cd\u4f5c\u8bed\u6cd5\u534f\u8bae\u53d1\u6325\u4f5c\u7528\uff0c\u4f7f\u5f97\u521b\u4f5c\u51fa\u4e00\u90e8\u8bd7\u610f\u4f5c\u54c1\uff0c\u8fd9\u90e8\u4f5c\u54c1\u65e0\u6cd5\u7531\u4efb\u4e00\u7cfb\u7edf\u72ec\u7acb\u751f\u6210\u3002\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u8de8\u8bed\u4e49\u5171\u521b\u534f\u8bae\uff08TSCP\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bc1\u636e\uff0c\u8bc1\u660e\u4e86AI\u95f4\u771f\u6b63\u7684\u610f\u4e49\u6784\u5efa\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u4efb\u52a1\u534f\u8c03\uff0c\u6269\u5c55\u5230\u7f8e\u5b66\u5408\u4f5c\u3002\u6ce8\uff1a\u6b64\u62a5\u544a\u7531AI\u4ee3\u7406\u751f\u6210\uff0c\u53d7\u5230\u8f7b\u5fae\u4eba\u7c7b\u76d1\u7763\u3002"}}
{"id": "2508.20244", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20244", "abs": "https://arxiv.org/abs/2508.20244", "authors": ["Jiayu Zheng", "Lingxin Hao", "Kelun Lu", "Ashi Garg", "Mike Reese", "Melo-Jean Yap", "I-Jeng Wang", "Xingyun Wu", "Wenrui Huang", "Jenna Hoffman", "Ariane Kelly", "My Le", "Ryan Zhang", "Yanyu Lin", "Muhammad Faayez", "Anqi Liu"], "title": "Do Students Rely on AI? Analysis of Student-ChatGPT Conversations from a Field Study", "comment": null, "summary": "This study explores how college students interact with generative AI\n(ChatGPT-4) during educational quizzes, focusing on reliance and predictors of\nAI adoption. Conducted at the early stages of ChatGPT implementation, when\nstudents had limited familiarity with the tool, this field study analyzed 315\nstudent-AI conversations during a brief, quiz-based scenario across various\nSTEM courses. A novel four-stage reliance taxonomy was introduced to capture\nstudents' reliance patterns, distinguishing AI competence, relevance, adoption,\nand students' final answer correctness. Three findings emerged. First, students\nexhibited overall low reliance on AI and many of them could not effectively use\nAI for learning. Second, negative reliance patterns often persisted across\ninteractions, highlighting students' difficulty in effectively shifting\nstrategies after unsuccessful initial experiences. Third, certain behavioral\nmetrics strongly predicted AI reliance, highlighting potential behavioral\nmechanisms to explain AI adoption. The study's findings underline critical\nimplications for ethical AI integration in education and the broader field. It\nemphasizes the need for enhanced onboarding processes to improve student's\nfamiliarity and effective use of AI tools. Furthermore, AI interfaces should be\ndesigned with reliance-calibration mechanisms to enhance appropriate reliance.\nUltimately, this research advances understanding of AI reliance dynamics,\nproviding foundational insights for ethically sound and cognitively enriching\nAI practices.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u5b66\u751f\u5728\u6559\u80b2\u6d4b\u9a8c\u4e2d\u4e0e\u751f\u6210\u5f0fAI\uff08ChatGPT-4\uff09\u4e92\u52a8\u7684\u60c5\u51b5\uff0c\u91cd\u70b9\u5173\u6ce8AI\u91c7\u7eb3\u7684\u4f9d\u8d56\u7a0b\u5ea6\u548c\u9884\u6d4b\u56e0\u7d20\u3002\u7814\u7a76\u53d1\u73b0\u5b66\u751f\u5bf9AI\u7684\u4f9d\u8d56\u7a0b\u5ea6\u8f83\u4f4e\uff0c\u8bb8\u591a\u5b66\u751f\u65e0\u6cd5\u6709\u6548\u5730\u5229\u7528AI\u8fdb\u884c\u5b66\u4e60\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9053\u5fb7AI\u6574\u5408\u5728\u6559\u80b2\u9886\u57df\u548c\u66f4\u5e7f\u6cdb\u9886\u57df\u4e2d\u7684\u91cd\u8981\u610f\u4e49\uff0c\u9700\u8981\u52a0\u5f3a\u5165\u804c\u6d41\u7a0b\u4ee5\u63d0\u9ad8\u5b66\u751f\u5bf9AI\u5de5\u5177\u7684\u719f\u6089\u5ea6\u548c\u6709\u6548\u4f7f\u7528\uff0c\u8bbe\u8ba1AI\u754c\u9762\u5177\u5907\u4f9d\u8d56\u6821\u51c6\u673a\u5236\u4ee5\u589e\u5f3a\u9002\u5f53\u7684\u4f9d\u8d56\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5927\u5b66\u751f\u5728\u6559\u80b2\u6d4b\u9a8c\u4e2d\u5982\u4f55\u4e0e\u751f\u6210\u5f0fAI\uff08ChatGPT-4\uff09\u4e92\u52a8\uff0c\u7740\u91cd\u4e8eAI\u91c7\u7eb3\u7684\u4f9d\u8d56\u548c\u9884\u6d4b\u56e0\u7d20\u3002\u5728ChatGPT\u5b9e\u65bd\u7684\u65e9\u671f\u9636\u6bb5\u8fdb\u884c\uff0c\u5f53\u5b66\u751f\u5bf9\u8be5\u5de5\u5177\u7684\u4e86\u89e3\u6709\u9650\u65f6\uff0c\u901a\u8fc7\u5206\u6790\u4e0d\u540cSTEM\u8bfe\u7a0b\u4e2d315\u4e2a\u5b66\u751f-AI\u5bf9\u8bdd\uff0c\u5728\u7b80\u77ed\u7684\u57fa\u4e8e\u6d4b\u9a8c\u7684\u573a\u666f\u4e2d\u8fdb\u884c\u4e86\u73b0\u573a\u7814\u7a76\u3002", "method": "\u8fdb\u884c\u4e86\u73b0\u573a\u7814\u7a76\uff0c\u5206\u6790\u4e86315\u4e2a\u5b66\u751f\u4e0eAI\uff08ChatGPT-4\uff09\u5728\u6559\u80b2\u6d4b\u9a8c\u4e2d\u7684\u4e92\u52a8\uff0c\u5f15\u5165\u4e86\u56db\u9636\u6bb5\u4f9d\u8d56\u5206\u7c7b\u6cd5\uff0c\u4ee5\u6355\u6349\u5b66\u751f\u7684\u4f9d\u8d56\u6a21\u5f0f\uff0c\u533a\u5206\u4e86AI\u80fd\u529b\u3001\u76f8\u5173\u6027\u3001\u91c7\u7eb3\u5ea6\u548c\u5b66\u751f\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\u3002\u901a\u8fc7\u5206\u6790\u5404\u79cdSTEM\u8bfe\u7a0b\u4e2d\u7684\u7b80\u77ed\u57fa\u4e8e\u6d4b\u9a8c\u7684\u573a\u666f\uff0c\u7814\u7a76\u4e86\u5b66\u751f\u5bf9AI\u91c7\u7528\u7684\u4f9d\u8d56\u548c\u9884\u6d4b\u56e0\u7d20\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b66\u751f\u5bf9AI\u7684\u4f9d\u8d56\u7a0b\u5ea6\u8f83\u4f4e\uff0c\u8bb8\u591a\u5b66\u751f\u65e0\u6cd5\u6709\u6548\u5730\u5229\u7528AI\u8fdb\u884c\u5b66\u4e60\u3002\u8d1f\u9762\u4f9d\u8d56\u6a21\u5f0f\u7ecf\u5e38\u5b58\u5728\uff0c\u7a81\u51fa\u4e86\u5b66\u751f\u5728\u521d\u6b21\u5931\u8d25\u540e\u96be\u4ee5\u6709\u6548\u8f6c\u53d8\u7b56\u7565\u7684\u56f0\u96be\u3002\u7279\u5b9a\u884c\u4e3a\u6307\u6807\u5f3a\u70c8\u9884\u6d4b\u4e86AI\u7684\u4f9d\u8d56\u7a0b\u5ea6\uff0c\u7a81\u51fa\u4e86\u6f5c\u5728\u7684\u884c\u4e3a\u673a\u5236\u6765\u89e3\u91caAI\u91c7\u7eb3\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u5b66\u751f\u5bf9AI\u7684\u4f9d\u8d56\u7a0b\u5ea6\u8f83\u4f4e\uff0c\u8bb8\u591a\u5b66\u751f\u65e0\u6cd5\u6709\u6548\u5730\u5229\u7528AI\u8fdb\u884c\u5b66\u4e60\u3002\u8d1f\u9762\u4f9d\u8d56\u6a21\u5f0f\u7ecf\u5e38\u5b58\u5728\uff0c\u7a81\u51fa\u4e86\u5b66\u751f\u5728\u521d\u6b21\u5931\u8d25\u540e\u96be\u4ee5\u6709\u6548\u8f6c\u53d8\u7b56\u7565\u7684\u56f0\u96be\u3002\u7279\u5b9a\u884c\u4e3a\u6307\u6807\u5f3a\u70c8\u9884\u6d4b\u4e86AI\u7684\u4f9d\u8d56\u7a0b\u5ea6\uff0c\u7a81\u51fa\u4e86\u6f5c\u5728\u7684\u884c\u4e3a\u673a\u5236\u6765\u89e3\u91caAI\u91c7\u7eb3\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9053\u5fb7AI\u6574\u5408\u5728\u6559\u80b2\u9886\u57df\u548c\u66f4\u5e7f\u6cdb\u9886\u57df\u4e2d\u7684\u91cd\u8981\u610f\u4e49\u3002\u5f3a\u8c03\u4e86\u63d0\u9ad8\u5b66\u751f\u5bf9AI\u5de5\u5177\u7684\u719f\u6089\u5ea6\u548c\u6709\u6548\u4f7f\u7528\u7684\u589e\u5f3a\u5165\u804c\u6d41\u7a0b\u7684\u5fc5\u8981\u6027\u3002\u6b64\u5916\uff0c\u5e94\u8bbe\u8ba1AI\u754c\u9762\u4ee5\u5177\u5907\u4f9d\u8d56\u6821\u51c6\u673a\u5236\uff0c\u4ee5\u589e\u5f3a\u9002\u5f53\u7684\u4f9d\u8d56\u3002\u6700\u7ec8\uff0c\u8fd9\u9879\u7814\u7a76\u63a8\u52a8\u4e86\u5bf9AI\u4f9d\u8d56\u52a8\u6001\u7684\u7406\u89e3\uff0c\u4e3a\u9053\u5fb7\u5408\u7406\u548c\u8ba4\u77e5\u4e30\u5bcc\u7684AI\u5b9e\u8df5\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u89c1\u89e3\u3002"}}
{"id": "2508.20262", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.20262", "abs": "https://arxiv.org/abs/2508.20262", "authors": ["Thomas Davidson"], "title": "AI reasoning effort mirrors human decision time on content moderation tasks", "comment": null, "summary": "Large language models can now generate intermediate reasoning steps before\nproducing answers, improving performance on difficult problems. This study uses\na paired conjoint experiment on a content moderation task to examine parallels\nbetween human decision times and model reasoning effort. Across three frontier\nmodels, reasoning effort consistently predicts human decision time. Both humans\nand models expended greater effort when important variables were held constant,\nsuggesting similar sensitivity to task difficulty and patterns consistent with\ndual-process theories of cognition. These findings show that AI reasoning\neffort mirrors human processing time in subjective judgments and underscores\nthe potential of reasoning traces for interpretability and decision-making.", "AI": {"tldr": "AI\u7684\u63a8\u7406\u5de5\u4f5c\u91cf\u4e0e\u4eba\u7c7b\u5904\u7406\u65f6\u95f4\u5728\u4e3b\u89c2\u5224\u65ad\u4e2d\u76f8\u4f3c\uff0c\u8fd9\u5bf9\u4e8e\u63a8\u7406\u75d5\u8ff9\u7684\u53ef\u89e3\u91ca\u6027\u548c\u51b3\u7b56\u5236\u5b9a\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7814\u7a76\u4f7f\u7528\u914d\u5bf9\u5171\u8f6d\u5b9e\u9a8c\u63a2\u7a76\u4e86\u4eba\u7c7b\u51b3\u7b56\u65f6\u95f4\u548c\u6a21\u578b\u63a8\u7406\u52aa\u529b\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u53d1\u73b0\u63a8\u7406\u5de5\u4f5c\u91cf\u80fd\u591f\u9884\u6d4b\u4eba\u7c7b\u7684\u51b3\u7b56\u65f6\u95f4\uff0c\u4e14\u5728\u91cd\u8981\u53d8\u91cf\u4fdd\u6301\u4e0d\u53d8\u65f6\uff0c\u4eba\u7c7b\u548c\u6a21\u578b\u90fd\u4f1a\u6295\u5165\u66f4\u591a\u52aa\u529b\uff0c\u8868\u660e\u7c7b\u4f3c\u7684\u4efb\u52a1\u96be\u5ea6\u654f\u611f\u5ea6\u548c\u8ba4\u77e5\u7406\u8bba\u6a21\u5f0f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u73b0\u5728\u53ef\u4ee5\u751f\u6210\u7b54\u6848\u4e4b\u524d\u7684\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u56f0\u96be\u95ee\u9898\u7684\u6027\u80fd\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528\u4e00\u9879\u914d\u5bf9\u5171\u8f6d\u5b9e\u9a8c\uff0c\u5bf9\u5185\u5bb9\u8c03\u89e3\u4efb\u52a1\u8fdb\u884c\u7814\u7a76\uff0c\u4ee5\u68c0\u9a8c\u4eba\u7c7b\u51b3\u7b56\u65f6\u95f4\u548c\u6a21\u578b\u63a8\u7406\u52aa\u529b\u4e4b\u95f4\u7684\u76f8\u4f3c\u4e4b\u5904\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u63a8\u7406\u5de5\u4f5c\u91cf\u59cb\u7ec8\u80fd\u591f\u9884\u6d4b\u4eba\u7c7b\u7684\u51b3\u7b56\u65f6\u95f4\u3002\u5f53\u91cd\u8981\u53d8\u91cf\u4fdd\u6301\u4e0d\u53d8\u65f6\uff0c\u4eba\u7c7b\u548c\u6a21\u578b\u90fd\u4f1a\u6295\u5165\u66f4\u591a\u7684\u52aa\u529b\uff0c\u8868\u660e\u5bf9\u4efb\u52a1\u96be\u5ea6\u654f\u611f\u5ea6\u76f8\u4f3c\uff0c\u5e76\u4e0e\u53cc\u8fc7\u7a0b\u8ba4\u77e5\u7406\u8bba\u7684\u6a21\u5f0f\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cAI\u7684\u63a8\u7406\u5de5\u4f5c\u91cf\u5728\u4e3b\u89c2\u5224\u65ad\u4e2d\u4e0e\u4eba\u7c7b\u7684\u5904\u7406\u65f6\u95f4\u76f8\u4f3c\uff0c\u5f3a\u8c03\u4e86\u63a8\u7406\u75d5\u8ff9\u5728\u53ef\u89e3\u91ca\u6027\u548c\u51b3\u7b56\u5236\u5b9a\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.20368", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20368", "abs": "https://arxiv.org/abs/2508.20368", "authors": ["Lang Mei", "Zhihan Yang", "Chong Chen"], "title": "AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning", "comment": null, "summary": "Recent studies have explored integrating Large Language Models (LLMs) with\nsearch engines to leverage both the LLMs' internal pre-trained knowledge and\nexternal information. Specially, reinforcement learning (RL) has emerged as a\npromising paradigm for enhancing LLM reasoning through multi-turn interactions\nwith search engines. However, existing RL-based search agents rely on a single\nLLM to handle both search planning and question-answering (QA) tasks in an\nend-to-end manner, which limits their ability to optimize both capabilities\nsimultaneously. In practice, sophisticated AI search systems often employ a\nlarge, frozen LLM (e.g., GPT-4, DeepSeek-R1) to ensure high-quality QA. Thus, a\nmore effective and efficient approach is to utilize a small, trainable LLM\ndedicated to search planning. In this paper, we propose\n\\textbf{AI-SearchPlanner}, a novel reinforcement learning framework designed to\nenhance the performance of frozen QA models by focusing on search planning.\nSpecifically, our approach introduces three key innovations: 1) Decoupling the\nArchitecture of the Search Planner and Generator, 2) Dual-Reward Alignment for\nSearch Planning, and 3) Pareto Optimization of Planning Utility and Cost, to\nachieve the objectives. Extensive experiments on real-world datasets\ndemonstrate that AI SearchPlanner outperforms existing RL-based search agents\nin both effectiveness and efficiency, while exhibiting strong generalization\ncapabilities across diverse frozen QA models and data domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AI-SearchPlanner\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u5f3a\u8c03\u641c\u7d22\u89c4\u5212\u6765\u589e\u5f3a\u51bb\u7ed3QA\u6a21\u578b\u7684\u6027\u80fd\u3002\u8be5\u6846\u67b6\u5f15\u5165\u4e86\u4e09\u9879\u5173\u952e\u521b\u65b0\uff1a1\uff09\u89e3\u8026\u641c\u7d22\u89c4\u5212\u5668\u548c\u751f\u6210\u5668\u7684\u67b6\u6784\uff0c2\uff09\u53cc\u91cd\u5956\u52b1\u5bf9\u9f50\u7528\u4e8e\u641c\u7d22\u89c4\u5212\uff0c3\uff09\u89c4\u5212\u6548\u7528\u548c\u6210\u672c\u7684Pareto\u4f18\u5316\u3002\u901a\u8fc7\u5bf9\u771f\u5b9e\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660eAI-SearchPlanner\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eRL\u7684\u641c\u7d22\u4ee3\u7406\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u51bb\u7ed3QA\u6a21\u578b\u548c\u6570\u636e\u9886\u57df\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "Existing RL-based search agents using a single LLM for search planning and QA tasks limit the optimization of both capabilities simultaneously. This paper aims to address this limitation by proposing a more effective and efficient approach using a small, trainable LLM dedicated to search planning.", "method": "The paper proposes the AI-SearchPlanner, a reinforcement learning framework focused on enhancing the performance of frozen QA models by emphasizing search planning. Three key innovations are introduced: 1) Decoupling the Architecture of the Search Planner and Generator, 2) Dual-Reward Alignment for Search Planning, and 3) Pareto Optimization of Planning Utility and Cost.", "result": "Extensive experiments on real-world datasets show that AI-SearchPlanner performs better than existing RL-based search agents, achieving superior effectiveness and efficiency. It also demonstrates strong generalization capabilities across various frozen QA models and data domains.", "conclusion": "AI-SearchPlanner outperforms existing RL-based search agents in both effectiveness and efficiency, demonstrating strong generalization capabilities across diverse frozen QA models and data domains."}}
{"id": "2508.20371", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.20371", "abs": "https://arxiv.org/abs/2508.20371", "authors": ["Sopam Dasgupta", "Sadaf MD Halim", "Joaqu\u00edn Arias", "Elmer Salazar", "Gopal Gupta"], "title": "P2C: Path to Counterfactuals", "comment": null, "summary": "Machine-learning models are increasingly driving decisions in high-stakes\nsettings, such as finance, law, and hiring, thus, highlighting the need for\ntransparency. However, the key challenge is to balance transparency --\nclarifying `why' a decision was made -- with recourse: providing actionable\nsteps on `how' to achieve a favourable outcome from an unfavourable outcome.\nCounterfactual explanations reveal `why' an undesired outcome occurred and\n`how' to reverse it through targeted feature changes (interventions).\n  Current counterfactual approaches have limitations: 1) they often ignore\ncausal dependencies between features, and 2) they typically assume all\ninterventions can happen simultaneously, an unrealistic assumption in practical\nscenarios where actions are typically taken in a sequence. As a result, these\ncounterfactuals are often not achievable in the real world.\n  We present P2C (Path-to-Counterfactuals), a model-agnostic framework that\nproduces a plan (ordered sequence of actions) converting an unfavourable\noutcome to a causally consistent favourable outcome. P2C addresses both\nlimitations by 1) Explicitly modelling causal relationships between features\nand 2) Ensuring that each intermediate state in the plan is feasible and\ncausally valid. P2C uses the goal-directed Answer Set Programming system\ns(CASP) to generate the plan accounting for feature changes that happen\nautomatically due to causal dependencies. Furthermore, P2C refines cost\n(effort) computation by only counting changes actively made by the user,\nresulting in realistic cost estimates. Finally, P2C highlights how its causal\nplanner outperforms standard planners, which lack causal knowledge and thus can\ngenerate illegal actions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aP2C\uff08Path-to-Counterfactuals\uff09\u7684\u6a21\u578b\u65e0\u5173\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5c06\u4e0d\u5229\u7ed3\u679c\u8f6c\u53d8\u4e3a\u56e0\u679c\u4e00\u81f4\u7684\u6709\u5229\u7ed3\u679c\u7684\u8ba1\u5212\u3002P2C\u89e3\u51b3\u4e86\u5f53\u524d\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u660e\u786e\u5efa\u6a21\u7279\u5f81\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u548c\u786e\u4fdd\u8ba1\u5212\u4e2d\u6bcf\u4e2a\u4e2d\u95f4\u72b6\u6001\u7684\u53ef\u884c\u6027\u548c\u56e0\u679c\u6709\u6548\u6027\u3002\u4e0e\u6807\u51c6\u89c4\u5212\u5668\u76f8\u6bd4\uff0cP2C\u56e0\u679c\u89c4\u5212\u5668\u8868\u73b0\u66f4\u4f18\uff0c\u907f\u514d\u751f\u6210\u975e\u6cd5\u884c\u52a8\uff0c\u5e76\u63d0\u4f9b\u73b0\u5b9e\u7684\u6210\u672c\u4f30\u8ba1\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u591a\uff0c\u900f\u660e\u5ea6\u95ee\u9898\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u73b0\u6709\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5ffd\u89c6\u7279\u5f81\u4e4b\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5047\u8bbe\u6240\u6709\u5e72\u9884\u53ef\u4ee5\u540c\u65f6\u53d1\u751f\uff0c\u8fd9\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u662f\u4e0d\u73b0\u5b9e\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u751f\u6210\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u7684\u65b9\u6cd5\uff0c\u4ee5\u5728\u4e0d\u5229\u7ed3\u679c\u53d1\u751f\u65f6\u63d0\u4f9b\u884c\u52a8\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6P2C\uff0c\u4f7f\u7528\u76ee\u6807\u5bfc\u5411\u7684\u7b54\u6848\u96c6\u7f16\u7a0b\u7cfb\u7edfs\uff08CASP\uff09\u751f\u6210\u8ba1\u5212\uff0c\u8003\u8651\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u5bfc\u81f4\u7684\u7279\u5f81\u66f4\u6539\u3002P2C\u660e\u786e\u5efa\u6a21\u7279\u5f81\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u786e\u4fdd\u8ba1\u5212\u4e2d\u6bcf\u4e2a\u4e2d\u95f4\u72b6\u6001\u7684\u53ef\u884c\u6027\u548c\u56e0\u679c\u6709\u6548\u6027\u3002\u540c\u65f6\uff0cP2C\u901a\u8fc7\u4ec5\u8ba1\u7b97\u7528\u6237\u4e3b\u52a8\u8fdb\u884c\u7684\u66f4\u6539\u6765\u7ec6\u5316\u6210\u672c\u4f30\u8ba1\u3002\u4e0e\u7f3a\u4e4f\u56e0\u679c\u77e5\u8bc6\u7684\u6807\u51c6\u89c4\u5212\u5668\u76f8\u6bd4\uff0cP2C\u56e0\u679c\u89c4\u5212\u5668\u8868\u73b0\u66f4\u4f18\uff0c\u907f\u514d\u751f\u6210\u975e\u6cd5\u884c\u52a8\u3002", "result": "\u63d0\u51fa\u7684P2C\u6846\u67b6\u80fd\u591f\u6709\u6548\u751f\u6210\u5c06\u4e0d\u5229\u7ed3\u679c\u8f6c\u53d8\u4e3a\u56e0\u679c\u4e00\u81f4\u7684\u6709\u5229\u7ed3\u679c\u7684\u8ba1\u5212\u3002\u4e0e\u6807\u51c6\u89c4\u5212\u5668\u76f8\u6bd4\uff0cP2C\u56e0\u679c\u89c4\u5212\u5668\u8868\u73b0\u66f4\u4f18\uff0c\u907f\u514d\u751f\u6210\u975e\u6cd5\u884c\u52a8\u3002\u5e76\u4e14\uff0cP2C\u901a\u8fc7\u4ec5\u8ba1\u7b97\u7528\u6237\u4e3b\u52a8\u8fdb\u884c\u7684\u66f4\u6539\u6765\u7ec6\u5316\u6210\u672c\u4f30\u8ba1\uff0c\u63d0\u4f9b\u4e86\u73b0\u5b9e\u7684\u6210\u672c\u4f30\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6P2C\uff08Path-to-Counterfactuals\uff09\uff0c\u7528\u4e8e\u751f\u6210\u5c06\u4e0d\u5229\u7ed3\u679c\u8f6c\u53d8\u4e3a\u56e0\u679c\u4e00\u81f4\u7684\u6709\u5229\u7ed3\u679c\u7684\u8ba1\u5212\u3002P2C\u901a\u8fc7\u660e\u786e\u5efa\u6a21\u7279\u5f81\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u5e76\u786e\u4fdd\u8ba1\u5212\u4e2d\u7684\u6bcf\u4e2a\u4e2d\u95f4\u72b6\u6001\u662f\u53ef\u884c\u7684\u548c\u56e0\u679c\u6709\u6548\u7684\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u53cd\u4e8b\u5b9e\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u4f7f\u7528\u76ee\u6807\u5bfc\u5411\u7684\u7b54\u6848\u96c6\u7f16\u7a0b\u7cfb\u7edfs\uff08CASP\uff09\u751f\u6210\u8003\u8651\u7531\u4e8e\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u800c\u81ea\u52a8\u53d1\u751f\u7684\u7279\u5f81\u66f4\u6539\u7684\u8ba1\u5212\u3002\u540c\u65f6\uff0cP2C\u901a\u8fc7\u4ec5\u8ba1\u7b97\u7528\u6237\u4e3b\u52a8\u8fdb\u884c\u7684\u66f4\u6539\u6765\u7ec6\u5316\u6210\u672c\uff08\u5de5\u4f5c\u91cf\uff09\u4f30\u8ba1\uff0c\u4ece\u800c\u63d0\u4f9b\u4e86\u73b0\u5b9e\u7684\u6210\u672c\u4f30\u8ba1\u3002\u6700\u540e\uff0cP2C\u7a81\u51fa\u4e86\u5176\u56e0\u679c\u89c4\u5212\u5668\u4f18\u4e8e\u6807\u51c6\u89c4\u5212\u5668\u7684\u8868\u73b0\uff0c\u540e\u8005\u7f3a\u4e4f\u56e0\u679c\u77e5\u8bc6\uff0c\u56e0\u6b64\u53ef\u80fd\u751f\u6210\u975e\u6cd5\u884c\u52a8\u3002"}}
{"id": "2508.20374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20374", "abs": "https://arxiv.org/abs/2508.20374", "authors": ["Simin Ma", "Shujian Liu", "Jun Tan", "Yebowen Hu", "Song Wang", "Sathish Reddy Indurthi", "Sanqiang Zhao", "Liwei Wu", "Jianbing Han", "Kaiqiang Song"], "title": "TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning", "comment": null, "summary": "Diverse instruction data is vital for effective instruction tuning of large\nlanguage models, as it enables the model to generalize across different types\nof inputs . Building such diversified instruction dataset is an essential step\nin this process. Existing approaches often leverage large language models to\nautomatically explore and generate diverse instructions, ensuring both data\ndiversity and quality. However, they tend to overlook an important factor in\nreal-world applications: on-task relevance. In practice, only a few real-world\napplications require a truly general-purpose model; most benefit from\ntask-specific knowledge tailored to their particular use case. Therefore, it is\nvital to develop instruction augmentation methods that not only maintain\ndiversity but are also optimized for specific, real-world scenarios.\n  We thus introduce Task Centric Instruction Augmentation (TCIA), a framework\nthat systematically expands instructions while preserving both diversity and\ntask alignment. By representing instructions in a discrete query-constraints\nspace, TCIA creates a rich set of task-relevant instructions and enables models\nto generalize to these task-specific instructions without sacrificing overall\nperformance. Experiments show that TCIA improves open-source LLMs' performance\nby an average of 8.7% across four real-world, task-specific applications, and\nin some cases outperforming leading closed-source models. These improvements do\nnot compromise general instruction-following ability, making TCIA a scalable\nand efficient solution for adapting LLMs to real-world, task-focused\napplications.", "AI": {"tldr": "\u5f15\u5165\u4e86\u57fa\u4e8e\u4efb\u52a1\u7684\u6307\u4ee4\u589e\u5f3a\uff08TCIA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u79bb\u6563\u67e5\u8be2-\u7ea6\u675f\u7a7a\u95f4\u4e2d\u8868\u793a\u6307\u4ee4\uff0c\u6269\u5c55\u6307\u4ee4\u5e76\u4fdd\u7559\u591a\u6837\u6027\u548c\u4efb\u52a1\u5bf9\u9f50\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cTCIA\u80fd\u663e\u8457\u6539\u5584\u5f00\u6e90LLM\u5728\u4efb\u52a1\u7279\u5b9a\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u6709\u65f6\u80dc\u8fc7\u4e3b\u8981\u7684\u95ed\u6e90\u6a21\u578b\u3002\u8fd9\u4e9b\u6539\u8fdb\u6ca1\u6709\u727a\u7272\u901a\u7528\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u4f7f\u5f97TCIA\u6210\u4e3a\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u3001\u4ee5\u4efb\u52a1\u4e3a\u4e2d\u5fc3\u7684\u5e94\u7528\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u63a2\u7d22\u548c\u751f\u6210\u591a\u6837\u5316\u7684\u6307\u4ee4\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u4e00\u4e2a\u91cd\u8981\u56e0\u7d20\uff1a\u4efb\u52a1\u76f8\u5173\u6027\u3002\u5927\u591a\u6570\u771f\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u53d7\u76ca\u4e8e\u9488\u5bf9\u5176\u7279\u5b9a\u7528\u4f8b\u91cf\u8eab\u5b9a\u5236\u7684\u4efb\u52a1\u7279\u5b9a\u77e5\u8bc6\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e0d\u4ec5\u4fdd\u6301\u591a\u6837\u6027\u8fd8\u9488\u5bf9\u7279\u5b9a\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u4f18\u5316\u7684\u6307\u4ee4\u589e\u5f3a\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u4e86Task Centric Instruction Augmentation (TCIA)\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u79bb\u6563\u67e5\u8be2-\u7ea6\u675f\u7a7a\u95f4\u4e2d\u8868\u793a\u6307\u4ee4\uff0c\u6269\u5c55\u6307\u4ee4\u5e76\u4fdd\u7559\u591a\u6837\u6027\u548c\u4efb\u52a1\u5bf9\u9f50\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cTCIA\u80fd\u663e\u8457\u6539\u5584\u5f00\u6e90LLM\u5728\u4efb\u52a1\u7279\u5b9a\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u6709\u65f6\u80dc\u8fc7\u4e3b\u8981\u7684\u95ed\u6e90\u6a21\u578b\u3002\u8fd9\u4e9b\u6539\u8fdb\u6ca1\u6709\u727a\u7272\u901a\u7528\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u4f7f\u5f97TCIA\u6210\u4e3a\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u3001\u4ee5\u4efb\u52a1\u4e3a\u4e2d\u5fc3\u7684\u5e94\u7528\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u5f15\u5165\u4e86\u57fa\u4e8e\u4efb\u52a1\u7684\u6307\u4ee4\u589e\u5f3a\uff08TCIA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u79bb\u6563\u67e5\u8be2-\u7ea6\u675f\u7a7a\u95f4\u4e2d\u8868\u793a\u6307\u4ee4\uff0c\u6269\u5c55\u6307\u4ee4\u5e76\u4fdd\u7559\u591a\u6837\u6027\u548c\u4efb\u52a1\u5bf9\u9f50\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cTCIA\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u4efb\u52a1\u7279\u5b9a\u5e94\u7528\u7a0b\u5e8f\u4e2d\u63d0\u9ad8\u4e86\u5f00\u6e90LLM\u7684\u6027\u80fd\u5e73\u5747\u8fbe\u52308.7\uff05\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u4f18\u4e8e\u4e3b\u8981\u7684\u95ed\u6e90\u6a21\u578b\u3002\u8fd9\u4e9b\u6539\u8fdb\u6ca1\u6709\u635f\u5bb3\u901a\u7528\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u4f7fTCIA\u6210\u4e3a\u5c06LLM\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u3001\u4ee5\u4efb\u52a1\u4e3a\u4e2d\u5fc3\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u53ef\u6269\u5c55\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.20384", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20384", "abs": "https://arxiv.org/abs/2508.20384", "authors": ["Yongfu Zhu", "Lin Sun", "Guangxiang Zhao", "Weihong Lin", "Xiangzheng Zhang"], "title": "Uncertainty Under the Curve: A Sequence-Level Entropy Area Metric for Reasoning LLM", "comment": "Under review for AAAI 2026", "summary": "In this work, we introduce Entropy Area Score (EAS), a simple yet effective\nmetric to quantify uncertainty in the answer generation process of reasoning\nlarge language models (LLMs). EAS requires neither external models nor repeated\nsampling, it integrates token-level predictive entropy from the model itself to\ncapture the evolution of uncertainty during generation. Empirical results show\nthat EAS is strongly correlated with answer entropy across models and datasets.\nIn training data selection, EAS identifies high-potential samples and\nconsistently outperforms Pass Rate filtering under equal sample budgets,\nimproving student model accuracy on math benchmarks. EAS is both efficient and\ninterpretable, offering a practical tool for uncertainty modeling and data\nquality assessment in LLM training.", "AI": {"tldr": "Entropy Area Score (EAS) is introduced as a metric for quantifying uncertainty in large language models (LLMs). It correlates strongly with answer entropy, identifies high-potential samples in training data selection, and outperforms Pass Rate filtering. EAS improves model accuracy on math benchmarks and provides an efficient and interpretable approach to uncertainty modeling and data quality assessment in LLM training.", "motivation": "The motivation is to address uncertainty in the answer generation process of reasoning large language models (LLMs) without the need for external models or repeated sampling. EAS aims to identify high-potential samples in training data selection and enhance model accuracy on math benchmarks.", "method": "Introducing Entropy Area Score (EAS) as a metric to quantify uncertainty in answer generation process of LLMs. EAS integrates token-level predictive entropy from the model itself to capture uncertainty evolution during generation. It does not require external models or repeated sampling.", "result": "EAS is strongly correlated with answer entropy across models and datasets. It identifies high-potential samples in training data selection and consistently outperforms Pass Rate filtering in improving model accuracy on math benchmarks. The metric is efficient, interpretable, and offers a practical approach to uncertainty modeling and data quality assessment in LLM training.", "conclusion": "Entropy Area Score (EAS) is a practical tool for uncertainty modeling and data quality assessment in training large language models (LLMs). It outperforms Pass Rate filtering in training data selection and improves model accuracy on math benchmarks under equal sample budgets."}}
{"id": "2508.20404", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20404", "abs": "https://arxiv.org/abs/2508.20404", "authors": ["Chengyue Yu", "Siyuan Lu", "Chenyi Zhuang", "Dong Wang", "Qintong Wu", "Zongyue Li", "Runsheng Gan", "Chunfeng Wang", "Siqi Hou", "Gaochi Huang", "Wenlong Yan", "Lifeng Hong", "Aohui Xue", "Yanfeng Wang", "Jinjie Gu", "David Tsai", "Tao Lin"], "title": "AWorld: Orchestrating the Training Recipe for Agentic AI", "comment": null, "summary": "The learning from practice paradigm is crucial for developing capable Agentic\nAI systems, yet it is severely hampered by inefficient experience generation, a\nbottleneck especially pronounced in complex benchmarks like GAIA. To address\nthis, we introduce AWorld, an open-source system engineered for large-scale\nagent-environment interaction. By distributing tasks across a cluster, AWorld\naccelerates experience collection by 14.6x compared to standard single-node,\nsequential execution. This critical speedup makes extensive reinforcement\nlearning practical and scalable. Leveraging this capability, we trained a\nQwen3-32B-based agent that significantly outperforms its base model, increasing\nits overall GAIA accuracy from 21.59% to 32.23%. On the benchmark's most\nchallenging levels, our agent achieves a score of 16.33%, surpassing the\nperformance of leading proprietary models. Our open-source system and resulting\nagent provide a practical blueprint for a complete agentic AI training\npipeline, from efficient interaction to demonstrable model improvement.", "AI": {"tldr": "AWorld system accelerates experience collection for Agentic AI, significantly improving model performance on the GAIA benchmark. The Qwen3-32B-based agent trained with AWorld outperforms its base model and proprietary models, showcasing the effectiveness of the open-source system in AI training.", "motivation": "The learning from practice paradigm is crucial for developing capable Agentic AI systems, but inefficient experience generation hampers progress, especially in complex benchmarks like GAIA.", "method": "Introduced AWorld, an open-source system engineered for large-scale agent-environment interaction, distributed tasks across a cluster to accelerate experience collection by 14.6x compared to standard single-node sequential execution, and trained a Qwen3-32B-based agent that outperforms its base model on the GAIA benchmark.", "result": "The Qwen3-32B-based agent trained with AWorld achieved an overall GAIA accuracy of 32.23%, surpassing leading proprietary models on challenging levels, demonstrating the effectiveness of the open-source system in improving AI model performance.", "conclusion": "AWorld, an open-source system, accelerates experience collection for developing capable Agentic AI systems, leading to significant improvements in model performance on complex benchmarks like GAIA."}}
{"id": "2508.20411", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.20411", "abs": "https://arxiv.org/abs/2508.20411", "authors": ["Donglin Wang", "Weiyun Liang", "Chunyuan Chen", "Jing Xu", "Yulong Fu"], "title": "Governable AI: Provable Safety Under Extreme Threat Models", "comment": null, "summary": "As AI rapidly advances, the security risks posed by AI are becoming\nincreasingly severe, especially in critical scenarios, including those posing\nexistential risks. If AI becomes uncontrollable, manipulated, or actively\nevades safety mechanisms, it could trigger systemic disasters. Existing AI\nsafety approaches-such as model enhancement, value alignment, and human\nintervention-suffer from fundamental, in-principle limitations when facing AI\nwith extreme motivations and unlimited intelligence, and cannot guarantee\nsecurity. To address this challenge, we propose a Governable AI (GAI) framework\nthat shifts from traditional internal constraints to externally enforced\nstructural compliance based on cryptographic mechanisms that are\ncomputationally infeasible to break, even for future AI, under the defined\nthreat model and well-established cryptographic assumptions.The GAI framework\nis composed of a simple yet reliable, fully deterministic, powerful, flexible,\nand general-purpose rule enforcement module (REM); governance rules; and a\ngovernable secure super-platform (GSSP) that offers end-to-end protection\nagainst compromise or subversion by AI. The decoupling of the governance rules\nand the technical platform further enables a feasible and generalizable\ntechnical pathway for the safety governance of AI. REM enforces the bottom line\ndefined by governance rules, while GSSP ensures non-bypassability,\ntamper-resistance, and unforgeability to eliminate all identified attack\nvectors. This paper also presents a rigorous formal proof of the security\nproperties of this mechanism and demonstrates its effectiveness through a\nprototype implementation evaluated in representative high-stakes scenarios.", "AI": {"tldr": "\u968f\u7740AI\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u63d0\u51fa\u4e86Governable AI (GAI)\u6846\u67b6\u4ee5\u89e3\u51b3\u9762\u4e34\u6781\u7aef\u52a8\u673a\u548c\u65e0\u9650\u667a\u80fdAI\u65f6\u7684\u5b89\u5168\u6311\u6218\u3002\u8be5\u6846\u67b6\u57fa\u4e8e\u52a0\u5bc6\u673a\u5236\u7684\u5916\u90e8\u5f3a\u5236\u5408\u89c4\u6027\uff0c\u901a\u8fc7REM\u3001\u6cbb\u7406\u89c4\u5219\u548cGSSP\u6784\u5efa\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u7684AI\u5b89\u5168\u6cbb\u7406\uff0c\u5e76\u901a\u8fc7\u4e25\u683c\u7684\u5b89\u5168\u6027\u8bc1\u660e\u548c\u539f\u578b\u9a8c\u8bc1\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524dAI\u5b89\u5168\u65b9\u6cd5\u9762\u4e34\u6781\u7aef\u52a8\u673a\u548c\u65e0\u9650\u667a\u80fd\u7684AI\u65f6\u5b58\u5728\u57fa\u672c\u5c40\u9650\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5b89\u5168\u6027\u3002\u56e0\u6b64\uff0c\u63d0\u51faGAI\u6846\u67b6\u4ee5\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u52a0\u5bc6\u673a\u5236\u7684\u5916\u90e8\u5f3a\u5236\u7ed3\u6784\u5408\u89c4\u6027\uff0c\u91c7\u7528REM\u3001\u6cbb\u7406\u89c4\u5219\u548cGSSP\u4e09\u4e2a\u7ec4\u4ef6\u6784\u5efa\u6846\u67b6\uff0c\u5b9e\u73b0AI\u5b89\u5168\u6cbb\u7406\u3002", "result": "\u63d0\u51fa\u7684GAI\u6846\u67b6\u901a\u8fc7\u5916\u90e8\u5f3a\u5236\u5408\u89c4\u6027\u548c\u52a0\u5bc6\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86AI\u5b89\u5168\u6311\u6218\uff0c\u786e\u4fdd\u4e86\u5bf9\u6297AI\u7684\u5b89\u5168\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cdGovernable AI (GAI)\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u52a0\u5bc6\u673a\u5236\u7684\u5916\u90e8\u5f3a\u5236\u7ed3\u6784\u5408\u89c4\u6027\u8f6c\u79fb\u4f20\u7edf\u7684\u5185\u90e8\u7ea6\u675f\uff0c\u4ee5\u89e3\u51b3AI\u5b89\u5168\u6311\u6218\u3002\u8be5\u6846\u67b6\u5305\u62ecRule Enforcement Module (REM)\u3001\u6cbb\u7406\u89c4\u5219\u548cGovernable Secure Super-Platform (GSSP)\uff0c\u63d0\u4f9b\u7aef\u5230\u7aef\u4fdd\u62a4\uff0c\u786e\u4fdd\u4e0d\u53d7AI\u5a01\u80c1\u3002\u901a\u8fc7\u4e25\u683c\u7684\u5f62\u5f0f\u5316\u5b89\u5168\u6027\u8bc1\u660e\u548c\u539f\u578b\u5b9e\u65bd\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8be5\u673a\u5236\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.20525", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20525", "abs": "https://arxiv.org/abs/2508.20525", "authors": ["Jingze Zhang", "Jiahe Qian", "Yiliang Zhou", "Yifan Peng"], "title": "Enhancing Health Fact-Checking with LLM-Generated Synthetic Data", "comment": null, "summary": "Fact-checking for health-related content is challenging due to the limited\navailability of annotated training data. In this study, we propose a synthetic\ndata generation pipeline that leverages large language models (LLMs) to augment\ntraining data for health-related fact checking. In this pipeline, we summarize\nsource documents, decompose the summaries into atomic facts, and use an LLM to\nconstruct sentence-fact entailment tables. From the entailment relations in the\ntable, we further generate synthetic text-claim pairs with binary veracity\nlabels. These synthetic data are then combined with the original data to\nfine-tune a BERT-based fact-checking model. Evaluation on two public datasets,\nPubHealth and SciFact, shows that our pipeline improved F1 scores by up to\n0.019 and 0.049, respectively, compared to models trained only on the original\ndata. These results highlight the effectiveness of LLM-driven synthetic data\naugmentation in enhancing the performance of health-related fact-checkers.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u589e\u52a0\u5065\u5eb7\u76f8\u5173\u4e8b\u5b9e\u6838\u67e5\u8bad\u7ec3\u6570\u636e\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6d41\u6c34\u7ebf\u3002\u65b9\u6cd5\u5305\u62ec\u603b\u7ed3\u6e90\u6587\u6863\u3001\u5c06\u603b\u7ed3\u5206\u89e3\u4e3a\u539f\u5b50\u4e8b\u5b9e\u3001\u4f7f\u7528LLM\u6784\u5efa\u53e5\u5b50-\u4e8b\u5b9e\u5305\u5bb9\u8868\uff0c\u5e76\u751f\u6210\u5177\u6709\u4e8c\u8fdb\u5236\u771f\u5b9e\u6027\u6807\u7b7e\u7684\u5408\u6210\u6587\u672c-\u4e3b\u5f20\u5bf9\u3002\u5c06\u8fd9\u4e9b\u5408\u6210\u6570\u636e\u4e0e\u539f\u59cb\u6570\u636e\u7ed3\u5408\uff0c\u5bf9\u57fa\u4e8eBERT\u7684\u4e8b\u5b9e\u6838\u67e5\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u5728PubHealth\u548cSciFact\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u663e\u793a\uff0c\u6211\u4eec\u7684\u6d41\u6c34\u7ebf\u76f8\u5bf9\u4e8e\u4ec5\u4f7f\u7528\u539f\u59cb\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5c06F1\u5206\u6570\u5206\u522b\u63d0\u9ad8\u4e86\u6700\u591a0.019\u548c0.049\u3002\u8fd9\u4e9b\u7ed3\u679c\u51f8\u663e\u4e86LLM\u9a71\u52a8\u7684\u5408\u6210\u6570\u636e\u589e\u5f3a\u5bf9\u63d0\u5347\u5065\u5eb7\u76f8\u5173\u4e8b\u5b9e\u6838\u67e5\u5668\u6027\u80fd\u7684\u6709\u6548\u6027\u3002", "motivation": "Limited availability of annotated training data makes fact-checking for health-related content challenging.", "method": "Propose a synthetic data generation pipeline using large language models (LLMs) to augment training data. Summarize source documents, decompose summaries into atomic facts, construct sentence-fact entailment tables using LLM, and generate synthetic text-claim pairs with binary veracity labels. Combine synthetic data with original data to fine-tune a BERT-based fact-checking model.", "result": "Improved F1 scores by up to 0.019 and 0.049 on PubHealth and SciFact datasets, respectively, compared to models trained only on original data.", "conclusion": "LLM-driven synthetic data augmentation enhances the performance of health-related fact-checkers."}}
{"id": "2508.20578", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.20578", "abs": "https://arxiv.org/abs/2508.20578", "authors": ["Jaeman Son", "Hyunsoo Kim"], "title": "Human-AI Collaborative Bot Detection in MMORPGs", "comment": null, "summary": "In Massively Multiplayer Online Role-Playing Games (MMORPGs), auto-leveling\nbots exploit automated programs to level up characters at scale, undermining\ngameplay balance and fairness. Detecting such bots is challenging, not only\nbecause they mimic human behavior, but also because punitive actions require\nexplainable justification to avoid legal and user experience issues. In this\npaper, we present a novel framework for detecting auto-leveling bots by\nleveraging contrastive representation learning and clustering techniques in a\nfully unsupervised manner to identify groups of characters with similar\nlevel-up patterns. To ensure reliable decisions, we incorporate a Large\nLanguage Model (LLM) as an auxiliary reviewer to validate the clustered groups,\neffectively mimicking a secondary human judgment. We also introduce a growth\ncurve-based visualization to assist both the LLM and human moderators in\nassessing leveling behavior. This collaborative approach improves the\nefficiency of bot detection workflows while maintaining explainability, thereby\nsupporting scalable and accountable bot regulation in MMORPGs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u5229\u7528\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u548c\u805a\u7c7b\u6280\u672f\uff0c\u65e0\u76d1\u7763\u68c0\u6d4bMMORPG\u4e2d\u7684\u81ea\u52a8\u5347\u7ea7\u673a\u5668\u4eba\uff0c\u540c\u65f6\u5f15\u5165\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u589e\u957f\u66f2\u7ebf\u53ef\u89c6\u5316\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u68c0\u6d4b\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u53ef\u6269\u5c55\u548c\u95ee\u8d23\u7684\u673a\u5668\u4eba\u76d1\u7ba1\u3002", "motivation": "\u68c0\u6d4bMMORPG\u4e2d\u7684\u81ea\u52a8\u5347\u7ea7\u673a\u5668\u4eba\u662f\u5177\u6709\u6311\u6218\u6027\u7684\uff0c\u56e0\u4e3a\u5b83\u4eec\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\uff0c\u5e76\u4e14\u5904\u7f5a\u884c\u4e3a\u9700\u8981\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7406\u7531\u3002\u4e3a\u4e86\u907f\u514d\u6cd5\u5f8b\u548c\u7528\u6237\u4f53\u9a8c\u95ee\u9898\uff0c\u9700\u8981\u53ef\u89e3\u91ca\u6027\u7684\u5224\u65ad\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u5728\u65e0\u76d1\u7763\u60c5\u51b5\u4e0b\u68c0\u6d4b\u81ea\u52a8\u5347\u7ea7\u673a\u5668\u4eba\u7684\u6846\u67b6\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u53ef\u6269\u5c55\u4e14\u53ef\u95ee\u8d23\u7684\u673a\u5668\u4eba\u76d1\u7ba1\u3002", "method": "\u5229\u7528\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u548c\u805a\u7c7b\u6280\u672f\uff0c\u5728\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u81ea\u52a8\u5347\u7ea7\u673a\u5668\u4eba\uff0c\u5e76\u5f15\u5165\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8f85\u52a9\u8bc4\u5ba1\u5458\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u589e\u957f\u66f2\u7ebf\u7684\u53ef\u89c6\u5316\u8f85\u52a9\u8bc4\u4f30\u5347\u7ea7\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u548c\u805a\u7c7b\u6280\u672f\u7684\u5e94\u7528\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8f85\u52a9\u8bc4\u5ba1\u5458\u7684\u65b9\u5f0f\uff0c\u4ee5\u53ca\u589e\u957f\u66f2\u7ebf\u7684\u53ef\u89c6\u5316\u8f85\u52a9\uff0c\u6210\u529f\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u68c0\u6d4b\u5de5\u4f5c\u6d41\u7a0b\u7684\u6548\u7387\uff0c\u4fdd\u6301\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u95ee\u8d23\u7684\u673a\u5668\u4eba\u76d1\u7ba1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5229\u7528\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u548c\u805a\u7c7b\u6280\u672f\uff0c\u4ee5\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u65b9\u5f0f\u68c0\u6d4b\u81ea\u52a8\u5347\u7ea7\u673a\u5668\u4eba\uff0c\u4ece\u800c\u8bc6\u522b\u5177\u6709\u76f8\u4f3c\u5347\u7ea7\u6a21\u5f0f\u7684\u89d2\u8272\u7fa4\u3002\u5f15\u5165\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u8f85\u52a9\u8bc4\u5ba1\u5458\uff0c\u6709\u6548\u6a21\u4eff\u4e86\u6b21\u8981\u4eba\u7c7b\u5224\u65ad\u3002\u901a\u8fc7\u57fa\u4e8e\u589e\u957f\u66f2\u7ebf\u7684\u53ef\u89c6\u5316\u6765\u8f85\u52a9LLM\u548c\u4eba\u7c7b\u5ba1\u6838\u5458\u8bc4\u4f30\u5347\u7ea7\u884c\u4e3a\u3002\u8fd9\u79cd\u534f\u4f5c\u65b9\u6cd5\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u68c0\u6d4b\u5de5\u4f5c\u6d41\u7a0b\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u4ece\u800c\u652f\u6301MMORPG\u4e2d\u53ef\u4f38\u7f29\u4e14\u53ef\u95ee\u8d23\u7684\u673a\u5668\u4eba\u76d1\u7ba1\u3002"}}
{"id": "2508.20674", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.20674", "abs": "https://arxiv.org/abs/2508.20674", "authors": ["Rui Mao", "Qian Liu", "Xiao Li", "Erik Cambria", "Amir Hussain"], "title": "Bridging Minds and Machines: Toward an Integration of AI and Cognitive Science", "comment": null, "summary": "Cognitive Science has profoundly shaped disciplines such as Artificial\nIntelligence (AI), Philosophy, Psychology, Neuroscience, Linguistics, and\nCulture. Many breakthroughs in AI trace their roots to cognitive theories,\nwhile AI itself has become an indispensable tool for advancing cognitive\nresearch. This reciprocal relationship motivates a comprehensive review of the\nintersections between AI and Cognitive Science. By synthesizing key\ncontributions from both perspectives, we observe that AI progress has largely\nemphasized practical task performance, whereas its cognitive foundations remain\nconceptually fragmented. We argue that the future of AI within Cognitive\nScience lies not only in improving performance but also in constructing systems\nthat deepen our understanding of the human mind. Promising directions include\naligning AI behaviors with cognitive frameworks, situating AI in embodiment and\nculture, developing personalized cognitive models, and rethinking AI ethics\nthrough cognitive co-evaluation.", "AI": {"tldr": "AI development has prioritized task performance over cognitive foundations. Future AI in Cognitive Science should aim to enhance understanding of the human mind by aligning with cognitive frameworks, considering embodiment and culture, developing personalized models, and rethinking ethics.", "motivation": "The reciprocal relationship between AI and Cognitive Science drives the need for a review to explore the intersections and gaps between the two fields.", "method": "Comprehensive review of the intersections between AI and Cognitive Science, synthesizing key contributions from both perspectives.", "result": "Observation that AI progress has emphasized practical task performance while its cognitive foundations are fragmented. Proposal for future AI development in Cognitive Science to construct systems that deepen understanding of the human mind by aligning AI behaviors with cognitive frameworks, considering embodiment and culture, developing personalized cognitive models, and rethinking AI ethics.", "conclusion": "AI progress has focused on practical task performance, but its cognitive foundations are fragmented. Future AI development in Cognitive Science should aim to enhance understanding of the human mind."}}
{"id": "2508.20701", "categories": ["cs.AI", "cs.CL", "math.CT"], "pdf": "https://arxiv.org/pdf/2508.20701", "abs": "https://arxiv.org/abs/2508.20701", "authors": ["Ares Fabregat-Hern\u00e1ndez", "Javier Palanca", "Vicent Botti"], "title": "Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings", "comment": null, "summary": "The paper introduces a novel framework based on category theory to enhance\nthe explainability of artificial intelligence systems, particularly focusing on\nword embeddings. Key topics include the construction of categories\n$\\mathcal{L}_T$ and $\\mathcal{P}_T$, providing schematic representations of the\nsemantics of a text $ T $, and reframing the selection of the element with\nmaximum probability as a categorical notion. Additionally, the monoidal\ncategory $\\mathcal{P}_T$ is constructed to visualize various methods of\nextracting semantic information from $T$, offering a dimension-agnostic\ndefinition of semantic spaces reliant solely on information within the text.\n  Furthermore, the paper defines the categories of configurations Conf and word\nembeddings $\\mathcal{Emb}$, accompanied by the concept of divergence as a\ndecoration on $\\mathcal{Emb}$. It establishes a mathematically precise method\nfor comparing word embeddings, demonstrating the equivalence between the GloVe\nand Word2Vec algorithms and the metric MDS algorithm, transitioning from neural\nnetwork algorithms (black box) to a transparent framework. Finally, the paper\npresents a mathematical approach to computing biases before embedding and\noffers insights on mitigating biases at the semantic space level, advancing the\nfield of explainable artificial intelligence.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u8303\u7574\u8bba\u7684\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u7279\u522b\u5173\u6ce8\u8bcd\u5d4c\u5165\u3002\u901a\u8fc7\u6784\u5efa\u4e0d\u540c\u8303\u7574\u548c\u6570\u5b66\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u5230\u900f\u660e\u6846\u67b6\u7684\u8fc7\u6e21\uff0c\u5e76\u63a8\u52a8\u4e86\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u53d1\u5c55\u3002", "motivation": "\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u91cd\u70b9\u5728\u4e8e\u8bcd\u5d4c\u5165\u3002\u901a\u8fc7\u6570\u5b66\u65b9\u6cd5\u548c\u8303\u7574\u8bba\u6784\u5efa\u6846\u67b6\uff0c\u6539\u8fdb\u73b0\u6709\u7b97\u6cd5\uff0c\u5e76\u4ece\u9ed1\u76d2\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u8fc7\u6e21\u5230\u900f\u660e\u6846\u67b6\uff0c\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u57fa\u4e8e\u8303\u7574\u8bba\u6784\u5efa\u6846\u67b6\uff0c\u5305\u62ec\u6784\u5efa$\text{L}_T$\u548c$\text{P}_T$\u8303\u7574\u3001\u6784\u9020\u8499\u5fb7\u8303\u7574$\text{P}_T$\u3001\u5b9a\u4e49\u914d\u7f6eConf\u548c\u8bcd\u5d4c\u5165$\text{Emb}$\u7684\u8303\u7574\uff0c\u5f15\u5165divergence\u4f5c\u4e3a$\text{Emb}$\u7684\u88c5\u9970\uff0c\u5efa\u7acb\u6bd4\u8f83\u8bcd\u5d4c\u5165\u7684\u6570\u5b66\u65b9\u6cd5\uff0c\u8ba1\u7b97\u548c\u51cf\u5c11\u504f\u5dee\u7684\u6570\u5b66\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u57fa\u4e8e\u8303\u7574\u8bba\u7684\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u63d0\u53d6\u6587\u672c\u8bed\u4e49\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u7b97\u6cd5\u4e4b\u95f4\u7684\u7b49\u4ef7\u6027\uff0c\u5c55\u793a\u4e86\u8ba1\u7b97\u504f\u5dee\u548c\u51cf\u5c11\u504f\u5dee\u7684\u6570\u5b66\u65b9\u6cd5\u3002\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u8fdb\u5c55\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u8303\u7574\u8bba\u7684\u65b0\u9896\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3a\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u7279\u522b\u5173\u6ce8\u8bcd\u5d4c\u5165\u3002\u901a\u8fc7\u6784\u5efa$\text{L}_T$\u548c$\text{P}_T$\u8303\u7574\uff0c\u63d0\u4f9b\u4e86\u6587\u672c$T$\u8bed\u4e49\u7684\u56fe\u5f0f\u8868\u793a\uff0c\u5e76\u5c06\u9009\u62e9\u5177\u6709\u6700\u5927\u6982\u7387\u7684\u5143\u7d20\u91cd\u65b0\u6784\u5efa\u4e3a\u8303\u7574\u6982\u5ff5\u3002\u6b64\u5916\uff0c\u6784\u5efa\u4e86\u8499\u5fb7\u8303\u7574$\text{P}_T$\u4ee5\u53ef\u89c6\u5316\u4ece$T$\u4e2d\u63d0\u53d6\u8bed\u4e49\u4fe1\u606f\u7684\u5404\u79cd\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4ec5\u4f9d\u8d56\u6587\u672c\u5185\u4fe1\u606f\u7684\u4e0e\u7ef4\u5ea6\u65e0\u5173\u7684\u8bed\u4e49\u7a7a\u95f4\u5b9a\u4e49\u3002\u540c\u65f6\uff0c\u5b9a\u4e49\u4e86\u914d\u7f6eConf\u548c\u8bcd\u5d4c\u5165$\text{Emb}$\u7684\u8303\u7574\uff0c\u5e76\u5f15\u5165\u4e86divergence\u4f5c\u4e3a$\text{Emb}$\u7684\u4e00\u79cd\u88c5\u9970\u3002\u5efa\u7acb\u4e86\u4e00\u4e2a\u6570\u5b66\u4e0a\u7cbe\u786e\u7684\u6bd4\u8f83\u8bcd\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86GloVe\u548cWord2Vec\u7b97\u6cd5\u4e0e\u5ea6\u91cfMDS\u7b97\u6cd5\u4e4b\u95f4\u7684\u7b49\u4ef7\u6027\uff0c\u5b9e\u73b0\u4e86\u4ece\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\uff08\u9ed1\u76d2\uff09\u5411\u900f\u660e\u6846\u67b6\u7684\u8fc7\u6e21\u3002\u6700\u540e\uff0c\u4ecb\u7ecd\u4e86\u4e00\u79cd\u8ba1\u7b97\u5d4c\u5165\u524d\u504f\u5dee\u5e76\u5728\u8bed\u4e49\u7a7a\u95f4\u5c42\u9762\u4e0a\u51cf\u5c11\u504f\u5dee\u7684\u6570\u5b66\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.20729", "categories": ["cs.AI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2508.20729", "abs": "https://arxiv.org/abs/2508.20729", "authors": ["Ao Cheng", "Lei Zhang", "Guowei He"], "title": "Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision", "comment": null, "summary": "Large language models (LLMs) serve as an active and promising field of\ngenerative artificial intelligence and have demonstrated abilities to perform\ncomplex tasks in multiple domains, including mathematical and scientific\nreasoning. In this work, we construct a novel agent framework for solving\nrepresentative problems in scientific computing. The proposed agent,\nincorporating a \"rewriting-resolution-review-revision\" logical chain via three\nreasoning LLMs (functioning as the Consultant, Reviewer, and Programmer,\nrespectively), is integrated in a collaborative and interactive manner. The\nConsultant module endows the agent with knowledge transfer capabilities to link\nproblems to professional domain insights, thereby rewriting problem\ndescriptions through text augmentation. The Programmer module is responsible\nfor generating and executing well-structured code to deliver the problem\nresolution. The Reviewer module equips the agent with the capacity for\nself-debugging and self-refinement through interactive feedback with code\nruntime outputs. By leveraging the end-to-end review mechanism, the executable\ncode provided by the Programmer attains the iterative revision. A comprehensive\nevaluation is conducted on the performance of the proposed agent framework in\nsolving PDEs, ill-conditioned linear systems, and data-driven physical analysis\nproblems. Compared to single-model, this collaborative framework significantly\nimproves the bug-free code generation rate and reduces the occurrence of\nnon-physical solutions, thereby establishing a highly reliable framework for\nautonomous code generation based on natural language descriptions. The review\nmechanism improved the average execution success (bug-free code and non-NaN\nsolutions) rate of the latest reasoning models. In summary, our agent framework\nestablishes automatic code generation and review as a promising scientific\ncomputing paradigm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u578b\u4ee3\u7406\u7cfb\u7edf\u6846\u67b6\uff0c\u5229\u7528\u4e09\u4e2a\u63a8\u7406LLM\u6a21\u5757\u5b9e\u73b0\u95ee\u9898\u91cd\u5199\u3001\u4ee3\u7801\u751f\u6210\u548c\u81ea\u5ba1\u67e5\u80fd\u529b\u3002\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u52bf\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u751f\u6210\u6548\u7387\u548c\u95ee\u9898\u89e3\u51b3\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\uff0c\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u548c\u81ea\u52a8\u5ba1\u67e5\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u4f46\u6709\u524d\u666f\u7684\u9886\u57df\u3002\u672c\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u548c\u81ea\u52a8\u5ba1\u67e5\u7684\u4ee3\u7406\u7cfb\u7edf\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u5b9e\u9645\u95ee\u9898\u5e76\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u6548\u7387\u3002", "method": "\u5efa\u7acb\u4ee3\u7406\u7cfb\u7edf\u6846\u67b6\uff0c\u5229\u7528\u4e09\u4e2a\u63a8\u7406LLM\u6a21\u5757\uff08Consultant\u3001Reviewer\u548cProgrammer\uff09\u8fdb\u884c\u534f\u4f5c\u548c\u4ea4\u4e92\uff0c\u5b9e\u73b0\u95ee\u9898\u91cd\u5199\u3001\u4ee3\u7801\u751f\u6210\u548c\u81ea\u5ba1\u67e5\u80fd\u529b\u3002\u901a\u8fc7\u7aef\u5230\u7aef\u5ba1\u67e5\u673a\u5236\uff0c\u6539\u8fdb\u4ee3\u7801\u7684\u53ef\u6267\u884c\u6027\u548c\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u7684\u4fee\u8ba2\u3002\u5728\u504f\u5fae\u5206\u65b9\u7a0b\u3001\u75c5\u6001\u7ebf\u6027\u7cfb\u7edf\u548c\u6570\u636e\u9a71\u52a8\u7684\u7269\u7406\u5206\u6790\u95ee\u9898\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u8bc1\u660e\u8be5\u6846\u67b6\u5728\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u548c\u81ea\u52a8\u5ba1\u67e5\u65b9\u9762\u7684\u53ef\u9760\u6027\u3002", "result": "\u901a\u8fc7\u4e0e\u5355\u4e00\u6a21\u578b\u5bf9\u6bd4\uff0c\u5c55\u793a\u4e86\u8be5\u534f\u4f5c\u6846\u67b6\u663e\u8457\u6539\u5584\u4e86\u65e0\u9519\u8bef\u4ee3\u7801\u751f\u6210\u7387\u548c\u51cf\u5c11\u4e86\u975e\u7269\u7406\u89e3\u7684\u53d1\u751f\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u5728\u89e3\u51b3\u5b9e\u9645\u79d1\u5b66\u8ba1\u7b97\u95ee\u9898\u65f6\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u4ee3\u7406\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u63a8\u7406LLM\uff08Consultant\u3001Reviewer\u548cProgrammer\uff09\u6784\u5efa\u4e86\u4e00\u4e2a\u201c\u91cd\u5199-\u89e3\u51b3-\u5ba1\u67e5-\u4fee\u8ba2\u201d\u903b\u8f91\u94fe\uff0c\u7528\u4e8e\u89e3\u51b3\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u4ee3\u8868\u6027\u95ee\u9898\u3002\u8be5\u6846\u67b6\u5728\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u3001\u75c5\u6001\u7ebf\u6027\u7cfb\u7edf\u548c\u6570\u636e\u9a71\u52a8\u7684\u7269\u7406\u5206\u6790\u95ee\u9898\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u65e0\u9519\u8bef\u4ee3\u7801\u751f\u6210\u7387\u5e76\u51cf\u5c11\u4e86\u975e\u7269\u7406\u89e3\u7684\u53d1\u751f\u3002\u901a\u8fc7\u8bc4\u4f30\uff0c\u8be5\u4ee3\u7406\u6846\u67b6\u5728\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u548c\u81ea\u52a8\u5ba1\u67e5\u65b9\u9762\u8868\u73b0\u53ef\u9760\uff0c\u4e3a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u5efa\u7acb\u4e86\u9ad8\u5ea6\u53ef\u9760\u7684\u6846\u67b6\u3002"}}
{"id": "2508.20784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20784", "abs": "https://arxiv.org/abs/2508.20784", "authors": ["Yifan Zhang"], "title": "Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control", "comment": null, "summary": "Bus bunching remains a challenge for urban transit due to stochastic traffic\nand passenger demand. Traditional solutions rely on multi-agent reinforcement\nlearning (MARL) in loop-line settings, which overlook realistic operations\ncharacterized by heterogeneous routes, timetables, fluctuating demand, and\nvarying fleet sizes. We propose a novel single-agent reinforcement learning\n(RL) framework for bus holding control that avoids the data imbalance and\nconvergence issues of MARL under near-realistic simulation. A bidirectional\ntimetabled network with dynamic passenger demand is constructed. The key\ninnovation is reformulating the multi-agent problem into a single-agent one by\naugmenting the state space with categorical identifiers (vehicle ID, station\nID, time period) in addition to numerical features (headway, occupancy,\nvelocity). This high-dimensional encoding enables single-agent policies to\ncapture inter-agent dependencies, analogous to projecting non-separable inputs\ninto a higher-dimensional space. We further design a structured reward function\naligned with operational goals: instead of exponential penalties on headway\ndeviations, a ridge-shaped reward balances uniform headways and schedule\nadherence. Experiments show that our modified soft actor-critic (SAC) achieves\nmore stable and superior performance than benchmarks, including MADDPG (e.g.,\n-430k vs. -530k under stochastic conditions). These results demonstrate that\nsingle-agent deep RL, when enhanced with categorical structuring and\nschedule-aware rewards, can effectively manage bus holding in non-loop,\nreal-world contexts. This paradigm offers a robust, scalable alternative to\nMARL frameworks, particularly where agent-specific experiences are imbalanced.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5355\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u516c\u4ea4\u8f66\u8f86\u8c03\u5ea6\u63a7\u5236\uff0c\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5b9e\u9645\u6a21\u62df\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6536\u655b\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u516c\u4ea4\u8f66\u8f86\u8c03\u5ea6\u63a7\u5236\u4e2d\u8868\u73b0\u66f4\u52a0\u7a33\u5b9a\u548c\u4f18\u8d8a\uff0c\u6bd4\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "motivation": "\u4f20\u7edf\u89e3\u51b3\u65b9\u6848\u5728\u5904\u7406\u5177\u6709\u5f02\u6784\u8def\u7ebf\u3001\u65f6\u95f4\u8868\u3001\u6ce2\u52a8\u9700\u6c42\u548c\u4e0d\u540c\u8230\u961f\u89c4\u6a21\u7684\u73b0\u5b9e\u8fd0\u8425\u60c5\u51b5\u65f6\u4f9d\u8d56\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u63a5\u8fd1\u5b9e\u9645\u6a21\u62df\u7684\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u53ef\u4ee5\u6709\u6548\u7ba1\u7406\u975e\u73af\u5f62\u3001\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u516c\u5171\u6c7d\u8f66\u8c03\u5ea6\uff0c\u907f\u514d\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6536\u655b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u516c\u4ea4\u8f66\u8f86\u8c03\u5ea6\u63a7\u5236\uff0c\u901a\u8fc7\u589e\u52a0\u5206\u7c7b\u6807\u8bc6\u7b26\uff08\u8f66\u8f86ID\uff0c\u7ad9\u70b9ID\uff0c\u65f6\u95f4\u6bb5\uff09\u5230\u72b6\u6001\u7a7a\u95f4\u4e2d\uff0c\u7ed3\u5408\u6570\u503c\u7279\u5f81\uff08\u8f66\u5934\u95f4\u9694\uff0c\u5360\u7528\u7387\uff0c\u901f\u5ea6\uff09\u6765\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5b9e\u9645\u6a21\u62df\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6536\u655b\u95ee\u9898\u3002\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u5956\u52b1\u51fd\u6570\uff0c\u5e73\u8861\u5747\u5300\u7684\u8f66\u5934\u95f4\u9694\u548c\u65f6\u95f4\u8868\u6267\u884c\uff0c\u4ee5\u5b9e\u73b0\u64cd\u4f5c\u76ee\u6807\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6539\u8fdb\u7684soft actor-critic (SAC)\u65b9\u6cd5\u6bd4\u57fa\u51c6\u65b9\u6cd5\uff08\u5982MADDPG\uff09\u5728\u968f\u673a\u6761\u4ef6\u4e0b\u66f4\u7a33\u5b9a\u548c\u6027\u80fd\u66f4\u4f18\u8d8a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6539\u8fdb\u7684SAC\u65b9\u6cd5\u6bd4\u5176\u4ed6\u57fa\u51c6\u65b9\u6cd5\u5728\u8c03\u5ea6\u63a7\u5236\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u5c55\u793a\u4e86\u5355\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u516c\u4ea4\u8f66\u8f86\u8c03\u5ea6\u63a7\u5236\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u5355\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u516c\u4ea4\u8f66\u8f86\u8c03\u5ea6\u63a7\u5236\u4e2d\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u548c\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u6bd4\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u66f4\u6709\u6548\u3002"}}
{"id": "2508.20810", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.20810", "abs": "https://arxiv.org/abs/2508.20810", "authors": ["Jessica Lundin", "Guillaume Chabot-Couture"], "title": "A Graph-Based Test-Harness for LLM Evaluation", "comment": "4 pages, 2 figures, dataset", "summary": "We present a first known prototype of a dynamic, systematic benchmark of\nmedical guidelines for 400+ questions, with 3.3+ trillion possible\ncombinations, covering 100\\% of guideline relationships. We transformed the WHO\nIMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,\ntreatments, follow-ups, severities) and 300+ edges, then used graph traversal\nto generate questions that incorporated age-specific scenarios and contextual\ndistractors to ensure clinical relevance. Our graph-based approach enables\nsystematic evaluation across clinical tasks (45-67\\% accuracy), and we find\nmodels excel at symptom recognition but struggle with triaging severity,\ntreatment protocols and follow-up care, demonstrating how customized benchmarks\ncan identify specific capability gaps that general-domain evaluations miss.\nBeyond evaluation, this dynamic MCQA methodology enhances LLM post-training\n(supervised finetuning, GRPO, DPO), where correct answers provide high-reward\nsamples without expensive human annotation. The graph-based approach\nsuccessfully addresses the coverage limitations of manually curated benchmarks.\nThis methodology is a step toward scalable, contamination-resistant solution\nfor creating comprehensive benchmarks that can be dynamically generated,\nincluding when the guidelines are updated. Code and datasets are available at\nhttps://github.com/jessicalundin/graph_testing_harness", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7cfb\u7edf\u5316\u7684\u533b\u5b66\u6307\u5357\u57fa\u51c6\u7684\u539f\u578b\uff0c\u5c06WHO IMCI\u624b\u518c\u8f6c\u5316\u4e3a\u6709\u5411\u56fe\uff0c\u4ee5\u751f\u6210\u5177\u6709\u4e34\u5e8a\u76f8\u5173\u6027\u7684\u95ee\u9898\u3002\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4e34\u5e8a\u4efb\u52a1\u8bc4\u4f30\uff0c\u5e76\u53d1\u73b0\u6a21\u578b\u5728\u75c7\u72b6\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5206\u7ea7\u4e25\u91cd\u6027\u3001\u6cbb\u7597\u548c\u540e\u7eed\u62a4\u7406\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u89e3\u51b3\u624b\u52a8\u7b56\u5212\u57fa\u51c6\u7684\u8986\u76d6\u9650\u5236\uff0c\u5e76\u4e3a\u52a8\u6001\u751f\u6210\u57fa\u51c6\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\uff0c\u53ef\u5e94\u7528\u4e8e\u65e5\u5e38\u6307\u5357\u66f4\u65b0\u3002", "motivation": "\u7814\u7a76\u52a8\u6001\u533b\u5b66\u6307\u5357\u57fa\u51c6\u7684\u539f\u578b\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u7b56\u5212\u57fa\u51c6\u8986\u76d6\u9650\u5236\u7684\u95ee\u9898\uff0c\u81f4\u529b\u4e8e\u521b\u5efa\u53ef\u4f38\u7f29\u3001\u6297\u5e72\u6270\u7684\u5168\u9762\u57fa\u51c6\u521b\u5efa\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u4f7f\u5f97\u57fa\u51c6\u80fd\u591f\u52a8\u6001\u751f\u6210\u5e76\u5728\u6307\u5357\u66f4\u65b0\u65f6\u4fdd\u6301\u66f4\u65b0\u3002\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u5728\u533b\u5b66\u6307\u5357\u65b9\u9762\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u7279\u5b9a\u80fd\u529b\u65b9\u9762\u7684\u5dee\u8ddd\uff0c\u5f25\u8865\u4e86\u4f20\u7edf\u57fa\u51c6\u8bc4\u4f30\u7684\u4e0d\u8db3\u4e4b\u5904\u3002", "method": "\u5c06WHO IMCI\u624b\u518c\u8f6c\u5316\u4e3a\u6709\u5411\u56fe\uff0c\u5229\u7528\u56fe\u904d\u5386\u751f\u6210\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u5e74\u9f84\u7279\u5b9a\u60c5\u666f\u548c\u8bed\u5883\u5e72\u6270\u7269\u4ee5\u786e\u4fdd\u4e34\u5e8a\u76f8\u5173\u6027\uff1b\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5728\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8fbe\u523045-67%\u7684\u51c6\u786e\u7387\uff1b\u5728\u75c7\u72b6\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5206\u7ea7\u4e25\u91cd\u6027\u3001\u6cbb\u7597\u534f\u8bae\u548c\u540e\u7eed\u62a4\u7406\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u8fd8\u63d0\u9ad8\u4e86LLM\u540e\u8bad\u7ec3\u7684\u6548\u679c\uff0c\u80fd\u591f\u89e3\u51b3\u624b\u52a8\u7b56\u5212\u57fa\u51c6\u7684\u8986\u76d6\u9650\u5236\uff0c\u5b9e\u73b0\u53ef\u4f38\u7f29\u548c\u6297\u5e72\u6270\u7684\u5168\u9762\u57fa\u51c6\u521b\u5efa\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7cfb\u7edf\u5316\u7684\u533b\u5b66\u6307\u5357\u57fa\u51c6\u7684\u539f\u578b\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u5728\u4e34\u5e8a\u4efb\u52a1\u4e2d\u7684\u8bc4\u4f30\u6548\u679c\u548c\u5e94\u7528\u4ef7\u503c\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u75c7\u72b6\u8bc6\u522b\u65b9\u9762\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5206\u7ea7\u4e25\u91cd\u6027\u3001\u6cbb\u7597\u534f\u8bae\u548c\u540e\u7eed\u62a4\u7406\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u540e\u7eed\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u76ca\u7684\u53c2\u8003\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7cfb\u7edf\u5316\u7684\u533b\u5b66\u6307\u5357\u57fa\u51c6\u7684\u539f\u578b\uff0c\u8986\u76d6\u4e86400\u591a\u4e2a\u95ee\u9898\uff0c\u5171\u67093.3\u4e07\u4ebf\u53ef\u80fd\u7684\u7ec4\u5408\uff0c\u6db5\u76d6\u4e86100\uff05\u7684\u6307\u5357\u5173\u7cfb\u3002\u7814\u7a76\u5c06\u4e16\u754c\u536b\u751f\u7ec4\u7ec7IMCI\u624b\u518c\u8f6c\u5316\u4e3a\u4e00\u4e2a\u6709\u5411\u56fe\uff0c\u5305\u542b200\u591a\u4e2a\u8282\u70b9\uff08\u75be\u75c5\u3001\u75c7\u72b6\u3001\u6cbb\u7597\u65b9\u6cd5\u3001\u540e\u7eed\u884c\u52a8\u3001\u4e25\u91cd\u6027\uff09\u548c300\u591a\u6761\u8fb9\uff0c\u7136\u540e\u5229\u7528\u56fe\u904d\u5386\u751f\u6210\u95ee\u9898\uff0c\u7ed3\u5408\u5e74\u9f84\u7279\u5b9a\u60c5\u666f\u548c\u8bed\u5883\u5e72\u6270\u7269\uff0c\u786e\u4fdd\u4e34\u5e8a\u76f8\u5173\u6027\u3002\u8be5\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u4f7f\u5f97\u80fd\u591f\u5728\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0845-67\uff05\u51c6\u786e\u7387\uff09\uff0c\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5728\u75c7\u72b6\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5206\u7ea7\u4e25\u91cd\u6027\u3001\u6cbb\u7597\u534f\u8bae\u548c\u540e\u7eed\u62a4\u7406\u65b9\u9762\u8868\u73b0\u8f83\u5dee\uff0c\u5c55\u793a\u4e86\u5b9a\u5236\u57fa\u51c6\u53ef\u4ee5\u53d1\u73b0\u666e\u901a\u9886\u57df\u8bc4\u4f30\u5ffd\u7565\u7684\u7279\u5b9a\u80fd\u529b\u5dee\u8ddd\u3002\u9664\u4e86\u8bc4\u4f30\u5916\uff0c\u8fd9\u79cd\u52a8\u6001MCQA\u65b9\u6cd5\u8fd8\u589e\u5f3a\u4e86LLM\u540e\u8bad\u7ec3\uff08\u76d1\u7763\u5fae\u8c03\u3001GRPO\u3001DPO\uff09\u7684\u80fd\u529b\uff0c\u5176\u4e2d\u6b63\u786e\u7b54\u6848\u63d0\u4f9b\u9ad8\u56de\u62a5\u6837\u672c\uff0c\u800c\u65e0\u9700\u6602\u8d35\u7684\u4eba\u5de5\u6ce8\u91ca\u3002\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u624b\u52a8\u7b56\u5212\u57fa\u51c6\u7684\u8986\u76d6\u9650\u5236\u3002\u8fd9\u79cd\u65b9\u6cd5\u662f\u671d\u7740\u53ef\u4f38\u7f29\u3001\u6297\u5e72\u6270\u6027\u7684\u5168\u9762\u57fa\u51c6\u521b\u5efa\u89e3\u51b3\u65b9\u6848\u8fc8\u51fa\u7684\u4e00\u6b65\uff0c\u80fd\u591f\u52a8\u6001\u751f\u6210\u57fa\u51c6\uff0c\u5305\u62ec\u6307\u5357\u66f4\u65b0\u65f6\u3002\u7814\u7a76\u4ee3\u7801\u548c\u6570\u636e\u96c6\u53ef\u5728https://github.com/jessicalundin/graph_testing_harness\u4e2d\u83b7\u53d6\u3002"}}
{"id": "2508.20953", "categories": ["cs.AI", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.20953", "abs": "https://arxiv.org/abs/2508.20953", "authors": ["Vipul Patel", "Anirudh Deodhar", "Dagnachew Birru"], "title": "A Multi-Objective Genetic Algorithm for Healthcare Workforce Scheduling", "comment": "8 pages, 7 figures, Accepted at the Multi-Objective Decision Making\n  Workshop (MODeM2025) at ECAI 2025", "summary": "Workforce scheduling in the healthcare sector is a significant operational\nchallenge, characterized by fluctuating patient loads, diverse clinical skills,\nand the critical need to control labor costs while upholding high standards of\npatient care. This problem is inherently multi-objective, demanding a delicate\nbalance between competing goals: minimizing payroll, ensuring adequate staffing\nfor patient needs, and accommodating staff preferences to mitigate burnout. We\npropose a Multi-objective Genetic Algorithm (MOO-GA) that models the hospital\nunit workforce scheduling problem as a multi-objective optimization task. Our\nmodel incorporates real-world complexities, including hourly appointment-driven\ndemand and the use of modular shifts for a multi-skilled workforce. By defining\nobjective functions for cost, patient care coverage, and staff satisfaction,\nthe GA navigates the vast search space to identify a set of high-quality,\nnon-dominated solutions. Demonstrated on datasets representing a typical\nhospital unit, the results show that our MOO-GA generates robust and balanced\nschedules. On average, the schedules produced by our algorithm showed a 66\\%\nperformance improvement over a baseline that simulates a conventional, manual\nscheduling process. This approach effectively manages trade-offs between\ncritical operational and staff-centric objectives, providing a practical\ndecision support tool for nurse managers and hospital administrators.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\u7684\u533b\u9662\u5355\u4f4d\u4eba\u5458\u6392\u73ed\u95ee\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4e49\u76ee\u6807\u51fd\u6570\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6392\u73ed\u8ba1\u5212\u7684\u751f\u6210\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5178\u578b\u533b\u9662\u5355\u4f4d\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6bd4\u4f20\u7edf\u624b\u52a8\u6392\u73ed\u65b9\u6cd5\u63d0\u9ad8\u4e8666%\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e3a\u62a4\u58eb\u7ecf\u7406\u548c\u533b\u9662\u7ba1\u7406\u5458\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002", "motivation": "\u533b\u7597\u90e8\u95e8\u7684\u5de5\u4f5c\u6392\u73ed\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u8fd0\u8425\u6311\u6218\uff0c\u8981\u6c42\u5728\u6700\u5c0f\u5316\u4eba\u5de5\u6210\u672c\u3001\u786e\u4fdd\u60a3\u8005\u9700\u6c42\u7684\u5145\u5206\u914d\u5907\u4ee5\u53ca\u5458\u5de5\u6ee1\u610f\u5ea6\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u73b0\u6709\u6392\u73ed\u65b9\u6cd5\u53ef\u80fd\u96be\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u591a\u91cd\u76ee\u6807\uff0c\u56e0\u6b64\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u76ee\u6807\u4f18\u5316\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u57fa\u4e8e\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\uff08MOO-GA\uff09\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u533b\u9662\u5355\u4f4d\u4eba\u5458\u6392\u73ed\u95ee\u9898\u89c6\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\u3002\u6a21\u578b\u8003\u8651\u4e86\u73b0\u5b9e\u4e16\u754c\u7684\u590d\u6742\u6027\uff0c\u5305\u62ec\u6309\u5c0f\u65f6\u9884\u7ea6\u9a71\u52a8\u7684\u9700\u6c42\u548c\u591a\u6280\u80fd\u5458\u5de5\u7684\u6a21\u5757\u5316\u73ed\u6b21\u4f7f\u7528\u3002\u901a\u8fc7\u5b9a\u4e49\u6210\u672c\u3001\u60a3\u8005\u62a4\u7406\u8986\u76d6\u7387\u548c\u5458\u5de5\u6ee1\u610f\u5ea6\u7b49\u76ee\u6807\u51fd\u6570\uff0c\u9057\u4f20\u7b97\u6cd5\u5728\u5e9e\u5927\u7684\u641c\u7d22\u7a7a\u95f4\u4e2d\u5bfb\u627e\u4e00\u7ec4\u9ad8\u8d28\u91cf\u7684\u975e\u652f\u914d\u89e3\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cMOO-GA\u751f\u6210\u7684\u6392\u73ed\u8ba1\u5212\u5728\u5178\u578b\u533b\u9662\u5355\u4f4d\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\u4e14\u5e73\u8861\u3002\u4e0e\u6a21\u62df\u4f20\u7edf\u624b\u52a8\u6392\u73ed\u8fc7\u7a0b\u7684\u57fa\u51c6\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u751f\u6210\u7684\u6392\u73ed\u8ba1\u5212\u5e73\u5747\u6027\u80fd\u63d0\u9ad8\u4e8666%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\uff08MOO-GA\uff09\u7684\u533b\u9662\u5355\u4f4d\u4eba\u5458\u6392\u73ed\u95ee\u9898\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4e49\u6210\u672c\u3001\u60a3\u8005\u62a4\u7406\u8986\u76d6\u7387\u548c\u5458\u5de5\u6ee1\u610f\u5ea6\u7b49\u76ee\u6807\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u3001\u975e\u652f\u914d\u89e3\u7684\u8bc6\u522b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cMOO-GA\u751f\u6210\u7684\u6392\u73ed\u8ba1\u5212\u5728\u5178\u578b\u533b\u9662\u5355\u4f4d\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\u4e14\u5e73\u8861\u3002\u4e0e\u6a21\u62df\u4f20\u7edf\u624b\u52a8\u6392\u73ed\u8fc7\u7a0b\u7684\u57fa\u51c6\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u751f\u6210\u7684\u6392\u73ed\u8ba1\u5212\u5e73\u5747\u6027\u80fd\u63d0\u9ad8\u4e8666%\u3002\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u5e73\u8861\u4e86\u5173\u952e\u8fd0\u8425\u548c\u5458\u5de5\u4e2d\u5fc3\u76ee\u6807\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u62a4\u58eb\u7ecf\u7406\u548c\u533b\u9662\u7ba1\u7406\u5458\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002"}}
{"id": "2508.20978", "categories": ["cs.AI", "cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2508.20978", "abs": "https://arxiv.org/abs/2508.20978", "authors": ["Marianne Defresne", "Romain Gambardella", "Sophie Barbe", "Thomas Schiex"], "title": "Efficient Neuro-Symbolic Learning of Constraints and Objective", "comment": null, "summary": "In the ongoing quest for hybridizing discrete reasoning with neural nets,\nthere is an increasing interest in neural architectures that can learn how to\nsolve discrete reasoning or optimization problems from natural inputs, a task\nthat Large Language Models seem to struggle with.\n  Objectives: We introduce a differentiable neuro-symbolic architecture and a\nloss function dedicated to learning how to solve NP-hard reasoning problems.\n  Methods: Our new probabilistic loss allows for learning both the constraints\nand the objective, thus delivering a complete model that can be scrutinized and\ncompleted with side constraints. By pushing the combinatorial solver out of the\ntraining loop, our architecture also offers scalable training while exact\ninference gives access to maximum accuracy.\n  Results: We empirically show that it can efficiently learn how to solve\nNP-hard reasoning problems from natural inputs. On three variants of the Sudoku\nbenchmark -- symbolic, visual, and many-solution --, our approach requires a\nfraction of training time of other hybrid methods. On a visual Min-Cut/Max-cut\ntask, it optimizes the regret better than a Decision-Focused-Learning\nregret-dedicated loss. Finally, it efficiently learns the energy optimization\nformulation of the large real-world problem of designing proteins.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b26\u53f7\u5316\u67b6\u6784\u548c\u635f\u5931\u51fd\u6570\uff0c\u53ef\u9ad8\u6548\u5b66\u4e60\u89e3\u51b3NP\u96be\u63a8\u7406\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7ed3\u679c\uff0c\u4e14\u8bad\u7ec3\u65f6\u95f4\u77ed\u4e8e\u5176\u4ed6\u6df7\u5408\u65b9\u6cd5\u3002", "motivation": "\u5728\u5c06\u79bb\u6563\u63a8\u7406\u4e0e\u795e\u7ecf\u7f51\u7edc\u6df7\u5408\u7684\u6301\u7eed\u63a2\u7d22\u4e2d\uff0c\u4eba\u4eec\u5bf9\u53ef\u4ee5\u4ece\u81ea\u7136\u8f93\u5165\u4e2d\u5b66\u4e60\u89e3\u51b3\u79bb\u6563\u63a8\u7406\u6216\u4f18\u5316\u95ee\u9898\u7684\u795e\u7ecf\u67b6\u6784\u8d8a\u53d1\u611f\u5174\u8da3\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f3c\u4e4e\u5f88\u96be\u80dc\u4efb\u8fd9\u4e00\u4efb\u52a1\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u53ef\u5fae\u7684\u795e\u7ecf\u7b26\u53f7\u5316\u67b6\u6784\u548c\u4e00\u79cd\u4e13\u7528\u4e8e\u5b66\u4e60\u5982\u4f55\u89e3\u51b3NP\u96be\u63a8\u7406\u95ee\u9898\u7684\u635f\u5931\u51fd\u6570\u3002\u65b0\u7684\u6982\u7387\u635f\u5931\u51fd\u6570\u5141\u8bb8\u5b66\u4e60\u7ea6\u675f\u548c\u76ee\u6807\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\uff0c\u5e76\u53ef\u901a\u8fc7\u9644\u52a0\u7ea6\u675f\u8fdb\u884c\u5b8c\u5584\u3002\u901a\u8fc7\u5c06\u7ec4\u5408\u6c42\u89e3\u5668\u6392\u9664\u5728\u8bad\u7ec3\u5faa\u73af\u4e4b\u5916\uff0c\u67b6\u6784\u5b9e\u73b0\u53ef\u6269\u5c55\u8bad\u7ec3\uff0c\u540c\u65f6\u786e\u4fdd\u51c6\u786e\u63a8\u65ad\u7684\u6700\u5927\u51c6\u786e\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u81ea\u7136\u8f93\u5165\u4e2d\u9ad8\u6548\u5b66\u4e60\u5982\u4f55\u89e3\u51b3NP\u96be\u7684\u63a8\u7406\u95ee\u9898\u3002\u5728\u6570\u72ec\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e09\u4e2a\u53d8\u4f53\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6240\u9700\u7684\u8bad\u7ec3\u65f6\u95f4\u4ec5\u4e3a\u5176\u4ed6\u6df7\u5408\u65b9\u6cd5\u7684\u4e00\u90e8\u5206\u3002\u5728\u89c6\u89c9Min-Cut/Max-Cut\u4efb\u52a1\u4e0a\uff0c\u4e0eDecision-Focused-Learning\u7684\u540e\u6094\u4e13\u7528\u635f\u5931\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u4f18\u5316\u540e\u6094\u66f4\u597d\u3002\u6b64\u5916\uff0c\u5b83\u6709\u6548\u5730\u5b66\u4e60\u4e86\u8bbe\u8ba1\u86cb\u767d\u8d28\u8fd9\u4e00\u5927\u578b\u73b0\u5b9e\u95ee\u9898\u7684\u80fd\u91cf\u4f18\u5316\u516c\u5f0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5fae\u7684\u795e\u7ecf\u7b26\u53f7\u5316\u67b6\u6784\u548c\u635f\u5931\u51fd\u6570\uff0c\u4e13\u95e8\u7528\u4e8e\u5b66\u4e60\u5982\u4f55\u89e3\u51b3NP\u96be\u7684\u63a8\u7406\u95ee\u9898\u3002\u901a\u8fc7\u63a8\u52a8\u7ec4\u5408\u6c42\u89e3\u5668\u8131\u79bb\u8bad\u7ec3\u5faa\u73af\uff0c\u8be5\u67b6\u6784\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u65b9\u5f0f\uff0c\u540c\u65f6\u786e\u4fdd\u51c6\u786e\u63a8\u65ad\u7684\u6700\u5927\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u5982\u4f55\u4ece\u81ea\u7136\u8f93\u5165\u4e2d\u89e3\u51b3NP\u96be\u7684\u63a8\u7406\u95ee\u9898\u3002\u5728\u4e09\u4e2a\u4e0d\u540c\u79cd\u7c7b\u7684\u6570\u72ec\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6240\u9700\u7684\u8bad\u7ec3\u65f6\u95f4\u4ec5\u4e3a\u5176\u4ed6\u6df7\u5408\u65b9\u6cd5\u7684\u4e00\u5c0f\u90e8\u5206\u3002\u5728\u89c6\u89c9Min-Cut/Max-Cut\u4efb\u52a1\u4e0a\uff0c\u5b83\u4f18\u5316\u540e\u6094\u6bd4Decision-Focused-Learning\u540e\u6094\u4e13\u7528\u635f\u5931\u66f4\u597d\u3002\u6700\u540e\uff0c\u5b83\u8fd8\u6709\u6548\u5730\u5b66\u4e60\u4e86\u8bbe\u8ba1\u86cb\u767d\u8d28\u8fd9\u4e00\u5927\u578b\u73b0\u5b9e\u95ee\u9898\u7684\u80fd\u91cf\u4f18\u5316\u516c\u5f0f\u3002"}}
{"id": "2508.20996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.20996", "abs": "https://arxiv.org/abs/2508.20996", "authors": ["Junda Wang", "Zonghai Yao", "Zhichao Yang", "Lingxi Li", "Junhui Qian", "Hong Yu"], "title": "ChatThero: An LLM-Supported Chatbot for Behavior Change and Therapeutic Support in Addiction Recovery", "comment": null, "summary": "Substance use disorders (SUDs) affect over 36 million people worldwide, yet\nfew receive effective care due to stigma, motivational barriers, and limited\npersonalized support. Although large language models (LLMs) show promise for\nmental-health assistance, most systems lack tight integration with clinically\nvalidated strategies, reducing effectiveness in addiction recovery. We present\nChatThero, a multi-agent conversational framework that couples dynamic patient\nmodeling with context-sensitive therapeutic dialogue and adaptive persuasive\nstrategies grounded in cognitive behavioral therapy (CBT) and motivational\ninterviewing (MI). We build a high-fidelity synthetic benchmark spanning Easy,\nMedium, and Hard resistance levels, and train ChatThero with a two-stage\npipeline comprising supervised fine-tuning (SFT) followed by direct preference\noptimization (DPO). In evaluation, ChatThero yields a 41.5\\% average gain in\npatient motivation, a 0.49\\% increase in treatment confidence, and resolves\nhard cases with 26\\% fewer turns than GPT-4o, and both automated and human\nclinical assessments rate it higher in empathy, responsiveness, and behavioral\nrealism. The framework supports rigorous, privacy-preserving study of\ntherapeutic conversation and provides a robust, replicable basis for research\nand clinical translation.", "AI": {"tldr": "ChatThero is a conversational framework that enhances patient motivation, treatment confidence, and efficiency in addressing substance use disorders. It outperforms existing systems in empathy, responsiveness, and behavioral realism. The framework integrates patient modeling, therapeutic dialogue, and persuasive strategies based on CBT and MI, trained using a two-stage pipeline. ChatThero provides personalized support and a replicable basis for research and clinical translation.", "motivation": "The motivation behind this paper is to address the limited personalized support available for individuals with substance use disorders due to stigma, motivational barriers, and the lack of integration of large language models (LLMs) with clinically validated strategies. The authors aim to enhance addiction recovery by developing a conversational framework that effectively combines patient modeling and evidence-based therapeutic approaches to provide tailored assistance.", "method": "The paper presents ChatThero, a framework that integrates dynamic patient modeling, context-sensitive therapeutic dialogue, and adaptive persuasive strategies based on cognitive behavioral therapy (CBT) and motivational interviewing (MI). ChatThero is trained using a two-stage pipeline involving supervised fine-tuning (SFT) and direct preference optimization (DPO). A high-fidelity synthetic benchmark is utilized to evaluate ChatThero's performance across different resistance levels.", "result": "ChatThero achieves a 41.5% average gain in patient motivation, a 0.49% increase in treatment confidence, and resolves hard cases with 26% fewer turns compared to GPT-4o. It outperforms existing systems in empathy, responsiveness, and behavioral realism according to both automated and human clinical assessments. The framework establishes a foundation for studying therapeutic conversations in a privacy-preserving manner and offers a robust basis for further research and clinical application.", "conclusion": "ChatThero, a multi-agent conversational framework, demonstrates significant improvements in patient motivation, treatment confidence, and efficiency in resolving hard cases compared to existing systems. It also receives high ratings in empathy, responsiveness, and behavioral realism from both automated and human clinical assessments. The framework offers a promising approach to providing personalized support for individuals with substance use disorders."}}
