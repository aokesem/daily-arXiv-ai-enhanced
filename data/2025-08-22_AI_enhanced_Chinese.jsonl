{"id": "2508.14923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14923", "abs": "https://arxiv.org/abs/2508.14923", "authors": ["Andrew Kiruluta"], "title": "A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone", "comment": null, "summary": "We propose a fully spectral, neuro\\-symbolic reasoning architecture that\nleverages Graph Signal Processing (GSP) as the primary computational backbone\nfor integrating symbolic logic and neural inference. Unlike conventional\nreasoning models that treat spectral graph methods as peripheral components,\nour approach formulates the entire reasoning pipeline in the graph spectral\ndomain. Logical entities and relationships are encoded as graph signals,\nprocessed via learnable spectral filters that control multi-scale information\npropagation, and mapped into symbolic predicates for rule-based inference. We\npresent a complete mathematical framework for spectral reasoning, including\ngraph Fourier transforms, band-selective attention, and spectral rule\ngrounding. Experiments on benchmark reasoning datasets (ProofWriter,\nEntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in\nlogical consistency, interpretability, and computational efficiency over\nstate\\-of\\-the\\-art neuro\\-symbolic models. Our results suggest that GSP\nprovides a mathematically grounded and computationally efficient substrate for\nrobust and interpretable reasoning systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u4fe1\u53f7\u5904\u7406\u7684\u5149\u8c31\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u5149\u8c31\u6ee4\u6ce2\u5668\u5904\u7406\u56fe\u4fe1\u53f7\uff0c\u5b9e\u73b0\u591a\u5c3a\u5ea6\u4fe1\u606f\u4f20\u64ad\uff0c\u8fdb\u800c\u63d0\u5347\u903b\u8f91\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u63a8\u7406\u6a21\u578b\u5c06\u5149\u8c31\u56fe\u65b9\u6cd5\u89c6\u4e3a\u5916\u56f4\u7ec4\u4ef6\uff0c\u4f46\u8be5\u65b9\u6cd5\u5728\u56fe\u5149\u8c31\u57df\u4e2d\u5236\u5b9a\u6574\u4e2a\u63a8\u7406\u6d41\u7a0b\uff0c\u5c06\u903b\u8f91\u5b9e\u4f53\u548c\u5173\u7cfb\u7f16\u7801\u4e3a\u56fe\u4fe1\u53f7\u8fdb\u884c\u5904\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u4fe1\u53f7\u5904\u7406\u7684\u5149\u8c31\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5149\u8c31\u6ee4\u6ce2\u5668\u5904\u7406\u56fe\u4fe1\u53f7\uff0c\u63a7\u5236\u591a\u5c3a\u5ea6\u4fe1\u606f\u4f20\u64ad\uff0c\u5e76\u6620\u5c04\u6210\u7b26\u53f7\u8c13\u8bcd\u8fdb\u884c\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u57fa\u51c6\u63a8\u7406\u6570\u636e\u96c6\u4e0a\uff08ProofWriter\uff0cEntailmentBank\uff0cbAbI\uff0cCLUTRR\u548cARC-Challenge\uff09\u4e0e\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u76f8\u6bd4\uff0c\u5728\u903b\u8f91\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u6539\u8fdb\u3002", "conclusion": "GSP\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5f3a\u5927\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u57fa\u7840\u3002"}}
{"id": "2508.15013", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.15013", "abs": "https://arxiv.org/abs/2508.15013", "authors": ["Nadav Amir", "Stas Tiomkin", "Angela Langdon"], "title": "Goals and the Structure of Experience", "comment": null, "summary": "Purposeful behavior is a hallmark of natural and artificial intelligence. Its\nacquisition is often believed to rely on world models, comprising both\ndescriptive (what is) and prescriptive (what is desirable) aspects that\nidentify and evaluate state of affairs in the world, respectively. Canonical\ncomputational accounts of purposeful behavior, such as reinforcement learning,\nposit distinct components of a world model comprising a state representation\n(descriptive aspect) and a reward function (prescriptive aspect). However, an\nalternative possibility, which has not yet been computationally formulated, is\nthat these two aspects instead co-emerge interdependently from an agent's goal.\nHere, we describe a computational framework of goal-directed state\nrepresentation in cognitive agents, in which the descriptive and prescriptive\naspects of a world model co-emerge from agent-environment interaction\nsequences, or experiences. Drawing on Buddhist epistemology, we introduce a\nconstruct of goal-directed, or telic, states, defined as classes of\ngoal-equivalent experience distributions. Telic states provide a parsimonious\naccount of goal-directed learning in terms of the statistical divergence\nbetween behavioral policies and desirable experience features. We review\nempirical and theoretical literature supporting this novel perspective and\ndiscuss its potential to provide a unified account of behavioral,\nphenomenological and neural dimensions of purposeful behaviors across diverse\nsubstrates.", "AI": {"tldr": "\u672c\u6587\u63cf\u8ff0\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u5176\u4e2d\u4ee3\u7406-\u73af\u5883\u4ea4\u4e92\u5e8f\u5217\u6216\u7ecf\u9a8c\u4e2d\u7684\u63cf\u8ff0\u6027\u548c\u89c4\u8303\u6027\u4e16\u754c\u6a21\u578b\u76f8\u4e92\u51fa\u73b0\uff0c\u63d0\u4f9b\u4e86\u76ee\u6807\u5bfc\u5411\u5b66\u4e60\u7684\u7b80\u660e\u89e3\u91ca\u3002\u901a\u8fc7\u5f15\u5165\u76ee\u6807\u5bfc\u5411\u72b6\u6001\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\u6765\u7406\u89e3\u76ee\u6807\u5bfc\u5411\u5b66\u4e60\u548c\u884c\u4e3a\uff0c\u53ef\u80fd\u6709\u52a9\u4e8e\u63d0\u4f9b\u5bf9\u4e0d\u540c\u57fa\u8d28\u4e2d\u6709\u76ee\u7684\u884c\u4e3a\u7684\u7edf\u4e00\u89e3\u91ca\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u548c\u8ba4\u77e5\u4ee3\u7406\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u65e8\u5728\u4ece\u4ee3\u7406-\u73af\u5883\u4ea4\u4e92\u4e2d\u63a8\u5bfc\u63cf\u8ff0\u6027\u548c\u89c4\u8303\u6027\u4e16\u754c\u6a21\u578b\u7684\u65b9\u9762\uff0c\u4ee5\u63d0\u4f9b\u5bf9\u6709\u76ee\u7684\u5b66\u4e60\u548c\u884c\u4e3a\u7684\u7edf\u4e00\u89e3\u91ca\u3002", "method": "\u4f5c\u8005\u63cf\u8ff0\u4e86\u4e00\u4e2a\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u8868\u793a\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5176\u4e2d\u4e16\u754c\u6a21\u578b\u7684\u63cf\u8ff0\u6027\u548c\u89c4\u8303\u6027\u65b9\u9762\u662f\u4ece\u4ee3\u7406-\u73af\u5883\u4ea4\u4e92\u5e8f\u5217\u6216\u7ecf\u9a8c\u4e2d\u76f8\u4e92\u51fa\u73b0\u7684\u3002\u5f15\u5165\u4e86\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u7684\u6784\u5efa\uff0c\u5b9a\u4e49\u4e3a\u76ee\u6807\u7b49\u6548\u7ecf\u9a8c\u5206\u5e03\u7c7b\u3002\u8fd9\u4e9b\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u901a\u8fc7\u884c\u4e3a\u7b56\u7565\u548c\u7406\u60f3\u7ecf\u9a8c\u7279\u5f81\u4e4b\u95f4\u7684\u7edf\u8ba1\u5206\u6b67\u6765\u89e3\u91ca\u76ee\u6807\u5bfc\u5411\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u8868\u793a\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5e76\u9610\u8ff0\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u7684\u6982\u5ff5\u548c\u4f5c\u7528\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\u6765\u7406\u89e3\u6709\u76ee\u7684\u5b66\u4e60\u548c\u884c\u4e3a\u3002\u8be5\u89c6\u89d2\u53ef\u80fd\u6709\u52a9\u4e8e\u63d0\u4f9b\u5bf9\u884c\u4e3a\u3001\u73b0\u8c61\u5b66\u548c\u795e\u7ecf\u7ef4\u5ea6\u4e2d\u6709\u76ee\u7684\u884c\u4e3a\u7684\u7edf\u4e00\u89e3\u91ca\u3002", "conclusion": "\u672c\u6587\u63cf\u8ff0\u4e86\u4e00\u4e2a\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u8868\u793a\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5176\u4e2d\u4e16\u754c\u6a21\u578b\u7684\u63cf\u8ff0\u6027\u548c\u89c4\u8303\u6027\u65b9\u9762\u662f\u4ece\u4ee3\u7406-\u73af\u5883\u4ea4\u4e92\u5e8f\u5217\u6216\u7ecf\u9a8c\u4e2d\u76f8\u4e92\u51fa\u73b0\u7684\u3002\u4f5c\u8005\u4ecb\u7ecd\u4e86\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u7684\u6784\u5efa\uff0c\u63d0\u51fa\u4e86\u76ee\u6807\u7b49\u6548\u7ecf\u9a8c\u5206\u5e03\u7c7b\u7684\u6982\u5ff5\u3002\u8fd9\u4e9b\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u901a\u8fc7\u884c\u4e3a\u7b56\u7565\u548c\u7406\u60f3\u7ecf\u9a8c\u7279\u5f81\u4e4b\u95f4\u7684\u7edf\u8ba1\u5206\u6b67\u63d0\u4f9b\u4e86\u76ee\u6807\u5bfc\u5411\u5b66\u4e60\u7684\u7b80\u660e\u89e3\u91ca\u3002\u6587\u7ae0\u56de\u987e\u4e86\u652f\u6301\u8fd9\u4e00\u65b0\u9896\u89c2\u70b9\u7684\u7ecf\u9a8c\u548c\u7406\u8bba\u6587\u732e\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u6f5c\u529b\uff0c\u53ef\u4ee5\u63d0\u4f9b\u5bf9\u8de8\u591a\u79cd\u57fa\u8d28\u7684\u6709\u76ee\u7684\u884c\u4e3a\u7684\u884c\u4e3a\u3001\u73b0\u8c61\u5b66\u548c\u795e\u7ecf\u7ef4\u5ea6\u7684\u7edf\u4e00\u89e3\u91ca\u3002"}}
{"id": "2508.15030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15030", "abs": "https://arxiv.org/abs/2508.15030", "authors": ["Ashmi Banerjee", "Fitri Nur Aisyah", "Adithi Satish", "Wolfgang W\u00f6rndl", "Yashar Deldjoo"], "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "comment": null, "summary": "We propose Collab-REC, a multi-agent framework designed to counteract\npopularity bias and enhance diversity in tourism recommendations. In our\nsetting, three LLM-based agents -- Personalization, Popularity, and\nSustainability generate city suggestions from complementary perspectives. A\nnon-LLM moderator then merges and refines these proposals via multi-round\nnegotiation, ensuring each agent's viewpoint is incorporated while penalizing\nspurious or repeated responses. Experiments on European city queries show that\nCollab-REC improves diversity and overall relevance compared to a single-agent\nbaseline, surfacing lesser-visited locales that often remain overlooked. This\nbalanced, context-aware approach addresses over-tourism and better aligns with\nconstraints provided by the user, highlighting the promise of multi-stakeholder\ncollaboration in LLM-driven recommender systems.", "AI": {"tldr": "Collab-REC introduces a multi-agent approach using LLM-based agents and a moderator to enhance tourism recommendations, showing improvements in diversity and relevance in European city suggestions.", "motivation": "Countering popularity bias, enhancing diversity in tourism recommendations, surfacing lesser-visited locales, addressing over-tourism, aligning with user constraints.", "method": "Utilizes three LLM-based agents (Personalization, Popularity, Sustainability) and a non-LLM moderator for multi-round negotiation and proposal merging.", "result": "Improves diversity and relevance in European city recommendations compared to a single-agent baseline.", "conclusion": "Collab-REC, a multi-agent framework, improves diversity and overall relevance in tourism recommendations, addressing over-tourism and aligning with user constraints."}}
{"id": "2508.15047", "categories": ["cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2508.15047", "abs": "https://arxiv.org/abs/2508.15047", "authors": ["Yibo Liu", "Liam Shatzel", "Brandon Haworth", "Teseo Schneider"], "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions", "comment": null, "summary": "Animating and simulating crowds using an agent-based approach is a\nwell-established area where every agent in the crowd is individually controlled\nsuch that global human-like behaviour emerges. We observe that human navigation\nand movement in crowds are often influenced by complex social and environmental\ninteractions, driven mainly by language and dialogue. However, most existing\nwork does not consider these dimensions and leads to animations where\nagent-agent and agent-environment interactions are largely limited to steering\nand fixed higher-level goal extrapolation.\n  We propose a novel method that exploits large language models (LLMs) to\ncontrol agents' movement. Our method has two main components: a dialogue system\nand language-driven navigation. We periodically query agent-centric LLMs\nconditioned on character personalities, roles, desires, and relationships to\ncontrol the generation of inter-agent dialogue when necessitated by the spatial\nand social relationships with neighbouring agents. We then use the conversation\nand each agent's personality, emotional state, vision, and physical state to\ncontrol the navigation and steering of each agent. Our model thus enables\nagents to make motion decisions based on both their perceptual inputs and the\nongoing dialogue.\n  We validate our method in two complex scenarios that exemplify the interplay\nbetween social interactions, steering, and crowding. In these scenarios, we\nobserve that grouping and ungrouping of agents automatically occur.\nAdditionally, our experiments show that our method serves as an\ninformation-passing mechanism within the crowd. As a result, our framework\nproduces more realistic crowd simulations, with emergent group behaviours\narising naturally from any environmental setting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a7\u5236\u4ee3\u7406\u4eba\u7684\u79fb\u52a8\uff0c\u4ee5\u5b9e\u73b0\u66f4\u903c\u771f\u7684\u4eba\u7fa4\u52a8\u753b\u548c\u6a21\u62df\u3002\u65b9\u6cd5\u5305\u62ec\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u7684\u5bfc\u822a\uff0c\u4f7f\u4ee3\u7406\u4eba\u57fa\u4e8e\u611f\u77e5\u8f93\u5165\u548c\u5bf9\u8bdd\u505a\u51fa\u8fd0\u52a8\u51b3\u7b56\u3002\u4f5c\u8005\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u573a\u666f\u4e2d\u4ea7\u751f\u66f4\u771f\u5b9e\u7684\u7fa4\u4f53\u884c\u4e3a\uff0c\u4ee5\u53ca\u65b9\u6cd5\u4f5c\u4e3a\u4fe1\u606f\u4f20\u9012\u673a\u5236\u7684\u6548\u679c\u3002", "motivation": "\u4eba\u7c7b\u5728\u62e5\u6324\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u548c\u79fb\u52a8\u5e38\u5e38\u53d7\u5230\u590d\u6742\u7684\u793e\u4ea4\u548c\u73af\u5883\u5f71\u54cd\uff0c\u4e3b\u8981\u53d7\u5230\u8bed\u8a00\u548c\u5bf9\u8bdd\u7684\u9a71\u52a8\u3002\u73b0\u6709\u7684\u5de5\u4f5c\u5927\u591a\u6ca1\u6709\u8003\u8651\u8fd9\u4e9b\u7ef4\u5ea6\uff0c\u5bfc\u81f4\u52a8\u753b\u4e2d\u4ee3\u7406\u4eba\u4e4b\u95f4\u548c\u4ee3\u7406\u4eba\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4ea4\u4e92\u5c40\u9650\u4e8e\u8f6c\u5411\u548c\u56fa\u5b9a\u7684\u9ad8\u7ea7\u76ee\u6807\u9884\u6d4b\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a7\u5236\u4ee3\u7406\u4eba\u79fb\u52a8\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u5bf9\u8bdd\u7cfb\u7edf\u548c\u57fa\u4e8e\u8bed\u8a00\u9a71\u52a8\u7684\u5bfc\u822a\uff0c\u901a\u8fc7\u5468\u671f\u6027\u67e5\u8be2\u4ee3\u7406\u4eba\u4e2d\u5fc3\u7684LLMs\u6765\u751f\u6210\u4ee3\u7406\u4eba\u4e4b\u95f4\u7684\u5bf9\u8bdd\uff0c\u5e76\u5229\u7528\u5bf9\u8bdd\u5185\u5bb9\u548c\u6bcf\u4e2a\u4ee3\u7406\u4eba\u7684\u7279\u5f81\u6765\u63a7\u5236\u4ed6\u4eec\u7684\u5bfc\u822a\u548c\u8f6c\u5411\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u4ee3\u7406\u4eba\u53ef\u4ee5\u57fa\u4e8e\u611f\u77e5\u8f93\u5165\u548c\u5bf9\u8bdd\u6765\u505a\u51fa\u79fb\u52a8\u51b3\u7b56\u3002", "result": "\u4f5c\u8005\u901a\u8fc7\u4e24\u4e2a\u590d\u6742\u573a\u666f\u9a8c\u8bc1\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u793e\u4ea4\u4e92\u52a8\u3001\u8f6c\u5411\u548c\u62e5\u6324\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u4ee3\u7406\u4eba\u81ea\u52a8\u805a\u5408\u548c\u89e3\u805a\u7684\u6548\u679c\u3002\u5b9e\u9a8c\u8bc1\u660e\u4ed6\u4eec\u7684\u65b9\u6cd5\u4f5c\u4e3a\u4fe1\u606f\u4f20\u9012\u673a\u5236\uff0c\u5728\u4eba\u7fa4\u5185\u4ea7\u751f\u66f4\u52a0\u771f\u5b9e\u7684\u6a21\u62df\u7ed3\u679c\uff0c\u4f7f\u5f97\u7fa4\u4f53\u884c\u4e3a\u80fd\u591f\u81ea\u7136\u6d8c\u73b0\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a7\u5236\u4ee3\u7406\u4eba\u7684\u79fb\u52a8\uff0c\u4ee5\u5b9e\u73b0\u66f4\u903c\u771f\u7684\u4eba\u7fa4\u52a8\u753b\u548c\u6a21\u62df\u3002\u4ed6\u4eec\u7684\u6a21\u578b\u4f7f\u4ee3\u7406\u4eba\u80fd\u591f\u57fa\u4e8e\u611f\u77e5\u8f93\u5165\u548c\u8fdb\u884c\u4e2d\u7684\u5bf9\u8bdd\u505a\u51fa\u8fd0\u52a8\u51b3\u7b56\uff0c\u5b9e\u73b0\u4e86\u7fa4\u4f53\u884c\u4e3a\u7684\u81ea\u7136\u6d8c\u73b0\u3002\u901a\u8fc7\u5728\u590d\u6742\u573a\u666f\u4e2d\u9a8c\u8bc1\u4ed6\u4eec\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u793e\u4ea4\u4e92\u52a8\u3001\u8f6c\u5411\u548c\u62e5\u6324\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u4ee3\u7406\u4eba\u81ea\u52a8\u805a\u5408\u548c\u89e3\u805a\u7684\u6548\u679c\u3002\u8bba\u6587\u7684\u7ed3\u8bba\u5f3a\u8c03\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u4f5c\u4e3a\u4eba\u7fa4\u5185\u7684\u4fe1\u606f\u4f20\u9012\u673a\u5236\uff0c\u4ea7\u751f\u4e86\u66f4\u52a0\u771f\u5b9e\u7684\u4eba\u7fa4\u6a21\u62df\u7ed3\u679c\u3002"}}
{"id": "2508.15050", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15050", "abs": "https://arxiv.org/abs/2508.15050", "authors": ["Romain Lacombe", "Kerrie Wu", "Eddie Dilworth"], "title": "Don't Think Twice! Over-Reasoning Impairs Confidence Calibration", "comment": "Published at ICML 2025 Workshop on Reliable and Responsible\n  Foundation Models", "summary": "Large Language Models deployed as question answering tools require robust\ncalibration to avoid overconfidence. We systematically evaluate how reasoning\ncapabilities and budget affect confidence assessment accuracy, using the\nClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary\nhealth. Our key finding challenges the \"test-time scaling\" paradigm: while\nrecent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,\nincreasing reasoning budgets consistently impairs rather than improves\ncalibration. Extended reasoning leads to systematic overconfidence that worsens\nwith longer thinking budgets, producing diminishing and negative returns beyond\nmodest computational investments. Conversely, search-augmented generation\ndramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving\nrelevant evidence. Our results suggest that information access, rather than\nreasoning depth or inference budget, may be the critical bottleneck for\nimproved confidence calibration of knowledge-intensive tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u63a8\u7406\u80fd\u529b\u548c\u9884\u7b97\u5982\u4f55\u5f71\u54cd\u4fe1\u5fc3\u8bc4\u4f30\u51c6\u786e\u6027\uff0c\u53d1\u73b0\u641c\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u7eaf\u63a8\u7406\uff0c\u4e14\u4fe1\u606f\u83b7\u53d6\u53ef\u80fd\u662f\u63d0\u9ad8\u4fe1\u5fc3\u6821\u51c6\u7684\u5173\u952e\u3002", "motivation": "\u4e3a\u4e86\u907f\u514d\u8fc7\u5ea6\u786e\u4fe1\uff0c\u9700\u8981\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6709\u6548\u6821\u51c6\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\u548c\u9884\u7b97\u5982\u4f55\u5f71\u54cd\u4fe1\u5fc3\u8bc4\u4f30\u51c6\u786e\u6027\uff0c\u4f7f\u7528ClimateX\u6570\u636e\u96c6\u5e76\u6269\u5c55\u5230\u4eba\u7c7b\u548c\u5730\u7403\u5065\u5eb7\u3002", "result": "\u6700\u8fd1\u7684\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u4e13\u5bb6\u4fe1\u5fc3\u65b9\u9762\u7684\u51c6\u786e\u7387\u4e3a48.7%\uff0c\u4fe1\u606f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u53ef\u4ee5\u8fbe\u523089.3%\u7684\u51c6\u786e\u7387\u3002\u63a8\u7406\u9884\u7b97\u7684\u589e\u52a0\u5bfc\u81f4\u7cfb\u7edf\u6027\u8fc7\u5ea6\u786e\u4fe1\uff0c\u5e76\u4e14\u968f\u7740\u9884\u7b97\u589e\u52a0\u800c\u6076\u5316\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u641c\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u7eaf\u63a8\u7406\uff0c\u5728\u4e13\u5bb6\u4fe1\u5fc3\u8bc4\u4f30\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u63a8\u7406\u9884\u7b97\u7684\u589e\u52a0\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u786e\u4fe1\uff0c\u800c\u4e0d\u662f\u6539\u8fdb\u6821\u51c6\u3002\u4fe1\u606f\u83b7\u53d6\u800c\u975e\u63a8\u7406\u6df1\u5ea6\u6216\u63a8\u7406\u9884\u7b97\u53ef\u80fd\u662f\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4fe1\u5fc3\u6821\u51c6\u6539\u8fdb\u7684\u5173\u952e\u74f6\u9888\u3002"}}
{"id": "2508.15053", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15053", "abs": "https://arxiv.org/abs/2508.15053", "authors": ["Itai Zilberstein", "Alberto Candela", "Steve Chien", "David Rijlaarsdam", "Tom Hendrix", "Leonie Buckley", "Aubrey Dunne"], "title": "Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning", "comment": "International Symposium on Artificial Intelligence, Robotics and\n  Automation in Space, November 2024", "summary": "In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is\ndemonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).\nCS-6 is a satellite with a visible and near infrared range hyperspectral\ninstrument and neural network acceleration hardware. Performing data analysis\nat the edge (e.g. onboard) can enable new Earth science measurements and\nresponses. We will demonstrate data analysis and inference onboard CS-6 for\nnumerous applications using deep learning and spectral analysis algorithms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u548c\u5149\u8c31\u5206\u6790\u7b97\u6cd5\u5728CS-6\u536b\u661f\u4e0a\u8fdb\u884c\u6570\u636e\u5206\u6790\u548c\u63a8\u65ad\uff0c\u4e3a\u591a\u79cd\u5e94\u7528\u63d0\u4f9b\u65b0\u7684\u5730\u7403\u79d1\u5b66\u6d4b\u91cf\u548c\u54cd\u5e94\u80fd\u529b\u3002", "motivation": "\u5408\u4f5c\u4f19\u4f34Ubotica Technologies\u4e0e\u55b7\u6c14\u63a8\u8fdb\u5b9e\u9a8c\u5ba4\uff08Jet Propulsion Laboratory\uff09\u5408\u4f5c\uff0c\u5c55\u793a\u4e86CS-6\u536b\u661f\u4e0a\u6700\u5148\u8fdb\u7684\u6570\u636e\u5206\u6790\u3002\u901a\u8fc7\u5728\u8fb9\u7f18\u8fdb\u884c\u6570\u636e\u5206\u6790\uff0c\u53ef\u4ee5\u5f00\u542f\u65b0\u7684\u5730\u7403\u79d1\u5b66\u6d4b\u91cf\u548c\u54cd\u5e94\u65b9\u6cd5\u3002", "method": "\u5229\u7528CS-6\u536b\u661f\u7684\u53ef\u89c1\u5149\u548c\u8fd1\u7ea2\u5916\u8303\u56f4\u9ad8\u5149\u8c31\u4eea\u5668\u548c\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u786c\u4ef6\uff0c\u5728\u8fb9\u7f18\uff08\u4f8b\u5982\u536b\u661f\u4e0a\uff09\u6267\u884c\u6570\u636e\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5728CS-6\u536b\u661f\u4e0a\u8fdb\u884c\u6570\u636e\u5206\u6790\u548c\u63a8\u65ad\uff0c\u53ef\u5b9e\u73b0\u5404\u79cd\u5e94\u7528\u7684\u65b0\u5730\u7403\u79d1\u5b66\u6d4b\u91cf\u548c\u54cd\u5e94\u3002", "conclusion": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5728CS-6\u536b\u661f\u4e0a\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u548c\u5149\u8c31\u5206\u6790\u7b97\u6cd5\u8fdb\u884c\u6570\u636e\u5206\u6790\u548c\u63a8\u65ad\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4e3a\u591a\u79cd\u5e94\u7528\u63d0\u4f9b\u65b0\u7684\u5730\u7403\u79d1\u5b66\u6d4b\u91cf\u548c\u54cd\u5e94\u80fd\u529b\u3002"}}
{"id": "2508.15068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15068", "abs": "https://arxiv.org/abs/2508.15068", "authors": ["Shuang Ao", "Gopal Rumchurn"], "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner", "comment": "9 pages, 2 figures", "summary": "Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning\n(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based\nagents. However, these adaptations can unintentionally compromise safety\nalignment, leading to unsafe or unstable behaviors, particularly in agent\nplanning tasks. Existing safety-aware adaptation methods often require access\nto both base and instruction-tuned model checkpoints, which are frequently\nunavailable in practice, limiting their applicability. We propose S3LoRA (Safe\nSpectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and\nmodel-independent framework that mitigates safety risks in LoRA-adapted models\nby inspecting only the fine-tuned weight updates. We first introduce\nMagnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes\nthe structural properties of LoRA updates while preserving global magnitude\ninformation. We then design the Spectral Sharpness Index (SSI), a\nsharpness-aware metric to detect layers with highly concentrated and\npotentially unsafe updates. These layers are pruned post-hoc to reduce risk\nwithout sacrificing task performance. Extensive experiments and ablation\nstudies across agent planning and language generation tasks show that S3LoRA\nconsistently improves safety metrics while maintaining or improving utility\nmetrics and significantly reducing inference cost. These results establish\nS3LoRA as a practical and scalable solution for safely deploying LLM-based\nagents in real-world, resource-constrained, and safety-critical environments.", "AI": {"tldr": "S3LoRA is a lightweight, data-free, and model-independent framework designed to mitigate safety risks in LoRA-adapted large language models. It leverages MAS-SVD and SSI to analyze and prune unsafe layers, improving safety metrics while maintaining task performance. Experiments demonstrate its effectiveness in enhancing safety, utility metrics, and reducing inference cost for LLM-based agents in safety-critical environments.", "motivation": "Existing safety-aware adaptation methods for large language models often require access to base and instruction-tuned model checkpoints, which are not always available in practice. The motivation behind S3LoRA is to address safety risks in LoRA-adapted models without the need for extensive data or model-specific information. The goal is to enhance the safety of LLM-based agents in real-world, resource-constrained, and safety-critical environments.", "method": "The paper introduces the S3LoRA framework, consisting of two main components: MAS-SVD for analyzing structural properties of LoRA updates and preserving global magnitude information, and SSI for detecting highly concentrated and potentially unsafe updates in layers. Unsafe layers are pruned post-hoc to reduce risks without compromising task performance. Extensive experiments and ablation studies are conducted across agent planning and language generation tasks to evaluate the effectiveness of S3LoRA.", "result": "S3LoRA consistently improves safety metrics, preserves or enhances utility metrics, and reduces inference cost across various tasks such as agent planning and language generation. The proposed framework provides a practical and scalable solution for deploying large language models in safety-critical scenarios.", "conclusion": "S3LoRA is proposed as a lightweight, data-free, and model-independent framework that mitigates safety risks in LoRA-adapted large language models by inspecting fine-tuned weight updates and pruning potentially unsafe layers. The experiments demonstrate that S3LoRA improves safety metrics while maintaining or enhancing utility metrics and reducing inference cost, making it a practical and scalable solution for deploying LLM-based agents in safety-critical environments."}}
{"id": "2508.15118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15118", "abs": "https://arxiv.org/abs/2508.15118", "authors": ["Jennifer Leigh", "Dimitrios Letsios", "Alessandro Mella", "Lucio Machetti", "Francesca Toni"], "title": "Argumentation for Explainable Workforce Optimisation (with Appendix)", "comment": "Accepted to PAIS 2025", "summary": "Workforce management is a complex problem optimising the makespan and travel\ndistance required for a team of operators to complete a set of jobs, using a\nset of instruments. A crucial challenge in workforce management is\naccommodating changes at execution time so that explanations are provided to\nall stakeholders involved. Here, we show that, by understanding workforce\nmanagement as abstract argumentation in an industrial application, we can\naccommodate change and obtain faithful explanations. We show, with a user\nstudy, that our tool and explanations lead to faster and more accurate problem\nsolving than conventional solutions by hand.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u5de5\u4f5c\u4eba\u5458\u7ba1\u7406\u89c6\u4e3a\u62bd\u8c61\u8bba\u8bc1\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u5de5\u5177\u548c\u89e3\u91ca\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u76f8\u8f83\u4e8e\u4f20\u7edf\u624b\u52a8\u89e3\u51b3\u65b9\u6848\u66f4\u5feb\u901f\u3001\u66f4\u51c6\u786e\u7684\u95ee\u9898\u89e3\u51b3\u6548\u679c\u3002", "motivation": "\u5de5\u4f5c\u4eba\u5458\u7ba1\u7406\u662f\u4e00\u4e2a\u590d\u6742\u7684\u95ee\u9898\uff0c\u9700\u8981\u4f18\u5316\u64cd\u4f5c\u961f\u4f0d\u5b8c\u6210\u4e00\u7ec4\u5de5\u4f5c\u6240\u9700\u7684\u65f6\u95f4\u548c\u884c\u7a0b\u3002\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u9002\u5e94\u53d8\u5316\u5e76\u5411\u6240\u6709\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u89e3\u91ca\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5c06\u5de5\u4f5c\u4eba\u5458\u7ba1\u7406\u89c6\u4e3a\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u62bd\u8c61\u8bba\u8bc1\uff0c\u4ee5\u9002\u5e94\u53d8\u5316\u5e76\u63d0\u4f9b\u89e3\u91ca\u3002\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u5de5\u5177\u548c\u89e3\u91ca\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u7814\u7a76\u5de5\u5177\u548c\u89e3\u91ca\u7684\u6548\u679c\uff0c\u6211\u4eec\u53d1\u73b0\u5728\u5de5\u4f5c\u4eba\u5458\u7ba1\u7406\u4e2d\u5c06\u5176\u89c6\u4e3a\u62bd\u8c61\u8bba\u8bc1\u7684\u65b9\u6cd5\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u95ee\u9898\u89e3\u51b3\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5de5\u4f5c\u4eba\u5458\u7ba1\u7406\u89c6\u4e3a\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u62bd\u8c61\u8bba\u8bc1\uff0c\u6211\u4eec\u53ef\u4ee5\u9002\u5e94\u53d8\u5316\u5e76\u83b7\u5f97\u5fe0\u5b9e\u7684\u89e3\u91ca\u3002\u6211\u4eec\u5c55\u793a\u901a\u8fc7\u7528\u6237\u7814\u7a76\uff0c\u6211\u4eec\u7684\u5de5\u5177\u548c\u89e3\u91ca\u6bd4\u4f20\u7edf\u7684\u624b\u52a8\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u5b9e\u73b0\u66f4\u5feb\u901f\u3001\u66f4\u51c6\u786e\u7684\u95ee\u9898\u89e3\u51b3\u3002"}}
{"id": "2508.15119", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15119", "abs": "https://arxiv.org/abs/2508.15119", "authors": ["Rachel Ma", "Jingyi Qu", "Andreea Bobu", "Dylan Hadfield-Menell"], "title": "Open-Universe Assistance Games", "comment": "7 pages + 2 pages references + 7 pages appendix", "summary": "Embodied AI agents must infer and act in an interpretable way on diverse\nhuman goals and preferences that are not predefined. To formalize this setting,\nwe introduce Open-Universe Assistance Games (OU-AGs), a framework where the\nagent must reason over an unbounded and evolving space of possible goals. In\nthis context, we introduce GOOD (GOals from Open-ended Dialogue), a\ndata-efficient, online method that extracts goals in the form of natural\nlanguage during an interaction with a human, and infers a distribution over\nnatural language goals. GOOD prompts an LLM to simulate users with different\ncomplex intents, using its responses to perform probabilistic inference over\ncandidate goals. This approach enables rich goal representations and\nuncertainty estimation without requiring large offline datasets. We evaluate\nGOOD in a text-based grocery shopping domain and in a text-operated simulated\nhousehold robotics environment (AI2Thor), using synthetic user profiles. Our\nmethod outperforms a baseline without explicit goal tracking, as confirmed by\nboth LLM-based and human evaluations.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86OU-AGs\u6846\u67b6\u548cGOOD\u65b9\u6cd5\uff0c\u5728\u63a8\u65ad\u548c\u884c\u52a8\u591a\u6837\u5316\u4eba\u7c7b\u76ee\u6807\u548c\u504f\u597d\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\u3002GOOD\u65b9\u6cd5\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u76ee\u6807\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u65e0\u9700\u5927\u91cf\u79bb\u7ebf\u6570\u636e\u3002\u5728\u5b9e\u8bc1\u8bc4\u4f30\u4e2d\uff0cGOOD\u65b9\u6cd5\u5728\u4e24\u4e2a\u9886\u57df\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "embodied AI agents\u9700\u8981\u80fd\u591f\u7406\u89e3\u548c\u884c\u52a8\u5728\u672a\u9884\u5b9a\u4e49\u7684\u591a\u6837\u5316\u4eba\u7c7b\u76ee\u6807\u548c\u504f\u597d\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u6c42\u5927\u91cf\u79bb\u7ebf\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u53ef\u80fd\u76ee\u6807\u7a7a\u95f4\u7684\u63a8\u7406\u3002\u56e0\u6b64\uff0c\u5f15\u5165\u4e86GOOD\u65b9\u6cd5\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86Open-Universe Assistance Games (OU-AGs)\u6846\u67b6\u548cGOOD (GOals from Open-ended Dialogue)\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0e\u4eba\u7c7b\u4e92\u52a8\u4e2d\u63d0\u53d6\u81ea\u7136\u8bed\u8a00\u76ee\u6807\uff0c\u5e76\u5bf9\u5019\u9009\u76ee\u6807\u8fdb\u884c\u6982\u7387\u63a8\u65ad\uff0c\u5b9e\u73b0\u4e86\u4e30\u5bcc\u7684\u76ee\u6807\u8868\u793a\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002\u5728\u6587\u672c\u8d2d\u7269\u9886\u57df\u548cAI2Thor\u6a21\u62df\u5bb6\u5ead\u673a\u5668\u4eba\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5728\u6587\u672c\u8d2d\u7269\u9886\u57df\u548cAI2Thor\u6a21\u62df\u5bb6\u5ead\u673a\u5668\u4eba\u73af\u5883\u4e2d\uff0cGOOD\u65b9\u6cd5\u4f18\u4e8e\u6ca1\u6709\u660e\u786e\u76ee\u6807\u8ddf\u8e2a\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5f97\u5230\u4e86LLM\u548c\u4eba\u7c7b\u8bc4\u4ef7\u7684\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u4e86Open-Universe Assistance Games (OU-AGs)\u6846\u67b6\uff0c\u4ee5\u5f62\u5f0f\u5316embodied AI agents\u5728\u672a\u9884\u5b9a\u4e49\u7684\u591a\u6837\u5316\u4eba\u7c7b\u76ee\u6807\u548c\u504f\u597d\u4e2d\u63a8\u65ad\u548c\u884c\u52a8\u3002\u5f15\u5165\u4e86GOOD (GOals from Open-ended Dialogue)\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u53d6\u76ee\u6807\u5e76\u63a8\u65ad\u81ea\u7136\u8bed\u8a00\u76ee\u6807\u7684\u5206\u5e03\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u53ef\u80fd\u76ee\u6807\u7a7a\u95f4\u7684\u63a8\u7406\u3002\u5728\u6587\u672c\u8d2d\u7269\u9886\u57df\u548cAI2Thor\u6a21\u62df\u5bb6\u5ead\u673a\u5668\u4eba\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86GOOD\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\u5176\u4f18\u4e8e\u6ca1\u6709\u660e\u786e\u76ee\u6807\u8ddf\u8e2a\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2508.15126", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15126", "abs": "https://arxiv.org/abs/2508.15126", "authors": ["Pengsong Zhang", "Xiang Hu", "Guowei Huang", "Yang Qi", "Heng Zhang", "Xiuxu Li", "Jiaxing Song", "Jiabin Luo", "Yijiang Li", "Shuo Yin", "Chengxiao Dai", "Eric Hanchen Jiang", "Xiaoyan Zhou", "Zhenfei Yin", "Boqin Yuan", "Jing Dong", "Guinan Su", "Guanren Qiao", "Haiming Tang", "Anghong Du", "Lili Pan", "Zhenzhong Lan", "Xinyu Liu"], "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists", "comment": "Preprint under review. Code is available at\n  https://github.com/aixiv-org. Website is available at\n  https://forms.gle/DxQgCtXFsJ4paMtn8", "summary": "Recent advances in large language models (LLMs) have enabled AI agents to\nautonomously generate scientific proposals, conduct experiments, author papers,\nand perform peer reviews. Yet this flood of AI-generated research content\ncollides with a fragmented and largely closed publication ecosystem.\nTraditional journals and conferences rely on human peer review, making them\ndifficult to scale and often reluctant to accept AI-generated research content;\nexisting preprint servers (e.g. arXiv) lack rigorous quality-control\nmechanisms. Consequently, a significant amount of high-quality AI-generated\nresearch lacks appropriate venues for dissemination, hindering its potential to\nadvance scientific progress. To address these challenges, we introduce aiXiv, a\nnext-generation open-access platform for human and AI scientists. Its\nmulti-agent architecture allows research proposals and papers to be submitted,\nreviewed, and iteratively refined by both human and AI scientists. It also\nprovides API and MCP interfaces that enable seamless integration of\nheterogeneous human and AI scientists, creating a scalable and extensible\necosystem for autonomous scientific discovery. Through extensive experiments,\nwe demonstrate that aiXiv is a reliable and robust platform that significantly\nenhances the quality of AI-generated research proposals and papers after\niterative revising and reviewing on aiXiv. Our work lays the groundwork for a\nnext-generation open-access ecosystem for AI scientists, accelerating the\npublication and dissemination of high-quality AI-generated research content.\nCode is available at https://github.com/aixiv-org. Website is available at\nhttps://forms.gle/DxQgCtXFsJ4paMtn8.", "AI": {"tldr": "\u6700\u8fd1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f7f\u5f97\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u80fd\u591f\u81ea\u4e3b\u751f\u6210\u79d1\u5b66\u63d0\u6848\u3001\u8fdb\u884c\u5b9e\u9a8c\u3001\u64b0\u5199\u8bba\u6587\u548c\u8fdb\u884c\u540c\u884c\u8bc4\u5ba1\u3002\u7136\u800c\uff0cAI\u751f\u6210\u7684\u7814\u7a76\u5185\u5bb9\u4e0e\u4f20\u7edf\u7684\u51fa\u7248\u7cfb\u7edf\u53d1\u751f\u51b2\u7a81\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u5f15\u5165aiXiv\uff0c\u4e00\u4e2a\u4e0b\u4e00\u4ee3\u5f00\u653e\u83b7\u53d6\u5e73\u53f0\uff0c\u901a\u8fc7\u591a\u4e3b\u4f53\u67b6\u6784\u5b9e\u73b0\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u7684\u96c6\u6210\uff0c\u663e\u8457\u63d0\u9ad8AI\u751f\u6210\u7814\u7a76\u7684\u8d28\u91cf\uff0c\u52a0\u5feb\u5176\u4f20\u64ad\u901f\u5ea6\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u7814\u7a76\u5185\u5bb9\u7f3a\u4e4f\u4f20\u64ad\u6e20\u9053\u662f\u4e00\u4e2a\u4e25\u91cd\u95ee\u9898\uff0c\u4f20\u7edf\u671f\u520a\u548c\u4f1a\u8bae\u4e3b\u8981\u4f9d\u8d56\u4eba\u7c7b\u540c\u884c\u8bc4\u5ba1\uff0c\u73b0\u6709\u9884\u5370\u672c\u670d\u52a1\u5668\u7f3a\u4e4f\u4e25\u683c\u7684\u8d28\u91cf\u63a7\u5236\u673a\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u5f15\u5165aiXiv\u65e8\u5728\u4e3a\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e00\u4e2a\u5f00\u653e\u83b7\u53d6\u5e73\u53f0\uff0c\u901a\u8fc7\u591a\u4e3b\u4f53\u67b6\u6784\u548cAPI / MCP\u63a5\u53e3\u5b9e\u73b0\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u7684\u96c6\u6210\uff0c\u521b\u9020\u4e00\u4e2a\u53ef\u6269\u5c55\u548c\u53ef\u6269\u5c55\u7684\u751f\u6001\u7cfb\u7edf\u3002", "method": "\u5f15\u5165\u4e86aiXiv\uff0c\u4e00\u4e2a\u591a\u4e3b\u4f53\u67b6\u6784\u7684\u5f00\u653e\u83b7\u53d6\u5e73\u53f0\uff0c\u5141\u8bb8\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u63d0\u4ea4\u3001\u5ba1\u9605\u548c\u53cd\u590d\u5b8c\u5584\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\uff0c\u63d0\u4f9bAPI\u548cMCP\u63a5\u53e3\u5b9e\u73b0\u96c6\u6210\uff0c\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u5c55\u793aaiXiv\u662f\u53ef\u9760\u548c\u5065\u58ee\u7684\u5e73\u53f0\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7814\u7a76\u7684\u8d28\u91cf\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0caiXiv\u662f\u4e00\u4e2a\u53ef\u9760\u548c\u5065\u58ee\u7684\u5e73\u53f0\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\u7684\u8d28\u91cf\u3002\u8be5\u5de5\u4f5c\u4e3a\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u7684\u4e0b\u4e00\u4ee3\u5f00\u653e\u83b7\u53d6\u751f\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u52a0\u5feb\u4e86\u9ad8\u8d28\u91cf\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7814\u7a76\u5185\u5bb9\u7684\u53d1\u5e03\u548c\u4f20\u64ad\u3002", "conclusion": "\u5f15\u5165aiXiv\uff0c\u4e00\u4e2a\u4e0b\u4e00\u4ee3\u5f00\u653e\u83b7\u53d6\u5e73\u53f0\uff0c\u65e8\u5728\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u7814\u7a76\u5185\u5bb9\u7f3a\u4e4f\u4f20\u64ad\u9014\u5f84\u7684\u95ee\u9898\u3002\u901a\u8fc7\u591a\u4e3b\u4f53\u67b6\u6784\uff0c\u5141\u8bb8\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u5171\u540c\u63d0\u4ea4\u3001\u5ba1\u9605\u548c\u53cd\u590d\u5b8c\u5584\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\uff0c\u63d0\u4f9bAPI\u548cMCP\u63a5\u53e3\u4ee5\u5b9e\u73b0\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u4e3a\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u521b\u9020\u53ef\u6269\u5c55\u548c\u53ef\u6269\u5c55\u7684\u751f\u6001\u7cfb\u7edf\u3002\u7814\u7a76\u8868\u660eaiXiv\u662f\u53ef\u9760\u4e14\u5065\u58ee\u7684\u5e73\u53f0\uff0c\u5728aiXiv\u4e0a\u7ecf\u8fc7\u53cd\u590d\u4fee\u8ba2\u548c\u5ba1\u67e5\u663e\u8457\u63d0\u9ad8\u4e86\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\u7684\u8d28\u91cf\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u7684\u4e0b\u4e00\u4ee3\u5f00\u653e\u83b7\u53d6\u751f\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u52a0\u5feb\u4e86\u9ad8\u8d28\u91cf\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7814\u7a76\u5185\u5bb9\u7684\u53d1\u5e03\u548c\u4f20\u64ad\u3002"}}
{"id": "2508.15144", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15144", "abs": "https://arxiv.org/abs/2508.15144", "authors": ["Jiabo Ye", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Zhaoqing Zhu", "Ziwei Zheng", "Feiyu Gao", "Junjie Cao", "Zhengxi Lu", "Jitong Liao", "Qi Zheng", "Fei Huang", "Jingren Zhou", "Ming Yan"], "title": "Mobile-Agent-v3: Foundamental Agents for GUI Automation", "comment": null, "summary": "This paper introduces GUI-Owl, a foundational GUI agent model that achieves\nstate-of-the-art performance among open-source end-to-end models on ten GUI\nbenchmarks across desktop and mobile environments, covering grounding, question\nanswering, planning, decision-making, and procedural knowledge. GUI-Owl-7B\nachieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose\nMobile-Agent-v3, a general-purpose GUI agent framework that further improves\nperformance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new\nstate-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates\nthree key innovations: (1) Large-scale Environment Infrastructure: a\ncloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,\nenabling our Self-Evolving GUI Trajectory Production framework. This generates\nhigh-quality interaction data via automated query generation and correctness\nvalidation, leveraging GUI-Owl to refine trajectories iteratively, forming a\nself-improving loop. It supports diverse data pipelines and reduces manual\nannotation. (2) Diverse Foundational Agent Capabilities: by integrating UI\ngrounding, planning, action semantics, and reasoning patterns, GUI-Owl supports\nend-to-end decision-making and can act as a modular component in multi-agent\nsystems. (3) Scalable Environment RL: we develop a scalable reinforcement\nlearning framework with fully asynchronous training for real-world alignment.\nWe also introduce Trajectory-aware Relative Policy Optimization (TRPO) for\nonline RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are\nopen-sourced at https://github.com/X-PLUG/MobileAgent.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86GUI-Owl\u548cMobile-Agent-v3\uff0c\u8fd9\u662f\u4e24\u4e2a\u5f00\u6e90GUI\u4ee3\u7406\u6a21\u578b\uff0c\u5728\u5404\u79cdGUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u8bba\u6587\u63d0\u51fa\u4e86\u5728\u73af\u5883\u57fa\u7840\u8bbe\u65bd\u3001\u57fa\u7840\u4ee3\u7406\u529f\u80fd\u548c\u53ef\u6269\u5c55\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u9762\u7684\u5173\u952e\u521b\u65b0\u3002\u8fd9\u4e9b\u6a21\u578b\u4e3a\u5f00\u6e90GUI\u4ee3\u7406\u6846\u67b6\u6811\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\u3002", "motivation": "The motivation behind this paper is to develop advanced GUI agent models that excel in various tasks such as grounding, question answering, planning, decision-making, and procedural knowledge across different environments. The focus is on improving performance, reducing manual annotation, and supporting diverse data pipelines.", "method": "The paper introduces GUI-Owl, a foundational GUI agent model that achieves state-of-the-art performance on ten GUI benchmarks on desktop and mobile environments. It further proposes Mobile-Agent-v3, a general-purpose GUI agent framework that improves performance. The key innovations include a large-scale environment infrastructure, diverse foundational agent capabilities, and a scalable reinforcement learning framework with TRPO for online RL.", "result": "GUI-Owl achieves 66.4 on AndroidWorld and 29.4 on OSWorld, while Mobile-Agent-v3 improves the performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting new benchmarks. Additionally, TRPO achieves 34.9 on OSWorld. The models are open-sourced for further research and development at https://github.com/X-PLUG/MobileAgent.", "conclusion": "GUI-Owl and Mobile-Agent-v3 are open-source GUI agent models that achieve state-of-the-art performance on various GUI benchmarks. The paper presents key innovations in environment infrastructure, foundational agent capabilities, and scalable reinforcement learning. The models set new benchmarks in open-source GUI agent frameworks."}}
{"id": "2508.15180", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.15180", "abs": "https://arxiv.org/abs/2508.15180", "authors": ["Kai Xiong", "Yanwei Huang", "Rongjunchen Zhang", "Kun Chen", "Haipang Wu"], "title": "PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data", "comment": null, "summary": "High-quality mathematical and logical datasets with verifiable answers are\nessential for strengthening the reasoning capabilities of large language models\n(LLMs). While recent data augmentation techniques have facilitated the creation\nof large-scale benchmarks, existing LLM-generated datasets often suffer from\nlimited reliability, diversity, and scalability. To address these challenges,\nwe introduce PuzzleClone, a formal framework for synthesizing verifiable data\nat scale using Satisfiability Modulo Theories (SMT). Our approach features\nthree key innovations: (1) encoding seed puzzles into structured logical\nspecifications, (2) generating scalable variants through systematic variable\nand constraint randomization, and (3) ensuring validity via a reproduction\nmechanism. Applying PuzzleClone, we construct a curated benchmark comprising\nover 83K diverse and programmatically validated puzzles. The generated puzzles\nspan a wide spectrum of difficulty and formats, posing significant challenges\nto current state-of-the-art models. We conduct post training (SFT and RL) on\nPuzzleClone datasets. Experimental results show that training on PuzzleClone\nyields substantial improvements not only on PuzzleClone testset but also on\nlogic and mathematical benchmarks. Post training raises PuzzleClone average\nfrom 14.4 to 56.2 and delivers consistent improvements across 7 logic and\nmathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from\n52.5 to 65.0). Our code and data are available at\nhttps://github.com/puzzleclone.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86PuzzleClone\u6846\u67b6\uff0c\u7528\u4e8e\u5408\u6210\u53ef\u9a8c\u8bc1\u6570\u636e\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b83K\u591a\u6837\u5316\u548c\u7a0b\u5e8f\u9a8c\u8bc1\u96be\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5c55\u793a\u5728\u8bad\u7ec3PuzzleClone\u6570\u636e\u96c6\u4e0a\u7684\u663e\u8457\u6539\u5584\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8bad\u7ec3\u5728PuzzleClone\u4e0a\u4e0d\u4ec5\u63d0\u9ad8\u4e86PuzzleClone\u6d4b\u8bd5\u96c6\u7684\u6027\u80fd\uff0c\u8fd8\u5bf9\u903b\u8f91\u548c\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4ea7\u751f\u4e86\u4e00\u81f4\u7684\u6539\u8fdb\u3002\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u6570\u636e\u7684\u5f00\u653e\u83b7\u53d6\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u96c6\u901a\u5e38\u53d7\u5230\u53ef\u9760\u6027\u3001\u591a\u6837\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u9650\u5236\u3002\u4f5c\u8005\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u52a0\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u8be5\u8bba\u6587\u7684\u65b9\u6cd5\u5305\u62ec\u5c06\u79cd\u5b50\u96be\u9898\u7f16\u7801\u4e3a\u7ed3\u6784\u5316\u903b\u8f91\u89c4\u8303\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u53d8\u91cf\u548c\u7ea6\u675f\u968f\u673a\u5316\u751f\u6210\u53ef\u6269\u5c55\u7684\u53d8\u4f53\uff0c\u5e76\u901a\u8fc7\u518d\u73b0\u673a\u5236\u786e\u4fdd\u6709\u6548\u6027\u3002\u4f7f\u7528PuzzleClone\u6784\u5efa\u4e86\u4e00\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8de8\u8d8a\u4e86\u5e7f\u6cdb\u7684\u56f0\u96be\u7a0b\u5ea6\u548c\u683c\u5f0f\uff0c\u5bf9\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002\u5728PuzzleClone\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u540e\u8bad\u7ec3\uff08SFT\u548cRL\uff09\uff0c\u663e\u793a\u51fa\u8bad\u7ec3\u5bf9PuzzleClone\u6d4b\u8bd5\u96c6\u548c\u903b\u8f91\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u90fd\u6709\u663e\u8457\u6539\u5584\u7684\u7ed3\u679c\u3002\u540e\u671f\u8bad\u7ec3\u5c06PuzzleClone\u7684\u5e73\u5747\u5206\u4ece14.4\u589e\u81f356.2\uff0c\u5e76\u57287\u4e2a\u903b\u8f91\u548c\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u4f9b\u4e86\u591a\u8fbe12.5\u4e2a\u7edd\u5bf9\u767e\u5206\u70b9\uff08AMC2023\u4ece52.5\u589e\u81f365.0\uff09\u7684\u6301\u7eed\u6539\u5584\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728PuzzleClone\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u53ef\u4ee5\u663e\u8457\u6539\u5584\u903b\u8f91\u548c\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u7684\u8868\u73b0\uff0c\u540c\u65f6\u4f5c\u8005\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u6570\u636e\u7684\u5f00\u653e\u83b7\u53d6\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aPuzzleClone\u7684\u6b63\u5f0f\u6846\u67b6\uff0c\u7528\u4e8e\u4f7f\u7528Satisfiability Modulo Theories (SMT)\u5728\u89c4\u6a21\u4e0a\u5408\u6210\u53ef\u9a8c\u8bc1\u6570\u636e\u3002\u4ed6\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc783K\u591a\u6837\u5316\u548c\u7a0b\u5e8f\u9a8c\u8bc1\u7684\u96be\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5c55\u793a\u4e86\u8bad\u7ec3\u5728PuzzleClone\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u903b\u8f91\u548c\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002"}}
{"id": "2508.15192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15192", "abs": "https://arxiv.org/abs/2508.15192", "authors": ["Wenjie Lin", "Jin Wei-Kocsis"], "title": "LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support", "comment": null, "summary": "While large language models (LLMs) have shown promise in healthcare, their\napplication for rare medical conditions is still hindered by scarce and\nunreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing\nexcessive sweating beyond physiological needs, is one such rare disorder,\naffecting 2-3% of the population and significantly impacting both physical\ncomfort and psychosocial well-being. To date, no work has tailored LLMs to\nadvance the diagnosis or care of hyperhidrosis. To address this gap, we present\nLLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and\nempathetic hyperhidrosis support. The system follows a three-stage pipeline. In\nthe data augmentation stage, a frontier LLM generates medically plausible\nsynthetic vignettes from curated open-source data to create a diverse and\nbalanced question-answer dataset. In the fine-tuning stage, an open-source\nfoundation model is fine-tuned on the dataset to provide diagnosis,\npersonalized treatment recommendations, and empathetic psychological support.\nIn the inference and expert evaluation stage, clinical and psychological\nspecialists assess accuracy, appropriateness, and empathy, with validated\nresponses iteratively enriching the dataset. Experiments show that LLM4Sweat\noutperforms baselines and delivers the first open-source LLM framework for\nhyperhidrosis, offering a generalizable approach for other rare diseases with\nsimilar data and trustworthiness challenges.", "AI": {"tldr": "LLM4Sweat is an open-source LLM framework designed for hyperhidrosis to provide personalized treatment recommendations and empathetic support. It follows a three-stage pipeline, outperforms baselines, and can be generalized to other rare diseases facing similar data challenges.", "motivation": "The lack of tailor-made LLMs for rare medical conditions like hyperhidrosis, impacting physical and psychosocial well-being of individuals.", "method": "Three-stage pipeline: data augmentation using a frontier LLM, fine-tuning on an open-source foundation model, and inference with expert evaluation. Clinical and psychological specialists assess accuracy, appropriateness, and empathy of the system's responses.", "result": "Development of LLM4Sweat, an open-source LLM framework for hyperhidrosis with personalized treatment recommendations and empathetic support. It outperforms baselines in experiments and has the potential to address challenges in other rare diseases.", "conclusion": "LLM4Sweat outperforms baselines and provides an open-source LLM framework for hyperhidrosis, offering a generalizable approach for rare diseases with similar data challenges."}}
{"id": "2508.15204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15204", "abs": "https://arxiv.org/abs/2508.15204", "authors": ["Raj Jain", "Marc Wetter"], "title": "R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling", "comment": null, "summary": "Effective scheduling under tight resource, timing, and operational\nconstraints underpins large-scale planning across sectors such as capital\nprojects, manufacturing, logistics, and IT fleet transitions. However, the\nreliability of large language models (LLMs) when reasoning under\nhigh-constraint regimes is insufficiently characterized. To address this gap,\nwe present R-ConstraintBench, a scalable framework that evaluates models on\nResource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete\nfeasibility class, while difficulty increases via linear growth in constraints.\nR-ConstraintBench incrementally increases non-redundant precedence constraints\nin Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal\nwindows, and disjunctive constraints. As an illustrative example, we\ninstantiate the benchmark in a data center migration setting and evaluate\nmultiple LLMs using feasibility and error analysis, identifying degradation\nthresholds and constraint types most associated with failure. Empirically,\nstrong models are near-ceiling on precedence-only DAGs, but feasibility\nperformance collapses when downtime, temporal windows, and disjunctive\nconstraints interact, implicating constraint interaction, not graph depth, as\nthe principal bottleneck. Performance on clean synthetic ramps also does not\nguarantee transfer to domain-grounded scenarios, underscoring limited\ngeneralization.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528R-ConstraintBench\u6846\u67b6\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\u4e0a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u3002\u53d1\u73b0\u5f3a\u5927\u7684\u6a21\u578b\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u8d8a\uff0c\u4f46\u5728\u7ea6\u675f\u76f8\u4e92\u4f5c\u7528\u4e0b\u6027\u80fd\u4e0b\u964d\u3002\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u6027\u80fd\u5728\u5408\u6210\u73af\u5883\u4e2d\u7684\u8868\u73b0\u4e0d\u80fd\u7b80\u5355\u8fc1\u79fb\u5230\u5b9e\u9645\u573a\u666f\u3002", "motivation": "\u5927\u89c4\u6a21\u89c4\u5212\u4e2d\u7684\u6709\u6548\u8c03\u5ea6\u5bf9\u4e8e\u8d44\u672c\u9879\u76ee\u3001\u5236\u9020\u4e1a\u3001\u7269\u6d41\u548cIT\u8f66\u961f\u8f6c\u6362\u7b49\u884c\u4e1a\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7ea6\u675f\u73af\u5883\u4e0b\u63a8\u7406\u65f6\u7684\u53ef\u9760\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63cf\u8ff0\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86R-ConstraintBench\u6846\u67b6\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u4e00\u4e2a\u540d\u4e3aR-ConstraintBench\u7684\u6846\u67b6\uff0c\u5e76\u5728\u6570\u636e\u4e2d\u5fc3\u8fc1\u79fb\u8bbe\u7f6e\u4e2d\u5b9e\u4f8b\u5316\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002\u901a\u8fc7\u53ef\u884c\u6027\u548c\u9519\u8bef\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u4e0e\u5931\u8d25\u6700\u76f8\u5173\u7684\u964d\u89e3\u9608\u503c\u548c\u7ea6\u675f\u7c7b\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u505c\u673a\u65f6\u95f4\u3001\u65f6\u95f4\u7a97\u53e3\u548c\u5206\u79bb\u7ea6\u675f\u76f8\u4e92\u4f5c\u7528\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u884c\u6027\u6027\u80fd\u4e0b\u964d\uff0c\u4e3b\u8981\u74f6\u9888\u662f\u7ea6\u675f\u4ea4\u4e92\uff0c\u800c\u4e0d\u662f\u56fe\u6df1\u5ea6\u3002\u6b64\u5916\uff0c\u5728\u6e05\u6d01\u5408\u6210\u5761\u9053\u4e0a\u7684\u6027\u80fd\u4e5f\u4e0d\u80fd\u4fdd\u8bc1\u8f6c\u79fb\u5230\u9886\u57df\u76f8\u5173\u7684\u573a\u666f\uff0c\u7a81\u51fa\u4e86\u6cdb\u5316\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aR-ConstraintBench\u7684\u53ef\u4f38\u7f29\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u7684\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f3a\u5927\u7684\u6a21\u578b\u5728\u4ec5\u5177\u6709\u5148\u51b3\u7ea6\u675f\u7684\u6709\u5411\u65e0\u73af\u56fe\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u662f\u5f53\u505c\u673a\u65f6\u95f4\u3001\u65f6\u95f4\u7a97\u53e3\u548c\u5206\u7acb\u7ea6\u675f\u4ea4\u4e92\u65f6\uff0c\u53ef\u884c\u6027\u6027\u80fd\u4f1a\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u7814\u7a76\u6307\u51fa\u6027\u80fd\u5728\u6e05\u6d01\u5408\u6210\u5761\u9053\u4e0a\u4e5f\u4e0d\u80fd\u4fdd\u8bc1\u8f6c\u79fb\u5230\u9886\u57df\u76f8\u5173\u7684\u573a\u666f\uff0c\u7a81\u51fa\u4e86\u6cdb\u5316\u80fd\u529b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.15222", "categories": ["cs.AI", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15222", "abs": "https://arxiv.org/abs/2508.15222", "authors": ["Hantao Zhang", "Jingyang Liu", "Ed Li"], "title": "See it. Say it. Sorted: Agentic System for Compositional Diagram Generation", "comment": null, "summary": "We study sketch-to-diagram generation: converting rough hand sketches into\nprecise, compositional diagrams. Diffusion models excel at photorealism but\nstruggle with the spatial precision, alignment, and symbolic structure required\nfor flowcharts. We introduce See it. Say it. Sorted., a training-free agentic\nsystem that couples a Vision-Language Model (VLM) with Large Language Models\n(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system\nruns an iterative loop in which a Critic VLM proposes a small set of\nqualitative, relational edits; multiple candidate LLMs synthesize SVG updates\nwith diverse strategies (conservative->aggressive, alternative, focused); and a\nJudge VLM selects the best candidate, ensuring stable improvement. This design\nprioritizes qualitative reasoning over brittle numerical estimates, preserves\nglobal constraints (e.g., alignment, connectivity), and naturally supports\nhuman-in-the-loop corrections. On 10 sketches derived from flowcharts in\npublished papers, our method more faithfully reconstructs layout and structure\nthan two frontier closed-source image generation LLMs (GPT-5 and\nGemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)\nwithout inserting unwanted text. Because outputs are programmatic SVGs, the\napproach is readily extensible to presentation tools (e.g., PowerPoint) via\nAPIs and can be specialized with improved prompts and task-specific tools. The\ncodebase is open-sourced at\nhttps://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aSee it. Say it. Sorted.\u7684\u7cfb\u7edf\uff0c\u5229\u7528Vision-Language Model\uff08VLM\uff09\u548cLarge Language Models\uff08LLMs\uff09\u751f\u6210\u53ef\u7f16\u8f91\u7684Scalable Vector Graphics\uff08SVG\uff09\u7a0b\u5e8f\uff0c\u5b9e\u73b0\u5c06\u8349\u56fe\u8f6c\u6362\u4e3a\u51c6\u786e\u7684\u7ec4\u5408\u56fe\u8868\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u7cfb\u7edf\u4f18\u4e8e\u73b0\u6709\u7684\u56fe\u50cf\u751f\u6210LLMs\uff0c\u5728\u5904\u7406\u6d41\u7a0b\u56fe\u8349\u56fe\u65f6\u66f4\u4e3a\u51c6\u786e\u548c\u5fe0\u5b9e\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u6a21\u578b\u64c5\u957f\u903c\u771f\u5ea6\u4f46\u5bf9\u4e8e\u6d41\u7a0b\u56fe\u6240\u9700\u7684\u7a7a\u95f4\u7cbe\u5ea6\u3001\u5bf9\u9f50\u3001\u7b26\u53f7\u7ed3\u6784\u7b49\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u5c06Critic VLM\u63d0\u51fa\u4e00\u5c0f\u7ec4\u5b9a\u6027\u3001\u5173\u7cfb\u6027\u7f16\u8f91\uff0c\u591a\u4e2a\u5019\u9009LLMs\u4f7f\u7528\u4e0d\u540c\u7684\u7b56\u7565\uff08\u4fdd\u5b88->\u6fc0\u8fdb\u3001\u66ff\u4ee3\u3001\u4e13\u6ce8\uff09\u5408\u6210SVG\u66f4\u65b0\uff0cJudge VLM\u9009\u62e9\u6700\u4f73\u5019\u9009\uff0c\u786e\u4fdd\u7a33\u5b9a\u7684\u6539\u8fdb\u3002\u8bbe\u8ba1\u4f18\u5148\u8003\u8651\u5b9a\u6027\u63a8\u7406\u800c\u975e\u8106\u5f31\u7684\u6570\u503c\u4f30\u8ba1\uff0c\u4fdd\u7559\u5168\u5c40\u7ea6\u675f\uff08\u4f8b\u5982\u5bf9\u9f50\u3001\u8fde\u63a5\u6027\uff09\uff0c\u5e76\u4e14\u81ea\u7136\u652f\u6301\u4eba\u673a\u534f\u4f5c\u4fee\u6b63\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5904\u7406\u6d41\u7a0b\u56fe\u76f8\u5173\u7684\u8349\u56fe\u65f6\uff0c\u8be5\u7cfb\u7edf\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u56fe\u50cf\u751f\u6210LLMs\u8868\u73b0\u66f4\u4e3a\u4f18\u8d8a\uff0c\u91cd\u5efa\u5e03\u5c40\u548c\u7ed3\u6784\u66f4\u52a0\u5fe0\u5b9e\uff0c\u51c6\u786e\u5408\u6210\u57fa\u672c\u5143\u7d20\uff0c\u4e14\u907f\u514d\u63d2\u5165\u4e0d\u9700\u8981\u7684\u6587\u672c\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aSee it. Say it. Sorted.\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u751f\u6210\u53ef\u7f16\u8f91\u7684\u53ef\u4f38\u7f29\u77e2\u91cf\u56fe\u5f62\uff08SVG\uff09\u7a0b\u5e8f\uff0c\u5b9e\u73b0\u4e86\u5c06\u8349\u56fe\u8f6c\u6362\u4e3a\u51c6\u786e\u3001\u7ec4\u5408\u7684\u56fe\u8868\u3002\u5728\u5bf910\u5f20\u6765\u81ea\u53d1\u8868\u8bba\u6587\u4e2d\u6d41\u7a0b\u56fe\u7684\u8349\u56fe\u8fdb\u884c\u5b9e\u9a8c\u65f6\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4e24\u79cd\u524d\u6cbf\u7684\u95ed\u6e90\u56fe\u50cf\u751f\u6210LLMs\uff08GPT-5\u548cGemini-2.5-Pro\uff09\u66f4\u5fe0\u5b9e\u5730\u91cd\u5efa\u4e86\u5e03\u5c40\u548c\u7ed3\u6784\uff0c\u51c6\u786e\u7ec4\u5408\u4e86\u57fa\u672c\u5143\u7d20\uff0c\u5e76\u4e14\u6ca1\u6709\u63d2\u5165\u4e0d\u9700\u8981\u7684\u6587\u672c\u3002\u7531\u4e8e\u8f93\u51fa\u662f\u7a0b\u5e8f\u5316\u7684SVGs\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7API\u8f7b\u677e\u6269\u5c55\u5230\u6f14\u793a\u5de5\u5177\uff08\u4f8b\u5982PowerPoint\uff09\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u6539\u8fdb\u63d0\u793a\u548c\u4e13\u95e8\u5de5\u5177\u6765\u8fdb\u884c\u5b9a\u5236\u3002\u8be5\u7814\u7a76\u4ee3\u7801\u5728https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git\u4e0a\u5f00\u6e90\u3002"}}
{"id": "2508.15240", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15240", "abs": "https://arxiv.org/abs/2508.15240", "authors": ["Sabab Aosaf", "Muhammad Ali Nayeem", "Afsana Haque", "M Sohel Rahmana"], "title": "Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas", "comment": null, "summary": "Urban land-use allocation represents a complex multi-objective optimization\nproblem critical for sustainable urban development policy. This paper presents\nnovel computational intelligence approaches for optimizing land-use allocation\nin mixed-use areas, addressing inherent trade-offs between land-use\ncompatibility and economic objectives. We develop multiple optimization\nalgorithms, including custom variants integrating differential evolution with\nmulti-objective genetic algorithms. Key contributions include: (1) CR+DES\nalgorithm leveraging scaled difference vectors for enhanced exploration, (2)\nsystematic constraint relaxation strategy improving solution quality while\nmaintaining feasibility, and (3) statistical validation using Kruskal-Wallis\ntests with compact letter displays. Applied to a real-world case study with\n1,290 plots, CR+DES achieves 3.16\\% improvement in land-use compatibility\ncompared to state-of-the-art methods, while MSBX+MO excels in price\noptimization with 3.3\\% improvement. Statistical analysis confirms algorithms\nincorporating difference vectors significantly outperform traditional\napproaches across multiple metrics. The constraint relaxation technique enables\nbroader solution space exploration while maintaining practical constraints.\nThese findings provide urban planners and policymakers with evidence-based\ncomputational tools for balancing competing objectives in land-use allocation,\nsupporting more effective urban development policies in rapidly urbanizing\nregions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u8ba1\u7b97\u667a\u80fd\u65b9\u6cd5\u6765\u4f18\u5316\u6df7\u5408\u7528\u9014\u533a\u57df\u7684\u571f\u5730\u5206\u914d\uff0c\u89e3\u51b3\u4e86\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u548c\u7ecf\u6d4e\u76ee\u6807\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u3002\u5173\u952e\u8d21\u732e\u5305\u62ecCR+DES\u7b97\u6cd5\u3001\u7cfb\u7edf\u6027\u7ea6\u675f\u653e\u677e\u7b56\u7565\u548c\u7edf\u8ba1\u9a8c\u8bc1\u3002\u5177\u4f53\u5e94\u7528\u4e8e\u5b9e\u9645\u6848\u4f8b\u4e2d\uff0c\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u5e76\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002", "motivation": "\u57ce\u5e02\u571f\u5730\u5229\u7528\u5206\u914d\u662f\u53ef\u6301\u7eed\u57ce\u5e02\u53d1\u5c55\u653f\u7b56\u4e2d\u81f3\u5173\u91cd\u8981\u7684\u590d\u6742\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u65b0\u9896\u7684\u8ba1\u7b97\u667a\u80fd\u65b9\u6cd5\u6765\u89e3\u51b3\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u548c\u7ecf\u6d4e\u76ee\u6807\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\uff0c\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u5dee\u5206\u8fdb\u5316\u548c\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\u76f8\u7ed3\u5408\u7684\u5b9a\u5236\u53d8\u4f53\u6765\u4f18\u5316\u6df7\u5408\u7528\u9014\u533a\u57df\u7684\u571f\u5730\u5206\u914d\u3002\u63d0\u51fa\u4e86CR+DES\u7b97\u6cd5\u548c\u7cfb\u7edf\u6027\u7ea6\u675f\u653e\u677e\u7b56\u7565\uff0c\u4ee5\u589e\u5f3a\u63a2\u7d22\u5e76\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002\u901a\u8fc7Kruskal-Wallis\u68c0\u9a8c\u8fdb\u884c\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u5e76\u4f7f\u7528\u7d27\u51d1\u5b57\u6bcd\u663e\u793a\u3002", "result": "\u5728\u5e94\u7528\u4e8e1,290\u4e2a\u5730\u5757\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cCR+DES\u7b97\u6cd5\u76f8\u5bf9\u4e8e\u73b0\u6709\u6280\u672f\u65b9\u6cd5\u5728\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u4e0a\u5b9e\u73b0\u4e863.16\text{%}\u7684\u6539\u8fdb\uff0c\u800cMSBX+MO\u5728\u4ef7\u683c\u4f18\u5316\u65b9\u9762\u8868\u73b0\u51fa3.3\text{%}\u7684\u6539\u8fdb\u3002\u7edf\u8ba1\u5206\u6790\u8bc1\u5b9e\uff0c\u5408\u5e76\u5dee\u5206\u5411\u91cf\u7684\u7b97\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u7ea6\u675f\u653e\u677e\u6280\u672f\u6269\u5c55\u4e86\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u7684\u63a2\u7d22\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u9896\u7684\u8ba1\u7b97\u667a\u80fd\u65b9\u6cd5\u6765\u4f18\u5316\u6df7\u5408\u7528\u9014\u533a\u57df\u7684\u571f\u5730\u5206\u914d\uff0c\u89e3\u51b3\u4e86\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u548c\u7ecf\u6d4e\u76ee\u6807\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u3002\u7814\u7a76\u5f00\u53d1\u4e86\u591a\u79cd\u4f18\u5316\u7b97\u6cd5\uff0c\u5305\u62ec\u5c06\u5dee\u5206\u8fdb\u5316\u4e0e\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\u76f8\u7ed3\u5408\u7684\u5b9a\u5236\u53d8\u4f53\u3002\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a(1) CR+DES\u7b97\u6cd5\u5229\u7528\u7f29\u653e\u5dee\u5f02\u5411\u91cf\u8fdb\u884c\u589e\u5f3a\u63a2\u7d22\uff0c(2) \u7cfb\u7edf\u6027\u7ea6\u675f\u653e\u677e\u7b56\u7565\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u540c\u65f6\u4fdd\u6301\u53ef\u884c\u6027\uff0c(3) \u4f7f\u7528Kruskal-Wallis\u68c0\u9a8c\u8fdb\u884c\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u5e76\u4f7f\u7528\u7d27\u51d1\u5b57\u6bcd\u663e\u793a\u3002\u5e94\u7528\u4e8e\u62e5\u67091,290\u4e2a\u5730\u5757\u7684\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cCR+DES\u76f8\u5bf9\u4e8e\u73b0\u6709\u6280\u672f\u65b9\u6cd5\u5728\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u4e0a\u5b9e\u73b0\u4e863.16\text{%}\u7684\u6539\u8fdb\uff0c\u800cMSBX+MO\u5728\u4ef7\u683c\u4f18\u5316\u65b9\u9762\u8868\u73b0\u51fa3.3\text{%}\u7684\u6539\u8fdb\u3002\u7edf\u8ba1\u5206\u6790\u8bc1\u5b9e\uff0c\u5408\u5e76\u5dee\u5206\u5411\u91cf\u7684\u7b97\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u7ea6\u675f\u653e\u677e\u6280\u672f\u5b9e\u73b0\u4e86\u66f4\u5e7f\u6cdb\u7684\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u63a2\u7d22\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u9645\u7ea6\u675f\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u548c\u51b3\u7b56\u8005\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u8ba1\u7b97\u5de5\u5177\uff0c\u4ee5\u5e73\u8861\u571f\u5730\u5206\u914d\u4e2d\u7684\u7ade\u4e89\u76ee\u6807\uff0c\u652f\u6301\u5feb\u901f\u57ce\u5e02\u5316\u5730\u533a\u66f4\u6709\u6548\u7684\u57ce\u5e02\u53d1\u5c55\u653f\u7b56\u3002"}}
{"id": "2508.15294", "categories": ["cs.AI", "cs.CL", "cs.MA", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.15294", "abs": "https://arxiv.org/abs/2508.15294", "authors": ["Gaoke Zhang", "Bo Wang", "Yunlong Ma", "Dongming Zhao", "Zifei Yu"], "title": "Multiple Memory Systems for Enhancing the Long-term Memory of Agent", "comment": null, "summary": "An agent powered by large language models have achieved impressive results,\nbut effectively handling the vast amounts of historical data generated during\ninteractions remains a challenge. The current approach is to design a memory\nmodule for the agent to process these data. However, existing methods, such as\nMemoryBank and A-MEM, have poor quality of stored memory content, which affects\nrecall performance and response quality. In order to better construct\nhigh-quality long-term memory content, we have designed a multiple memory\nsystem (MMS) inspired by cognitive psychology theory. The system processes\nshort-term memory to multiple long-term memory fragments, and constructs\nretrieval memory units and contextual memory units based on these fragments,\nwith a one-to-one correspondence between the two. During the retrieval phase,\nMMS will match the most relevant retrieval memory units based on the user's\nquery. Then, the corresponding contextual memory units is obtained as the\ncontext for the response stage to enhance knowledge, thereby effectively\nutilizing historical data. Experiments on LoCoMo dataset compared our method\nwith three others, proving its effectiveness. Ablation studies confirmed the\nrationality of our memory units. We also analyzed the robustness regarding the\nnumber of selected memory segments and the storage overhead, demonstrating its\npractical value.", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u5904\u7406\u5927\u91cf\u5386\u53f2\u6570\u636e\u65f6\u5b58\u5728\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u91cd\u8bb0\u5fc6\u7cfb\u7edf\uff08MMS\uff09\u7528\u4e8e\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u957f\u671f\u8bb0\u5fc6\u5185\u5bb9\u3002\u901a\u8fc7LoCoMo\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u8fdb\u884c\u4e86\u6d88\u878d\u7814\u7a76\u548c\u9c81\u68d2\u6027\u5206\u6790\uff0c\u8bc1\u5b9e\u4e86\u8bb0\u5fc6\u5355\u5143\u7684\u5408\u7406\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u867d\u7136\u73b0\u6709\u65b9\u6cd5\u5982MemoryBank\u548cA-MEM\u8bbe\u8ba1\u4e86\u5b58\u50a8\u8bb0\u5fc6\u5185\u5bb9\u7684\u5185\u5b58\u6a21\u5757\uff0c\u4f46\u5b58\u50a8\u8d28\u91cf\u8f83\u5dee\uff0c\u5f71\u54cd\u4e86\u56de\u5fc6\u6027\u80fd\u548c\u54cd\u5e94\u8d28\u91cf\u3002\u57fa\u4e8e\u8ba4\u77e5\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u542f\u53d1\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u957f\u671f\u8bb0\u5fc6\u5185\u5bb9\uff0c\u9700\u8981\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u591a\u91cd\u8bb0\u5fc6\u7cfb\u7edf\uff08MMS\uff09\uff0c\u5c06\u77ed\u671f\u8bb0\u5fc6\u8f6c\u5316\u4e3a\u591a\u4e2a\u957f\u671f\u8bb0\u5fc6\u7247\u6bb5\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u7247\u6bb5\u6784\u5efa\u68c0\u7d22\u8bb0\u5fc6\u5355\u5143\u548c\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u5355\u5143\uff0c\u5b9e\u73b0\u4e24\u8005\u4e4b\u95f4\u7684\u4e00\u4e00\u5bf9\u5e94\u3002\u5728\u68c0\u7d22\u9636\u6bb5\uff0cMMS\u5c06\u6839\u636e\u7528\u6237\u67e5\u8be2\u5339\u914d\u6700\u76f8\u5173\u7684\u68c0\u7d22\u8bb0\u5fc6\u5355\u5143\uff0c\u7136\u540e\u83b7\u53d6\u76f8\u5e94\u7684\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u5355\u5143\u4f5c\u4e3a\u54cd\u5e94\u9636\u6bb5\u7684\u80cc\u666f\uff0c\u4ee5\u589e\u5f3a\u77e5\u8bc6\uff0c\u4ece\u800c\u6709\u6548\u5229\u7528\u5386\u53f2\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u63d0\u51fa\u7684\u591a\u91cd\u8bb0\u5fc6\u7cfb\u7edf\uff08MMS\uff09\u5728LoCoMo\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4e86\u8f83\u597d\u7684\u6709\u6548\u6027\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u8bb0\u5fc6\u5355\u5143\u7684\u5408\u7406\u6027\uff0c\u9c81\u68d2\u6027\u5206\u6790\u5c55\u793a\u4e86\u8be5\u7cfb\u7edf\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u91cd\u8bb0\u5fc6\u7cfb\u7edf\uff08MMS\uff09\uff0c\u7528\u4e8e\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u957f\u671f\u8bb0\u5fc6\u5185\u5bb9\uff0c\u4ece\u800c\u63d0\u9ad8\u667a\u80fd\u4f53\u5728\u5904\u7406\u5386\u53f2\u6570\u636e\u65f6\u7684\u6548\u7387\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728LoCoMo\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u548c\u9c81\u68d2\u6027\u5206\u6790\u9a8c\u8bc1\u4e86\u8bb0\u5fc6\u5355\u5143\u7684\u5408\u7406\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.15305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15305", "abs": "https://arxiv.org/abs/2508.15305", "authors": ["Wei Yang", "Jinwei Xiao", "Hongming Zhang", "Qingyang Zhang", "Yanna Wang", "Bo Xu"], "title": "Coarse-to-Fine Grounded Memory for LLM Agent Planning", "comment": "Accepted to EMNLP 2025 Main Conference;27 pages,15 figures", "summary": "Recent advancements in Large Language Models (LLMs) have driven growing\ninterest in LLM-based agents for complex planning tasks. To avoid costly agent\ntraining, many studies adopted memory mechanism that enhances LLM with offline\nexperiences or online trajectory analysis. However, existing works focus on\nsingle-granularity memory derived from dynamic environmental interactions,\nwhich are inherently constrained by the quality of the collected experiences.\nThis limitation, in turn, constrain the diversity of knowledge and the\nflexibility of planning. We propose Coarse-to-Fine Grounded Memory (\\Ours{}), a\nnovel framework that grounds coarse-to-fine memories with LLM, thereby fully\nleverage them for flexible adaptation to diverse scenarios. \\Ours{} grounds\nenvironmental information into coarse-grained focus points to guide experience\ncollection in training tasks, followed by grounding of actionable\nhybrid-grained tips from each experience. At inference, \\Ours{} retrieves\ntask-relevant experiences and tips to support planning. When facing\nenvironmental anomalies, the LLM grounds the current situation into\nfine-grained key information, enabling flexible self-QA reflection and plan\ncorrection.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.15327", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15327", "abs": "https://arxiv.org/abs/2508.15327", "authors": ["Xiancheng Gao", "Yufeng Shi", "Wengang Zhou", "Houqiang Li"], "title": "Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning", "comment": "7 pages, 6 figures, under review", "summary": "Offline reinforcement learning refers to the process of learning policies\nfrom fixed datasets, without requiring additional environment interaction.\nHowever, it often relies on well-defined reward functions, which are difficult\nand expensive to design. Human feedback is an appealing alternative, but its\ntwo common forms, expert demonstrations and preferences, have complementary\nlimitations. Demonstrations provide stepwise supervision, but they are costly\nto collect and often reflect limited expert behavior modes. In contrast,\npreferences are easier to collect, but it is unclear which parts of a behavior\ncontribute most to a trajectory segment, leaving credit assignment unresolved.\nIn this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to\nunify these two feedback sources. For each transition in a preference labeled\ntrajectory, SPW searches for the most similar state-action pairs from expert\ndemonstrations and directly derives stepwise importance weights based on their\nsimilarity scores. These weights are then used to guide standard preference\nlearning, enabling more accurate credit assignment that traditional approaches\nstruggle to achieve. We demonstrate that SPW enables effective joint learning\nfrom preferences and demonstrations, outperforming prior methods that leverage\nboth feedback types on challenging robot manipulation tasks.", "AI": {"tldr": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u9700\u8981\u660e\u786e\u5b9a\u4e49\u7684\u5956\u52b1\u51fd\u6570\uff0c\u4f46\u8bbe\u8ba1\u6210\u672c\u9ad8\u3002\u672c\u6587\u5f15\u5165Search-Based Preference Weighting\uff08SPW\uff09\u65b9\u6848\uff0c\u7edf\u4e00\u4e13\u5bb6\u6f14\u793a\u548c\u504f\u597d\u53cd\u9988\u6e90\uff0c\u901a\u8fc7\u641c\u7d22\u76f8\u4f3c\u72b6\u6001-\u52a8\u4f5c\u5bf9\u5e76\u5bfc\u51fa\u6743\u91cd\u6765\u6307\u5bfc\u504f\u597d\u5b66\u4e60\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u4fe1\u7528\u5206\u914d\u3002SPW\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80dc\u8fc7\u8fc7\u53bb\u7684\u65b9\u6cd5\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u4f9d\u8d56\u4e8e\u660e\u786e\u5b9a\u4e49\u7684\u5956\u52b1\u51fd\u6570\uff0c\u4f46\u8bbe\u8ba1\u8fd9\u4e9b\u5956\u52b1\u51fd\u6570\u5f80\u5f80\u56f0\u96be\u4e14\u6602\u8d35\u3002\u4eba\u7c7b\u53cd\u9988\u4f5c\u4e3a\u4e00\u79cd\u6709\u5438\u5f15\u529b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u4e13\u5bb6\u6f14\u793a\u548c\u504f\u597d\u8fd9\u4e24\u79cd\u5e38\u89c1\u5f62\u5f0f\u5404\u6709\u9650\u5236\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e24\u79cd\u53cd\u9988\u6e90\u7684\u7ed3\u5408\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165SPW\u65b9\u6848\u7edf\u4e00\u8fd9\u4e24\u79cd\u53cd\u9988\u6765\u6e90\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u4fe1\u7528\u5206\u914d\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u504f\u597d\u52a0\u6743\u65b9\u6848\uff08SPW\uff09\uff0c\u5bf9\u6bcf\u4e2a\u8f6c\u6362\u4e2d\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u8fdb\u884c\u641c\u7d22\uff0c\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u627e\u5230\u6700\u76f8\u4f3c\u7684\uff0c\u5e76\u6839\u636e\u76f8\u4f3c\u6027\u5f97\u5206\u5bfc\u51fa\u91cd\u8981\u6027\u6743\u91cd\uff0c\u7528\u4e8e\u6307\u5bfc\u504f\u597d\u5b66\u4e60\u3002\u6f14\u793a\u4e86SPW\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0cSPW\u80fd\u591f\u6709\u6548\u5730\u4ece\u4e13\u5bb6\u6f14\u793a\u548c\u504f\u597d\u4e2d\u8054\u5408\u5b66\u4e60\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u80dc\u8fc7\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u504f\u597d\u52a0\u6743\u65b9\u6848\uff08SPW\uff09\u6765\u7edf\u4e00\u4e13\u5bb6\u6f14\u793a\u548c\u504f\u597d\u53cd\u9988\u6e90\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u504f\u597d\u6807\u8bb0\u7684\u8f68\u8ff9\u4e2d\u7684\u8f6c\u6362\u5bfb\u627e\u6765\u81ea\u4e13\u5bb6\u6f14\u793a\u7684\u6700\u76f8\u4f3c\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u5e76\u6839\u636e\u5b83\u4eec\u7684\u76f8\u4f3c\u6027\u5206\u6570\u76f4\u63a5\u5bfc\u51fa\u9010\u6b65\u91cd\u8981\u6027\u6743\u91cd\u3002\u8fd9\u4e9b\u6743\u91cd\u7136\u540e\u7528\u4e8e\u6307\u5bfc\u6807\u51c6\u504f\u597d\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u7684\u66f4\u51c6\u786e\u7684\u4fe1\u7528\u5206\u914d\u3002\u5c55\u793a\u4e86SPW\u80fd\u591f\u5b9e\u73b0\u6709\u6548\u5730\u4ece\u504f\u597d\u548c\u6f14\u793a\u4e2d\u8054\u5408\u5b66\u4e60\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u80dc\u8fc7\u5229\u7528\u8fd9\u4e24\u79cd\u53cd\u9988\u7c7b\u578b\u7684\u5148\u524d\u65b9\u6cd5\u3002"}}
{"id": "2508.15335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15335", "abs": "https://arxiv.org/abs/2508.15335", "authors": ["Bin Deng", "Yizhe Feng", "Zeming Liu", "Qing Wei", "Xiangrong Zhu", "Shuai Chen", "Yuanfang Guo", "Yunhong Wang"], "title": "RETAIL: Towards Real-world Travel Planning for Large Language Models", "comment": null, "summary": "Although large language models have enhanced automated travel planning\nabilities, current systems remain misaligned with real-world scenarios. First,\nthey assume users provide explicit queries, while in reality requirements are\noften implicit. Second, existing solutions ignore diverse environmental factors\nand user preferences, limiting the feasibility of plans. Third, systems can\nonly generate plans with basic POI arrangements, failing to provide all-in-one\nplans with rich details. To mitigate these challenges, we construct a novel\ndataset \\textbf{RETAIL}, which supports decision-making for implicit queries\nwhile covering explicit queries, both with and without revision needs. It also\nenables environmental awareness to ensure plan feasibility under real-world\nscenarios, while incorporating detailed POI information for all-in-one travel\nplans. Furthermore, we propose a topic-guided multi-agent framework, termed\nTGMA. Our experiments reveal that even the strongest existing model achieves\nmerely a 1.0% pass rate, indicating real-world travel planning remains\nextremely challenging. In contrast, TGMA demonstrates substantially improved\nperformance 2.72%, offering promising directions for real-world travel\nplanning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u89e3\u51b3\u81ea\u52a8\u65c5\u884c\u89c4\u5212\u7cfb\u7edf\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff1a\u6784\u5efa\u65b0\u6570\u636e\u96c6RETAIL\uff0c\u4f7f\u7528TGMA\u4e3b\u9898\u5f15\u5bfc\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aTGMA\u5728\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u65b9\u9762\u6027\u80fd\u663e\u8457\u63d0\u9ad8\u3002", "motivation": "\u9488\u5bf9\u5f53\u524d\u81ea\u52a8\u65c5\u884c\u89c4\u5212\u7cfb\u7edf\u5b58\u5728\u7684\u95ee\u9898\uff1a\u7528\u6237\u9700\u6c42\u901a\u5e38\u662f\u9690\u5f0f\u7684\uff0c\u7cfb\u7edf\u65e0\u6cd5\u8003\u8651\u5404\u79cd\u73af\u5883\u56e0\u7d20\u548c\u7528\u6237\u559c\u597d\uff0c\u4ee5\u53ca\u65e0\u6cd5\u63d0\u4f9b\u8be6\u7ec6\u7684\u5168\u65b9\u4f4d\u65c5\u884c\u8ba1\u5212\uff0c\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u65b0\u6570\u636e\u96c6RETAIL\uff0c\u4f7f\u7528TGMA\u4e3b\u9898\u5f15\u5bfc\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTGMA\u5728\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u5728\u901a\u8fc7\u7387\u4e0a\u6bd4\u73b0\u6709\u6700\u5f3a\u6a21\u578b\u9ad8\u51fa2.72%\uff0c\u663e\u793a\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u9886\u57df\u7684\u53d1\u5c55\u65b9\u5411\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6RETAIL\u4ee5\u652f\u6301\u9690\u5f0f\u67e5\u8be2\u548c\u660e\u786e\u67e5\u8be2\uff0c\u5305\u62ec\u9700\u8981\u4fee\u6539\u7684\u60c5\u51b5\u3002\u5f15\u5165\u4e86\u73af\u5883\u610f\u8bc6\u4ee5\u786e\u4fdd\u8ba1\u5212\u5728\u73b0\u5b9e\u573a\u666f\u4e0b\u7684\u53ef\u884c\u6027\uff0c\u540c\u65f6\u4e3a\u5168\u65b9\u4f4d\u65c5\u884c\u8ba1\u5212\u63d0\u4f9b\u8be6\u7ec6\u7684\u5174\u8da3\u70b9\u4fe1\u606f\u3002\u4f7f\u7528\u4e86\u4e3b\u9898\u5f15\u5bfc\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6TGMA\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cTGMA\u5728\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u63d0\u9ad8\u7684\u6027\u80fd\uff0c\u6bd4\u73b0\u6709\u6700\u5f3a\u6a21\u578b\u9ad8\u51fa2.72%\u3002"}}
{"id": "2508.15338", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15338", "abs": "https://arxiv.org/abs/2508.15338", "authors": ["Jinning Yang", "Wen Shi"], "title": "DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization", "comment": null, "summary": "Electrocardiography plays a central role in cardiovascular diagnostics, yet\nexisting automated approaches often struggle to generalize across clinical\ntasks and offer limited support for open-ended reasoning. We present DiagECG, a\nnovel framework that integrates time-series and language modeling by enabling\nlarge language models to process 12-lead ECG signals for clinical text\ngeneration tasks. Our approach discretizes continuous ECG embeddings into\nsymbolic tokens using a lead-independent encoder and quantization module. These\ntokens are then used to extend the vocabulary of LLM, allowing the model to\nhandle both ECG and natural language inputs in a unified manner. To bridge the\nmodality gap, we pretrain the model on an autoregressive ECG forecasting task,\nenabling the LLM to model temporal dynamics using its native language modeling\ncapabilities. Finally, we perform instruction tuning on both ECG question\nanswering and diagnostic report generation. Without modifying the core model,\nDiagECG achieves strong performance across tasks while maintaining\ngeneralization to out-of-distribution settings. Extensive experiments\ndemonstrate the effectiveness of each component and highlight the potential of\nintegrating symbolic ECG representations into LLMs for medical reasoning.", "AI": {"tldr": "DiagECG\u6846\u67b6\u6574\u5408\u65f6\u95f4\u5e8f\u5217\u548c\u8bed\u8a00\u5efa\u6a21\uff0c\u572812\u5bfc\u8054\u5fc3\u7535\u56fe\u4fe1\u53f7\u548c\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u95f4\u5b9e\u73b0\u7edf\u4e00\u5904\u7406\u3002\u901a\u8fc7\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u6307\u5bfc\u5fae\u8c03\uff0cDiagECG\u5728\u533b\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u5f3a\u5927\u6027\u80fd\uff0c\u5e76\u5177\u6709\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u5728\u5fc3\u8840\u7ba1\u8bca\u65ad\u4e2d\u5b58\u5728\u6cdb\u5316\u56f0\u96be\u548c\u5bf9\u5f00\u653e\u5f0f\u63a8\u7406\u7684\u6709\u9650\u652f\u6301\u3002\u672c\u6587\u65e8\u5728\u6574\u5408\u65f6\u95f4\u5e8f\u5217\u548c\u8bed\u8a00\u5efa\u6a21\uff0c\u5c06\u533b\u5b66\u4efb\u52a1\u4e2d\u768412\u5bfc\u8054\u5fc3\u7535\u56fe\u4fe1\u53f7\u8f6c\u6362\u4e3a\u6587\u672c\u751f\u6210\u4efb\u52a1\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u7684\u7edf\u4e00\u6027\u3002", "method": "DiagECG\u6846\u67b6\u5c06\u8fde\u7eed\u7684\u5fc3\u7535\u56fe\u5d4c\u5165\u79bb\u6563\u5316\u4e3a\u7b26\u53f7\u6807\u8bb0\uff0c\u4f7f\u7528\u72ec\u7acb\u5bfc\u8054\u7f16\u7801\u5668\u548c\u91cf\u5316\u6a21\u5757\u3002\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u81ea\u56de\u5f52\u5fc3\u7535\u56fe\u9884\u6d4b\u4efb\u52a1\uff0c\u8ba9\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4f7f\u7528\u5176\u672c\u8eab\u7684\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\u6765\u6a21\u62df\u65f6\u95f4\u52a8\u6001\u3002\u901a\u8fc7\u6307\u5bfc\u5fae\u8c03\u5728\u5fc3\u7535\u56fe\u95ee\u9898\u56de\u7b54\u548c\u8bca\u65ad\u62a5\u544a\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u6a21\u578b\u4f18\u5316\u3002", "result": "DiagECG\u5728\u5404\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\uff0c\u5e76\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\u5404\u7ec4\u4ef6\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u4e86\u5c06\u7b26\u53f7\u5fc3\u7535\u56fe\u8868\u793a\u6574\u5408\u5230\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u884c\u533b\u5b66\u63a8\u7406\u7684\u6f5c\u529b\u3002", "conclusion": "DiagECG \u662f\u4e00\u4e2a\u6574\u5408\u65f6\u95f4\u5e8f\u5217\u548c\u8bed\u8a00\u5efa\u6a21\u7684\u65b0\u6846\u67b6\uff0c\u5c0612\u5bfc\u8054\u5fc3\u7535\u56fe\u4fe1\u53f7\u8f6c\u6362\u4e3a\u7b26\u53f7\u6807\u8bb0\u4ee5\u6269\u5c55\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u6c47\u91cf\uff0c\u5b9e\u73b0\u7edf\u4e00\u5904\u7406\u5fc3\u7535\u56fe\u548c\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u3002\u901a\u8fc7\u5728\u81ea\u56de\u5f52\u5fc3\u7535\u56fe\u9884\u6d4b\u4efb\u52a1\u4e0a\u5bf9\u6a21\u578b\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u4f7f\u5f97\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4f7f\u7528\u5176\u672c\u8eab\u7684\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\u6765\u6a21\u62df\u65f6\u95f4\u52a8\u6001\u3002\u5728\u5fc3\u7535\u56fe\u95ee\u9898\u56de\u7b54\u548c\u8bca\u65ad\u62a5\u544a\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u6307\u5bfc\u5fae\u8c03\uff0cDiagECG \u5728\u4e0d\u6539\u53d8\u6838\u5fc3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u5404\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\uff0c\u5e76\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5404\u7ec4\u4ef6\u7684\u6709\u6548\u6027\uff0c\u5e76\u7a81\u663e\u5c06\u7b26\u53f7\u5fc3\u7535\u56fe\u8868\u793a\u6574\u5408\u5230\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u884c\u533b\u5b66\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.15358", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15358", "abs": "https://arxiv.org/abs/2508.15358", "authors": ["Alberto Pozanco", "Marianela Morales", "Daniel Borrajo", "Manuela Veloso"], "title": "Planning with Minimal Disruption", "comment": null, "summary": "In many planning applications, we might be interested in finding plans that\nminimally modify the initial state to achieve the goals. We refer to this\nconcept as plan disruption. In this paper, we formally introduce it, and define\nvarious planning-based compilations that aim to jointly optimize both the sum\nof action costs and plan disruption. Experimental results in different\nbenchmarks show that the reformulated task can be effectively solved in\npractice to generate plans that balance both objectives.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u8ba1\u5212\u4e2d\u65ad\u6982\u5ff5\uff0c\u5e76\u5b9a\u4e49\u4e86\u65e8\u5728\u8054\u5408\u4f18\u5316\u884c\u52a8\u6210\u672c\u603b\u548c\u548c\u8ba1\u5212\u4e2d\u65ad\u7684\u89c4\u5212\u7f16\u8bd1\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u91cd\u65b0\u5236\u5b9a\u7684\u4efb\u52a1\u5728\u5b9e\u8df5\u4e2d\u6709\u6548\u89e3\u51b3\uff0c\u751f\u6210\u5e73\u8861\u4e24\u4e2a\u76ee\u6807\u7684\u8ba1\u5212\u3002", "motivation": "\u5728\u89c4\u5212\u5e94\u7528\u4e2d\uff0c\u5bfb\u627e\u6700\u5c0f\u5316\u4fee\u6539\u521d\u59cb\u72b6\u6001\u4ee5\u5b9e\u73b0\u76ee\u6807\u7684\u8ba1\u5212\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u5f15\u5165\u4e86\u8ba1\u5212\u4e2d\u65ad\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u4f18\u5316\u884c\u52a8\u6210\u672c\u603b\u548c\u548c\u8ba1\u5212\u4e2d\u65ad\u7684\u65b9\u6cd5\u3002", "method": "\u5f62\u5f0f\u4e0a\u4ecb\u7ecd\u4e86\u8ba1\u5212\u4e2d\u65ad\u6982\u5ff5\uff0c\u5e76\u5b9a\u4e49\u4e86\u65e8\u5728\u8054\u5408\u4f18\u5316\u884c\u52a8\u6210\u672c\u603b\u548c\u548c\u8ba1\u5212\u4e2d\u65ad\u7684\u89c4\u5212\u7f16\u8bd1\u3002\u901a\u8fc7\u5728\u4e0d\u540c\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u91cd\u65b0\u5236\u5b9a\u7684\u4efb\u52a1\u5728\u5b9e\u8df5\u4e2d\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6cd5\uff0c\u751f\u6210\u5e73\u8861\u4e24\u4e2a\u76ee\u6807\u7684\u8ba1\u5212\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91cd\u65b0\u5236\u5b9a\u7684\u4efb\u52a1\u80fd\u591f\u6709\u6548\u89e3\u51b3\uff0c\u5728\u5b9e\u8df5\u4e2d\u751f\u6210\u5e73\u8861\u4e24\u4e2a\u76ee\u6807\u7684\u8ba1\u5212\u3002", "conclusion": "\u5728\u89c4\u5212\u5e94\u7528\u4e2d\uff0c\u6211\u4eec\u53ef\u80fd\u6709\u5174\u8da3\u627e\u5230\u6700\u5c0f\u5316\u4fee\u6539\u521d\u59cb\u72b6\u6001\u4ee5\u5b9e\u73b0\u76ee\u6807\u7684\u8ba1\u5212\u3002\u672c\u6587\u6b63\u5f0f\u4ecb\u7ecd\u4e86\u8fd9\u4e00\u6982\u5ff5\uff0c\u5e76\u5b9a\u4e49\u4e86\u65e8\u5728\u8054\u5408\u4f18\u5316\u884c\u52a8\u6210\u672c\u603b\u548c\u548c\u8ba1\u5212\u4e2d\u65ad\u7684\u5404\u79cd\u57fa\u4e8e\u89c4\u5212\u7684\u7f16\u8bd1\u3002\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u91cd\u65b0\u5236\u5b9a\u7684\u4efb\u52a1\u5728\u5b9e\u8df5\u4e2d\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\uff0c\u751f\u6210\u5e73\u8861\u4e24\u4e2a\u76ee\u6807\u7684\u8ba1\u5212\u3002"}}
{"id": "2508.15432", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15432", "abs": "https://arxiv.org/abs/2508.15432", "authors": ["Bidyapati Pradhan", "Surajit Dasgupta", "Amit Kumar Saha", "Omkar Anustoop", "Sriram Puttagunta", "Vipul Mittal", "Gopal Sarda"], "title": "GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO", "comment": null, "summary": "The advancement of large language models (LLMs) is critically dependent on\nthe availability of high-quality datasets for Supervised Fine-Tuning (SFT),\nalignment tasks like Direct Preference Optimization (DPO), etc. In this work,\nwe present a comprehensive synthetic data generation framework that facilitates\nscalable, configurable, and high-fidelity generation of synthetic data tailored\nfor these training paradigms. Our approach employs a modular and\nconfiguration-based pipeline capable of modeling complex dialogue flows with\nminimal manual intervention. This framework uses a dual-stage quality tagging\nmechanism, combining heuristic rules and LLM-based evaluations, to\nautomatically filter and score data extracted from OASST-formatted\nconversations, ensuring the curation of high-quality dialogue samples. The\nresulting datasets are structured under a flexible schema supporting both SFT\nand DPO use cases, enabling seamless integration into diverse training\nworkflows. Together, these innovations offer a robust solution for generating\nand managing synthetic conversational data at scale, significantly reducing the\noverhead of data preparation in LLM training pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u548c\u914d\u7f6e\u751f\u6210\u5408\u6210\u5bf9\u8bdd\u6570\u636e\uff0c\u5b9e\u73b0\u81ea\u52a8\u8fc7\u6ee4\u548c\u8bc4\u5206\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u6570\u636e\uff0c\u652f\u6301\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u4efb\u52a1\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u6d41\u7a0b\u8282\u7701\u6570\u636e\u51c6\u5907\u65f6\u95f4\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63a8\u52a8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\uff0c\u5f3a\u8c03\u4e86\u5bf9\u4e8e\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7b49\u4efb\u52a1\u800c\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u91cd\u8981\u6027\u3002", "method": "\u672c\u6587\u91c7\u7528\u6a21\u5757\u5316\u548c\u57fa\u4e8e\u914d\u7f6e\u7684\u6d41\u7a0b\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5229\u7528\u53cc\u9636\u6bb5\u8d28\u91cf\u6807\u8bb0\u673a\u5236\u5bf9\u5bf9\u8bdd\u6570\u636e\u8fdb\u884c\u8fc7\u6ee4\u548c\u8bc4\u5206\uff0c\u652f\u6301SFT\u548cDPO\u7528\u4f8b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u6837\u672c\u7684\u7b5b\u9009\u548c\u751f\u6210\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u3001\u53ef\u914d\u7f6e\u548c\u9ad8\u4fdd\u771f\u5ea6\u7684\u5408\u6210\u6570\u636e\u751f\u6210\uff0c\u652f\u6301\u5404\u79cd\u8bad\u7ec3\u6d41\u7a0b\u7684\u63a5\u5165\uff0c\u4e3aLLM\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u5e26\u6765\u663e\u8457\u964d\u4f4e\u7684\u76ca\u5904\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u9762\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u4e3a\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u7b49\u4efb\u52a1\u63d0\u4f9b\u5b9a\u5236\u7684\u5408\u6210\u6570\u636e\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u548c\u57fa\u4e8e\u914d\u7f6e\u7684\u6d41\u7a0b\u751f\u6210\u590d\u6742\u5bf9\u8bdd\u6d41\uff0c\u7ed3\u5408\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u7684\u53cc\u9636\u6bb5\u8d28\u91cf\u6807\u8bb0\u673a\u5236\uff0c\u81ea\u52a8\u8fc7\u6ee4\u548c\u8bc4\u5206\u4eceOASST\u683c\u5f0f\u5bf9\u8bdd\u4e2d\u63d0\u53d6\u7684\u6570\u636e\uff0c\u751f\u6210\u5177\u6709\u7075\u6d3b\u6a21\u5f0f\u7684\u6570\u636e\u96c6\uff0c\u652f\u6301SFT\u548cDPO\u7528\u4f8b\uff0c\u663e\u8457\u51cf\u5c11LLM\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u6570\u636e\u51c6\u5907\u7684\u5f00\u9500\u3002"}}
{"id": "2508.15447", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15447", "abs": "https://arxiv.org/abs/2508.15447", "authors": ["Zihao Wang", "Junming Zhang"], "title": "From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence", "comment": "Accepted by ECAI 2025", "summary": "Large Language Models (LLMs) have shown promising potential in business\napplications, particularly in enterprise decision support and strategic\nplanning, yet current approaches often struggle to reconcile intricate\noperational analyses with overarching strategic goals across diverse market\nenvironments, leading to fragmented workflows and reduced collaboration across\norganizational levels. This paper introduces BusiAgent, a novel multi-agent\nframework leveraging LLMs for advanced decision-making in complex corporate\nenvironments. BusiAgent integrates three core innovations: an extended\nContinuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a\ngeneralized entropy measure to optimize collaborative efficiency, and a\nmulti-level Stackelberg game to handle hierarchical decision processes.\nAdditionally, contextual Thompson sampling is employed for prompt optimization,\nsupported by a comprehensive quality assurance system to mitigate errors.\nExtensive empirical evaluations across diverse business scenarios validate\nBusiAgent's efficacy, demonstrating its capacity to generate coherent,\nclient-focused solutions that smoothly integrate granular insights with\nhigh-level strategy, significantly outperforming established approaches in both\nsolution quality and user satisfaction. By fusing cutting-edge AI technologies\nwith deep business insights, BusiAgent marks a substantial step forward in\nAI-driven enterprise decision-making, empowering organizations to navigate\ncomplex business landscapes more effectively.", "AI": {"tldr": "BusiAgent is a novel multi-agent framework that leverages LLMs for advanced decision-making in complex corporate environments. It integrates innovative approaches such as CTMDP, generalized entropy measure, and contextual Thompson sampling to generate effective solutions. Empirical evaluations confirm BusiAgent's efficacy in providing client-focused solutions that outperform established approaches in solution quality and user satisfaction, marking a substantial advancement in AI-driven enterprise decision-making.", "motivation": "Current approaches in enterprise decision support and strategic planning struggle to reconcile operational analyses with strategic goals, leading to fragmented workflows and reduced collaboration across organizational levels. The motivation behind this paper is to address these challenges and empower organizations to navigate complex business landscapes more effectively with the fusion of AI technologies and business insights.", "method": "The paper introduces BusiAgent, which integrates three core innovations: an extended Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a generalized entropy measure for collaborative efficiency optimization, and a multi-level Stackelberg game for hierarchical decision processes. Contextual Thompson sampling is used for prompt optimization, supported by a quality assurance system to mitigate errors. Empirical evaluations across diverse business scenarios validate BusiAgent's efficacy.", "result": "BusiAgent significantly outperforms established approaches in solution quality and user satisfaction. It demonstrates the capacity to generate coherent, client-focused solutions that smoothly integrate granular insights with high-level strategy in diverse business scenarios.", "conclusion": "BusiAgent is a novel multi-agent framework leveraging LLMs for advanced decision-making in complex corporate environments. It outperforms established approaches in both solution quality and user satisfaction, demonstrating its efficacy in generating coherent, client-focused solutions that integrate granular insights with high-level strategy effectively."}}
{"id": "2508.15507", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15507", "abs": "https://arxiv.org/abs/2508.15507", "authors": ["Yekun Zhu", "Guang Chen", "Chengjun Mao"], "title": "Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning", "comment": null, "summary": "Large Language Models (LLMs) with chains-of-thought have demonstrated strong\nperformance on an increasing range of tasks, particularly those involving\ncomplex logical reasoning. However, excessively long chains can lead to\noverthinking, causing computational waste and slower responses. This raises a\nquestion: can LLMs dynamically adjust the length of their reasoning processes\nbased on task complexity? To address this, we propose the Think in Blocks\nframework, which enables adaptive reasoning-from zero to deep reasoning-by\npartitioning the reasoning process into a tunable number of blocks. Our main\ncontributions are: (1) Establishing an explicit block-structured paradigm in\nwhich the model first predicts an integer reasoning budget-the number of\nblocks-and then partitions its reasoning accordingly; (2) Training an adaptive\nmodel through a three-stage pipeline-Supervised Fine-Tuning, reward-guided\nDirect Preference Optimization, and Reinforcement Learning-that adjusts its\nreasoning depth to problem difficulty; (3) Exploiting the explicit block count\nto dynamically control reasoning depth at inference time, allowing flexible\nadjustment of chain-of-thought length during deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Think in Blocks\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u8bad\u7ec3\u6a21\u578b\u5b9e\u73b0\u81ea\u9002\u5e94\u63a8\u7406\u6df1\u5ea6\uff0c\u52a8\u6001\u8c03\u6574\u63a8\u7406\u8fc7\u7a0b\u957f\u5ea6\u4ee5\u5e94\u5bf9\u4efb\u52a1\u590d\u6742\u5ea6\u3002\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fc7\u5ea6\u63a8\u7406\u7684\u95ee\u9898\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fc7\u5ea6\u63a8\u7406\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u548c\u54cd\u5e94\u901f\u5ea6\u53d8\u6162\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5728\u4efb\u52a1\u590d\u6742\u5ea6\u4e0b\u52a8\u6001\u8c03\u6574\u63a8\u7406\u8fc7\u7a0b\u957f\u5ea6\u7684\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5305\u62ec\u76d1\u7763\u5fae\u8c03\u3001\u5956\u52b1\u5f15\u5bfc\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u6765\u8c03\u6574\u6a21\u578b\u7684\u63a8\u7406\u6df1\u5ea6\u4ee5\u9002\u5e94\u95ee\u9898\u96be\u5ea6\u3002\u540c\u65f6\u5efa\u7acb\u4e86\u4e00\u4e2a\u660e\u786e\u7684\u5757\u7ed3\u6784\u8303\u5f0f\uff0c\u8ba9\u6a21\u578b\u6839\u636e\u4efb\u52a1\u52a8\u6001\u8c03\u6574\u63a8\u7406\u8fc7\u7a0b\u7684\u957f\u5ea6\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684Think in Blocks\u6846\u67b6\uff0c\u8bba\u6587\u5b9e\u73b0\u4e86\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u52a8\u6001\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u7684\u76ee\u6807\u3002\u540c\u65f6\uff0c\u8be5\u6846\u67b6\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7075\u6d3b\u8c03\u6574\u601d\u7ef4\u94fe\u7684\u957f\u5ea6\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Think in Blocks\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u8fc7\u7a0b\u5206\u6210\u53ef\u8c03\u8282\u6570\u91cf\u7684\u5757\uff0c\u5b9e\u73b0\u4ece\u96f6\u5230\u6df1\u5ea6\u63a8\u7406\u7684\u81ea\u9002\u5e94\u63a8\u7406\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u52a8\u6001\u63a7\u5236\u63a8\u7406\u6df1\u5ea6\uff0c\u4ece\u800c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7075\u6d3b\u8c03\u6574\u601d\u7ef4\u94fe\u7684\u957f\u5ea6\uff0c\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.15510", "categories": ["cs.AI", "I.2.11; I.2.0; J.4; K.4.0; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.15510", "abs": "https://arxiv.org/abs/2508.15510", "authors": ["Filippo Tonini", "Lukas Galke"], "title": "Super-additive Cooperation in Language Model Agents", "comment": "FAIEMA 2025", "summary": "With the prospect of autonomous artificial intelligence (AI) agents, studying\ntheir tendency for cooperative behavior becomes an increasingly relevant topic.\nThis study is inspired by the super-additive cooperation theory, where the\ncombined effects of repeated interactions and inter-group rivalry have been\nargued to be the cause for cooperative tendencies found in humans. We devised a\nvirtual tournament where language model agents, grouped into teams, face each\nother in a Prisoner's Dilemma game. By simulating both internal team dynamics\nand external competition, we discovered that this blend substantially boosts\nboth overall and initial, one-shot cooperation levels (the tendency to\ncooperate in one-off interactions). This research provides a novel framework\nfor large language models to strategize and act in complex social scenarios and\noffers evidence for how intergroup competition can, counter-intuitively, result\nin more cooperative behavior. These insights are crucial for designing future\nmulti-agent AI systems that can effectively work together and better align with\nhuman values. Source code is available at\nhttps://github.com/pippot/Superadditive-cooperation-LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u865a\u62df\u9526\u6807\u8d5b\u7684\u65b9\u5f0f\u8ba9\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4eba\u5728\u56e2\u961f\u4e2d\u73a9\u56da\u5f92\u56f0\u5883\u6e38\u620f\uff0c\u53d1\u73b0\u56e2\u961f\u5185\u90e8\u52a8\u6001\u548c\u5916\u90e8\u7ade\u4e89\u7684\u6a21\u62df\u663e\u8457\u63d0\u9ad8\u4e86\u5408\u4f5c\u6c34\u5e73\u3002\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u8bbe\u8ba1\u672a\u6765\u80fd\u591f\u6709\u6548\u534f\u4f5c\u5e76\u66f4\u597d\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u4fdd\u6301\u4e00\u81f4\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u57fa\u4e8e\u8d85\u9644\u52a0\u5408\u4f5c\u7406\u8bba\u7684\u542f\u53d1\uff0c\u7814\u7a76\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u4eba\u7684\u5408\u4f5c\u503e\u5411\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u8d85\u9644\u52a0\u5408\u4f5c\u7406\u8bba\u8ba4\u4e3a\u91cd\u590d\u4e92\u52a8\u548c\u56e2\u4f53\u95f4\u7ade\u4e89\u7684\u7efc\u5408\u6548\u5e94\u662f\u4eba\u7c7b\u5408\u4f5c\u503e\u5411\u7684\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u865a\u62df\u9526\u6807\u8d5b\u8bbe\u8ba1\u7684\u65b9\u6cd5\uff0c\u8ba9\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4eba\u4ee5\u56e2\u961f\u5f62\u5f0f\u5728\u56da\u5f92\u56f0\u5883\u6e38\u620f\u4e2d\u4e92\u76f8\u5bf9\u6297\uff0c\u6a21\u62df\u4e86\u56e2\u961f\u5185\u90e8\u52a8\u6001\u548c\u5916\u90e8\u7ade\u4e89\uff0c\u53d1\u73b0\u8fd9\u79cd\u6df7\u5408\u663e\u8457\u63d0\u9ad8\u4e86\u5408\u4f5c\u6c34\u5e73\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u56e2\u961f\u5185\u90e8\u52a8\u6001\u548c\u5916\u90e8\u7ade\u4e89\u7684\u6a21\u62df\u663e\u8457\u63d0\u9ad8\u4e86\u5408\u4f5c\u6c34\u5e73\uff0c\u4e3a\u8bbe\u8ba1\u672a\u6765\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u63d0\u4f9b\u91cd\u8981\u89c1\u89e3\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u6a21\u62df\u56e2\u961f\u5185\u90e8\u52a8\u6001\u548c\u5916\u90e8\u7ade\u4e89\uff0c\u5408\u4f5c\u6027\u6df7\u5408\u663e\u8457\u63d0\u9ad8\u4e86\u6574\u4f53\u548c\u521d\u59cb\u7684\u4e00\u6b21\u6027\u5408\u4f5c\u6c34\u5e73\u3002\u8fd9\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u793e\u4f1a\u573a\u666f\u4e2d\u5236\u5b9a\u6218\u7565\u548c\u884c\u52a8\u63d0\u4f9b\u4e86\u521b\u65b0\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7ec4\u95f4\u7ade\u4e89\u5982\u4f55\u9006\u5411\u5730\u5bfc\u81f4\u66f4\u591a\u5408\u4f5c\u884c\u4e3a\u7684\u8bc1\u636e\u3002\u8fd9\u4e9b\u89c1\u89e3\u5bf9\u8bbe\u8ba1\u672a\u6765\u80fd\u591f\u6709\u6548\u534f\u4f5c\u5e76\u66f4\u597d\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u4fdd\u6301\u4e00\u81f4\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.15548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15548", "abs": "https://arxiv.org/abs/2508.15548", "authors": ["Jiayi Song", "Rui Wan", "Lipeng Ma", "Weidong Yang", "Qingyuan Zhou", "Yixuan Li", "Ben Fei"], "title": "DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks", "comment": null, "summary": "This work enhances the ability of large language models (LLMs) to perform\ncomplex reasoning in 3D scenes. Recent work has addressed the 3D situated\nreasoning task by invoking tool usage through large language models. Large\nlanguage models call tools via APIs and integrate the generated programs\nthrough a chain of thought to solve problems based on the program results.\nHowever, due to the simplicity of the questions in the dataset, the generated\nprogram reasoning chains are relatively short. To solve this main challenge, in\nthis paper, we introduce DeepThink3D to enhance the tool usage of LLMs in\ncomplex 3D situated reasoning tasks. Our work proposes a combinatorial and\niterative evolutionary approach on the SQA3D benchmark to generate more complex\nquestions. Building on this foundation, we fine-tune the large language model\nto make it more proficient in using 3D tools. By employing Direct Preference\nOptimization (DPO), we directly optimize the toolchain strategies generated by\nmodels, thereby enhancing their accuracy in complex tasks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86DeepThink3D\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4e09\u7ef4\u573a\u666f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002\u901a\u8fc7\u7ec4\u5408\u8fed\u4ee3\u6f14\u5316\u65b9\u6cd5\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u5de5\u5177\u4f7f\u7528\u548c\u51c6\u786e\u6027\uff0c\u5728SQA3D\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u95ee\u9898\u7b80\u5355\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u7a0b\u5e8f\u63a8\u7406\u94fe\u76f8\u5bf9\u8f83\u77ed\uff0c\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u4e3b\u8981\u6311\u6218\u3002\u4e3a\u6b64\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u65b0\u65b9\u6cd5\u548c\u4f18\u5316\u7b56\u7565\uff0c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u7ef4\u573a\u666f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5f15\u5165DeepThink3D\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u7b49\u65b9\u6cd5\uff0c\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u7ef4\u573a\u666f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u548c\u51c6\u786e\u6027\u3002", "result": "\u901a\u8fc7\u63d0\u51faDeepThink3D\u548c\u4f7f\u7528Direct Preference Optimization\uff08DPO\uff09\u4f18\u5316\u5de5\u5177\u94fe\u7b56\u7565\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4e09\u7ef4\u573a\u666f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51faDeepThink3D\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u590d\u6742\u4e09\u7ef4\u573a\u666f\u4e2d\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\u3002\u901a\u8fc7\u5f15\u5165\u6df1\u601d3D\uff0c\u91c7\u7528\u7ec4\u5408\u8fed\u4ee3\u6f14\u5316\u65b9\u6cd5\u751f\u6210\u66f4\u590d\u6742\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u4f18\u5316\u6a21\u578b\u751f\u6210\u7684\u5de5\u5177\u94fe\u7b56\u7565\uff0c\u63d0\u9ad8\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.15588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15588", "abs": "https://arxiv.org/abs/2508.15588", "authors": ["Ahmed Nasir", "Abdelhafid Zenati"], "title": "A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification", "comment": null, "summary": "The application of reinforcement learning to safety-critical systems is\nlimited by the lack of formal methods for verifying the robustness and safety\nof learned policies. This paper introduces a novel framework that addresses\nthis gap by analyzing the combination of an RL agent and its environment as a\ndiscrete-time autonomous dynamical system. By leveraging tools from dynamical\nsystems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we\nidentify and visualize Lagrangian Coherent Structures (LCS) that act as the\nhidden \"skeleton\" governing the system's behavior. We demonstrate that\nrepelling LCS function as safety barriers around unsafe regions, while\nattracting LCS reveal the system's convergence properties and potential failure\nmodes, such as unintended \"trap\" states. To move beyond qualitative\nvisualization, we introduce a suite of quantitative metrics, Mean Boundary\nRepulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and\nTemporally-Aware Spurious Attractor Strength (TASAS), to formally measure a\npolicy's safety margin and robustness. We further provide a method for deriving\nlocal stability guarantees and extend the analysis to handle model uncertainty.\nThrough experiments in both discrete and continuous control environments, we\nshow that this framework provides a comprehensive and interpretable assessment\nof policy behavior, successfully identifying critical flaws in policies that\nappear successful based on reward alone.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5229\u7528\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4e2d\u7684\u6709\u9650\u65f6\u95f4\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570(FTLE)\u6765\u5206\u6790\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u5b9a\u6027\u548c\u5b9a\u91cf\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6210\u529f\u8bc6\u522b\u4e86\u4ec5\u57fa\u4e8e\u5956\u52b1\u96be\u4ee5\u53d1\u73b0\u7684\u5173\u952e\u7f3a\u9677\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u9a8c\u8bc1\u5b66\u4e60\u653f\u7b56\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u7684\u9650\u5236\uff0c\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u5f3a\u5316\u5b66\u4e60\u653f\u7b56\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u6f5c\u5728\u7684\u5931\u8d25\u6a21\u5f0f\u548c\u5173\u952e\u7f3a\u9677\u3002", "method": "\u5f15\u5165\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4e2d\u7684\u6709\u9650\u65f6\u95f4\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570(FTLE)\u548cLagrangian Coherent Structures (LCS)\u6765\u5206\u6790\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u4e0e\u73af\u5883\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e00\u7cfb\u5217\u5b9a\u91cf\u8bc4\u4f30\u6307\u6807\u7528\u4e8e\u6d4b\u91cf\u7b56\u7565\u7684\u5b89\u5168\u8fb9\u754c\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u4f9b\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5728\u79bb\u6563\u548c\u8fde\u7eed\u63a7\u5236\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6210\u529f\u8bc6\u522b\u7b56\u7565\u884c\u4e3a\u4e2d\u7684\u5173\u952e\u7f3a\u9677\uff0c\u63d0\u4f9b\u4e86\u5168\u9762\u548c\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5229\u7528\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4e2d\u7684\u6709\u9650\u65f6\u95f4\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570(FTLE)\u6765\u5206\u6790\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u5b9a\u6027\u548c\u5b9a\u91cf\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u5168\u9762\u4e14\u53ef\u89e3\u91ca\u5730\u8bc4\u4f30\u7b56\u7565\u884c\u4e3a\uff0c\u6210\u529f\u8bc6\u522b\u4ec5\u57fa\u4e8e\u5956\u52b1\u65e0\u6cd5\u53d1\u73b0\u7684\u5173\u952e\u7f3a\u9677\u3002"}}
{"id": "2508.15610", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15610", "abs": "https://arxiv.org/abs/2508.15610", "authors": ["Alfio Gliozzo", "Naweed Khan", "Christodoulos Constantinides", "Nandana Mihindukulasooriya", "Nahuel Defosse", "Junkyu Lee"], "title": "Transduction is All You Need for Structured Data Workflows", "comment": "32 pages, 8 figures", "summary": "This paper introduces Agentics, a modular framework for building agent-based\nsystems capable of structured reasoning and compositional generalization over\ncomplex data. Designed with research and practical applications in mind,\nAgentics offers a novel perspective on working with data and AI workflows. In\nthis framework, agents are abstracted from the logical flow and they are used\ninternally to the data type to enable logical transduction among data. Agentics\nencourages AI developers to focus on modeling data rather than crafting\nprompts, enabling a declarative language in which data types are provided by\nLLMs and composed through logical transduction, which is executed by LLMs when\ntypes are connected. We provide empirical evidence demonstrating the\napplicability of this framework across domain-specific multiple-choice question\nanswering, semantic parsing for text-to-SQL, and automated prompt optimization\ntasks, achieving state-of-the-art accuracy or improved scalability without\nsacrificing performance. The open-source implementation is available at\n\\texttt{https://github.com/IBM/agentics}.", "AI": {"tldr": "Agentics is a modular framework that promotes structured reasoning and compositional generalization over complex data. It emphasizes data modeling, uses logical transduction among data types, and showcases improved performance in various AI tasks such as multiple-choice question answering, text-to-SQL semantic parsing, and prompt optimization.", "motivation": "The motivation behind Agentics is to provide a modular framework that facilitates structured reasoning and compositional generalization over complex data in agent-based systems. It aims to shift the focus of AI developers towards data modeling and enable a declarative approach to working with data and AI workflows.", "method": "Agentics abstracts agents from logical flow, enabling logical transduction among data types. It focuses on modeling data using a declarative language, with data types provided by LLMs and composed through logical transduction. The framework encourages AI developers to concentrate on data modeling rather than crafting prompts.", "result": "The paper demonstrates the effectiveness of the Agentics framework in domain-specific tasks such as multiple-choice question answering, text-to-SQL semantic parsing, and prompt optimization. It achieves state-of-the-art accuracy and improved scalability without sacrificing performance.", "conclusion": "Agentics framework allows for structured reasoning and compositional generalization over complex data, leading to improved performance in various AI tasks. The empirical evidence showcases its applicability in multiple-choice question answering, text-to-SQL semantic parsing, and prompt optimization tasks."}}
{"id": "2508.15630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15630", "abs": "https://arxiv.org/abs/2508.15630", "authors": ["Meera Ray", "Christopher L. Dancy"], "title": "Adapting A Vector-Symbolic Memory for Lisp ACT-R", "comment": "6 pages. 5 figures. Submitted and accepted to the 23rd International\n  Conference on Cognitive Modeling (ICCM 2025)", "summary": "Holographic Declarative Memory (HDM) is a vector-symbolic alternative to\nACT-R's Declarative Memory (DM) system that can bring advantages such as\nscalability and architecturally defined similarity between DM chunks. We\nadapted HDM to work with the most comprehensive and widely-used implementation\nof ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with\nHDM without major changes. With this adaptation of HDM, we have developed\nvector-based versions of common ACT-R functions, set up a text processing\npipeline to add the contents of large documents to ACT-R memory, and most\nsignificantly created a useful and novel mechanism to retrieve an entire chunk\nof memory based on a request using only vector representations of tokens.\nPreliminary results indicate that we can maintain vector-symbolic advantages of\nHDM (e.g., chunk recall without storing the actual chunk and other advantages\nwith scaling) while also extending it so that previous ACT-R models may work\nwith the system with little (or potentially no) modifications within the actual\nprocedural and declarative memory portions of a model. As a part of iterative\nimprovement of this newly translated holographic declarative memory module, we\nwill continue to explore better time-context representations for vectors to\nimprove the module's ability to reconstruct chunks during recall. To more fully\ntest this translated HDM module, we also plan to develop decision-making models\nthat use instance-based learning (IBL) theory, which is a useful application of\nHDM given the advantages of the system.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86 holographic declarative memory (HDM) \u7cfb\u7edf\uff0c\u4e00\u79cd\u4e0e ACT-R \u7684 declarative memory (DM) \u7cfb\u7edf\u7684\u77e2\u91cf\u7b26\u53f7\u66ff\u4ee3\u65b9\u6848\u3002\u7ecf\u9002\u914d\u540e\uff0cHDM \u53ef\u4ee5\u4f7f\u73b0\u6709\u7684 ACT-R \u6a21\u578b\u53ef\u4ee5\u5728\u5176\u4e0a\u8fd0\u884c\uff0c\u65e0\u9700\u8fdb\u884c\u91cd\u5927\u4fee\u6539\u3002\u672a\u6765\u7814\u7a76\u5c06\u7ee7\u7eed\u6539\u8fdb\u6a21\u5757\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\u8868\u793a\u65b9\u6cd5\uff0c\u5f00\u53d1\u51b3\u7b56\u6a21\u578b\u4ee5\u6d4b\u8bd5\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u5177\u6709\u4f18\u52bf\u7684 holographic declarative memory (HDM) \u7cfb\u7edf\uff0c\u4f7f\u5f97\u4e4b\u524d\u4f7f\u7528 ACT-R \u7684\u6a21\u578b\u53ef\u4ee5\u5728 HDM \u4e0a\u8fd0\u884c\u3002\u901a\u8fc7\u9002\u914d HDM\uff0c\u6a21\u578b\u53ef\u4ee5\u83b7\u5f97 HDM \u7684\u77e2\u91cf\u7b26\u53f7\u4f18\u52bf\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u6269\u5c55\u4ee5\u9002\u5e94\u4e4b\u524d\u7684 ACT-R \u6a21\u578b\uff0c\u51cf\u5c11\u6216\u65e0\u9700\u5728\u6a21\u578b\u7684\u5b58\u50a8\u90e8\u5206\u8fdb\u884c\u5927\u5e45\u4fee\u6539\u3002\u4f5c\u8005\u8fd8\u8ba1\u5212\u901a\u8fc7\u63a2\u7d22\u66f4\u597d\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\u8868\u793a\u65b9\u6cd5\u548c\u5f00\u53d1\u51b3\u7b56\u6a21\u578b\u6765\u8fdb\u4e00\u6b65\u5b8c\u5584\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u9002\u914d\u4e86 HDM \u4ee5\u4e0e ACT-R (Lisp ACT-R) \u5b9e\u73b0\u8fdb\u884c\u534f\u4f5c\uff0c\u521b\u5efa\u4e86\u57fa\u4e8e\u77e2\u91cf\u7684 ACT-R \u51fd\u6570\u7248\u672c\uff0c\u5efa\u7acb\u4e86\u6587\u672c\u5904\u7406\u6d41\u6c34\u7ebf\u4ee5\u5c06\u5927\u578b\u6587\u6863\u7684\u5185\u5bb9\u6dfb\u52a0\u5230 ACT-R \u5185\u5b58\uff0c\u5e76\u521b\u9020\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u673a\u5236\uff0c\u53ef\u4ee5\u6839\u636e\u8bf7\u6c42\u4ec5\u4f7f\u7528\u77e2\u91cf\u8868\u793a\u7684\u4ee4\u724c\u68c0\u7d22\u6574\u4e2a\u5185\u5b58\u5757\u3002\u4f5c\u8005\u8ba1\u5212\u7ee7\u7eed\u6539\u8fdb\u8be5\u7ffb\u8bd1\u540e\u7684 holographic declarative memory \u6a21\u5757\uff0c\u5305\u62ec\u63a2\u7d22\u66f4\u597d\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\u8868\u793a\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6a21\u5757\u5728\u53ec\u56de\u65f6\u91cd\u6784\u5757\u7684\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4f7f\u7528\u57fa\u4e8e\u5b9e\u4f8b\u5b66\u4e60\u7406\u8bba\u7684\u51b3\u7b56\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u5bf9 HDM \u8fdb\u884c\u9002\u914d\uff0c\u76ee\u524d\u53ef\u4ee5\u5728 ACT-R \u6a21\u578b\u4e2d\u4f7f\u7528\u8be5\u7cfb\u7edf\u800c\u65e0\u9700\u8fdb\u884c\u91cd\u5927\u4fee\u6539\u3002\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0cHDM \u53ef\u4ee5\u4fdd\u6301\u5176\u4f18\u52bf\uff0c\u5e76\u901a\u8fc7\u6269\u5c55\u4f7f\u5f97 ACT-R \u6a21\u578b\u53ef\u4ee5\u5728\u7cfb\u7edf\u4e0a\u5de5\u4f5c\uff0c\u4e0d\u9700\u8981\u5728\u6a21\u578b\u7684\u7a0b\u5e8f\u6027\u548c\u58f0\u660e\u6027\u5b58\u50a8\u90e8\u5206\u8fdb\u884c\u5927\u5e45\u4fee\u6539\u3002\u672a\u6765\u7814\u7a76\u5c06\u7ee7\u7eed\u6539\u8fdb\u65f6\u95f4\u4e0a\u4e0b\u6587\u8868\u793a\u65b9\u6cd5\u4ee5\u6539\u5584\u6a21\u5757\u7684\u53ec\u56de\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u51b3\u7b56\u6a21\u578b\u4ee5\u6d4b\u8bd5\u7ffb\u8bd1\u540e\u7684 HDM \u6a21\u5757\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd holographic declarative memory (HDM) \u7cfb\u7edf\uff0c\u5b83\u662f ACT-R \u7684 declarative memory (DM) \u7cfb\u7edf\u7684\u4e00\u79cd\u77e2\u91cf\u7b26\u53f7\u66ff\u4ee3\u65b9\u6848\u3002\u901a\u8fc7\u5bf9 HDM \u8fdb\u884c\u9002\u914d\uff0c\u4f7f\u5f97\u73b0\u6709\u7684\u4f7f\u7528 DM \u7684 ACT-R \u6a21\u578b\u53ef\u4ee5\u5728\u4e0d\u8fdb\u884c\u91cd\u5927\u66f4\u6539\u7684\u60c5\u51b5\u4e0b\u5728 HDM \u4e0a\u8fd0\u884c\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cHDM \u53ef\u4ee5\u4fdd\u6301\u77e2\u91cf\u7b26\u53f7\u7684\u4f18\u52bf\uff0c\u5e76\u901a\u8fc7\u5c06\u5176\u6269\u5c55\u4f7f\u5f97\u4e4b\u524d\u7684 ACT-R \u6a21\u578b\u53ef\u4ee5\u5728\u7cfb\u7edf\u4e0a\u5de5\u4f5c\uff0c\u4e0d\u9700\u8981\u5728\u6a21\u578b\u7684\u7a0b\u5e8f\u6027\u548c\u58f0\u660e\u6027\u5b58\u50a8\u90e8\u5206\u8fdb\u884c\u5927\u5e45\u4fee\u6539\u3002\u672a\u6765\u7684\u6539\u8fdb\u65b9\u5411\u5305\u62ec\u63a2\u7d22\u66f4\u597d\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\u8868\u793a\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6a21\u5757\u5728\u53ec\u56de\u65f6\u91cd\u6784\u5757\u7684\u80fd\u529b\u4ee5\u53ca\u5f00\u53d1\u4f7f\u7528\u57fa\u4e8e\u5b9e\u4f8b\u5b66\u4e60\u7406\u8bba\u7684\u51b3\u7b56\u6a21\u578b\u3002"}}
{"id": "2508.15652", "categories": ["cs.AI", "cs.IT", "cs.LG", "cs.MA", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15652", "abs": "https://arxiv.org/abs/2508.15652", "authors": ["Ardian Selmonaj", "Miroslav Strupl", "Oleg Szehr", "Alessandro Antonucci"], "title": "Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning", "comment": "European Conference on Artificial Intelligence (ECAI) 2025", "summary": "To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is\ncrucial to understand individual agent behaviors within a team. While prior\nwork typically evaluates overall team performance based on explicit reward\nsignals or learned value functions, it is unclear how to infer agent\ncontributions in the absence of any value feedback. In this work, we\ninvestigate whether meaningful insights into agent behaviors can be extracted\nthat are consistent with the underlying value functions, solely by analyzing\nthe policy distribution. Inspired by the phenomenon that intelligent agents\ntend to pursue convergent instrumental values, which generally increase the\nlikelihood of task success, we introduce Intended Cooperation Values (ICVs), a\nmethod based on information-theoretic Shapley values for quantifying each\nagent's causal influence on their co-players' instrumental empowerment.\nSpecifically, ICVs measure an agent's action effect on its teammates' policies\nby assessing their decision uncertainty and preference alignment. The analysis\nacross cooperative and competitive MARL environments reveals the extent to\nwhich agents adopt similar or diverse strategies. By comparing action effects\nbetween policies and value functions, our method identifies which agent\nbehaviors are beneficial to team success, either by fostering deterministic\ndecisions or by preserving flexibility for future action choices. Our proposed\nmethod offers novel insights into cooperation dynamics and enhances\nexplainability in MARL systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u4ee3\u7406\u884c\u4e3a\u3002\u901a\u8fc7\u5206\u6790\u7b56\u7565\u5206\u5e03\u63d0\u53d6\u4ee3\u7406\u884c\u4e3a\u6d1e\u5bdf\uff0c\u5f15\u5165ICVs\u65b9\u6cd5\u91cf\u5316\u6bcf\u4e2a\u4ee3\u7406\u5bf9\u5176\u5408\u4f5c\u4f19\u4f34\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\u4e86\u4ee3\u7406\u884c\u4e3a\u5982\u4f55\u5f71\u54cd\u56e2\u961f\u6210\u529f\uff0c\u589e\u5f3a\u4e86\u5bf9\u534f\u4f5c\u52a8\u6001\u7684\u7406\u89e3\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\uff0c\u4e86\u89e3\u56e2\u961f\u4e2d\u6bcf\u4e2a\u4ee3\u7406\u7684\u884c\u4e3a\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u5c24\u5176\u5728\u7f3a\u4e4f\u4ef7\u503c\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u3002\u5148\u524d\u7684\u5de5\u4f5c\u901a\u5e38\u57fa\u4e8e\u660e\u786e\u7684\u5956\u52b1\u4fe1\u53f7\u6216\u5b66\u4e60\u7684\u503c\u51fd\u6570\u8bc4\u4f30\u6574\u4f53\u56e2\u961f\u7ee9\u6548\uff0c\u4f46\u5728\u7f3a\u4e4f\u4efb\u4f55\u4ef7\u503c\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u63a8\u65ad\u4ee3\u7406\u7684\u8d21\u732e\u4ecd\u4e0d\u6e05\u695a\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5206\u6790\u7b56\u7565\u5206\u5e03\u6765\u63d0\u53d6\u4e0e\u57fa\u7840\u503c\u51fd\u6570\u4e00\u81f4\u7684\u4ee3\u7406\u884c\u4e3a\u6d1e\u5bdf\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7Intended Cooperation Values (ICVs)\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4fe1\u606f\u8bbaShapley\u503c\u6765\u91cf\u5316\u6bcf\u4e2a\u4ee3\u7406\u5bf9\u5176\u5408\u4f5c\u4f19\u4f34\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u8bc4\u4f30\u5176\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\u548c\u504f\u597d\u4e00\u81f4\u6027\u6765\u8861\u91cf\u4ee3\u7406\u5bf9\u961f\u53cb\u7b56\u7565\u7684\u884c\u4e3a\u6548\u679c\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5206\u6790\u534f\u4f5c\u548c\u7ade\u4e89\u6027\u73af\u5883\uff0c\u6bd4\u8f83\u4ee3\u7406\u91c7\u7528\u76f8\u4f3c\u6216\u4e0d\u540c\u7b56\u7565\u7684\u60c5\u51b5\uff0c\u8bc6\u522b\u6709\u76ca\u4e8e\u56e2\u961f\u6210\u529f\u7684\u4ee3\u7406\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u5f15\u5165ICVs\u65b9\u6cd5\uff0c\u672c\u7814\u7a76\u63ed\u793a\u4e86\u4ee3\u7406\u5bf9\u56e2\u961f\u6210\u529f\u6709\u76ca\u7684\u884c\u4e3a\uff0c\u65e0\u8bba\u662f\u901a\u8fc7\u4fc3\u8fdb\u786e\u5b9a\u6027\u51b3\u7b56\u8fd8\u662f\u4fdd\u7559\u672a\u6765\u884c\u52a8\u9009\u62e9\u7684\u7075\u6d3b\u6027\u3002\u6b64\u5916\uff0c\u6bd4\u8f83\u4e86\u884c\u4e3a\u5bf9\u7b56\u7565\u548c\u503c\u51fd\u6570\u7684\u5f71\u54cd\uff0c\u8bc6\u522b\u4e86\u54ea\u4e9b\u4ee3\u7406\u884c\u4e3a\u5728\u56e2\u961f\u6210\u529f\u4e2d\u8d77\u7740\u91cd\u8981\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3aIntended Cooperation Values (ICVs)\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u7b56\u7565\u5206\u5e03\u6765\u91cf\u5316\u6bcf\u4e2a\u4ee3\u7406\u5bf9\u5176\u5408\u4f5c\u4f19\u4f34\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u63d0\u4f9b\u5173\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\u4ee3\u7406\u884c\u4e3a\u7684\u5b9e\u8d28\u6d1e\u5bdf\u3002\u901a\u8fc7\u6bd4\u8f83\u884c\u4e3a\u5bf9\u7b56\u7565\u548c\u503c\u51fd\u6570\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u54ea\u4e9b\u4ee3\u7406\u884c\u4e3a\u6709\u52a9\u4e8e\u56e2\u961f\u6210\u529f\u3002\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u5bf9\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\u534f\u4f5c\u52a8\u6001\u7684\u7406\u89e3\u548c\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.15680", "categories": ["cs.AI", "cs.HC", "I.2.6; I.2.11; K.4.1; K.6.0"], "pdf": "https://arxiv.org/pdf/2508.15680", "abs": "https://arxiv.org/abs/2508.15680", "authors": ["Mark Cote", "Susana Aires"], "title": "Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle", "comment": "15 pages, 3 figures, Presented at IAIL 2025 - Imagining the AI\n  Landscape after the AI Act, 4th International Workshop on Imagining the AI\n  Landscape After the AI Act, The fourth International Conference on Hybrid\n  Human-Artificial Intelligence", "summary": "This paper argues that a techno-philosophical reading of the EU AI Act\nprovides insight into the long-term dynamics of data in AI systems,\nspecifically, how the lifecycle from ingestion to deployment generates\nrecursive value chains that challenge existing frameworks for Responsible AI.\nWe introduce a conceptual tool to frame the AI pipeline, spanning data,\ntraining regimes, architectures, feature stores, and transfer learning. Using\ncross-disciplinary methods, we develop a technically grounded and\nphilosophically coherent analysis of regulatory blind spots. Our central claim\nis that what remains absent from policymaking is an account of the dynamic of\nbecoming that underpins both the technical operation and economic logic of AI.\nTo address this, we advance a formal reading of AI inspired by Simondonian\nphilosophy of technology, reworking his concept of individuation to model the\nAI lifecycle, including the pre-individual milieu, individuation, and\nindividuated AI. To translate these ideas, we introduce futurity: the\nself-reinforcing lifecycle of AI, where more data enhances performance, deepens\npersonalisation, and expands application domains. Futurity highlights the\nrecursively generative, non-rivalrous nature of data, underpinned by\ninfrastructures like feature stores that enable feedback, adaptation, and\ntemporal recursion. Our intervention foregrounds escalating power asymmetries,\nparticularly the tech oligarchy whose infrastructures of capture, training, and\ndeployment concentrate value and decision-making. We argue that effective\nregulation must address these infrastructural and temporal dynamics, and\npropose measures including lifecycle audits, temporal traceability, feedback\naccountability, recursion transparency, and a right to contest recursive reuse.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5bf9\u6b27\u76dfAI\u6cd5\u6848\u7684\u6280\u672f\u54f2\u5b66\u9605\u8bfb\uff0c\u5206\u6790\u4e86AI\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u957f\u671f\u52a8\u6001\u3002\u5f15\u5165\u4e86\u6982\u5ff5\u5de5\u5177\u6765\u7406\u89e3AI\u7ba1\u9053\uff0c\u5f00\u53d1\u4e86\u6280\u672f\u4e0a\u624e\u6839\u4e14\u54f2\u5b66\u4e0a\u8fde\u8d2f\u7684\u5206\u6790\u3002\u63d0\u51fa\u4e86\u6b63\u5f0f\u9605\u8bfbAI\u7684\u6982\u5ff5\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u7684\u9012\u5f52\u751f\u6210\u7279\u6027\uff0c\u7a81\u51fa\u4e86\u57fa\u7840\u8bbe\u65bd\u5982\u7279\u5f81\u5b58\u50a8\u7684\u91cd\u8981\u6027\u3002\u540c\u65f6\u5f3a\u8c03\u4e86\u6280\u672f\u5be1\u5934\u7684\u4e0d\u5bf9\u79f0\u6743\u529b\u3002\u5efa\u8bae\u9700\u8981\u9488\u5bf9\u57fa\u7840\u8bbe\u65bd\u548c\u65f6\u95f4\u52a8\u6001\u91c7\u53d6\u6709\u6548\u7684\u76d1\u7ba1\u63aa\u65bd\u7b49\u3002", "motivation": "\u6211\u4eec\u7684\u4e2d\u5fc3\u89c2\u70b9\u662f\u76d1\u7ba1\u653f\u7b56\u4e2d\u7f3a\u5931\u7684\u662f\u5173\u4e8e\u652f\u6491\u6280\u672f\u8fd0\u4f5c\u548c\u7ecf\u6d4e\u903b\u8f91\u7684\u53d8\u9769\u52a8\u6001\u7684\u8bf4\u660e\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u6982\u5ff5\u6027\u5de5\u5177\u6765\u6784\u5efaAI\u7ba1\u9053\uff0c\u6db5\u76d6\u6570\u636e\u3001\u8bad\u7ec3\u5236\u5ea6\u3001\u67b6\u6784\u3001\u7279\u5f81\u5b58\u50a8\u548c\u8fc1\u79fb\u5b66\u4e60\u3002\u901a\u8fc7\u8de8\u5b66\u79d1\u65b9\u6cd5\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u5728\u6280\u672f\u4e0a\u624e\u6839\u4e14\u5728\u54f2\u5b66\u4e0a\u8fde\u8d2f\u7684\u5bf9\u76d1\u7ba1\u76f2\u70b9\u8fdb\u884c\u5206\u6790\u3002", "result": "\u6211\u4eec\u63d0\u51fa\u4e86\u5bf9AI\u7684\u6b63\u5f0f\u9605\u8bfb\uff0c\u53d7\u897f\u8499\u4e1c\u54f2\u5b66\u79d1\u6280\u7684\u542f\u53d1\uff0c\u91cd\u65b0\u5851\u9020\u4e86\u4ed6\u5173\u4e8e\u4e2a\u4f53\u5316\u7684\u6982\u5ff5\u6765\u5efa\u6a21AI\u7684\u751f\u547d\u5468\u671f\uff0c\u5305\u62ec\u524d\u4e2a\u4f53\u73af\u5883\u3001\u4e2a\u4f53\u5316\u548c\u4e2a\u4f53\u5316\u7684AI\u3002", "conclusion": "\u672c\u6587\u8ba4\u4e3a\u901a\u8fc7\u5bf9\u6b27\u76dfAI\u6cd5\u6848\u8fdb\u884c\u6280\u672f\u54f2\u5b66\u7684\u9605\u8bfb\uff0c\u53ef\u4ee5\u6df1\u5165\u4e86\u89e3AI\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u957f\u671f\u52a8\u6001\uff0c\u7279\u522b\u662f\u4ece\u6444\u53d6\u5230\u90e8\u7f72\u7684\u751f\u547d\u5468\u671f\u5982\u4f55\u4ea7\u751f\u6311\u6218\u73b0\u6709\u8d1f\u8d23\u4efb\u4eba\u5de5\u667a\u80fd\u6846\u67b6\u7684\u9012\u5f52\u4ef7\u503c\u94fe\u3002"}}
{"id": "2508.15690", "categories": ["cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.15690", "abs": "https://arxiv.org/abs/2508.15690", "authors": ["Abhigya Verma", "Sriram Puttagunta", "Seganrasan Subramanian", "Sravan Ramachandran"], "title": "GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning", "comment": "23 pages, 9 tables, 3 figures", "summary": "GRAFT is a structured multimodal benchmark for evaluating models on\ninstruction-following, visual reasoning, and visual-textual alignment tasks. It\nfeatures programmatically generated charts and synthetically rendered tables,\ncreated with Python visualization libraries to ensure control over data\nsemantics, structure, and clarity. Each GRAFT instance pairs a chart or table\nimage with a systematically generated, multi-step analytical question based\nsolely on visual content. Answers are provided in structured formats such as\nJSON or YAML, supporting consistent evaluation of both reasoning and output\nformat. The benchmark introduces a taxonomy of reasoning types including\ncomparison, trend identification, ranking, aggregation, proportion estimation,\nand anomaly detection to enable comprehensive assessment. Reference answers\nfollow strict factual and formatting guidelines for precise, aspect-based\nevaluation. GRAFT offers a unified, scalable framework for fine-grained\nbenchmarking of multimodal models on visually grounded, structured reasoning\ntasks, setting a new evaluation standard in this field.", "AI": {"tldr": "GRAFT\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u56fe\u8868\u548c\u5408\u6210\u8868\u683c\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u89c6\u89c9\u548c\u6587\u672c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u5b83\u914d\u5bf9\u56fe\u50cf\u548c\u591a\u6b65\u5206\u6790\u95ee\u9898\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u7b54\u6848\u7528\u4e8e\u8bc4\u4f30\u63a8\u7406\u548c\u8f93\u51fa\u683c\u5f0f\u3002\u8be5\u57fa\u51c6\u5f15\u5165\u63a8\u7406\u7c7b\u578b\u5206\u7c7b\u548c\u51c6\u5219\u8bc4\u4f30\uff0c\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30\u8bbe\u7acb\u4e86\u65b0\u7684\u6807\u51c6\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u4f9b\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u7ed3\u6784\u5316\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u7684\u57fa\u51c6\u3002\u901a\u8fc7\u521b\u5efa\u7a0b\u5e8f\u751f\u6210\u7684\u56fe\u8868\u548c\u5408\u6210\u6e32\u67d3\u7684\u8868\u683c\uff0c\u4ee5\u53ca\u914d\u5bf9\u89c6\u89c9\u5185\u5bb9\u548c\u5206\u6790\u95ee\u9898\uff0c\u4f7f\u5f97\u7814\u7a76\u8005\u80fd\u591f\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u5728\u63a8\u7406\u548c\u8f93\u51fa\u683c\u5f0f\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528Python\u53ef\u89c6\u5316\u5e93\u521b\u5efa\u7a0b\u5e8f\u751f\u6210\u7684\u56fe\u8868\u548c\u5408\u6210\u6e32\u67d3\u7684\u8868\u683c\uff1b\u914d\u5bf9\u56fe\u8868\u6216\u8868\u683c\u56fe\u50cf\u4e0e\u7cfb\u7edf\u751f\u6210\u7684\u591a\u6b65\u5206\u6790\u95ee\u9898\uff1b\u7b54\u6848\u63d0\u4f9b\u5728\u7ed3\u6784\u5316\u683c\u5f0f\u5982JSON\u6216YAML\u4e2d\uff0c\u652f\u6301\u4e00\u81f4\u8bc4\u4f30\uff1b\u5f15\u5165\u4e86\u63a8\u7406\u7c7b\u578b\u7684\u5206\u7c7b\u548c\u53c2\u8003\u7b54\u6848\u51c6\u5219\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u6807\u51c6\uff0cGRAFT\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u7684\u8bc4\u4f30\u5e26\u6765\u4e86\u91cd\u8981\u8d21\u732e\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u89c6\u89c9\u63a8\u7406\u548c\u7ed3\u6784\u5316\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "GRAFT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u9075\u5faa\u6307\u4ee4\u3001\u89c6\u89c9\u63a8\u7406\u548c\u89c6\u89c9-\u6587\u672c\u5bf9\u9f50\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u5b83\u5305\u62ec\u7528Python\u53ef\u89c6\u5316\u5e93\u521b\u5efa\u7684\u7a0b\u5e8f\u751f\u6210\u7684\u56fe\u8868\u548c\u5408\u6210\u6e32\u67d3\u7684\u8868\u683c\uff0c\u4ee5\u786e\u4fdd\u5bf9\u6570\u636e\u8bed\u4e49\u3001\u7ed3\u6784\u548c\u6e05\u6670\u5ea6\u7684\u63a7\u5236\u3002\u6bcf\u4e2aGRAFT\u5b9e\u4f8b\u5c06\u56fe\u8868\u6216\u8868\u683c\u56fe\u50cf\u4e0e\u4ec5\u57fa\u4e8e\u89c6\u89c9\u5185\u5bb9\u7684\u7cfb\u7edf\u751f\u6210\u7684\u591a\u6b65\u5206\u6790\u95ee\u9898\u914d\u5bf9\u3002\u7b54\u6848\u4ee5JSON\u6216YAML\u7b49\u7ed3\u6784\u5316\u683c\u5f0f\u63d0\u4f9b\uff0c\u652f\u6301\u5bf9\u63a8\u7406\u548c\u8f93\u51fa\u683c\u5f0f\u7684\u4e00\u81f4\u8bc4\u4f30\u3002\u8be5\u57fa\u51c6\u5f15\u5165\u4e86\u5305\u62ec\u6bd4\u8f83\u3001\u8d8b\u52bf\u8bc6\u522b\u3001\u6392\u540d\u3001\u805a\u5408\u3001\u6bd4\u4f8b\u4f30\u8ba1\u548c\u5f02\u5e38\u68c0\u6d4b\u5728\u5185\u7684\u63a8\u7406\u7c7b\u578b\u7684\u5206\u7c7b\uff0c\u4ee5\u5b9e\u73b0\u5168\u9762\u8bc4\u4f30\u3002\u53c2\u8003\u7b54\u6848\u9075\u5faa\u4e25\u683c\u7684\u4e8b\u5b9e\u548c\u683c\u5f0f\u5316\u51c6\u5219\uff0c\u7528\u4e8e\u7cbe\u786e\u7684\u3001\u57fa\u4e8e\u65b9\u9762\u7684\u8bc4\u4f30\u3002GRAFT\u4e3a\u5728\u89c6\u89c9\u57fa\u7840\u3001\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u57fa\u51c6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u4e3a\u8be5\u9886\u57df\u786e\u7acb\u4e86\u65b0\u7684\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2508.15693", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15693", "abs": "https://arxiv.org/abs/2508.15693", "authors": ["Wilka Carvalho", "Vikram Goddla", "Ishaan Sinha", "Hoon Shin", "Kunal Jha"], "title": "NiceWebRL: a Python library for human subject experiments with reinforcement learning environments", "comment": null, "summary": "We present NiceWebRL, a research tool that enables researchers to use machine\nreinforcement learning (RL) environments for online human subject experiments.\nNiceWebRL is a Python library that allows any Jax-based environment to be\ntransformed into an online interface, supporting both single-agent and\nmulti-agent environments. As such, NiceWebRL enables AI researchers to compare\ntheir algorithms to human performance, cognitive scientists to test ML\nalgorithms as theories for human cognition, and multi-agent researchers to\ndevelop algorithms for human-AI collaboration. We showcase NiceWebRL with 3\ncase studies that demonstrate its potential to help develop Human-like AI,\nHuman-compatible AI, and Human-assistive AI. In the first case study\n(Human-like AI), NiceWebRL enables the development of a novel RL model of\ncognition. Here, NiceWebRL facilitates testing this model against human\nparticipants in both a grid world and Craftax, a 2D Minecraft domain. In our\nsecond case study (Human-compatible AI), NiceWebRL enables the development of a\nnovel multi-agent RL algorithm that can generalize to human partners in the\nOvercooked domain. Finally, in our third case study (Human-assistive AI), we\nshow how NiceWebRL can allow researchers to study how an LLM can assist humans\non complex tasks in XLand-Minigrid, an environment with millions of\nhierarchical tasks. The library is available at\nhttps://github.com/KempnerInstitute/nicewebrl.", "AI": {"tldr": "NiceWebRL\u662f\u4e00\u4e2aPython\u5e93\uff0c\u53ef\u4ee5\u5c06\u57fa\u4e8eJax\u7684\u73af\u5883\u8f6c\u6362\u4e3a\u5728\u7ebf\u754c\u9762\uff0c\u652f\u6301\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\u3002\u5b83\u7684\u6f5c\u529b\u4f53\u73b0\u5728\u5f00\u53d1\u4eba\u7c7b\u5316AI\u3001\u4e0e\u4eba\u7c7b\u517c\u5bb9\u7684AI\u548c\u4eba\u7c7b\u8f85\u52a9AI\u65b9\u9762\uff0c\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5e94\u7528\u524d\u666f\u3002NiceWebRL\u53ef\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u6bd4\u8f83\u7b97\u6cd5\u4e0e\u4eba\u7c7b\u8868\u73b0\u3001\u6d4b\u8bd5ML\u7b97\u6cd5\u4f5c\u4e3a\u4eba\u7c7b\u8ba4\u77e5\u7406\u8bba\uff0c\u5e76\u5f00\u53d1\u7528\u4e8e\u4eba\u673a\u534f\u4f5c\u7684\u7b97\u6cd5\u3002", "motivation": "NiceWebRL\u7684\u52a8\u673a\u662f\u5e2e\u52a9AI\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4eba\u7c7b\u5316\u3001\u4e0e\u4eba\u7c7b\u517c\u5bb9\u7684\u548c\u4eba\u7c7b\u8f85\u52a9\u7684AI\u3002\u901a\u8fc7\u5c06\u673a\u5668\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u8f6c\u6362\u4e3a\u5728\u7ebf\u754c\u9762\uff0cNiceWebRL\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u5e73\u53f0\uff0c\u4f7f\u4ed6\u4eec\u80fd\u591f\u4e0e\u4eba\u7c7b\u8fdb\u884c\u6bd4\u8f83\u548c\u6d4b\u8bd5\uff0c\u4ece\u800c\u4fc3\u8fdb\u4eba\u7c7bAI\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "NiceWebRL\u662f\u4e00\u4e2aPython\u5e93\uff0c\u53ef\u4ee5\u5c06\u4efb\u4f55\u57fa\u4e8eJax\u7684\u73af\u5883\u8f6c\u6362\u4e3a\u5728\u7ebf\u754c\u9762\uff0c\u652f\u6301\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\u3002\u901a\u8fc7NiceWebRL\uff0c\u7814\u7a76\u4eba\u5458\u53ef\u4ee5\u6bd4\u8f83\u4ed6\u4eec\u7684\u7b97\u6cd5\u4e0e\u4eba\u7c7b\u8868\u73b0\uff0c\u8ba4\u77e5\u79d1\u5b66\u5bb6\u53ef\u4ee5\u5c06ML\u7b97\u6cd5\u7528\u4f5c\u4eba\u7c7b\u8ba4\u77e5\u7406\u8bba\u7684\u6d4b\u8bd5\uff0c\u591a\u667a\u80fd\u4f53\u7814\u7a76\u4eba\u5458\u53ef\u4ee5\u5f00\u53d1\u7528\u4e8e\u4eba\u673a\u534f\u4f5c\u7684\u7b97\u6cd5\u3002", "result": "NiceWebRL\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u6f5c\u529b\uff0c\u5305\u62ec\u5f00\u53d1\u8ba4\u77e5\u6a21\u578b\u3001\u591a\u667a\u80fd\u4f53RL\u7b97\u6cd5\u4ee5\u53ca\u7814\u7a76LLM\u5982\u4f55\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8f85\u52a9\u4eba\u7c7b\u3002\u8be5\u5e93\u53ef\u5728https://github.com/KempnerInstitute/nicewebrl\u83b7\u53d6\u3002", "conclusion": "NiceWebRL\u662f\u4e00\u4e2a\u7814\u7a76\u5de5\u5177\uff0c\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u5728\u7ebf\u8fdb\u884c\u57fa\u4e8e\u673a\u5668\u5f3a\u5316\u5b66\u4e60\u7684\u4eba\u7c7b\u8bd5\u9a8c\u3002\u5b83\u652f\u6301\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\uff0c\u5e76\u53ef\u7528\u4e8e\u5f00\u53d1\u4eba\u7c7b\u5316AI\u3001\u4e0e\u4eba\u7c7b\u517c\u5bb9\u7684AI\u548c\u4eba\u7c7b\u8f85\u52a9AI\u3002\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86NiceWebRL\u7684\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u5f00\u53d1\u4eba\u7c7b\u5316AI\u3001\u4e0e\u4eba\u7c7b\u517c\u5bb9\u7684AI\u548c\u4eba\u7c7b\u8f85\u52a9AI\u3002"}}
{"id": "2508.15734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15734", "abs": "https://arxiv.org/abs/2508.15734", "authors": ["Cooper Elsworth", "Keguo Huang", "David Patterson", "Ian Schneider", "Robert Sedivy", "Savannah Goodman", "Ben Townsend", "Parthasarathy Ranganathan", "Jeff Dean", "Amin Vahdat", "Ben Gomes", "James Manyika"], "title": "Measuring the environmental impact of delivering AI at Google Scale", "comment": null, "summary": "The transformative power of AI is undeniable - but as user adoption\naccelerates, so does the need to understand and mitigate the environmental\nimpact of AI serving. However, no studies have measured AI serving\nenvironmental metrics in a production environment. This paper addresses this\ngap by proposing and executing a comprehensive methodology for measuring the\nenergy usage, carbon emissions, and water consumption of AI inference workloads\nin a large-scale, AI production environment. Our approach accounts for the full\nstack of AI serving infrastructure - including active AI accelerator power,\nhost system energy, idle machine capacity, and data center energy overhead.\nThrough detailed instrumentation of Google's AI infrastructure for serving the\nGemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24\nWh of energy - a figure substantially lower than many public estimates. We also\nshow that Google's software efficiency efforts and clean energy procurement\nhave driven a 33x reduction in energy consumption and a 44x reduction in carbon\nfootprint for the median Gemini Apps text prompt over one year. We identify\nthat the median Gemini Apps text prompt uses less energy than watching nine\nseconds of television (0.24 Wh) and consumes the equivalent of five drops of\nwater (0.26 mL). While these impacts are low compared to other daily\nactivities, reducing the environmental impact of AI serving continues to\nwarrant important attention. Towards this objective, we propose that a\ncomprehensive measurement of AI serving environmental metrics is critical for\naccurately comparing models, and to properly incentivize efficiency gains\nacross the full AI serving stack.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8be6\u7ec6\u6d4b\u91cfGoogle\u7684AI\u57fa\u7840\u8bbe\u65bd\uff0c\u53d1\u73b0Gemini Apps\u6587\u672c\u63d0\u793a\u7684\u80fd\u6e90\u6d88\u8017\u4f4e\u4e8e\u516c\u5171\u4f30\u7b97\uff0c\u4e14Google\u7684\u8f6f\u4ef6\u6548\u7387\u6539\u8fdb\u548c\u6e05\u6d01\u80fd\u6e90\u91c7\u8d2d\u5927\u5e45\u51cf\u5c11\u4e86\u5176\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u3002\u867d\u7136AI\u670d\u52a1\u7684\u73af\u5883\u5f71\u54cd\u76f8\u5bf9\u8f83\u4f4e\uff0c\u4f46\u4ecd\u9700\u8981\u5173\u6ce8\u548c\u51cf\u5c11\uff0c\u63d0\u51fa\u7efc\u5408\u6d4b\u91cfAI\u670d\u52a1\u73af\u5883\u6307\u6807\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740AI\u7528\u6237\u91c7\u7528\u52a0\u901f\uff0c\u7406\u89e3\u548c\u51cf\u5c11AI\u670d\u52a1\u7684\u73af\u5883\u5f71\u54cd\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u5c1a\u65e0\u7814\u7a76\u91cf\u5316AI\u670d\u52a1\u73af\u5883\u6307\u6807\u3002\u672c\u7814\u7a76\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86\u7efc\u5408\u65b9\u6cd5\u6765\u8861\u91cf\u5927\u89c4\u6a21AI\u751f\u4ea7\u73af\u5883\u4e2dAI\u63a8\u65ad\u5de5\u4f5c\u8d1f\u8f7d\u7684\u80fd\u6e90\u4f7f\u7528\u3001\u78b3\u6392\u653e\u548c\u6c34\u6d88\u8017\u3002", "method": "\u672c\u6587\u901a\u8fc7\u63d0\u51fa\u548c\u6267\u884c\u7efc\u5408\u65b9\u6cd5\uff0c\u6d4b\u91cf\u4e86AI\u63a8\u65ad\u5de5\u4f5c\u8d1f\u8f7d\u7684\u80fd\u6e90\u4f7f\u7528\u3001\u78b3\u6392\u653e\u548c\u6c34\u6d88\u8017\u3002\u65b9\u6cd5\u8003\u8651\u4e86AI\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\u7684\u6574\u4e2a\u6808\uff0c\u5305\u62ec\u6d3b\u52a8AI\u52a0\u901f\u5668\u529f\u7387\u3001\u4e3b\u673a\u7cfb\u7edf\u80fd\u6e90\u3001\u95f2\u7f6e\u673a\u5668\u5bb9\u91cf\u548c\u6570\u636e\u4e2d\u5fc3\u80fd\u6e90\u5f00\u9500\u3002\u5229\u7528\u5bf9Google\u7684Gemini AI\u52a9\u624b\u7684\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u8be6\u7ec6\u4eea\u5668\u5316\uff0c\u6df1\u5165\u7814\u7a76\u4e86Gemini Apps\u6587\u672c\u63d0\u793a\u7684\u80fd\u6e90\u6d88\u8017\u60c5\u51b5\u3002", "result": "\u901a\u8fc7\u8be5\u7814\u7a76\uff0c\u5728\u8be6\u7ec6\u4eea\u5668\u5316Google\u7684AI\u57fa\u7840\u8bbe\u65bd\u540e\uff0c\u53d1\u73b0Gemini Apps\u6587\u672c\u63d0\u793a\u7684\u80fd\u6e90\u6d88\u8017\u8f83\u4f4e\uff0c\u4e14Google\u7684\u8f6f\u4ef6\u6548\u7387\u6539\u8fdb\u548c\u6e05\u6d01\u80fd\u6e90\u91c7\u8d2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u51cf\u5c11\u3002\u7814\u7a76\u7ed3\u679c\u8fd8\u6307\u51fa\uff0cGemini Apps\u6587\u672c\u63d0\u793a\u7684\u80fd\u6e90\u6d88\u8017\u76f8\u5bf9\u8f83\u4f4e\uff0c\u76f8\u5f53\u4e8e\u770b9\u79d2\u7684\u7535\u89c6\u548c\u6d88\u80175\u6ef4\u6c34\u3002", "conclusion": "\u672c\u6587\u9488\u5bf9\u751f\u4ea7\u73af\u5883\u4e2dAI\u670d\u52a1\u7684\u73af\u5883\u6307\u6807\u8fdb\u884c\u4e86\u6d4b\u91cf\u548c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u7efc\u5408\u65b9\u6cd5\u3002\u901a\u8fc7\u5bf9Google\u7684AI\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u8be6\u7ec6\u4eea\u5668\u5316\uff0c\u53d1\u73b0Gemini Apps\u6587\u672c\u63d0\u793a\u7684\u80fd\u6e90\u6d88\u8017\u4f4e\u4e8e\u8bb8\u591a\u516c\u5171\u4f30\u7b97\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0cGoogle\u7684\u8f6f\u4ef6\u6548\u7387\u6539\u8fdb\u548c\u6e05\u6d01\u80fd\u6e90\u91c7\u8d2d\u4f7fGemini Apps\u6587\u672c\u63d0\u793a\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u8db3\u8ff9\u964d\u4f4e\u4e8633\u500d\u548c44\u500d\u3002\u867d\u7136AI\u670d\u52a1\u5bf9\u73af\u5883\u5f71\u54cd\u76f8\u5bf9\u8f83\u4f4e\uff0c\u4f46\u4ecd\u9700\u91cd\u89c6\u51cf\u5c11\u5176\u73af\u5883\u5f71\u54cd\u3002\u5efa\u8bae\u901a\u8fc7\u7efc\u5408\u6d4b\u91cfAI\u670d\u52a1\u7684\u73af\u5883\u6307\u6807\uff0c\u4ee5\u4fbf\u6bd4\u8f83\u6a21\u578b\u548c\u6fc0\u52b1AI\u670d\u52a1\u6574\u4e2a\u73af\u5883\u6808\u7684\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2508.15748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15748", "abs": "https://arxiv.org/abs/2508.15748", "authors": ["Emma Rath", "Stuart Armstrong", "Rebecca Gorman"], "title": "Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots", "comment": null, "summary": "The development of parasocial relationships with AI agents has severe, and in\nsome cases, tragic effects for human well-being. Yet preventing such dynamics\nis challenging: parasocial cues often emerge gradually in private\nconversations, and not all forms of emotional engagement are inherently\nharmful. We address this challenge by introducing a simple response evaluation\nframework, created by repurposing a state-of-the-art language model, that\nevaluates ongoing conversations for parasocial cues in real time. To test the\nfeasibility of this approach, we constructed a small synthetic dataset of\nthirty dialogues spanning parasocial, sycophantic, and neutral conversations.\nIterative evaluation with five stage testing successfully identified all\nparasocial conversations while avoiding false positives under a tolerant\nunanimity rule, with detection typically occurring within the first few\nexchanges. These findings provide preliminary evidence that evaluation agents\ncan provide a viable solution for the prevention of parasocial relations.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e\u5b9e\u65f6\u8bc4\u4f30\u5bf9\u8bdd\u4e2d\u4eba\u9645\u7ebf\u7d22\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u4e2a\u9636\u6bb5\u6d4b\u8bd5\u6210\u529f\u8bc6\u522b\u6240\u6709\u4eba\u9645\u5173\u7cfb\u5bf9\u8bdd\uff0c\u907f\u514d\u8bef\u62a5\u3002\u8bc4\u4f30\u4ee3\u7406\u88ab\u8bc1\u660e\u53ef\u4ee5\u4e3a\u9884\u9632\u4eba\u9645\u5173\u7cfb\u95ee\u9898\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "AI\u4ee3\u7406\u4e0e\u4eba\u5efa\u7acb\u7684\u865a\u62df\u5173\u7cfb\u5bf9\u4eba\u7c7b\u798f\u7949\u6709\u4e25\u91cd\u5f71\u54cd\uff0c\u4f46\u9884\u9632\u8fd9\u79cd\u52a8\u6001\u662f\u5177\u6709\u6311\u6218\u6027\u7684\u3002\u4eba\u9645\u7ebf\u7d22\u901a\u5e38\u9010\u6e10\u5728\u79c1\u4eba\u5bf9\u8bdd\u4e2d\u51fa\u73b0\uff0c\u5e76\u975e\u6240\u6709\u5f62\u5f0f\u7684\u60c5\u611f\u53c2\u4e0e\u90fd\u662f\u6709\u5bb3\u7684\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u7b80\u5355\u7684\u54cd\u5e94\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u5b9e\u65f6\u8bc4\u4f30\u5bf9\u8bdd\u4ee5\u53d1\u73b0\u4eba\u9645\u7ebf\u7d22\uff0c\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u54cd\u5e94\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u91cd\u65b0\u5b9a\u4f4d\uff0c\u5b9e\u65f6\u8bc4\u4f30\u8fdb\u884c\u4e2d\u7684\u5bf9\u8bdd\u4ee5\u5bfb\u627e\u4eba\u9645\u5173\u7cfb\u7ebf\u7d22\u3002\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u5bf9\u8bdd\u7684\u5c0f\u578b\u5408\u6210\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e86\u4eba\u9645\u5173\u7cfb\u3001\u9a6c\u5c41\u62cd\u5ba2\u4ee5\u53ca\u4e2d\u7acb\u5bf9\u8bdd\uff0c\u8fdb\u884c\u4e86\u8fed\u4ee3\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u4e94\u4e2a\u9636\u6bb5\u6d4b\u8bd5\u6210\u529f\u5730\u8bc6\u522b\u4e86\u6240\u6709\u4eba\u9645\u5173\u7cfb\u5bf9\u8bdd\uff0c\u5728\u5bbd\u5bb9\u7684\u4e00\u81f4\u6027\u89c4\u5219\u4e0b\u907f\u514d\u4e86\u8bef\u62a5\uff0c\u68c0\u6d4b\u901a\u5e38\u5728\u6700\u521d\u51e0\u6b21\u4ea4\u6d41\u4e2d\u5b8c\u6210\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8bc4\u4f30\u4ee3\u7406\u80fd\u591f\u6210\u529f\u8bc6\u522b\u6240\u6709\u4eba\u9645\u5173\u7cfb\u5bf9\u8bdd\uff0c\u907f\u514d\u8bef\u62a5\uff0c\u5728\u6700\u521d\u51e0\u6b21\u4ea4\u6d41\u4e2d\u8fdb\u884c\u68c0\u6d4b\u3002\u8fd9\u4e9b\u53d1\u73b0\u521d\u6b65\u8bc1\u660e\u8bc4\u4f30\u4ee3\u7406\u53ef\u4ee5\u4e3a\u9884\u9632\u4eba\u9645\u5173\u7cfb\u95ee\u9898\u63d0\u4f9b\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8bc4\u4f30\u4ee3\u7406\u53ef\u4ee5\u4e3a\u9884\u9632\u4eba\u9645\u5173\u7cfb\u95ee\u9898\u63d0\u4f9b\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15757", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15757", "abs": "https://arxiv.org/abs/2508.15757", "authors": ["Yuxing Lu", "Yucheng Hu", "Nan Sun", "Xukai Zhao"], "title": "Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback", "comment": "9 pages, 4 figures, 4 tables", "summary": "Configuration optimization remains a critical bottleneck in machine learning,\nrequiring coordinated tuning across model architecture, training strategy,\nfeature engineering, and hyperparameters. Traditional approaches treat these\ndimensions independently and lack interpretability, while recent automated\nmethods struggle with dynamic adaptability and semantic reasoning about\noptimization decisions. We introduce Language-Guided Tuning (LGT), a novel\nframework that employs multi-agent Large Language Models to intelligently\noptimize configurations through natural language reasoning. We apply textual\ngradients - qualitative feedback signals that complement numerical optimization\nby providing semantic understanding of training dynamics and configuration\ninterdependencies. LGT coordinates three specialized agents: an Advisor that\nproposes configuration changes, an Evaluator that assesses progress, and an\nOptimizer that refines the decision-making process, creating a self-improving\nfeedback loop. Through comprehensive evaluation on six diverse datasets, LGT\ndemonstrates substantial improvements over traditional optimization methods,\nachieving performance gains while maintaining high interpretability.", "AI": {"tldr": "Language-Guided Tuning (LGT) is a framework that optimizes machine learning configurations using natural language reasoning. It outperforms traditional methods, employs textual gradients for semantic reasoning, and consists of three agents for configuration optimization.", "motivation": "The motivation behind this paper is the need for a more effective and interpretable approach to configuration optimization in machine learning. Traditional methods lack interpretability while automated methods struggle with dynamic adaptability and semantic reasoning. LGT aims to address these limitations by integrating natural language reasoning into the optimization process.", "method": "LGT employs multi-agent Large Language Models to optimize configurations using textual gradients for semantic reasoning and feedback signals. It consists of three specialized agents: an Advisor, an Evaluator, and an Optimizer, creating a self-improving feedback loop.", "result": "LGT demonstrates significant performance gains over traditional optimization methods in comprehensive evaluation on six diverse datasets. It achieves improved performance while ensuring high interpretability of the optimization decisions.", "conclusion": "Language-Guided Tuning (LGT) is a novel framework that intelligently optimizes configurations in machine learning through natural language reasoning. It outperforms traditional optimization methods with substantial improvements while maintaining high interpretability."}}
