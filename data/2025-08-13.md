<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 41]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Topos Theory for Generative AI and LLMs](https://arxiv.org/abs/2508.08293)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文提出了使用拓扑理论和范畴论中的通用构造方法，探索新型LLM架构，验证了LLMs的分类形成了一个拓扑，定义了LLM拓扑架构的潜在实现。


<details>
  <summary>Details</summary>
Motivation: 通过拓扑理论和范畴论的研究，构建新型分类生成AI架构和LLM架构，探索其通用构造。未来有望提高模型的性能和泛化能力。

Method: 本文使用拓扑理论和范畴论中的通用构造方法，探索了新型LLM架构。借鉴Transformer模型的理论结果，构建了LLM架构，并验证了LLMs的分类形成了一个拓扑。利用函数性描述反向传播，定义了LLM拓扑架构的潜在实现。

Result: 验证了LLMs的分类形成了一个拓扑，展示了新型LLM架构的潜在实现。

Conclusion: 本文提出了使用拓扑理论设计新型分类生成AI架构(GAIAs)的方法。通过研究前沿的Transformer模型理论结果，探索了基于LLMs的新型架构，并使用范畴论中的通用构造来构建新型LLM架构。最终验证了LLMs的分类形成了一个拓扑，需要展示指数对象和子对象分类器的存在。通过函数性描述反向传播，定义了LLM拓扑架构的潜在实现。

Abstract: We propose the design of novel categorical generative AI architectures
(GAIAs) using topos theory, a type of category that is ``set-like": a topos has
all (co)limits, is Cartesian closed, and has a subobject classifier. Previous
theoretical results on the Transformer model have shown that it is a universal
sequence-to-sequence function approximator, and dense in the space of all
continuous functions with compact support on the Euclidean space of embeddings
of tokens. Building on this theoretical result, we explore novel architectures
for LLMs that exploit the property that the category of LLMs, viewed as
functions, forms a topos. Previous studies of large language models (LLMs) have
focused on daisy-chained linear architectures or mixture-of-experts. In this
paper, we use universal constructions in category theory to construct novel LLM
architectures based on new types of compositional structures. In particular,
these new compositional structures are derived from universal properties of LLM
categories, and include pullback, pushout, (co) equalizers, exponential
objects, and subobject classifiers. We theoretically validate these new
compositional structures by showing that the category of LLMs is (co)complete,
meaning that all diagrams have solutions in the form of (co)limits. Building on
this completeness result, we then show that the category of LLMs forms a topos,
a ``set-like" category, which requires showing the existence of exponential
objects as well as subobject classifiers. We use a functorial characterization
of backpropagation to define a potential implementation of an LLM topos
architecture.

</details>


### [2] [Topos Causal Models](https://arxiv.org/abs/2508.08295)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文提出了拓扑因果模型(TCMs)，展示了其在因果推断中的重要性，通过证明每个因果图都有一个“解”来实现因果模型的近似，强调自然变换在衡量近似质量中的作用，提出了一种新颖的因果近似解释，为建立局部自治因果机制的全局函数提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于展示拓扑因果模型在因果推断中的重要性，从提出新的因果模型角度探索因果推断的各种应用，为因果等价和干预提供形式化的推理方式，并通过内部逻辑和Kripke-Joyal语义来理解因果模型。

Method: 本文通过证明拓扑因果模型是(co)complete的，展示了每个因果图都有一个(co)limit的“解”，从而表明任意因果模型都可以通过某个全局函数来“近似”，同时重视自然变换在衡量近似质量中的作用。

Result: 拓扑因果模型(TCMs)是一个重要的因果模型类别，具有(co)complete性质，能够处理复杂的因果推断问题，通过局部自治因果机制的全局函数解构建立全局函数，同时通过拓扑构造提供了因果等价和因果干预的推理方式。

Conclusion: 这篇论文提出了拓扑因果模型(TCMs)，展示了其与因果推断中许多应用的关键性质，通过引入一种新颖的因果近似解释，可以有效解决复杂的因果图，为建立局部自治因果机制的全局函数提供了理论基础。

Abstract: We propose topos causal models (TCMs), a novel class of causal models that
exploit the key properties of a topos category: they are (co)complete, meaning
all (co)limits exist, they admit a subobject classifier, and allow exponential
objects. The main goal of this paper is to show that these properties are
central to many applications in causal inference. For example, subobject
classifiers allow a categorical formulation of causal intervention, which
creates sub-models. Limits and colimits allow causal diagrams of arbitrary
complexity to be ``solved", using a novel interpretation of causal
approximation. Exponential objects enable reasoning about equivalence classes
of operations on causal models, such as covered edge reversal and causal
homotopy. Analogous to structural causal models (SCMs), TCMs are defined by a
collection of functions, each defining a ``local autonomous" causal mechanism
that assemble to induce a unique global function from exogenous to endogenous
variables. Since the category of TCMs is (co)complete, which we prove in this
paper, every causal diagram has a ``solution" in the form of a (co)limit: this
implies that any arbitrary causal model can be ``approximated" by some global
function with respect to the morphisms going into or out of the diagram.
Natural transformations are crucial in measuring the quality of approximation.
In addition, we show that causal interventions are modeled by subobject
classifiers: any sub-model is defined by a monic arrow into its parent model.
Exponential objects permit reasoning about entire classes of causal
equivalences and interventions. Finally, as TCMs form a topos, they admit an
internal logic defined as a Mitchell-Benabou language with an associated
Kripke-Joyal semantics. We show how to reason about causal models in TCMs using
this internal logic.

</details>


### [3] [An Efficient Application of Goal Programming to Tackle Multiobjective Problems with Recurring Fitness Landscapes](https://arxiv.org/abs/2508.08297)
*Rodrigo Lankaites Pinheiro,Dario Landa-Silva,Wasakorn Laesanklang,Ademir Aparecido Constantino*

Main category: cs.AI

TL;DR: 该论文提出了一种方法，通过结合多目标算法和目标规划，在具有相似适应度景观的问题实例中找到良好的折衷解决方案，提高了解决问题的效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 许多实际应用需要决策者在考虑多个冲突目标时评估解决方案的质量，解决高度受限制的多目标问题通常是一项艰巨的任务。

Method: 通过使用计算开销较大的多目标算法解决一个给定问题情景的实例，然后利用效率高的单目标算法和目标规划解决相同问题情景的其他实例。使用了三个基于目标的目标函数。

Result: 在多目标车辆路径问题实例上展示了提出的方法的有效性和效率。

Conclusion: 提出了一种方法，结合多目标算法和目标规划，用于解决具有相似适应度景观的问题实例，能够在短时间内产生良好的结果。

Abstract: Many real-world applications require decision-makers to assess the quality of
solutions while considering multiple conflicting objectives. Obtaining good
approximation sets for highly constrained many-objective problems is often a
difficult task even for modern multiobjective algorithms. In some cases,
multiple instances of the problem scenario present similarities in their
fitness landscapes. That is, there are recurring features in the fitness
landscapes when searching for solutions to different problem instances. We
propose a methodology to exploit this characteristic by solving one instance of
a given problem scenario using computationally expensive multiobjective
algorithms to obtain a good approximation set and then using Goal Programming
with efficient single-objective algorithms to solve other instances of the same
problem scenario. We use three goal-based objective functions and show that on
benchmark instances of the multiobjective vehicle routing problem with time
windows, the methodology is able to produce good results in short computation
time. The methodology allows to combine the effectiveness of state-of-the-art
multiobjective algorithms with the efficiency of goal programming to find good
compromise solutions in problem scenarios where instances have similar fitness
landscapes.

</details>


### [4] [LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models](https://arxiv.org/abs/2508.08300)
*Yongchao Huang*

Main category: cs.AI

TL;DR: 该论文研究了使用LLM自动化贝叶斯推断的过程，提出了LLM-BI概念管道，并通过两个实验验证了LLM的潜力，为概率编程的自动化推断管线铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯推断的普及面临着先验分布和似然函数的规范化问题，需要专业的统计专业知识。本论文旨在探索使用LLM自动化这一过程的可行性。

Method: 介绍了LLM-BI（大型语言模型驱动的贝叶斯推断）的概念管道，通过两个实验展示了LLM能够从自然语言中获取先验分布并指定完整的模型结构。

Result: 实验结果表明LLM可以成功从自然语言中获取先验分布，并且能够从高层问题描述中指定整个模型结构，包括先验和似然函数。

Conclusion: 该论文研究了使用大型语言模型（LLM）自动化贝叶斯推断的过程，并证实了LLM在自动化贝叶斯建模中的潜力。

Abstract: A significant barrier to the widespread adoption of Bayesian inference is the
specification of prior distributions and likelihoods, which often requires
specialized statistical expertise. This paper investigates the feasibility of
using a Large Language Model (LLM) to automate this process. We introduce
LLM-BI (Large Language Model-driven Bayesian Inference), a conceptual pipeline
for automating Bayesian workflows. As a proof-of-concept, we present two
experiments focused on Bayesian linear regression. In Experiment I, we
demonstrate that an LLM can successfully elicit prior distributions from
natural language. In Experiment II, we show that an LLM can specify the entire
model structure, including both priors and the likelihood, from a single
high-level problem description. Our results validate the potential of LLMs to
automate key steps in Bayesian modeling, enabling the possibility of an
automated inference pipeline for probabilistic programming.

</details>


### [5] [First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models](https://arxiv.org/abs/2508.08308)
*Chuanruo Fu,Yuncheng Du*

Main category: cs.AI

TL;DR: 提出了First Ask Then Answer（FATA）交互范式，通过多维补充问题和用户信息相结合，提高了LLMs的响应质量和相关性，实验结果显示FATA在综合指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: LLMs在面对用户提供不完整或模糊的信息时往往难以提供准确可操作的答案。本研究的动机是通过新的交互范式FATA解决这一问题，强调完整性和用户参与，提高对话效率和稳定性。

Method: 使用First Ask Then Answer（FATA）交互范式，通过促使LLMs生成多维补充问题，结合用户提供信息和原始查询，采用复杂的引导技术，提高响应质量和相关性。评估采用了多领域基准测试，与两个对照实验（B-Prompt和C-Prompt）对比。

Result: 实验证明，FATA在综合指标上比B-Prompt提高约40%，具有较低的变异系数，表现更加稳定。

Conclusion: 提出了一种新的交互范式First Ask Then Answer（FATA），通过提示词引导LLMs主动生成多维补充问题，结合用户提供的信息和原始查询，通过复杂的引导技术实现了显著提高的响应质量和相关性。与现有的澄清方法（如针对模棱两可的CLAM框架和自问自答的方法Self-Ask）相比，FATA强调完整性和用户参与，采用一次性策略生成所有澄清问题，减少对话长度，提高效率。实验证明，FATA在综合指标上比B-Prompt提高约40%，且具有比C-Prompt低8%的变异系数，表现更加稳定。

Abstract: Large Language Models (LLMs) often struggle to deliver accurate and
actionable answers when user-provided information is incomplete or
ill-specified. We propose a new interaction paradigm, First Ask Then Answer
(FATA), in which, through prompt words, LLMs are guided to proactively generate
multidimensional supplementary questions for users prior to response
generation. Subsequently, by integrating user-provided supplementary
information with the original query through sophisticated prompting techniques,
we achieve substantially improved response quality and relevance. In contrast
to existing clarification approaches -- such as the CLAM framework oriented to
ambiguity and the self-interrogation Self-Ask method -- FATA emphasizes
completeness (beyond mere disambiguation) and user participation (inviting
human input instead of relying solely on model-internal reasoning). It also
adopts a single-turn strategy: all clarifying questions are produced at once,
thereby reducing dialogue length and improving efficiency. Conceptually, FATA
uses the reasoning power of LLMs to scaffold user expression, enabling
non-expert users to formulate more comprehensive and contextually relevant
queries. To evaluate FATA, we constructed a multi-domain benchmark and compared
it with two controls: a baseline prompt (B-Prompt) and a context-enhanced
expert prompt (C-Prompt). Experimental results show that FATA outperforms
B-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient
of variation 8% lower than C-Prompt, indicating superior stability.

</details>


### [6] [What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge](https://arxiv.org/abs/2508.08344)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: 知识图检索增强生成方法在知识不完整情况下推理能力有限，依赖内部记忆，泛化能力受设计影响。提出构建基准测试方法和评估协议，系统评估这些方法的表现，发现现有方法在缺失知识时表现有限。


<details>
  <summary>Details</summary>
Motivation: 现有的评估做法存在不足之处，基准测试通常包括可以直接使用知识图中现有三元组回答的问题，使得模型是否进行推理还是直接检索答案变得不明确。此外，评估指标不一致和宽松的答案匹配标准进一步模糊了有意义的比较。

Method: 介绍了一种构建基准测试的通用方法和评估协议，系统评估了知识图检索增强生成方法在知识不完整情况下的表现。

Result: 我们的实证结果表明，目前的知识图检索增强生成方法在缺失知识的情况下具有有限的推理能力，常常依赖内部记忆，并且根据设计的不同展现出不同程度的泛化能力。

Conclusion: 当前的知识图检索增强生成方法在知识不完整情况下具有有限的推理能力，常常依赖内部记忆，并且根据设计的不同存在不同程度的泛化能力。

Abstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an
increasingly explored approach for combining the reasoning capabilities of
large language models with the structured evidence of knowledge graphs.
However, current evaluation practices fall short: existing benchmarks often
include questions that can be directly answered using existing triples in KG,
making it unclear whether models perform reasoning or simply retrieve answers
directly. Moreover, inconsistent evaluation metrics and lenient answer matching
criteria further obscure meaningful comparisons. In this work, we introduce a
general method for constructing benchmarks, together with an evaluation
protocol, to systematically assess KG-RAG methods under knowledge
incompleteness. Our empirical results show that current KG-RAG methods have
limited reasoning ability under missing knowledge, often rely on internal
memorization, and exhibit varying degrees of generalization depending on their
design.

</details>


### [7] [UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games](https://arxiv.org/abs/2508.08382)
*Timo Bertram*

Main category: cs.AI

TL;DR: 本研究介绍了UrzaGPT，使用LLM在魔术风云中推荐实时选秀决策。经过微调，UrzaGPT表现优于其他模型，并展示了仅使用LLMs进行选秀的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于当前AI模型在CCG任务（如套牌构建和游戏玩法）中表现远远不及人类玩家，本研究旨在解决这一问题。通过使用UrzaGPT和LLM，探讨了仅使用LLMs进行选秀是否可行。

Method: 采用UrzaGPT，基于开放权重的LLM，并利用对注释选秀记录数据集进行低秩适应微调。对UrzaGPT与零-shot LLMs以及最先进的领域特定模型进行了基准测试。通过UrzaGPT微调较小模型，在仅进行了10,000步的情况下实现了66.2%的准确率。

Result: UrzaGPT在实时选秀中表现优于零-shot LLMs和领域特定模型。微调较小模型后，准确率达到了66.2%，展示了仅使用LLMs进行选秀的潜力。

Conclusion: 本研究使用UrzaGPT，在魔术风云中提供实时卡牌选秀决策推荐。通过对注释的选秀记录数据集进行低秩调整微调，我们超越了零-shot LLM以及最先进的领域特定模型。尽管未调整的较小LLMs无法进行选秀，但更大的GPT-4o达到了43%的零-shot性能。使用UrzaGPT微调较小模型，仅进行了10,000步，就实现了66.2%的准确率。虽然尚未达到领域特定模型的能力，但我们表明仅使用LLMs进行选秀是可能的，并且得出结论称使用LLMs可以在未来实现性能良好、通用且易于更新的选秀AI。

Abstract: Collectible card games (CCGs) are a difficult genre for AI due to their
partial observability, long-term decision-making, and evolving card sets. Due
to this, current AI models perform vastly worse than human players at CCG tasks
such as deckbuilding and gameplay. In this work, we introduce UrzaGPT, a
domain-adapted large language model that recommends real-time drafting
decisions in Magic: The Gathering. Starting from an open-weight LLM, we use
Low-Rank Adaptation fine-tuning on a dataset of annotated draft logs. With
this, we leverage the language modeling capabilities of LLM, and can quickly
adapt to different expansions of the game. We benchmark UrzaGPT in comparison
to zero-shot LLMs and the state-of-the-art domain-specific model. Untuned,
small LLMs like Llama-3-8B are completely unable to draft, but the larger
GPT-4o achieves a zero-shot performance of 43%. Using UrzaGPT to fine-tune
smaller models, we achieve an accuracy of 66.2% using only 10,000 steps.
Despite this not reaching the capability of domain-specific models, we show
that solely using LLMs to draft is possible and conclude that using LLMs can
enable performant, general, and update-friendly drafting AIs in the future.

</details>


### [8] [Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning](https://arxiv.org/abs/2508.08385)
*Masataro Asai*

Main category: cs.AI

TL;DR: 该论文提出了一种高效的多臂赌博机（MAB）基于蒙特卡洛树搜索（MCTS）的经典规划实现方法。通过双层修改MCTS和树的折叠方法，提高了节点选择性能并进一步优化了性能。


<details>
  <summary>Details</summary>
Motivation: MCTS在决定扩展哪个节点时花费了大量时间，特别是在经典规划中，节点搜索深度可能非常大，导致节点选择的运行时间显著。为了改善这一瓶颈，提出了双层修改MCTS的方法，并引入了树的折叠来进一步提高性能。

Method: 提出了一种双层修改MCTS的方法，运行一个从每个选定的叶节点开始的最佳优先搜索，以改善节点选择的性能瓶颈，并实现摊销O（1）运行时间。同时引入了树的折叠方法来减少动作选择步骤。

Result: 通过提出的双层修改MCTS方法和树的折叠方法，实现了对节点选择的摊销O（1）运行时间，并进一步提高了性能。

Conclusion: 提出了一种高效的多臂赌博机（MAB）基于蒙特卡洛树搜索（MCTS）的经典规划实现方法。通过引入双层修改MCTS，从每个选定的叶节点运行一个从未展开节点开始的最佳优先搜索，从而实现了对节点选择的摊销O（1）运行时间。此外，引入了树的折叠（Tree Collapsing）方法，减少了动作选择步骤并进一步提高了性能。

Abstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based
Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is
that it spends a significant time deciding which node to expand next. While
selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity
with traditional array-based priority-queues for dense integer keys, the
tree-based OPEN list used by MCTS requires $O(\log N)$, which roughly
corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily
large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node
selection is significant, unlike in game tree search, where the cost is
negligible compared to the node evaluation (rollouts) because $d$ is inherently
limited by the game (e.g., $d\leq 361$ in Go). To improve this bottleneck, we
propose a bilevel modification to MCTS that runs a best-first search from each
selected leaf node with an expansion budget proportional to $d$, which achieves
amortized $O(1)$ runtime for node selection, equivalent to the traditional
queue-based OPEN list. In addition, we introduce Tree Collapsing, an
enhancement that reduces action selection steps and further improves the
performance.

</details>


### [9] [Solver-Aided Expansion of Loops to Avoid Generate-and-Test](https://arxiv.org/abs/2508.08442)
*Niklas Dewally,Özgür Akgün*

Main category: cs.AI

TL;DR: 本文提出了一种新方法来改善约束建模语言的编译效率，避免完全枚举循环，通过使用求解器计算仅生成最终约束集所需组合，加快编译速度，同时保持生成的模型与传统方法相同。


<details>
  <summary>Details</summary>
Motivation: 标准方法在编译过程中生成所有归纳变量的组合，然后利用部分求值来丢弃简化为结合-交换操作符的幺元（例如，并集为真，求和为0）的组合，但这在对于大部分组合最终不相关的问题上效率较低。因此，本研究旨在提高将高级用户模型转化为求解器准备形式的效率。

Method: 本文采用了一种避免完全枚举循环的方法，通过使用求解器计算仅生成最终约束集所需组合的方法来改进约束建模语言的编译效率。

Result: 通过所提出的方法，生成的模型与传统展平方法产生的模型相同，但编译速度明显更快。特别适用于归纳变量范围广泛且具有选择性前提条件的问题。

Conclusion: 本文提出了一种新方法，通过使用求解器计算生成最终约束集所需的组合，避免了完全枚举的过程，从而提高了约束建模语言编译的效率。

Abstract: Constraint modelling languages like MiniZinc and Essence rely on unrolling
loops (in the form of quantified expressions and comprehensions) during
compilation. Standard approaches generate all combinations of induction
variables and use partial evaluation to discard those that simplify to identity
elements of associative-commutative operators (e.g. true for conjunction, 0 for
summation). This can be inefficient for problems where most combinations are
ultimately irrelevant. We present a method that avoids full enumeration by
using a solver to compute only the combinations required to generate the final
set of constraints. The resulting model is identical to that produced by
conventional flattening, but compilation can be significantly faster. This
improves the efficiency of translating high-level user models into solver-ready
form, particularly when induction variables range over large domains with
selective preconditions.

</details>


### [10] [OverFill: Two-Stage Models for Efficient Language Model Decoding](https://arxiv.org/abs/2508.08446)
*Woojeong Kim,Junxiong Wang,Jing Nathan Yan,Mohamed Abdelfattah,Alexander M. Rush*

Main category: cs.AI

TL;DR: OverFill proposes a model that separates prefill and decode stages in LLM inference, improving accuracy and efficiency tradeoffs. It outperforms pruned models in generation quality and performance and matches same-sized models trained from scratch while using less training data.


<details>
  <summary>Details</summary>
Motivation: LLMs face deployment challenges due to high inference costs, particularly in the decode stage for long sequences. Current decoder-only models treat prefill and decode stages uniformly, despite their distinct computational profiles.

Method: The proposed OverFill model starts with a full model for prefill, processes system and user inputs in parallel, and then switches to a dense pruned model for generating tokens sequentially. It leverages more compute during prefill to improve generation quality with minimal latency overhead.

Result: The 3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, and the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average across standard benchmarks. OverFill matches the performance of same-sized models trained from scratch while using significantly less training data.

Conclusion: OverFill decouples the prefill and decode stages in LLM inference, optimizing accuracy and efficiency tradeoffs. It significantly outperforms pruned models in terms of generation quality and performance across benchmarks.

Abstract: Large language models (LLMs) excel across diverse tasks but face significant
deployment challenges due to high inference costs. LLM inference comprises
prefill (compute-bound) and decode (memory-bound) stages, with decode
dominating latency particularly for long sequences. Current decoder-only models
handle both stages uniformly, despite their distinct computational profiles. We
propose OverFill, which decouples these stages to optimize accuracy-efficiency
tradeoffs. OverFill begins with a full model for prefill, processing system and
user inputs in parallel. It then switches to a dense pruned model, while
generating tokens sequentially. Leveraging more compute during prefill,
OverFill improves generation quality with minimal latency overhead. Our
3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, while
the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average
across standard benchmarks. OverFill matches the performance of same-sized
models trained from scratch, while using significantly less training data. Our
code is available at https://github.com/friendshipkim/overfill.

</details>


### [11] [A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search](https://arxiv.org/abs/2508.08477)
*Joan Salvà Soler,Grégoire de Lambertye*

Main category: cs.AI

TL;DR: 该论文介绍了一种解决触发弧旅行商问题(TA-TSP)的方法，包括基于GRASP元启发式的算法和多种启发式算法组合。在实验中取得了不错的结果，在MESS 2024比赛中名列前茅，适用于实时路由应用中的状态相关旅行成本。


<details>
  <summary>Details</summary>
Motivation: 该论文提出TA-TSP解决方案的动机是为了模拟仓库操作中的可压缩存储系统等场景，提出了一种适用于具有状态相关旅行成本的实时路由应用的解决方法。

Method: 该论文介绍了一种基于GRASP元启发式的方法，结合多个构造启发式算法和多邻域局部搜索来解决TA-TSP问题。构造阶段使用混合整数规划(MIP)技术将TA-TSP转化为一系列定制的TSP实例，改进阶段采用2-Opt、Swap和Relocate操作符。

Result: 在实验中，该方法在MESS 2024比赛数据集上平均优化间隙为0.77%和0.40%，并在60秒内与已知最佳解决方案相比取得了不错的结果。在较小的合成数据集上，该方法在相同时间限制下比Gurobi求解器的解决方案好了11.3%。

Conclusion: 该论文提出了基于GRASP元启发式的方法来解决触发弧旅行商问题(TA-TSP)，在实验中取得了不错的优化结果，并在MESS 2024比赛中取得了前三名的成绩，展示了该算法在实时路由应用中的适用性。

Abstract: The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP
by introducing dynamic arc costs that change when specific \textit{trigger}
arcs are traversed, modeling scenarios such as warehouse operations with
compactable storage systems. This paper introduces a GRASP-based metaheuristic
that combines multiple construction heuristics with a multi-neighborhood local
search. The construction phase uses mixed-integer programming (MIP) techniques
to transform the TA-TSP into a sequence of tailored TSP instances, while the
improvement phase applies 2-Opt, Swap, and Relocate operators. Computational
experiments on MESS 2024 competition instances achieved average optimality gaps
of 0.77\% and 0.40\% relative to the best-known solutions within a 60-second
limit. On smaller, synthetically generated datasets, the method produced
solutions 11.3\% better than the Gurobi solver under the same time constraints.
The algorithm finished in the top three at MESS 2024, demonstrating its
suitability for real-time routing applications with state-dependent travel
costs.

</details>


### [12] [Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback](https://arxiv.org/abs/2508.08486)
*Parker Whitfill,Stewy Slocum*

Main category: cs.AI

TL;DR: 本文探讨了LLMs的对齐技术，指出了仅仅依赖于序数比较无法有效恢复首选模型的不足，并提出了通过引入对响应质量的基数反馈来收集数据的方法。作者证明了这种方法的有效性，并通过实证研究验证了其优于仅使用序数比较的方法的效果。


<details>
  <summary>Details</summary>
Motivation: 最近的工作集中在改善标签质量或减轻特定偏见，但作者认为存在更根本的限制：这些方法收集了错误类型的数据。作者的动机在于解决这一问题，引入了基于对响应质量的基数反馈的方法，以优化模型选择过程。

Method: 作者证明了仅依赖于序数比较无法系统地恢复首选模型这一不可能结果，提出了一种基于对响应质量的基数反馈的模型选择方法。为了解决这一问题，作者收集并公开发布了一个愿意支付调查数据集，采用实验经济学中广泛应用的工具。同时，作者还进行了实证研究，发现将基数反馈纳入偏好微调能够使模型在下游基准测试中表现优异。

Result: 作者证明了依赖于序数比较无法恢复首选模型，并提出了一个基于基数反馈的模型选择方法。通过实证研究，作者发现引入基数反馈可以改善模型在下游基准测试中的表现。

Conclusion: 通过引入基于助手的 QED 评估方法，文章揭示了仅仅依赖于序数比较的算法无法系统地恢复首选模型，证明了这种方法收集了错误类型的数据。研究表明，选择最佳模型需要根据响应质量的基数反馈来恢复对模型的偏好。作者通过收集 25,000 个愿意支付评估的基数判断数据集，实证表明将基数反馈纳入偏好微调能够使模型优先考虑高影响改进，并在下游基准测试中胜过仅使用序数的方法。

Abstract: Alignment techniques for LLMs rely on optimizing preference-based objectives
-- where these preferences are typically elicited as ordinal, binary choices
between responses. Recent work has focused on improving label quality or
mitigating particular biases, but we identify a more fundamental limitation:
these methods collect the wrong kind of data. We prove an impossibility result:
no algorithm relying solely on ordinal comparisons can systematically recover
the most preferred model. Intuitively, ordinal data lacks the information
needed to resolve tradeoffs -- e.g., fixing a factual error on one prompt
versus improving style on another. We show that selecting the optimal model
requires recovering preferences over \emph{models} (rather than just
responses), which can only be identified given cardinal feedback about response
quality. To address this, we collect and publicly release a dataset of 25,000
cardinal judgments using willingness-to-pay elicitations, a well-established
tool from experimental economics. Empirically, we find that incorporating
cardinal feedback into preference fine-tuning allows models to prioritize
high-impact improvements and outperform ordinal-only methods on downstream
benchmarks, such as Arena-Hard.

</details>


### [13] [POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08493)
*Szymon Jakubicz,Karol Kuźniak,Jan Wawszczak,Paweł Gora*

Main category: cs.AI

TL;DR: 最近，强化学习方法在解决组合性问题中表现出潜力。本文改进了 POMO 模型，创建了 POMO+ 方法，在车辆路径问题的解决中取得更好结果。通过实验证明，我们的方法在 CVRPLIB 数据集上取得改进，展望未来研究带来更多进展。


<details>
  <summary>Details</summary>
Motivation: 最近，强化学习 (RL) 方法在解决组合性问题方面显示出了潜力。POMO 在多项任务上表现出色，但仍有改进空间。

Method: 我们改进了 POMO 模型，创建了 POMO+ 方法，利用初始节点更明智地找到解决方案。在新模型上进行了实验，观察到我们的解决方案收敛更快，并取得更好的结果。

Result: 我们观察到新方法 POMO+ 在车辆路径问题的解决中取得了更好的结果，实验显示收敛速度更快。在 CVRPLIB 数据集上的验证表明，在最多 100 个客户的问题实例中有所改进。

Conclusion: 通过本项目，我们改进了 POMO 模型，创建了一个名为 POMO+ 的方法，在解决车辆路径问题方面取得了更好的结果。我们的研究在 CVRPLIB 数据集上进行验证，在最多 100 个客户的问题实例中实现了改进。我们希望这项研究能在该领域带来进一步的发展。

Abstract: In recent years, reinforcement learning (RL) methods have emerged as a
promising approach for solving combinatorial problems. Among RL-based models,
POMO has demonstrated strong performance on a variety of tasks, including
variants of the Vehicle Routing Problem (VRP). However, there is room for
improvement for these tasks. In this work, we improved POMO, creating a method
(\textbf{POMO+}) that leverages the initial nodes to find a solution in a more
informed way. We ran experiments on our new model and observed that our
solution converges faster and achieves better results. We validated our models
on the CVRPLIB dataset and noticed improvements in problem instances with up to
100 customers. We hope that our research in this project can lead to further
advancements in the field.

</details>


### [14] [Large Language Models as Oracles for Ontology Alignment](https://arxiv.org/abs/2508.08500)
*Sviatoslav Lushnei,Dmytro Shumskyi,Severyn Shykula,Ernesto Jimenez-Ruiz,Artur d'Avila Garcez*

Main category: cs.AI

TL;DR: 本文研究了在本体对齐中使用大型语言模型（LLM）代替领域专家的可行性。结果表明LLM在验证不确定性较高的本体对齐方面具有潜在优势。通过对OAEI的多个匹配任务进行评估，分析了不同LLM的性能，并与模拟Oracle进行了比较。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探索在本体对齐中使用LLM的可行性，以减少对大型本体进行对齐时人工参与造成的昂贵成本。作者认为使用LLM只在系统不确定性较高的相互对应子集验证阶段，可以提高效率和降低成本。

Method: 作者在研究中使用了大型语言模型（LLM）作为领域专家的替代方案，重点验证在本体对齐过程中系统不确定的相互对应子集。作者对Ontology Alignment Evaluation Initiative（OAEI）的多个匹配任务进行了广泛评估，分析了几种最先进的LLM的性能，并使用了不同的本体驱动提示模板。同时，还通过与具有可变错误率的模拟Oracle进行比较，评估了LLM的效果。

Result: 通过研究发现，使用大型语言模型（LLM）在验证本体对齐系统不确定性较高的相互对应子集方面具有潜在优势。作者通过对OAEI的多个匹配任务进行广泛评估，分析了几种最先进的LLM的性能，并与具有可变错误率的模拟Oracle进行了比较。

Conclusion: 本文探讨了在本体对齐过程中使用大型语言模型（LLM）作为领域专家的替代方案的可行性。研究表明，LLM在验证本体对齐系统不确定性较高的相互对应子集方面具有潜在优势。通过对本体对齐评估倡议（OAEI）的多个匹配任务进行广泛评估，本文分析了几种最先进的LLM的性能，并使用不同本体驱动的提示模板。同时，LLM结果还与具有可变错误率的模拟Oracle进行了比较。

Abstract: Ontology alignment plays a crucial role in integrating diverse data sources
across domains. There is a large plethora of systems that tackle the ontology
alignment problem, yet challenges persist in producing highly quality
correspondences among a set of input ontologies. Human-in-the-loop during the
alignment process is essential in applications requiring very accurate
mappings. User involvement is, however, expensive when dealing with large
ontologies. In this paper, we explore the feasibility of using Large Language
Models (LLM) as an alternative to the domain expert. The use of the LLM focuses
only on the validation of the subset of correspondences where an ontology
alignment system is very uncertain. We have conducted an extensive evaluation
over several matching tasks of the Ontology Alignment Evaluation Initiative
(OAEI), analysing the performance of several state-of-the-art LLMs using
different ontology-driven prompt templates. The LLM results are also compared
against simulated Oracles with variable error rates.

</details>


### [15] [GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games](https://arxiv.org/abs/2508.08501)
*Yuchen Li,Cong Lin,Muhammad Umair Nasir,Philip Bontrager,Jialin Liu,Julian Togelius*

Main category: cs.AI

TL;DR: GVGAI-LLM is a video game benchmark that exposes limitations of LLMs in spatial reasoning and basic planning. It offers a diverse collection of arcade-style games with interpretable metrics to assess model behavior. Current models demonstrate spatial and logical errors, prompting the need for structured prompting and spatial grounding techniques. Despite some improvements, the benchmark remains unsolved, providing a testbed for advancing research on language model capabilities.


<details>
  <summary>Details</summary>
Motivation: The motivation behind GVGAI-LLM is to provide a benchmark that challenges LLMs in handling tasks different from existing benchmarks. Current models show consistent spatial and logical errors, highlighting the need for structured prompting and spatial grounding techniques to improve performance.

Method: The benchmark is built on the General Video Game AI framework and includes a diverse collection of arcade-style games. It leverages a game description language for rapid creation of new games and levels, preventing overfitting over time. Each game scene is represented in ASCII characters for efficient processing by language models. Interpretable metrics like the meaningful step ratio, step efficiency, and overall score are defined to assess model behavior.

Result: Zero-shot evaluations across a broad set of games and levels with diverse challenges indicate persistent limitations of LLMs in spatial reasoning and basic planning. Interventions such as structured prompting and spatial grounding techniques lead to partial improvements but the benchmark remains unsolved. GVGAI-LLM serves as a reproducible testbed for advancing research on language model capabilities, especially in agentic behavior and contextual reasoning.

Conclusion: GVGAI-LLM is introduced as a video game benchmark to evaluate the reasoning and problem-solving capabilities of large language models (LLMs). The benchmark reveals persistent limitations of LLMs in spatial reasoning and basic planning, motivating further research on structured prompting and spatial grounding techniques.

Abstract: We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning
and problem-solving capabilities of large language models (LLMs). Built on the
General Video Game AI framework, it features a diverse collection of
arcade-style games designed to test a model's ability to handle tasks that
differ from most existing LLM benchmarks. The benchmark leverages a game
description language that enables rapid creation of new games and levels,
helping to prevent overfitting over time. Each game scene is represented by a
compact set of ASCII characters, allowing for efficient processing by language
models. GVGAI-LLM defines interpretable metrics, including the meaningful step
ratio, step efficiency, and overall score, to assess model behavior. Through
zero-shot evaluations across a broad set of games and levels with diverse
challenges and skill depth, we reveal persistent limitations of LLMs in spatial
reasoning and basic planning. Current models consistently exhibit spatial and
logical errors, motivating structured prompting and spatial grounding
techniques. While these interventions lead to partial improvements, the
benchmark remains very far from solved. GVGAI-LLM provides a reproducible
testbed for advancing research on language model capabilities, with a
particular emphasis on agentic behavior and contextual reasoning.

</details>


### [16] [SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering](https://arxiv.org/abs/2508.08529)
*Arshia Ilaty,Hossein Shirazi,Hajar Homayouni*

Main category: cs.AI

TL;DR: The paper introduces SynLLM, a framework using 20 LLMs to generate synthetic medical tabular data with structured prompts. Evaluation across three datasets shows the impact of prompt engineering on data quality and privacy. Rule-based prompts achieve the best balance. LLMs, when guided by well-designed prompts, can generate clinically plausible and privacy-aware synthetic data for safer healthcare research.


<details>
  <summary>Details</summary>
Motivation: Access to real-world medical data is restricted due to privacy regulations, hindering healthcare research. Synthetic data is a promising alternative, but realistic and privacy-conscious data generation is challenging. Existing approaches lack systematic prompting strategies and comprehensive evaluation frameworks.

Method: The paper presents SynLLM, a modular framework utilizing 20 state-of-the-art open-source LLMs to generate synthetic medical tabular data. It proposes four prompt types to control data generation without fine-tuning and features a rigorous evaluation pipeline assessing data quality across statistical fidelity, clinical consistency, and privacy preservation.

Result: The evaluation of SynLLM across three public medical datasets (Diabetes, Cirrhosis, and Stroke) using 20 LLMs shows that prompt engineering significantly impacts data quality and privacy risk. Rule-based prompts achieve the best privacy-quality balance, demonstrating that LLMs guided by well-designed prompts can generate clinically plausible and privacy-aware synthetic medical data.

Conclusion: LLMs can generate high-quality synthetic medical tabular data when guided by structured prompts and evaluated with comprehensive evaluation frameworks, contributing to safer and more effective data sharing in healthcare research.

Abstract: Access to real-world medical data is often restricted due to privacy
regulations, posing a significant barrier to the advancement of healthcare
research. Synthetic data offers a promising alternative; however, generating
realistic, clinically valid, and privacy-conscious records remains a major
challenge. Recent advancements in Large Language Models (LLMs) offer new
opportunities for structured data generation; however, existing approaches
frequently lack systematic prompting strategies and comprehensive,
multi-dimensional evaluation frameworks.
  In this paper, we present SynLLM, a modular framework for generating
high-quality synthetic medical tabular data using 20 state-of-the-art
open-source LLMs, including LLaMA, Mistral, and GPT variants, guided by
structured prompts. We propose four distinct prompt types, ranging from
example-driven to rule-based constraints, that encode schema, metadata, and
domain knowledge to control generation without model fine-tuning. Our framework
features a comprehensive evaluation pipeline that rigorously assesses generated
data across statistical fidelity, clinical consistency, and privacy
preservation.
  We evaluate SynLLM across three public medical datasets, including Diabetes,
Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt
engineering significantly impacts data quality and privacy risk, with
rule-based prompts achieving the best privacy-quality balance. SynLLM
establishes that, when guided by well-designed prompts and evaluated with
robust, multi-metric criteria, LLMs can generate synthetic medical data that is
both clinically plausible and privacy-aware, paving the way for safer and more
effective data sharing in healthcare research.

</details>


### [17] [UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss](https://arxiv.org/abs/2508.08615)
*Zhichao Wang,Xinhai Chen,Qinglin Wang,Xiang Gao,Qingyang Zhang,Menghan Jia,Xiang Zhang,Jie Liu*

Main category: cs.AI

TL;DR: 本论文介绍了一种无监督和可泛化的网格移动网络UGM2N，通过局部几何特征学习实现无监督网格适应，引入物理约束损失函数M-Uniform loss实现网格等距分布，实现了与现有方法相比一致的卓越性能，包括在不同PDEs和网格几何情况下的鲁棒性表现，能够扩展到多尺度分辨率且无需担心网格缠结问题，并保证错误的减少。


<details>
  <summary>Details</summary>
Motivation: 传统的网格移动技术存在计算复杂性高和几何不灵活性的问题，现有的基于监督学习的方法在跨不同PDEs和网格拓扑的零样本泛化方面面临挑战，本研究旨在解决这些问题。

Method: 通过局部几何特征学习实现无监督网格适应，引入物理约束损失函数M-Uniform loss实现网格等距分布，并构建了无监督和可泛化的网格移动网络UGM2N。

Result: 实验结果表明提出的网络在高效网格适应方面表现出方程不可知的泛化能力和几何独立性，具有比现有方法更优越的性能，包括在不同PDEs和网格几何情况下的鲁棒性表现，并且能够扩展到多尺度分辨率，保证减少错误且无需担心网格缠结。

Conclusion: 提出了一种无监督和可泛化的网格移动网络（UGM2N），通过局部几何特征学习实现无监督网格适应，引入一种物理约束损失函数（M-Uniform loss）强制在节点级别实现网格等距分布，实现了与现有方法相比一致的卓越性能，包括在不同PDEs和网格几何情况下的鲁棒性表现，能够扩展到多尺度分辨率且无需担心网格缠结问题，并保证错误的减少。

Abstract: Partial differential equations (PDEs) form the mathematical foundation for
modeling physical systems in science and engineering, where numerical solutions
demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address
this challenge by dynamically relocating mesh nodes to rapidly-varying regions,
enhancing both simulation accuracy and computational efficiency. However,
traditional approaches suffer from high computational complexity and geometric
inflexibility, limiting their applicability, and existing supervised
learning-based approaches face challenges in zero-shot generalization across
diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and
Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised
mesh adaptation through localized geometric feature learning, eliminating the
dependency on pre-adapted meshes. We then develop a physics-constrained loss
function, M-Uniform loss, that enforces mesh equidistribution at the nodal
level.Experimental results demonstrate that the proposed network exhibits
equation-agnostic generalization and geometric independence in efficient mesh
adaptation. It demonstrates consistent superiority over existing methods,
including robust performance across diverse PDEs and mesh geometries,
scalability to multi-scale resolutions and guaranteed error reduction without
mesh tangling.

</details>


### [18] [AgriGPT: a Large Language Model Ecosystem for Agriculture](https://arxiv.org/abs/2508.08632)
*Bo Yang,Yu Zhang,Lanfei Feng,Yunkui Chen,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Yurui Li,Yuxuan Chen,Guijun Yang,Yong He,Runhe Huang,Shijian Li*

Main category: cs.AI

TL;DR: AgriGPT is a specialized LLM ecosystem for agriculture, offering a high-quality QA dataset (Agri-342K) and utilizing Tri-RAG framework for reliable reasoning. It introduces AgriBench-13K for evaluation and outperforms general-purpose LLMs in domain adaptation and reasoning tasks. The framework is modular, extensible, and aims to empower agricultural communities.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the limitations of applying Large Language Models in agriculture by creating a domain-specialized ecosystem. The paper aims to provide structured data, reliable reasoning, and evaluation frameworks tailored for agricultural stakeholders, practitioners, and policy-makers.

Method: The paper proposes AgriGPT, which includes Agri-342K, a high-quality QA dataset compiled from credible data sources. It utilizes Tri-RAG framework for factual grounding, combining dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning. The paper also introduces AgriBench-13K, a benchmark suite for comprehensive evaluation of AgriGPT.

Result: Experiments show that AgriGPT outperforms general-purpose LLMs in domain adaptation and reasoning tasks. The framework is modular, extensible, and aims to empower agricultural communities by releasing models, datasets, and code for open research.

Conclusion: AgriGPT is a domain-specialized LLM ecosystem designed for agricultural usage, addressing the lack of domain-specific models, datasets, and evaluation frameworks in agriculture. It outperforms general-purpose LLMs in domain adaptation and reasoning, offering benefits to agricultural stakeholders and underserved regions.

Abstract: Despite the rapid progress of Large Language Models (LLMs), their application
in agriculture remains limited due to the lack of domain-specific models,
curated datasets, and robust evaluation frameworks. To address these
challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for
agricultural usage. At its core, we design a multi-agent scalable data engine
that systematically compiles credible data sources into Agri-342K, a
high-quality, standardized question-answer (QA) dataset. Trained on this
dataset, AgriGPT supports a broad range of agricultural stakeholders, from
practitioners to policy-makers. To enhance factual grounding, we employ
Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining
dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning,
thereby improving the LLM's reasoning reliability. For comprehensive
evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks
with varying types and complexities. Experiments demonstrate that AgriGPT
significantly outperforms general-purpose LLMs on both domain adaptation and
reasoning. Beyond the model itself, AgriGPT represents a modular and extensible
LLM ecosystem for agriculture, comprising structured data construction,
retrieval-enhanced generation, and domain-specific evaluation. This work
provides a generalizable framework for developing scientific and
industry-specialized LLMs. All models, datasets, and code will be released to
empower agricultural communities, especially in underserved regions, and to
promote open, impactful research.

</details>


### [19] [Diminution: On Reducing the Size of Grounding ASP Programs](https://arxiv.org/abs/2508.08633)
*HuanYu Yang,Fengming Zhu,YangFan Wu,Jianmin Ji*

Main category: cs.AI

TL;DR: 本研究介绍了 diminution 概念，定义为 Herbrand universe 的选定子集，用于生成减少的导出程序。通过特定的编码方案，整合现有 grounders，大幅提高 ASP 的性能，减少导出时间和文件大小。在基准测试中取得了显著的性能改进，证明 diminutions 是缓解 ASP 导出瓶颈的有效方法。


<details>
  <summary>Details</summary>
Motivation: 大的 Herbrand universes 会生成巨大的导出程序，导致求解困难，许多方法使用 ad-hoc 启发式改善导出性能，因此需要一种更正式和通用的策略。因此，本研究引入 diminution 概念，旨在提高 ASP 的性能并解决导出瓶颈问题。

Method: 引入 diminution 概念，定义其为 Herbrand universe 的选定子集，用于在求解之前生成减少的导出程序。提出一个具体的编码方案，使得 ASP 解决器可以评估候选子集。通过领域谓词与现有的 grounders 紧密集成。

Result: 在五个基准测试中，采用本文策略选择的 diminutions 显著改善性能，平均减少导出时间高达70%，导出文件大小最多减少85%。这些结果表明，利用 diminutions 是缓解 ASP 导出瓶颈的稳健且通用的方法。

Conclusion: 引入 diminution 概念能够显著提高 ASP 的性能，平均减少约70%的导出时间和最多减少85%的导出文件大小。该方法通过选择 Herbrand universe 的子集生成减少的导出程序，与现有的 grounders 紧密整合，证明了在 ASP 中缓解导出瓶颈的强大和通用方法。

Abstract: Answer Set Programming (ASP) is often hindered by the grounding bottleneck:
large Herbrand universes generate ground programs so large that solving becomes
difficult. Many methods employ ad-hoc heuristics to improve grounding
performance, motivating the need for a more formal and generalizable strategy.
We introduce the notion of diminution, defined as a selected subset of the
Herbrand universe used to generate a reduced ground program before solving. We
give a formal definition of diminution, analyze its key properties, and study
the complexity of identifying it. We use a specific encoding that enables
off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates
seamlessly with existing grounders via domain predicates. In extensive
experiments on five benchmarks, applying diminutions selected by our strategy
yields significant performance improvements, reducing grounding time by up to
70% on average and decreasing the size of grounding files by up to 85%. These
results demonstrate that leveraging diminutions constitutes a robust and
general-purpose approach for alleviating the grounding bottleneck in ASP.

</details>


### [20] [P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records](https://arxiv.org/abs/2508.08646)
*Naama Kashani,Mira Cohen,Uri Shaham*

Main category: cs.AI

TL;DR: 提出了一种针对电子健康记录（EHR）数据的个性化、在线且成本感知的特征选择框架，旨在支持医生在患者筛查场景下的决策制定。通过在线方式为每个患者获取特征，考虑预算限制和特征变化成本，有效管理稀疏和多模态数据，以确保在多样化医疗环境中的稳健且可扩展的性能。该方法旨在提高诊断信心并优化资源利用。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录的出现改变了医疗保健，但从这些复杂的多模态数据中提取有意义的见解仍然是研究人员面临的重大挑战。传统特征选择方法难以处理EHR数据的稀疏性和异质性，尤其当考虑患者特定变化和临床应用中的特征成本时。因此，为了克服这些挑战，需要提出一种新颖的个性化、在线和成本感知的特征选择框架，专门针对EHR数据。

Method: 提出了个性化、在线和成本感知的特征选择框架，旨在解决传统特征选择方法在处理EHR数据时遇到的稀疏性、异质性以及患者特定变化和临床应用中的特征成本等挑战。该框架采用在线方式为每个患者获取特征，考虑预算限制和特征变化成本，旨在有效管理稀疏和多模态数据，确保在不同医疗环境中的性能稳健和可扩展。

Result: 提出的框架能够有效管理稀疏和多模态数据，实现在多样化医疗环境中的稳健和可扩展性能。该方法主要应用于支持医生在患者筛查场景下的决策制定，通过引导医生在预算限制下逐步获取最具信息量的特征，旨在提高诊断信心并优化资源利用。

Conclusion: 提出了一种针对电子健康记录（EHR）数据的个性化、在线且成本感知的特征选择框架，旨在支持医生在患者筛查场景下的决策制定。该框架通过在线方式为每个患者获取特征，考虑预算限制和特征变化成本，有效管理稀疏和多模态数据，以确保在多样化医疗环境中的稳健且可扩展的性能。通过指导医生在预算限制下逐步获取最具信息量的特征，该方法旨在提高诊断信心并优化资源利用。

Abstract: Electronic Health Records (EHR) have revolutionized healthcare by digitizing
patient data, improving accessibility, and streamlining clinical workflows.
However, extracting meaningful insights from these complex and multimodal
datasets remains a significant challenge for researchers. Traditional feature
selection methods often struggle with the inherent sparsity and heterogeneity
of EHR data, especially when accounting for patient-specific variations and
feature costs in clinical applications. To address these challenges, we propose
a novel personalized, online and cost-aware feature selection framework
tailored specifically for EHR datasets. The features are aquired in an online
fashion for individual patients, incorporating budgetary constraints and
feature variability costs. The framework is designed to effectively manage
sparse and multimodal data, ensuring robust and scalable performance in diverse
healthcare contexts. A primary application of our proposed method is to support
physicians' decision making in patient screening scenarios. By guiding
physicians toward incremental acquisition of the most informative features
within budget constraints, our approach aims to increase diagnostic confidence
while optimizing resource utilization.

</details>


### [21] [Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training](https://arxiv.org/abs/2508.08652)
*Vishakha Lall,Yisi Liu*

Main category: cs.AI

TL;DR: 本研究探讨了一种使用大型语言模型进行基于提示的推理，以评估程序性沟通遵从性的方法。通过海事领域的案例研究，发现提示能够有效进行上下文感知推理，无需任务特定的训练。研究结果表明，这种方法在培训环境中具有实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 在模拟训练中准确评估程序性沟通的遵从性至关重要，尤其是在安全关键领域，遵守遵从性检查表反映了操作能力。研究动机在于探索一种轻量级、可部署的方法，利用开源大型语言模型可以在消费级GPU上高效运行。

Method: 本文提出了Prompt-and-Check方法，通过上下文丰富的提示来评估协议中每个检查项是否已经完成，仅基于转录的口头交流。通过在海事领域进行案例研究，使用LLama 2 7B、LLaMA 3 8B和Mistral 7B等模型在RTX 4070 GPU上本地运行。对每个检查项目，将包含相关转录摘录的提示馈入模型，输出一个遵从性判断。通过分类准确度和一致性评分，评估模型输出与专家注释的真实情况。

Result: 通过海事领域的案例研究，发现利用提示实现了有效的上下文感知推理，而无需任务特定的训练。研究结果突出了LLMs在培训环境中增强总结、绩效反馈和自动化评估的实际效用。

Conclusion: 该论文探讨了一种利用大型语言模型（LLMs）进行基于提示的推理来评估程序性沟通遵从性的方法。研究表明，利用提示能够有效进行上下文感知的推理，而无需特定任务的训练。采用这种方法在培训环境中增强了总结、绩效反馈和自动化评估的实际效用。

Abstract: Accurate evaluation of procedural communication compliance is essential in
simulation-based training, particularly in safety-critical domains where
adherence to compliance checklists reflects operational competence. This paper
explores a lightweight, deployable approach using prompt-based inference with
open-source large language models (LLMs) that can run efficiently on
consumer-grade GPUs. We present Prompt-and-Check, a method that uses
context-rich prompts to evaluate whether each checklist item in a protocol has
been fulfilled, solely based on transcribed verbal exchanges. We perform a case
study in the maritime domain with participants performing an identical
simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and
Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a
prompt incorporating relevant transcript excerpts is fed into the model, which
outputs a compliance judgment. We assess model outputs against expert-annotated
ground truth using classification accuracy and agreement scores. Our findings
demonstrate that prompting enables effective context-aware reasoning without
task-specific training. This study highlights the practical utility of LLMs in
augmenting debriefing, performance feedback, and automated assessment in
training environments.

</details>


### [22] [Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08659)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux,Daniele Vigo*

Main category: cs.AI

TL;DR: 该研究提出了一种迭代学习混合优化求解器，利用节点破坏模型和图神经网络（GNNs）机器学习混合模型，指导大邻域搜索算子，以改进元启发式算法在解决CVRP中的性能。实验证明该混合机制提高了解决质量，展现出可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决容量车辆路径问题（CVRP）中元启发式算法性能不足的问题，降低操作复杂性，缩小优化过程中的搜索空间，提高解决质量并展示可扩展性。

Method: 提出了迭代学习混合优化求解器，整合了节点破坏模型和图神经网络（GNNs）机器学习混合模型，用于指导大邻域搜索（LNS）算子。利用图表示问题和解决方案的结构属性，引导节点移除的战略选择。

Result: 提出的混合机制改进了基线元启发式算法的性能，在标准CVRP基准问题和大规模实例上均取得了积极的实验结果。

Conclusion: 该研究提出了一种迭代学习混合优化求解器，旨在加强元启发式算法在解决容量车辆路径问题（CVRP）中的性能。通过整合提出的节点破坏模型，并利用图神经网络（GNNs）的机器学习混合模型来指导元启发式优化框架中的大邻域搜索（LNS）算子。该模型利用问题和解决方案的结构属性，将其表示为图，以指导有关节点移除的战略选择。提出的方法降低了操作复杂性，并缩小了涉及优化过程中的搜索空间。这种混合方法特定应用于CVRP，并不需要在不同规模的问题实例之间重新训练。所提出的混合机制能够改进基线元启发式算法的性能。我们的方法不仅提高了标准CVRP基准问题的解决质量，还在高达30,000个客户节点的大规模实例上证明了可扩展性。在基准数据集上的实验评估显示，所提出的混合机制能够改进不同基线算法，在类似设置下获得更优质的解决方案。

Abstract: In this research, we propose an iterative learning hybrid optimization solver
developed to strengthen the performance of metaheuristic algorithms in solving
the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism
integrates the proposed Node-Destroyer Model, a machine learning hybrid model
that utilized Graph Neural Networks (GNNs) such identifies and selects customer
nodes to guide the Large Neighborhood Search (LNS) operator within the
metaheuristic optimization frameworks. This model leverages the structural
properties of the problem and solution that can be represented as a graph, to
guide strategic selections concerning node removal. The proposed approach
reduces operational complexity and scales down the search space involved in the
optimization process. The hybrid approach is applied specifically to the CVRP
and does not require retraining across problem instances of different sizes.
The proposed hybrid mechanism is able to improve the performance of baseline
metaheuristic algorithms. Our approach not only enhances the solution quality
for standard CVRP benchmarks but also proves scalability on very large-scale
instances with up to 30,000 customer nodes. Experimental evaluations on
benchmark datasets show that the proposed hybrid mechanism is capable of
improving different baseline algorithms, achieving better quality of solutions
under similar settings.

</details>


### [23] [Aryabhata: An exam-focused language model for JEE Math](https://arxiv.org/abs/2508.08665)
*Ritvik Rastogi,Sachin Dharashivkar,Sandeep Varma*

Main category: cs.AI

TL;DR: Aryabhata 1.0是一个为印度学术考试JEE优化的数学推理模型，通过合并强大的推理模型并采用监督微调和课程学习进行训练。同时应用强化学习方法进一步提高性能，已在基准测试中表现优异，是一个为学生提供更好学习结果的基础模型。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于尽管大型语言模型取得了快速进展，但目前的模型通常不适合教育用途，因此需要开发一个针对印度学术考试JEE进行优化的数学推理模型。

Method: 将强大的开放式推理模型合并，经过监督微调和课程学习，以验证的思维链踪迹进行训练。此外，采用强化学习方法，包括A2C目标和新颖的探索策略，如自适应组大小调整和温度缩放，来进一步提高模型性能。

Result: 在JEE Main 2025和MATH、GSM8K等基准测试中评估，Aryabhata在准确性和效率方面优于现有模型，同时提供教育上有用的逐步推理过程。

Conclusion: Aryabhata 1.0是一个精心优化的数学推理模型，专为印度学术考试（JEE）而设计，在准确性和效率方面胜过现有模型，并提供教育上有用的逐步推理。研究团队将Aryabhata作为基础模型发布，旨在推动以考试为中心的开源小语言模型，为学生学习提供更好的结果。

Abstract: We present Aryabhata 1.0, a compact 7B parameter math reasoning model
optimized for the Indian academic exam, the Joint Entrance Examination (JEE).
Despite rapid progress in large language models (LLMs), current models often
remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong
open-weight reasoning models, followed by supervised fine-tuning (SFT) with
curriculum learning on verified chain-of-thought (CoT) traces curated through
best-of-$n$ rejection sampling. To further boost performance, we apply
reinforcement learning with verifiable rewards (RLVR) using A2C objective with
group-relative advantage estimation along with novel exploration strategies
such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both
in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K)
benchmarks, Aryabhata outperforms existing models in accuracy and efficiency,
while offering pedagogically useful step-by-step reasoning. We release
Aryabhata as a foundation model to advance exam-centric, open-source small
language models. This marks our first open release for community feedback
(https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training
future models to further improve learning outcomes for students.

</details>


### [24] [STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision](https://arxiv.org/abs/2508.08688)
*Chen Li,Han Zhang,Zhantao Yang,Fangyi Chen,Zihan Wang,Anudeepsekhar Bolimera,Marios Savvides*

Main category: cs.AI

TL;DR: STEALR-Vision enhances VLMs with topology-aware reasoning, achieving significant accuracy improvements and efficiency. It outperforms existing models on various datasets, showing strong generalization and consistently better performance compared to Chain-Only training.


<details>
  <summary>Details</summary>
Motivation: Current vision-language models struggle with complex multimodal tasks and tend to generate verbose outputs due to their reliance on chain-of-thought reasoning. Many tasks benefit from alternative topologies like trees or graphs, which are not effectively utilized in existing models.

Method: The paper introduces STEALR-Vision with TopoAug, a synthetic data pipeline to enrich training with diverse topological structures. It uses supervised fine-tuning and reinforcement learning to post-train Qwen2VL models. Frugal Learning technique is proposed to reduce output length with minimal accuracy loss.

Result: STEALR-Vision improves accuracy by 9.7% over its base model and surpasses the larger Qwen2VL-72B-Instruct by 7.3% on MATH-V and VLM-S2H datasets. It outperforms Phi-4-Multimodal-Instruct by up to 28.4% and LLaMA-3.2-11B-Vision-Instruct by up to 13.2% on out-of-distribution benchmarks.

Conclusion: STEALR-Vision introduces a training framework for topology-aware reasoning, improving accuracy and efficiency in VLMs. It outperforms existing models on both in-distribution and out-of-distribution benchmarks, demonstrating strong generalization. The approach achieves higher overall accuracy and consistently outperforms Chain-Only training method.

Abstract: Vision-language models (VLMs) have made significant strides in reasoning, yet
they often struggle with complex multimodal tasks and tend to generate overly
verbose outputs. A key limitation is their reliance on chain-of-thought (CoT)
reasoning, despite many tasks benefiting from alternative topologies like trees
or graphs. To address this, we introduce STELAR-Vision, a training framework
for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline
that enriches training with diverse topological structures. Using supervised
fine-tuning and reinforcement learning, we post-train Qwen2VL models with both
accuracy and efficiency in mind. Additionally, we propose Frugal Learning,
which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H,
STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the
larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it
outperforms Phi-4-Multimodal-Instruct by up to 28.4% and
LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong
generalization. Compared to Chain-Only training, our approach achieves 4.3%
higher overall accuracy on in-distribution datasets and consistently
outperforms across all OOD benchmarks. We have released datasets, and code will
be available.

</details>


### [25] [Simulating Generative Social Agents via Theory-Informed Workflow Design](https://arxiv.org/abs/2508.08726)
*Yuwei Yan,Jinghua Piao,Xiaochong Lan,Chenyang Shao,Pan Hui,Yong Li*

Main category: cs.AI

TL;DR: 最近的大型语言模型为基于代理的社会模拟带来了新机遇。本研究提出了一个基于社会认知理论的框架，包括动机、行动规划和学习模块，使代理能够表现出更灵活和情境适当的行为。实验表明，基于理论的代理在复杂条件下能够重现真实人类行为模式，并比传统生成基线表现更好。去除关键模块会增加错误率，强调了这些模块对生成真实社交行为的重要性。


<details>
  <summary>Details</summary>
Motivation: 最近的大型语言模型取得了强大的推理和角色扮演能力，为基于代理的社会模拟开辟了新的机遇。然而，大多数现有代理的实现是针对特定场景的，缺乏统一的框架来指导设计。缺乏通用的社交代理限制了它们在不同社会背景下的泛化能力和产生一致、真实行为的能力。

Method: 基于社会认知理论提出了三个关键模块：动机、行动规划和学习，共同使代理能够理解其目标、规划连贯的行动，并随时间调整其行为，从而实现更灵活和情境适当的回应。

Result: 实验证明，基于理论的代理在多个忠实度指标上比传统生成基线实现了高达75%的更低偏差。消融研究显示，去除动机、规划或学习模块会增加错误率，验证了它们对生成真实和连贯社交行为的重要性。

Conclusion: 提出了一种基于理论的框架，用于设计LLM社交代理，实现更灵活和符合情境的回应。通过综合实验，证明其在复杂条件下可复现真实的人类行为模式，并与传统生成基线相比，实现了高达75%的更低偏差。消融研究进一步表明，去除动机、规划或学习模块会增加错误率，验证了它们对生成真实和连贯社交行为的独特和必要贡献。

Abstract: Recent advances in large language models have demonstrated strong reasoning
and role-playing capabilities, opening new opportunities for agent-based social
simulations. However, most existing agents' implementations are
scenario-tailored, without a unified framework to guide the design. This lack
of a general social agent limits their ability to generalize across different
social contexts and to produce consistent, realistic behaviors. To address this
challenge, we propose a theory-informed framework that provides a systematic
design process for LLM-based social agents. Our framework is grounded in
principles from Social Cognition Theory and introduces three key modules:
motivation, action planning, and learning. These modules jointly enable agents
to reason about their goals, plan coherent actions, and adapt their behavior
over time, leading to more flexible and contextually appropriate responses.
Comprehensive experiments demonstrate that our theory-driven agents reproduce
realistic human behavior patterns under complex conditions, achieving up to 75%
lower deviation from real-world behavioral data across multiple fidelity
metrics compared to classical generative baselines. Ablation studies further
show that removing motivation, planning, or learning modules increases errors
by 1.5 to 3.2 times, confirming their distinct and essential contributions to
generating realistic and coherent social behaviors.

</details>


### [26] [Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance](https://arxiv.org/abs/2508.08774)
*Dongwook Choi,Taeyoon Kwon,Dongil Yang,Hyojun Kim,Jinyoung Yeo*

Main category: cs.AI

TL;DR: 本文提出了一个记忆增强的增强现实（AR）代理的概念性框架，旨在通过学习和适应用户特定经验，提供个性化任务辅助。框架包括感知模块、记忆模块、时空推理模块和执行器模块。展示了框架的实施路线图、未来评估策略、潜在目标应用和使用案例。致力于推动未来研究，开发更智能的AR系统，可以有效地将用户的交互历史与适应性、上下文感知的任务辅助相结合。


<details>
  <summary>Details</summary>
Motivation: 当前AR代理在支持即时任务方面表现出色，但在处理需要理解和利用用户长期经验和偏好的复杂多步场景时存在困难。这一局限性源自它们无法捕捉、保留和推理历史用户交互的时空语境。为了解决这些挑战，提出了记忆增强的AR代理的概念性框架。

Method: 提出了记忆增强的AR代理的概念性框架，包括感知模块、记忆模块、时空推理模块和执行器模块。展示了实施路线图、未来评估策略、潜在目标应用和使用案例。

Result: 提出的概念性框架为记忆增强的AR代理提供了个性化任务辅助，可以从用户特定经验中学习和适应。展示了框架的实施路线图、未来评估策略、潜在目标应用和使用案例，以展示框架在不同领域的实际适用性。

Conclusion: 提出了一个概念性的框架，用于记忆增强的增强现实（AR）代理，旨在通过学习和适应用户特定经验，提供个性化任务辅助。框架包括四个相互连接的模块：感知模块、记忆模块、时空推理模块和执行器模块。展示了框架的实施路线图、未来评估策略、潜在目标应用和使用案例，以展示框架在不同领域的实际适用性。致力于推动未来研究，开发更智能的AR系统，可以有效地将用户的交互历史与适应性、上下文感知的任务辅助相结合。

Abstract: Augmented Reality (AR) systems are increasingly integrating foundation
models, such as Multimodal Large Language Models (MLLMs), to provide more
context-aware and adaptive user experiences. This integration has led to the
development of AR agents to support intelligent, goal-directed interactions in
real-world environments. While current AR agents effectively support immediate
tasks, they struggle with complex multi-step scenarios that require
understanding and leveraging user's long-term experiences and preferences. This
limitation stems from their inability to capture, retain, and reason over
historical user interactions in spatiotemporal contexts. To address these
challenges, we propose a conceptual framework for memory-augmented AR agents
that can provide personalized task assistance by learning from and adapting to
user-specific experiences over time. Our framework consists of four
interconnected modules: (1) Perception Module for multimodal sensor processing,
(2) Memory Module for persistent spatiotemporal experience storage, (3)
Spatiotemporal Reasoning Module for synthesizing past and present contexts, and
(4) Actuator Module for effective AR communication. We further present an
implementation roadmap, a future evaluation strategy, a potential target
application and use cases to demonstrate the practical applicability of our
framework across diverse domains. We aim for this work to motivate future
research toward developing more intelligent AR systems that can effectively
bridge user's interaction history with adaptive, context-aware task assistance.

</details>


### [27] [A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions](https://arxiv.org/abs/2508.08795)
*Amir Mohammad Salehoof,Ali Ramezani,Yadollah Yaghoobzadeh,Majid Nili Ahmadabadi*

Main category: cs.AI

TL;DR: 大型语言模型从大型文本语料库中获取大量知识，但信息可能变得过时或不准确。重新训练成本高，因此知识编辑是一种有效替代方案。该论文介绍了一种功能性分类方法，探讨了编辑机制与不同类型知识的关系，概述了现有方法的优缺点，并列举了开放挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 原因在于大型语言模型（LLMs）从大型文本语料库中获得了大量知识，但这些信息可能变得过时或不准确。重新训练成本高昂，因此知识编辑提供了一种有效的替代方案，可以在不进行完整重新训练的情况下修改内部知识。

Method: 该论文介绍了一种基于功能的分类方法，探讨了知识编辑的机制与不同类型知识的关系，通过这种方法组织评论和研究现有方法的优缺点。

Result: 通过引入功能性分类法，使得对知识编辑机制与不同类型知识之间关系的探讨更加全面，突出了编辑效果与目标知识性质的依赖关系。

Conclusion: 这篇论文提出了一种基于功能的分类方法，以提供更全面的视角，探讨了知识编辑的机制如何适用于不同类型的知识，强调了编辑效果与目标知识性质的关系。通过沿着这两个轴线组织我们的评论，我们对当前的研究领域进行了梳理，概述了现有方法的优势和局限性，正式定义了问题，调查了评估任务和数据集，并就未来的挑战和发展方向进行了结论。

Abstract: Large language models (LLMs) acquire vast knowledge from large text corpora,
but this information can become outdated or inaccurate. Since retraining is
computationally expensive, knowledge editing offers an efficient alternative --
modifying internal knowledge without full retraining. These methods aim to
update facts precisely while preserving the model's overall capabilities. While
existing surveys focus on the mechanism of editing (e.g., parameter changes vs.
external memory), they often overlook the function of the knowledge being
edited. This survey introduces a novel, complementary function-based taxonomy
to provide a more holistic view. We examine how different mechanisms apply to
various knowledge types -- factual, temporal, conceptual, commonsense, and
social -- highlighting how editing effectiveness depends on the nature of the
target knowledge. By organizing our review along these two axes, we map the
current landscape, outline the strengths and limitations of existing methods,
define the problem formally, survey evaluation tasks and datasets, and conclude
with open challenges and future directions.

</details>


### [28] [GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs](https://arxiv.org/abs/2508.08815)
*Roberto Barile,Claudia d'Amato,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 本文提出了GRainsaCK软件资源，解决了知识图谱链接预测中解释方法评估的问题。GRainsaCK能够统一评估协议，简化解释评估任务，并提高模块化和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱往往不完整，链接预测方法用于预测缺失的事实。尽管大多数采用基于嵌入式的可扩展解决方案，但它们缺乏可理解性，这在许多领域可能至关重要。解释方法通过识别支持知识来解释预测的事实。然而，由于缺乏标准评估协议和整体基准资源，定量评估/比较结果解释具有挑战性。

Method: 本文填补了知识图谱链接预测中解释方法的评估/比较方面的重要空白，提出了GRainsaCK软件资源。该资源能够简化所有涉及解释评估的任务，包括模型训练和解释评估，统一评估协议。此外，GRainsaCK通过实现主要组件为易替换的函数，增强了其模块化和可扩展性。

Result: 提出了GRainsaCK软件资源，能够统一评估协议并简化解释评估任务，提高模块化和可扩展性。

Conclusion: 本文介绍了GRainsaCK，一个可重复使用的软件资源，用于完全简化与解释评估相关的各项任务，从模型训练到解释评估，统一评估协议。通过将主要组件实现为易替换的函数，GRainsaCK进一步提高了模块化和可扩展性。最后，为促进其重复使用，提供了详尽的文档，包括教程。

Abstract: Since Knowledge Graphs are often incomplete, link prediction methods are
adopted for predicting missing facts. Scalable embedding based solutions are
mostly adopted for this purpose, however, they lack comprehensibility, which
may be crucial in several domains. Explanation methods tackle this issue by
identifying supporting knowledge explaining the predicted facts. Regretfully,
evaluating/comparing quantitatively the resulting explanations is challenging
as there is no standard evaluation protocol and overall benchmarking resource.
We fill this important gap by proposing GRainsaCK, a reusable software resource
that fully streamlines all the tasks involved in benchmarking explanations,
i.e., from model training to evaluation of explanations along the same
evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by
implementing the main components as functions that can be easily replaced.
Finally, fostering its reuse, we provide extensive documentation including a
tutorial.

</details>


### [29] [Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation](https://arxiv.org/abs/2508.08816)
*Yuechen Wang,Yuming Qiao,Dan Meng,Jun Yang,Haonan Lu,Zhenyu Yang,Xudong Zhang*

Main category: cs.AI

TL;DR: E-Agent introduces innovative mRAG planning and execution strategies, outperforming existing methods by 13% in accuracy and reducing redundant searches by 37% according to experiments on the RemPlan benchmark.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing multimodal retrieval-augmented generation (mRAG) systems in real-world scenarios like news analysis and trending topics, focusing on overcoming rigid retrieval strategies and under-utilization of visual information.

Method: The paper proposes E-Agent, an agent framework with a mRAG planner and task executor for optimized workflows. It introduces the Real-World mRAG Planning (RemPlan) benchmark to evaluate planning capabilities.

Result: E-Agent outperforms state-of-the-art mRAG methods in experiments across RemPlan and established benchmarks, showcasing its effectiveness.

Conclusion: E-Agent demonstrates superior performance in mRAG systems, achieving a 13% accuracy gain over existing methods and reducing redundant searches by 37%.

Abstract: Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising
solution to address the temporal limitations of Multimodal Large Language
Models (MLLMs) in real-world scenarios like news analysis and trending topics.
However, existing approaches often suffer from rigid retrieval strategies and
under-utilization of visual information. To bridge this gap, we propose
E-Agent, an agent framework featuring two key innovations: a mRAG planner
trained to dynamically orchestrate multimodal tools based on contextual
reasoning, and a task executor employing tool-aware execution sequencing to
implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning
strategy that enables efficient information retrieval while minimizing
redundant tool invocations. To rigorously assess the planning capabilities of
mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark.
This novel benchmark contains both retrieval-dependent and
retrieval-independent question types, systematically annotated with essential
retrieval tools required for each instance. The benchmark's explicit mRAG
planning annotations and diverse question design enhance its practical
relevance by simulating real-world scenarios requiring dynamic mRAG decisions.
Experiments across RemPlan and three established benchmarks demonstrate
E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods
while reducing redundant searches by 37%.

</details>


### [30] [Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition](https://arxiv.org/abs/2508.08830)
*Mustafa Akben,Vinayaka Gude,Haya Ajjan*

Main category: cs.AI

TL;DR: 本研究评估了MLLMs在情绪识别上的表现，发现MLLMs在个体水平上优于人类，但人类团体在集体智慧方面表现更优。结合人类和MLLM预测的协作方法效果最佳，为有效情感人工智能提供了有希望的路径。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）越来越普遍，AI识别和回应人类情绪对有效的人机交互至关重要。然而，MLLMs的情感智能尚未被充分探索。本研究旨在填补这一研究空白，探讨人类和AI协作在情感识别方面的潜力。

Method: 本研究评估了MLLMs在Reading the Mind in the Eyes Test（RMET）及其多元种族对应物（MRMET）上的情绪识别能力，并将其与人类参与者的表现进行了比较。研究采用了聚合独立人类决策以模拟集体智慧的方法，发现人类团体显著超越了聚合MLLM预测的表现。同时，结合人类和MLLM预测的协作方法（增强智能）实现了比单独人类或MLLM更高的准确性。

Result: 研究结果显示，MLLMs平均而言在两项测试中准确识别情绪的能力超过了人类。然而，通过聚合独立人类决策，人类团体在性能上显著超越了聚合MLLM预测。人类和MLLM合作的协作方法实现了比单独人类或MLLM更高的准确性。

Conclusion: 研究发现，虽然多模式大语言模型（MLLMs）在个体水平上具有较强的情绪识别能力，但人类团体的集体智慧和人工智能协作的协同潜力提供了通往有效情感人工智能的最有希望的途径。

Abstract: The ability to discern subtle emotional cues is fundamental to human social
intelligence. As artificial intelligence (AI) becomes increasingly common, AI's
ability to recognize and respond to human emotions is crucial for effective
human-AI interactions. In particular, whether such systems can match or surpass
human experts remains to be seen. However, the emotional intelligence of AI,
particularly multimodal large language models (MLLMs), remains largely
unexplored. This study evaluates the emotion recognition abilities of MLLMs
using the Reading the Mind in the Eyes Test (RMET) and its multiracial
counterpart (MRMET), and compares their performance against human participants.
Results show that, on average, MLLMs outperform humans in accurately
identifying emotions across both tests. This trend persists even when comparing
performance across low, medium, and expert-level performing groups. Yet when we
aggregate independent human decisions to simulate collective intelligence,
human groups significantly surpass the performance of aggregated MLLM
predictions, highlighting the wisdom of the crowd. Moreover, a collaborative
approach (augmented intelligence) that combines human and MLLM predictions
achieves greater accuracy than either humans or MLLMs alone. These results
suggest that while MLLMs exhibit strong emotion recognition at the individual
level, the collective intelligence of humans and the synergistic potential of
human-AI collaboration offer the most promising path toward effective emotional
AI. We discuss the implications of these findings for the development of
emotionally intelligent AI systems and future research directions.

</details>


### [31] [Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation](https://arxiv.org/abs/2508.08882)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.AI

TL;DR: 本文研究了当前工具综合数学推理系统中单一代理和双代理混合框架的性能差异，提出了双代理框架的训练方法，通过减少认知干扰，促进稳定的推理编码协调，提高了系统性能。


<details>
  <summary>Details</summary>
Motivation: 作者观察到当前工具综合数学推理系统在问题推理、代码生成和代码执行方面采用单一代理范式时，存在认知负荷干扰的问题，因此提出了采用双代理混合框架的设计。

Method: 本文通过对比研究证实了单一代理和双代理混合框架的性能差异，提出了采用双代理框架的训练方法，包括模仿学习和强化学习。通过给予代码代理匹配中间真实程序的强奖励和有效执行的弱奖励，以及通过优势估计来评估中间步骤的推理代理，来减少认知干扰。

Result: 通过对比研究发现，双代理混合框架相较于单一代理在正确推理路径的生成方面有显著改进。

Conclusion: 本文说明当前工具综合数学推理系统往往采用单一代理范式，作者提出了双代理混合框架，其中一个推理代理负责问题分解，另一个代码代理负责代码生成和执行。训练结合了模仿学习和强化学习。通过减少认知干扰和促进稳定的推理编码协调，这种分离角色设计提高了系统性能。

Abstract: Current tool-integrated mathematical reasoning systems often adopt a
single-agent paradigm, where one large language model handles problem
reasoning, code generation, and code execution in an integrated workflow. While
this design eases coordination, we hypothesize that it imposes cognitive load
interference, as the agent must interleave long-horizon reasoning with precise
program synthesis. We validate this hypothesis through a controlled comparison
between a reasoning-only agent and a reasoning-plus-code agent, finding that
the latter produces significantly fewer correct reasoning paths despite having
tool-calling capabilities. To address this, we propose a dual-agent hybrid
framework: a Reasoning Agent performs stepwise problem decomposition, and a
Code Agent handles code generation and execution. Training combines imitation
learning and reinforcement learning: the Code Agent receives strong rewards for
matching intermediate ground-truth programs and weaker rewards for valid
execution, while the Reasoning Agent is optimized chiefly via final-answer
accuracy using advantage estimation to credit intermediate steps. This
decoupled role design reduces cognitive interference and promotes stable
reasoning-coding coordination.

</details>


### [32] [Compass-Thinker-7B Technical Report](https://arxiv.org/abs/2508.08909)
*Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang*

Main category: cs.AI

TL;DR: Compass-Thinker-7B model is introduced to explore Reinforcement Learning potential efficiently with reduced resources. It outperforms same-sized RL models in mathematics tasks, achieving 40% accuracy in a challenging evaluation, showcasing exceptional reasoning potential.


<details>
  <summary>Details</summary>
Motivation: Addressed the high computational costs and resource demands of conducting RL experiments on hyperscale models by proposing a model that aims to explore RL capabilities with fewer resources. Provides insights for further research into RL applications for larger models.

Method: Proposed the Compass-Thinker-7B model to explore Reinforcement Learning potential with reduced computational resources and costs, trained from an open-source model using a specially designed Reinforcement Learning Pipeline, and curated a dataset of 30k verifiable mathematics problems for training. Configured data and training settings with varying difficulty distributions to gradually release the model's potential and improve training efficiency.

Result: Extensive evaluations demonstrate that Compass-Thinker-7B possesses exceptional reasoning potential and excels in mathematics tasks, achieving superior performance compared to the same-sized RL model, particularly achieving 40% accuracy in the challenging AIME2024 evaluation.

Conclusion: Compass-Thinker-7B model demonstrates exceptional reasoning potential and outperforms the same-sized RL model in mathematics tasks, achieving 40% accuracy in a challenging evaluation.

Abstract: Recent R1-Zero-like research further demonstrates that reasoning extension
has given large language models (LLMs) unprecedented reasoning capabilities,
and Reinforcement Learning is the core technology to elicit its complex
reasoning. However, conducting RL experiments directly on hyperscale models
involves high computational costs and resource demands, posing significant
risks. We propose the Compass-Thinker-7B model, which aims to explore the
potential of Reinforcement Learning with less computational resources and
costs, and provides insights for further research into RL recipes for larger
models. Compass-Thinker-7B is trained from an open source model through a
specially designed Reinforcement Learning Pipeline. we curate a dataset of 30k
verifiable mathematics problems for the Reinforcement Learning Pipeline. By
configuring data and training settings with different difficulty distributions
for different stages, the potential of the model is gradually released and the
training efficiency is improved. Extensive evaluations show that
Compass-Thinker-7B possesses exceptional reasoning potential, and achieves
superior performance on mathematics compared to the same-sized RL
model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B
achieves 40% accuracy.

</details>


### [33] [Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models](https://arxiv.org/abs/2508.08926)
*Wei Cai,Jian Zhao,Yuchu Jiang,Tianle Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: Large Vision-Language Models are vulnerable to Implicit Reasoning Safety issues that lead to unsafe outputs. The paper introduces Safe Semantics, Unsafe Interpretations dataset and shows the effectiveness of In-Context Learning with SSUI in mitigating these threats.


<details>
  <summary>Details</summary>
Motivation: Address the safety challenges faced by Large Vision-Language Models (LVLMs) with multimodal inputs, specifically focusing on Implicit Reasoning Safety and unsafe outputs triggered by combined inputs.

Method: Developed Safe Semantics, Unsafe Interpretations dataset to showcase Implicit Reasoning Safety in LVLMs. Demonstrated the effectiveness of In-Context Learning with SSUI in mitigating implicit multimodal threats.

Result: Demonstrated the urgent need to enhance cross-modal implicit reasoning in LVLMs through the development of Safe Semantics, Unsafe Interpretations dataset and the implementation of In-Context Learning with SSUI.

Conclusion: LVLMs face safety challenges due to Implicit Reasoning Safety, which can lead to unsafe outputs. In-Context Learning with Safe Semantics and SSUI can mitigate these threats.

Abstract: Large Vision-Language Models face growing safety challenges with multimodal
inputs. This paper introduces the concept of Implicit Reasoning Safety, a
vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due
to flawed or hidden reasoning. To showcase this, we developed Safe Semantics,
Unsafe Interpretations, the first dataset for this critical issue. Our
demonstrations show that even simple In-Context Learning with SSUI
significantly mitigates these implicit multimodal threats, underscoring the
urgent need to improve cross-modal implicit reasoning.

</details>


### [34] [Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty](https://arxiv.org/abs/2508.08992)
*Rui Wang,Qihan Lin,Jiayu Liu,Qing Zong,Tianshi Zheng,Weiqi Wang,Yangqiu Song*

Main category: cs.AI

TL;DR: 研究探讨了前景理论在当代大型语言模型中的应用以及认识标记对它们的决策行为的影响。通过实验和评估框架，发现PT模型在不同语言形式表达不确定性时并不始终可靠。


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未探讨前景理论是否适用于现代大型语言模型，以及表达人类不确定性的认识标记是否影响它们的决策行为。为填补这些研究空白，设计了实验来探究LLMs的决策行为，并引入认识标记来模拟不确定性。

Method: 设计了一个基于经济问卷的三阶段实验，提出了一个更一般和精确的评估框架来模拟LLMs在PT下的决策行为，并通过在可比较上下文中常用的认识标记的经验概率值引入不确定性。然后根据相应的概率值将认识标记纳入评估框架，以检验它们对LLMs决策行为的影响。

Result: 结果表明，在使用不同语言形式表达不确定性的情况下，使用PT模型来解释LLMs的决策行为并不始终可靠。

Conclusion: 研究发现，使用前景理论（PT）模型来解释大型语言模型（LLMs）的决策行为并不始终可靠，特别是在不同语言形式表达的不确定性情况下。

Abstract: Prospect Theory (PT) models human decision-making under uncertainty, while
epistemic markers (e.g., maybe) serve to express uncertainty in language.
However, it remains largely unexplored whether Prospect Theory applies to
contemporary Large Language Models and whether epistemic markers, which express
human uncertainty, affect their decision-making behaviour. To address these
research gaps, we design a three-stage experiment based on economic
questionnaires. We propose a more general and precise evaluation framework to
model LLMs' decision-making behaviour under PT, introducing uncertainty through
the empirical probability values associated with commonly used epistemic
markers in comparable contexts. We then incorporate epistemic markers into the
evaluation framework based on their corresponding probability values to examine
their influence on LLM decision-making behaviours. Our findings suggest that
modelling LLMs' decision-making with PT is not consistently reliable,
particularly when uncertainty is expressed in diverse linguistic forms. Our
code is released in https://github.com/HKUST-KnowComp/MarPT.

</details>


### [35] [Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory](https://arxiv.org/abs/2508.08997)
*Sizhe Yuen,Francisco Gomez Medina,Ting Su,Yali Du,Adam J. Sobey*

Main category: cs.AI

TL;DR: 本文介绍了一种名为内在记忆代理的框架，针对多Agent系统中基于LLMs的挑战提出了解决方案。通过维护角色对齐的记忆模板，专注于任务相关信息，该方法在结构化规划任务上取得了显著改进，并在数据管道设计任务上产生了高质量设计。研究结果表明，内在方法可以提高多Agent LLM系统在结构化任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 动机：多Agent系统在协同解决复杂问题时表现出巨大潜力，但面临上下文窗口限制等挑战。提出这一内在记忆代理框架旨在解决这些挑战，通过结构化的代理特定记忆与Agent输出内在演变，从而改善记忆一致性、角色遵从和程序完整性。

Method: 方法：本文提出的内在记忆代理框架通过 agent-specific 记忆，保留专业视角的对齐记忆模板，同时专注于任务相关信息。在PDDL数据集上对该方法进行了基准测试，并比较了其性能。此外，在复杂数据管道设计任务上进行了额外评估，并展示了与现有方法相比在5个指标上的改进：可伸缩性、可靠性、可用性、成本效益和文档化，并提供了额外定性证据。

Result: 结果：通过在PDDL数据集和复杂数据管道设计任务上进行的测试，证明了内在记忆代理框架的优越性能。在多Agent LLM系统中，该方法相比现有最先进多Agent记忆方法提高了38.6%的性能，同时具有最高的令牌效率。

Conclusion: 结论：通过引入内在记忆代理这一新颖框架，本文解决了基于大型语言模型（LLMs）构建的多Agent系统面临的上下文窗口限制等基本挑战。该方法在PDDL数据集上表现出很高的性能，在复杂数据管道设计任务上展示出更高质量的设计。研究结果表明，通过结构化的内在方法来解决记忆限制可以提高多Agent LLM系统在结构化规划任务上的能力。

Abstract: Multi-agent systems built on Large Language Models (LLMs) show exceptional
promise for complex collaborative problem-solving, yet they face fundamental
challenges stemming from context window limitations that impair memory
consistency, role adherence, and procedural integrity. This paper introduces
Intrinsic Memory Agents, a novel framework that addresses these limitations
through structured agent-specific memories that evolve intrinsically with agent
outputs. Specifically, our method maintains role-aligned memory templates that
preserve specialized perspectives while focusing on task-relevant information.
We benchmark our approach on the PDDL dataset, comparing its performance to
existing state-of-the-art multi-agentic memory approaches and showing an
improvement of 38.6\% with the highest token efficiency. An additional
evaluation is performed on a complex data pipeline design task, we demonstrate
that our approach produces higher quality designs when comparing 5 metrics:
scalability, reliability, usability, cost-effectiveness and documentation with
additional qualitative evidence of the improvements. Our findings suggest that
addressing memory limitations through structured, intrinsic approaches can
improve the capabilities of multi-agent LLM systems on structured planning
tasks.

</details>


### [36] [Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs](https://arxiv.org/abs/2508.09019)
*Shivam Dubey*

Main category: cs.AI

TL;DR: 本文介绍了一种新的方法来在大型语言模型中识别和减轻偏见，通过训练内部"探针"来检测各种偏见，并计算"转向向量"来主动引导模型生成过程，避免生成有害、刻板或有偏见内容。实验证明这种方法的有效性，提供了更安全、更中立的大型语言模型构建方案。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）越来越多地融入社会系统中，它们持续和放大有害偏见的风险变得极为关键。传统的减轻偏见的方法通常依赖于数据过滤或事后输出调节，这些方法将模型视为不透明的黑匣子。因此，本工作的动机在于引入一个完整的端到端系统，利用机械解释的技术直接识别和主动减轻模型内部的偏见。

Method: 本工作首先训练模型内部激活的线性"探针"来检测各种偏见，然后通过比较有偏见和中立语句的激活模式来计算"转向向量"。在推理过程中添加这些向量以主动引导模型的生成过程，使其避免生成有害、刻板或有偏见内容。作者通过实验证明这种激活引导技术的有效性。

Result: 作者提出的方法在实验中表现出很高的准确性，能够几乎完美地识别模型中的有偏见内容，并成功地将有偏见的生成转变为更中立的替代方案。他们的激活引导技术在实践中表现出有效性，可以使大型语言模型生成更安全、更中立的内容。

Conclusion: 本文介绍了一种完整的端到端系统，利用机械解释的技术来识别和主动减轻模型内部的偏见。他们的方法包括训练模型内部激活的线性"探针"来检测各种偏见（例如性别、种族、年龄）的潜在表征，以及通过对比模型对于有偏见和中立语句的激活模式来计算"转向向量"。通过在推理过程中添加这些向量，他们可以主动引导模型的生成过程，使其远离产生有害、刻板或有偏见内容。实验证明这种激活引导技术的有效性，成功地将有偏见的完成转变为更中立的替代方案。因此，他们提出了一个健壮且可重复的系统，提供了一个更直接和可解释的方法来构建更安全和更负责任的大型语言模型（LLMs）。

Abstract: As large language models (LLMs) become more integrated into societal systems,
the risk of them perpetuating and amplifying harmful biases becomes a critical
safety concern. Traditional methods for mitigating bias often rely on data
filtering or post-hoc output moderation, which treat the model as an opaque
black box. In this work, we introduce a complete, end-to-end system that uses
techniques from mechanistic interpretability to both identify and actively
mitigate bias directly within a model's internal workings. Our method involves
two primary stages. First, we train linear "probes" on the internal activations
of a model to detect the latent representations of various biases (e.g.,
gender, race, age). Our experiments on \texttt{gpt2-large} demonstrate that
these probes can identify biased content with near-perfect accuracy, revealing
that bias representations become most salient in the model's later layers.
Second, we leverage these findings to compute "steering vectors" by contrasting
the model's activation patterns for biased and neutral statements. By adding
these vectors during inference, we can actively steer the model's generative
process away from producing harmful, stereotypical, or biased content in
real-time. We demonstrate the efficacy of this activation steering technique,
showing that it successfully alters biased completions toward more neutral
alternatives. We present our work as a robust and reproducible system that
offers a more direct and interpretable approach to building safer and more
accountable LLMs.

</details>


### [37] [A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems](https://arxiv.org/abs/2508.09027)
*Jie Wang,Guang Wang*

Main category: cs.AI

TL;DR: 本文提出了FiXGBoost模型，用于在拼车系统中预测乘客的请求前等待时间，实现了可解释性和良好性能。研究了需求和供给动态对等待时间的影响，并进行了重要性分析，实验结果表明该模型表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多集中在已匹配司机信息的情况下进行请求后等待时间预测，而本文关注了请求前等待时间预测，这有助于乘客更有效地计划行程，提升乘客和司机的体验。此前尚未完全被现有研究作品所探讨。

Method: 通过深入的数据驱动研究，探讨了需求和供给动态对乘客等待时间的影响，基于分析和特征工程，提出了FiXGBoost模型。进一步进行了重要性分析，量化了每个因素的贡献。

Result: 实验使用了超过3000万条真实世界的拼车数据集，结果表明FiXGBoost能够在请求前预测乘客等待时间，并具有较高的可解释性。

Conclusion: 本文提出了一种新颖的基于特征交互的XGBoost模型FiXGBoost，用于预测乘客等待时间，该模型在不知道分配的司机信息的情况下进行预测，实现了较高的可解释性和良好的性能。

Abstract: Passenger waiting time prediction plays a critical role in enhancing both
ridesharing user experience and platform efficiency. While most existing
research focuses on post-request waiting time prediction with knowing the
matched driver information, pre-request waiting time prediction (i.e., before
submitting a ride request and without matching a driver) is also important, as
it enables passengers to plan their trips more effectively and enhance the
experience of both passengers and drivers. However, it has not been fully
studied by existing works. In this paper, we take the first step toward
understanding the predictability and explainability of pre-request passenger
waiting time in ridesharing systems. Particularly, we conduct an in-depth
data-driven study to investigate the impact of demand&supply dynamics on
passenger waiting time. Based on this analysis and feature engineering, we
propose FiXGBoost, a novel feature interaction-based XGBoost model designed to
predict waiting time without knowing the assigned driver information. We
further perform an importance analysis to quantify the contribution of each
factor. Experiments on a large-scale real-world ridesharing dataset including
over 30 million trip records show that our FiXGBoost can achieve a good
performance for pre-request passenger waiting time prediction with high
explainability.

</details>


### [38] [CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks](https://arxiv.org/abs/2508.09054)
*Debdeep Mukherjee,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Victor Martin,Thierry Josse,Jonathan Brown,Kenza Saiah*

Main category: cs.AI

TL;DR: 本文提出了利用深度神经网络的预测性维护框架，可以在CVCM故障升级为失效之前对异常进行分类。该方法通过验证案例和符合性预测取得了显著的成功，对提高运行可靠性具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 早期识别故障类型对于改善维护规划、最小化停机时间和收入损失至关重要。传统方法依赖于明显的信号变化，很难及早检测到由于时间演变而不易在监控信号中明显看出的微妙异常。

Method: 本文利用深度神经网络，建立了预测性维护框架，用于对CVCM异常进行分类。方法通过在不同安装地点验证10个CVCM故障案例，以及符合ISO-17359标准，通过符合性预测提供了不确定性估计。

Result: 利用深度神经网络的预测性维护框架在CVCM故障分类方面表现出色，实现了99.31%的整体准确率，在异常发生1%之内检测。通过符合性预测提供了不确定性估计，达到99%的置信度。

Conclusion: 本文提出了一种利用深度神经网络的预测性维护框架，可以在故障升级为失效之前对异常进行分类。该方法在不同安装位置上验证了10个连续变量电流调制(CVCM)故障案例，符合ISO-17359标准，优于传统技术，在异常发生1%之内检测精度达到99.31%。通过符合性预测，提供了不确定性估计，在不同类别中实现了99%的置信度。由于CVCM在全球范围内部署，该方法具有可扩展性，可适用于其他轨道电路和铁路系统，提高了运行可靠性。

Abstract: Track circuits are critical for railway operations, acting as the main
signalling sub-system to locate trains. Continuous Variable Current Modulation
(CVCM) is one such technology. Like any field-deployed, safety-critical asset,
it can fail, triggering cascading disruptions. Many failures originate as
subtle anomalies that evolve over time, often not visually apparent in
monitored signals. Conventional approaches, which rely on clear signal changes,
struggle to detect them early. Early identification of failure types is
essential to improve maintenance planning, minimising downtime and revenue
loss. Leveraging deep neural networks, we propose a predictive maintenance
framework that classifies anomalies well before they escalate into failures.
Validated on 10 CVCM failure cases across different installations, the method
is ISO-17359 compliant and outperforms conventional techniques, achieving
99.31% overall accuracy with detection within 1% of anomaly onset. Through
conformal prediction, we provide uncertainty estimates, reaching 99% confidence
with consistent coverage across classes. Given CVCMs global deployment, the
approach is scalable and adaptable to other track circuits and railway systems,
enhancing operational reliability.

</details>


### [39] [SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling](https://arxiv.org/abs/2508.09105)
*Shixuan Sun,Siyuan Liang,Ruoyu Chen,Jianjie Huang,Jingzhi Li,Xiaochun Cao*

Main category: cs.AI

TL;DR: RAG 和 MRAG 提高了大型语言模型的知识覆盖性和上下文理解能力，但内容来源不明确，本文提出了 SMA 方法以解决这一问题。该方法能够在半黑盒设置下对生成内容进行来源归因，并通过零阶优化和跨模态归因技术实现了新的数据审计视角。


<details>
  <summary>Details</summary>
Motivation: 当前的 RAG 和 MRAG 方法虽然改善了大语言模型的知识覆盖和上下文理解，但不同来源的内容会模糊不清，现有的会员推理方法无法可靠地将生成的输出归因于预训练、外部检索或用户输入，影响了隐私泄漏的可追溯度。

Method: 提出了Source-aware Membership Audit (SMA)方法，通过零阶优化设计归因估计机制，并引入了跨模态归因技术。

Result: 论文设计了一种能够在半黑盒设置下实现生成内容来源细粒度归因的方法，通过零阶优化设计归因估计机制和跨模态归因技术，实现了数据来源的新视角。

Conclusion: 该论文提出了第一个基于源的会员审计（SMA），实现了对生成内容的细粒度来源归因，在半黑盒设置下具有检索控制功能。通过零阶优化设计归因估计机制，通过大规模扰动采样和岭回归建模，稳健地近似了输入标记对输出的真实影响。SMA引入了一种跨模态归因技术，通过MLLMs将图像输入投影为文本描述，实现了文本模态中的标记级别归因，首次在MRAG系统中实现了对图像检索痕迹的会员推理。该工作将会员推断的焦点从“数据是否被记忆”转移到“内容的来源何处”，为复杂生成系统中审核数据来源提供了新的视角。

Abstract: Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented
Generation (MRAG) significantly improve the knowledge coverage and contextual
understanding of Large Language Models (LLMs) by introducing external knowledge
sources. However, retrieval and multimodal fusion obscure content provenance,
rendering existing membership inference methods unable to reliably attribute
generated outputs to pre-training, external retrieval, or user input, thus
undermining privacy leakage accountability
  To address these challenges, we propose the first Source-aware Membership
Audit (SMA) that enables fine-grained source attribution of generated content
in a semi-black-box setting with retrieval control capabilities.To address the
environmental constraints of semi-black-box auditing, we further design an
attribution estimation mechanism based on zero-order optimization, which
robustly approximates the true influence of input tokens on the output through
large-scale perturbation sampling and ridge regression modeling. In addition,
SMA introduces a cross-modal attribution technique that projects image inputs
into textual descriptions via MLLMs, enabling token-level attribution in the
text modality, which for the first time facilitates membership inference on
image retrieval traces in MRAG systems. This work shifts the focus of
membership inference from 'whether the data has been memorized' to 'where the
content is sourced from', offering a novel perspective for auditing data
provenance in complex generative systems.

</details>


### [40] [OpenCUA: Open Foundations for Computer-Use Agents](https://arxiv.org/abs/2508.09123)
*Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y. Charles,Zhilin Yang,Tao Yu*

Main category: cs.AI

TL;DR: 提出了OpenCUA框架，通过注解基础设施、AgentNet数据集和可扩展的数据转换管道，实现了机器代理模型在CUA基准测试中的强大表现，超越了OpenAI CUA（GPT-4o），释放了注解工具、数据集、代码和模型，为进一步的CUA研究提供了开放的基础。


<details>
  <summary>Details</summary>
Motivation: 随着商业潜力增长，现有的最优秀的CUA系统细节仍然封闭，研究社区需要开放的CUA框架来研究它们的能力、限制和风险。为了弥合这一差距，提出了OpenCUA框架，以便为进一步的CUA研究建立开放的基础。

Method: 提出OpenCUA框架，包括注解基础设施、AgentNet数据集和可扩展的数据转换管道。通过长链式的思维推理将演示转换为状态-动作对，实现数据规模的增长而持续得到强大的性能提升。演示结果在CUA基准测试中表现出色，并且OpenCUA-32B在OSWorld-Verified平台上达到了34.8%的平均成功率。

Result: 提出了一个全面开源的框架OpenCUA，成功实现了机器代理模型在CUA基准测试中表现出色，超越了OpenAI CUA（GPT-4o），在OSWorld-Verified上创造了新的最佳模型。研究显示该方法在不同领域有良好泛化能力，并且通过增加测试时间计算获得显著的性能提升。释放了注解工具、数据集、代码和模型，为进一步的CUA研究提供了开放的基础。

Conclusion: 提出了OpenCUA，一个全面开源的框架，用于扩展CUA数据和基础模型。通过注解基础设施、AgentNet数据集和可扩展的数据转换管道，实现了机器代理模型在CUA基准测试上的强大表现，尤其是OpenCUA-32B在OSWorld-Verified上创造了34.8%的平均成功率，超越了OpenAI CUA（GPT-4o），成为开源模型中的新的最佳模型。研究表明该方法在不同领域具有良好的泛化能力，并且在测试时间计算增加时表现显著提升。最终释放了注解工具、数据集、代码和模型，为进一步的CUA研究建立了开放基础。

Abstract: Vision-language models have demonstrated impressive capabilities as
computer-use agents (CUAs) capable of automating diverse computer tasks. As
their commercial potential grows, critical details of the most capable CUA
systems remain closed. As these agents will increasingly mediate digital
interactions and execute consequential decisions on our behalf, the research
community needs access to open CUA frameworks to study their capabilities,
limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive
open-source framework for scaling CUA data and foundation models. Our framework
consists of: (1) an annotation infrastructure that seamlessly captures human
computer-use demonstrations; (2) AgentNet, the first large-scale computer-use
task dataset spanning 3 operating systems and 200+ applications and websites;
(3) a scalable pipeline that transforms demonstrations into state-action pairs
with reflective long Chain-of-Thought reasoning that sustain robust performance
gains as data scales. Our end-to-end agent models demonstrate strong
performance across CUA benchmarks. In particular, OpenCUA-32B achieves an
average success rate of 34.8% on OSWorld-Verified, establishing a new
state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA
(GPT-4o). Further analysis confirms that our approach generalizes well across
domains and benefits significantly from increased test-time computation. We
release our annotation tool, datasets, code, and models to build open
foundations for further CUA research.

</details>


### [41] [BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://arxiv.org/abs/2508.09129)
*Xianghe Pang,Shuo Tang,Rui Ye,Yuwen Du,Yaxin Du,Siheng Chen*

Main category: cs.AI

TL;DR: BrowseMaster addresses the challenges of current agents by balancing search and reasoning effectively. It outperforms existing models on English and Chinese benchmarks, demonstrating strong capabilities in complex information-seeking tasks.


<details>
  <summary>Details</summary>
Motivation: Existing large language model-based agents struggle with balancing expansive search and strategic reasoning due to limitations in search breadth and reasoning depth. Slow, serial querying and noisy raw inputs hinder coverage of relevant sources and continuity of multi-step reasoning.

Method: Proposed BrowseMaster, a framework with a programmatically augmented planner-executor agent pair. The planner formulates search strategies based on task constraints, and the executor conducts efficient retrieval to provide concise, relevant evidence.

Result: Extensive experiments on English and Chinese benchmarks show BrowseMaster consistently outperforms baseline models, with scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh.

Conclusion: BrowseMaster outperforms open-source and proprietary baselines, achieving high scores on challenging benchmarks in both English and Chinese, demonstrating strong capability in complex information-seeking tasks.

Abstract: Effective information seeking in the vast and ever-growing digital landscape
requires balancing expansive search with strategic reasoning. Current large
language model (LLM)-based agents struggle to achieve this balance due to
limitations in search breadth and reasoning depth, where slow, serial querying
restricts coverage of relevant sources and noisy raw inputs disrupt the
continuity of multi-step reasoning. To address these challenges, we propose
BrowseMaster, a scalable framework built around a programmatically augmented
planner-executor agent pair. The planner formulates and adapts search
strategies based on task constraints, while the executor conducts efficient,
targeted retrieval to supply the planner with concise, relevant evidence. This
division of labor preserves coherent, long-horizon reasoning while sustaining
broad and systematic exploration, overcoming the trade-off that limits existing
agents. Extensive experiments on challenging English and Chinese benchmarks
show that BrowseMaster consistently outperforms open-source and proprietary
baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh,
which demonstrates its strong capability in complex, reasoning-heavy
information-seeking tasks at scale.

</details>
