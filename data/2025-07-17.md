<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 本文探讨了人类与自然关系的转变以及人工智能在生态设计中的潜力。通过案例研究，展示了人工智能在数据分析、图像识别和生态恢复等方面的应用，提出了将强化学习与植物修复相结合的设计路径。研究结果突出了人工智能在连接科学洞见、艺术实践和环境监护方面的潜力，为未来可持续生态系统研究提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨人类与自然之间的关系转变以及人工智能在此过程中的中介作用，提出了一种新的生态设计范式。通过展示案例研究，强调了人工智能在生态设计领域的应用潜力和创新性，以及对于未来研究的启示。

Method: 作者在人工智能辅助水资源修复的原型基础上，提出了一种将强化学习与基于植物的植物修复相结合的设计路径。研究结果突出了人工智能在连接科学洞见、艺术实践和环境监护方面的潜力，为未来可持续、技术驱动的生态系统研究提供了路线图。

Result: 通过本文研究人工智能在生态设计中的应用，展示了人工智能不仅可以作为创意工具，还可以引领生态设计理论和实践的转变，为构建可持续、技术驱动的生态系统提供了新的思路和方法。

Conclusion: 人工智能在生态设计中的应用可以推动人类与自然之间从人类主导转向真正相互依存的关系，拓展了创作方法并重构了生态设计的理论和实践。通过案例研究，展示了艺术家和设计师如何应用人工智能进行数据分析、图像识别和生态恢复，产生与传统媒体不同的成果。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [2] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 该论文介绍了一种模块化设计的LLM代理，利用经典和现代游戏套件作为测试平台，统一了分析每个模块如何影响性能的工作流程。实验结果表明，模块化设计提升了游戏表现，记忆在长期谜题中起主导作用，感知对于视觉嘈杂的游戏至关重要。


<details>
  <summary>Details</summary>
Motivation: 通过这种模块化设计的LLM代理，可以处理各种多轮游戏环境，而无需进行特定领域的工程。并且利用游戏作为测试平台可以验证每个模块对性能的影响，从而提高通用代理的表现。

Method: 介绍了一种模块化设计的LLM代理的设计，包括感知、记忆和推理组件，利用经典和现代游戏套件作为测试平台，统一了分析每个模块如何影响不同的动态交互设置中的性能的工作流程。进行了大量实验来验证设计效果。

Result: 实验表明，模块化设计提升了游戏表现，对未经设计的基线有一致的提升。记忆在长期视角谜题中起主导作用，而感知对视觉嘈杂的街机游戏至关重要。

Conclusion: 该论文介绍了一种模块化设计的LLM代理的设计，包括感知、记忆和推理组件，使得单个LLM或VLM骨干可以在广泛的多轮游戏环境中进行处理，无需特定领域的工程。他们的框架利用经典和现代游戏套件作为测试平台，统一了分析每个模块如何影响不同的动态交互设置中的性能的工作流程。大量实验表明，这种设计提升了游戏表现，对未经设计的基线有一致的提升，并揭示了独特的贡献模式，例如，在长期视角谜题中记忆起主导作用，而在视觉嘈杂的街机游戏中感知至关重要。这些发现突显了他们的模块化设计在推进通用代理方面的效果，考虑到游戏在日常人类体验中的熟悉性和普遍性。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [3] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: 本研究针对MLLMs作为验证器时出现的协议偏见问题提出了解决方法SGV，通过引入一种轻量级方法，在两个步骤中有效利用MLLMs的知识和推理能力，提高了验证器的性能和任务完成率。实验结果显示，引入SGV方法后，MLLM验证器在各项任务中取得了显著提高，超过了先前的最佳成绩。


<details>
  <summary>Details</summary>
Motivation: AI领域中，将MLLMs用作验证器在一些领域取得了成功，但在缺乏明确成功标准的领域（如计算机使用）中仍然面临挑战。人类能够识别合适的结果，但将这种直觉转化为可扩展的规则是非常困难的。本研究旨在评估MLLMs作为代理轨迹验证器的效果，并发现了“协议偏见”现象。为了解决这一问题，提出了SGV方法，旨在更有效地利用MLLMs的知识和推理能力，提高验证器的性能和任务完成率。

Method: 通过引入自我植根验证（SGV）方法，利用多模态大型语言模型（MLLMs）的采样机制，在两个步骤中操作：首先从MLLM中获取与任务完成相关的广泛先验信息，然后在自我生成的先验信息的基础上理解和评估候选轨迹。SGV通过增强MLLM验证器的性能，从而提高了准确性和失败检测率，并在多个任务中表现出色。

Result: 通过引入SGV方法，MLLM验证器的准确性和失败检测率提高了高达20个百分点。在Web导航、计算机使用和机器人操作等任务中，MLLM验证器通过SGV方法的增强表现出色，提高了GUI专家在OSWorld、robomimic中的扩散政策以及VisualWebArena中的ReAct代理的任务完成率，在基准测试中表现优异，超过先前最佳成绩48%。

Conclusion: 提出了自我植根验证（SGV）方法，以解决多模态大型语言模型（MLLMs）作为验证器时存在的一些限制，通过利用它们的知识和推理能力更有效地评估代理轨迹。在Web导航、计算机使用和机器人操作领域进行了评估，发现MLLMs存在一种“协议偏见”现象，即倾向于偏向其上下文窗口信息，容易生成一系列思考链条来解释有缺陷的行为。提出的SGV方法能够提高MLLMs验证器的准确性和失败检测率，同时实现对异构代理的实时监督，在各项任务中表现优异，刷新了各项基准测试的最佳成绩。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [4] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: 该研究介绍了名为ClarifAI的新方法，旨在提高人工智能系统的透明度和可解释性。通过结合基于案例推理和本体的方法，ClarifAI旨在满足不同利益相关者对于AI应用程序解释需求的复杂性。该方法展示了在提供详尽解释机制方面的潜力，并可在高风险环境下应用。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于增强人工智能系统的可理解性，特别是在涉及决策的高风险环境中。通过引入ClarifAI这一新方法，旨在满足不同利益相关者对于人工智能解释需求的复杂性。

Method: 结合基于案例推理和本体的方法来设计ClarifAI，以提高人工智能系统的透明度和可解释性。

Result: 通过结合CBR和本体，ClarifAI展示了在提供详尽解释机制方面的潜力，为人工智能的应用增加了可解释性。同时，该方法在高风险环境下的适用性得到了突出展示。

Conclusion: 该研究介绍了一种名为ClarifAI的新方法，旨在增强人工智能在决策改进领域中的透明度和可解释性。通过利用基于案例推理（CBR）方法并整合本体驱动方法，ClarifAI旨在满足涉及AI应用程序的各方利益相关者复杂的解释需求。研究详细阐述了ClarifAI的理论基础，结合CBR和本体以提供详尽的解释机制。同时，它进一步阐述了设计原则和架构蓝图，突出了ClarifAI在不同领域增强AI可解释性的潜力和其在高风险环境中的适用性。这项研究描绘了ClariAI在推进AI系统可解释性方面的重要作用，为其在关键决策流程中的部署铺平了道路。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [5] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 本论文介绍了DP-Bench基准测试和DPLM模型，展示了在动态规划问题上的性能。提出了DualReflect合成数据生成管道，强调了在低数据情况下后向生成和大规模情况下前向生成的价值权衡。


<details>
  <summary>Details</summary>
Motivation: DP问题由于其固有的随机转换和训练数据有限的特性而提出独特挑战，使得直接应用现有基于LLM的模型或其他优化问题（如线性或整数规划）的框架变得困难。因此，利用大型语言模型（LLMs）自动化DP模型的制定具有潜力。

Method: 提出了DualReflect，一种新颖的合成数据生成管道，旨在扩展来自有限初始示例集的训练数据。DualReflect结合了前向生成以提高多样性和后向生成以提高可靠性。结果揭示了一个关键观点：在低数据情形下，后向生成由于其强大的正确性保证而受青睐，而尽管缺乏这种保证，但在大规模情况下，前向生成因引入多样性的表现而变得越来越有价值。这种权衡突显了这两种方法的互补优势及其结合的重要性。

Result: 提出的DPLM模型在动态规划问题上取得了与最先进的LLMs相当的性能，甚至在难题上表现更好。结合了前向和后向生成的合成数据生成管道DualReflect显示出在训练数据受限的情况下的重要作用。

Conclusion: 介绍了DP-Bench，这是第一个涵盖广泛的教科书级动态规划问题的基准测试，旨在实现系统评估。引入了Dynamic Programming Language Model（DPLM），一个具有7B参数的专门模型，其性能与OpenAI的o1和DeepSeek-R1等最先进的LLMs相当，并在困难问题上超越它们。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [6] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 该论文调查了群体智能算法在搜索文档语义相似性方面的最新进展，并提出了未来研究方向。采用调查研究方法，总结了群体智能算法的应用及其有效性。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于群体智能算法在人工智能领域的受欢迎程度日益增加，其在解决实际问题中的有效性已被证实，调查研究可以帮助了解这些算法在搜索文档方面的应用情况。

Method: 文中采用了调查研究的方法，通过综述群体智能算法在搜索文档语义相似性方面的应用情况，总结最新进展。

Result: 通过调查和总结，发现群体智能算法在搜索文档语义相似性方面得到了广泛应用，并提出了未来的研究方向。

Conclusion: 该论文调查了利用群体智能算法在基于语义相似性搜索文档方面的最新进展，并提出了未来的研究方向。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [7] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 本文介绍了一种新的成本受限的深度优先搜索（CB-DFS）方法，利用现代CPU和GPU的并行性，建立了类似Batch IDA*和Batch BTS的算法。作者在3x3魔方和4x4滑块谜题上评估了这一方法，展示了GPU操作在DFS中可以高效批处理的能力。进行了大量实验，分析了超参数、神经网络启发大小和硬件资源对性能的影响。


<details>
  <summary>Details</summary>
Motivation: GPU技术的迅速发展为增强经典搜索算法带来了新的机会，但在搜索过程中利用GPU的算法仍然很少。本文基于Asynchronous Parallel IDA*（AIDA*）的通用方法，提出了一种批处理GPU计算的新方法，旨在探索深度优先搜索中GPU并行计算的效能。

Method: 介绍了一种新的成本受限的深度优先搜索（CB-DFS）方法，利用现代CPU和GPU的并行性，建立了类似Batch IDA*和Batch BTS的算法。通过在3x3魔方和4x4滑块谜题上的评估以及大量实验，验证了GPU操作在DFS中可以高效批处理的能力，并分析了不同因素对性能的影响。

Result: 在3x3魔方和4x4滑块谜题上评估了CB-DFS方法，并展示了GPU操作在DFS中高效批处理的能力。通过实验分析了超参数、神经网络启发大小和硬件资源对性能的影响。

Conclusion: 本文介绍了一种在深度优先搜索中批处理GPU计算的新方法，通过结合现代CPU和GPU的并行性，提出了成本受限的深度优先搜索（CB-DFS）方法，用于创建诸如Batch IDA*和Batch BTS等新算法。作者在3x3魔方和4x4滑块谜题上评估了这一方法，展示了GPU操作在DFS中可以高效批处理的能力。此外，作者进行了大量实验，分析了超参数、神经网络启发大小和硬件资源对性能的影响。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [8] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Aime is a novel multi-agent framework designed to overcome limitations of traditional frameworks in multi-agent systems with LLMs. It introduces dynamic planning and execution, outperforming specialized agents in different domains and establishing itself as a more resilient and effective foundation for multi-agent collaboration.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to address the critical limitations of prevalent plan-and-execute frameworks in multi-agent systems, such as rigid plan execution, static agent capabilities, and inefficient communication. By introducing Aime, the aim is to enhance adaptability and robustness in dynamic environments.

Method: Introducing Aime, a multi-agent framework with core innovations including a Dynamic Planner, an Actor Factory, and a centralized Progress Management Module. These components enable dynamic, reactive planning and execution, replacing the static workflow with a fluid and adaptive architecture.

Result: Empirical evaluation of Aime on various benchmarks demonstrates its consistent outperformance of highly specialized state-of-the-art agents. Aime's superior adaptability and task success rate validate it as a more resilient and effective foundation for multi-agent collaboration.

Conclusion: Aime, a novel multi-agent framework, has been introduced to overcome the limitations of traditional plan-and-execute frameworks in multi-agent systems powered by Large Language Models (LLMs). It demonstrates superior adaptability and task success rate compared to specialized agents in various domains, making it a more resilient and effective foundation for multi-agent collaboration.

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [9] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 研究使用强化学习算法训练智能体，在模拟环境中让智能体学会穿过通道并避开障碍物，仅使用光流作为感觉输入。发现训练后的智能体主要关注光流不连续区域和光流幅度较大的区域，避开产生大光流的障碍物，保持环境中心位置，类似飞行昆虫行为。这种模式在独立训练的智能体中持续存在，可作为发展无人机简单明确控制规则的良好策略。


<details>
  <summary>Details</summary>
Motivation: 生物启发设计在自主无人机导航中经常用于利用生物系统对飞行和避障能力，尽管其感知和计算能力有限。本研究针对蜜蜂主要利用视觉中物体的视觉运动（光流）作为导航的感觉输入进行了训练，希望能为开发无人机的简单明确控制规则提供策略。

Method: 使用强化学习算法训练智能体，仅使用光流作为感觉输入，在模拟环境中让智能体学会穿过通道并避开障碍物。检查训练后的智能体的注意力模式，以确定它们主要基于光流的哪些区域做出运动决策。

Result: 智能体主要关注光流不连续区域和光流幅度较大的区域，以避开产生大光流的障碍物，并在环境中保持中心位置，类似飞行昆虫的行为。这种模式在独立训练的智能体中持续存在，表明这可能是为物理无人机开发简单明确控制规则的良好策略。

Conclusion: 研究结果表明，训练使用仅光流作为感觉输入的强化学习智能体，主要关注光流不连续区域和光流幅度较大的区域，以避开产生大光流的障碍物，并在环境中保持中心位置，类似飞行昆虫的行为。这种模式在独立训练的智能体中持续存在，这表明这可能是为物理无人机开发简单明确控制规则的良好策略。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [10] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 该论文提出了拓扑增强的多智能体强化学习（MARL）方法，用于优化混合交通中连接和自主车辆的合作决策。通过构建游戏拓扑张量和基于QMIX的RL算法，实现了有效的探索和利用之间的平衡，展示了在交通效率、安全性、决策平稳性和任务完成方面的优越性能。算法在混合自动化和完全自主交通场景中表现良好，可在	extit{https://github.com/leoPub/tpemarl}获取源代码。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的勘探与利用之间的权衡是一个基本挑战，而在混合自动化交通中，由于联合状态-动作空间的指数增长，这一挑战更为严峻。因此，本研究旨在解决这一问题，通过拓扑增强MARL方法实现连接和自主车辆在混合交通中的合作决策优化。

Method: 构建游戏拓扑张量以压缩高维交通状态信息，减少MARL算法的搜索空间；利用QMIX作为RL算法的主干，建立拓扑增强MARL框架，包含访问次数和智能体相互信息；进行了大量模拟实验评估算法在不同情况下的有效性，评估包括训练动态、探索模式、宏观交通性能指标和微观车辆行为；展示算法在交通效率、安全性、决策平稳性和任务完成方面的优越性能。

Result: 通过大量模拟实验验证了TPE-MARL方法的有效性，展示了在交通效率、安全性、决策平稳性和任务完成等方面的优越性能，同时表现出与人类驾驶员相当甚至超过其的决策合理性。

Conclusion: 该论文提出了一种拓扑增强的多智能体强化学习（MARL）方法，用于优化混合交通中连接和自主车辆（CAVs）的合作决策。研究构建了游戏拓扑张量以压缩高维交通状态信息，降低MARL算法的搜索空间；基于设计的游戏拓扑张量，结合QMIX作为RL算法的主干，建立了一个包含访问次数和智能体相互信息的拓扑增强MARL框架。通过在不同交通密度和CAV渗透率下进行的大量模拟，证明了TPE-MARL的有效性。评估涵盖了训练动态、探索模式、宏观交通性能指标以及微观车辆行为，显示TPE-MARL成功地平衡了探索和利用，在交通效率、安全性、决策平稳性和任务完成方面表现出优越性能。此外，该算法在混合自动化和完全自主交通场景中表现出与人类驾驶员相当甚至超过其的决策合理性。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [11] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 该论文介绍了部分可观察参考策略规划的方法，提出了一种新颖的随时在线近似POMDP求解器，通过深度抽样有意义的未来历史和渐进策略更新，提供了理论保证。实证评估结果显示，该算法在大规模问题上性能优于当前在线基准。


<details>
  <summary>Details</summary>
Motivation: 本论文的动机在于解决近似POMDP求解中采样稀疏性的问题，提出了新的方法来克服在线规划中的性能损失。通过对动态演变环境中的大规模问题进行实证评估，验证了算法的有效性和优越性。

Method: 该论文提出了一种部分可观察参考策略规划的方法，采用了深度抽样有意义的未来历史和渐进策略更新的策略。对算法的基本方案提供了理论保证，性能损失被界定为采样近似误差的平均值。在两个大规模问题上进行了实证评估，确认了理论结果并表明求解器优于当前在线基准。

Result: 通过理论分析和实证评估，证明了该算法的性能优于当前在线基准，在解决大规模问题时取得了显著的改进。

Conclusion: 该论文介绍了部分可观察参考策略规划（Partially Observable Reference Policy Programming）的方法，提出了一种新颖的随时在线近似POMDP求解器。通过深度抽样有意义的未来历史，同时强制渐进策略更新，为算法的基本方案提供了理论保证。该算法的性能损失被界定为采样近似误差的平均值，而不是通常的最大值，这是在线规划的采样稀疏性的关键要求。在两个大规模问题上的实证评估中，包括在动态演变环境中的直升机紧急情况，结果验证了理论结果，并表明我们的求解器明显优于当前的在线基准。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [12] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo is a novel framework that uses Large Language Models (LLMs) to automatically design effective and interpretable energy prediction heuristics. It incorporates physical insights from building characteristics and operational data, achieving state-of-the-art performance on benchmarks and improving generalization and transparency in prediction logic. The framework promotes the automated design of robust, physically grounded heuristics for complex energy systems.


<details>
  <summary>Details</summary>
Motivation: Accurate building energy forecasting is crucial, and existing methods lack precision or struggle with generalization. Traditional heuristics are often imprecise, while advanced models may be opaque and overlook physical principles. The paper aims to address these limitations by introducing BuildEvo, which bridges the gap between precision and interpretability in energy prediction.

Method: BuildEvo employs an evolutionary process to guide Large Language Models (LLMs) in constructing and enhancing energy prediction heuristics. It systematically incorporates physical insights from building characteristics and operational data, such as data from the Building Data Genome Project 2, to design more effective and interpretable heuristics.

Result: BuildEvo demonstrates improved performance, generalization, and transparency in energy prediction compared to traditional heuristics and advanced models. It establishes state-of-the-art results on benchmarks and enhances the trustworthy design of robust energy prediction models for complex systems.

Conclusion: BuildEvo introduces a novel framework that uses Large Language Models (LLMs) to automatically design effective and interpretable energy prediction heuristics, achieving state-of-the-art performance on benchmarks and improving generalization and transparency in prediction logic. The framework promotes the automated design of robust, physically grounded heuristics for complex energy systems.

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [13] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 该研究通过中国象棋作为测试平台，提出了一个针对该游戏的训练框架和模型Xiangqi-R1，通过多阶段训练和强化学习等方式，提升了大语言模型在空间战略推理方面的性能表现。实验结果显示Xiangqi-R1相比通用大语言模型取得了显著进展，为在空间复杂领域创建通用战略智能提供了有益路径。


<details>
  <summary>Details</summary>
Motivation: 通过研究通用大语言模型在空间战略推理中的表现，发现其在复杂和完全可观察的棋盘游戏中的效果不足。因此，为了提高大语言模型在这些环境中的战略能力，选择了中国象棋作为具有挑战性和丰富性的测试平台。

Method: 研究采用了中国象棋作为测试平台，提出了一个针对中国象棋的训练框架，包含了通过专家注释和引擎评估增强五百万个棋盘移动对数据集，并训练了一个7B参数的Xiangqi-R1模型。模型采用了多阶段训练，包括精细调整以捕捉基本的空间规则，融合战略注释来改善决策，以及利用Group Relative Policy Optimization (GRPO)进行强化学习以提高推理稳定性。

Result: 实验结果显示，相比于通用大语言模型，Xiangqi-R1在棋盘游戏中取得了明显进展，在移动合法性和分析准确性方面分别提升了18%和22%。

Conclusion: 该研究表明，尽管通用大语言模型在空间战略推理方面存在挑战，但通过针对中国象棋的训练框架和模型Xiangqi-R1的引入，可以在这些任务中取得显著的进展。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>
