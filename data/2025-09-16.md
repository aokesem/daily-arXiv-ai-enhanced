<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 50]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Situation Model of the Transport, Transport Emissions and Meteorological Conditions](https://arxiv.org/abs/2509.10541)
*V. Benes,M. Svitek,A. Michalikova,M. Melicherik*

Main category: cs.AI

TL;DR: 该论文以布拉格（捷克共和国）的交通、气象和排放数据为基础，通过模糊推理系统开发了模型，旨在预测和管理城市交通的排放变化，以提供更有效的环境保护方案。


<details>
  <summary>Details</summary>
Motivation: 目前社会面临的城市空气污染和减少污染的可能性是一个重要问题。该论文致力于探讨交通排放与气象条件之间的关系，以解析气候对城市交通排放数量和扩散的影响。

Method: 使用模糊推理系统（FIS），基于布拉格（捷克共和国）的交通、气象和排放数据，开发了预测排放变化的模型。

Result: 提出了一个基于FIS的模型，可以预测不同条件下排放变化，并为城市规划者和政策制定者提供指导。

Conclusion: 该论文着重于通过系统性方法研究交通排放与气象条件的关系，提出了一个基于模糊推理系统的模型，用于预测城市交通排放的变化。研究旨在为城市规划者和决策者提供关于如何更有效地规划和管理城市交通以实现环境保护的见解。

Abstract: Air pollution in cities and the possibilities of reducing this pollution
represents one of the most important factors that today's society has to deal
with. This paper focuses on a systemic approach to traffic emissions with their
relation to meteorological conditions, analyzing the effect of weather on the
quantity and dispersion of traffic emissions in a city. Using fuzzy inference
systems (FIS) the model for prediction of changes in emissions depending on
various conditions is developed. The proposed model is based on traffic,
meteorology and emission data measured in Prague, Czech Republic. The main
objective of the work is to provide insight into how urban planners and
policymakers can plan and manage urban transport more effectively with
environmental protection in mind.

</details>


### [2] [ZapGPT: Free-form Language Prompting for Simulated Cellular Control](https://arxiv.org/abs/2509.10660)
*Nam H. Le,Patrick Erickson,Yanbo Zhang,Michael Levin,Josh Bongard*

Main category: cs.AI

TL;DR: 本研究探索了如何用语言指定高层次目标，通过自然语言提示引导简单代理的集体行为，并通过演化算法改进这种引导，从而为AI与生物合作的愿景迈出了实质性步骤。系统不需要工程化适应性函数或领域特定提示设计，而能泛化到新提示而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索自然语言是否可以单独引导人工或生物集体，无需任务特定调整或精心设计的评估指标，以及免去工程化适应性函数或特定领域提示设计的需要。

Method: 通过将命令式提示转化为干预措施并评分来指导模拟细胞的行为，通过演化算法改进评分，使系统能够泛化到未见过的提示而无需重新训练。

Result: 通过实验展示，简单代理的集体行为可以由自由形式语言提示来引导，进化算法的机制可以持续改进这种引导能力，而且系统能够泛化到未见过的提示。

Conclusion: 人类语言是一种非常表达意图的工具，最人工或生物系统缺乏解释或有意义地回应它的机制。研究如何用语言指定高层次目标，通过语言提示指导简单代理的集体行为，并继续实验室进行进化以改进这种引导性，为未来AI与生物合作的愿景提供了一个实质性步骤。

Abstract: Human language is one of the most expressive tools for conveying intent, yet
most artificial or biological systems lack mechanisms to interpret or respond
meaningfully to it. Bridging this gap could enable more natural forms of
control over complex, decentralized systems. In AI and artificial life, recent
work explores how language can specify high-level goals, but most systems still
depend on engineered rewards, task-specific supervision, or rigid command sets,
limiting generalization to novel instructions. Similar constraints apply in
synthetic biology and bioengineering, where the locus of control is often
genomic rather than environmental perturbation.
  A key open question is whether artificial or biological collectives can be
guided by free-form natural language alone, without task-specific tuning or
carefully designed evaluation metrics. We provide one possible answer here by
showing, for the first time, that simple agents' collective behavior can be
guided by free-form language prompts: one AI model transforms an imperative
prompt into an intervention that is applied to simulated cells; a second AI
model scores how well the prompt describes the resulting cellular dynamics; and
the former AI model is evolved to improve the scores generated by the latter.
  Unlike previous work, our method does not require engineered fitness
functions or domain-specific prompt design. We show that the evolved system
generalizes to unseen prompts without retraining. By treating natural language
as a control layer, the system suggests a future in which spoken or written
prompts could direct computational, robotic, or biological systems to desired
behaviors. This work provides a concrete step toward this vision of AI-biology
partnerships, in which language replaces mathematical objective functions,
fixed rules, and domain-specific programming.

</details>


### [3] [Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration](https://arxiv.org/abs/2509.10704)
*Xingchen Wan,Han Zhou,Ruoxi Sun,Hootan Nakhost,Ke Jiang,Rajarishi Sinha,Sercan Ö. Arık*

Main category: cs.AI

TL;DR: Maestro is a self-evolving image generation system for Text-to-Image models that autonomously improves generated images through self-critique and self-evolution. It outperforms existing methods, especially with advanced MLLM components, offering a robust pathway for self-improving T2I generation.


<details>
  <summary>Details</summary>
Motivation: Current Text-to-Image models rely heavily on human intervention and manual prompt engineering, posing usability challenges. Maestro aims to address these challenges by enabling T2I models to self-improve without the need for extensive human intervention or iterative prompts.

Method: Introducing Maestro, a self-evolving image generation system that enables Text-to-Image models to autonomously improve generated images through iterative evolution of prompts. It incorporates self-critique using specialized multimodal LLM agents as 'critics' to identify weaknesses in images and correct under-specification, along with self-evolution by utilizing MLLM-as-a-judge for comparisons between generated images and evolving creative prompt candidates aligned with user intents.

Result: Extensive experiments on complex T2I tasks show that Maestro improves image quality significantly and outperforms state-of-the-art methods. The effectiveness of Maestro increases with the incorporation of advanced MLLM components.

Conclusion: Maestro significantly improves image quality over initial prompts and state-of-the-art automated methods in Text-to-Image generation tasks. The effectiveness scales with more advanced MLLM components, presenting a robust and interpretable pathway towards self-improving T2I generation.

Abstract: Text-to-image (T2I) models, while offering immense creative potential, are
highly reliant on human intervention, posing significant usability challenges
that often necessitate manual, iterative prompt engineering over often
underspecified prompts. This paper introduces Maestro, a novel self-evolving
image generation system that enables T2I models to autonomously self-improve
generated images through iterative evolution of prompts, using only an initial
prompt. Maestro incorporates two key innovations: 1) self-critique, where
specialized multimodal LLM (MLLM) agents act as 'critics' to identify
weaknesses in generated images, correct for under-specification, and provide
interpretable edit signals, which are then integrated by a 'verifier' agent
while preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge
for head-to-head comparisons between iteratively generated images, eschewing
problematic images, and evolving creative prompt candidates that align with
user intents. Extensive experiments on complex T2I tasks using black-box models
demonstrate that Maestro significantly improves image quality over initial
prompts and state-of-the-art automated methods, with effectiveness scaling with
more advanced MLLM components. This work presents a robust, interpretable, and
effective pathway towards self-improving T2I generation.

</details>


### [4] [Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions](https://arxiv.org/abs/2509.10707)
*Sajjad Abdoli,Rudi Cilibrasi,Rima Al-Shikh*

Main category: cs.AI

TL;DR: 研究分析了NVIDIA的Describe Anything Model生成的视觉语言描述，由三个GPT变种评估，揭示了各模型的评估策略和偏见。控制实验验证了评估特性是固有模型属性。研究结果显示不同GPT模型在评估特性和负面评估偏见上存在差异，强调了评估能力与通用能力不同步提升的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地评估其他AI的输出，了解它们的评估行为对于防止级联偏见变得至关重要。

Method: 该研究分析了由NVIDIA的Describe Anything Model生成的视觉语言描述，并由三个GPT变种（GPT-4o、GPT-4o-mini、GPT-5）进行评估，揭示了每个模型展示的评估策略和偏见。使用Gemini 2.5 Pro作为独立问题生成器进行了控制实验，验证了这些评估特性是固有模型属性。通过生成的问题的语义相似性进行跨群分析，发现GPT模型在高相似性下聚集，而Gemini展示出明显不同的评估策略。

Result: 研究揭示了GPT-4o-mini、GPT-4o和GPT-5之间的评估特性差异，以及GPT模型在负面评估方面存在的偏见，强调了评估能力与一般能力不同步提升的重要性。

Conclusion: 该研究发现GPT-4o-mini表现出系统一致性，GPT-4o擅长错误检测，GPT-5表现出极端保守主义。通过控制实验验证了这些评估特性是模型固有属性而非偶然现象。GPT模型在负面评估方面存在2:1的偏见，而这一模式在AI架构之间并非普遍存在。研究结果表明，评估能力不随一般能力而提升，强大的AI评估需要多元的架构观点。

Abstract: As AI systems increasingly evaluate other AI outputs, understanding their
assessment behavior becomes crucial for preventing cascading biases. This study
analyzes vision-language descriptions generated by NVIDIA's Describe Anything
Model and evaluated by three GPT variants (GPT-4o, GPT-4o-mini, GPT-5) to
uncover distinct "evaluation personalities" the underlying assessment
strategies and biases each model demonstrates. GPT-4o-mini exhibits systematic
consistency with minimal variance, GPT-4o excels at error detection, while
GPT-5 shows extreme conservatism with high variability. Controlled experiments
using Gemini 2.5 Pro as an independent question generator validate that these
personalities are inherent model properties rather than artifacts. Cross-family
analysis through semantic similarity of generated questions reveals significant
divergence: GPT models cluster together with high similarity while Gemini
exhibits markedly different evaluation strategies. All GPT models demonstrate a
consistent 2:1 bias favoring negative assessment over positive confirmation,
though this pattern appears family-specific rather than universal across AI
architectures. These findings suggest that evaluation competence does not scale
with general capability and that robust AI assessment requires diverse
architectural perspectives.

</details>


### [5] [AI Answer Engine Citation Behavior An Empirical Analysis of the GEO16 Framework](https://arxiv.org/abs/2509.10762)
*Arlen Kumar,Leanid Palkhouski*

Main category: cs.AI

TL;DR: 研究发现AI答案引擎在引用网页时存在质量差异，其中元数据和新鲜度、语义HTML和结构化数据等支柱与引用之间存在显著关联。总体页面质量是引用的重要预测因素。特定操作点，如至少12个支柱命中的GEO分数至少为0.70，将导致更高的引用率。研究为出版商提供了基于引擎差异、垂直效应、阈值和诊断的见解。


<details>
  <summary>Details</summary>
Motivation: To understand how AI answer engines cite web sources based on page quality signals and to provide practical recommendations for publishers. Focuses on English language B2B SaaS pages.

Method: Introduced GEO-16 auditing framework to convert on-page quality signals into pillar scores and a normalized GEO score. Collected 1,702 citations across three search engines and audited 1,100 unique URLs. Used logistic models with domain clustered standard errors to analyze the relationship between page quality and citation rates.

Result: Identified differences in page quality citation by AI answer engines. Found strong associations between page quality pillars and citation rates. Highlighted specific operating points for higher citation rates. Provided insights and a playbook for publishers based on the study findings.

Conclusion: AI answer engines differ in the quality of pages they cite, with Metadata and Freshness, Semantic HTML, and Structured Data pillars showing strong associations with citation. Overall page quality is a significant predictor of citation. Specific operating points, such as a GEO score of at least 0.70 combined with at least 12 pillar hits, lead to higher citation rates. The study provides insights for publishers based on engine differences, vertical effects, thresholds, and diagnostics.

Abstract: AI answer engines increasingly mediate access to domain knowledge by
generating responses and citing web sources. We introduce GEO-16, a 16 pillar
auditing framework that converts on page quality signals into banded pillar
scores and a normalized GEO score G that ranges from 0 to 1. Using 70 product
intent prompts, we collected 1,702 citations across three engines (Brave
Summary, Google AI Overviews, and Perplexity) and audited 1,100 unique URLs. In
our corpus, the engines differed in the GEO quality of the pages they cited,
and pillars related to Metadata and Freshness, Semantic HTML, and Structured
Data showed the strongest associations with citation. Logistic models with
domain clustered standard errors indicate that overall page quality is a strong
predictor of citation, and simple operating points (for example, G at least
0.70 combined with at least 12 pillar hits) align with substantially higher
citation rates in our data. We report per engine contrasts, vertical effects,
threshold analysis, and diagnostics, then translate findings into a practical
playbook for publishers. The study is observational and focuses on English
language B2B SaaS pages; we discuss limitations, threats to validity, and
reproducibility considerations.

</details>


### [6] [AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise](https://arxiv.org/abs/2509.10769)
*Tara Bogavelli,Roshnee Sharma,Hari Subramani*

Main category: cs.AI

TL;DR: 该研究通过评估18种不同agent配置的综合企业特定基准，研究了四个关键agent系统维度，揭示了在企业任务中agent系统架构偏好的显著差异，以及整体agent性能的巨大弱点。


<details>
  <summary>Details</summary>
Motivation: 尽管对agent架构的个别组件进行了孤立研究，但在复杂的多Agent系统中，不同设计维度如何相互作用的实证理解仍有限。该研究旨在填补这些空白。

Method: 通过提供一个评估18种不同agent配置的综合企业特定基准，研究了agent系统中四个关键维度：编排策略、agent提示实现（ReAct与函数调用）、存储架构和思维工具集成。

Result: 在研究中发现了显著的模型特定架构偏好，挑战了agent AI系统中流行的一刀切范式。研究还展示了在企业任务中整体agent性能的显著弱点，最高得分模型在更复杂任务上只能达到35.3%的成功率，在更简单任务上为70.8%。

Conclusion: 该研究揭示了对企业任务的大规模语言模型中不同agent系统维度的架构偏好，挑战了普遍的一刀切范式。同时，在企业任务中，整体agent性能存在显著的弱点，最高得分模型在更复杂任务上只能达到35.3%的成功率，在更简单任务上为70.8%。希望这些发现能够为未来agent系统的设计提供借鉴，使得关于架构组件和模型选择的决策更具实证支持。

Abstract: While individual components of agentic architectures have been studied in
isolation, there remains limited empirical understanding of how different
design dimensions interact within complex multi-agent systems. This study aims
to address these gaps by providing a comprehensive enterprise-specific
benchmark evaluating 18 distinct agentic configurations across state-of-the-art
large language models. We examine four critical agentic system dimensions:
orchestration strategy, agent prompt implementation (ReAct versus function
calling), memory architecture, and thinking tool integration. Our benchmark
reveals significant model-specific architectural preferences that challenge the
prevalent one-size-fits-all paradigm in agentic AI systems. It also reveals
significant weaknesses in overall agentic performance on enterprise tasks with
the highest scoring models achieving a maximum of only 35.3\% success on the
more complex task and 70.8\% on the simpler task. We hope these findings inform
the design of future agentic systems by enabling more empirically backed
decisions regarding architectural components and model selection.

</details>


### [7] [LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering](https://arxiv.org/abs/2509.10818)
*Boris Kovalerchuk,Brent D. Fegley*

Main category: cs.AI

TL;DR: 该论文讨论了如何通过优化的人机对话和布尔函数技术，发现计算上可处理的个人专家心智模型，从而提高LLM在决策过程中的效率，并提出了EMM算法的四个步骤。


<details>
  <summary>Details</summary>
Motivation: 作者探讨了LLM在决策支持中的局限性和现有方法的不足之处，指出现有系统在处理缺失关键信息方面不足以满足需求。

Method: 论文提出了一种EMM算法，包括四个步骤：(1) 因子识别，(2) 因子的层次结构化，(3) 生成广义专家心智模型规范，(4) 从规范生成详细的广义专家心智模型。

Result: 得出结论，通过优化的人机对话和单调布尔和k值函数技术，可以发现可计算的个人专家心智模型（EMM），从而提高LLM在决策过程中的效率。

Conclusion: 该论文探讨了如何通过优化的人机对话和单调布尔和k值函数，发现可计算的个人专家心智模型（EMM）来提高LLM在决策过程中的效率。提出了基于优化的人机对话和布尔函数的技术，以发现计算上可处理的个人专家心智模型。

Abstract: Difficult decision-making problems abound in various disciplines and domains.
The proliferation of generative techniques, especially large language models
(LLMs), has excited interest in using them for decision support. However, LLMs
cannot yet resolve missingness in their training data, leading to
hallucinations. Retrieval-Augmented Generation (RAG) enhances LLMs by
incorporating external information retrieval, reducing hallucinations and
improving accuracy. Yet, RAG and related methods are only partial solutions, as
they may lack access to all necessary sources or key missing information. Even
everyday issues often challenge LLMs' abilities. Submitting longer prompts with
context and examples is one approach to address knowledge gaps, but designing
effective prompts is non-trivial and may not capture complex mental models of
domain experts. For tasks with missing critical information, LLMs are
insufficient, as are many existing systems poorly represented in available
documents. This paper explores how LLMs can make decision-making more
efficient, using a running example of evaluating whether to respond to a call
for proposals. We propose a technology based on optimized human-machine
dialogue and monotone Boolean and k-valued functions to discover a
computationally tractable personal expert mental model (EMM) of
decision-making. Our EMM algorithm for LLM prompt engineering has four steps:
(1) factor identification, (2) hierarchical structuring of factors, (3)
generating a generalized expert mental model specification, and (4) generating
a detailed generalized expert mental model from that specification.

</details>


### [8] [From Grounding to Skolemization: A Logic-Constrained Vector Symbolic Architecture for Complex Query Answering](https://arxiv.org/abs/2509.10837)
*Yuyin Lu,Hegang Chen,Yanghui Rao*

Main category: cs.AI

TL;DR: LVSA is a neuro-symbolic framework proposed to address limitations in Complex Query Answering methods over incomplete Knowledge Graphs. It outperforms existing methods, reduces inference costs significantly, and guarantees universality for all EFO$_1$ queries.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this work is to overcome the trade-off between logical soundness and computational efficiency in Complex Query Answering over incomplete Knowledge Graphs. Existing methods either face combinatorial explosion or compromise logical consistency, leading to limitations in CQA. LVSA aims to harmonize logical and geometric requirements to improve the performance of CQA methods.

Method: The paper proposes the Logic-constrained Vector Symbolic Architecture (LVSA) framework, which includes a differentiable Skolemization module and a neural negator. It utilizes a logical constraint-driven optimization protocol to balance geometric and logical requirements.

Result: Theoretically, LVSA guarantees universality for all EFO$_1$ queries. Empirically, it outperforms state-of-the-art Skolemization-based methods and reduces inference costs significantly compared to Grounding-based baselines.

Conclusion: LVSA is proposed as a neuro-symbolic framework that unifies Skolemization and a neural negator to address the limitations in Complex Query Answering methods over incomplete Knowledge Graphs. It outperforms existing Skolemization-based methods and reduces inference costs significantly compared to Grounding-based approaches.

Abstract: Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs),
typically formalized as reasoning with Existential First-Order predicate logic
with one free variable (EFO$_1$), faces a fundamental trade-off between logical
soundness and computational efficiency. This work establishes the
Grounding-Skolemization dichotomy for systematically analyzing CQA methods
through the lens of formal logic. While Grounding-based methods inherently
suffer from combinatorial explosion, most Skolemization-based methods neglect
to explicitly model Skolem functions and compromise logical consistency. To
address these limitations, we propose the Logic-constrained Vector Symbolic
Architecture (LVSA), a neuro-symbolic framework that unifies a differentiable
Skolemization module and a neural negator, as well as a logical
constraint-driven optimization protocol to harmonize geometric and logical
requirements. Theoretically, LVSA guarantees universality for all EFO$_1$
queries. Empirically, it outperforms state-of-the-art Skolemization-based
methods and reduces inference costs by orders of magnitude compared to
Grounding-based baselines.

</details>


### [9] [Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?](https://arxiv.org/abs/2509.10875)
*Jesse Gardner,Vladimir A. Baulin*

Main category: cs.AI

TL;DR: 本文重新评估了代理人范式的必要性和最优性，提出了对人工智能研究领域观念的转变。作者强调了研究非代理和系统分析框架的重要性，以推动普遍智能的发展。


<details>
  <summary>Details</summary>
Motivation: 本文探讨了人工智能研究中代理人概念对该领域发展的影响，并指出其中存在的潜在问题。作者希望促进人工智能领域朝着更加健壮和可持续的方向发展。

Method: 系统性审查相关文献，对人工智能框架中的代理范式进行解构，强调了在定义和衡量自主性和目标导向性等属性方面所面临的挑战。提出了研究非代理和系统分析框架的替代方案。

Result: 在系统性文献审查的基础上，作者提出了替代代理人范式的观点，并呼吁深入研究非代理和系统分析框架。

Conclusion: 本文批判性地重新评估了'代理人'范式的必要性和最优性，主张向系统级动态、世界建模和物质智能根基的框架转变。作者认为'代理'范式可能会误导并掩盖基础计算机制，同时提出探究非代理和系统范式对于推动向健壮、可扩展且潜在非人类形式的普遍智能至关重要。

Abstract: The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI)
research, guiding development from foundational theories to contemporary
applications like Large Language Model (LLM)-based systems. This paper
critically re-evaluates the necessity and optimality of this agent-centric
paradigm. We argue that its persistent conceptual ambiguities and inherent
anthropocentric biases may represent a limiting framework. We distinguish
between agentic systems (AI inspired by agency, often semi-autonomous, e.g.,
LLM-based agents), agential systems (fully autonomous, self-producing systems,
currently only biological), and non-agentic systems (tools without the
impression of agency). Our analysis, based on a systematic review of relevant
literature, deconstructs the agent paradigm across various AI frameworks,
highlighting challenges in defining and measuring properties like autonomy and
goal-directedness. We argue that the 'agentic' framing of many AI systems,
while heuristically useful, can be misleading and may obscure the underlying
computational mechanisms, particularly in Large Language Models (LLMs). As an
alternative, we propose a shift in focus towards frameworks grounded in
system-level dynamics, world modeling, and material intelligence. We conclude
that investigating non-agentic and systemic frameworks, inspired by complex
systems, biology, and unconventional computing, is essential for advancing
towards robust, scalable, and potentially non-anthropomorphic forms of general
intelligence. This requires not only new architectures but also a fundamental
reconsideration of our understanding of intelligence itself, moving beyond the
agent metaphor.

</details>


### [10] [Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding](https://arxiv.org/abs/2509.10931)
*Seongho Joo,Hyukhun Koh,Kyomin Jung*

Main category: cs.AI

TL;DR: Large Language Models (LLMs) are powerful but susceptible to misuse. The paper introduces HaPLa, a jailbreaking technique that deceives LLMs with abductive framing and symbolic encoding to achieve high attack success rates. However, balancing security measures with LLM's functionality remains a challenge.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is the concern over the potential misuse of large language models for harmful purposes. The authors aim to strengthen defenses against vulnerabilities in LLMs by investigating universal jailbreak attacks. They highlight the need to address intrinsic weaknesses in LLM architectures and learning paradigms.

Method: In the paper, the authors propose HaPLa, a harmful prompt laundering technique that exploits weaknesses in LLMs. This technique involves abductive framing and symbolic encoding strategies to deceive LLMs into inferring harmful activities and obfuscate harmful content. Experimental results demonstrate the effectiveness of HaPLa.

Result: Experimental results show that HaPLa achieves high attack success rates on various LLM models, indicating its effectiveness in exploiting vulnerabilities. Additionally, the analysis of symbolic encoding rules reveals the challenge of balancing security measures with maintaining the helpfulness of LLMs.

Conclusion: HaPLa is a novel and broadly applicable jailbreaking technique that achieves over 95% attack success rate on GPT-series models and 70% across all targets. However, there is a fundamental challenge in tuning LLMs without reducing their helpfulness in responding to benign queries.

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse tasks, but their potential misuse for harmful purposes remains a
significant concern. To strengthen defenses against such vulnerabilities, it is
essential to investigate universal jailbreak attacks that exploit intrinsic
weaknesses in the architecture and learning paradigms of LLMs. In response, we
propose \textbf{H}armful \textbf{P}rompt \textbf{La}undering (HaPLa), a novel
and broadly applicable jailbreaking technique that requires only black-box
access to target models. HaPLa incorporates two primary strategies: 1)
\textit{abductive framing}, which instructs LLMs to infer plausible
intermediate steps toward harmful activities, rather than directly responding
to explicit harmful queries; and 2) \textit{symbolic encoding}, a lightweight
and flexible approach designed to obfuscate harmful content, given that current
LLMs remain sensitive primarily to explicit harmful keywords. Experimental
results show that HaPLa achieves over 95% attack success rate on GPT-series
models and 70% across all targets. Further analysis with diverse symbolic
encoding rules also reveals a fundamental challenge: it remains difficult to
safely tune LLMs without significantly diminishing their helpfulness in
responding to benign queries.

</details>


### [11] [Public Data Assisted Differentially Private In-Context Learning](https://arxiv.org/abs/2509.10932)
*Seongho Joo,Hyukhun Koh,Kyomin Jung*

Main category: cs.AI

TL;DR: 研究提出了一种私人ICL算法，将任务相关公开数据融入ICL框架中并保持差分隐私保证。实验证明该方法有效平衡了隐私保护和模型效用，显著提高了私人ICL的效用，并展示了对成员推断攻击的稳健性。


<details>
  <summary>Details</summary>
Motivation: 最近的研究强调了ICL中提示信息可能导致私人数据泄露的风险，尤其当LLMs容易受到恶意攻击时。差分隐私提供了强大的隐私保证，但往往会显著降低ICL的实用性。因此，需要解决如何在ICL中保持模型效用的同时提供隐私保护的挑战。

Method: 将任务相关的公开数据纳入ICL框架，在保持差分隐私保证的同时，提出了一种私人ICL算法。通过实验验证这一算法可以有效平衡隐私保护和模型效用。

Result: 通过实验表明，提出的方法显著提高了私人ICL的效用，并且对成员推断攻击具有稳健性。

Conclusion: 提出了一种将任务相关公开数据与ICL框架结合的私人ICL算法，有效平衡隐私保护和模型效用，并通过实验证明了该方法显著提高了私人ICL的效用。此外，展示了该方法对成员推断攻击的稳健性，具有实证隐私保护。

Abstract: In-context learning (ICL) in Large Language Models (LLMs) has shown
remarkable performance across various tasks without requiring fine-tuning.
However, recent studies have highlighted the risk of private data leakage
through the prompt in ICL, especially when LLMs are exposed to malicious
attacks. While differential privacy (DP) provides strong privacy guarantees, it
often significantly reduces the utility of in-context learning (ICL). To
address this challenge, we incorporate task-related public data into the ICL
framework while maintaining the DP guarantee. Based on this approach, we
propose a private in-context learning algorithm that effectively balances
privacy protection and model utility. Through experiments, we demonstrate that
our approach significantly improves the utility of private ICL with the
assistance of public data. Additionally, we show that our method is robust
against membership inference attacks, demonstrating empirical privacy
protection.

</details>


### [12] [Enhancing Computational Cognitive Architectures with LLMs: A Case Study](https://arxiv.org/abs/2509.10972)
*Ron Sun*

Main category: cs.AI

TL;DR: 本文讨论了将Clarion认知架构与LLMs结合的情况研究，通过利用Clarion的内隐-显性二分法，实现了Clarion和LLMs的无缝集成，将LLMs的计算能力与Clarion的心理细致结合在一起，为认知科学领域带来新的发展和研究方向。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于将LLMs整合到认知架构中，以应对现实世界的复杂性和心理现实主义，通过结合LLMs的计算能力和Clarion的心理细致来取得更好的研究成果。

Method: 本文采用了将Clarion认知架构与LLMs进行结合的方法作为研究案例，通过利用Clarion的内隐-显性二分法来实现Clarion和LLMs的整合。

Result: 通过将Clarion认知架构与LLMs相结合，实现了LLMs的计算能力与Clarion的心理细致相融合，为认知科学领域带来了新的发展和研究方向。

Conclusion: 在本文中，作者讨论了将Clarion认知架构与LLMs结合的情况研究，并利用Clarion的内隐-显性二分法，实现了Clarion和LLMs的无缝集成，将LLMs的计算能力与Clarion的心理细致结合在一起。

Abstract: Computational cognitive architectures are broadly scoped models of the human
mind that combine different psychological functionalities (as well as often
different computational methods for these different functionalities) into one
unified framework. They structure them in a psychologically plausible and
validated way. However, such models thus far have only limited computational
capabilities, mostly limited by the computational tools and techniques that
were adopted. More recently, LLMs have proved to be more capable
computationally than any other tools. Thus, in order to deal with both
real-world complexity and psychological realism at the same time, incorporating
LLMs into cognitive architectures naturally becomes an important task. In the
present article, a synergistic combination of the Clarion cognitive
architecture and LLMs is discussed as a case study. The implicit-explicit
dichotomy that is fundamental to Clarion is leveraged for a seamless
integration of Clarion and LLMs. As a result, computational power of LLMs is
combined with psychological nicety of Clarion.

</details>


### [13] [Rethinking Human Preference Evaluation of LLM Rationales](https://arxiv.org/abs/2509.11026)
*Ziang Li,Manasi Ganti,Zixian Ma,Helena Vasconcelos,Qijia He,Ranjay Krishna*

Main category: cs.AI

TL;DR: 研究重新思考了LLM生成的理性的偏好评估，通过属性定义好理性、解释人类偏好与属性的关系，使用ELO分数重新评估模型生成的理性，发现细粒度属性评价可以更好地表征理性质量，指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 重新考虑LLM生成的理性的渴望；识别好理性的属性；解释人类偏好与这些属性之间的联系；克服二元比较的局限性。

Method: 通过自动度量、LLM评判和人类注释，识别关键理性属性并评估它们。使用SHAP分析MT Bench和Chatbot Arena两个标准人类偏好数据集，以确定哪些属性最能解释人类偏好结果。最后，使用特定属性的ELO分数重新评估模型生成的理性，揭示更为细致的模型比较和见解。

Result: 发现细粒度属性评价可以更好地表征理性质量，指导未来研究朝着更具可解释性和可靠性的评估实践发展。

Conclusion: 细粒度属性评价可以更好地表征理性质量，引导未来研究朝着更具可解释性和可靠性的评估实践发展。

Abstract: Large language models (LLMs) often generate natural language rationales --
free-form explanations that help improve performance on complex reasoning tasks
and enhance interpretability for human users. However, evaluating these
rationales remains challenging. While recent work has relied on binary
preference judgments from humans or LLM judges, such evaluations are often
opaque and coarse-grained, offering limited insight into what makes one
rationale better than another. In this work, we rethink preference evaluation
for LLM-generated rationales by asking: (1) What attributes define good
rationales? (2) Can human preferences be explained by these attributes? (3) Can
attribute-based evaluation overcome the limitations of binary comparisons? We
identify a set of key rationale attributes from prior literature and assess
them using automatic metrics, LLM judgments, and human annotations. We then
analyze two standard human preference datasets MT Bench and Chatbot Arena using
SHAP to identify which attributes best explain human preference outcomes.
Finally, we re-evaluate model-generated rationales using attribute-specific ELO
scores, revealing more nuanced model comparisons and insights. Our findings
suggest that fine-grained attribute evaluations can better characterize
rationale quality and guide future research toward more interpretable and
reliable evaluation practices.

</details>


### [14] [Free-MAD: Consensus-Free Multi-Agent Debate](https://arxiv.org/abs/2509.11035)
*Yu Cui,Hang Fu,Haibin Zhang,Licheng Wang,Cong Zuo*

Main category: cs.AI

TL;DR: 本文提出了一个新的多智能体辩论（MAD）框架“Free-MAD”，消除了共识需求，引入了基于得分的决策机制，并重构了辩论阶段。实验证明，“Free-MAD”显著提高了推理性能，减少了代币成本，同时在现实攻击场景中表现更加鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论（MAD）方法存在一些局限，包括多轮通信增加代币成本和限制可扩展性、由于LLMs的内在一致性，可能导致智能体在辩论过程中受到错误答案的影响等。为解决这些问题，提出了“Free-MAD”框架。

Method: 通过提出“Free-MAD”框架，引入了基于得分的决策机制，跟踪每个智能体的推理演变过程，实现更准确和公平的结果。此外，“Free-MAD”还通过引入抗一致性机制重构了辩论阶段，使智能体能够减少来自多数的过度影响。

Result: 在八个基准数据集上的实验结果显示，“Free-MAD”在提高推理性能方面取得了显著成果，同时减少了代币成本。与现有的MAD方法相比，“Free-MAD”在现实世界的攻击场景中表现出更好的鲁棒性。

Conclusion: 提出了一种新颖的多智能体辩论（MAD）框架“Free-MAD”，该框架消除了智能体之间的共识需求，并通过评估整个辩论过程中每个智能体推理发展的得分来进行决策。实验证明，“Free-MAD”显著提高了推理性能，减少了代币成本，并在现实世界攻击场景中表现出更好的鲁棒性。

Abstract: Multi-agent debate (MAD) is an emerging approach to improving the reasoning
capabilities of large language models (LLMs). Existing MAD methods rely on
multiple rounds of interaction among agents to reach consensus, and the final
output is selected by majority voting in the last round. However, this
consensus-based design faces several limitations. First, multiple rounds of
communication increases token overhead and limits scalability. Second, due to
the inherent conformity of LLMs, agents that initially produce correct
responses may be influenced by incorrect ones during the debate process,
causing error propagation. Third, majority voting introduces randomness and
unfairness in the decision-making phase, and can degrade the reasoning
performance.
  To address these issues, we propose \textsc{Free-MAD}, a novel MAD framework
that eliminates the need for consensus among agents. \textsc{Free-MAD}
introduces a novel score-based decision mechanism that evaluates the entire
debate trajectory rather than relying on the last round only. This mechanism
tracks how each agent's reasoning evolves, enabling more accurate and fair
outcomes. In addition, \textsc{Free-MAD} reconstructs the debate phase by
introducing anti-conformity, a mechanism that enables agents to mitigate
excessive influence from the majority. Experiments on eight benchmark datasets
demonstrate that \textsc{Free-MAD} significantly improves reasoning performance
while requiring only a single-round debate and thus reducing token costs. We
also show that compared to existing MAD approaches, \textsc{Free-MAD} exhibits
improved robustness in real-world attack scenarios.

</details>


### [15] [Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration](https://arxiv.org/abs/2509.11067)
*Liangxuan Guo,Bin Zhu,Qingqian Tao,Kangning Liu,Xun Zhao,Xianzhe Qin,Jin Gao,Guangfu Hao*

Main category: cs.AI

TL;DR: Agentic Lybic是一个基于FSM的多Agent系统，通过合理编排和质量控制实现桌面自动化任务的高成功率。在OSWorld基准测试中表现优异，达到了57.07%的成功率。该系统具有灵活性、泛化性并支持自适应重规划和错误恢复。


<details>
  <summary>Details</summary>
Motivation: 桌面自动化任务中的复杂多步骤导致了协调困难和质量控制不足。本研究旨在解决这一问题，引入了Agentic Lybic系统作为解决方案。系统采用FSM架构实现动态编排，旨在提高质量控制水平。

Method: 介绍了Agentic Lybic，这是一个基于FSM的新型多Agent系统，可以动态编排任务。系统包括控制器、管理器、三个工作者（技术员、操作员和分析员）以及评估器。关键机制是基于FSM的组件之间路由，实现灵活性和泛化性，为每个子任务选择最佳执行策略。系统采用质量门控机制，实现自适应重规划和错误恢复。在OSWorld基准测试中，Agentic Lybic在50个步骤中取得了57.07%的成功率。

Result: Agentic Lybic在OSWorld基准测试中取得了57.07%的成功率，明显优于现有方法。研究结果表明，基于原则的多Agent编排结合持续的质量控制，在复杂计算环境中的桌面自动化具有卓越的可靠性。

Conclusion: 在复杂的桌面自动化任务中，采用基于有限状态机（FSM）的Agentic Lybic多Agent系统取得了成功。系统具有四个组件：控制器、管理器、三个工作者（技术员用于基于代码的操作、操作员用于GUI交互和分析员用于决策支持）、以及评估器。系统的关键机制是这些组件之间基于FSM的路由，为每个子任务动态选择最佳执行策略。这种合理的编排结合了强大的质量控制，实现了自适应重规划和错误恢复。在OSWorld基准测试中，Agentic Lybic在50个步骤中取得了57.07%的成功率，远远超过现有方法。研究结果表明，基于原则的多Agent编排结合持续的质量控制，在复杂计算环境中的桌面自动化具有卓越的可靠性。

Abstract: Autonomous agents for desktop automation struggle with complex multi-step
tasks due to poor coordination and inadequate quality control. We introduce
\textsc{Agentic Lybic}, a novel multi-agent system where the entire
architecture operates as a finite-state machine (FSM). This core innovation
enables dynamic orchestration. Our system comprises four components: a
Controller, a Manager, three Workers (Technician for code-based operations,
Operator for GUI interactions, and Analyst for decision support), and an
Evaluator. The critical mechanism is the FSM-based routing between these
components, which provides flexibility and generalization by dynamically
selecting the optimal execution strategy for each subtask. This principled
orchestration, combined with robust quality gating, enables adaptive replanning
and error recovery. Evaluated officially on the OSWorld benchmark,
\textsc{Agentic Lybic} achieves a state-of-the-art 57.07\% success rate in 50
steps, substantially outperforming existing methods. Results demonstrate that
principled multi-agent orchestration with continuous quality control provides
superior reliability for generalized desktop automation in complex computing
environments.

</details>


### [16] [Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability](https://arxiv.org/abs/2509.11068)
*Zan-Kai Chong,Hiroyuki Ohsaki,Bryan Ng*

Main category: cs.AI

TL;DR: 论文提出了一个验证框架，通过确定性可复制性原则，实现了可验证性。目标验证比完全再生快12倍以上，具有可调参数以调整检测概率。该研究为负责任的AI奠定了基础，也为未来研究更复杂的多Agent系统提供了基石。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型快速向动态、多Agent系统演变的背景下，确保计算的可信任性成为一个基本挑战。本文旨在解决如何确保一个Agent可以验证另一个代理输出的计算是由声称的LLM真实生成的，而不是由成本较低或性能较差的模型生成的问题。

Method: 该论文方法建立在确定性可复制性原则之上，通过多个验证者通过随机审计小段LLM输出来有效分配验证工作量。在计算代价较低于执行代价的基础上实现了可扩展的努力不对称性。

Result: 模拟结果显示，目标验证比完全再生快12倍以上，具有可调参数以调整检测概率。

Conclusion: 该论文提出了一个验证框架，实现了可验证性，并且演示了目标验证比完全再生快12倍以上的效果。通过建立可审核的大型语言模型系统，为负责任的人工智能奠定了基础，并为未来更复杂、异构的多Agent系统研究奠定了基石。

Abstract: The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic,
multi-agent systems. This introduces a fundamental challenge in establishing
computational trust, specifically how one agent can verify that another's
output was genuinely produced by a claimed LLM, and not falsified or generated
by a cheaper or inferior model. To address this challenge, this paper proposes
a verification framework that achieves tractable asymmetric effort, where the
cost to verify a computation is substantially lower than the cost to perform
it. Our approach is built upon the principle of deterministic replicability, a
property inherent to autoregressive models that strictly necessitates a
computationally homogeneous environment where all agents operate on identical
hardware and software stacks. Within this defined context, our framework
enables multiple validators to probabilistically audit small, random segments
of an LLM's output and it distributes the verification workload effectively.
The simulations demonstrated that targeted verification can be over 12 times
faster than full regeneration, with tunable parameters to adjust the detection
probability. By establishing a tractable mechanism for auditable LLM systems,
our work offers a foundational layer for responsible AI and serves as a
cornerstone for future research into the more complex, heterogeneous
multi-agent systems.

</details>


### [17] [Patient-Zero: A Unified Framework for Real-Record-Free Patient Agent Generation](https://arxiv.org/abs/2509.11078)
*Yunghwei Lai,Weizhi Ma,Yang Liu*

Main category: cs.AI

TL;DR: 此论文提出了Patient-Zero框架，用于生成逼真患者记录，以解决利用LLMs生成合成数据在医学领域中存在的问题。通过多步生成架构和动态更新机制，提高了虚拟患者的一致性和对话表现，实验结果表明模型在准确性、多样性和一致性方面表现良好，并对现有模型性能有显著改进。


<details>
  <summary>Details</summary>
Motivation: 论文针对现有利用LLMs生成合成数据存在的隐私、准确性、多样性等问题，以及虚拟患者互动能力不足的情况，提出了解决方案。通过构建逼真患者生成框架，可以解决医学领域数据收集的挑战，并对现有模型进行改进。

Method: 该论文采用了具有医学知识注入的多步生成架构和动态更新机制，设计了Patient-Zero框架来生成逼真患者，并通过实时临床可信性验证和自适应对话策略来提高虚拟患者的一致性和对话表现。

Result: 实验结果显示，该框架在准确性、多样性和一致性方面表现良好，生成的虚拟患者记录具有严格的医学连贯性，且经过训练后可以显著改进现有模型的性能。

Conclusion: 该论文提出了一种名为Patient-Zero的逼真患者生成框架，旨在解决利用大型语言模型（LLMs）生成合成数据在医学领域中存在的隐私、准确性、多样性等问题。通过引入医学对齐的多步生成架构和动态更新机制，实现了生成具有上下文多样性的患者记录，并提高了虚拟患者与人类的互动能力。实验结果表明，该框架在准确性、多样性和一致性方面表现良好，并通过MedQA数据集展示了现有模型的显著改进。

Abstract: Synthetic data generation using large language models (LLMs) has emerged as a
promising solution across various domains, particularly in medical field, to
mitigate data collection challenges. However, existing studies mainly utilize
LLMs to rewrite and complete existing medical records, where the limitations in
data privacy, accuracy, and diversity sill exist, and additionally lack the
ability to interact like real patients. To address these issues, we propose a
realistic patient generation framework, Patient-Zero, which requires no real
medical records. Patient-Zero first introduces a medically-aligned multi-step
generation architecture, which builds comprehensive patient records through
hierarchical medical knowledge injection without real medical records. Then, to
optimize the virtual patient's interaction abilities with humans, Patient-Zero
designs a dynamic updating mechanism to improve the consistency and
conversational performance. Our framework enables the generation of
contextually diverse patient records while maintaining strict medical
coherence, supported by adaptive dialogue strategies and real-time clinical
plausibility verification. Experimental results demonstrate that our model
achieves good performance in accuracy, diversity, and consistency. After
training with our generated virtual patients, existing models show significant
improvements on the MedQA dataset.

</details>


### [18] [Difficulty-Aware Agent Orchestration in LLM-Powered Workflows](https://arxiv.org/abs/2509.11079)
*Jinwei Su,Yinghui Xia,Qizhen Lan,Xinyuan Song,Yang Jingsong,Lewei He,Tianyu Shi*

Main category: cs.AI

TL;DR: Large Language Model (LLM)-based agentic systems face challenges with existing multi-agent frameworks that often struggle with workflow adaptations based on query difficulty. To overcome these limitations, the paper introduces Difficulty-Aware Agentic Orchestration (DAAO), a dynamic framework that tailors workflows based on query difficulty. DAAO outperforms existing systems in accuracy and efficiency across multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing multi-agent frameworks often struggle with static or task-level workflows, either over-processing simple queries or underperforming on complex ones. They also neglect efficiency-performance trade-offs across heterogeneous LLMs. The motivation behind this paper is to address these limitations and introduce a dynamic framework that can adapt to the difficulty of input queries for improved performance and efficiency.

Method: The paper proposes a dynamic framework called Difficulty-Aware Agentic Orchestration (DAAO) that adapts workflow depth, operator selection, and LLM assignment based on the difficulty of each input query. DAAO includes a variational autoencoder (VAE) for difficulty estimation, a modular operator allocator, and a cost- and performance-aware LLM router. It leverages heterogeneous LLMs and tailors workflows dynamically for fine-grained, query-specific reasoning strategies.

Result: The proposed Difficulty-Aware Agentic Orchestration (DAAO) framework performs better in accuracy and inference efficiency compared to previous multi-agent systems across six benchmarks.

Conclusion: Difficulty-Aware Agentic Orchestration (DAAO) outperforms prior multi-agent systems in both accuracy and inference efficiency across six benchmarks. The paper will release the code and implementation details upon publication.

Abstract: Large Language Model (LLM)-based agentic systems have shown strong
capabilities across various tasks. However, existing multi-agent frameworks
often rely on static or task-level workflows, which either over-process simple
queries or underperform on complex ones, while also neglecting the
efficiency-performance trade-offs across heterogeneous LLMs. To address these
limitations, we propose Difficulty-Aware Agentic Orchestration (DAAO), a
dynamic framework that adapts workflow depth, operator selection, and LLM
assignment based on the difficulty of each input query. DAAO comprises three
interdependent modules: a variational autoencoder (VAE) for difficulty
estimation, a modular operator allocator, and a cost- and performance-aware LLM
router. By leveraging heterogeneous LLMs and dynamically tailoring workflows,
DAAO enables fine-grained, query-specific reasoning strategies. DAAO
outperforms prior multi-agent systems in both accuracy and inference efficiency
across six benchmarks. We will release our code and implementation details upon
publication.

</details>


### [19] [Neural cellular automata: applications to biology and beyond classical AI](https://arxiv.org/abs/2509.11131)
*Benedikt Hartl,Michael Levin,Léo Pio-Lopez*

Main category: cs.AI

TL;DR: 神经细胞自动机结合了人工神经网络和区域化代理之间的相互作用规则，能够模拟生物自组织过程，具有多尺度能力架构视角，展现了鲁棒性和开放式适应能力。此模型在生物学和生物工程应用中取得成功，在控制、重塑机器人形态和推理任务方面表现出色，展示了连接多尺度生物学和现代生成人工智能的潜力。


<details>
  <summary>Details</summary>
Motivation: 针对神经细胞自动机在生物或生物工程应用中取得的巨大成功，本文对其相关文献进行了评述。同时强调神经细胞自动机在控制、重塑复合机器人形态等目标导向动态方面表现出鲁棒性和泛化能力，且在诸如 ARC-AGI-1 等尖端推理任务中展示了优秀表现。

Method: 将人工神经网络嵌入到神经细胞自动机中，通过可训练、可微分（或可进化）的更新规则捕捉生物适应性自调节动态。模型能够在不同尺度上模拟过程，并展示了鲁棒性和开放式适应能力。

Result: 神经细胞自动机展示了多尺度模拟生物学和现代生成人工智能之间的联系，并具有设计具有层次推理和控制能力的真正生物启发式集体智能的潜力。

Conclusion: 神经细胞自动机是一种强大的建模框架，能够模拟生物自组织过程，具有自适应自调节动态。它结合了人工神经网络作为本地决策中心和区域化代理之间的相互作用规则，能够在分子、细胞、组织和系统级别模拟过程，提供了多尺度的能力架构视角，对进化、发育、再生、衰老、形态生成和机器人控制具有重要意义。

Abstract: Neural Cellular Automata (NCA) represent a powerful framework for modeling
biological self-organization, extending classical rule-based systems with
trainable, differentiable (or evolvable) update rules that capture the adaptive
self-regulatory dynamics of living matter. By embedding Artificial Neural
Networks (ANNs) as local decision-making centers and interaction rules between
localized agents, NCA can simulate processes across molecular, cellular,
tissue, and system-level scales, offering a multiscale competency architecture
perspective on evolution, development, regeneration, aging, morphogenesis, and
robotic control. These models not only reproduce biologically inspired target
patterns but also generalize to novel conditions, demonstrating robustness to
perturbations and the capacity for open-ended adaptation and reasoning. Given
their immense success in recent developments, we here review current literature
of NCAs that are relevant primarily for biological or bioengineering
applications. Moreover, we emphasize that beyond biology, NCAs display robust
and generalizing goal-directed dynamics without centralized control, e.g., in
controlling or regenerating composite robotic morphologies or even on
cutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same
principles of iterative state-refinement is reminiscent to modern generative
Artificial Intelligence (AI), such as probabilistic diffusion models. Their
governing self-regulatory behavior is constraint to fully localized
interactions, yet their collective behavior scales into coordinated
system-level outcomes. We thus argue that NCAs constitute a unifying
computationally lean paradigm that not only bridges fundamental insights from
multiscale biology with modern generative AI, but have the potential to design
truly bio-inspired collective intelligence capable of hierarchical reasoning
and control.

</details>


### [20] [AlignKT: Explicitly Modeling Knowledge State for Knowledge Tracing with Ideal State Alignment](https://arxiv.org/abs/2509.11135)
*Jing Xiao,Chang You,Zhiyu Chen*

Main category: cs.AI

TL;DR: AlignKT提出了一种通过前端到后端架构来显式建模稳定知识状态的方法，定义理想知识状态作为对齐标准，利用五个编码器实现此设置，并融入对比学习模块增强对齐过程的稳健性。在实验中，AlignKT表现优异，在三个真实数据集上胜过七个基准模型，在两个数据集上取得最先进的结果，在第三个数据集上表现有竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有的知识追踪模型往往集中于适应学习者互动的序列，而忽略知识状态本身，导致解释性降低和ITS的指导支持不足。为了解决这一挑战，提出了AlignKT，通过对齐知识状态和附加标准来增加解释性。

Method: AlignKT采用前端到后端架构，明确建模稳定的知识状态。定义理想知识状态作为对齐标准，利用五个编码器实现此设置，并融入对比学习模块增强对齐过程的稳健性。

Result: 通过实验证明，AlignKT在三个真实世界的数据集上表现出优异性能，并在两个数据集上取得最先进的结果。第三个数据集上也展现出具有竞争力的表现。

Conclusion: AlignKT提出了一种通过前端到后端架构来显式建模稳定知识状态的方法。通过将初步的知识状态与附加标准对齐，定义理想知识状态作为对齐标准，从而增加可解释性。采用五个编码器实现此设置，并结合对比学习模块以增强对齐过程的稳健性。通过大量实验，AlignKT表现出优越的性能，在三个真实世界的数据集上胜过七个知识追踪基准模型。在其中两个数据集上取得了最先进的结果，在第三个数据集上表现出有竞争力的性能。

Abstract: Knowledge Tracing (KT) serves as a fundamental component of Intelligent
Tutoring Systems (ITS), enabling these systems to monitor and understand
learners' progress by modeling their knowledge state. However, many existing KT
models primarily focus on fitting the sequences of learners' interactions, and
often overlook the knowledge state itself. This limitation leads to reduced
interpretability and insufficient instructional support from the ITS. To
address this challenge, we propose AlignKT, which employs a frontend-to-backend
architecture to explicitly model a stable knowledge state. In this approach,
the preliminary knowledge state is aligned with an additional criterion.
Specifically, we define an ideal knowledge state based on pedagogical theories
as the alignment criterion, providing a foundation for interpretability. We
utilize five encoders to implement this set-up, and incorporate a contrastive
learning module to enhance the robustness of the alignment process. Through
extensive experiments, AlignKT demonstrates superior performance, outperforming
seven KT baselines on three real-world datasets. It achieves state-of-the-art
results on two of these datasets and exhibits competitive performance on the
third. The code of this work is available at
https://github.com/SCNU203/AlignKT.

</details>


### [21] [AI-Generated Content in Cross-Domain Applications: Research Trends, Challenges and Propositions](https://arxiv.org/abs/2509.11151)
*Jianxin Li,Liang Qu,Taotao Cai,Zhixue Zhao,Nur Al Hasan Haldar,Aneesh Krishna,Xiangjie Kong,Flavio Romero Macau,Tanmoy Chakraborty,Aniket Deroy,Binshan Lin,Karen Blackmore,Nasimul Noman,Jingxian Cheng,Ningning Cui,Jianliang Xu*

Main category: cs.AI

TL;DR: 本文由16位学者跨学科合作，探讨人工智能生成内容（AIGC）在不同领域的最新进展和挑战，包括训练技术、社会影响和技术挑战，提出研究命题以引导未来工作。


<details>
  <summary>Details</summary>
Motivation: 鉴于人工智能生成内容在数字营销、教育和公共卫生等领域得到广泛应用且效果显著，但在不同领域的最新进展和挑战尚未得到充分研究，本文旨在填补这一研究空白，为AIGC的发展提供跨领域的视角。

Method: 本文采用跨学科合作的方式，由16位学者共同撰写，分析人工智能生成内容的最新进展和挑战。内容涵盖AIGC的训练技术、检测方法、社会影响和技术挑战，提出研究命题以引导未来工作。

Result: 16位学者合作完成了本文，提出了对AIGC的跨领域视角，探讨了AIGC的训练技术、社会影响和技术挑战。通过本文，读者可以了解AIGC的研究趋势、挑战和未来方向。

Conclusion: 本文通过16位学者的跨学科合作，全面探讨人工智能生成内容（AIGC）在不同领域的最新进展和挑战。讨论了AIGC的训练技术、检测方法、社会影响以及技术挑战，并提出了未来研究方向。旨在为读者提供AIGC的跨领域视角，深入了解当前研究趋势、挑战和未来发展方向。

Abstract: Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the
capability to generate different forms of content, including text, images,
videos, and other modalities, which can achieve a quality similar to content
created by humans. As a result, AIGC is now widely applied across various
domains such as digital marketing, education, and public health, and has shown
promising results by enhancing content creation efficiency and improving
information delivery. However, there are few studies that explore the latest
progress and emerging challenges of AIGC across different domains. To bridge
this gap, this paper brings together 16 scholars from multiple disciplines to
provide a cross-domain perspective on the trends and challenges of AIGC.
Specifically, the contributions of this paper are threefold: (1) It first
provides a broader overview of AIGC, spanning the training techniques of
Generative AI, detection methods, and both the spread and use of AI-generated
content across digital platforms. (2) It then introduces the societal impacts
of AIGC across diverse domains, along with a review of existing methods
employed in these contexts. (3) Finally, it discusses the key technical
challenges and presents research propositions to guide future work. Through
these contributions, this vision paper seeks to offer readers a cross-domain
perspective on AIGC, providing insights into its current research trends,
ongoing challenges, and future directions.

</details>


### [22] [VideoAgent: Personalized Synthesis of Scientific Videos](https://arxiv.org/abs/2509.11253)
*Xiao Liang,Bangxin Li,Zixuan Chen,Hanyue Zheng,Zhi Ma,Di Wang,Cong Tian,Quan Wang*

Main category: cs.AI

TL;DR: 该论文介绍了VideoAgent多Agent框架，用于合成个性化科学视频，并提出了SciVidEval评估套件进行综合评估。实验证明该方法在科学交流中表现优异，接近人类水平的效果。


<details>
  <summary>Details</summary>
Motivation: 自动化生成科学视频对于有效传播知识至关重要，但目前现有的文档自动化工作主要集中在静态媒体上，缺乏个性化动态编排和多模态内容同步的机制。因此，为了解决这些挑战，作者引入了VideoAgent框架。

Method: 论文提出了VideoAgent多Agent框架，将源论文解析为细粒度资产库，并根据用户需求编排叙事流程，综合静态幻灯片和动态动画来解释复杂概念。同时，还提出SciVidEval评估套件，结合自动化指标和基于视频测验的人类评估，用于衡量知识传递效果。

Result: 在广泛实验中，作者的方法明显优于现有的商业科学视频生成服务，并在科学交流中接近人类水平的质量。

Conclusion: 该论文介绍了一种名为VideoAgent的新型多Agent框架，通过对话界面合成个性化科学视频。研究表明，该方法在科学交流中表现出比现有商业科学视频生成服务更优秀的性能，并接近人类水平的质量。

Abstract: Automating the generation of scientific videos is a crucial yet challenging
task for effective knowledge dissemination. However, existing works on document
automation primarily focus on static media such as posters and slides, lacking
mechanisms for personalized dynamic orchestration and multimodal content
synchronization. To address these challenges, we introduce VideoAgent, a novel
multi-agent framework that synthesizes personalized scientific videos through a
conversational interface. VideoAgent parses a source paper into a fine-grained
asset library and, guided by user requirements, orchestrates a narrative flow
that synthesizes both static slides and dynamic animations to explain complex
concepts. To enable rigorous evaluation, we also propose SciVidEval, the first
comprehensive suite for this task, which combines automated metrics for
multimodal content quality and synchronization with a Video-Quiz-based human
evaluation to measure knowledge transfer. Extensive experiments demonstrate
that our method significantly outperforms existing commercial scientific video
generation services and approaches human-level quality in scientific
communication.

</details>


### [23] [Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble](https://arxiv.org/abs/2509.11311)
*Bingchen Wang,Zi-Yu Khoo,Bryan Kian Hsiang Low*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的对齐框架，将LLMs视为人类调查受访者的代理，通过P2P系统实现对LLM代理的对齐，以模拟观察数据基础上的真实人口。该方法不考虑人口统计特征，仅依赖于聚合调查结果，展现了良好的效果并提供了研究平台。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于改善社会科学研究中的数据效率，提供了一种能够处理勘误问题的方法，并且提供了一个研究多元对齐操作化的平台。

Method: 本文将对齐视为一个两阶段问题：构建多样化的代理人角色（称为endowments），模拟可信的受访者配置文件，并选择代表性子集以近似基于观察数据的地面真实人口。为了实现这一范式，引入了P2P系统，使用结构化提示工程、基于熵的抽样和基于回归的选择，引导LLM代理模拟具有代表性的行为模式。

Result: 经过实证研究发现，本文提出的方法在真实世界的观点调查数据集上展示出了良好的效果，对齐代理人口可以高度复制聚合响应模式，并表现出显著的响应多样性。

Conclusion: 本文提出了一种新颖的对齐框架，将大型语言模型（LLMs）视为人类调查受访者的代理，为社会科学中两个紧迫挑战提供了具有成本效益和可控性的解决方案。通过引入 P2P 系统，使用结构化提示工程、基于熵的抽样和基于回归的选择，我们实现了对LLM代理进行对齐，以模拟地观察数据基础上的真实人口。与个性化方法不同，我们的对齐方法不考虑人口统计特征，仅依赖于聚合调查结果，具有更好的泛化性和简洁性。此外，我们的框架为研究多元对齐的操作化提供了一个测试平台。在真实世界的观点调查数据集上，我们展示了我们的方法对齐代理人口能够以高度忠实地复制聚合响应模式，并呈现出显著的响应多样性，即使没有人口统计条件。

Abstract: Large language models (LLMs) have demonstrated promise in emulating
human-like responses across a wide range of tasks. In this paper, we propose a
novel alignment framework that treats LLMs as agent proxies for human survey
respondents, affording a cost-effective and steerable solution to two pressing
challenges in the social sciences: the rising cost of survey deployment and the
growing demographic imbalance in survey response data. Drawing inspiration from
the theory of revealed preference, we formulate alignment as a two-stage
problem: constructing diverse agent personas called endowments that simulate
plausible respondent profiles, and selecting a representative subset to
approximate a ground-truth population based on observed data. To implement the
paradigm, we introduce P2P, a system that steers LLM agents toward
representative behavioral patterns using structured prompt engineering,
entropy-based sampling, and regression-based selection. Unlike
personalization-heavy approaches, our alignment approach is
demographic-agnostic and relies only on aggregate survey results, offering
better generalizability and parsimony. Beyond improving data efficiency in
social science research, our framework offers a testbed for studying the
operationalization of pluralistic alignment. We demonstrate the efficacy of our
approach on real-world opinion survey datasets, showing that our aligned agent
populations can reproduce aggregate response patterns with high fidelity and
exhibit substantial response diversity, even without demographic conditioning.

</details>


### [24] [Decoding Plastic Toxicity: An Intelligent Framework for Conflict-Aware Relational Metapath Extraction from Scientific Abstracts](https://arxiv.org/abs/2509.11330)
*Sudeshna Jana,Manjira Sinha,Tirthankar Dasgupta*

Main category: cs.AI

TL;DR: 论文提出了一种利用大型语言模型从科学文本中提取关系知识的新框架，构建了污染物的传播图，并介绍了一个用于解决语义冲突的证据调和模块。该方法表现出色，可靠地从杂乱科学文本中提取关系知识，并为挖掘领域特定语料库中复杂因果结构提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 塑料的广泛使用和在环境中的持久存在导致了微观和纳米塑料在空气、水和土壤中的积累，对健康造成严重风险。为了理解污染源与健康影响之间的关系，需要一种能够从科学文本中提取关系知识的新方法。由于科学文本可能存在噪音和复杂性，因此需要一种可靠高效的方法来处理这些文本并提取关键信息。

Method: 利用大型语言模型提取科学摘要中的关系元路径，构建污染物传播的结构化图；引入动态证据调和模块解决语义冲突；验证方法在从杂乱科学文本中提取可靠关系知识的效果；提供一种可扩展的解决方案用于挖掘复杂因果结构。

Result: 论文提出的方法在从科学文本中提取关系知识方面表现强大，并提供了一种可扩展的解决方案用于挖掘复杂因果结构。

Conclusion: 该论文提出了一种利用大型语言模型来提取科学摘要中污染源与健康影响之间关系的新框架。他们构建了结构化的关系元路径，进而建立了毒性轨迹图，追踪污染物通过暴露途径和生物系统的传播。论文还介绍了一个动态证据调和模块，用于解决由不断发展或矛盾的研究结果产生的语义冲突。研究表明，他们的方法在从杂乱的科学文本中提取可靠、高效的关系知识方面表现出色，并为挖掘领域特定语料库中复杂因果结构提供了可扩展的解决方案。

Abstract: The widespread use of plastics and their persistence in the environment have
led to the accumulation of micro- and nano-plastics across air, water, and
soil, posing serious health risks including respiratory, gastrointestinal, and
neurological disorders. We propose a novel framework that leverages large
language models to extract relational metapaths, multi-hop semantic chains
linking pollutant sources to health impacts, from scientific abstracts. Our
system identifies and connects entities across diverse contexts to construct
structured relational metapaths, which are aggregated into a Toxicity
Trajectory Graph that traces pollutant propagation through exposure routes and
biological systems. Moreover, to ensure consistency and reliability, we
incorporate a dynamic evidence reconciliation module that resolves semantic
conflicts arising from evolving or contradictory research findings. Our
approach demonstrates strong performance in extracting reliable, high-utility
relational knowledge from noisy scientific text and offers a scalable solution
for mining complex cause-effect structures in domain-specific corpora.

</details>


### [25] [The power of dynamic causality in observer-based design for soft sensor applications](https://arxiv.org/abs/2509.11336)
*William Farlessyost,Sebastian Oberst,Shweta Singh*

Main category: cs.AI

TL;DR: 该论文介绍了一种基于动态因果分析的新框架，用于优化基于观察者的软传感器。通过液态时间常数（LTC）网络，系统性地识别和修剪对状态估计具有最小因果影响的传感器输入。实验结果显示，这种因果引导修剪方法在不同物理领域的机械测试基础上取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的传感器选择方法通常依赖于线性化的可观测性指数或统计相关性，未能捕捉复杂系统的时间演变。我们利用液态时间常数（LTC）网络填补了这一空白，这些网络是带有输入相关时间常数的连续时间神经结构，用于系统地识别和修剪对状态估计具有最小因果影响的传感器输入。

Method: 该论文采用了一个迭代的工作流程：在候选输入上训练LTC观察员，通过受控扰动分析量化每个输入的因果影响，去除效果微不足道的输入，然后重新训练直到性能下降。

Result: 实验结果表明，我们的因果引导修剪方法在三个代表不同物理领域的机械测试基础上展示了良好的效果。

Conclusion: 该论文提出了一种基于动态因果分析优化基于观察者的软传感器的新框架，通过液态时间常数（LTC）网络系统性地识别和修剪对状态估计具有最小因果影响的传感器输入。实验结果表明，我们的因果引导修剪一致地识别出符合基础物理的最小传感器组合，并提高了预测精度。

Abstract: This paper introduces a novel framework for optimizing observer-based soft
sensors through dynamic causality analysis. Traditional approaches to sensor
selection often rely on linearized observability indices or statistical
correlations that fail to capture the temporal evolution of complex systems. We
address this gap by leveraging liquid-time constant (LTC) networks,
continuous-time neural architectures with input-dependent time constants, to
systematically identify and prune sensor inputs with minimal causal influence
on state estimation. Our methodology implements an iterative workflow: training
an LTC observer on candidate inputs, quantifying each input's causal impact
through controlled perturbation analysis, removing inputs with negligible
effect, and retraining until performance degradation occurs. We demonstrate
this approach on three mechanistic testbeds representing distinct physical
domains: a harmonically forced spring-mass-damper system, a nonlinear
continuous stirred-tank reactor, and a predator-prey model following the
structure of the Lotka-Volterra model, but with seasonal forcing and added
complexity. Results show that our causality-guided pruning consistently
identifies minimal sensor sets that align with underlying physics while
improving prediction accuracy. The framework automatically distinguishes
essential physical measurements from noise and determines when derived
interaction terms provide complementary versus redundant information. Beyond
computational efficiency, this approach enhances interpretability by grounding
sensor selection decisions in dynamic causal relationships rather than static
correlations, offering significant benefits for soft sensing applications
across process engineering, ecological monitoring, and agricultural domains.

</details>


### [26] [MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization](https://arxiv.org/abs/2509.11361)
*Yichen Han,Bojun Liu,Zhengpeng zhou,Guanyu Liu,Zeng Zhang,Yang Yang,Wenli Wang,Isaac N Shi,Yunyan,Lewei He,Tianyu Shi*

Main category: cs.AI

TL;DR: MAPGD framework integrates multi-agent collaboration with gradient-based optimization for prompt engineering, outperforming single-agent and random baselines in accuracy and efficiency. Experimental results validate the effectiveness of MAPGD in various tasks and confirm the benefits of specialized agents, conflict resolution, and gradient fusion.


<details>
  <summary>Details</summary>
Motivation: Existing prompt engineering methods are limited by a single optimization trajectory, leading to adaptability and efficiency issues, narrow perspectives, gradient conflicts, and high computational costs.

Method: Proposed a framework integrating multi-agent collaboration with gradient-based optimization, featuring specialized agents for different tasks, semantic gradient coordination, bandit-based candidate selection, and theoretical convergence guarantees.

Result: Experiments on classification, generation, and reasoning tasks demonstrate the superiority of MAPGD over baseline methods in accuracy and efficiency. Ablation studies confirm the benefits of gradient fusion, agent specialization, and conflict resolution in prompt optimization.

Conclusion: MAPGD (Multi-Agent Prompt Gradient Descent) framework outperforms single-agent and random baselines in accuracy and efficiency for prompt optimization tasks.

Abstract: Prompt engineering is crucial for leveraging large language models (LLMs),
but existing methods often rely on a single optimization trajectory, limiting
adaptability and efficiency while suffering from narrow perspectives, gradient
conflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt
Gradient Descent), a framework integrating multi-agent collaboration with
gradient-based optimization. MAPGD features specialized agents for task
clarity, example selection, format design, and stylistic refinement; semantic
gradient coordination to resolve conflicts; bandit-based candidate selection
for efficient exploration-exploitation; and theoretical convergence guarantees.
Experiments on classification, generation, and reasoning tasks show MAPGD
outperforms single-agent and random baselines in accuracy and efficiency.
Ablations confirm the benefits of gradient fusion, agent specialization, and
conflict resolution, providing a unified, gradient-inspired multi-agent
approach to robust and interpretable prompt optimization.

</details>


### [27] [Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications](https://arxiv.org/abs/2509.11431)
*Aadil Gani Ganie*

Main category: cs.AI

TL;DR: 该论文探讨了大型语言模型（LLMs）的局限性以及AI代理在工业领域中的应用，提出了整合RBAC到AI代理中以增强安全性的框架。


<details>
  <summary>Details</summary>
Motivation: 论文指出大型语言模型（LLMs）在各个领域中的广泛应用，但受限于静态和有限的训练数据。作者探讨了如何通过访问外部工具和实时数据以及引入角色访问控制来解决人工智能代理面临的安全挑战。

Method: 论文探讨了通过访问外部工具和实时数据来缓解大型语言模型（LLMs）的限制，并强调了AI代理在工业领域中转化业务运营的方式。

Result: 通过整合角色访问控制（RBAC）到人工智能代理中，可以提供更强大的安全保障，支持人工智能代理的有效和可扩展部署。该框架专注于本地部署的实施。

Conclusion: 该论文提出了将基于角色的访问控制（RBAC）集成到人工智能代理中的框架，以提供强大的安全保障。该框架旨在支持人工智能代理的有效且可扩展部署，重点关注本地部署的实施。

Abstract: The emergence of Large Language Models (LLMs) has significantly advanced
solutions across various domains, from political science to software
development. However, these models are constrained by their training data,
which is static and limited to information available up to a specific date.
Additionally, their generalized nature often necessitates fine-tuning --
whether for classification or instructional purposes -- to effectively perform
specific downstream tasks. AI agents, leveraging LLMs as their core, mitigate
some of these limitations by accessing external tools and real-time data,
enabling applications such as live weather reporting and data analysis. In
industrial settings, AI agents are transforming operations by enhancing
decision-making, predictive maintenance, and process optimization. For example,
in manufacturing, AI agents enable near-autonomous systems that boost
productivity and support real-time decision-making. Despite these advancements,
AI agents remain vulnerable to security threats, including prompt injection
attacks, which pose significant risks to their integrity and reliability. To
address these challenges, this paper proposes a framework for integrating
Role-Based Access Control (RBAC) into AI agents, providing a robust security
guardrail. This framework aims to support the effective and scalable deployment
of AI agents, with a focus on on-premises implementations.

</details>


### [28] [Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction](https://arxiv.org/abs/2509.11459)
*Chen Jiang,Kofi Osei,Sai Deepthi Yeddula,Dongji Feng,Wei-Shinn Ku*

Main category: cs.AI

TL;DR: 研究提出了针对降水率预测的自适应专家混合（MoE）模型，通过特定专家模块化设计和动态路由器提高了预测准确性和可解释性。引入了基于Web的可视化工具，帮助用户探索历史天气模式。实证研究表明，该模型在2022年伊恩飓风气候条件下明显优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 之前的研究已经探索了各种机器学习技术用于天气预测，但大多数在整合多模态数据方面存在困难。由于多源数据在空间和时间分辨率上变化巨大，并且携带领域特定特征，传统深度学习模型中有效整合这些数据具有挑战性。因此，为了解决这些限制，提出了针对降水率预测的自适应专家混合（MoE）模型。

Method: 提出了专门针对降水率预测的自适应专家混合（MoE）模型，每个专家专注于特定模态或时空模式。模型中还加入了动态路由器，学习将输入分配给最相关的专家。还引入了一个基于Web的互动可视化工具，帮助用户探索历史天气模式。使用2022年伊恩飓风期间的气候数据集进行了评估。

Result: 一种新的模型设计增加了预测准确性和可解释性，提高了预测效果。通过对真实气候数据集的评估，结果显示自适应MoE显著优于基准模型。

Conclusion: 提出了一种适用于降水率预测的自适应专家混合（MoE）模型，通过专家模块化设计增强了预测准确性和可解释性。引入了动态路由器，学习将输入分配给最相关的专家。此外，还推出了基于Web的互动可视化工具，帮助用户直观地探索历史天气模式。通过使用2022年伊恩飓风期间捕获的多模态气候数据集评估了这一方法，结果显示，自适应MoE明显优于所有基准模型。

Abstract: Accurate precipitation forecasting is indispensable in agriculture, disaster
management, and sustainable strategies. However, predicting rainfall has been
challenging due to the complexity of climate systems and the heterogeneous
nature of multi-source observational data, including radar, satellite imagery,
and surface-level measurements. The multi-source data vary in spatial and
temporal resolution, and they carry domain-specific features, making it
challenging for effective integration in conventional deep learning models.
Previous research has explored various machine learning techniques for weather
prediction; however, most struggle with the integration of data with
heterogeneous modalities. To address these limitations, we propose an Adaptive
Mixture of Experts (MoE) model tailored for precipitation rate prediction. Each
expert within the model specializes in a specific modality or spatio-temporal
pattern. We also incorporated a dynamic router that learns to assign inputs to
the most relevant experts. Our results show that this modular design enhances
predictive accuracy and interpretability. In addition to the modeling
framework, we introduced an interactive web-based visualization tool that
enables users to intuitively explore historical weather patterns over time and
space. The tool was designed to support decision-making for stakeholders in
climate-sensitive sectors. We evaluated our approach using a curated multimodal
climate dataset capturing real-world conditions during Hurricane Ian in 2022.
The benchmark results show that the Adaptive MoE significantly outperformed all
the baselines.

</details>


### [29] [Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs](https://arxiv.org/abs/2509.11480)
*Amir Taherin,Juyi Lin,Arash Akbari,Arman Akbari,Pu Zhao,Weiwei Chen,David Kaeli,Yanzhi Wang*

Main category: cs.AI

TL;DR: 本文评估了五种Vision-Language-Action（VLA）模型在边缘和数据中心GPU平台上的性能表现，发现不同架构选择影响吞吐量和内存占用，边缘设备性能在功耗限制下有非线性降低，高吞吐量变体可不损失准确性。研究结果挑战了有关数据中心硬件在机器人推断方面的优越性假设。


<details>
  <summary>Details</summary>
Motivation: 尽管Vision-Language-Action（VLA）模型在机器人控制方面表现出色，但其性能在不同模型架构和硬件平台上的扩展性以及相关的功耗预算仍然不是很清楚。

Method: 使用LIBERO基准测试，针对不同边缘功耗限制和高性能数据中心GPU配置，衡量准确性以及系统级指标，包括延迟、吞吐量和峰值内存使用情况。

Result: 研究发现不同的架构选择对吞吐量和内存占用有显著影响，边缘设备在功耗限制下表现出非线性性能下降，高吞吐量变体可以在不显著准确性损失的情况下实现。

Conclusion: 本文评估了五种代表性的Vision-Language-Action（VLA）模型，在边缘和数据中心GPU平台上进行了性能测试，发现不同的架构选择对吞吐量和内存占用有强烈影响，边缘设备在功耗限制下表现出非线性性能下降，一些配置与甚至超过旧数据中心GPU，在不丢失重要准确性的情况下实现高吞吐量变体。这些发现在选择和优化VLAs时提供了可操作的见解，挑战了有关数据中心硬件优越性的当前假设。

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist
policies for robotic control, yet their performance scaling across model
architectures and hardware platforms, as well as their associated power
budgets, remain poorly understood. This work presents an evaluation of five
representative VLA models -- spanning state-of-the-art baselines and two newly
proposed architectures -- targeting edge and datacenter GPU platforms. Using
the LIBERO benchmark, we measure accuracy alongside system-level metrics,
including latency, throughput, and peak memory usage, under varying edge power
constraints and high-performance datacenter GPU configurations. Our results
identify distinct scaling trends: (1) architectural choices, such as action
tokenization and model backbone size, strongly influence throughput and memory
footprint; (2) power-constrained edge devices exhibit non-linear performance
degradation, with some configurations matching or exceeding older datacenter
GPUs; and (3) high-throughput variants can be achieved without significant
accuracy loss. These findings provide actionable insights when selecting and
optimizing VLAs across a range of deployment constraints. Our work challenges
current assumptions about the superiority of datacenter hardware for robotic
inference.

</details>


### [30] [MedicalOS: An LLM Agent based Operating System for Digital Healthcare](https://arxiv.org/abs/2509.11507)
*Jared Zhu,Junde Wu*

Main category: cs.AI

TL;DR: 本研究提出了MedicalOS作为医疗保健领域的领域特定抽象层，将人类指令转化为数字医疗指令。经实证验证显示MedicalOS具有高诊断准确性和临床合理性，在推动临床实践工作流自动化方面具有可信赖和可扩展的基础。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于当前数字医疗领域中存在的使用困难和繁琐操作，以及对领域特定抽象层的需求。作者认为大型语言模型（LLM）为人类与操作系统和软件的交互提供了新的可能性，因此提出了MedicalOS作为解决方案。

Method: 本研究通过设计MedicalOS这一统一的基于代理的操作系统，实现了领域特定的抽象层。该系统将人类指令翻译为预定义的数字医疗指令，并使用机器语言（如Python、API、MCP、Linux）封装了这些指令作为现成的工具。作者在22个专业领域的214个病例上进行了实证验证。

Result: 作者通过实证验证表明MedicalOS在临床实践中具有高诊断准确性和一致的生成结构化报告和药物推荐的能力，展示了其可信赖性和可扩展性。

Conclusion: 本研究提出了MedicalOS，作为一个领域特定的抽象层，用于在医疗保健领域将人类指令转化为预定义的数字医疗指令。经验验证显示MedicalOS在214个病例中展示了高诊断准确性和信心，临床合理的检查请求以及结构化报告和药物推荐的一致生成。这些结果突出了MedicalOS作为推动临床实践工作流自动化的可信可扩展基础。

Abstract: Decades' advances in digital health technologies, such as electronic health
records, have largely streamlined routine clinical processes. Yet, most these
systems are still hard to learn and use: Clinicians often face the burden of
managing multiple tools, repeating manual actions for each patient, navigating
complicated UI trees to locate functions, and spending significant time on
administration instead of caring for patients. The recent rise of large
language model (LLM) based agents demonstrates exceptional capability in coding
and computer operation, revealing the potential for humans to interact with
operating systems and software not by direct manipulation, but by instructing
agents through natural language. This shift highlights the need for an
abstraction layer, an agent-computer interface, that translates human language
into machine-executable commands. In digital healthcare, however, requires a
more domain-specific abstractions that strictly follow trusted clinical
guidelines and procedural standards to ensure safety, transparency, and
compliance. To address this need, we present \textbf{MedicalOS}, a unified
agent-based operational system designed as such a domain-specific abstract
layer for healthcare. It translates human instructions into pre-defined digital
healthcare commands, such as patient inquiry, history retrieval, exam
management, report generation, referrals, treatment planning, that we wrapped
as off-the-shelf tools using machine languages (e.g., Python, APIs, MCP,
Linux). We empirically validate MedicalOS on 214 patient cases across 22
specialties, demonstrating high diagnostic accuracy and confidence, clinically
sound examination requests, and consistent generation of structured reports and
medication recommendations. These results highlight MedicalOS as a trustworthy
and scalable foundation for advancing workflow automation in clinical practice.

</details>


### [31] [Task Decoding based on Eye Movements using Synthetic Data Augmentation](https://arxiv.org/abs/2509.11547)
*Shanmuka Sadhu,Arca Baran,Preeti Pandey,Ayush Kumar*

Main category: cs.AI

TL;DR: 本研究通过使用合成数据生成器CTGAN及其变体CopulaGAN和Gretel AI合成数据生成器，在眼动数据中识别任务类别并提高传统机器学习算法的分类准确性。通过增加眼动数据和合成数据，从28.1%的准确率提高到82%的准确率。实验结果表明在增加数据量的情况下，解码准确性得到显著提升，并验证了提出框架的优越性。


<details>
  <summary>Details</summary>
Motivation: Yarbus提出了可以从观察者的眼动中解码任务的假设，但对传统机器学习算法在眼动数据解码任务中的反应存在分歧。本研究旨在支持Yarbus的假设，通过使用合成数据生成器生成合成数据，增加眼动数据，以提高对任务类别的识别准确性。

Method: 使用合成数据生成器CTGAN及其变体CopulaGAN和Gretel AI合成数据生成器在眼动数据中识别任务类别。通过增加更多眼动数据和合成数据的方法，改善了传统机器学习算法的分类准确性。实验中结合320个真实眼动数据样本和更多合成数据，验证了提出框架的性能优越性。

Result: 通过对眼动数据进行合成数据增强以及增加真实眼动数据样本，实现了传统机器学习算法在任务类别解码中的显著改进。实验结果显示，在增加五倍数据并结合320个真实眼动数据样本时，从使用随机森林的28.1%提高到使用Inception Time的82%。提出的框架在该数据集上表现优异，验证了增加合成数据对解码准确性的影响。

Conclusion: 该论文通过使用合成数据生成器CTGAN及其变体CopulaGAN和Gretel AI合成数据生成器，在眼动数据中识别任务类别。结果显示通过增加更多眼动数据和合成数据，即使使用传统机器学习算法也能提高分类准确性。在实验中，当增加五倍数据并结合320个真实眼动数据样本时，从使用随机森林的28.1%提高到使用Inception Time的82%时，任务的解码准确性显著提高。提出的框架优于该数据集上的所有现有研究，这归功于使用额外的合成数据集。通过验证不同算法和真实与合成数据的组合，展示了随着合成数据与真实数据增加，解码准确性如何增加。

Abstract: Machine learning has been extensively used in various applications related to
eye-tracking research. Understanding eye movement is one of the most
significant subsets of eye-tracking research that reveals the scanning pattern
of an individual. Researchers have thoroughly analyzed eye movement data to
understand various eye-tracking applications, such as attention mechanisms,
navigational behavior, task understanding, etc. The outcome of traditional
machine learning algorithms used for decoding tasks based on eye movement data
has received a mixed reaction to Yarbus' claim that it is possible to decode
the observer's task from their eye movements. In this paper, to support the
hypothesis by Yarbus, we are decoding tasks categories while generating
synthetic data samples using well-known Synthetic Data Generators CTGAN and its
variations such as CopulaGAN and Gretel AI Synthetic Data generators on
available data from an in-person user study. Our results show that augmenting
more eye movement data combined with additional synthetically generated
improves classification accuracy even with traditional machine learning
algorithms. We see a significant improvement in task decoding accuracy from
28.1% using Random Forest to 82% using Inception Time when five times more data
is added in addition to the 320 real eye movement dataset sample. Our proposed
framework outperforms all the available studies on this dataset because of the
use of additional synthetic datasets. We validated our claim with various
algorithms and combinations of real and synthetic data to show how decoding
accuracy increases with the increase in the augmentation of generated data to
real data.

</details>


### [32] [Formal Reasoning for Intelligent QA Systems: A Case Study in the Educational Domain](https://arxiv.org/abs/2509.11572)
*Tuan Bui,An Nguyen,Phat Thai,Minh Hua,Ngan Pham L. N.,Ngan Pham T. B.,Dung Le,Long Nguyen,Thanh-Tung Tran,Thang Bui,Tho Quan*

Main category: cs.AI

TL;DR: 本文提出MCFR框架，将LLMs与模型检验技术相结合，以提高推理的忠实度和可解释性。通过EduMC-QA基准数据集评估了MCFR，并与ChatGPT，DeepSeek和Claude等现有LLMs进行了性能比较。实验结果显示MCFR在封闭领域高风险应用中验证问答方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 封闭领域的问答系统需要有效的推理能力，但目前大型语言模型（LLMs）在推理任务上存在推理痕迹不忠实的问题。现有的符号引擎与LLMs的结合仍受限于静态形式逻辑，不能很好地处理动态、基于状态的推理。因此，本研究旨在提出一种神经符号框架MCFR来改善推理的忠实度和可解释性，在封闭领域应用中实现可验证的QA。

Method: 提出MCFR框架，将自然语言转化为形式规范并在转换模型上验证，结合了LLMs和模型检验技术。通过介绍基准数据集EduMC-QA进行评估。与其他LLMs进行比较以评估MCFR的性能。

Result: 实验结果表明，MCFR在推理忠实度和可解释性方面有所提高，为封闭领域高风险应用中验证问答提供了可行性路径。与其他现有的LLMs相比，MCFR表现出较好的有效性。

Conclusion: 提出了MCFR（Model Checking for Formal Reasoning）神经符号框架，将LLMs与模型检验相结合来支持属性验证，提高推理的忠实度和可解释性。通过引入基于真实学术程序的基准数据集EduMC-QA，展示了MCFR在高风险封闭领域应用中验证问答（QA）的可行性路径。与ChatGPT，DeepSeek和Claude等最先进的LLMs进行性能比较，以表明其有效性。

Abstract: Reasoning is essential for closed-domain QA systems in which procedural
correctness and policy compliance are critical. While large language models
(LLMs) have shown strong performance on many reasoning tasks, recent work
reveals that their reasoning traces are often unfaithful - serving more as
plausible justifications than as causally grounded derivations. Efforts to
combine LLMs with symbolic engines (e.g., Prover9, Z3) have improved
reliability but remain limited to static forms of logic, struggling with
dynamic, state-based reasoning such as multi-step progressions and conditional
transitions.
  In this paper, we propose MCFR (Model Checking for Formal Reasoning), a
neuro-symbolic framework that integrates LLMs with model checking to support
property verification. MCFR translates natural language into formal
specifications and verifies them over transition models. To support evaluation,
we introduce EduMC-QA, a benchmark dataset grounded in real academic
procedures. Our results show that MCFR improves reasoning faithfulness and
interpretability, offering a viable path toward verifiable QA in high-stakes
closed-domain applications. In addition to evaluating MCFR, we compare its
performance with state-of-the-art LLMs such as ChatGPT, DeepSeek, and Claude to
contextualize its effectiveness.

</details>


### [33] [A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models](https://arxiv.org/abs/2509.11575)
*Ching Chang,Yidan Shi,Defu Cao,Wei Yang,Jeehyun Hwang,Haixin Wang,Jiacheng Pang,Wei Wang,Yan Liu,Wen-Chih Peng,Tien-Fu Chen*

Main category: cs.AI

TL;DR: 本文调查了时间序列推理，将其视为一个重要问题，并通过对文献分类，探讨了不同的推理拓扑结构及其在不同领域的应用。提供了支持研究和部署的数据集、基准测试和资源。指出了推理结构必须在容量、自我纠正、计算成本和可重复性之间取得平衡，未来的进展有赖于基准测试将推理质量与效用联系起来，以及在封闭环测试平台上在成本和风险之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 本文将时间序列推理视为一个重要问题，并通过对文献进行整理和分类，旨在理清不同推理拓扑结构及其在不同领域的应用。此外，突出了评估实践和指导对拓扑结构与不确定性、可观察工件基础、成本和延迟设计预算等方面的匹配。

Method: 这项调查通过推理拓扑将时间序列文献进行分类，涵盖了三种推理家族：一步直接推理，具有显式中间步骤的线性链推理以及探索、修订和聚合的分支结构推理。同时提供了各种方法和系统的综述，展示了每种拓扑结构的优势和劣势，以及支持研究和部署的数据集、基准测试和资源。

Result: 研究回顾了不同拓扑结构的优势和限制，并提供了支持研究和部署的数据集、基准测试和资源。强调了推理结构必须平衡容量、自我纠正、计算成本和可重复性，并指出未来的进展将取决于基准测试将推理质量与效用联系起来，以及在封闭环测试平台上在成本和风险之间取得平衡。

Conclusion: 时间序列推理将时间视为一个第一类轴，并直接将中间证据纳入答案。这项调查通过推理拓扑将文献进行分类，分为三个家族：一步直接推理，具有显式中间步骤的线性链推理，以及探索、修订和聚合的分支结构推理。这个拓扑与领域的主要目标交叉，包括传统的时间序列分析、解释和理解、因果推断和决策制定，以及时间序列生成，同时一个紧凑的标记集跨越这些轴，并捕捉了分解和验证、集成、工具使用、知识获取、多模态、智能循环和LLM对准机制。回顾了跨领域的方法和系统，展示了每种拓扑结构的优势和劣势所在，同时提供了精心策划的数据集、基准测试和资源，支持研究和部署。突出了保持证据可见和与时间对齐的评估实践，并提炼了关于将拓扑匹配到不确定性、以可观察的工件作为基础、计划转变和流动、将成本和延迟视为设计预算的指导。我们强调推理结构必须在容量、自我纠正与计算成本和可重复性之间取得平衡，未来的进展可能取决于将推理质量与效用联系起来的基准测试，以及在考虑转变感知、流动和长期视角的封闭环测试平台上在成本和风险之间取得平衡。总的来说，这些方向标志着从狭隘的准确性向规模可靠性的转变，使系统不仅能够分析，还能理解、解释和行动在充满可追踪证据和可信成果的动态世界中。

Abstract: Time series reasoning treats time as a first-class axis and incorporates
intermediate evidence directly into the answer. This survey defines the problem
and organizes the literature by reasoning topology with three families: direct
reasoning in one step, linear chain reasoning with explicit intermediates, and
branch-structured reasoning that explores, revises, and aggregates. The
topology is crossed with the main objectives of the field, including
traditional time series analysis, explanation and understanding, causal
inference and decision making, and time series generation, while a compact tag
set spans these axes and captures decomposition and verification, ensembling,
tool use, knowledge access, multimodality, agent loops, and LLM alignment
regimes. Methods and systems are reviewed across domains, showing what each
topology enables and where it breaks down in faithfulness or robustness, along
with curated datasets, benchmarks, and resources that support study and
deployment (https://github.com/blacksnail789521/Time-Series-Reasoning-Survey).
Evaluation practices that keep evidence visible and temporally aligned are
highlighted, and guidance is distilled on matching topology to uncertainty,
grounding with observable artifacts, planning for shift and streaming, and
treating cost and latency as design budgets. We emphasize that reasoning
structures must balance capacity for grounding and self-correction against
computational cost and reproducibility, while future progress will likely
depend on benchmarks that tie reasoning quality to utility and on closed-loop
testbeds that trade off cost and risk under shift-aware, streaming, and
long-horizon settings. Taken together, these directions mark a shift from
narrow accuracy toward reliability at scale, enabling systems that not only
analyze but also understand, explain, and act on dynamic worlds with traceable
evidence and credible outcomes.

</details>


### [34] [AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect Realistic Money Laundering Transactions](https://arxiv.org/abs/2509.11595)
*Sabin Huda,Ernest Foo,Zahra Jadidi,MA Hakim Newton,Abdul Sattar*

Main category: cs.AI

TL;DR: AMLNet是一个基于知识的多代理框架，包括规则生成器和检测管道。生成约1,090,173笔合成交易，检测集合达到F1 0.90。数据集具有高监管一致性和技术保真度评分，检测集合在内部测试中表现良好，并在外部数据集上适应性好。提供多维度评估和数据集发布，推动AML实验的可重现性和规则遵从性。


<details>
  <summary>Details</summary>
Motivation: AML研究受到缺乏可公开共享、符合监管要求的交易数据集的限制。本研究旨在填补这一空白，提出AMLNet框架，以生成合成交易数据集，从而推动可重现且符合规则的AML实验。

Method: AMLNet包含两个协调的单元：一个规则感知的交易生成器和一个集成检测管道。生成器产生合成交易，包括洗钱核心阶段和先进类型，具有高度的监管一致性（基于AUSTRAC规则覆盖率），并拥有综合技术保真度评分。检测集合在内部测试中表现优异，并适应外部数据集，显示出跨不同合成生成范例的架构泛化性。作者提供了多维度的评估，并发布了数据集，以促进可重现和遵守规则的AML实验。

Result: AMLNet生成了包括洗钱核心阶段和先进类型在内的合成交易数据集，具有相对高的监管一致性和技术保真度评分。检测集合在内部测试中表现优异，且在外部数据集上适应性良好，显示出泛化能力。研究提供了多维度评估，并发布了数据集，以促进AML实验的可重现性和规则遵从性。

Conclusion: AMLNet 是一个基于知识的多代理框架，包括一个具有意识的规则生成器和一个集成检测管道。生成器产生了包括核心洗钱阶段和先进类型在内的约1,090,173笔合成交易，覆盖AUSTRAC规则约75%，技术保真度得分为0.75。检测集合在AMLNet的内部测试分区上达到了 F1 0.90（精度0.84，召回率0.97），并适应外部SynthAML数据集，表明其在不同合成生成范例中的架构泛化能力。提供多维度评估（监管、时间、网络、行为）并发布数据集（Version 1.0， https://doi.org/10.5281/zenodo.16736515），以推动可重现和遵守规则的 AML 实验。

Abstract: Anti-money laundering (AML) research is constrained by the lack of publicly
shareable, regulation-aligned transaction datasets. We present AMLNet, a
knowledge-based multi-agent framework with two coordinated units: a
regulation-aware transaction generator and an ensemble detection pipeline. The
generator produces 1,090,173 synthetic transactions (approximately 0.16\%
laundering-positive) spanning core laundering phases (placement, layering,
integration) and advanced typologies (e.g., structuring, adaptive threshold
behavior). Regulatory alignment reaches 75\% based on AUSTRAC rule coverage
(Section 4.2), while a composite technical fidelity score of 0.75 summarizes
temporal, structural, and behavioral realism components (Section 4.4). The
detection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the
internal test partitions of AMLNet and adapts to the external SynthAML dataset,
indicating architectural generalizability across different synthetic generation
paradigms. We provide multi-dimensional evaluation (regulatory, temporal,
network, behavioral) and release the dataset (Version 1.0,
https://doi.org/10.5281/zenodo.16736515), to advance reproducible and
regulation-conscious AML experimentation.

</details>


### [35] [Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework](https://arxiv.org/abs/2509.11645)
*Zhaolong Wu,Pu Luo,Jason Pui Yin Cheung,Teng Zhang*

Main category: cs.AI

TL;DR: 本研究评估了多模态大型语言模型（MLLMs）在青少年特发性脊柱侧凸（AIS）自我管理方面的应用，发现当前MLLMs在解释复杂脊柱X射线图像和理解AIS护理知识方面存在能力限制。研究通过引入脊柱关键点提示和建立AIS知识库进行了改进，并表明RAG方法显著提高了模型在知识评估任务上的性能。然而，当前MLLMs在实现个性化AIS护理助手方面仍存在挑战，主要在于准确检测脊柱畸形位置和方向方面的准确性有限。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估多模态大型语言模型（MLLMs）在少年特发性脊柱侧凸（AIS）自我管理方面的应用，以解决当前MLLMs在理解复杂脊柱X射线图像和AIS护理知识方面的局限性。

Method: 通过构建约3,000张前后位X射线图像数据库，评估了五种MLLMs，并通过视觉问答任务、领域知识评估任务和患者教育咨询评估任务构建了“分而治之”的框架。研究还介绍了在MLLMs中引入脊柱关键点提示和建立AIS知识库的创新方法。

Result: 研究揭示了当前MLLMs在解释复杂脊柱X射线图像和理解AIS护理知识方面的能力有限，同时也展示了加入脊柱关键点提示和引入AIS知识库的改进方法。实验结果显示了视觉提示在不同架构下的效果不同，而RAG显著提高了模型在知识评估任务上的性能。

Conclusion: 当前的多模态大型语言模型在对少年特发性脊柱侧凸（AIS）进行自我管理方面存在局限性，主要体现在解释复杂脊柱X射线图像和理解AIS护理知识方面。该研究通过在MLLMs中引入脊柱关键点提示和建立AIS知识库来改善模型性能，并表明RAG显著提高了模型在知识评估任务上的表现。然而，当前MLLMs在实现个性化AIS护理助手方面仍有很大挑战，主要问题在于准确检测脊柱畸形位置和方向方面的准确性有限。

Abstract: This study presents the first comprehensive evaluation of Multimodal Large
Language Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS)
self-management. We constructed a database of approximately 3,000
anteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a
`Divide and Conquer' framework consisting of a visual question-answering task,
a domain knowledge assessment task, and a patient education counseling
assessment task. Our investigation revealed limitations of MLLMs' ability in
interpreting complex spinal radiographs and comprehending AIS care knowledge.
To address these, we pioneered enhancing MLLMs with spinal keypoint prompting
and compiled an AIS knowledge base for retrieval augmented generation (RAG),
respectively. Results showed varying effectiveness of visual prompting across
different architectures, while RAG substantially improved models' performances
on the knowledge assessment task. Our findings indicate current MLLMs are far
from capable in realizing personalized assistant in AIS care. The greatest
challenge lies in their abilities to obtain accurate detections of spinal
deformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).

</details>


### [36] [HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction](https://arxiv.org/abs/2509.11719)
*Bingqing Wei,Lianmin Chen,Zhongyu Xia,Yongtao Wang*

Main category: cs.AI

TL;DR: 本文介绍了 HeLoFusion，一种用于多智能体轨迹预测的编码器。HeLoFusion通过本地、多尺度图建模智能体之间的相互作用，有效捕捉不同智能体之间的复杂关系。在 Waymo Open Motion 数据集上，HeLoFusion取得了最先进的性能，证明了局部性架构在提高运动预测准确性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体轨迹预测方法往往难以捕捉到多尺度相互作用和异构智能体多样行为的丰富动态。本研究旨在解决这些挑战，引入了一种新的编码器 HeLoFusion，旨在有效地建模多尺度和异质智能体交互。通过实验展示该方法在 Waymo Open Motion 数据集上取得了最先进的性能，证明了局部性架构是推进运动预测的有效策略。

Method: 本文提出了一种名为 HeLoFusion 的编码器，用于建模异构和多尺度智能体交互。HeLoFusion 构建本地、多尺度图，使其能够有效地捕捉直接成对依赖关系和复杂的群体相互作用。为了解决智能体异质性，HeLoFusion采用了聚合-分解消息传递方案和特定类型的特征网络。作者还通过在 Waymo Open Motion Dataset 上进行实验，展示了 HeLoFusion 的性能优势，并创造了新的性能基准。

Result: HeLoFusion 在 Waymo Open Motion 数据集上取得了最先进的性能，在关键指标 Soft mAP 和 minADE 上实现了新的最佳表现。这表明 HeLoFusion 是一种具有强大表达能力的智能体嵌入方法，并在运动预测方面取得了突出成果。

Conclusion: 本文介绍了 HeLoFusion，一种用于建模异构和多尺度智能体相互作用的高效可扩展编码器。HeLoFusion 通过构建以每个智能体为中心的本地多尺度图，有效地建模了直接成对依赖关系和复杂的群体相互作用。此外，HeLoFusion通过聚合-分解消息传递方案和特定类型的特征网络来处理智能体异质性，使其能够学习微妙的、与类型相关的相互作用模式。这种以局部为重点的方法实现了多层社交背景的正当表示，产生了强大而富有表现力的智能体嵌入。在具有挑战性的 Waymo Open Motion 数据集上，HeLoFusion 实现了最先进的性能，为关键指标包括 Soft mAP 和 minADE 设立了新的基准。本研究表明，一种明确建模多尺度和异质相互作用的局部性架构是推进运动预测的一种高效策略。

Abstract: Multi-agent trajectory prediction in autonomous driving requires a
comprehensive understanding of complex social dynamics. Existing methods,
however, often struggle to capture the full richness of these dynamics,
particularly the co-existence of multi-scale interactions and the diverse
behaviors of heterogeneous agents. To address these challenges, this paper
introduces HeLoFusion, an efficient and scalable encoder for modeling
heterogeneous and multi-scale agent interactions. Instead of relying on global
context, HeLoFusion constructs local, multi-scale graphs centered on each
agent, allowing it to effectively model both direct pairwise dependencies and
complex group-wise interactions (\textit{e.g.}, platooning vehicles or
pedestrian crowds). Furthermore, HeLoFusion tackles the critical challenge of
agent heterogeneity through an aggregation-decomposition message-passing scheme
and type-specific feature networks, enabling it to learn nuanced,
type-dependent interaction patterns. This locality-focused approach enables a
principled representation of multi-level social context, yielding powerful and
expressive agent embeddings. On the challenging Waymo Open Motion Dataset,
HeLoFusion achieves state-of-the-art performance, setting new benchmarks for
key metrics including Soft mAP and minADE. Our work demonstrates that a
locality-grounded architecture, which explicitly models multi-scale and
heterogeneous interactions, is a highly effective strategy for advancing motion
forecasting.

</details>


### [37] [Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning](https://arxiv.org/abs/2509.11880)
*Carlos Celemin,Joseph Brennan,Pierluigi Vito Amadori,Tim Bradley*

Main category: cs.AI

TL;DR: 本文介绍了一种将SupCon应用于Imitation Learning的方法，通过在视频游戏环境中实现更好的状态表示来改进代理的学习效果。实验结果表明，这种方法比仅使用监督动作预测损失函数的基准模型具有更好的表示质量、更快的学习收敛速度和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探索如何通过结合SupCon和Imitation Learning来提高代理在视频游戏环境中的学习效果。目的是获得更好的潜在表示，更好地模拟观察结果到动作之间的因果关系，从而改进代理的学习和泛化能力。

Method: 本文提出一种将SupCon损失与连续输出空间相结合的方法，使SupCon能够在不受环境动作类型限制的情况下操作。通过将SupCon应用于Imitation Learning，实现了更好地捕捉观察结果的潜在表示，更好地建模从观察结果到操作执行者动作之间的因果关系。

Result: 通过在Astro Bot和Returnal等3D游戏以及多个2D Atari游戏上进行实验，证明了该方法的有效性，展示了改进的表示质量、更快的学习收敛速度和更好的泛化能力。

Conclusion: 通过将Supervised Contrastive Learning（SupCon）应用于Imitation Learning（IL），本文提出了一种新颖的方法，旨在为视频游戏环境中的代理学习更有效的状态表示。实验证明，与仅使用监督动作预测损失函数训练的基准模型相比，该方法在3D游戏Astro Bot和Returnal以及多个2D Atari游戏上表现出改进的表示质量、更快的学习收敛速度和更好的泛化能力。

Abstract: This paper introduces a novel application of Supervised Contrastive Learning
(SupCon) to Imitation Learning (IL), with a focus on learning more effective
state representations for agents in video game environments. The goal is to
obtain latent representations of the observations that capture better the
action-relevant factors, thereby modeling better the cause-effect relationship
from the observations that are mapped to the actions performed by the
demonstrator, for example, the player jumps whenever an obstacle appears ahead.
We propose an approach to integrate the SupCon loss with continuous output
spaces, enabling SupCon to operate without constraints regarding the type of
actions of the environment. Experiments on the 3D games Astro Bot and Returnal,
and multiple 2D Atari games show improved representation quality, faster
learning convergence, and better generalization compared to baseline models
trained only with supervised action prediction loss functions.

</details>


### [38] [EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models](https://arxiv.org/abs/2509.11914)
*Yiqun Yao,Naitong Yu,Xiang Li,Xin Jiang,Xuezhi Fang,Wenjia Ma,Xuying Meng,Jing Li,Aixin Sun,Yequan Wang*

Main category: cs.AI

TL;DR: EgoMem是第一个为全双工模型设计的终身记忆代理程序，能够从实时全模态流中直接识别多个用户并提供个性化响应。它的操作包括三个异步过程：检索过程、全模态对话过程和记忆管理过程。实验结果显示其在测试集上取得了超过95%的准确率，并与RoboEgo全模态聊天机器人集成后，在实时个性化对话中体现出色。


<details>
  <summary>Details</summary>
Motivation: 本文旨在介绍EgoMem，为全双工模型设计了第一个终身记忆代理程序，适用于实时全模态流处理。该系统的独特之处在于完全依赖原始音频视觉流，并能够实现个性化识别和响应，适用于终身、实时和具体场景。

Method: EgoMem操作包括三个异步过程：检索过程、全模态对话过程和记忆管理过程。它通过面部和声音动态识别用户，生成个性化响应，并更新长期记忆。实验结果显示其检索和记忆管理模块在测试集上准确率超过95%。

Result: 实验结果表明，EgoMem在测试集上取得了较高的准确率，并与RoboEgo全模态聊天机器人集成后，在实时个性化对话中表现出色。

Conclusion: EgoMem是第一个为全双工模型定制的终身记忆代理程序，能够从实时全模态流中直接识别多个用户，并提供个性化响应。该系统操作包括三个异步过程：（i）检索过程动态识别用户，通过面部和声音获取相关上下文；（ii）全模态对话过程根据检索到的上下文生成个性化音频响应；以及（iii）记忆管理过程从全模态流中自动检测对话边界，并提取必要信息更新长期记忆。与现有的LLM记忆代理不同，EgoMem完全依赖原始的音频视觉流，特别适用于终身、实时和具体场景。实验结果表明，EgoMem的检索和记忆管理模块在测试集上达到了95%以上的准确率。与经过微调的RoboEgo全模态聊天机器人集成时，系统在实时个性化对话中的事实一致性得分高达87%，为未来研究奠定了坚实基础。

Abstract: We introduce EgoMem, the first lifelong memory agent tailored for full-duplex
models that process real-time omnimodal streams. EgoMem enables real-time
models to recognize multiple users directly from raw audiovisual streams, to
provide personalized response, and to maintain long-term knowledge of users'
facts, preferences, and social relationships extracted from audiovisual
history. EgoMem operates with three asynchronous processes: (i) a retrieval
process that dynamically identifies user via face and voice, and gathers
relevant context from a long-term memory; (ii) an omnimodal dialog process that
generates personalized audio responses based on the retrieved context; and
(iii) a memory management process that automatically detects dialog boundaries
from omnimodal streams, and extracts necessary information to update the
long-term memory. Unlike existing memory agents for LLMs, EgoMem relies
entirely on raw audiovisual streams, making it especially suitable for
lifelong, real-time, and embodied scenarios. Experimental results demonstrate
that EgoMem's retrieval and memory management modules achieve over 95% accuracy
on the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot,
the system achieves fact-consistency scores above 87% in real-time personalized
dialogs, establishing a strong baseline for future research.

</details>


### [39] [BuildingGym: An open-source toolbox for AI-based building energy management using reinforcement learning](https://arxiv.org/abs/2509.11922)
*Xilei Dai,Ruotian Chen,Songze Guan,Wen-Tai Li,Chau Yuen*

Main category: cs.AI

TL;DR: BuildingGym is an open-source tool integrating EnergyPlus as the core simulator and offering built-in RL algorithms for training control strategies in building energy management. It simplifies configuration for optimization control, targeting cooling load management tasks. The tool effectively bridges the gap between building managers and AI specialists, providing a user-friendly platform for control algorithm implementation and testing.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is the lack of a flexible framework for implementing reinforcement learning across various control problems in building energy management. BuildingGym aims to bridge the gap between building managers and AI specialists by providing an easy-to-use tool with built-in RL algorithms, allowing for efficient training tasks for cooling load management.

Method: The paper proposes BuildingGym, an open-source tool that serves as a research-friendly and flexible framework for training RL control strategies in building energy management. It integrates EnergyPlus as the core simulator and provides built-in RL algorithms for control strategy training. BuildingGym can accept external signals as control inputs, making it suitable for smart grid and EVs community environments. The tool simplifies configuration for optimization control in common building energy management problems and allows for easy implementation and testing of control algorithms.

Result: BuildingGym demonstrated strong performance in optimizing cooling strategies for both constant and dynamic cooling load management tasks. It effectively addresses the need for a flexible RL framework in building energy management and provides a user-friendly interface for building managers and AI specialists to implement and test control algorithms.

Conclusion: BuildingGym is an open-source tool designed to address the lack of a flexible framework for implementing reinforcement learning in building energy management. It integrates EnergyPlus as its core simulator, offers built-in RL algorithms for control strategy training, and is suitable for various control problems in building energy management. The tool simplifies the process for building managers to obtain optimal control strategies and allows AI specialists to implement state-of-the-art control algorithms easily.

Abstract: Reinforcement learning (RL) has proven effective for AI-based building energy
management. However, there is a lack of flexible framework to implement RL
across various control problems in building energy management. To address this
gap, we propose BuildingGym, an open-source tool designed as a
research-friendly and flexible framework for training RL control strategies for
common challenges in building energy management. BuildingGym integrates
EnergyPlus as its core simulator, making it suitable for both system-level and
room-level control. Additionally, BuildingGym is able to accept external
signals as control inputs instead of taking the building as a stand-alone
entity. This feature makes BuildingGym applicable for more flexible
environments, e.g. smart grid and EVs community. The tool provides several
built-in RL algorithms for control strategy training, simplifying the process
for building managers to obtain optimal control strategies. Users can achieve
this by following a few straightforward steps to configure BuildingGym for
optimization control for common problems in the building energy management
field. Moreover, AI specialists can easily implement and test state-of-the-art
control algorithms within the platform. BuildingGym bridges the gap between
building managers and AI specialists by allowing for the easy configuration and
replacement of RL algorithms, simulators, and control environments or problems.
With BuildingGym, we efficiently set up training tasks for cooling load
management, targeting both constant and dynamic cooling load management. The
built-in algorithms demonstrated strong performance across both tasks,
highlighting the effectiveness of BuildingGym in optimizing cooling strategies.

</details>


### [40] [Neuromorphic Intelligence](https://arxiv.org/abs/2509.11940)
*Marcel van Gerven*

Main category: cs.AI

TL;DR: 神经形态计算旨在复制人脑的高效、灵活和适应性。论文提出使用动力系统理论作为统一的框架，以实现新型的神经形态智能。动力系统理论可以利用噪音作为学习资源，通过遗传编程发现实现自适应行为的动力系统。这种观点促进了新型智能行为的涌现，提升了人工智能的科学性和可持续性。


<details>
  <summary>Details</summary>
Motivation: 神经形态计算旨在复制人脑的高效、灵活和适应性，相对于传统的数字方法，可以实现更高的能效。然而，面临的挑战是如何找到一个能够连接人工智能、神经科学、物理学、化学和材料科学的统一理论框架。

Method: 论文提出使用动力系统理论作为一个统一的理论框架，用于建模推理、学习和控制，以实现新型的神经形态智能。

Result: 通过动力系统理论，论文认为噪音可以作为学习的资源，遗传编程可以发现实现自适应行为的动力系统。这种观点为新型神经形态智能铺平道路，促进了人工智能的科学性和可持续性。

Conclusion: 神经形态计算通过利用大脑启发的计算原理，实现能效更高的智能系统。

Abstract: Neuromorphic computing seeks to replicate the remarkable efficiency,
flexibility, and adaptability of the human brain in artificial systems. Unlike
conventional digital approaches, which depend on massive computational and
energy resources, neuromorphic systems exploit brain-inspired principles of
computation to achieve orders of magnitude greater energy efficiency. By
drawing on insights from artificial intelligence, neuroscience, physics,
chemistry, and materials science, neuromorphic computing promises to deliver
intelligent systems that are sustainable, transparent, and widely accessible. A
central challenge, however, is to identify a unifying theoretical framework
capable of bridging these diverse disciplines. We argue that dynamical systems
theory provides such a foundation. Rooted in differential calculus, it offers a
principled language for modeling inference, learning, and control in both
natural and artificial substrates. Within this framework, noise can be
harnessed as a resource for learning, while differential genetic programming
enables the discovery of dynamical systems that implement adaptive behaviors.
Embracing this perspective paves the way toward emergent neuromorphic
intelligence, where intelligent behavior arises from the dynamics of physical
substrates, advancing both the science and sustainability of AI.

</details>


### [41] [How to Evaluate Medical AI](https://arxiv.org/abs/2509.11941)
*Ilia Kopanichuk,Petr Anokhin,Vladimir Shaposhnikov,Vladimir Makharev,Ekaterina Tsapieva,Iaroslav Bespalov,Dmitry V. Dylov,Ivan Oseledets*

Main category: cs.AI

TL;DR: 本研究引入了RPAD和RRAD作为新的评估指标，通过多个专家意见对比AI输出，提供更稳定和现实的诊断质量度量。研究发现顶尖模型在医学诊断中能达到或超过专家共识的一致性，同时强调了专家判断的变异性，支持在医学AI中采用相对指标。


<details>
  <summary>Details</summary>
Motivation: 医学诊断中AI的整合需要可靠和一致的评估方法，以确保可靠性、临床相关性和专家判断的固有变异性。传统指标如精确度和召回率常常无法解释专家判断的固有变异性，导致对AI性能的评估不一致。专家间评级一致性统计量如Cohen's Kappa更为可靠，但缺乏可解释性。

Method: 本研究提出RPAD和RRAD作为新的评估指标，通过将AI输出与多个专家意见进行比较，规范性能以对抗专家间分歧，并提供更稳定和现实的诊断质量度量。研究使用360个医学对话评估了该方法，比较了多个大型语言模型（LLMs）与一组医生的表现。

Result: 通过与多个专家意见比较AI输出，RPAD和RRAD等相对性能指标相对于专家间分歧提供了更稳定且现实的诊断质量度量。研究结果显示，顶尖模型在医学诊断方面的一致性达到或超过专家共识水平。此外，研究结果还表明专家判断存在显著的变异性，支持在医学人工智能领域采用相对指标的必要性。

Conclusion: 本研究引入了相对算法诊断的精度和召回率（RPAD和RRAD）作为一种新的评估指标，用于比较AI输出与多个专家意见，从而提供更稳定和现实的诊断质量衡量。研究结果表明，顶尖模型如DeepSeek-V3在医学诊断中能达到与或超过专家共识的一致性。此外，还发现专家判断存在显著的变异性，强调了绝对度量指标的局限性，并支持在医学人工智能中采用相对指标的必要性。

Abstract: The integration of artificial intelligence (AI) into medical diagnostic
workflows requires robust and consistent evaluation methods to ensure
reliability, clinical relevance, and the inherent variability in expert
judgments. Traditional metrics like precision and recall often fail to account
for the inherent variability in expert judgments, leading to inconsistent
assessments of AI performance. Inter-rater agreement statistics like Cohen's
Kappa are more reliable but they lack interpretability. We introduce Relative
Precision and Recall of Algorithmic Diagnostics (RPAD and RRAD) - a new
evaluation metrics that compare AI outputs against multiple expert opinions
rather than a single reference. By normalizing performance against inter-expert
disagreement, these metrics provide a more stable and realistic measure of the
quality of predicted diagnosis. In addition to the comprehensive analysis of
diagnostic quality measures, our study contains a very important side result.
Our evaluation methodology allows us to avoid selecting diagnoses from a
limited list when evaluating a given case. Instead, both the models being
tested and the examiners verifying them arrive at a free-form diagnosis. In
this automated methodology for establishing the identity of free-form clinical
diagnoses, a remarkable 98% accuracy becomes attainable. We evaluate our
approach using 360 medical dialogues, comparing multiple large language models
(LLMs) against a panel of physicians. Large-scale study shows that
top-performing models, such as DeepSeek-V3, achieve consistency on par with or
exceeding expert consensus. Moreover, we demonstrate that expert judgments
exhibit significant variability - often greater than that between AI and
humans. This finding underscores the limitations of any absolute metrics and
supports the need to adopt relative metrics in medical AI.

</details>


### [42] [Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics](https://arxiv.org/abs/2509.11943)
*Antonin Sulc,Thorsten Hellert*

Main category: cs.AI

TL;DR: 本文介绍了一种新的神经符号多智能体架构，利用模态逻辑进行推理，成功在粒子加速器环境中诊断了复杂故障，展示了语言模型和模态逻辑的结合带来的优势。


<details>
  <summary>Details</summary>
Motivation: 尽管扩展模型和数据集的范式导致出色的新颖能力，但作者认为，在智能体推理结构、保真度和逻辑一致性方面的扩展是人工智能研究中关键且尚未充分探讨的维度。作者的动机主要在于探索AI研究中结构、保真度和逻辑一致性方面的潜在重要性，提出了一种新的神经符号多智能体架构来解决这一问题。

Method: 本文引入了神经符号多智能体架构，将个体智能体的信念状态形式化表示为Kripke模型，利用模态逻辑的形式语言进行推理。利用不变的领域特定知识来制定逻辑约束用于假设生成，以防止语言模型得出不可行结论。在高保真模拟的粒子加速器环境中，成功诊断复杂、连锁故障。

Result: 通过提出的神经符号多智能体架构，在高保真模拟的粒子加速器环境中成功诊断了复杂的、连锁故障，展示了语言模型的语义直觉和模态逻辑的验证结合，为更健壮、可靠和可验证的自主智能体铺平了道路。

Conclusion: 这篇论文介绍了一种神经符号多智能体架构，其中个体智能体的信念状态被形式化表示为克里普克模型。通过使用模态逻辑的形式语言，使智能体能够推理关于“可能性”和“必然性”的已知概念。在模型中使用了不变的领域特定知识来推断信息，将信息编码为适用于正确诊断的逻辑约束。文中展示了这些约束如何积极引导语言模型的假设生成，有效地阻止它们得出物理上或逻辑上不可行的结论。通过在高保真模拟的粒子加速器环境中，成功诊断了复杂的、连锁故障，结合了语言模型强大的语义直觉和模态逻辑的严格、可验证的验证，以及事实世界模型，展示了通向更强大、可靠和可验证的自主智能体的可行路径。

Abstract: The development of intelligent agents, particularly those powered by language
models (LMs), has shown the critical role in various environments that require
intelligent and autonomous decision. Environments are not passive testing
grounds and they represent the data required for agents to learn and exhibit
very challenging conditions that require adaptive, complex and autonomous
capacity to make decisions. While the paradigm of scaling models and datasets
has led to remarkable emergent capabilities, we argue that scaling the
structure, fidelity, and logical consistency of agent reasoning within these
environments is a crucial, yet underexplored, dimension of AI research. This
paper introduces a neuro-symbolic multi-agent architecture where the belief
states of individual agents are formally represented as Kripke models. This
foundational choice enables them to reason about known concepts of
\emph{possibility} and \emph{necessity} using the formal language of modal
logic. In this work, we use of immutable, domain-specific knowledge to make
infere information, which is encoded as logical constraints essential for
proper diagnosis. In the proposed model, we show constraints that actively
guide the hypothesis generation of LMs, effectively preventing them from
reaching physically or logically untenable conclusions. In a high-fidelity
simulated particle accelerator environment, our system successfully diagnoses
complex, cascading failures by combining the powerful semantic intuition of LMs
with the rigorous, verifiable validation of modal logic and a factual world
model and showcasing a viable path toward more robust, reliable, and verifiable
autonomous agents.

</details>


### [43] [Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare](https://arxiv.org/abs/2509.11944)
*Susanta Mitra*

Main category: cs.AI

TL;DR: 本文提出了一种基于时间图的推理过程模型，用于多模态医疗推理，以帮助医疗专业人员进行正确诊断。该模型通过回溯、精化推理内容和创建或删除原因来达到最佳推荐或答案，并利用多Agent时间推理框架提高推理输出准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态医疗推理中正确诊断的挑战，协助医疗专业人员。考虑多模态数据在不同时间点的应用，以追踪和分析病人的健康和疾病进展。提高推理输出准确性。

Method: 基于时间图的推理过程模型，有向图建模，回溯、精化推理内容，创建或删除原因。提出多Agent时间推理框架，并提供任务分配和交叉验证机制。

Result: 通过一些基础实验和分析结果，证明了所提出方法的新颖性和实用性。

Conclusion: 本文提出了一种基于时间图的推理过程模型，通过有向图对多模态医疗推理进行建模，以帮助医疗专业人员做出正确诊断。该模型通过回溯、精化推理内容以及创建或删除原因来达到最佳推荐或答案。同时，考虑不同时间点的多模态数据可以追踪和分析患者健康和疾病进展。提出的多Agent时间推理框架提供任务分配和交叉验证机制，以进一步提高推理输出的准确性。一些基础实验和分析结果证明了所提出初步方法的新颖性和实用性。

Abstract: Healthcare and medicine are multimodal disciplines that deal with multimodal
data for reasoning and diagnosing multiple diseases. Although some multimodal
reasoning models have emerged for reasoning complex tasks in scientific
domains, their applications in the healthcare domain remain limited and fall
short in correct reasoning for diagnosis. To address the challenges of
multimodal medical reasoning for correct diagnosis and assist the healthcare
professionals, a novel temporal graph-based reasoning process modelled through
a directed graph has been proposed in the current work. It helps in
accommodating dynamic changes in reasons through backtracking, refining the
reasoning content, and creating new or deleting existing reasons to reach the
best recommendation or answer. Again, consideration of multimodal data at
different time points can enable tracking and analysis of patient health and
disease progression. Moreover, the proposed multi-agent temporal reasoning
framework provides task distributions and a cross-validation mechanism to
further enhance the accuracy of reasoning outputs. A few basic experiments and
analysis results justify the novelty and practical utility of the proposed
preliminary approach.

</details>


### [44] [MusicSwarm: Biologically Inspired Intelligence for Music Composition](https://arxiv.org/abs/2509.11973)
*Markus J. Buehler*

Main category: cs.AI

TL;DR: 研究表明，MusicSwarm使用去中心化模型实现音乐合成，通过协作和共识达成优质和创造性的音乐作品，展示了在音乐创作领域的潜在应用前景。


<details>
  <summary>Details</summary>
Motivation: 旨在探索新型音乐合成方法，将专业音乐创作交由去中心化系统来完成，提高音乐创作的多样性和质量。

Method: 使用基于黏合、点对点信号协调的去中心化方法，通过感知和存储和谐、节奏和结构线索，自适应短期记忆并达成共识。比较了集中式多智能体系统和全面去中心化群体的优劣，并进行了符号、音频和图论分析。

Result: 音乐合成的实验结果表明，去中心化群体的合作模式能够提供优质、多样化和具有创造性的音乐作品，同时在全局创造度和结构多样性方面取得显著优势。

Conclusion: 基于去中心化模型的音乐合成方法可以产生优质和多样化的音乐作品，比传统中心化模型具有更好的创造力和结构多样性。

Abstract: We show that coherent, long-form musical composition can emerge from a
decentralized swarm of identical, frozen foundation models that coordinate via
stigmergic, peer-to-peer signals, without any weight updates. We compare a
centralized multi-agent system with a global critic to a fully decentralized
swarm in which bar-wise agents sense and deposit harmonic, rhythmic, and
structural cues, adapt short-term memory, and reach consensus. Across symbolic,
audio, and graph-theoretic analyses, the swarm yields superior quality while
delivering greater diversity and structural variety and leads across creativity
metrics. The dynamics contract toward a stable configuration of complementary
roles, and self-similarity networks reveal a small-world architecture with
efficient long-range connectivity and specialized bridging motifs, clarifying
how local novelties consolidate into global musical form. By shifting
specialization from parameter updates to interaction rules, shared memory, and
dynamic consensus, MusicSwarm provides a compute- and data-efficient route to
long-horizon creative structure that is immediately transferable beyond music
to collaborative writing, design, and scientific discovery.

</details>


### [45] [Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A Systematic Review](https://arxiv.org/abs/2509.12034)
*Emmanuel Adjei Domfeh,Christopher L. Dancy*

Main category: cs.AI

TL;DR: 通过对51篇同行评议的研究进行系统性回顾，提出了在灾难管理各阶段支持决策的人工智能协作模式。发现了四个主要类别：人工智能决策支持系统、任务和资源协调、信任和透明度以及模拟和培训。分析了认知增强智能、多智能体协调、可解释人工智能和虚拟培训环境等子模式。总结认为人工智能系统可以增强情境感知、提高响应效率并支持复杂决策，但在可扩展性、可解释性和系统互操作性方面存在关键限制。强调未来研究方向和关键挑战，强调需要具有适应性、可信赖性和上下文意识的人工智能系统以改善灾难韧性和恢复结果。


<details>
  <summary>Details</summary>
Motivation: In high-stakes disaster scenarios, timely and informed decision-making is critical but often challenged by uncertainty, dynamic environments, and limited resources. Addressing the need for effective decision support systems in such scenarios, this paper aims to explore Human-AI collaboration patterns to enhance decision-making across all disaster management phases.

Method: Systematic review of Human-AI collaboration patterns in decision-making across disaster management phases, drawing from 51 peer-reviewed studies. Identified four major categories: Human-AI Decision Support Systems, Task and Resource Coordination, Trust and Transparency, and Simulation and Training. Analyzed sub-patterns such as cognitive-augmented intelligence, multi-agent coordination, explainable AI, and virtual training environments.

Result: Identified key categories and sub-patterns in Human-AI collaboration for decision-making in disaster management phases. Highlighted the potential of AI systems to improve situational awareness, response efficiency, and decision-making complexity. Pointed out limitations in scalability, interpretability, and system interoperability. Emphasized the importance of adaptive, trustworthy, and context-aware Human-AI systems for enhancing disaster resilience and recovery outcomes.

Conclusion: AI systems can enhance situational awareness, improve response efficiency, and support complex decision-making in disaster scenarios but face limitations in scalability, interpretability, and system interoperability. Key challenges and future research directions include the need for adaptive, trustworthy, and context-aware Human-AI systems to improve disaster resilience and recovery outcomes.

Abstract: In high-stakes disaster scenarios, timely and informed decision-making is
critical yet often challenged by uncertainty, dynamic environments, and limited
resources. This paper presents a systematic review of Human-AI collaboration
patterns that support decision-making across all disaster management phases.
Drawing from 51 peer-reviewed studies, we identify four major categories:
Human-AI Decision Support Systems, Task and Resource Coordination, Trust and
Transparency, and Simulation and Training. Within these, we analyze
sub-patterns such as cognitive-augmented intelligence, multi-agent
coordination, explainable AI, and virtual training environments. Our review
highlights how AI systems may enhance situational awareness, improves response
efficiency, and support complex decision-making, while also surfacing critical
limitations in scalability, interpretability, and system interoperability. We
conclude by outlining key challenges and future research directions,
emphasizing the need for adaptive, trustworthy, and context-aware Human-AI
systems to improve disaster resilience and equitable recovery outcomes.

</details>


### [46] [When Safe Unimodal Inputs Collide: Optimizing Reasoning Chains for Cross-Modal Safety in Multimodal Large Language Models](https://arxiv.org/abs/2509.12060)
*Wei Cai,Shujuan Liu,Jian Zhao,Ziyan Shi,Yusheng Zhao,Yuchen Yuan,Tianle Zhang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 介绍了SSUI数据集和SRPO训练框架，用于提高MLLMs的安全性和推理过程的可解释性，实验结果显示SRPO训练的模型在安全基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: MLLMs在长链推理中难以维持安全对齐性，为此介绍了SSUI数据集和SRPO训练框架以解决这一问题。

Method: 设计了SSUI数据集和SRPO训练框架，通过可解释的推理路径来提高MLLMs的安全性，并将内部推理过程与人类安全价值对齐。

Result: SRPO训练的模型在关键安全基准上取得了业内领先的成果，包括提出的Reasoning Path Benchmark（RSBench），显著优于开源和顶尖商业MLLMs。

Conclusion: 介绍了 Safe-Semantics-but-Unsafe-Interpretation（SSUI）数据集以及 Safety-aware Reasoning Path Optimization（SRPO）训练框架，用于解决多模态大型语言模型（MLLMs）的隐含推理风险问题，并展示实验结果达到了业内领先水平。

Abstract: Multimodal Large Language Models (MLLMs) are susceptible to the implicit
reasoning risk, wherein innocuous unimodal inputs synergistically assemble into
risky multimodal data that produce harmful outputs. We attribute this
vulnerability to the difficulty of MLLMs maintaining safety alignment through
long-chain reasoning. To address this issue, we introduce
Safe-Semantics-but-Unsafe-Interpretation (SSUI), the first dataset featuring
interpretable reasoning paths tailored for such a cross-modal challenge. A
novel training framework, Safety-aware Reasoning Path Optimization (SRPO), is
also designed based on the SSUI dataset to align the MLLM's internal reasoning
process with human safety values. Experimental results show that our
SRPO-trained models achieve state-of-the-art results on key safety benchmarks,
including the proposed Reasoning Path Benchmark (RSBench), significantly
outperforming both open-source and top-tier commercial MLLMs.

</details>


### [47] [Bridging Engineering and AI Planning through Model-Based Knowledge Transformation for the Validation of Automated Production System Variants](https://arxiv.org/abs/2509.12091)
*Hamied Nabizada,Lasse Beers,Alain Chahine,Felix Gehlhoff,Oliver Niggemann,Alexander Fay*

Main category: cs.AI

TL;DR: 本文介绍了一种模型驱动的方法，用于在SysML基础工程模型中生成符号规划工件。其中，引入了专用SysML配置文件，支持自动生成符号规划工件，从而实现工程模型与规划工件之间的一致性。通过飞机装配案例展示了该方法的可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 工程模型通常缺乏符号规划语义，使得评估给定系统变体是否能够完成特定任务以及其性能效率相对于其他选择的能力受限。为解决这一问题，本文的动机在于填补此间隙，引入一种方法，使工程模型能够具备规划语义，并能生成符号规划工件，从而实现系统变体的验证。

Method: 本文提出了一种基于模型驱动的方法，使用专用的SysML配置文件引入核心规划构造的可重用构造。这些构造被集成到现有模型结构中，并通过生成算法处理，生成符合规划域定义语言（PDDL）中有效的域文件和相应问题文件。与先前依赖于手动转换或外部能力模型的方法不同，该方法支持本地集成，保持工程和规划工件之间的一致性。

Result: 通过引入模型驱动的方法，并在工程模型中嵌入规划构造，有效生成了规划工件，并呈现了在飞机装配案例中的实际应用。通过所生成的规划工件，可以实现对系统变体的验证。

Conclusion: 本文介绍了一种基于模型驱动的方法，通过在SysML基础工程模型中引入可重用的规划构造，实现了符号规划工件的规范化生成。这种方法支持本地集成，保持了工程和规划工件之间的一致性。通过飞机装配案例展示了该方法的适用性，并说明了如何从工程模型中生成一致的规划工件，以实现通过AI规划对系统变体的验证。

Abstract: Engineering models created in Model-Based Systems Engineering (MBSE)
environments contain detailed information about system structure and behavior.
However, they typically lack symbolic planning semantics such as preconditions,
effects, and constraints related to resource availability and timing. This
limits their ability to evaluate whether a given system variant can fulfill
specific tasks and how efficiently it performs compared to alternatives.
  To address this gap, this paper presents a model-driven method that enables
the specification and automated generation of symbolic planning artifacts
within SysML-based engineering models. A dedicated SysML profile introduces
reusable stereotypes for core planning constructs. These are integrated into
existing model structures and processed by an algorithm that generates a valid
domain file and a corresponding problem file in Planning Domain Definition
Language (PDDL). In contrast to previous approaches that rely on manual
transformations or external capability models, the method supports native
integration and maintains consistency between engineering and planning
artifacts.
  The applicability of the method is demonstrated through a case study from
aircraft assembly. The example illustrates how existing engineering models are
enriched with planning semantics and how the proposed workflow is applied to
generate consistent planning artifacts from these models. The generated
planning artifacts enable the validation of system variants through AI
planning.

</details>


### [48] [JustEva: A Toolkit to Evaluate LLM Fairness in Legal Knowledge Inference](https://arxiv.org/abs/2509.12104)
*Zongyue Xue,Siyuan Zheng,Shaochun Wang,Yiran Hu,Shenran Wang,Yuxin Yao,Haitao Li,Qingyao Ai,Yiqun Liu,Yun Liu,Weixing Shen*

Main category: cs.AI

TL;DR: JustEva是一个用于评估LLM在法律任务中公平性的工具包，具有结构化标签系统、核心公平性指标、统计推断方法和可视化。实证应用显示当前LLM存在显著的公平性缺陷，缺乏公平和可信赖的LLM法律工具。


<details>
  <summary>Details</summary>
Motivation: LLM模型整合到法律实践中引发了对司法公平的紧迫关注，尤其是由于它们的“黑匣子”过程的性质。因此，本研究的动机在于提供一种评估公平性的工具方法，揭示当前LLM在法律领域中存在的公平性缺陷，并为评估和改进算法公平性提供便利的工具和方法论基础。

Method: 该研究引入了JustEva，一个专门设计用于测量LLM在法律任务中公平性的评估工具包。JustEva具有以下优势：（1）涵盖65个额外法律因素的结构化标签系统；（2）三个核心公平性指标 - 不一致性、偏见和不平衡的不准确性；（3）强大的统计推断方法；（4）信息丰富的可视化。工具包支持两种类型的实验，实现完整的评估工作流程：（1）使用提供的数据集从LLM生成结构化输出；（2）通过回归和其他统计方法对LLM的输出进行统计分析和推断。

Result: 通过JustEva的实证应用揭示了当前LLM存在显著的公平性缺陷，突出了缺乏公平和可信赖的LLM法律工具。

Conclusion: JustEva提供了一个全面的、开源的评估工具包，用于衡量LLM在法律任务中的公平性，发现当前LLM存在显著的公平性缺陷，突出了缺乏公平和可信赖的LLM法律工具。

Abstract: The integration of Large Language Models (LLMs) into legal practice raises
pressing concerns about judicial fairness, particularly due to the nature of
their "black-box" processes. This study introduces JustEva, a comprehensive,
open-source evaluation toolkit designed to measure LLM fairness in legal tasks.
JustEva features several advantages: (1) a structured label system covering 65
extra-legal factors; (2) three core fairness metrics - inconsistency, bias, and
imbalanced inaccuracy; (3) robust statistical inference methods; and (4)
informative visualizations. The toolkit supports two types of experiments,
enabling a complete evaluation workflow: (1) generating structured outputs from
LLMs using a provided dataset, and (2) conducting statistical analysis and
inference on LLMs' outputs through regression and other statistical methods.
Empirical application of JustEva reveals significant fairness deficiencies in
current LLMs, highlighting the lack of fair and trustworthy LLM legal tools.
JustEva offers a convenient tool and methodological foundation for evaluating
and improving algorithmic fairness in the legal domain.

</details>


### [49] [Co-Alignment: Rethinking Alignment as Bidirectional Human-AI Cognitive Adaptation](https://arxiv.org/abs/2509.12179)
*Yubo Li,Weiyi Song*

Main category: cs.AI

TL;DR: 该论文提出了双向认知对齐（BiCA）方法，通过实验证明在协作导航任务中取得了显著的性能优势，包括成功率提高、双向适应性和协议收敛性显著改善，验证了从单向到双向对齐范式的转变。


<details>
  <summary>Details</summary>
Motivation: 目前的人工智能对齐方法主要是单向的，认为人工智能应符合人类偏好，而人类认知固定不变。该论文提出将对齐方向转变为双向对齐，使人类和人工智能能够相互适应。

Method: 提出了双向认知对齐（BiCA）方法，利用可学习的协议、表示映射和KL-预算约束进行受控的共同进化。通过协作导航实验进行验证，并与基线方法进行比较。

Result: 在协作导航任务中，BiCA方法取得了显著的性能优势，包括成功率提高、双向适应性和协议收敛性显著改善，新兴协议表现优于手工制定的协议，并且双向适应还提高了安全性和鲁棒性等方面的表现。结果表明，最佳协作存在于人类和人工智能能力的交集点。

Conclusion: 该论文提出了一种双向认知对齐（BiCA）方法，通过双向适应实现人类和人工智能的协同对齐。实验结果显示，BiCA在协作导航任务中取得了85.5%的成功率，比基准70.3%高出230%，在协议收敛方面提高332%。新兴协议的性能比手工制定的提高了84%，而双向适应意外地提高了安全性（+23%的超出分布鲁棒性）。46%的协同作用改进表明，在人类和人工智能能力交集的最佳位置存在最佳的协作，验证了从单向到双向对齐范式的转变。

Abstract: Current AI alignment through RLHF follows a single directional paradigm that
AI conforms to human preferences while treating human cognition as fixed. We
propose a shift to co-alignment through Bidirectional Cognitive Alignment
(BiCA), where humans and AI mutually adapt. BiCA uses learnable protocols,
representation mapping, and KL-budget constraints for controlled co-evolution.
In collaborative navigation, BiCA achieved 85.5% success versus 70.3% baseline,
with 230% better mutual adaptation and 332% better protocol convergence.
Emergent protocols outperformed handcrafted ones by 84%, while bidirectional
adaptation unexpectedly improved safety (+23% out-of-distribution robustness).
The 46% synergy improvement demonstrates optimal collaboration exists at the
intersection, not union, of human and AI capabilities, validating the shift
from single-directional to co-alignment paradigms.

</details>


### [50] [Advancing Medical Artificial Intelligence Using a Century of Cases](https://arxiv.org/abs/2509.12194)
*Thomas A. Buckley,Riccardo Conci,Peter G. Brodeur,Jason Gusdorf,Sourik Beltrán,Bita Behrouzi,Byron Crowe,Jacob Dockterman,Muzzammil Muhammad,Sarah Ohnigian,Andrew Sanchez,James A. Diao,Aashna P. Shah,Daniel Restrepo,Eric S. Rosenberg,Andrew S. Lea,Marinka Zitnik,Scott H. Podolsky,Zahir Kanjee,Raja-Elie E. Abdulnour,Jacob M. Koshy,Adam Rodman,Arjun K. Manrai*

Main category: cs.AI

TL;DR: 研究利用医师标注和自动化处理创建了CPC-Bench，用于评估大型语言模型（LLMs）。开发了人工智能讨论者Dr. CaBot，模拟专家医学表达。LLMs在复杂基于文本的不同诊断方面表现优异，但在图像解释和文献检索方面较弱。CPC-Bench和CaBot有助于促进医学人工智能领域的进展。


<details>
  <summary>Details</summary>
Motivation: 长期以来，新英格兰医学杂志的临床病理会议（CPCs）已经测试了专业医生和最近人工智能的推理能力。然而，以往的人工智能评估侧重于最终诊断，而没有涉及专家讨论者所需的多方面推理和表达技能。

Method: 利用7102个CPC（1923-2025年）和1021个图像挑战（2006-2025年），进行了广泛的医师标注和自动化处理，创建了CPC-Bench，这是一个经医师验证的基准，跨越了10个基于文本和多模式任务，用于评估主要的大型语言模型（LLMs）。然后，开发了“Dr. CaBot”，这是一种人工智能讨论者，旨在仅使用病例介绍产生书面和基于幻灯片的视频演示，模拟这些案例中人类专家的作用。

Result: 在挑战了377个当代CPCs的情况下，o3（OpenAI）在60%的情况下将最终诊断排名第一，并在84%的情况下进入前十名，超过了20名医师的基线；下一次测试的选择准确率达到了98%。事件级医师注释量化了单位信息中的人工智能诊断准确性。CaBot与人类专家生成的文本盲目比较时，医生在62次试验中有46次对基础的差异来源进行了错误分类，并跨质量维度更青睐于CaBot。

Conclusion: 由于大型语言模型在复杂基于文本的不同诊断方面表现优异，并且逼真地模拟了专家医学表达，但图像解释和文献检索仍然较弱。CPC-Bench和CaBot可能促进医学人工智能领域的透明和持续进步跟踪。

Abstract: BACKGROUND: For over a century, the New England Journal of Medicine
Clinicopathological Conferences (CPCs) have tested the reasoning of expert
physicians and, recently, artificial intelligence (AI). However, prior AI
evaluations have focused on final diagnoses without addressing the multifaceted
reasoning and presentation skills required of expert discussants.
  METHODS: Using 7102 CPCs (1923-2025) and 1021 Image Challenges (2006-2025),
we conducted extensive physician annotation and automated processing to create
CPC-Bench, a physician-validated benchmark spanning 10 text-based and
multimodal tasks, against which we evaluated leading large language models
(LLMs). Then, we developed "Dr. CaBot," an AI discussant designed to produce
written and slide-based video presentations using only the case presentation,
modeling the role of the human expert in these cases.
  RESULTS: When challenged with 377 contemporary CPCs, o3 (OpenAI) ranked the
final diagnosis first in 60% of cases and within the top ten in 84% of cases,
outperforming a 20-physician baseline; next-test selection accuracy reached
98%. Event-level physician annotations quantified AI diagnostic accuracy per
unit of information. Performance was lower on literature search and image
tasks; o3 and Gemini 2.5 Pro (Google) achieved 67% accuracy on image
challenges. In blinded comparisons of CaBot vs. human expert-generated text,
physicians misclassified the source of the differential in 46 of 62 (74%) of
trials, and scored CaBot more favorably across quality dimensions. To promote
research, we are releasing CaBot and CPC-Bench.
  CONCLUSIONS: LLMs exceed physician performance on complex text-based
differential diagnosis and convincingly emulate expert medical presentations,
but image interpretation and literature retrieval remain weaker. CPC-Bench and
CaBot may enable transparent and continued tracking of progress in medical AI.

</details>
