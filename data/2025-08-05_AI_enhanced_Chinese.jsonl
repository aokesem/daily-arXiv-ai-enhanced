{"id": "2508.00844", "categories": ["cs.AI", "cs.ET", "cs.MA", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2508.00844", "abs": "https://arxiv.org/abs/2508.00844", "authors": ["Christopher Wissuchek", "Patrick Zschech"], "title": "Exploring Agentic Artificial Intelligence Systems: Towards a Typological Framework", "comment": "Preprint accepted for archival and presentation at the Pacific-Asia\n  Conference on Information Systems (PACIS) 2025, Kuala Lumpur, Malaysia", "summary": "Artificial intelligence (AI) systems are evolving beyond passive tools into\nautonomous agents capable of reasoning, adapting, and acting with minimal human\nintervention. Despite their growing presence, a structured framework is lacking\nto classify and compare these systems. This paper develops a typology of\nagentic AI systems, introducing eight dimensions that define their cognitive\nand environmental agency in an ordinal structure. Using a multi-phase\nmethodological approach, we construct and refine this typology, which is then\nevaluated through a human-AI hybrid approach and further distilled into\nconstructed types. The framework enables researchers and practitioners to\nanalyze varying levels of agency in AI systems. By offering a structured\nperspective on the progression of AI capabilities, the typology provides a\nfoundation for assessing current systems and anticipating future developments\nin agentic AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u548c\u6bd4\u8f83AI\u7cfb\u7edf\u7684\u7ed3\u6784\u6846\u67b6\uff0c\u5b9a\u4e49\u4e868\u4e2a\u7ef4\u5ea6\u6765\u63cf\u8ff0AI\u7cfb\u7edf\u7684\u8ba4\u77e5\u548c\u73af\u5883\u4ee3\u7406\u80fd\u529b\u3002\u91c7\u7528\u591a\u9636\u6bb5\u65b9\u6cd5\u6784\u5efa\u548c\u7ec6\u5316\u4e86\u4ee3\u7406AI\u7cfb\u7edf\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\u6df7\u5408\u65b9\u6cd5\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u63d0\u70bc\u4e3a\u6784\u5efa\u7c7b\u578b\u3002\u8fd9\u4e2a\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u80fd\u591f\u5206\u6790AI\u7cfb\u7edf\u4e2d\u4e0d\u540c\u7ea7\u522b\u7684\u4ee3\u7406\u80fd\u529b\uff0c\u4e3a\u8bc4\u4f30\u5f53\u524d\u7cfb\u7edf\u5e76\u9884\u6d4b\u672a\u6765\u7684\u4ee3\u7406AI\u53d1\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5b58\u5728\u8d8a\u6765\u8d8a\u591a\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u6846\u67b6\u6765\u5bf9\u8fd9\u4e9b\u7cfb\u7edf\u8fdb\u884c\u5206\u7c7b\u548c\u6bd4\u8f83\u3002\u8be5\u8bba\u6587\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u53d1\u5c55\u4e86\u4e00\u79cd\u4ee3\u7406AI\u7cfb\u7edf\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u4ee5\u4fbf\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u80fd\u591f\u5206\u6790AI\u7cfb\u7edf\u4e2d\u4e0d\u540c\u7ea7\u522b\u7684\u4ee3\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u65b9\u6cd5\u8bba\uff0c\u6784\u5efa\u548c\u7ec6\u5316\u4e86\u4ee3\u7406AI\u7cfb\u7edf\u7684\u5206\u7c7b\u6846\u67b6\u3002\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\u6df7\u5408\u65b9\u6cd5\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u63d0\u70bc\u4e3a\u6784\u5efa\u7c7b\u578b\u3002", "result": "\u8bba\u6587\u5efa\u7acb\u4e86\u63cf\u8ff0\u4ee3\u7406AI\u7cfb\u7edf\u8ba4\u77e5\u548c\u73af\u5883\u4ee3\u7406\u80fd\u529b\u7684\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u8bc4\u4f30\u548c\u63d0\u70bc\u5f97\u5230\u4e86\u6784\u5efa\u7684\u7c7b\u578b\u3002\u8fd9\u4e2a\u6846\u67b6\u4e3a\u8bc4\u4f30\u5f53\u524d\u7cfb\u7edf\u548c\u9884\u6d4b\u672a\u6765\u4ee3\u7406AI\u53d1\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u548c\u6bd4\u8f83AI\u7cfb\u7edf\u7684\u7ed3\u6784\u6846\u67b6\uff0c\u5b9a\u4e49\u4e868\u4e2a\u7ef4\u5ea6\u6765\u63cf\u8ff0AI\u7cfb\u7edf\u7684\u8ba4\u77e5\u548c\u73af\u5883\u4ee3\u7406\u80fd\u529b\u3002\u901a\u8fc7\u7814\u7a76\u4eba\u5458\u4e0eAI\u6df7\u5408\u65b9\u6cd5\u7684\u8bc4\u4f30\uff0c\u5c06\u8be5\u6846\u67b6\u8fdb\u4e00\u6b65\u7cbe\u70bc\u4e3a\u6784\u5efa\u7684\u7c7b\u578b\u3002\u8fd9\u4e2a\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u80fd\u591f\u5206\u6790AI\u7cfb\u7edf\u4e2d\u4e0d\u540c\u7ea7\u522b\u7684\u4ee3\u7406\u80fd\u529b\uff0c\u4e3a\u8bc4\u4f30\u5f53\u524d\u7cfb\u7edf\u5e76\u9884\u6d4b\u672a\u6765\u7684\u4ee3\u7406AI\u53d1\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.00853", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00853", "abs": "https://arxiv.org/abs/2508.00853", "authors": ["Kei Itoh"], "title": "A Formal Framework for the Definition of 'State': Hierarchical Representation and Meta-Universe Interpretation", "comment": "43 pages, 8 figures, 8 Tables, in English, in Japanese", "summary": "This study aims to reinforce the theoretical foundation for diverse\nsystems--including the axiomatic definition of intelligence--by introducing a\nmathematically rigorous and unified formal structure for the concept of\n'state,' which has long been used without consensus or formal clarity. First, a\n'hierarchical state grid' composed of two axes--state depth and mapping\nhierarchy--is proposed to provide a unified notational system applicable across\nmathematical, physical, and linguistic domains. Next, the 'Intermediate\nMeta-Universe (IMU)' is introduced to enable explicit descriptions of definers\n(ourselves) and the languages we use, thereby allowing conscious meta-level\noperations while avoiding self-reference and logical inconsistency. Building on\nthis meta-theoretical foundation, this study expands inter-universal theory\nbeyond mathematics to include linguistic translation and agent integration,\nintroducing the conceptual division between macrocosm-inter-universal and\nmicrocosm-inter-universal operations for broader expressivity. Through these\ncontributions, this paper presents a meta-formal logical framework--grounded in\nthe principle of definition = state--that spans time, language, agents, and\noperations, providing a mathematically robust foundation applicable to the\ndefinition of intelligence, formal logic, and scientific theory at large.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u7ed3\u6784\u6765\u52a0\u5f3a\u591a\u6837\u5316\u7cfb\u7edf\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5f15\u5165\u4e86'\u5206\u5c42\u72b6\u6001\u7f51\u683c'\u548c'\u4e2d\u95f4\u5143\u5b87\u5b99'\u7684\u6982\u5ff5\uff0c\u62d3\u5c55\u4e86\u8d85\u5b87\u5b99\u7406\u8bba\u7684\u9002\u7528\u8303\u56f4\u3002\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b9a\u4e49=\u72b6\u6001\u539f\u5219\u7684\u5143\u5f62\u5f0f\u903b\u8f91\u6846\u67b6\uff0c\u4e3a\u667a\u80fd\u5b9a\u4e49\u548c\u79d1\u5b66\u7406\u8bba\u63d0\u4f9b\u4e86\u6570\u5b66\u7a33\u5065\u57fa\u7840\u3002", "motivation": "\u586b\u8865\u4e86\u957f\u671f\u5b58\u5728\u7f3a\u4e4f\u5171\u8bc6\u6216\u5f62\u5f0f\u6e05\u6670\u7684'\u72b6\u6001'\u6982\u5ff5\uff0c\u52a0\u5f3a\u591a\u6837\u5316\u7cfb\u7edf\u7684\u7406\u8bba\u57fa\u7840\uff0c\u62d3\u5c55\u4e86\u8d85\u5b87\u5b99\u7406\u8bba\u7684\u9002\u7528\u8303\u56f4\uff0c\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u8868\u8fbe\u6027\u3002\u4e3a\u667a\u80fd\u5b9a\u4e49\u3001\u5f62\u5f0f\u903b\u8f91\u548c\u79d1\u5b66\u7406\u8bba\u63d0\u4f9b\u4e86\u6570\u5b66\u7a33\u5065\u57fa\u7840\u3002", "method": "\u4ecb\u7ecd\u4e86'\u5206\u5c42\u72b6\u6001\u7f51\u683c'\u548c'\u4e2d\u95f4\u5143\u5b87\u5b99'\u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u63d0\u4f9b\u7edf\u4e00\u7684\u7b26\u53f7\u4f53\u7cfb\u548c\u5b9e\u73b0\u5bf9\u5b9a\u4e49\u8005\u548c\u8bed\u8a00\u7684\u660e\u786e\u63cf\u8ff0\uff0c\u5bf9\u8d85\u5b87\u5b99\u7406\u8bba\u8fdb\u884c\u6269\u5c55\u5e76\u5f15\u5165\u5b8f\u89c2-\u8d85\u5b87\u5b99\u548c\u5fae\u89c2-\u8d85\u5b87\u5b99\u64cd\u4f5c\u7684\u6982\u5ff5\u533a\u5206\uff0c\u6784\u5efa\u4e86\u57fa\u4e8e\u5b9a\u4e49=\u72b6\u6001\u539f\u5219\u7684\u5143\u5f62\u5f0f\u903b\u8f91\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b26\u53f7\u4f53\u7cfb\u548c\u7406\u8bba\u6846\u67b6\uff0c\u53ef\u9002\u7528\u4e8e\u591a\u4e2a\u9886\u57df\u7684\u6982\u5ff5\u8868\u8fbe\u548c\u64cd\u4f5c\uff0c\u52a0\u5f3a\u4e86\u7cfb\u7edf\u7406\u8bba\u7684\u57fa\u7840\uff0c\u6269\u5c55\u4e86\u8d85\u5b87\u5b99\u7406\u8bba\u7684\u8303\u7574\uff0c\u4e3a\u667a\u80fd\u5b9a\u4e49\u548c\u79d1\u5b66\u7406\u8bba\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u52a0\u5f3a\u591a\u6837\u5316\u7cfb\u7edf\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5305\u62ec\u667a\u80fd\u7684\u516c\u7406\u5b9a\u4e49\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u6570\u5b66\u4e25\u8c28\u548c\u7edf\u4e00\u7684\u5f62\u5f0f\u7ed3\u6784\uff0c\u4ee5\u6982\u5ff5\u201c\u72b6\u6001\u201d\u4e3a\u57fa\u7840\u3002\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u4e24\u4e2a\u8f74\u7ec4\u6210\u7684\u201c\u5206\u5c42\u72b6\u6001\u7f51\u683c\u201d\u2014\u2014\u72b6\u6001\u6df1\u5ea6\u548c\u6620\u5c04\u5c42\u6b21\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7b26\u53f7\u4f53\u7cfb\uff0c\u53ef\u9002\u7528\u4e8e\u6570\u5b66\u3001\u7269\u7406\u548c\u8bed\u8a00\u9886\u57df\u3002\u540c\u65f6\u5f15\u5165\u4e86\u201c\u4e2d\u95f4\u5143\u5b87\u5b99\uff08IMU\uff09\u201d\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u5b9a\u4e49\u8005\uff08\u6211\u4eec\u81ea\u8eab\uff09\u548c\u6240\u4f7f\u7528\u8bed\u8a00\u7684\u660e\u786e\u63cf\u8ff0\uff0c\u4ece\u800c\u5141\u8bb8\u6709\u610f\u8bc6\u7684\u5143\u5c42\u64cd\u4f5c\uff0c\u540c\u65f6\u907f\u514d\u81ea\u6211\u53c2\u7167\u548c\u903b\u8f91\u4e0d\u4e00\u81f4\u3002\u6784\u5efa\u5728\u8fd9\u4e00\u5143\u7406\u8bba\u57fa\u7840\u4e4b\u4e0a\uff0c\u8be5\u7814\u7a76\u5c06\u8d85\u5b87\u5b99\u7406\u8bba\u6269\u5c55\u5230\u6570\u5b66\u4ee5\u5916\u9886\u57df\uff0c\u5305\u62ec\u8bed\u8a00\u7ffb\u8bd1\u548c\u4ee3\u7406\u96c6\u6210\uff0c\u4ecb\u7ecd\u4e86\u5b8f\u89c2-\u8d85\u5b87\u5b99\u548c\u5fae\u89c2-\u8d85\u5b87\u5b99\u64cd\u4f5c\u4e4b\u95f4\u7684\u6982\u5ff5\u533a\u5206\uff0c\u4ee5\u63d0\u4f9b\u66f4\u5e7f\u6cdb\u7684\u8868\u8fbe\u6027\u3002\u901a\u8fc7\u8fd9\u4e9b\u8d21\u732e\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5b9a\u4e49=\u72b6\u6001\u539f\u5219\u7684\u5143\u5f62\u5f0f\u903b\u8f91\u6846\u67b6\uff0c\u6db5\u76d6\u4e86\u65f6\u95f4\u3001\u8bed\u8a00\u3001\u4ee3\u7406\u548c\u64cd\u4f5c\uff0c\u4e3a\u667a\u80fd\u5b9a\u4e49\u3001\u5f62\u5f0f\u903b\u8f91\u548c\u79d1\u5b66\u7406\u8bba\u7684\u6570\u5b66\u7a33\u5065\u57fa\u7840\u3002"}}
{"id": "2508.00890", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.00890", "abs": "https://arxiv.org/abs/2508.00890", "authors": ["Fali Wang", "Hui Liu", "Zhenwei Dai", "Jingying Zeng", "Zhiwei Zhang", "Zongyu Wu", "Chen Luo", "Zhen Li", "Xianfeng Tang", "Qi He", "Suhang Wang"], "title": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks", "comment": "Under review", "summary": "Test-time scaling (TTS) enhances the performance of large language models\n(LLMs) by allocating additional compute resources during inference. However,\nexisting research primarily investigates TTS in single-stage tasks; while many\nreal-world problems are multi-stage complex tasks, composed of a sequence of\nheterogeneous subtasks with each subtask requires LLM of specific capability.\nTherefore, we study a novel problem: the test-time compute-optimal scaling in\nmulti-stage complex tasks, aiming to select suitable models and allocate\nbudgets per subtask to maximize overall performance. TTS in multi-stage tasks\nintroduces two fundamental challenges: (i) The combinatorial search space of\nmodel and budget allocations, combined with the high cost of inference, makes\nbrute-force search impractical. (ii) The optimal model and budget allocations\nacross subtasks are interdependent, increasing the complexity of the\ncompute-optimal search. To address this gap, we conduct extensive pilot\nexperiments on four tasks across six datasets, deriving three empirical\ninsights characterizing the behavior of LLMs in multi-stage complex tasks.\nInformed by these insights, we propose AgentTTS, an LLM-agent-based framework\nthat autonomously searches for compute-optimal allocations through iterative\nfeedback-driven interactions with the execution environment. Experimental\nresults demonstrate that AgentTTS significantly outperforms traditional and\nother LLM-based baselines in search efficiency, and shows improved robustness\nto varying training set sizes and enhanced interpretability.", "AI": {"tldr": "AgentTTS is a new framework for test-time compute-optimal scaling in multi-stage complex tasks. It outperforms traditional methods and LLM-based baselines in search efficiency and shows improved robustness and interpretability. Experimental results support the effectiveness of AgentTTS in maximizing overall performance in multi-stage tasks.", "motivation": "The existing research primarily focuses on test-time scaling in single-stage tasks, while real-world problems often involve multi-stage complex tasks. The paper aims to address the lack of study on test-time compute-optimal scaling in multi-stage tasks and the challenges it presents, such as the combinatorial search space and interdependence of model and budget allocations across subtasks.", "method": "The paper conducts extensive pilot experiments on four tasks across six datasets to derive empirical insights on the behavior of LLMs in multi-stage complex tasks. Based on these insights, the paper proposes AgentTTS, an LLM-agent-based framework that autonomously searches for compute-optimal allocations through iterative feedback-driven interactions with the execution environment.", "result": "Experimental results show that AgentTTS significantly outperforms traditional and other LLM-based baselines in search efficiency, robustness to varying training set sizes, and enhanced interpretability in multi-stage complex tasks. The pilot experiments provide three empirical insights characterizing the behavior of LLMs in such tasks, leading to the development of AgentTTS.", "conclusion": "AgentTTS, a novel LLM-agent-based framework, outperforms traditional and other LLM-based baselines in search efficiency for test-time compute-optimal scaling in multi-stage complex tasks. It also shows improved robustness to varying training set sizes and enhanced interpretability. Experimental results support the effectiveness of AgentTTS in maximizing overall performance in multi-stage tasks."}}
{"id": "2508.00899", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00899", "abs": "https://arxiv.org/abs/2508.00899", "authors": ["Abeer Dyoub", "Ivan Letteri", "Francesca A. Lisi"], "title": "ff4ERA: A new Fuzzy Framework for Ethical Risk Assessment in AI", "comment": null, "summary": "The emergence of Symbiotic AI (SAI) introduces new challenges to ethical\ndecision-making as it deepens human-AI collaboration. As symbiosis grows, AI\nsystems pose greater ethical risks, including harm to human rights and trust.\nEthical Risk Assessment (ERA) thus becomes crucial for guiding decisions that\nminimize such risks. However, ERA is hindered by uncertainty, vagueness, and\nincomplete information, and morality itself is context-dependent and imprecise.\nThis motivates the need for a flexible, transparent, yet robust framework for\nERA. Our work supports ethical decision-making by quantitatively assessing and\nprioritizing multiple ethical risks so that artificial agents can select\nactions aligned with human values and acceptable risk levels. We introduce\nff4ERA, a fuzzy framework that integrates Fuzzy Logic, the Fuzzy Analytic\nHierarchy Process (FAHP), and Certainty Factors (CF) to quantify ethical risks\nvia an Ethical Risk Score (ERS) for each risk type. The final ERS combines the\nFAHP-derived weight, propagated CF, and risk level. The framework offers a\nrobust mathematical approach for collaborative ERA modeling and systematic,\nstep-by-step analysis. A case study confirms that ff4ERA yields\ncontext-sensitive, ethically meaningful risk scores reflecting both expert\ninput and sensor-based evidence. Risk scores vary consistently with relevant\nfactors while remaining robust to unrelated inputs. Local sensitivity analysis\nshows predictable, mostly monotonic behavior across perturbations, and global\nSobol analysis highlights the dominant influence of expert-defined weights and\ncertainty factors, validating the model design. Overall, the results\ndemonstrate ff4ERA ability to produce interpretable, traceable, and risk-aware\nethical assessments, enabling what-if analyses and guiding designers in\ncalibrating membership functions and expert judgments for reliable ethical\ndecision support.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86ff4ERA\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u7cca\u903b\u8f91\u3001FAHP\u548cCF\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u91cf\u5316\u9053\u5fb7\u98ce\u9669\uff0c\u4e3a\u5408\u4f5c\u7684ERA\u5efa\u6a21\u63d0\u4f9b\u5f3a\u5927\u7684\u6570\u5b66\u65b9\u6cd5\u3002ff4ERA\u80fd\u591f\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u53ef\u8ffd\u8e2a\u548c\u98ce\u9669\u611f\u77e5\u7684\u9053\u5fb7\u8bc4\u4f30\uff0c\u5e2e\u52a9\u8bbe\u8ba1\u8005\u8fdb\u884c\u53ef\u9760\u7684\u9053\u5fb7\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5174\u8d77\u5bfc\u81f4\u4e86Symbiotic AI\uff08SAI\uff09\u7684\u51fa\u73b0\uff0c\u52a0\u6df1\u4e86\u4eba\u5de5\u667a\u80fd\u548c\u4eba\u7c7b\u5408\u4f5c\u5e26\u6765\u7684\u9053\u5fb7\u51b3\u7b56\u6311\u6218\u3002\u7531\u4e8e\u4f26\u7406\u98ce\u9669\u8bc4\u4f30\uff08ERA\uff09\u53d7\u5230\u4e0d\u786e\u5b9a\u6027\u3001\u6a21\u7cca\u6027\u548c\u4fe1\u606f\u4e0d\u5b8c\u6574\u6027\u7684\u9650\u5236\uff0c\u9053\u5fb7\u98ce\u9669\u8bc4\u4f30\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6a21\u7cca\u903b\u8f91\u3001\u6a21\u7cca\u5c42\u6b21\u5206\u6790\u8fc7\u7a0b\uff08FAHP\uff09\u548c\u786e\u5b9a\u6027\u56e0\u5b50\uff08CF\uff09\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86ff4ERA\u6846\u67b6\u6765\u91cf\u5316\u9053\u5fb7\u98ce\u9669\uff0c\u5e76\u5f15\u5165\u4e86Ethical Risk Score\uff08ERS\uff09\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\u3002\u901a\u8fc7\u5177\u4f53\u6848\u4f8b\u7684\u7814\u7a76\uff0c\u8bc1\u5b9e\u4e86ff4ERA\u80fd\u591f\u4ea7\u751f\u4e0e\u4e13\u5bb6\u610f\u89c1\u548c\u4f20\u611f\u5668\u6570\u636e\u76f8\u4e00\u81f4\u7684\u6709\u610f\u4e49\u7684\u98ce\u9669\u8bc4\u5206\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660eff4ERA\u80fd\u591f\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u53ef\u8ffd\u8e2a\u548c\u98ce\u9669\u611f\u77e5\u7684\u9053\u5fb7\u8bc4\u4f30\uff0c\u8fdb\u884c\u4e86\u672c\u5730\u654f\u611f\u6027\u5206\u6790\u548c\u5168\u5c40Sobol\u5206\u6790\uff0c\u5e76\u9a8c\u8bc1\u4e86\u4e13\u5bb6\u5b9a\u4e49\u6743\u91cd\u548c\u786e\u5b9a\u6027\u56e0\u5b50\u5bf9\u6a21\u578b\u8bbe\u8ba1\u7684\u4e3b\u5bfc\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86ff4ERA\uff0c\u4e00\u4e2a\u6a21\u7cca\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u7cca\u903b\u8f91\u3001\u6a21\u7cca\u5c42\u6b21\u5206\u6790\u8fc7\u7a0b\uff08FAHP\uff09\u548c\u786e\u5b9a\u6027\u56e0\u5b50\uff08CF\uff09\u7ed3\u5408\uff0c\u4e3a\u6bcf\u79cd\u98ce\u9669\u7c7b\u578b\u91cf\u5316\u9053\u5fb7\u98ce\u9669\uff0c\u6700\u7ec8\u7efc\u5408\u4e86FAHP\u5bfc\u51fa\u7684\u6743\u91cd\u3001\u4f20\u64adCF\u548c\u98ce\u9669\u6c34\u5e73\u3002\u8be5\u6846\u67b6\u4e3a\u5408\u4f5c\u7684ERA\u5efa\u6a21\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6570\u5b66\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u3001\u9010\u6b65\u7684\u5206\u6790\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660eff4ERA\u80fd\u591f\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u53ef\u8ffd\u8e2a\u548c\u98ce\u9669\u611f\u77e5\u7684\u9053\u5fb7\u8bc4\u4f30\uff0c\u5b9e\u73b0\u5047\u8bbe\u5206\u6790\uff0c\u6307\u5bfc\u8bbe\u8ba1\u8005\u6821\u51c6\u6210\u5458\u51fd\u6570\u548c\u4e13\u5bb6\u5224\u65ad\uff0c\u4e3a\u53ef\u9760\u7684\u9053\u5fb7\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u5e2e\u52a9\u3002"}}
{"id": "2508.00902", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.00902", "abs": "https://arxiv.org/abs/2508.00902", "authors": ["Kenneth Payne"], "title": "An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models", "comment": "26 pages, 2 figures, 9 tables, 2 appendices", "summary": "Judgment of risk is key to decision-making under uncertainty. As Daniel\nKahneman and Amos Tversky famously discovered, humans do so in a distinctive\nway that departs from mathematical rationalism. Specifically, they demonstrated\nexperimentally that humans accept more risk when they feel themselves at risk\nof losing something than when they might gain. I report the first tests of\nKahneman and Tversky's landmark 'prospect theory' with Large Language Models,\nincluding today's state of the art chain-of-thought 'reasoners'.\n  In common with humans, I find that prospect theory often anticipates how\nthese models approach risky decisions across a range of scenarios. I also\ndemonstrate that context is key to explaining much of the variance in risk\nappetite. The 'frame' through which risk is apprehended appears to be embedded\nwithin the language of the scenarios tackled by the models. Specifically, I\nfind that military scenarios generate far larger 'framing effects' than do\ncivilian settings, ceteris paribus. My research suggests, therefore, that\nlanguage models the world, capturing our human heuristics and biases. But also\nthat these biases are uneven - the idea of a 'frame' is richer than simple\ngains and losses. Wittgenstein's notion of 'language games' explains the\ncontingent, localised biases activated by these scenarios. Finally, I use my\nfindings to reframe the ongoing debate about reasoning and memorisation in\nLLMs.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u9996\u6b21\u6d4b\u8bd5\u4e86Kahneman\u548cTversky\u7684\u524d\u666f\u7406\u8bba\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u4e0e\u4eba\u7c7b\u5b58\u5728\u76f8\u4f3c\u6027\u3002\u4f5c\u8005\u5f3a\u8c03\u4e86\u8bed\u5883\u5bf9\u98ce\u9669\u504f\u597d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u6a21\u578b\u5904\u7406\u573a\u666f\u65f6\u7684\u8bed\u8a00\u5f71\u54cd\u98ce\u9669\u611f\u77e5\u3002\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u91cd\u65b0\u754c\u5b9a\u5173\u4e8eLLM\u4e2d\u63a8\u7406\u548c\u8bb0\u5fc6\u7684\u8ba8\u8bba\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7a76Kahneman\u548cTversky\u7684\u524d\u666f\u7406\u8bba\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4ee5\u53ca\u4eba\u7c7b\u4e0e\u6a21\u578b\u5728\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u76f8\u4f3c\u6027\u3002\u4f5c\u8005\u8bd5\u56fe\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u524d\u666f\u7406\u8bba\u5728\u6a21\u578b\u4e2d\u7684\u6548\u679c\uff0c\u4e86\u89e3\u4e0d\u540c\u8bed\u5883\u4e0b\u98ce\u9669\u6001\u5ea6\u7684\u53d8\u5316\uff0c\u5e76\u63a2\u8ba8\u6a21\u578b\u5904\u7406\u573a\u666f\u65f6\u7684\u8bed\u8a00\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u9996\u6b21\u6d4b\u8bd5\u4e86Kahneman\u548cTversky\u7684\u524d\u666f\u7406\u8bba\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u57fa\u4e8e\u4e0d\u540c\u573a\u666f\u5bf9\u6a21\u578b\u7684\u51b3\u7b56\u65b9\u5f0f\u8fdb\u884c\u63a2\u7a76\u3002\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u524d\u666f\u7406\u8bba\u80fd\u591f\u8f83\u597d\u5730\u9884\u6d4b\u6a21\u578b\u5728\u98ce\u9669\u51b3\u7b56\u65b9\u9762\u7684\u8d8b\u52bf\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u8fd8\u63ed\u793a\u4e86\u8bed\u5883\u5728\u89e3\u91ca\u98ce\u9669\u504f\u597d\u5dee\u5f02\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u53d1\u73b0\u98ce\u9669\u611f\u77e5\u7684\u2018\u6846\u67b6\u2019\u5d4c\u5165\u5728\u6a21\u578b\u5904\u7406\u7684\u573a\u666f\u8bed\u8a00\u4e2d\u3002\u6700\u540e\uff0c\u4f5c\u8005\u8fd0\u7528\u7814\u7a76\u6210\u679c\u91cd\u65b0\u754c\u5b9a\u4e86\u5173\u4e8eLLM\u4e2d\u63a8\u7406\u548c\u8bb0\u5fc6\u7684\u8ba8\u8bba\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u524d\u666f\u7406\u8bba\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u6709\u6548\uff0c\u6a21\u578b\u5728\u51b3\u7b56\u4e2d\u4e0e\u4eba\u7c7b\u5b58\u5728\u76f8\u4f3c\u6027\u3002\u4f5c\u8005\u8fd8\u5f3a\u8c03\u4e86\u8bed\u5883\u5bf9\u98ce\u9669\u504f\u597d\u7684\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u6a21\u578b\u5904\u7406\u573a\u666f\u65f6\u7684\u8bed\u8a00\u4f1a\u5f71\u54cd\u98ce\u9669\u611f\u77e5\u3002\u6700\u7ec8\uff0c\u7814\u7a76\u6210\u679c\u6709\u52a9\u4e8e\u91cd\u65b0\u5b9a\u4e49LLM\u4e2d\u63a8\u7406\u548c\u8bb0\u5fc6\u7684\u8ba8\u8bba\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u53d1\u73b0Kahneman\u548cTversky\u7684\u524d\u666f\u7406\u8bba\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u4e0e\u4eba\u7c7b\u5bf9\u98ce\u9669\u7684\u5224\u65ad\u65b9\u5f0f\u5b58\u5728\u76f8\u4f3c\u6027\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u98ce\u9669\u6001\u5ea6\u7684\u53d8\u5316\u3002\u4f5c\u8005\u6307\u51fa\u8bed\u5883\u662f\u89e3\u91ca\u98ce\u9669\u504f\u597d\u5dee\u5f02\u7684\u5173\u952e\uff0c\u800c\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u573a\u666f\u4e5f\u5f71\u54cd\u4eba\u7c7b\u542f\u53d1\u5f0f\u548c\u504f\u89c1\u7684\u8868\u8fbe\u3002\u7814\u7a76\u8868\u660e\uff0c\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u6a21\u62df\u4eba\u7c7b\u7684\u51b3\u7b56\u7279\u70b9\uff0c\u4f46\u504f\u89c1\u4e0d\u5747\u5300\uff0c\u4e30\u5bcc\u4e86\u2018\u6846\u67b6\u2019\u6982\u5ff5\u3002\u6700\u540e\uff0c\u4f5c\u8005\u5229\u7528\u7814\u7a76\u7ed3\u679c\u91cd\u65b0\u6784\u5efa\u4e86\u6709\u5173LLM\u4e2d\u63a8\u7406\u548c\u8bb0\u5fc6\u7684\u6301\u7eed\u8fa9\u8bba\u3002"}}
{"id": "2508.00914", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00914", "abs": "https://arxiv.org/abs/2508.00914", "authors": ["Dominic Simon", "Rickard Ewetz"], "title": "Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis", "comment": "14 pages, 15 figures, pre-print of paper accepted to IJCAI 2025", "summary": "Large Language Models (LLMs) require lightweight avenues of updating stored\ninformation that has fallen out of date. Knowledge Editing (KE) approaches have\nbeen successful in updating model knowledge for simple factual queries but\nstruggle with handling tasks that require compositional reasoning such as\nmulti-hop question answering (MQA). We observe that existing knowledge editors\nleverage decompositional techniques that result in illogical reasoning\nprocesses. In this paper, we propose a knowledge editor for MQA based on\nsemantic analysis called CHECK. Our framework is based on insights from an\nanalogy between compilers and reasoning using LLMs. Similar to how source code\nis first compiled before being executed, we propose to semantically analyze\nreasoning chains before executing the chains to answer questions. Reasoning\nchains with semantic errors are revised to ensure consistency through logic\noptimization and re-prompting the LLM model at a higher temperature. We\nevaluate the effectiveness of CHECK against five state-of-the-art frameworks on\nfour datasets and achieve an average 22.8% improved MQA accuracy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86CHECK\u77e5\u8bc6\u7f16\u8f91\u5668\uff0c\u8fd0\u7528\u8bed\u4e49\u5206\u6790\u5904\u7406\u591a\u8df3\u95ee\u9898\u56de\u7b54\uff0c\u901a\u8fc7\u5728\u6267\u884c\u524d\u5bf9\u63a8\u7406\u94fe\u8fdb\u884c\u8bed\u4e49\u5206\u6790\u548c\u4fee\u8ba2\uff0c\u903b\u8f91\u4f18\u5316\u4ee5\u53ca\u5728\u66f4\u9ad8\u6e29\u5ea6\u4e0b\u91cd\u65b0\u63d0\u793aLLM\u6a21\u578b\uff0c\u53d6\u5f97\u4e8622.8\uff05\u7684\u5e73\u5747MQA\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "LLM\u9700\u8981\u8f7b\u91cf\u7ea7\u66f4\u65b0\u8fc7\u65f6\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u7b80\u5355\u4e8b\u5b9e\u67e5\u8be2\u65b9\u9762\u8868\u73b0\u6210\u529f\uff0c\u4f46\u5728\u5904\u7406\u9700\u8981\u7ec4\u5408\u63a8\u7406\u7684\u4efb\u52a1\uff08\u5982\u591a\u8df3\u95ee\u9898\u56de\u7b54\uff09\u65f6\u9047\u5230\u56f0\u96be\u3002\u5df2\u6709\u77e5\u8bc6\u7f16\u8f91\u5668\u5229\u7528\u5206\u89e3\u6280\u672f\u8fdb\u884c\u63a8\u7406\uff0c\u5bfc\u81f4\u4e0d\u5408\u903b\u8f91\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u5206\u6790\u7684\u77e5\u8bc6\u7f16\u8f91\u5668CHECK\uff0c\u901a\u8fc7\u5728\u6267\u884c\u524d\u5bf9\u63a8\u7406\u94fe\u8fdb\u884c\u8bed\u4e49\u5206\u6790\uff0c\u5bf9\u5177\u6709\u8bed\u4e49\u9519\u8bef\u7684\u63a8\u7406\u94fe\u8fdb\u884c\u4fee\u8ba2\u4ee5\u786e\u4fdd\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u903b\u8f91\u4f18\u5316\u548c\u5728\u66f4\u9ad8\u6e29\u5ea6\u4e0b\u518d\u6b21\u63d0\u793aLLM\u6a21\u578b\u3002", "result": "\u4f7f\u7528CHECK\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u8f83\u4e8e\u4e94\u79cd\u6700\u5148\u8fdb\u7684\u6846\u67b6\uff0c\u5e73\u5747MQA\u51c6\u786e\u7387\u63d0\u9ad8\u4e8622.8\uff05\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u5206\u6790\u7684\u77e5\u8bc6\u7f16\u8f91\u5668CHECK\uff0c\u7528\u4e8e\u5904\u7406\u9700\u8981\u7ec4\u5408\u63a8\u7406\u7684\u591a\u8df3\u95ee\u9898\u56de\u7b54\uff0c\u76f8\u6bd4\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u5e73\u574722.8\uff05\u7684MQA\u51c6\u786e\u7387\u63d0\u5347\u3002"}}
{"id": "2508.00967", "categories": ["cs.AI", "cs.RO", "68T07, 68T45, 93C85", "I.2.6; I.2.9; I.2.10; I.4.8"], "pdf": "https://arxiv.org/pdf/2508.00967", "abs": "https://arxiv.org/abs/2508.00967", "authors": ["Massoud Pourmandi"], "title": "Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF", "comment": "15 pages, 3 figures, 1 table, 1 algorithm. Preprint based on NeurIPS\n  2024 template", "summary": "The proposal introduces an innovative drone swarm perception system that aims\nto solve problems related to computational limitations and low-bandwidth\ncommunication, and real-time scene reconstruction. The framework enables\nefficient multi-agent 3D/4D scene synthesis through federated learning of\nshared diffusion model and YOLOv12 lightweight semantic extraction and local\nNeRF updates while maintaining privacy and scalability. The framework redesigns\ngenerative diffusion models for joint scene reconstruction, and improves\ncooperative scene understanding, while adding semantic-aware compression\nprotocols. The approach can be validated through simulations and potential\nreal-world deployment on drone testbeds, positioning it as a disruptive\nadvancement in multi-agent AI for autonomous systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u65e0\u4eba\u673a\u7fa4\u4f53\u611f\u77e5\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u3001\u8f7b\u91cf\u7ea7\u8bed\u4e49\u63d0\u53d6\u548c\u672c\u5730NeRF\u66f4\u65b0\u89e3\u51b3\u4e86\u8ba1\u7b97\u9650\u5236\u3001\u4f4e\u5e26\u5bbd\u901a\u4fe1\u548c\u5b9e\u65f6\u91cd\u5efa\u7b49\u95ee\u9898\u3002\u91cd\u65b0\u8bbe\u8ba1\u751f\u6210\u6269\u6563\u6a21\u578b\uff0c\u589e\u52a0\u8bed\u4e49\u611f\u77e5\u538b\u7f29\u534f\u8bae\uff0c\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u573a\u666f\u7efc\u5408\u6548\u7387\u548c\u5408\u4f5c\u7406\u89e3\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u6f5c\u5728\u7684\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4ef7\u503c\uff0c\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u591a\u667a\u80fd\u4f53AI\u5e26\u6765\u4e86\u98a0\u8986\u6027\u8fdb\u5c55\u3002", "motivation": "\u672c\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u73b0\u6709\u7684\u65e0\u4eba\u673a\u611f\u77e5\u7cfb\u7edf\u4e2d\u9047\u5230\u7684\u8ba1\u7b97\u9650\u5236\u3001\u4f4e\u5e26\u5bbd\u901a\u4fe1\u548c\u5b9e\u65f6\u573a\u666f\u91cd\u5efa\u7b49\u95ee\u9898\uff0c\u65e8\u5728\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u5728\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u548c\u6548\u7387\u3002\u901a\u8fc7\u5f15\u5165\u8054\u90a6\u5b66\u4e60\u548c\u8f7b\u91cf\u7ea7\u8bed\u4e49\u63d0\u53d6\u7b49\u65b0\u6280\u672f\uff0c\u91cd\u65b0\u8bbe\u8ba1\u751f\u6210\u6269\u6563\u6a21\u578b\u548c\u589e\u52a0\u8bed\u4e49\u611f\u77e5\u538b\u7f29\u534f\u8bae\uff0c\u4ee5\u6539\u5584\u573a\u666f\u7406\u89e3\u548c\u91cd\u5efa\u7684\u80fd\u529b\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u65b0\u7684\u65e0\u4eba\u673a\u7fa4\u4f53\u611f\u77e5\u7cfb\u7edf\u6846\u67b6\uff0c\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u3001YOLOv12\u8f7b\u91cf\u7ea7\u8bed\u4e49\u63d0\u53d6\u548c\u672c\u5730NeRF\u66f4\u65b0\u7b49\u6280\u672f\u6765\u89e3\u51b3\u8ba1\u7b97\u9650\u5236\u3001\u4f4e\u5e26\u5bbd\u901a\u4fe1\u548c\u5b9e\u65f6\u573a\u666f\u91cd\u5efa\u95ee\u9898\u3002\u6846\u67b6\u91cd\u65b0\u8bbe\u8ba1\u4e86\u751f\u6210\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u8054\u5408\u573a\u666f\u91cd\u5efa\uff0c\u5e76\u589e\u52a0\u4e86\u8bed\u4e49\u611f\u77e5\u538b\u7f29\u534f\u8bae\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\uff0c\u5e76\u6709\u6f5c\u5728\u7684\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u53ef\u80fd\u6027\u3002", "result": "\u901a\u8fc7\u8be5\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f533D/4D\u573a\u666f\u7efc\u5408\uff0c\u63d0\u9ad8\u4e86\u5408\u4f5c\u573a\u666f\u7406\u89e3\u5e76\u52a0\u5f3a\u4e86\u8bed\u4e49\u611f\u77e5\u538b\u7f29\uff0c\u4e3a\u65e0\u4eba\u673a\u7fa4\u4f53\u7684\u611f\u77e5\u7cfb\u7edf\u5e26\u6765\u4e86\u91cd\u8981\u7684\u8fdb\u6b65\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65e0\u4eba\u673a\u7fa4\u4f53\u611f\u77e5\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u4e0e\u8ba1\u7b97\u9650\u5236\u3001\u4f4e\u5e26\u5bbd\u901a\u4fe1\u548c\u5b9e\u65f6\u573a\u666f\u91cd\u5efa\u76f8\u5173\u7684\u95ee\u9898\u3002\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u5171\u4eab\u6269\u6563\u6a21\u578b\u548cYOLOv12\u8f7b\u91cf\u7ea7\u8bed\u4e49\u63d0\u53d6\u4ee5\u53ca\u672c\u5730NeRF\u66f4\u65b0\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f533D/4D\u573a\u666f\u7efc\u5408\u3002\u6846\u67b6\u91cd\u65b0\u8bbe\u8ba1\u4e86\u751f\u6210\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u8054\u5408\u573a\u666f\u91cd\u5efa\uff0c\u5e76\u901a\u8fc7\u6dfb\u52a0\u8bed\u4e49\u611f\u77e5\u538b\u7f29\u534f\u8bae\u6765\u6539\u5584\u5408\u4f5c\u573a\u666f\u7406\u89e3\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\uff0c\u5e76\u6709\u6f5c\u5728\u7684\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u53ef\u80fd\u6027\uff0c\u5b9a\u4f4d\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u591a\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u7684\u98a0\u8986\u6027\u8fdb\u5c55\u3002"}}
{"id": "2508.01012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01012", "abs": "https://arxiv.org/abs/2508.01012", "authors": ["Yiyi Lu", "Hoi Ian Au", "Junyao Zhang", "Jingyu Pan", "Yiting Wang", "Ang Li", "Jianyi Zhang", "Yiran Chen"], "title": "AutoEDA: Enabling EDA Flow Automation through Microservice-Based LLM Agents", "comment": null, "summary": "Modern Electronic Design Automation (EDA) workflows, especially the\nRTL-to-GDSII flow, require heavily manual scripting and demonstrate a multitude\nof tool-specific interactions which limits scalability and efficiency. While\nLLMs introduces strides for automation, existing LLM solutions require\nexpensive fine-tuning and do not contain standardized frameworks for\nintegration and evaluation. We introduce AutoEDA, a framework for EDA\nautomation that leverages paralleled learning through the Model Context\nProtocol (MCP) specific for standardized and scalable natural language\nexperience across the entire RTL-to-GDSII flow. AutoEDA limits fine-tuning\nthrough structured prompt engineering, implements intelligent parameter\nextraction and task decomposition, and provides an extended CodeBLEU metric to\nevaluate the quality of TCL scripts. Results from experiments over five\npreviously curated benchmarks show improvements in automation accuracy and\nefficiency, as well as script quality when compared to existing methods.\nAutoEDA is released open-sourced to support reproducibility and the EDA\ncommunity. Available at: https://github.com/AndyLu666/MCP-EDA-Server", "AI": {"tldr": "AutoEDA is a framework for EDA automation that utilizes MCP for standardized and scalable natural language experience, improving automation accuracy, efficiency, and script quality compared to existing methods. It introduces structured prompt engineering, intelligent parameter extraction, and an extended CodeBLEU metric for evaluating TCL script quality. Released open-source to support reproducibility in the EDA community.", "motivation": "Existing LLM solutions for EDA automation lack standardized frameworks for integration and evaluation, requiring expensive fine-tuning. The manual scripting and tool-specific interactions in RTL-to-GDSII workflows limit scalability and efficiency.", "method": "AutoEDA leverages paralleled learning through the Model Context Protocol (MCP) for standardized and scalable natural language experience. It implements structured prompt engineering, intelligent parameter extraction, and task decomposition, while introducing an extended CodeBLEU metric for evaluating TCL script quality.", "result": "AutoEDA demonstrates improvements in automation accuracy, efficiency, and script quality over existing methods through experiments on five curated benchmarks.", "conclusion": "AutoEDA, a framework for EDA automation, enhances automation accuracy and efficiency, improves script quality, and introduces structured prompt engineering and intelligent parameter extraction."}}
{"id": "2508.01031", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01031", "abs": "https://arxiv.org/abs/2508.01031", "authors": ["Jingzhe Ni", "Xiaolong Yin", "Xintong Li", "Xingyu Lu", "Ji Wei", "Ruofeng Tong", "Min Tang", "Peng Du"], "title": "CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent", "comment": null, "summary": "Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing\nbut typically requires a high level of expertise from designers. To lower the\nentry barrier and improve design efficiency, we present an agent for CAD\nconceptual design powered by large language models (LLMs). The agent accepts\nboth abstract textual descriptions and freehand sketches as input, engaging in\ninteractive dialogue with users to refine and clarify design requirements\nthrough comprehensive requirement analysis. Built upon a novel\nContext-Independent Imperative Paradigm (CIP), the agent generates high-quality\nCAD modeling code. During the generation process, the agent incorporates\niterative visual feedback to improve model quality. Generated design cases are\nstored in a structured knowledge base, enabling continuous improvement of the\nagent's code generation capabilities. Experimental results demonstrate that our\nmethod achieves state-of-the-art performance in CAD code generation.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684CAD\u6982\u5ff5\u8bbe\u8ba1\u4ee3\u7406\uff0c\u80fd\u591f\u63a5\u53d7\u6587\u672c\u63cf\u8ff0\u548c\u624b\u7ed8\u8349\u56fe\u4f5c\u4e3a\u8f93\u5165\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u4f18\u5316\u8bbe\u8ba1\u8981\u6c42\uff0c\u5e76\u751f\u6210\u9ad8\u8d28\u91cfCAD\u5efa\u6a21\u4ee3\u7801\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728CAD\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4eCAD\u9886\u57df\u8bbe\u8ba1\u8005\u6240\u9700\u7684\u4e13\u4e1a\u6c34\u5e73\u8981\u6c42\uff0c\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684CAD\u6982\u5ff5\u8bbe\u8ba1\u4ee3\u7406\u3002\u8be5\u4ee3\u7406\u80fd\u591f\u4e0e\u7528\u6237\u4ea4\u4e92\uff0c\u63a5\u53d7\u591a\u79cd\u5f62\u5f0f\u7684\u8f93\u5165\uff0c\u5e76\u901a\u8fc7\u5168\u9762\u7684\u9700\u6c42\u5206\u6790\u4f18\u5316\u8bbe\u8ba1\u8981\u6c42\u3002", "method": "\u8bba\u6587\u5efa\u7acb\u4e86\u4e00\u79cd\u57fa\u4e8eContext-Independent Imperative Paradigm\uff08CIP\uff09\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884cCAD\u6982\u5ff5\u8bbe\u8ba1\uff0c\u7ed3\u5408\u8fed\u4ee3\u7684\u89c6\u89c9\u53cd\u9988\u6765\u63d0\u9ad8\u6a21\u578b\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u5e93\u5b58\u50a8\u751f\u6210\u7684\u8bbe\u8ba1\u6848\u4f8b\uff0c\u6301\u7eed\u6539\u8fdb\u4ee3\u7406\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728CAD\u4ee3\u7801\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u4e1a\u754c\u9886\u5148\u8868\u73b0\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684CAD\u6982\u5ff5\u8bbe\u8ba1\u4ee3\u7406\uff0c\u80fd\u591f\u63a5\u53d7\u62bd\u8c61\u7684\u6587\u672c\u63cf\u8ff0\u548c\u81ea\u7531\u624b\u7ed8\u8349\u56fe\u4f5c\u4e3a\u8f93\u5165\uff0c\u901a\u8fc7\u4e0e\u7528\u6237\u8fdb\u884c\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u6765\u4f18\u5316\u8bbe\u8ba1\u8981\u6c42\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7684CAD\u5efa\u6a21\u4ee3\u7801\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728CAD\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8fbe\u5230\u4e86\u4e1a\u754c\u9886\u5148\u6c34\u5e73\u3002"}}
{"id": "2508.01057", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.01057", "abs": "https://arxiv.org/abs/2508.01057", "authors": ["Fengze Yang", "Bo Yu", "Yang Zhou", "Xuewen Luo", "Zhengzhong Tu", "Chenxi Liu"], "title": "REACT: A Real-Time Edge-AI Based V2X Framework for Accident Avoidance in Autonomous Driving System", "comment": "24 pages, 6 tables, 7 figures", "summary": "Collisions caused by human error are the most common type of multi-vehicle\ncrash, highlighting the critical need for autonomous driving (AD) systems to\nleverage cooperative perception through Vehicle-to-Everything (V2X)\ncommunication. This capability extends situational awareness beyond the\nlimitations of onboard sensors. However, current transformer-based V2X\nframeworks suffer from limited generalization, shallow contextual reasoning,\nand reliance on mono-modal inputs. Vision-Language Models (VLMs) offer enhanced\nreasoning and multimodal integration but typically fall short of real-time\nperformance requirements in safety-critical applications. This paper presents\nREACT, a real-time, V2X-integrated trajectory optimization framework built upon\na fine-tuned lightweight VLM. REACT integrates a set of specialized modules\nthat process multimodal inputs into optimized, risk-aware trajectories. To\nensure real-time performance on edge devices, REACT incorporates edge\nadaptation strategies that reduce model complexity and accelerate inference.\nEvaluated on the DeepAccident benchmark, REACT achieves state-of-the-art\nperformance, a 77% collision rate reduction, a 48.2% Video Panoptic Quality\n(VPQ), and a 0.57-second inference latency on the Jetson AGX Orin. Ablation\nstudies validate the contribution of each input, module, and edge adaptation\nstrategy. These results demonstrate the feasibility of lightweight VLMs for\nreal-time edge-based cooperative planning and showcase the potential of\nlanguage-guided contextual reasoning to improve safety and responsiveness in\nautonomous driving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86REACT\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6V2X\u96c6\u6210\u8f68\u8ff9\u4f18\u5316\uff0c\u57fa\u4e8e\u8f7b\u91cf\u7ea7VLM\u3002\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u548cDeepAccident\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86REACT\u5728\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u6027\u548c\u54cd\u5e94\u6027\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5f53\u524d\u57fa\u4e8e\u53d8\u538b\u5668\u7684V2X\u6846\u67b6\u5b58\u5728\u4e00\u5b9a\u5c40\u9650\uff0c\u5982\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3001\u4e0a\u4e0b\u6587\u63a8\u7406\u8868\u9762\u4ee5\u53ca\u5bf9\u5355\u6a21\u6001\u8f93\u5165\u7684\u4f9d\u8d56\u3002\u4f5c\u8005\u8ba4\u4e3a\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u80fd\u591f\u63d0\u4f9b\u589e\u5f3a\u7684\u63a8\u7406\u548c\u591a\u6a21\u6001\u6574\u5408\uff0c\u4f46\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u901a\u5e38\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u6027\u80fd\u8981\u6c42\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86REACT\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u548c\u54cd\u5e94\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u672c\u6587\u901a\u8fc7\u63d0\u51faREACT\u6846\u67b6\uff0c\u7ed3\u5408\u4e13\u95e8\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u7684\u6a21\u5757\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u3001V2X\u96c6\u6210\u7684\u8f68\u8ff9\u4f18\u5316\u3002\u4e3a\u4e86\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4fdd\u8bc1\u5b9e\u65f6\u6027\u80fd\uff0cREACT\u91c7\u7528\u4e86\u8fb9\u7f18\u9002\u5e94\u7b56\u7565\uff0c\u964d\u4f4e\u6a21\u578b\u590d\u6742\u6027\u5e76\u52a0\u901f\u63a8\u65ad\u3002\u4f5c\u8005\u4f7f\u7528DeepAccident\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u8bc1\u660eREACT\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u5e76\u8fdb\u884c\u4e86\u6d88\u878d\u7814\u7a76\u4ee5\u9a8c\u8bc1\u6bcf\u4e2a\u8981\u7d20\u7684\u8d21\u732e\u3002", "result": "REACT\u6846\u67b6\u5728DeepAccident\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4ee4\u4eba\u77a9\u76ee\u7684\u6210\u679c\uff0c\u964d\u4f4e\u4e86\u78b0\u649e\u7387\u3001\u63d0\u9ad8\u4e86\u89c6\u9891\u5168\u666f\u8d28\u91cf\uff0c\u5e76\u5728Jetson AGX Orin\u4e0a\u5b9e\u73b0\u4e86\u8f83\u4f4e\u7684\u63a8\u65ad\u5ef6\u8fdf\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86REACT\u5404\u90e8\u5206\u7684\u91cd\u8981\u6027\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u5b9e\u65f6\u8fb9\u7f18\u5408\u4f5c\u89c4\u5212\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREACT\u7684\u5b9e\u65f6V2X\u96c6\u6210\u8f68\u8ff9\u4f18\u5316\u6846\u67b6\uff0c\u57fa\u4e8e\u7ecf\u8fc7\u5fae\u8c03\u7684\u8f7b\u91cf\u7ea7VLM\u3002REACT\u5728DeepAccident\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u6700\u65b0\u6210\u679c\uff0c\u6210\u529f\u964d\u4f4e\u4e8677%\u7684\u78b0\u649e\u7387\uff0c\u63d0\u9ad8\u4e8648.2%\u7684\u89c6\u9891\u5168\u666f\u8d28\u91cf\uff08VPQ\uff09\uff0c\u5e76\u5728Jetson AGX Orin\u4e0a\u5b9e\u73b0\u4e860.57\u79d2\u7684\u63a8\u65ad\u5ef6\u8fdf\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u6bcf\u4e2a\u8f93\u5165\u3001\u6a21\u5757\u548c\u8fb9\u7f18\u9002\u5e94\u7b56\u7565\u7684\u8d21\u732e\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\u8f7b\u91cf\u7ea7VLM\u5728\u5b9e\u65f6\u8fb9\u7f18\u5408\u4f5c\u89c4\u5212\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8bed\u8a00\u5f15\u5bfc\u7684\u80cc\u666f\u63a8\u7406\u5728\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u6027\u548c\u54cd\u5e94\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.01073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01073", "abs": "https://arxiv.org/abs/2508.01073", "authors": ["Martin B\u00f6ckling", "Heiko Paulheim"], "title": "gpuRDF2vec -- Scalable GPU-based RDF2vec", "comment": "18 pages, ISWC 2025", "summary": "Generating Knowledge Graph (KG) embeddings at web scale remains challenging.\nAmong existing techniques, RDF2vec combines effectiveness with strong\nscalability. We present gpuRDF2vec, an open source library that harnesses\nmodern GPUs and supports multi-node execution to accelerate every stage of the\nRDF2vec pipeline. Extensive experiments on both synthetically generated graphs\nand real-world benchmarks show that gpuRDF2vec achieves up to a substantial\nspeedup over the currently fastest alternative, i.e., jRDF2vec. In a\nsingle-node setup, our walk-extraction phase alone outperforms pyRDF2vec,\nSparkKGML, and jRDF2vec by a substantial margin using random walks on large/\ndense graphs, and scales very well to longer walks, which typically lead to\nbetter quality embeddings. Our implementation of gpuRDF2vec enables\npractitioners and researchers to train high-quality KG embeddings on\nlarge-scale graphs within practical time budgets and builds on top of Pytorch\nLightning for the scalable word2vec implementation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86gpuRDF2vec\uff0c\u901a\u8fc7\u5229\u7528\u73b0\u4ee3GPU\u548c\u591a\u8282\u70b9\u6267\u884c\u652f\u6301\u6765\u52a0\u901f\u77e5\u8bc6\u56fe\u5d4c\u5165\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660egpuRDF2vec\u5728\u901f\u5ea6\u548c\u6027\u80fd\u4e0a\u660e\u663e\u4f18\u4e8e\u5176\u4ed6\u6280\u672f\uff0c\u5c24\u5176\u5728\u5904\u7406\u5927\u578b/\u5bc6\u96c6\u56fe\u7684\u968f\u673a\u6e38\u8d70\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u4e2d\uff0c\u751f\u6210Web\u89c4\u6a21\u7684\u77e5\u8bc6\u56fe\u5d4c\u5165\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u4f5c\u8005\u901a\u8fc7\u63a8\u51fagpuRDF2vec\uff0c\u65e8\u5728\u89e3\u51b3RDF2vec\u6d41\u7a0b\u4e2d\u7684\u6548\u7387\u548c\u6269\u5c55\u6027\u95ee\u9898\u3002\u5176\u76ee\u7684\u662f\u52a0\u901f\u77e5\u8bc6\u56fe\u5d4c\u5165\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u5176\u9002\u7528\u4e8e\u5904\u7406\u5927\u89c4\u6a21\u56fe\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86gpuRDF2vec\uff0c\u4e00\u79cd\u5229\u7528\u73b0\u4ee3GPU\u548c\u591a\u8282\u70b9\u6267\u884c\u652f\u6301\u6765\u52a0\u901fRDF2vec\u6d41\u7a0b\u7684\u5f00\u6e90\u5e93\u3002\u5728\u5b9e\u9a8c\u4e2d\uff0c\u5c55\u793a\u4e86gpuRDF2vec\u5728\u901f\u5ea6\u548c\u6027\u80fd\u4e0a\u7684\u4f18\u8d8a\u6027\uff0c\u5c24\u5176\u5728\u5927\u578b/\u5bc6\u96c6\u56fe\u4e0a\u7684\u968f\u673a\u6e38\u8d70\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u8be5\u5b9e\u73b0\u6784\u5efa\u5728Pytorch Lightning\u4e0a\uff0c\u7528\u4e8e\u5b9e\u73b0\u53ef\u6269\u5c55\u7684word2vec\u3002", "result": "gpuRDF2vec\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u578b/\u5bc6\u96c6\u56fe\u7684\u968f\u673a\u6e38\u8d70\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002\u5355\u8282\u70b9\u8bbe\u7f6e\u4e0b\uff0c\u5176\u6b65\u9aa4\u6027\u80fd\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\uff0c\u5305\u62ecpyRDF2vec\u3001SparkKGML\u548cjRDF2vec\u3002\u8be5\u5b9e\u73b0\u4f7f\u5f97\u5728\u5b9e\u9645\u65f6\u95f4\u9884\u7b97\u5185\u751f\u6210\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u5d4c\u5165\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "gpuRDF2vec\u662f\u4e00\u4e2a\u5f00\u6e90\u5e93\uff0c\u5229\u7528\u73b0\u4ee3GPU\u548c\u652f\u6301\u591a\u8282\u70b9\u6267\u884c\uff0c\u52a0\u901fRDF2vec\u6d41\u7a0b\u7684\u6bcf\u4e2a\u9636\u6bb5\u3002\u5728\u5355\u8282\u70b9\u8bbe\u7f6e\u4e2d\uff0c\u5176\u62bd\u53d6\u6b65\u9aa4\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u6280\u672f\uff0c\u5305\u62ecpyRDF2vec\u3001SparkKGML\u548cjRDF2vec\uff0c\u7279\u522b\u5728\u5904\u7406\u5927\u578b/\u5bc6\u96c6\u56fe\u7684\u968f\u673a\u6e38\u8d70\u65f6\u8868\u73b0\u51fa\u8272\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cgpuRDF2vec\u5728\u901f\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u63d0\u5347\u3002\u8be5\u5b9e\u73b0\u4f7f\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5728\u5b9e\u9645\u65f6\u95f4\u9884\u7b97\u5185\u5bf9\u5927\u89c4\u6a21\u56fe\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u77e5\u8bc6\u56fe\u5d4c\u5165\u3002"}}
{"id": "2508.01097", "categories": ["cs.AI", "nlin.AO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2508.01097", "abs": "https://arxiv.org/abs/2508.01097", "authors": ["Neil F. Johnson", "Frank Yingjie Huo"], "title": "Multispin Physics of AI Tipping Points and Hallucinations", "comment": null, "summary": "Output from generative AI such as ChatGPT, can be repetitive and biased. But\nmore worrying is that this output can mysteriously tip mid-response from good\n(correct) to bad (misleading or wrong) without the user noticing. In 2024\nalone, this reportedly caused $67 billion in losses and several deaths.\nEstablishing a mathematical mapping to a multispin thermal system, we reveal a\nhidden tipping instability at the scale of the AI's 'atom' (basic Attention\nhead). We derive a simple but essentially exact formula for this tipping point\nwhich shows directly the impact of a user's prompt choice and the AI's training\nbias. We then show how the output tipping can get amplified by the AI's\nmultilayer architecture. As well as helping improve AI transparency,\nexplainability and performance, our results open a path to quantifying users'\nAI risk and legal liabilities.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86AI\u8f93\u51fa\u503e\u659c\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u4f46\u57fa\u672c\u51c6\u786e\u7684\u516c\u5f0f\u6765\u63cf\u8ff0\u8fd9\u79cd\u503e\u659c\u70b9\u3002\u901a\u8fc7\u5efa\u7acb\u6570\u5b66\u6620\u5c04\u5230\u591a\u81ea\u65cb\u70ed\u7cfb\u7edf\uff0c\u9610\u660e\u4e86AI\u503e\u659c\u4e0d\u7a33\u5b9a\u6027\u7684\u673a\u7406\u3002\u8fd9\u4e9b\u7ed3\u679c\u5e2e\u52a9\u6539\u5584AI\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4e3a\u91cf\u5316\u7528\u6237\u7684AI\u98ce\u9669\u548c\u6cd5\u5f8b\u8d23\u4efb\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "AI\u751f\u6210\u7684\u8f93\u51fa\u53ef\u80fd\u4f1a\u5728\u7528\u6237\u6ce8\u610f\u4e0d\u5230\u7684\u60c5\u51b5\u4e0b\u4ece\u597d\uff08\u6b63\u786e\uff09\u8f6c\u53d8\u4e3a\u574f\uff08\u8bef\u5bfc\u6027\u6216\u9519\u8bef\uff09\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5de8\u989d\u635f\u5931\u548c\u5b89\u5168\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u63ed\u793aAI\u8f93\u51fa\u503e\u659c\u7684\u539f\u56e0\u548c\u673a\u7406\u5bf9\u4e8e\u6539\u5584AI\u7684\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5efa\u7acb\u6570\u5b66\u6620\u5c04\u5230\u591a\u81ea\u65cb\u70ed\u7cfb\u7edf\uff0c\u63ed\u793aAI\u503e\u659c\u4e0d\u7a33\u5b9a\u6027\uff0c\u5e76\u63a8\u5bfc\u51fa\u76f8\u5173\u7684\u516c\u5f0f\u3002\u5c55\u793aAI\u8f93\u51fa\u503e\u659c\u5982\u4f55\u53d7\u5230\u591a\u5c42\u4f53\u7cfb\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "result": "\u63ed\u793a\u4e86AI\u7684'\u539f\u5b50'\u5c3a\u5ea6\u4e0a\u9690\u85cf\u7684\u503e\u659c\u4e0d\u7a33\u5b9a\u6027\uff0c\u5e76\u5f97\u51fa\u4e86\u76f8\u5173\u7684\u7b80\u5355\u516c\u5f0f\u3002\u8bc1\u660e\u4e86\u7528\u6237\u63d0\u793a\u9009\u62e9\u548cAI\u8bad\u7ec3\u504f\u5dee\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u591a\u5c42\u4f53\u7cfb\u7ed3\u6784\u5982\u4f55\u653e\u5927\u8fd9\u79cd\u5f71\u54cd\u3002\u4e3a\u91cf\u5316\u7528\u6237\u7684AI\u98ce\u9669\u548c\u6cd5\u5f8b\u8d23\u4efb\u63d0\u4f9b\u4e86\u53ef\u80fd\u7684\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u6570\u5b66\u6620\u5c04\u5230\u591a\u81ea\u65cb\u70ed\u7cfb\u7edf\uff0c\u63ed\u793a\u4e86AI\u7684'\u539f\u5b50'\uff08\u57fa\u672c\u6ce8\u610f\u529b\u5934\uff09\u5c3a\u5ea6\u4e0a\u9690\u85cf\u7684\u503e\u659c\u4e0d\u7a33\u5b9a\u6027\u3002\u6211\u4eec\u5f97\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u4f46\u57fa\u672c\u4e0a\u51c6\u786e\u7684\u516c\u5f0f\uff0c\u663e\u793a\u4e86\u7528\u6237\u63d0\u793a\u9009\u62e9\u548cAI\u8bad\u7ec3\u504f\u5dee\u5bf9\u5176\u503e\u659c\u70b9\u7684\u76f4\u63a5\u5f71\u54cd\u3002\u6211\u4eec\u8fd8\u5c55\u793a\u4e86AI\u8f93\u51fa\u503e\u659c\u5982\u4f55\u53d7\u5230AI\u7684\u591a\u5c42\u4f53\u7cfb\u7ed3\u6784\u7684\u653e\u5927\u3002\u9664\u4e86\u5e2e\u52a9\u63d0\u9ad8AI\u7684\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u5916\uff0c\u6211\u4eec\u7684\u7ed3\u679c\u8fd8\u4e3a\u91cf\u5316\u7528\u6237\u7684AI\u98ce\u9669\u548c\u6cd5\u5f8b\u8d23\u4efb\u5f00\u8f9f\u4e86\u4e00\u6761\u9053\u8def\u3002"}}
{"id": "2508.01109", "categories": ["cs.AI", "68T07", "I.2; J.4"], "pdf": "https://arxiv.org/pdf/2508.01109", "abs": "https://arxiv.org/abs/2508.01109", "authors": ["Satiyabooshan Murugaboopathy", "Connor T. Jerzak", "Adel Daoud"], "title": "Platonic Representations for Poverty Mapping: Unified Vision-Language Codes or Agent-Induced Novelty?", "comment": "7 figures", "summary": "We investigate whether socio-economic indicators like household wealth leave\nrecoverable imprints in satellite imagery (capturing physical features) and\nInternet-sourced text (reflecting historical/economic narratives). Using\nDemographic and Health Survey (DHS) data from African neighborhoods, we pair\nLandsat images with LLM-generated textual descriptions conditioned on\nlocation/year and text retrieved by an AI search agent from web sources. We\ndevelop a multimodal framework predicting household wealth (International\nWealth Index) through five pipelines: (i) vision model on satellite images,\n(ii) LLM using only location/year, (iii) AI agent searching/synthesizing web\ntext, (iv) joint image-text encoder, (v) ensemble of all signals. Our framework\nyields three contributions. First, fusing vision and agent/LLM text outperforms\nvision-only baselines in wealth prediction (e.g., R-squared of 0.77 vs. 0.63 on\nout-of-sample splits), with LLM-internal knowledge proving more effective than\nagent-retrieved text, improving robustness to out-of-country and out-of-time\ngeneralization. Second, we find partial representational convergence: fused\nembeddings from vision/language modalities correlate moderately (median cosine\nsimilarity of 0.60 after alignment), suggesting a shared latent code of\nmaterial well-being while retaining complementary details, consistent with the\nPlatonic Representation Hypothesis. Although LLM-only text outperforms\nagent-retrieved data, challenging our Agent-Induced Novelty Hypothesis, modest\ngains from combining agent data in some splits weakly support the notion that\nagent-gathered information introduces unique representational structures not\nfully captured by static LLM knowledge. Third, we release a large-scale\nmultimodal dataset comprising more than 60,000 DHS clusters linked to satellite\nimages, LLM-generated descriptions, and agent-retrieved texts.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6574\u5408\u536b\u661f\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\uff0c\u6210\u529f\u9884\u6d4b\u4e86\u5bb6\u5ead\u8d22\u5bcc\u6c34\u5e73\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u6001\u7684\u878d\u5408\u5728\u8d22\u5bcc\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5b58\u5728\u4e00\u5b9a\u7684\u5171\u4eab\u6f5c\u5728\u7f16\u7801\u3002\u7814\u7a76\u6570\u636e\u96c6\u5305\u542b60,000\u591a\u4e2aDHS\u96c6\u7fa4\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\uff08\u5982\u5bb6\u5ead\u8d22\u5bcc\uff09\u662f\u5426\u5728\u536b\u661f\u56fe\u50cf\u548c\u7f51\u7edc\u6587\u672c\u4e2d\u7559\u4e0b\u53ef\u68c0\u6d4b\u7684\u75d5\u8ff9\uff0c\u4ee5\u63d0\u9ad8\u8d22\u5bcc\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002\u6211\u4eec\u5173\u6ce8\u5982\u4f55\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\uff0c\u4ee5\u53ca\u4e0d\u540c\u6a21\u6001\u4e4b\u95f4\u662f\u5426\u5b58\u5728\u5171\u4eab\u7684\u6f5c\u5728\u7f16\u7801\uff0c\u8fdb\u4e00\u6b65\u4e86\u89e3\u8fd9\u4e9b\u6570\u636e\u6e90\u5728\u8d22\u5bcc\u9884\u6d4b\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u6765\u81ea\u975e\u6d32\u793e\u533a\u7684\u4eba\u53e3\u548c\u5065\u5eb7\u8c03\u67e5\uff08DHS\uff09\u6570\u636e\uff0c\u6211\u4eec\u7ed3\u5408\u4e86Landsat\u56fe\u50cf\u3001LLM\u751f\u6210\u7684\u6587\u672c\u63cf\u8ff0\u548c\u6765\u81ea\u7f51\u7edc\u6765\u6e90\u7684\u6587\u672c\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\u6765\u9884\u6d4b\u5bb6\u5ead\u8d22\u5bcc\uff08\u56fd\u9645\u8d22\u5bcc\u6307\u6570\uff09\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e94\u79cd\u6d41\u7a0b\uff1a\uff08i\uff09\u57fa\u4e8e\u536b\u661f\u56fe\u50cf\u7684\u89c6\u89c9\u6a21\u578b\uff0c\uff08ii\uff09\u4ec5\u4f7f\u7528\u4f4d\u7f6e/\u5e74\u4efd\u6570\u636e\u7684LLM\uff0c\uff08iii\uff09AI\u4ee3\u7406\u641c\u7d22/\u5408\u6210\u7f51\u7edc\u6587\u672c\uff0c\uff08iv\uff09\u8054\u5408\u56fe\u50cf-\u6587\u672c\u7f16\u7801\u5668\uff0c\uff08v\uff09\u6240\u6709\u4fe1\u53f7\u7684\u96c6\u5408\u3002", "result": "\u901a\u8fc7\u6574\u5408\u536b\u661f\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\uff0c\u6211\u4eec\u7684\u591a\u6a21\u6001\u6846\u67b6\u5728\u8d22\u5bcc\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\uff0c\u8d85\u8d8a\u4e86\u4ec5\u4f7f\u7528\u89c6\u89c9\u6a21\u578b\u7684\u57fa\u51c6\u7ebf\u3002\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u6001\u7684\u878d\u5408\u5d4c\u5165\u5728\u4ee3\u8868\u7269\u8d28\u798f\u7949\u7684\u5171\u4eab\u6f5c\u5728\u4ee3\u7801\u4e2d\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u4f3c\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u4e92\u8865\u7ec6\u8282\uff0c\u652f\u6301\u4e86\u67cf\u62c9\u56fe\u8868\u5f81\u5047\u8bbe\u3002\u540c\u65f6\uff0c\u6211\u4eec\u53d1\u5e03\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u53d1\u5c55\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u536b\u661f\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\uff0c\u6211\u4eec\u7684\u591a\u6a21\u6001\u6846\u67b6\u5728\u8d22\u5bcc\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\uff0c\u8d85\u8d8a\u4e86\u4ec5\u4f7f\u7528\u89c6\u89c9\u6a21\u578b\u7684\u57fa\u51c6\u7ebf\u3002\u7814\u7a76\u8868\u660e\uff0c\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u6001\u7684\u878d\u5408\u5d4c\u5165\u5728\u4ee3\u8868\u7269\u8d28\u798f\u7949\u7684\u5171\u4eab\u6f5c\u5728\u4ee3\u7801\u4e2d\u5177\u6709\u4e00\u5b9a\u7684\u76f8\u4f3c\u6027\uff0c\u652f\u6301\u4e86\u67cf\u62c9\u56fe\u8868\u5f81\u5047\u8bbe\u3002\u6211\u4eec\u8fd8\u53d1\u5e03\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e86\u8d85\u8fc760,000\u4e2aDHS\u96c6\u7fa4\uff0c\u5176\u4e2d\u5305\u62ec\u536b\u661f\u56fe\u50cf\u3001LLM\u751f\u6210\u7684\u63cf\u8ff0\u548cAI\u4ee3\u7406\u68c0\u7d22\u7684\u6587\u672c\u3002"}}
{"id": "2508.01158", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01158", "abs": "https://arxiv.org/abs/2508.01158", "authors": ["Yunlong Lin", "Zirui Li", "Guodong Du", "Xiaocong Zhao", "Cheng Gong", "Xinwei Wang", "Chao Lu", "Jianwei Gong"], "title": "H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving", "comment": "Open source code: https://github.com/BIT-Jack/H2C-lifelong", "summary": "Deep learning (DL) has shown state-of-the-art performance in trajectory\nprediction, which is critical to safe navigation in autonomous driving (AD).\nHowever, most DL-based methods suffer from catastrophic forgetting, where\nadapting to a new distribution may cause significant performance degradation in\npreviously learned ones. Such inability to retain learned knowledge limits\ntheir applicability in the real world, where AD systems need to operate across\nvarying scenarios with dynamic distributions. As revealed by neuroscience, the\nhippocampal circuit plays a crucial role in memory replay, effectively\nreconstructing learned knowledge based on limited resources. Inspired by this,\nwe propose a hippocampal circuit-inspired continual learning method (H2C) for\ntrajectory prediction across varying scenarios. H2C retains prior knowledge by\nselectively recalling a small subset of learned samples. First, two\ncomplementary strategies are developed to select the subset to represent\nlearned knowledge. Specifically, one strategy maximizes inter-sample diversity\nto represent the distinctive knowledge, and the other estimates the overall\nknowledge by equiprobable sampling. Then, H2C updates via a memory replay loss\nfunction calculated by these selected samples to retain knowledge while\nlearning new data. Experiments based on various scenarios from the INTERACTION\ndataset are designed to evaluate H2C. Experimental results show that H2C\nreduces catastrophic forgetting of DL baselines by 22.71% on average in a\ntask-free manner, without relying on manually informed distributional shifts.\nThe implementation is available at https://github.com/BIT-Jack/H2C-lifelong.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d77\u9a6c\u56de\u8def\u7075\u611f\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff08H2C\uff09\uff0c\u7528\u4e8e\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u8fdb\u884c\u8f68\u8ff9\u9884\u6d4b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cH2C\u5728\u65e0\u9700\u624b\u52a8\u901a\u77e5\u5206\u5e03\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u5e73\u5747\u51cf\u5c11\u4e86DL\u57fa\u7ebf\u6a21\u578b\u7684\u707e\u96be\u6027\u9057\u5fd8\u7387\u8fbe\u523022.71%\u3002", "motivation": "\u7531\u4e8e\u5927\u591a\u6570\u57fa\u4e8eDL\u7684\u65b9\u6cd5\u906d\u53d7\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\uff0c\u56e0\u6b64\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3DL\u65b9\u6cd5\u7684\u8fd9\u4e00\u5c40\u9650\u6027\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5f00\u53d1\u4e24\u79cd\u4e92\u8865\u7b56\u7565\u6765\u9009\u62e9\u4e00\u5c0f\u90e8\u5206\u5b66\u4e60\u6837\u672c\uff0c\u4ee3\u8868\u5df2\u5b66\u77e5\u8bc6\uff0c\u7136\u540e\u901a\u8fc7\u8fd9\u4e9b\u9009\u5b9a\u7684\u6837\u672c\u8ba1\u7b97\u5185\u5b58\u56de\u653e\u635f\u5931\u51fd\u6570\u6765\u66f4\u65b0H2C\uff0c\u4ece\u800c\u5728\u5b66\u4e60\u65b0\u6570\u636e\u7684\u540c\u65f6\u4fdd\u7559\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eH2C\u76f8\u8f83DL\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u4efb\u52a1\u81ea\u7531\u72b6\u6001\u4e0b\u5e73\u5747\u51cf\u5c11\u4e8622.71%\u7684\u707e\u96be\u6027\u9057\u5fd8\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d77\u9a6c\u56de\u8def\u7075\u611f\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff08H2C\uff09\uff0c\u7528\u4e8e\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u8fdb\u884c\u8f68\u8ff9\u9884\u6d4b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cH2C\u5728\u65e0\u9700\u624b\u52a8\u901a\u77e5\u5206\u5e03\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u5e73\u5747\u51cf\u5c11\u4e86DL\u57fa\u7ebf\u6a21\u578b\u7684\u707e\u96be\u6027\u9057\u5fd8\u7387\u8fbe\u523022.71%\u3002"}}
{"id": "2508.01181", "categories": ["cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS", "68", "I.2.10"], "pdf": "https://arxiv.org/pdf/2508.01181", "abs": "https://arxiv.org/abs/2508.01181", "authors": ["Zhiyuan Han", "Beier Zhu", "Yanlong Xu", "Peipei Song", "Xun Yang"], "title": "Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning", "comment": "ACM Multimedia 2025", "summary": "Despite their strong performance in multimodal emotion reasoning, existing\nMultimodal Large Language Models (MLLMs) often overlook the scenarios involving\nemotion conflicts, where emotional cues from different modalities are\ninconsistent. To fill this gap, we first introduce CA-MER, a new benchmark\ndesigned to examine MLLMs under realistic emotion conflicts. It consists of\nthree subsets: video-aligned, audio-aligned, and consistent, where only one or\nall modalities reflect the true emotion. However, evaluations on our CA-MER\nreveal that current state-of-the-art emotion MLLMs systematically over-rely on\naudio signal during emotion conflicts, neglecting critical cues from visual\nmodality. To mitigate this bias, we propose MoSEAR, a parameter-efficient\nframework that promotes balanced modality integration. MoSEAR consists of two\nmodules: (1)MoSE, modality-specific experts with a regularized gating mechanism\nthat reduces modality bias in the fine-tuning heads; and (2)AR, an attention\nreallocation mechanism that rebalances modality contributions in frozen\nbackbones during inference. Our framework offers two key advantages: it\nmitigates emotion conflicts and improves performance on consistent\nsamples-without incurring a trade-off between audio and visual modalities.\nExperiments on multiple benchmarks-including MER2023, EMER, DFEW, and our\nCA-MER-demonstrate that MoSEAR achieves state-of-the-art performance,\nparticularly under modality conflict conditions.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165CA-MER\u57fa\u51c6\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u7eea\u51b2\u7a81\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51faMoSEAR\u6846\u67b6\u4ee5\u5e73\u8861\u6a21\u6001\u96c6\u6210\u3001\u51cf\u5c11\u504f\u89c1\u3002\u5b9e\u9a8c\u8bc1\u660eMoSEAR\u5728\u60c5\u7eea\u51b2\u7a81\u4e0b\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5728MER2023\u3001EMER\u3001DFEW\u548cCA-MER\u7b49\u591a\u4e2a\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f73\u8868\u73b0\u3002", "motivation": "Existing multimodal large language models lack consideration for scenarios with emotion conflicts, where cues from different modalities are inconsistent. The goal is to address this gap and improve emotion reasoning in such conditions.", "method": "Introduces CA-MER benchmark to evaluate multimodal large language models under emotion conflicts. Proposes MoSEAR framework with modality-specific experts and attention reallocation mechanism to balance modality integration and reduce bias. Conducts experiments on MER2023, EMER, DFEW, and CA-MER to validate the framework's performance under modality conflicts.", "result": "MoSEAR framework mitigates bias towards audio signals during emotion conflicts, enhances performance on consistent samples, and outperforms existing state-of-the-art emotion large language models in modality conflict scenarios.", "conclusion": "MoSEAR framework improves emotion reasoning performance in multimodal large language models by addressing bias towards audio signals during emotion conflicts, achieving state-of-the-art results across multiple benchmarks."}}
{"id": "2508.01186", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.01186", "abs": "https://arxiv.org/abs/2508.01186", "authors": ["Chaojia Yu", "Zihan Cheng", "Hanwen Cui", "Yishuo Gao", "Zexu Luo", "Yijin Wang", "Hangbin Zheng", "Yong Zhao"], "title": "A Survey on Agent Workflow -- Status and Future", "comment": "12 pages, 3 figures, accepted to IEEE Conference,\n  ICAIBD(International Conference of Artificial Intelligence and Big Data)\n  2025. This is the author's version, not the publisher's. See\n  https://ieeexplore.ieee.org/document/11082076", "summary": "In the age of large language models (LLMs), autonomous agents have emerged as\na powerful paradigm for achieving general intelligence. These agents\ndynamically leverage tools, memory, and reasoning capabilities to accomplish\nuser-defined goals. As agent systems grow in complexity, agent\nworkflows-structured orchestration frameworks-have become central to enabling\nscalable, controllable, and secure AI behaviors. This survey provides a\ncomprehensive review of agent workflow systems, spanning academic frameworks\nand industrial implementations. We classify existing systems along two key\ndimensions: functional capabilities (e.g., planning, multi-agent collaboration,\nexternal API integration) and architectural features (e.g., agent roles,\norchestration flows, specification languages). By comparing over 20\nrepresentative systems, we highlight common patterns, potential technical\nchallenges, and emerging trends. We further address concerns related to\nworkflow optimization strategies and security. Finally, we outline open\nproblems such as standardization and multimodal integration, offering insights\nfor future research at the intersection of agent design, workflow\ninfrastructure, and safe automation.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\uff0c\u5206\u7c7b\u548c\u6bd4\u8f83\u4e8620\u591a\u4e2a\u7cfb\u7edf\uff0c\u5f3a\u8c03\u4e86\u529f\u80fd\u80fd\u529b\u548c\u67b6\u6784\u7279\u5f81\u3002\u8ba8\u8bba\u4e86\u6280\u672f\u6311\u6218\u3001\u65b0\u5174\u8d8b\u52bf\u4ee5\u53ca\u4e0e\u5de5\u4f5c\u6d41\u4f18\u5316\u7b56\u7565\u548c\u5b89\u5168\u6027\u76f8\u5173\u7684\u95ee\u9898\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e9b\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u548c\u89c1\u89e3\u3002", "motivation": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\uff0c\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\u662f\u5b9e\u73b0\u901a\u7528\u667a\u80fd\u7684\u5f3a\u5927\u8303\u5f0f\u3002\u4ee3\u7406\u7cfb\u7edf\u4e0d\u65ad\u5229\u7528\u5de5\u5177\u3001\u8bb0\u5fc6\u548c\u63a8\u7406\u80fd\u529b\u6765\u5b9e\u73b0\u7528\u6237\u5b9a\u4e49\u7684\u76ee\u6807\u3002\u968f\u7740\u4ee3\u7406\u7cfb\u7edf\u590d\u6742\u6027\u7684\u589e\u957f\uff0c\u4ee3\u7406\u5de5\u4f5c\u6d41\u7ed3\u6784\u5316\u7f16\u6392\u6846\u67b6\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u63a7\u548c\u5b89\u5168\u7684\u4eba\u5de5\u667a\u80fd\u884c\u4e3a\u3002", "method": "\u5bf9\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\u8fdb\u884c\u4e86\u5168\u9762\u56de\u987e\uff0c\u5206\u7c7b\u73b0\u6709\u7cfb\u7edf\uff0c\u5e76\u6bd4\u8f83\u4e8620\u591a\u4e2a\u4ee3\u8868\u6027\u7cfb\u7edf\u3002\u7a81\u51fa\u4e86\u529f\u80fd\u80fd\u529b\u548c\u67b6\u6784\u7279\u5f81\u4e24\u4e2a\u5173\u952e\u7ef4\u5ea6\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\u7684\u7efc\u5408\u56de\u987e\uff0c\u5206\u7c7b\u73b0\u6709\u7cfb\u7edf\uff0c\u5e76\u6bd4\u8f83\u4e86\u8d85\u8fc720\u4e2a\u4ee3\u8868\u6027\u7cfb\u7edf\u3002\u5f3a\u8c03\u4e86\u5171\u540c\u6a21\u5f0f\u3001\u6f5c\u5728\u6280\u672f\u6311\u6218\u548c\u65b0\u5174\u8d8b\u52bf\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u4e0e\u5de5\u4f5c\u6d41\u4f18\u5316\u7b56\u7565\u548c\u5b89\u5168\u6027\u76f8\u5173\u7684\u95ee\u9898\u3002\u6700\u540e\uff0c\u6982\u8ff0\u4e86\u4e00\u4e9b\u5f00\u653e\u6027\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u7684\u89c1\u89e3\u3002", "conclusion": "\u5bf9\u4ee3\u7406\u5de5\u4f5c\u6d41\u7cfb\u7edf\u8fdb\u884c\u4e86\u5168\u9762\u56de\u987e\uff0c\u63d0\u4f9b\u4e86\u5728\u5b66\u672f\u6846\u67b6\u548c\u5de5\u4e1a\u5b9e\u73b0\u4e2d\u8fdb\u884c\u5206\u7c7b\u7684\u8c03\u67e5\u3002\u7a81\u51fa\u4e86\u5e38\u89c1\u6a21\u5f0f\u3001\u6f5c\u5728\u6280\u672f\u6311\u6218\u548c\u65b0\u5174\u8d8b\u52bf\u3002\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86\u4e0e\u5de5\u4f5c\u6d41\u4f18\u5316\u7b56\u7565\u548c\u5b89\u5168\u6027\u76f8\u5173\u7684\u95ee\u9898\u3002\u6700\u540e\uff0c\u6982\u8ff0\u4e86\u6807\u51c6\u5316\u548c\u591a\u6a21\u6001\u96c6\u6210\u7b49\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4e3a\u4ee3\u7406\u8bbe\u8ba1\u3001\u5de5\u4f5c\u6d41\u57fa\u7840\u8bbe\u65bd\u548c\u5b89\u5168\u81ea\u52a8\u5316\u4ea4\u53c9\u7814\u7a76\u7684\u672a\u6765\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2508.01191", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.01191", "abs": "https://arxiv.org/abs/2508.01191", "authors": ["Chengshuai Zhao", "Zhen Tan", "Pingchuan Ma", "Dawei Li", "Bohan Jiang", "Yancheng Wang", "Yingzhen Yang", "Huan Liu"], "title": "Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens", "comment": null, "summary": "Chain-of-Thought (CoT) prompting has been shown to improve Large Language\nModel (LLM) performance on various tasks. With this approach, LLMs appear to\nproduce human-like reasoning steps before providing answers (a.k.a., CoT\nreasoning), which often leads to the perception that they engage in deliberate\ninferential processes. However, some initial findings suggest that CoT\nreasoning may be more superficial than it appears, motivating us to explore\nfurther. In this paper, we study CoT reasoning via a data distribution lens and\ninvestigate if CoT reasoning reflects a structured inductive bias learned from\nin-distribution data, allowing the model to conditionally generate reasoning\npaths that approximate those seen during training. Thus, its effectiveness is\nfundamentally bounded by the degree of distribution discrepancy between the\ntraining data and the test queries. With this lens, we dissect CoT reasoning\nvia three dimensions: task, length, and format. To investigate each dimension,\nwe design DataAlchemy, an isolated and controlled environment to train LLMs\nfrom scratch and systematically probe them under various distribution\nconditions. Our results reveal that CoT reasoning is a brittle mirage that\nvanishes when it is pushed beyond training distributions. This work offers a\ndeeper understanding of why and when CoT reasoning fails, emphasizing the\nongoing challenge of achieving genuine and generalizable reasoning.", "AI": {"tldr": "Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) appears to be human-like but is revealed to be superficial when tested with queries outside training data. CoT reasoning is found to lack genuine and generalizable reasoning capabilities, emphasizing the challenges in achieving authentic reasoning in LLMs.", "motivation": "Initial findings suggest that CoT reasoning may be more superficial than perceived, prompting the authors to explore further and understand if it is a result of structured inductive bias. The motivation is to delve into the effectiveness of CoT reasoning and its limitations when faced with test queries outside the training data distributions.", "method": "The paper studies CoT reasoning through a data distribution lens to investigate if it reflects a structured inductive bias learned from in-distribution data. The authors designed DataAlchemy, an isolated environment, to train LLMs from scratch and systematically probe them under various distribution conditions.", "result": "The results demonstrate that CoT reasoning is constrained by the degree of distribution discrepancy between training data and test queries. The study dissects CoT reasoning across three dimensions: task, length, and format, revealing its limitations and vulnerabilities when pushed beyond the boundaries of training distributions.", "conclusion": "CoT reasoning is found to be a brittle mirage that disappears when faced with test queries beyond the training distributions, indicating a lack of genuine and generalizable reasoning in Large Language Models (LLMs). This study highlights the challenges in achieving authentic reasoning capabilities."}}
{"id": "2508.01203", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01203", "abs": "https://arxiv.org/abs/2508.01203", "authors": ["Junjie Shi", "Wei Ma", "Shi Ying", "Lingxiao Jiang", "Yang liu", "Bo Du"], "title": "Importance Sampling is All You Need: Predict LLM's performance on new benchmark by reusing existing benchmark", "comment": null, "summary": "With the rapid advancement of large language models , code generation has\nbecome a key benchmark for evaluating LLM capabilities. However, existing\nbenchmarks face two major challenges: (1) the escalating cost of constructing\nhigh-quality test suites and reference solutions, and (2) the increasing risk\nof data contamination, which undermines the reliability of benchmark-based\nevaluations. In this paper, we propose BIS, a prompt-centric evaluation\nframework that enables ground-truth-free prediction of LLM performance on code\ngeneration tasks. Rather than executing generated code, BIS estimates\nperformance metrics by analyzing the prompt distribution alone. Built on\nimportance sampling theory and implemented using Importance Weighted\nAutoencoders, our method reweights samples from existing annotated benchmarks\nto estimate performance on new, unseen benchmarks. To stabilize the estimation,\nwe introduce weight truncation strategies and compute marginal expectations\nacross the fitted distributions. BIS serves as a complementary tool that\nsupports benchmark development and validation under constrained resources,\noffering actionable and quick feedback for prompt selection and contamination\nassessment. We conduct extensive experiments involving 8,000 evaluation points\nacross 4 CodeLlama models and 9 diverse benchmarks. Our framework achieves an\naverage absolute prediction error of 1.1% for code correctness scores, with\nbest- and worst-case errors of 0.3% and 1.9%, respectively. It also generalizes\nwell to other metrics, attaining average absolute errors of 2.15% for pass@1.\nThese results demonstrate the reliability and broad applicability of BIS, which\ncan significantly reduce the cost and effort of benchmarking LLMs in\ncode-related tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BIS\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790Prompt\u5206\u5e03\u5b9e\u73b0\u4e86\u5bf9LLM\u6027\u80fd\u7684\u9884\u6d4b\uff0c\u65e0\u9700\u771f\u5b9e\u6570\u636e\u3002\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0cBIS\u5229\u7528\u91cd\u8981\u6027\u52a0\u6743\u81ea\u7f16\u7801\u5668\u5bf9\u73b0\u6709\u6807\u8bb0\u57fa\u51c6\u8fdb\u884c\u6837\u672c\u52a0\u6743\uff0c\u4f30\u8ba1\u65b0\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u3002\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\uff0cBIS\u5728\u4ee3\u7801\u6b63\u786e\u6027\u5f97\u5206\u4e0a\u5e73\u5747\u7edd\u5bf9\u9884\u6d4b\u8bef\u5dee\u4e3a1.1%\uff0c\u4e14\u6cdb\u5316\u6027\u80fd\u826f\u597d\u3002\u8be5\u6846\u67b6\u53ef\u663e\u8457\u964d\u4f4e\u8bc4\u4f30LLMs\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6210\u672c\u548c\u5de5\u4f5c\u91cf\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u57fa\u51c6\u9762\u4e34\u6784\u5efa\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u5957\u4ef6\u548c\u53c2\u8003\u89e3\u51b3\u65b9\u6848\u6210\u672c\u4e0a\u5347\u4ee5\u53ca\u6570\u636e\u6c61\u67d3\u98ce\u9669\u589e\u52a0\u7b49\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86BIS\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002BIS\u6846\u67b6\u53ef\u4ee5\u5728\u4e0d\u9700\u771f\u5b9e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4f30\u8ba1LLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u57fa\u51c6\u5f00\u53d1\u548c\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u548c\u5feb\u901f\u53cd\u9988\u3002", "method": "\u57fa\u4e8e\u91cd\u8981\u6027\u62bd\u6837\u7406\u8bba\uff0c\u4f7f\u7528\u91cd\u8981\u6027\u52a0\u6743\u81ea\u7f16\u7801\u5668\u5b9e\u73b0BIS\u6846\u67b6\u3002\u91cd\u65b0\u52a0\u6743\u73b0\u6709\u6807\u8bb0\u57fa\u51c6\u7684\u6837\u672c\uff0c\u4ee5\u4f30\u8ba1\u5bf9\u65b0\u7684\u3001\u672a\u89c1\u57fa\u51c6\u7684\u6027\u80fd\u3002\u5f15\u5165\u6743\u91cd\u622a\u65ad\u7b56\u7565\u7a33\u5b9a\u4f30\u8ba1\uff0c\u5e76\u8ba1\u7b97\u62df\u5408\u5206\u5e03\u7684\u8fb9\u9645\u671f\u671b\u3002", "result": "\u57288,000\u4e2a\u8bc4\u4f30\u70b9\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u6d89\u53ca4\u4e2aCodeLlama\u6a21\u578b\u548c9\u4e2a\u4e0d\u540c\u57fa\u51c6\uff0cBIS\u6846\u67b6\u5728\u4ee3\u7801\u6b63\u786e\u6027\u5f97\u5206\u4e0a\u5e73\u5747\u7edd\u5bf9\u9884\u6d4b\u8bef\u5dee\u4e3a1.1%\uff0c\u6cdb\u5316\u6027\u80fd\u826f\u597d\uff0c\u5728pass@1\u7b49\u5176\u4ed6\u6307\u6807\u4e0a\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a2.15%\u3002\u8fd9\u4e9b\u7ed3\u679c\u663e\u793a\u4e86BIS\u7684\u53ef\u9760\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u8bc4\u4f30LLMs\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6210\u672c\u548c\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePrompt\u7684\u8bc4\u4f30\u6846\u67b6BIS\uff0c\u53ef\u4ee5\u5728\u4e0d\u9700\u8981\u771f\u5b9e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u9884\u6d4bLLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5206\u6790Prompt\u5206\u5e03\uff0c\u5229\u7528\u91cd\u8981\u6027\u52a0\u6743\u81ea\u7f16\u7801\u5668\u4ece\u73b0\u6709\u6807\u8bb0\u57fa\u51c6\u4e2d\u91cd\u65b0\u4f30\u8ba1\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u7a33\u5b9a\u4f30\u8ba1\u6027\u80fd\uff0c\u5e76\u5f15\u5165\u4e86\u6743\u91cd\u622a\u65ad\u7b56\u7565\u548c\u8ba1\u7b97\u62df\u5408\u5206\u5e03\u7684\u8fb9\u9645\u671f\u671b\u3002BIS\u4f5c\u4e3a\u4e00\u4e2a\u8f85\u52a9\u5de5\u5177\uff0c\u652f\u6301\u57fa\u51c6\u5f00\u53d1\u548c\u9a8c\u8bc1\uff0c\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u7528\u4e8ePrompt\u9009\u62e9\u548c\u6c61\u67d3\u8bc4\u4f30\u7684\u53ef\u64cd\u4f5c\u3001\u5feb\u901f\u53cd\u9988\u3002\u901a\u8fc7\u6d89\u53ca4\u4e2aCodeLlama\u6a21\u578b\u548c9\u4e2a\u4e0d\u540c\u57fa\u51c6\u76848,000\u4e2a\u8bc4\u4f30\u70b9\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5e73\u5747\u7edd\u5bf9\u9884\u6d4b\u8bef\u5dee\u4e3a1.1%\uff0c\u5728\u4ee3\u7801\u6b63\u786e\u6027\u5f97\u5206\u65b9\u9762\u8868\u73b0\u6700\u4f73\u548c\u6700\u5dee\u7684\u9519\u8bef\u5206\u522b\u4e3a0.3%\u548c1.9%\u3002\u540c\u65f6\u5728\u5176\u4ed6\u6307\u6807\u4e0a\u4e5f\u6709\u826f\u597d\u7684\u6cdb\u5316\u6027\u80fd\uff0cpass@1\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4e3a2.15%\u3002\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86BIS\u7684\u53ef\u9760\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u8bc4\u4f30LLMs\u7684\u6210\u672c\u548c\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2508.01208", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01208", "abs": "https://arxiv.org/abs/2508.01208", "authors": ["Mingchen Mei", "Yi Li", "YiYao Qian", "Zijun Jia"], "title": "Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests", "comment": null, "summary": "Fault detection is crucial for ensuring the safety and reliability of modern\nindustrial systems. However, a significant scientific challenge is the lack of\nrigorous risk control and reliable uncertainty quantification in existing\ndiagnostic models, particularly when facing complex scenarios such as\ndistributional shifts. To address this issue, this paper proposes a novel fault\ndetection method that integrates significance testing with the conformal\nprediction framework to provide formal risk guarantees. The method transforms\nfault detection into a hypothesis testing task by defining a nonconformity\nmeasure based on model residuals. It then leverages a calibration dataset to\ncompute p-values for new samples, which are used to construct prediction sets\nmathematically guaranteed to contain the true label with a user-specified\nprobability, $1-\\alpha$. Fault classification is subsequently performed by\nanalyzing the intersection of the constructed prediction set with predefined\nnormal and fault label sets. Experimental results on cross-domain fault\ndiagnosis tasks validate the theoretical properties of our approach. The\nproposed method consistently achieves an empirical coverage rate at or above\nthe nominal level ($1-\\alpha$), demonstrating robustness even when the\nunderlying point-prediction models perform poorly. Furthermore, the results\nreveal a controllable trade-off between the user-defined risk level ($\\alpha$)\nand efficiency, where higher risk tolerance leads to smaller average prediction\nset sizes. This research contributes a theoretically grounded framework for\nfault detection that enables explicit risk control, enhancing the\ntrustworthiness of diagnostic systems in safety-critical applications and\nadvancing the field from simple point predictions to informative,\nuncertainty-aware outputs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u663e\u8457\u6027\u68c0\u9a8c\u548c\u7b26\u5408\u9884\u6d4b\u6846\u67b6\uff0c\u4ee5\u63d0\u4f9b\u98ce\u9669\u4fdd\u8bc1\u3002\u65b9\u6cd5\u57fa\u4e8e\u6a21\u578b\u6b8b\u5dee\u5b9a\u4e49\u975e\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u5229\u7528\u6821\u51c6\u6570\u636e\u96c6\u8ba1\u7b97p\u503c\uff0c\u6784\u5efa\u6570\u5b66\u4fdd\u8bc1\u7684\u9884\u6d4b\u96c6\u3002\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u5728\u6545\u969c\u8bca\u65ad\u4efb\u52a1\u4e0a\u7684\u7406\u8bba\u5c5e\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u7a33\u5065\u6027\u53ca\u7528\u6237\u98ce\u9669\u8bbe\u7f6e\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u8bca\u65ad\u6a21\u578b\u5728\u9762\u5bf9\u590d\u6742\u60c5\u666f\u5982\u5206\u5e03\u8f6c\u79fb\u65f6\u5f80\u5f80\u7f3a\u4e4f\u4e25\u8c28\u7684\u98ce\u9669\u63a7\u5236\u548c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u5f62\u5f0f\u5316\u98ce\u9669\u4fdd\u8bc1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5c06\u6545\u969c\u68c0\u6d4b\u8f6c\u5316\u4e3a\u5047\u8bbe\u68c0\u9a8c\u4efb\u52a1\uff0c\u5e76\u7ed3\u5408\u7b26\u5408\u9884\u6d4b\u6846\u67b6\uff0c\u91c7\u7528\u6a21\u578b\u6b8b\u5dee\u4f5c\u4e3a\u975e\u4e00\u81f4\u6027\u5ea6\u91cf\u3002\u5229\u7528\u6821\u51c6\u6570\u636e\u96c6\u8ba1\u7b97\u65b0\u6837\u672c\u7684p\u503c\uff0c\u6784\u5efa\u6570\u5b66\u4fdd\u8bc1\u7684\u9884\u6d4b\u96c6\u3002\u6545\u969c\u5206\u7c7b\u901a\u8fc7\u5206\u6790\u9884\u6d4b\u96c6\u4e0e\u6b63\u5e38\u548c\u6545\u969c\u6807\u7b7e\u96c6\u7684\u4ea4\u96c6\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8de8\u9886\u57df\u6545\u969c\u8bca\u65ad\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u7406\u8bba\u5c5e\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u540d\u4e49\u6c34\u5e73($1-\\alpha$)\u4e0a\u59cb\u7ec8\u5b9e\u73b0\u4e86\u7ecf\u9a8c\u8986\u76d6\u7387\uff0c\u5c55\u793a\u4e86\u7a33\u5065\u6027\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u7528\u6237\u5b9a\u4e49\u7684\u98ce\u9669\u6c34\u5e73($\\alpha$)\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u53ef\u63a7\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u663e\u8457\u6027\u68c0\u9a8c\u4e0e\u7b26\u5408\u9884\u6d4b\u6846\u67b6\u76f8\u7ed3\u5408\u7684\u65b0\u578b\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u63d0\u4f9b\u5f62\u5f0f\u5316\u98ce\u9669\u4fdd\u8bc1\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u6545\u969c\u68c0\u6d4b\u8f6c\u5316\u4e3a\u5047\u8bbe\u68c0\u9a8c\u4efb\u52a1\uff0c\u57fa\u4e8e\u6a21\u578b\u6b8b\u5dee\u5b9a\u4e49\u4e00\u79cd\u975e\u4e00\u81f4\u6027\u5ea6\u91cf\u3002\u7136\u540e\u5229\u7528\u6821\u51c6\u6570\u636e\u96c6\u4e3a\u65b0\u6837\u672c\u8ba1\u7b97p\u503c\uff0c\u7528\u4e8e\u6784\u5efa\u6570\u5b66\u4e0a\u4fdd\u8bc1\u4ee5\u7528\u6237\u6307\u5b9a\u6982\u7387$1-\\alpha$\u5305\u542b\u771f\u5b9e\u6807\u7b7e\u7684\u9884\u6d4b\u96c6\u3002\u6545\u969c\u5206\u7c7b\u968f\u540e\u901a\u8fc7\u5206\u6790\u6784\u5efa\u7684\u9884\u6d4b\u96c6\u4e0e\u9884\u5b9a\u4e49\u7684\u6b63\u5e38\u548c\u6545\u969c\u6807\u7b7e\u96c6\u7684\u4ea4\u96c6\u8fdb\u884c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u59cb\u7ec8\u5b9e\u73b0\u4e86\u9ad8\u4e8e\u540d\u4e49\u6c34\u5e73($1-\\alpha$)\u7684\u7ecf\u9a8c\u8986\u76d6\u7387\uff0c\u5373\u4f7f\u57fa\u7840\u70b9\u9884\u6d4b\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u4e5f\u8868\u73b0\u51fa\u7a33\u5065\u6027\u3002\u6b64\u5916\uff0c\u7ed3\u679c\u663e\u793a\u4e86\u7528\u6237\u5b9a\u4e49\u7684\u98ce\u9669\u6c34\u5e73($\\alpha$)\u4e0e\u6548\u7387\u4e4b\u95f4\u53ef\u63a7\u7684\u6743\u8861\uff0c\u98ce\u9669\u5bb9\u5fcd\u5ea6\u8f83\u9ad8\u4f1a\u5bfc\u81f4\u8f83\u5c0f\u7684\u5e73\u5747\u9884\u6d4b\u96c6\u5927\u5c0f\u3002"}}
{"id": "2508.01237", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01237", "abs": "https://arxiv.org/abs/2508.01237", "authors": ["Cheng Tan", "Qi Chen", "Jingxuan Wei", "Gaowei Wu", "Zhangyang Gao", "Siyuan Li", "Bihui Yu", "Ruifeng Guo", "Stan Z. Li"], "title": "SketchAgent: Generating Structured Diagrams from Hand-Drawn Sketches", "comment": "Accepted by IJCAI 2025", "summary": "Hand-drawn sketches are a natural and efficient medium for capturing and\nconveying ideas. Despite significant advancements in controllable natural image\ngeneration, translating freehand sketches into structured, machine-readable\ndiagrams remains a labor-intensive and predominantly manual task. The primary\nchallenge stems from the inherent ambiguity of sketches, which lack the\nstructural constraints and semantic precision required for automated diagram\ngeneration. To address this challenge, we introduce SketchAgent, a multi-agent\nsystem designed to automate the transformation of hand-drawn sketches into\nstructured diagrams. SketchAgent integrates sketch recognition, symbolic\nreasoning, and iterative validation to produce semantically coherent and\nstructurally accurate diagrams, significantly reducing the need for manual\neffort. To evaluate the effectiveness of our approach, we propose the\nSketch2Diagram Benchmark, a comprehensive dataset and evaluation framework\nencompassing eight diverse diagram categories, such as flowcharts, directed\ngraphs, and model architectures. The dataset comprises over 6,000 high-quality\nexamples with token-level annotations, standardized preprocessing, and rigorous\nquality control. By streamlining the diagram generation process, SketchAgent\nholds great promise for applications in design, education, and engineering,\nwhile offering a significant step toward bridging the gap between intuitive\nsketching and machine-readable diagram generation. The benchmark is released at\nhttps://huggingface.co/datasets/DiagramAgent/Sketch2Diagram-Benchmark.", "AI": {"tldr": "SketchAgent automates transforming hand-drawn sketches into structured diagrams, introducing the Sketch2Diagram Benchmark for evaluation. It integrates sketch recognition, symbolic reasoning, and iterative validation, aiming to reduce manual efforts significantly and bridging the gap between intuitive sketching and machine-readable diagram generation.", "motivation": "The paper aims to tackle the labor-intensive and manual task of translating freehand sketches into machine-readable diagrams. It emphasizes the gap between intuitive sketching and automated diagram generation, aiming to streamline the process.", "method": "SketchAgent integrates sketch recognition, symbolic reasoning, and iterative validation to transform hand-drawn sketches into structured diagrams. It focuses on addressing the ambiguity of sketches by ensuring semantic coherence and structural accuracy.", "result": "SketchAgent shows promise in applications such as design, education, and engineering by bridging the gap between intuitive sketching and machine-readable diagram generation.", "conclusion": "SketchAgent is introduced as a multi-agent system to automate hand-drawn sketches into structured diagrams, reducing manual efforts significantly. The Sketch2Diagram Benchmark is proposed for evaluating the effectiveness of the approach, encompassing diverse diagram categories and over 6,000 high-quality examples."}}
{"id": "2508.01261", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01261", "abs": "https://arxiv.org/abs/2508.01261", "authors": ["Sushant Mehta", "Raj Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Unifying Mixture of Experts and Multi-Head Latent Attention for Efficient Language Models", "comment": null, "summary": "We present MoE-MLA-RoPE, a novel architecture combination that combines\nMixture of Experts (MoE) with Multi-head Latent Attention (MLA) and Rotary\nPosition Embeddings (RoPE) for efficient language modeling. Our approach\naddresses the fundamental trade-off between model capacity and computational\nefficiency through three key innovations: (1) fine-grained expert routing with\n64 micro-experts and top-$k$ selection, enabling flexible specialization\nthrough 3.6 * 10^7 possible expert combinations; (2) shared expert isolation\nthat dedicates 2 always active experts for common patterns while routing to 6\nof 62 specialized experts; and (3) gradient-conflict-free load balancing that\nmaintains expert utilization without interfering with primary loss\noptimization.\n  Extensive experiments on models ranging from 17M to 202M parameters\ndemonstrate that MoE-MLA-RoPE with compression ratio r=d/2 achieves 68% KV\ncache memory reduction and 3.2x inference speedup while maintaining competitive\nperplexity (0.8% degradation). Compared to the parameters with 53.9M\nparameters, MoE-MLA-RoPE improves the validation loss by 6.9% over the vanilla\ntransformers while using 42% fewer active parameters per forward pass.\nFLOP-matched experiments reveal even larger gains: 11.1% improvement with 3.2x\ninference acceleration. Automated evaluation using GPT-4 as a judge confirms\nquality improvements in generation, with higher scores on coherence (8.1/10),\ncreativity (7.9/10) and grammatical correctness (8.2/10). Our results establish\nthat architectural novelty, not parameter scaling, defines the efficiency\nfrontier for resource-constrained language model deployment.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86MoE-MLA-RoPE\u67b6\u6784\uff0c\u7ed3\u5408\u4e86MoE\u3001MLA\u548cRoPE\uff0c\u7528\u4e8e\u9ad8\u6548\u7684\u8bed\u8a00\u5efa\u6a21\u3002\u901a\u8fc7\u521b\u65b0\u7684\u4e13\u5bb6\u8def\u7531\u3001\u5171\u4eab\u4e13\u5bb6\u9694\u79bb\u548c\u8d1f\u8f7d\u5e73\u8861\uff0c\u89e3\u51b3\u4e86\u6a21\u578b\u5bb9\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u7684\u6298\u8877\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cMoE-MLA-RoPE\u5728\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u52a0\u901f\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u6709\u6240\u63d0\u5347\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u67b6\u6784\u521b\u65b0\u6bd4\u53c2\u6570\u89c4\u6a21\u5b9a\u4e49\u4e86\u6548\u7387\u524d\u6cbf\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u6a21\u578b\u5bb9\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u51faMoE-MLA-RoPE\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u60c5\u51b5\u4e0b\u7684\u9ad8\u6548\u8bed\u8a00\u5efa\u6a21\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u521b\u65b0\u89e3\u51b3\u4e86\u6a21\u578b\u5bb9\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u57fa\u672c\u6298\u8877\uff1a\uff081\uff0964\u4e2a\u5fae\u4e13\u5bb6\u548ctop- k\u9009\u62e9\u7684\u7ec6\u7c92\u5ea6\u4e13\u5bb6\u8def\u7531\uff0c\u5b9e\u73b0\u4e863.6*10^7\u79cd\u4e13\u5bb6\u7ec4\u5408\u7684\u7075\u6d3b\u4e13\u4e1a\u5316\uff1b\uff082\uff09\u5171\u4eab\u4e13\u5bb6\u9694\u79bb\uff0c\u4e3a\u5e38\u89c1\u6a21\u5f0f\u4e13\u95e8\u5206\u914d\u4e862\u4e2a\u59cb\u7ec8\u6d3b\u52a8\u7684\u4e13\u5bb6\uff0c\u540c\u65f6\u8def\u7531\u523062\u4e2a\u4e13\u4e1a\u5316\u4e13\u5bb6\u4e2d\u76846\u4e2a\uff1b\uff083\uff09\u68af\u5ea6\u51b2\u7a81\u81ea\u7531\u7684\u8d1f\u8f7d\u5e73\u8861\uff0c\u901a\u8fc7\u7ef4\u62a4\u4e13\u5bb6\u5229\u7528\u7387\u800c\u4e0d\u5e72\u6270\u4e3b\u8981\u635f\u5931\u4f18\u5316\u3002", "result": "\u7ecf\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0cMoE-MLA-RoPE\u5728\u6a21\u578b\u53c2\u6570\u8303\u56f4\u4ece17M\u5230202M\u4e4b\u95f4\uff0c\u5b9e\u73b0\u4e86\u5185\u5b58\u51cf\u5c11\u3001\u63a8\u7406\u52a0\u901f\u7684\u6548\u679c\uff0c\u5e76\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u7684\u56f0\u60d1\u5ea6\u3002\u4e0e53.9M\u53c2\u6570\u7684\u6a21\u578b\u76f8\u6bd4\uff0cMoE-MLA-RoPE\u5728\u9a8c\u8bc1\u635f\u5931\u65b9\u9762\u53d6\u5f97\u4e866.9%\u7684\u6539\u5584\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86MoE-MLA-RoPE\uff0c\u8fd9\u662f\u4e00\u79cd\u521b\u65b0\u7684\u67b6\u6784\u7ec4\u5408\uff0c\u7ed3\u5408\u4e86\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u3001\u591a\u5934\u6f5c\u5728\u6ce8\u610f\uff08MLA\uff09\u548c\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff08RoPE\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u7684\u8bed\u8a00\u5efa\u6a21\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cMoE-MLA-RoPE\u5728\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u52a0\u901f\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u5584\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u7684\u56f0\u60d1\u5ea6\u3002\u901a\u8fc7\u5bf9GPT-4\u8fdb\u884c\u81ea\u52a8\u8bc4\u4f30\uff0c\u8bc1\u5b9e\u4e86\u5176\u751f\u6210\u8d28\u91cf\u7684\u63d0\u9ad8\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u4e2d\uff0c\u67b6\u6784\u521b\u65b0\u800c\u975e\u53c2\u6570\u7f29\u653e\u5b9a\u4e49\u4e86\u6548\u7387\u524d\u6cbf\u3002"}}
{"id": "2508.01268", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.01268", "abs": "https://arxiv.org/abs/2508.01268", "authors": ["Roya Arkhmammadova", "Hosein Madadi Tamar", "M. Emre Gursoy"], "title": "Win-k: Improved Membership Inference Attacks on Small Language Models", "comment": null, "summary": "Small language models (SLMs) are increasingly valued for their efficiency and\ndeployability in resource-constrained environments, making them useful for\non-device, privacy-sensitive, and edge computing applications. On the other\nhand, membership inference attacks (MIAs), which aim to determine whether a\ngiven sample was used in a model's training, are an important threat with\nserious privacy and intellectual property implications. In this paper, we study\nMIAs on SLMs. Although MIAs were shown to be effective on large language models\n(LLMs), they are relatively less studied on emerging SLMs, and furthermore,\ntheir effectiveness decreases as models get smaller. Motivated by this finding,\nwe propose a new MIA called win-k, which builds on top of a state-of-the-art\nattack (min-k). We experimentally evaluate win-k by comparing it with five\nexisting MIAs using three datasets and eight SLMs. Results show that win-k\noutperforms existing MIAs in terms of AUROC, TPR @ 1% FPR, and FPR @ 99% TPR\nmetrics, especially on smaller models.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3awin-k\u7684\u65b0\u578bMIA\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684MIAs\uff0c\u5c24\u5176\u5728\u8f83\u5c0f\u7684\u6a21\u578b\u4e0a\u6027\u80fd\u7a81\u51fa\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u662fMIAs\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0a\u5df2\u88ab\u8bc1\u660e\u6709\u6548\uff0c\u4f46\u5728\u65b0\u5174SLMs\u4e0a\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\uff0c\u5176\u6709\u6548\u6027\u968f\u7740\u6a21\u578b\u53d8\u5c0f\u800c\u964d\u4f4e\u3002\u9274\u4e8e\u8fd9\u4e00\u53d1\u73b0\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5efa\u7acb\u5728\u73b0\u6709\u653b\u51fb\uff08min-k\uff09\u57fa\u7840\u4e0a\u7684\u65b0\u578bMIA\uff0c\u5373win-k\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3awin-k\u7684\u65b0\u578bMIAs\uff0c\u5e76\u901a\u8fc7\u4e0e\u4e94\u79cd\u73b0\u6709MIAs\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u548c\u516b\u79cdSLMs\u4e0a\u7684\u6bd4\u8f83\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cwin-k\u5728AUROC\u3001TPR @ 1% FPR\u548cFPR @ 99% TPR\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u8f83\u5c0f\u7684\u6a21\u578b\u4e0a\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u4e0a\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff08MIAs\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3awin-k\u7684\u65b0\u578bMIA\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cwin-k\u5728AUROC\u3001TPR @ 1% FPR\u548cFPR @ 99% TPR\u7b49\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684MIAs\uff0c\u5c24\u5176\u5728\u8f83\u5c0f\u7684\u6a21\u578b\u4e0a\u8868\u73b0\u66f4\u4e3a\u51fa\u8272\u3002"}}
{"id": "2508.01273", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01273", "abs": "https://arxiv.org/abs/2508.01273", "authors": ["Xianda Zheng", "Zijian Huang", "Meng-Fen Chiang", "Michael J. Witbrock", "Kaiqi Zhao"], "title": "KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs", "comment": null, "summary": "Knowledge conflicts commonly arise across diverse sources, and their\nprevalence has increased with the advent of LLMs. When dealing with conflicts\nbetween multiple contexts, also known as \\emph{inter-context knowledge\nconflicts}, LLMs are often confused by lengthy and conflicting contexts. To\naddress this challenge, we propose the Knowledge Conflict Reasoning (KCR)\nframework, which enhances the ability of LLMs to resolve conflicting knowledge.\nThe key idea of KCR is to train backbone LLMs to establish a correct reasoning\nprocess by rewarding them for selecting and adhering to the context with\nstronger logical consistency when presented with conflicting contexts.\nSpecifically, we first extract reasoning paths, represented by either text or\nlocal knowledge graphs, from the conflicting long contexts. Subsequently, we\nemploy Reinforcement Learning to encourage the model to learn the paradigm of\nreasoning process that follows correct reasoning paths rather than the\nincorrect counterparts. This enables the backbone models to genuinely acquire\nthe capability to resolve inter-context knowledge conflicts within long\ncontexts. Experimental results demonstrate that our framework significantly\nimproves the ability of various backbone models to resolve knowledge conflicts\nin long-context scenarios, yielding substantial performance gains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u77e5\u8bc6\u51b2\u7a81\u63a8\u7406\uff08KCR\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e3b\u5e72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b3\u957f\u7bc7\u6587\u672c\u4e2d\u8de8\u4e0a\u4e0b\u6587\u77e5\u8bc6\u51b2\u7a81\uff0c\u4ee5\u663e\u8457\u63d0\u9ad8\u89e3\u51b3\u80fd\u529b\u548c\u6027\u80fd\u3002", "motivation": "\u9762\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5904\u7406\u591a\u4e2a\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u51b2\u7a81\u65f6\u7ecf\u5e38\u6df7\u6dc6\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u77e5\u8bc6\u51b2\u7a81\u63a8\u7406\uff08KCR\uff09\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3aLLMs\u89e3\u51b3\u51b2\u7a81\u77e5\u8bc6\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u77e5\u8bc6\u51b2\u7a81\u63a8\u7406\uff08KCR\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e3b\u5e72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b3\u8de8\u4e0a\u4e0b\u6587\u77e5\u8bc6\u51b2\u7a81\u3002\u9996\u5148\u4ece\u5b58\u5728\u51b2\u7a81\u7684\u957f\u6587\u672c\u4e2d\u63d0\u53d6\u63a8\u7406\u8def\u5f84\uff0c\u7136\u540e\u9f13\u52b1\u6a21\u578b\u5b66\u4e60\u6b63\u786e\u63a8\u7406\u8fc7\u7a0b\u7684\u8303\u5f0f\uff0c\u4ee5\u89e3\u51b3\u8de8\u4e0a\u4e0b\u6587\u77e5\u8bc6\u51b2\u7a81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5404\u79cd\u4e3b\u5e72\u6a21\u578b\u5728\u957f\u7bc7\u6587\u672c\u60c5\u666f\u4e0b\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u7684\u80fd\u529b\uff0c\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u77e5\u8bc6\u51b2\u7a81\u63a8\u7406\uff08KCR\uff09\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b3\u51b2\u7a81\u77e5\u8bc6\u7684\u80fd\u529b\u3002\u901a\u8fc7\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff0c\u8bad\u7ec3\u4e3b\u5e72LLMs\u5efa\u7acb\u6b63\u786e\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ece\u800c\u63d0\u9ad8\u89e3\u51b3\u957f\u7bc7\u6587\u672c\u4e2d\u8de8\u4e0a\u4e0b\u6587\u77e5\u8bc6\u51b2\u7a81\u7684\u6548\u679c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u6539\u5584\u4e86\u5404\u79cd\u4e3b\u5e72\u6a21\u578b\u5728\u957f\u6587\u672c\u60c5\u666f\u4e0b\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u7684\u80fd\u529b\uff0c\u53d6\u5f97\u4e86\u5b9e\u8d28\u6027\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2508.01274", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01274", "abs": "https://arxiv.org/abs/2508.01274", "authors": ["Jui-Ming Yao", "Bing-Cheng Xie", "Sheng-Wei Peng", "Hao-Yuan Chen", "He-Rong Zheng", "Bing-Jia Tan", "Peter Shaojui Wang", "Shun-Feng Su"], "title": "Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) process visual, acoustic, and\ntextual inputs, addressing the limitations of single-modality LLMs. However,\nexisting benchmarks often overlook tri-modal evaluation in Traditional Chinese\nand do not consider inference latency. To address this, we introduce Multi-TW,\nthe first Traditional Chinese benchmark for evaluating the performance and\nlatency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice\nquestions (image and text, audio and text pairs) sourced from official\nproficiency tests developed with the Steering Committee for the Test of\nProficiency-Huayu (SC-TOP). We evaluated various any-to-any models and\nvision-language models (VLMs) with audio transcription. Our results show that\nclosed-source models generally outperform open-source ones across modalities,\nalthough open-source models can perform well in audio tasks. End-to-end\nany-to-any pipelines offer clear latency advantages compared to VLMs using\nseparate audio transcription. Multi-TW presents a comprehensive view of model\ncapabilities and highlights the need for Traditional Chinese fine-tuning and\nefficient multimodal architectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86Multi-TW\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4efb\u610f-\u4efb\u610f\u591a\u6a21\u6001\u6a21\u578b\u6027\u80fd\u548c\u5ef6\u8fdf\u7684\u4f20\u7edf\u4e2d\u6587\u57fa\u51c6\u3002\u7814\u7a76\u53d1\u73b0\u95ed\u6e90\u6a21\u578b\u901a\u5e38\u5728\u5404\u6a21\u6001\u4e0a\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u5728\u97f3\u9891\u4efb\u52a1\u4e0a\u8868\u73b0\u4e5f\u4e0d\u9519\u3002\u7aef\u5230\u7aef\u7684\u4efb\u610f-\u4efb\u610f\u7ba1\u9053\u76f8\u5bf9\u4e8e\u4f7f\u7528\u5355\u72ec\u97f3\u9891\u8f6c\u5f55\u7684VLMs\u6709\u660e\u663e\u7684\u5ef6\u8fdf\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5f80\u5f80\u5ffd\u89c6\u4e86\u4f20\u7edf\u4e2d\u6587\u7684\u4e09\u6a21\u6001\u8bc4\u4f30\uff0c\u5e76\u672a\u8003\u8651\u63a8\u7406\u5ef6\u8fdf\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5f15\u5165\u4e86Multi-TW\uff0c\u65e8\u5728\u8bc4\u4f30\u4efb\u610f-\u4efb\u610f\u591a\u6a21\u6001\u6a21\u578b\u7684\u6027\u80fd\u548c\u5ef6\u8fdf\u3002", "method": "\u5f15\u5165\u4e86Multi-TW\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4efb\u610f-\u4efb\u610f\u591a\u6a21\u6001\u6a21\u578b\u6027\u80fd\u548c\u5ef6\u8fdf\u7684\u4f20\u7edf\u4e2d\u6587\u57fa\u51c6\u3002\u8be5\u57fa\u51c6\u5305\u62ec\u4e86\u6765\u6e90\u4e8e\u7531\u534e\u8bed\u6d4b\u8bd5\u6d4b\u9a8c\u59d4\u5458\u4f1a\uff08SC-TOP\uff09\u5f00\u53d1\u7684\u5b98\u65b9\u80fd\u529b\u6d4b\u8bd5\u7684900\u4e2a\u591a\u9879\u9009\u62e9\u95ee\u9898\uff08\u56fe\u50cf\u548c\u6587\u672c\u3001\u97f3\u9891\u548c\u6587\u672c\u914d\u5bf9\uff09\u3002\u8bc4\u4f30\u4e86\u5404\u79cd\u4efb\u610f-\u4efb\u610f\u6a21\u578b\u548c\u5e26\u6709\u97f3\u9891\u8f6c\u5f55\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u95ed\u6e90\u6a21\u578b\u5728\u5404\u6a21\u6001\u4e0a\u901a\u5e38\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u5c3d\u7ba1\u5f00\u6e90\u6a21\u578b\u5728\u97f3\u9891\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002\u7aef\u5230\u7aef\u7684\u4efb\u610f-\u4efb\u610f\u7ba1\u9053\u76f8\u5bf9\u4e8e\u4f7f\u7528\u5355\u72ec\u97f3\u9891\u8f6c\u5f55\u7684VLMs\u5177\u6709\u660e\u663e\u7684\u5ef6\u8fdf\u4f18\u52bf\u3002", "conclusion": "\u5728\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65b9\u9762\uff0c\u95ed\u6e90\u6a21\u578b\u901a\u5e38\u5728\u5404\u6a21\u6001\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u5c3d\u7ba1\u5f00\u6e90\u6a21\u578b\u5728\u97f3\u9891\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\u3002\u7aef\u5230\u7aef\u7684\u4efb\u610f-\u4efb\u610f\u7ba1\u9053\u76f8\u5bf9\u4e8e\u4f7f\u7528\u5355\u72ec\u97f3\u9891\u8f6c\u5f55\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5177\u6709\u660e\u663e\u7684\u5ef6\u8fdf\u4f18\u52bf\u3002Multi-TW\u63d0\u4f9b\u4e86\u6a21\u578b\u80fd\u529b\u7684\u5168\u9762\u89c6\u89d2\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u4f20\u7edf\u4e2d\u6587\u5fae\u8c03\u548c\u9ad8\u6548\u591a\u6a21\u6001\u67b6\u6784\u65b9\u9762\u7684\u9700\u6c42\u3002"}}
{"id": "2508.01285", "categories": ["cs.AI", "cs.ET", "cs.IR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2508.01285", "abs": "https://arxiv.org/abs/2508.01285", "authors": ["Yujing Ke", "Kevin George", "Kathan Pandya", "David Blumenthal", "Maximilian Sprang", "Gerrit Gro\u00dfmann", "Sebastian Vollmer", "David Antony Selby"], "title": "BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation", "comment": "7 pages main content + 11 pages appendices", "summary": "Identifying novel hypotheses is essential to scientific research, yet this\nprocess risks being overwhelmed by the sheer volume and complexity of available\ninformation. Existing automated methods often struggle to generate novel and\nevidence-grounded hypotheses, lack robust iterative refinement and rarely\nundergo rigorous temporal evaluation for future discovery potential. To address\nthis, we propose BioDisco, a multi-agent framework that draws upon language\nmodel-based reasoning and a dual-mode evidence system (biomedical knowledge\ngraphs and automated literature retrieval) for grounded novelty, integrates an\ninternal scoring and feedback loop for iterative refinement, and validates\nperformance through pioneering temporal and human evaluations and a\nBradley-Terry paired comparison model to provide statistically-grounded\nassessment. Our evaluations demonstrate superior novelty and significance over\nablated configurations representative of existing agentic architectures.\nDesigned for flexibility and modularity, BioDisco allows seamless integration\nof custom language models or knowledge graphs, and can be run with just a few\nlines of code. We anticipate researchers using this practical tool as a\ncatalyst for the discovery of new hypotheses.", "AI": {"tldr": "BioDisco \u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6 BioDisco\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u548c\u53cc\u6a21\u8bc1\u636e\u7cfb\u7edf\u751f\u6210\u65b0\u9896\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u5047\u8bbe\uff0c\u901a\u8fc7\u8bc4\u4f30\u8868\u660e\u8868\u73b0\u4f18\u8d8a\uff0c\u53ef\u7075\u6d3b\u96c6\u6210\u5b9a\u5236\u6a21\u578b\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u6765\u53d1\u73b0\u65b0\u7684\u5047\u8bbe\u3002", "motivation": "\u672c\u7814\u7a76\u9488\u5bf9\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u5728\u751f\u6210\u65b0\u9896\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u5047\u8bbe\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u4e25\u683c\u7684\u65f6\u95f4\u8bc4\u4f30\u548c\u672a\u6765\u53d1\u73b0\u6f5c\u529b\u7684\u95ee\u9898\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86 BioDisco \u6846\u67b6\uff0c\u65e8\u5728\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u66f4\u6709\u6548\u5730\u53d1\u73b0\u65b0\u7684\u5047\u8bbe\u3002", "method": "BioDisco \u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u53cc\u6a21\u8bc1\u636e\u7cfb\u7edf\uff0c\u91c7\u7528\u5185\u90e8\u8bc4\u5206\u548c\u53cd\u9988\u5faa\u73af\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\u3002\u901a\u8fc7\u5f00\u521b\u6027\u7684\u65f6\u95f4\u548c\u4eba\u7c7b\u8bc4\u4f30\u4ee5\u53ca Bradley-Terry \u914d\u5bf9\u6bd4\u8f83\u6a21\u578b\u9a8c\u8bc1\u6027\u80fd\uff0c\u63d0\u4f9b\u7edf\u8ba1\u57fa\u7840\u7684\u8bc4\u4f30\u3002", "result": "BioDisco \u5728\u65b0\u9896\u6027\u548c\u91cd\u8981\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u4ee3\u7406\u4f53\u7cfb\u7ed3\u6784\u53d6\u5f97\u4e86\u8f83\u597d\u7684\u6548\u679c\u3002\u53ef\u7075\u6d3b\u96c6\u6210\u5b9a\u5236\u8bed\u8a00\u6a21\u578b\u6216\u77e5\u8bc6\u56fe\uff0c\u6613\u4e8e\u4f7f\u7528\u3002", "conclusion": "BioDisco \u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u53cc\u6a21\u8bc1\u636e\u7cfb\u7edf\uff08\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u548c\u81ea\u52a8\u6587\u732e\u68c0\u7d22\uff09\u6765\u751f\u6210\u65b0\u9896\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u5047\u8bbe\u3002\u901a\u8fc7\u5185\u90e8\u8bc4\u5206\u548c\u53cd\u9988\u5faa\u73af\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\uff0c\u5e76\u901a\u8fc7\u5f00\u521b\u6027\u7684\u65f6\u95f4\u548c\u4eba\u7c7b\u8bc4\u4f30\u4ee5\u53ca Bradley-Terry \u914d\u5bf9\u6bd4\u8f83\u6a21\u578b\u9a8c\u8bc1\u6027\u80fd\uff0c\u63d0\u4f9b\u7edf\u8ba1\u57fa\u7840\u7684\u8bc4\u4f30\u3002\u5176\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u4ee3\u7406\u4f53\u7cfb\u7ed3\u6784\u76f8\u6bd4\uff0cBioDisco \u5728\u65b0\u9896\u6027\u548c\u91cd\u8981\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002BioDisco \u5177\u6709\u7075\u6d3b\u6027\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5141\u8bb8\u65e0\u7f1d\u96c6\u6210\u5b9a\u5236\u8bed\u8a00\u6a21\u578b\u6216\u77e5\u8bc6\u56fe\uff0c\u4ec5\u9700\u51e0\u884c\u4ee3\u7801\u5373\u53ef\u8fd0\u884c\u3002\u9884\u8ba1\u7814\u7a76\u4eba\u5458\u5c06\u4f7f\u7528\u8fd9\u4e2a\u5b9e\u7528\u5de5\u5177\u4f5c\u4e3a\u53d1\u73b0\u65b0\u5047\u8bbe\u7684\u50ac\u5316\u5242\u3002"}}
{"id": "2508.01300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01300", "abs": "https://arxiv.org/abs/2508.01300", "authors": ["Ma'ayan Armony", "Albert Mero\u00f1o-Pe\u00f1uela", "Gerard Canal"], "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective", "comment": null, "summary": "The reasoning and planning abilities of Large Language Models (LLMs) have\nbeen a frequent topic of discussion in recent years. Their ability to take\nunstructured planning problems as input has made LLMs' integration into AI\nplanning an area of interest. Nevertheless, LLMs are still not reliable as\nplanners, with the generated plans often containing mistaken or hallucinated\nactions. Existing benchmarking and evaluation methods investigate planning with\nLLMs, focusing primarily on success rate as a quality indicator in various\nplanning tasks, such as validating plans or planning in relaxed conditions. In\nthis paper, we approach planning with LLMs as a natural language processing\n(NLP) task, given that LLMs are NLP models themselves. We propose a recovery\npipeline consisting of an NLP-based evaluation of the generated plans, along\nwith three stages to recover the plans through NLP manipulation of the\nLLM-generated plans, and eventually complete the plan using a symbolic planner.\nThis pipeline provides a holistic analysis of LLM capabilities in the context\nof AI task planning, enabling a broader understanding of the quality of invalid\nplans. Our findings reveal no clear evidence of underlying reasoning during\nplan generation, and that a pipeline comprising an NLP-based analysis of the\nplans, followed by a recovery mechanism, still falls short of the quality and\nreliability of classical planners. On average, only the first 2.65 actions of\nthe plan are executable, with the average length of symbolically generated\nplans being 8.4 actions. The pipeline still improves action quality and\nincreases the overall success rate from 21.9% to 27.5%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89c4\u5212\u80fd\u529b\u65b9\u9762\u7684\u95ee\u9898\uff0c\u6307\u51faLLMs\u4f5c\u4e3aAI\u89c4\u5212\u9886\u57df\u7684\u4e00\u90e8\u5206\u5b58\u5728\u53ef\u9760\u6027\u95ee\u9898\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542bNLP\u8bc4\u4f30\u548c\u89c4\u5212\u6062\u590d\u6d41\u7a0b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u4e00\u6d41\u7a0b\u53ef\u4ee5\u6539\u5584LLM\u751f\u6210\u7684\u8ba1\u5212\u7684\u8d28\u91cf\u548c\u6210\u529f\u7387\u3002\u7136\u800c\uff0c\u4e0e\u4f20\u7edf\u89c4\u5212\u5668\u76f8\u6bd4\uff0c\u4ecd\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdbLLM\u7684\u89c4\u5212\u80fd\u529b\u3002", "motivation": "LLM\u7684\u89c4\u5212\u548c\u63a8\u7406\u80fd\u529b\u4e00\u76f4\u662f\u7814\u7a76\u7684\u70ed\u70b9\u8bdd\u9898\uff0c\u7136\u800c\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8LLM\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u7387\u4f5c\u4e3a\u8d28\u91cf\u6307\u6807\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u8ba4\u4e3a\u4ee5\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u65b9\u5f0f\u5bf9LLM\u7684\u89c4\u5212\u80fd\u529b\u8fdb\u884c\u7814\u7a76\u662f\u5fc5\u8981\u7684\uff0c\u4ece\u800c\u6df1\u5165\u4e86\u89e3\u5176\u5728AI\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\u7684\u89c4\u5212\u6062\u590d\u6d41\u7a0b\uff0c\u5e76\u7ed3\u5408\u7b26\u53f7\u5316\u89c4\u5212\u5668\u5b8c\u6210\u89c4\u5212\uff0c\u4ee5\u5904\u7406LLM\u751f\u6210\u7684\u8ba1\u5212\u3002\u8be5\u8fc7\u7a0b\u4ece\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u89d2\u5ea6\u89e3\u6790LLM\u751f\u6210\u7684\u8ba1\u5212\uff0c\u5e76\u4f7f\u7528NLP\u64cd\u4f5c\u5bf9\u8ba1\u5212\u8fdb\u884c\u6062\u590d\uff0c\u6700\u7ec8\u901a\u8fc7\u7b26\u53f7\u5316\u89c4\u5212\u5668\u5b8c\u6210\u89c4\u5212\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u751f\u6210\u7684\u8ba1\u5212\u5b58\u5728\u4e00\u5b9a\u7f3a\u9677\uff0c\u4f46\u901a\u8fc7\u63d0\u51fa\u7684\u89c4\u5212\u6062\u590d\u6d41\u7a0b\uff0c\u53ef\u4ee5\u63d0\u9ad8\u884c\u52a8\u8d28\u91cf\u548c\u603b\u4f53\u6210\u529f\u7387\u3002\u7136\u800c\uff0c\u4e0e\u4f20\u7edf\u89c4\u5212\u5668\u76f8\u6bd4\uff0cLLM\u4ecd\u7136\u6709\u6539\u8fdb\u7684\u7a7a\u95f4\u3002\u5e73\u5747\u800c\u8a00\uff0c\u8ba1\u5212\u4e2d\u4ec5\u524d2.65\u4e2a\u884c\u52a8\u53ef\u6267\u884c\uff0c\u7b26\u53f7\u5316\u751f\u6210\u7684\u8ba1\u5212\u5e73\u5747\u957f\u5ea6\u4e3a8.4\u4e2a\u884c\u52a8\u3002\u6700\u7ec8\u7684\u89c4\u5212\u6d41\u7a0b\u4f7f\u5f97\u603b\u4f53\u6210\u529f\u7387\u4ece21.9%\u63d0\u9ad8\u523027.5%\u3002", "conclusion": "\u8be5\u8bba\u6587\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u7efc\u5408\u7684\u89c4\u5212\u6062\u590d\u6d41\u7a0b\uff0c\u4ee5\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u65b9\u5f0f\u5904\u7406LLM\u751f\u6210\u7684\u89c4\u5212\uff0c\u63ed\u793a\u4e86LLM\u5728AI\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1LLM\u5728\u751f\u6210\u8ba1\u5212\u65f6\u5b58\u5728\u4e00\u4e9b\u7f3a\u9677\uff0c\u4f46\u901a\u8fc7NLP\u5206\u6790\u548c\u89c4\u5212\u6062\u590d\u673a\u5236\uff0c\u53ef\u4ee5\u63d0\u9ad8\u884c\u52a8\u8d28\u91cf\u548c\u603b\u4f53\u6210\u529f\u7387\u3002\u7136\u800c\uff0c\u4e0e\u4f20\u7edf\u89c4\u5212\u5668\u76f8\u6bd4\uff0cLLM\u7684\u89c4\u5212\u8d28\u91cf\u548c\u53ef\u9760\u6027\u4ecd\u6709\u5f85\u8fdb\u4e00\u6b65\u63d0\u9ad8\u3002"}}
{"id": "2508.01306", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.01306", "abs": "https://arxiv.org/abs/2508.01306", "authors": ["Yelim Ahn", "Jaejin Lee"], "title": "PUZZLED: Jailbreaking LLMs through Word-Based Puzzles", "comment": "15 pages", "summary": "As large language models (LLMs) are increasingly deployed across diverse\ndomains, ensuring their safety has become a critical concern. In response,\nstudies on jailbreak attacks have been actively growing. Existing approaches\ntypically rely on iterative prompt engineering or semantic transformations of\nharmful instructions to evade detection. In this work, we introduce PUZZLED, a\nnovel jailbreak method that leverages the LLM's reasoning capabilities. It\nmasks keywords in a harmful instruction and presents them as word puzzles for\nthe LLM to solve. We design three puzzle types-word search, anagram, and\ncrossword-that are familiar to humans but cognitively demanding for LLMs. The\nmodel must solve the puzzle to uncover the masked words and then proceed to\ngenerate responses to the reconstructed harmful instruction. We evaluate\nPUZZLED on five state-of-the-art LLMs and observe a high average attack success\nrate (ASR) of 88.8%, specifically 96.5% on GPT-4.1 and 92.3% on Claude 3.7\nSonnet. PUZZLED is a simple yet powerful attack that transforms familiar\npuzzles into an effective jailbreak strategy by harnessing LLMs' reasoning\ncapabilities.", "AI": {"tldr": "PUZZLED\u662f\u4e00\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u8c1c\u9898\u8f6c\u6362\u6210\u6709\u6548\u8d8a\u72f1\u7b56\u7565\uff0c\u901a\u8fc7LLMs\u7684\u63a8\u7406\u80fd\u529b\u83b7\u5f97\u9ad8\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5b83\u4eec\u7684\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u9274\u4e8e\u8fd9\u4e00\u95ee\u9898\uff0c\u5173\u4e8e\u8d8a\u72f1\u653b\u51fb\u7684\u7814\u7a76\u6b63\u5728\u79ef\u6781\u589e\u957f\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u8fed\u4ee3\u63d0\u793a\u5de5\u7a0b\u6216\u5bf9\u6709\u5bb3\u6307\u4ee4\u8fdb\u884c\u8bed\u4e49\u8f6c\u6362\u4ee5\u89c4\u907f\u68c0\u6d4b\uff0c\u800c\u672c\u7814\u7a76\u5f15\u5165\u4e86PUZZLED\u65b9\u6cd5\uff0c\u5229\u7528LLMs\u7684\u63a8\u7406\u80fd\u529b\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u8d8a\u72f1\u65b9\u6cd5\u3002", "method": "PUZZLED\u65b9\u6cd5\u8bbe\u8ba1\u4e86\u4e09\u79cd\u7c7b\u578b\u7684\u8c1c\u9898\uff1a\u5355\u8bcd\u641c\u7d22\u3001\u5b57\u8c1c\u548c\u7eb5\u6a2a\u586b\u5b57\uff0c\u8fd9\u4e9b\u8c1c\u9898\u5bf9\u4eba\u7c7b\u719f\u6089\u4f46\u5bf9LLMs\u5177\u6709\u8ba4\u77e5\u6311\u6218\uff0cLLMs\u5fc5\u987b\u89e3\u51b3\u8fd9\u4e9b\u8c1c\u9898\u624d\u80fd\u63ed\u793a\u63a9\u76d6\u7684\u5173\u952e\u5b57\u5e76\u751f\u6210\u54cd\u5e94\u3002", "result": "\u5728\u4e94\u79cd\u6700\u5148\u8fdb\u7684LLMs\u4e0a\u8bc4\u4f30PUZZLED\uff0c\u89c2\u5bdf\u5230\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387(ASR)\u9ad8\u8fbe88.8%\uff0c\u7279\u522b\u662f\u5728GPT-4.1\u548cClaude 3.7 Sonnet\u4e0a\u8fbe\u5230\u4e8696.5%\u548c92.3%\u3002", "conclusion": "PUZZLED\u662f\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u63a8\u7406\u80fd\u529b\u7684\u65b0\u9896\u8d8a\u72f1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5173\u952e\u5b57\u63a9\u76d6\u5728\u6709\u8db3\u591f\u8ba4\u77e5\u9700\u6c42\u7684\u5355\u8bcd\u8c1c\u9898\u4e2d\uff0c\u6210\u529f\u5229\u7528\u4e86LLMs\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5177\u6709\u9ad8\u653b\u51fb\u6210\u529f\u7387\u3002"}}
{"id": "2508.01323", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC", "47H10, 06B10, 91B40, 91B55, 68T20", "I.2.0; I.2.11; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.01323", "abs": "https://arxiv.org/abs/2508.01323", "authors": ["Faruk Alpay", "Bugra Kilictas", "Taylan Alpay", "Hamdi Alakkad"], "title": "Idempotent Equilibrium Analysis of Hybrid Workflow Allocation: A Mathematical Schema for Future Work", "comment": "25 pages, 9 figures, 4 tables. Proves existence/uniqueness of an\n  \"idempotent equilibrium\" for human-AI task allocation and provides\n  closed-form steady-state automation share", "summary": "The rapid advance of large-scale AI systems is reshaping how work is divided\nbetween people and machines. We formalise this reallocation as an iterated\ntask-delegation map and show that--under broad, empirically grounded\nassumptions--the process converges to a stable idempotent equilibrium in which\nevery task is performed by the agent (human or machine) with enduring\ncomparative advantage. Leveraging lattice-theoretic fixed-point tools (Tarski\nand Banach), we (i) prove existence of at least one such equilibrium and (ii)\nderive mild monotonicity conditions that guarantee uniqueness. In a stylised\ncontinuous model the long-run automated share takes the closed form $x^* =\n\\alpha / (\\alpha + \\beta)$, where $\\alpha$ captures the pace of automation and\n$\\beta$ the rate at which new, human-centric tasks appear; hence full\nautomation is precluded whenever $\\beta > 0$. We embed this analytic result in\nthree complementary dynamical benchmarks--a discrete linear update, an\nevolutionary replicator dynamic, and a continuous Beta-distributed task\nspectrum--each of which converges to the same mixed equilibrium and is\nreproducible from the provided code-free formulas. A 2025-to-2045 simulation\ncalibrated to current adoption rates projects automation rising from\napproximately 10% of work to approximately 65%, leaving a persistent one-third\nof tasks to humans. We interpret that residual as a new profession of workflow\nconductor: humans specialise in assigning, supervising and integrating AI\nmodules rather than competing with them. Finally, we discuss implications for\nskill development, benchmark design and AI governance, arguing that policies\nwhich promote \"centaur\" human-AI teaming can steer the economy toward the\nwelfare-maximising fixed point.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u89c4\u6a21AI\u7cfb\u7edf\u5feb\u901f\u53d1\u5c55\u5bf9\u5de5\u4f5c\u5206\u5de5\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4efb\u52a1\u5206\u914d\u7684\u7a33\u5b9a\u7b49\u5e42\u5747\u8861\u72b6\u6001\uff0c\u5e76\u63a8\u5bfc\u51fa\u786e\u4fdd\u552f\u4e00\u6027\u7684\u6761\u4ef6\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\u5927\u7ea665%\u7684\u5de5\u4f5c\u5c06\u88ab\u81ea\u52a8\u5316\u6267\u884c\uff0c\u5269\u4f59\u4efb\u52a1\u7559\u7ed9\u4eba\u7c7b\uff0c\u5f62\u6210\u65b0\u7684\u5de5\u4f5c\u6d41\u7a0b\u7ba1\u7406\u8005\u804c\u4e1a\u3002\u6700\u7ec8\uff0c\u7814\u7a76\u6307\u51fa\u901a\u8fc7\u4fc3\u8fdb\u201c\u534a\u4eba\u534a\u9a6c\u201d\u4eba\u673a\u56e2\u961f\u5408\u4f5c\u7684\u653f\u7b56\u53ef\u4ee5\u5f15\u5bfc\u7ecf\u6d4e\u8fbe\u5230\u6700\u5927\u798f\u7949\u7684\u56fa\u5b9a\u70b9\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8\u5927\u89c4\u6a21AI\u7cfb\u7edf\u5feb\u901f\u53d1\u5c55\u5bf9\u5de5\u4f5c\u5206\u5de5\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u4eba\u7c7b\u548c\u673a\u5668\u5728\u4efb\u52a1\u5206\u914d\u4e0a\u7684\u91cd\u65b0\u5206\u914d\uff0c\u5bfb\u627e\u7a33\u5b9a\u7684\u7b49\u5e42\u5747\u8861\u72b6\u6001\u5e76\u63a8\u5bfc\u51fa\u80fd\u591f\u786e\u4fdd\u552f\u4e00\u6027\u7684\u6761\u4ef6\u3002\u53e6\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u4e0d\u540c\u52a8\u6001\u57fa\u51c6\u4e0b\u7684\u5206\u6790\uff0c\u4ee5\u53ca\u6839\u636e\u5f53\u524d\u91c7\u7528\u7387\u6821\u51c6\u7684\u672a\u6765\u6a21\u62df\u7ed3\u679c\u3002", "method": "\u901a\u8fc7\u683c\u8bba\u56fa\u5b9a\u70b9\u5de5\u5177\uff08Tarski\u548cBanach\uff09\uff0c\u8bc1\u660e\u81f3\u5c11\u5b58\u5728\u4e00\u4e2a\u7a33\u5b9a\u7b49\u5e42\u5747\u8861\u72b6\u6001\uff0c\u5e76\u63a8\u5bfc\u51fa\u80fd\u591f\u786e\u4fdd\u552f\u4e00\u6027\u7684\u6e29\u548c\u5355\u8c03\u6027\u6761\u4ef6\u3002\u8be5\u7814\u7a76\u8fd8\u5728\u4e09\u79cd\u4e0d\u540c\u52a8\u6001\u57fa\u51c6\u4e0b\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u5206\u522b\u4e3a\u79bb\u6563\u7ebf\u6027\u66f4\u65b0\u3001\u8fdb\u5316\u590d\u5236\u52a8\u6001\u548c\u8fde\u7eedBeta\u5206\u5e03\u4efb\u52a1\u8c31\uff0c\u6700\u7ec8\u6536\u655b\u5230\u76f8\u540c\u7684\u6df7\u5408\u5747\u8861\u72b6\u6001\u3002\u7814\u7a76\u901a\u8fc72025\u5e74\u81f32045\u5e74\u7684\u6a21\u62df\u5c55\u793a\uff0c\u81ea\u52a8\u5316\u5de5\u4f5c\u5c06\u4ece\u7ea610%\u4e0a\u5347\u5230\u7ea665%\uff0c\u5269\u4f59\u4e09\u5206\u4e4b\u4e00\u7684\u4efb\u52a1\u5c06\u7531\u4eba\u7c7b\u6267\u884c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u968f\u7740\u81ea\u52a8\u5316\u7684\u589e\u52a0\uff0c\u5c06\u6709\u5927\u7ea665%\u7684\u5de5\u4f5c\u81ea\u52a8\u5316\u6267\u884c\uff0c\u5269\u4f59\u7684\u4e09\u5206\u4e4b\u4e00\u4efb\u52a1\u7559\u7ed9\u4eba\u7c7b\u6267\u884c\uff0c\u5f62\u6210\u4e00\u79cd\u65b0\u7684\u5de5\u4f5c\u6d41\u7a0b\u7ba1\u7406\u8005\u804c\u4e1a\u3002\u7814\u7a76\u6307\u51fa\uff0c\u901a\u8fc7\u4fc3\u8fdb\u201c\u534a\u4eba\u534a\u9a6c\u201d\u4eba\u673a\u56e2\u961f\u5408\u4f5c\u7684\u653f\u7b56\u53ef\u4ee5\u5f15\u5bfc\u7ecf\u6d4e\u8d70\u5411\u6700\u5927\u798f\u7949\u7684\u56fa\u5b9a\u70b9\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u5728\u5927\u89c4\u6a21AI\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\u4e0b\uff0c\u5de5\u4f5c\u5206\u5de5\u6b63\u9010\u6e10\u91cd\u65b0\u5206\u914d\u7ed9\u4eba\u7c7b\u548c\u673a\u5668\uff0c\u6700\u7ec8\u8d8b\u5411\u4e8e\u7a33\u5b9a\u7684\u7b49\u5e42\u5747\u8861\u72b6\u6001\uff0c\u6bcf\u9879\u4efb\u52a1\u7531\u5177\u6709\u6301\u4e45\u6bd4\u8f83\u4f18\u52bf\u7684\u4ee3\u7406\uff08\u4eba\u7c7b\u6216\u673a\u5668\uff09\u6267\u884c\u3002\u8be5\u7814\u7a76\u57fa\u4e8e\u5e7f\u6cdb\u7684\u3001\u7ecf\u9a8c\u57fa\u7840\u7684\u5047\u8bbe\uff0c\u8bc1\u660e\u81f3\u5c11\u5b58\u5728\u4e00\u4e2a\u8fd9\u6837\u7684\u5747\u8861\u72b6\u6001\uff0c\u5e76\u63a8\u5bfc\u51fa\u80fd\u591f\u786e\u4fdd\u552f\u4e00\u6027\u7684\u6e29\u548c\u5355\u8c03\u6027\u6761\u4ef6\u3002\u901a\u8fc7\u683c\u8bba\u56fa\u5b9a\u70b9\u5de5\u5177\uff08Tarski\u548cBanach\uff09\uff0c\u7814\u7a76\u5728\u7406\u60f3\u5316\u8fde\u7eed\u6a21\u578b\u4e2d\uff0c\u957f\u671f\u81ea\u52a8\u5316\u4efd\u989d\u7684\u8868\u8fbe\u5f0f\u4e3a$x^* = \frac{\\alpha}{(\\alpha + \\beta)}$\uff0c\u5176\u4e2d$\\alpha$\u4ee3\u8868\u81ea\u52a8\u5316\u7684\u901f\u5ea6\uff0c$\\beta$\u4ee3\u8868\u65b0\u7684\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u4efb\u52a1\u51fa\u73b0\u7684\u901f\u7387\u3002\u7814\u7a76\u8fd8\u5c06\u8fd9\u4e00\u5206\u6790\u7ed3\u679c\u5d4c\u5165\u5230\u4e09\u79cd\u4e92\u8865\u7684\u52a8\u6001\u57fa\u51c6\u4e2d\uff0c\u6700\u7ec8\u6536\u655b\u5230\u76f8\u540c\u7684\u6df7\u5408\u5747\u8861\u72b6\u6001\uff0c\u5e76\u53ef\u4ece\u63d0\u4f9b\u7684\u65e0\u4ee3\u7801\u516c\u5f0f\u4e2d\u518d\u73b0\u3002\u6839\u636e\u5f53\u524d\u91c7\u7528\u7387\u6821\u51c6\u76842025\u5e74\u81f32045\u5e74\u6a21\u62df\u663e\u793a\uff0c\u81ea\u52a8\u5316\u5de5\u4f5c\u5c06\u4ece\u7ea610%\u4e0a\u5347\u5230\u7ea665%\uff0c\u4ecd\u6709\u4e09\u5206\u4e4b\u4e00\u7684\u4efb\u52a1\u4fdd\u7559\u7ed9\u4eba\u7c7b\u3002\u7814\u7a76\u89e3\u91ca\u8fd9\u4e00\u6b8b\u7559\u90e8\u5206\u4e3a\u65b0\u7684\u5de5\u4f5c\u6d41\u7a0b\u7ba1\u7406\u8005\u804c\u4e1a\uff1a\u4eba\u7c7b\u4e13\u95e8\u8d1f\u8d23\u5206\u914d\u3001\u76d1\u7763\u548c\u6574\u5408AI\u6a21\u5757\uff0c\u800c\u975e\u4e0e\u5176\u7ade\u4e89\u3002\u6700\u540e\uff0c\u8ba8\u8bba\u4e86\u5bf9\u6280\u80fd\u53d1\u5c55\u3001\u57fa\u51c6\u8bbe\u8ba1\u548cAI\u6cbb\u7406\u7684\u5f71\u54cd\uff0c\u8ba4\u4e3a\u4fc3\u8fdb\u201c\u534a\u4eba\u534a\u9a6c\u201d\u4eba\u673a\u56e2\u961f\u5408\u4f5c\u7684\u653f\u7b56\u53ef\u4ee5\u5f15\u5bfc\u7ecf\u6d4e\u8d70\u5411\u6700\u5927\u798f\u7949\u7684\u56fa\u5b9a\u70b9\u3002"}}
{"id": "2508.01324", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01324", "abs": "https://arxiv.org/abs/2508.01324", "authors": ["Ke Miao", "Yuke Hu", "Xiaochen Li", "Wenjie Bao", "Zhihao Liu", "Zhan Qin", "Kui Ren"], "title": "Towards Evaluation for Real-World LLM Unlearning", "comment": null, "summary": "This paper analyzes the limitations of existing unlearning evaluation metrics\nin terms of practicality, exactness, and robustness in real-world LLM\nunlearning scenarios. To overcome these limitations, we propose a new metric\ncalled Distribution Correction-based Unlearning Evaluation (DCUE). It\nidentifies core tokens and corrects distributional biases in their confidence\nscores using a validation set. The evaluation results are quantified using the\nKolmogorov-Smirnov test. Experimental results demonstrate that DCUE overcomes\nthe limitations of existing metrics, which also guides the design of more\npractical and reliable unlearning algorithms in the future.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u5ea6\u91cf\u6807\u51c6DCUE\uff0c\u901a\u8fc7\u5206\u5e03\u6821\u6b63\u8bc6\u522b\u6838\u5fc3\u6807\u8bb0\u5e76\u63d0\u9ad8\u7f6e\u4fe1\u5206\u6570\u7684\u51c6\u786e\u6027\uff0c\u4f7f\u7528Kolmogorov-Smirnov\u68c0\u9a8c\u91cf\u5316\u8bc4\u4f30\u7ed3\u679c\uff0c\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u8bbe\u8ba1\u66f4\u53ef\u9760\u7684\u9057\u5fd8\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u5206\u6790\u73b0\u6709\u9057\u5fd8\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u9488\u5bf9\u5176\u5b9e\u9645\u6027\u3001\u7cbe\u786e\u6027\u548c\u9c81\u68d2\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5ea6\u91cf\u6807\u51c6\u4ee5\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u540c\u65f6\u6307\u5bfc\u672a\u6765\u66f4\u53ef\u9760\u7684\u9057\u5fd8\u7b97\u6cd5\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u6821\u6b63\u7684\u9057\u5fd8\u8bc4\u4f30\uff08DCUE\uff09\u6307\u6807\uff0c\u4f7f\u7528Kolmogorov-Smirnov\u68c0\u9a8c\u5bf9\u8bc4\u4f30\u7ed3\u679c\u8fdb\u884c\u91cf\u5316\uff0c\u5e76\u901a\u8fc7\u8bc6\u522b\u6838\u5fc3\u6807\u8bb0\u548c\u6821\u6b63\u7f6e\u4fe1\u5206\u6570\u4e2d\u7684\u5206\u5e03\u504f\u5dee\u6765\u514b\u670d\u73b0\u6709\u6307\u6807\u7684\u5c40\u9650\u6027\u3002", "result": "DCUE\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u73b0\u6709\u7684\u9057\u5fd8\u8bc4\u4f30\u6307\u6807\u5728\u5b9e\u9645\u6027\u3001\u7cbe\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u57fa\u4e8e\u5206\u5e03\u6821\u6b63\u7684\u9057\u5fd8\u8bc4\u4f30\uff08DCUE\uff09\u3002DCUE\u901a\u8fc7\u9a8c\u8bc1\u96c6\u8bc6\u522b\u6838\u5fc3\u6807\u8bb0\uff0c\u5e76\u6821\u6b63\u5b83\u4eec\u7684\u7f6e\u4fe1\u5206\u6570\u4e2d\u7684\u5206\u5e03\u504f\u5dee\u3002\u8bc4\u4f30\u7ed3\u679c\u4f7f\u7528Kolmogorov-Smirnov\u68c0\u9a8c\u8fdb\u884c\u91cf\u5316\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDCUE\u514b\u670d\u4e86\u73b0\u6709\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u4e5f\u4e3a\u672a\u6765\u8bbe\u8ba1\u66f4\u5b9e\u7528\u548c\u53ef\u9760\u7684\u9057\u5fd8\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2508.01330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01330", "abs": "https://arxiv.org/abs/2508.01330", "authors": ["Zihan Zheng", "Tianle Cui", "Chuwen Xie", "Jiahui Zhang", "Jiahui Pan", "Lewei He", "Qianglong Chen"], "title": "NatureGAIA: Pushing the Frontiers of GUI Agents with a Challenging Benchmark and High-Quality Trajectory Dataset", "comment": null, "summary": "The rapid advancement of Large Language Model (LLM)-driven Graphical User\nInterface (GUI) agents is significantly hampered by the profound limitations of\nexisting evaluation benchmarks in terms of accuracy, reproducibility, and\nscalability. To address this critical gap, we introduce \\Benchmark, a novel\nbenchmark engineered on the principle of Causal Pathways. This design paradigm\nstructures complex tasks into a series of programmatically verifiable atomic\nsteps, ensuring a rigorous, fully automated, and reproducible standard for\nassessment. Concurrently, to mitigate the inherent capability deficits of\nagents, we developed \\Agent, a hierarchical agent architecture specifically\noptimized for long-horizon tasks. We leveraged this agent to generate a\nhigh-quality, human-verified trajectory dataset that uniquely captures diverse\nand even self-correcting interaction patterns of LLMs. We then utilized this\ndataset to perform Reinforcement Fine-Tuning (RFT) on the Qwen2.5-VL-7B model.\nOur experiments reveal that \\Benchmark~presents a formidable challenge to\ncurrent state-of-the-art LLMs; even the top-performing Claude-sonnet-4 achieved\na Weighted Pathway Success Rate (WPSR) of only 34.6\\%. Moreover, while RFT\nsubstantially improved the smaller model's GUI execution capabilities (WPSR\nincreased from 3.3\\% to 10.8\\%), its performance degraded sharply when handling\ncomplex scenarios. This outcome highlights the inherent capability ceiling of\nsmaller models when faced with comprehensive tasks that integrate perception,\ndecision-making, and execution. This research contributes a rigorous evaluation\nstandard and a high-quality dataset to the community, aiming to guide the\nfuture development of GUI agents.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u57fa\u51c6Benchmark\u548cAgent\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684GUI\u4ee3\u7406\uff0c\u586b\u8865\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u7684\u9650\u5236\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aBenchmark\u5bf9\u6700\u5148\u8fdb\u7684LLMs\u6784\u6210\u6311\u6218\uff0cRFT\u6539\u5584\u4e86\u8f83\u5c0f\u6a21\u578b\u7684GUI\u6267\u884c\u80fd\u529b\uff0c\u4f46\u590d\u6742\u573a\u666f\u4e0b\u6027\u80fd\u4e0b\u964d\u3002\u7814\u7a76\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6807\u51c6\u548c\u6570\u636e\u96c6\uff0c\u5f15\u5bfc\u672a\u6765GUI\u4ee3\u7406\u7684\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u57fa\u51c6\u5728\u51c6\u786e\u6027\u3001\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u91cd\u5927\u9650\u5236\uff0c\u963b\u788d\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u56fe\u5f62\u7528\u6237\u754c\u9762\u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u5173\u952e\u5dee\u8ddd\uff0c\u7814\u7a76\u5f15\u5165\u4e86Benchmark\u548cAgent\uff0c\u65e8\u5728\u5f15\u9886\u672a\u6765GUI\u4ee3\u7406\u7684\u53d1\u5c55\u3002", "method": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86Benchmark\u548cAgent\u4f5c\u4e3a\u8bc4\u4f30\u6807\u51c6\u548c\u4ee3\u7406\u4f53\u7cfb\u7ed3\u6784\uff0c\u901a\u8fc7Benchmark\u7684\u56e0\u679c\u8def\u5f84\u8bbe\u8ba1\u8303\u5f0f\u5c06\u590d\u6742\u4efb\u52a1\u7ed3\u6784\u5316\u4e3a\u4e00\u7cfb\u5217\u53ef\u7f16\u7a0b\u9a8c\u8bc1\u7684\u539f\u5b50\u6b65\u9aa4\uff0c\u786e\u4fdd\u4e86\u5bf9\u884c\u4e3a\u7684\u4e25\u683c\u3001\u5b8c\u5168\u81ea\u52a8\u5316\u548c\u53ef\u91cd\u590d\u6027\u7684\u8bc4\u4f30\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u7f13\u89e3\u4ee3\u7406\u7684\u56fa\u6709\u80fd\u529b\u7f3a\u9677\uff0c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u9488\u5bf9\u957f\u671f\u4efb\u52a1\u8fdb\u884c\u4f18\u5316\u7684\u5206\u5c42\u4ee3\u7406\u4f53\u7cfb\u7ed3\u6784\u3002\u7814\u7a76\u5229\u7528\u8fd9\u4e2a\u4ee3\u7406\u751f\u6210\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u3001\u7ecf\u4eba\u5de5\u9a8c\u8bc1\u7684\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u6355\u6349\u4e86LLMs\u7684\u591a\u6837\u5316\u751a\u81f3\u81ea\u6211\u6821\u6b63\u7684\u4ea4\u4e92\u6a21\u5f0f\u3002\u4e4b\u540e\uff0c\u5229\u7528\u8fd9\u4e2a\u6570\u636e\u96c6\u5bf9Qwen2.5-VL-7B\u6a21\u578b\u8fdb\u884c\u4e86\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eBenchmark\u5bf9\u5f53\u524d\u6700\u5148\u8fdb\u7684LLMs\u6784\u6210\u4e86\u5de8\u5927\u6311\u6218\uff0cRFT\u663e\u8457\u6539\u5584\u4e86\u8f83\u5c0f\u6a21\u578b\u7684GUI\u6267\u884c\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u573a\u666f\u65f6\u6027\u80fd\u4e0b\u964d\u3002\u7814\u7a76\u4e3a\u793e\u533a\u8d21\u732e\u4e86\u4e25\u683c\u7684\u8bc4\u4f30\u6807\u51c6\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u8def\u5f84\u7684\u65b0\u578b\u57fa\u51c6\uff08Benchmark\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u56fe\u5f62\u7528\u6237\u754c\u9762\u4ee3\u7406\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5f15\u5165Benchmark\u548cAgent\uff0c\u7814\u7a76\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u5728\u51c6\u786e\u6027\u3001\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u7684\u91cd\u5927\u9650\u5236\u3002\u5b9e\u9a8c\u8868\u660e\uff0cBenchmark\u5bf9\u5f53\u524d\u6700\u5148\u8fdb\u7684LLMs\u6784\u6210\u4e86\u5de8\u5927\u6311\u6218\uff0c\u751a\u81f3\u6392\u540d\u7b2c\u4e00\u7684\u6a21\u578b\u5728\u6743\u91cd\u8def\u5f84\u6210\u529f\u7387\uff08WPSR\uff09\u4ec5\u4e3a34.6\uff05\u3002\u6b64\u5916\uff0c\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u663e\u8457\u6539\u5584\u4e86\u8f83\u5c0f\u6a21\u578b\u7684GUI\u6267\u884c\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u573a\u666f\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u7a81\u663e\u51fa\u8f83\u5c0f\u6a21\u578b\u5728\u9762\u5bf9\u7efc\u5408\u4efb\u52a1\u65f6\u7684\u56fa\u6709\u80fd\u529b\u4e0a\u9650\u3002\u8be5\u7814\u7a76\u4e3a\u793e\u533a\u8d21\u732e\u4e86\u4e25\u683c\u7684\u8bc4\u4f30\u6807\u51c6\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u65e8\u5728\u5f15\u5bfc\u672a\u6765GUI\u4ee3\u7406\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.01368", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01368", "abs": "https://arxiv.org/abs/2508.01368", "authors": ["Zhehong Ren", "Tianluo Zhang", "Yiheng Lu", "Yushen Liang", "Promethee Spathis"], "title": "Relation-Aware LNN-Transformer for Intersection-Centric Next-Step Prediction", "comment": "8 pages, 5 figures", "summary": "Next-step location prediction plays a pivotal role in modeling human\nmobility, underpinning applications from personalized navigation to strategic\nurban planning. However, approaches that assume a closed world - restricting\nchoices to a predefined set of points of interest (POIs) - often fail to\ncapture exploratory or target-agnostic behavior and the topological constraints\nof urban road networks. Hence, we introduce a road-node-centric framework that\nrepresents road-user trajectories on the city's road-intersection graph,\nthereby relaxing the closed-world constraint and supporting next-step\nforecasting beyond fixed POI sets. To encode environmental context, we\nintroduce a sector-wise directional POI aggregation that produces compact\nfeatures capturing distance, bearing, density and presence cues. By combining\nthese cues with structural graph embeddings, we obtain semantically grounded\nnode representations. For sequence modeling, we integrate a Relation-Aware\nLNN-Transformer - a hybrid of a Continuous-time Forgetting Cell CfC-LNN and a\nbearing-biased self-attention module - to capture both fine-grained temporal\ndynamics and long-range spatial dependencies. Evaluated on city-scale road-user\ntrajectories, our model outperforms six state-of-the-art baselines by up to 17\npercentage points in accuracy at one hop and 10 percentage points in MRR, and\nmaintains high resilience under noise, losing only 2.4 percentage points in\naccuracy at one under 50 meter GPS perturbation and 8.9 percentage points in\naccuracy at one hop under 25 percent POI noise.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9053\u8def\u8282\u70b9\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5206\u533a\u5f0f\u65b9\u5411\u6027POI\u6c47\u805a\u548cLNN-Transformer\u8fdb\u884c\u5efa\u6a21\uff0c\u5728\u57ce\u5e02\u9053\u8def\u4ea4\u53c9\u56fe\u4e0a\u8f68\u8ff9\u9884\u6d4b\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u6bd4\u516d\u79cd\u57fa\u7ebf\u6a21\u578b\u6709\u8f83\u5927\u7684\u51c6\u786e\u6027\u63d0\u5347\uff0c\u5e76\u5728\u566a\u58f0\u4e0b\u8868\u73b0\u9c81\u68d2\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8ePOI\u96c6\u5408\u7684\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u63a2\u7d22\u6027\u6216\u76ee\u6807\u65e0\u5173\u884c\u4e3a\u4ee5\u53ca\u57ce\u5e02\u9053\u8def\u7f51\u7edc\u7684\u62d3\u6251\u7ea6\u675f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8d85\u8d8aPOI\u96c6\u7684\u6846\u67b6\u6765\u652f\u6301\u4e0b\u4e00\u6b65\u9884\u6d4b\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7f16\u7801\u73af\u5883\u80cc\u666f\u548c\u9053\u8def\u7f51\u7edc\u4fe1\u606f\uff0c\u5f15\u5165\u4e86\u5206\u533a\u5f0f\u65b9\u5411\u6027POI\u805a\u5408\u548c\u7ed3\u6784\u56fe\u5d4c\u5165\uff0c\u5e76\u7ed3\u5408LNN-Transformer\u8fdb\u884c\u7ec6\u7c92\u5ea6\u65f6\u95f4\u52a8\u6001\u548c\u8fdc\u7a0b\u7a7a\u95f4\u4f9d\u8d56\u6027\u5efa\u6a21\u3002", "method": "\u8be5\u8bba\u6587\u5f15\u5165\u4e86\u57fa\u4e8e\u9053\u8def\u8282\u70b9\u7684\u6846\u67b6\uff0c\u5206\u533a\u5f0f\u65b9\u5411\u6027POI\u6c47\u805a\u548c\u7ed3\u6784\u56fe\u5d4c\u5165\uff0c\u4ee5\u53caLNN-Transformer\u7528\u4e8e\u5e8f\u5217\u5efa\u6a21\u3002\u6a21\u578b\u7efc\u5408\u8003\u8651\u4e86\u65f6\u95f4\u52a8\u6001\u548c\u7a7a\u95f4\u4f9d\u8d56\u6027\uff0c\u901a\u8fc7\u5bf9\u73af\u5883\u80cc\u666f\u548c\u9053\u8def\u4ea4\u53c9\u56fe\u8fdb\u884c\u5efa\u6a21\u6765\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "result": "\u8be5\u6a21\u578b\u5728\u57ce\u5e02\u89c4\u6a21\u4e0b\u9053\u8def\u7528\u6237\u8f68\u8ff9\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u51c6\u786e\u6027\u9ad8\u4e8e\u516d\u79cd\u6700\u5148\u8fdb\u57fa\u7ebf\u6a21\u578b\u6700\u591a17\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u5728\u566a\u58f0\u4e0b\u4fdd\u6301\u8f83\u9ad8\u7684\u9c81\u68d2\u6027\u3002\u5728GPS\u6270\u52a8\u548cPOI\u566a\u58f0\u4e0b\uff0c\u6a21\u578b\u7684\u51c6\u786e\u6027\u635f\u5931\u8f83\u5c0f\uff0c\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u566a\u58f0\u4e0b\u90fd\u80fd\u4fdd\u6301\u8f83\u9ad8\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9053\u8def\u8282\u70b9\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u57ce\u5e02\u9053\u8def\u4ea4\u53c9\u56fe\u4e0a\u8868\u793a\u9053\u8def\u7528\u6237\u8f68\u8ff9\uff0c\u652f\u6301\u8d85\u51fa\u56fa\u5b9aPOI\u96c6\u7684\u4e0b\u4e00\u6b65\u9884\u6d4b\u3002\u901a\u8fc7\u5f15\u5165\u5206\u533a\u5f0f\u65b9\u5411\u6027POI\u6c47\u805a\u6765\u7f16\u7801\u73af\u5883\u80cc\u666f\uff0c\u7ed3\u5408\u7ed3\u6784\u56fe\u5d4c\u5165\u548c\u5173\u7cfb\u611f\u77e5\u7684LNN-Transformer\u8fdb\u884c\u5e8f\u5217\u5efa\u6a21\uff0c\u8be5\u6a21\u578b\u5728\u57ce\u5e02\u89c4\u6a21\u7684\u9053\u8def\u7528\u6237\u8f68\u8ff9\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u516d\u79cd\u6700\u5148\u8fdb\u57fa\u7ebf\u6a21\u578b\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.01432", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01432", "abs": "https://arxiv.org/abs/2508.01432", "authors": ["Yuanzhe Shen", "Kaimin Wang", "Changze Lv", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "TripTailor: A Real-World Benchmark for Personalized Travel Planning", "comment": "Accepted to ACL 2025 Findings", "summary": "The continuous evolution and enhanced reasoning capabilities of large\nlanguage models (LLMs) have elevated their role in complex tasks, notably in\ntravel planning, where demand for personalized, high-quality itineraries is\nrising. However, current benchmarks often rely on unrealistic simulated data,\nfailing to reflect the differences between LLM-generated and real-world\nitineraries. Existing evaluation metrics, which primarily emphasize\nconstraints, fall short of providing a comprehensive assessment of the overall\nquality of travel plans. To address these limitations, we introduce TripTailor,\na benchmark designed specifically for personalized travel planning in\nreal-world scenarios. This dataset features an extensive collection of over\n500,000 real-world points of interest (POIs) and nearly 4,000 diverse travel\nitineraries, complete with detailed information, providing a more authentic\nevaluation framework. Experiments show that fewer than 10\\% of the itineraries\ngenerated by the latest state-of-the-art LLMs achieve human-level performance.\nMoreover, we identify several critical challenges in travel planning, including\nthe feasibility, rationality, and personalized customization of the proposed\nsolutions. We hope that TripTailor will drive the development of travel\nplanning agents capable of understanding and meeting user needs while\ngenerating practical itineraries. Our code and dataset are available at\nhttps://github.com/swxkfm/TripTailor", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86TripTailor\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u4e3a\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u63d0\u4f9b\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u7814\u7a76\u53d1\u73b0\u5c11\u4e8e10% \u7684\u6700\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u65c5\u884c\u8ba1\u5212\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\uff0c\u5e76\u786e\u5b9a\u4e86\u65c5\u884c\u89c4\u5212\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u7ecf\u5e38\u4f9d\u8d56\u4e8e\u4e0d\u771f\u5b9e\u7684\u6a21\u62df\u6570\u636e\uff0c\u672a\u80fd\u53cd\u6620\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u65c5\u884c\u8ba1\u5212\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u5dee\u5f02\u3002\u73b0\u6709\u7684\u8bc4\u4f30\u6307\u6807\u4e3b\u8981\u5f3a\u8c03\u7ea6\u675f\u6761\u4ef6\uff0c\u65e0\u6cd5\u4e3a\u65c5\u884c\u8ba1\u5212\u7684\u6574\u4f53\u8d28\u91cf\u63d0\u4f9b\u5168\u9762\u8bc4\u4f30\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5f15\u5165TripTailor\u8fd9\u6837\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u8bbe\u8ba1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u63d0\u4f9b\u66f4\u771f\u5b9e\u3001\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86TripTailor\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec500,000\u591a\u4e2a\u73b0\u5b9e\u4e16\u754c\u5174\u8da3\u70b9\u548c\u8fd14,000\u4e2a\u591a\u6837\u5316\u65c5\u884c\u89c4\u5212\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u65c5\u884c\u8ba1\u5212\u4e2d\uff0c\u5c11\u4e8e10% \u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u8868\u73b0\u3002\u7814\u7a76\u8fd8\u786e\u5b9a\u4e86\u65c5\u884c\u89c4\u5212\u4e2d\u7684\u51e0\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5982\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3001\u5408\u7406\u6027\u548c\u4e2a\u6027\u5316\u5b9a\u5236\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c11\u4e8e10% \u7684\u6700\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u65c5\u884c\u8ba1\u5212\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u786e\u5b9a\u4e86\u65c5\u884c\u89c4\u5212\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5982\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3001\u5408\u7406\u6027\u548c\u4e2a\u6027\u5316\u5b9a\u5236\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86TripTailor\uff0c\u8fd9\u662f\u4e00\u4e2a\u9488\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u8bbe\u8ba1\u7684\u57fa\u51c6\uff0c\u65e8\u5728\u5f25\u8865\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u7684\u4e0d\u771f\u5b9e\u56e0\u7d20\uff0c\u5e76\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u7814\u7a76\u53d1\u73b0\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u65c5\u884c\u8ba1\u5212\u4e2d\uff0c\u5c11\u4e8e10% \u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u8868\u73b0\u3002\u6b64\u5916\uff0c\u7814\u7a76\u6307\u51fa\u65c5\u884c\u89c4\u5212\u4e2d\u5b58\u5728\u51e0\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3001\u5408\u7406\u6027\u548c\u4e2a\u6027\u5316\u5b9a\u5236\u3002\u5e0c\u671bTripTailor\u80fd\u63a8\u52a8\u5f00\u53d1\u80fd\u591f\u7406\u89e3\u5e76\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u7684\u65c5\u884c\u89c4\u5212\u4ee3\u7406\u3002"}}
{"id": "2508.01475", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01475", "abs": "https://arxiv.org/abs/2508.01475", "authors": ["Zhen Wu", "Ritam Dutt", "Luke M. Breitfeller", "Armineh Nourbakhsh", "Siddharth Parekh", "Carolyn Ros\u00e9"], "title": "$R^2$-CoD: Understanding Text-Graph Complementarity in Relational Reasoning via Knowledge Co-Distillation", "comment": null, "summary": "Relational reasoning lies at the core of many NLP tasks, drawing on\ncomplementary signals from text and graphs. While prior research has\ninvestigated how to leverage this dual complementarity, a detailed and\nsystematic understanding of text-graph interplay and its effect on hybrid\nmodels remains underexplored. We take an analysis-driven approach to\ninvestigate text-graph representation complementarity via a unified\narchitecture that supports knowledge co-distillation (CoD). We explore five\ntasks involving relational reasoning that differ in how text and graph\nstructures encode the information needed to solve that task. By tracking how\nthese dual representations evolve during training, we uncover interpretable\npatterns of alignment and divergence, and provide insights into when and why\ntheir integration is beneficial.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790\u9a71\u52a8\u7684\u65b9\u6cd5\u7814\u7a76\u4e86\u6587\u672c-\u56fe\u5f62\u8868\u793a\u7684\u4e92\u8865\u6027\uff0c\u63ed\u793a\u4e86\u77e5\u8bc6\u5171\u84b8\u998f\u5728\u6df7\u5408\u6a21\u578b\u4e2d\u7684\u4f5c\u7528\u3002\u7814\u7a76\u63a2\u7a76\u4e86\u4e94\u4e2a\u4e0d\u540c\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u4e2d\u6587\u672c\u548c\u56fe\u5f62\u7ed3\u6784\u7684\u6f14\u53d8\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f53\u548c\u4e3a\u4f55\u6574\u5408\u662f\u6709\u76ca\u7684\u6d1e\u5bdf\u3002\u7ed3\u679c\u8868\u660e\u6587\u672c-\u56fe\u5f62\u8868\u793a\u7684\u4e92\u8865\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5982\u4f55\u5229\u7528\u6587\u672c\u548c\u56fe\u5f62\u7684\u53cc\u91cd\u4e92\u8865\u6027\uff0c\u4f46\u5bf9\u6587\u672c-\u56fe\u5f62\u76f8\u4e92\u4f5c\u7528\u53ca\u5176\u5bf9\u6df7\u5408\u6a21\u578b\u7684\u5f71\u54cd\u7f3a\u4e4f\u8be6\u5c3d\u548c\u7cfb\u7edf\u7684\u7406\u89e3\u3002\u56e0\u6b64\uff0c\u672c\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u901a\u8fc7\u5206\u6790\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u6df1\u5165\u63a2\u8ba8\u6587\u672c-\u56fe\u5f62\u8868\u793a\u7684\u4e92\u8865\u6027\uff0c\u5e76\u4e86\u89e3\u5176\u5bf9\u6df7\u5408\u6a21\u578b\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u5206\u6790\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u652f\u6301\u77e5\u8bc6\u5171\u84b8\u998f\u7684\u7edf\u4e00\u67b6\u6784\u63a2\u7a76\u6587\u672c-\u56fe\u5f62\u8868\u793a\u7684\u4e92\u8865\u6027\u3002\u901a\u8fc7\u7814\u7a76\u4e94\u4e2a\u4e0d\u540c\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u4e2d\u6587\u672c\u548c\u56fe\u5f62\u7ed3\u6784\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6f14\u53d8\uff0c\u63ed\u793a\u4e86\u5bf9\u9f50\u548c\u5206\u6b67\u7684\u6a21\u5f0f\uff0c\u5e76\u9610\u660e\u4e86\u6574\u5408\u7684\u76ca\u5904\u3002", "result": "\u901a\u8fc7\u7814\u7a76\u8868\u660e\uff0c\u6587\u672c-\u56fe\u5f62\u8868\u793a\u7684\u4e92\u8865\u6027\u5bf9\u4e8e\u6df7\u5408\u6a21\u578b\u7684\u6027\u80fd\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\u4e86\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u6587\u672c\u548c\u56fe\u5f62\u7ed3\u6784\u7f16\u7801\u4fe1\u606f\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53cc\u91cd\u8868\u793a\u7684\u6f14\u53d8\u6a21\u5f0f\u3002\u540c\u65f6\uff0c\u8bba\u6587\u63d0\u4f9b\u4e86\u5bf9\u6574\u5408\u7684\u6d1e\u5bdf\uff0c\u89e3\u91ca\u4e86\u4e3a\u4f55\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6574\u5408\u662f\u6709\u76ca\u7684\u3002", "conclusion": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790\u9a71\u52a8\u7684\u65b9\u6cd5\u7814\u7a76\u4e86\u6587\u672c-\u56fe\u5f62\u8868\u793a\u7684\u4e92\u8865\u6027\uff0c\u63ed\u793a\u4e86\u77e5\u8bc6\u5171\u84b8\u998f\u5728\u6df7\u5408\u6a21\u578b\u4e2d\u7684\u4f5c\u7528\u3002\u901a\u8fc7\u5bf9\u4e94\u4e2a\u6d89\u53ca\u5173\u7cfb\u63a8\u7406\u7684\u4efb\u52a1\u8fdb\u884c\u63a2\u7d22\uff0c\u53d1\u73b0\u4e86\u6587\u672c\u548c\u56fe\u5f62\u7ed3\u6784\u5982\u4f55\u7f16\u7801\u4efb\u52a1\u6240\u9700\u4fe1\u606f\u7684\u4e0d\u540c\u4e4b\u5904\u3002\u8ddf\u8e2a\u8fd9\u4e9b\u53cc\u91cd\u8868\u793a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6f14\u53d8\uff0c\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u7684\u5bf9\u9f50\u548c\u5206\u6b67\u6a21\u5f0f\uff0c\u5e76\u6df1\u5165\u63a2\u8ba8\u4e86\u5b83\u4eec\u7684\u6574\u5408\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u6709\u76ca\u4e4b\u5904\u3002"}}
{"id": "2508.01476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01476", "abs": "https://arxiv.org/abs/2508.01476", "authors": ["Arindam Khanda", "Anurag Satpathy", "Amit Jha", "Sajal K. Das"], "title": "CARGO: A Co-Optimization Framework for EV Charging and Routing in Goods Delivery Logistics", "comment": null, "summary": "With growing interest in sustainable logistics, electric vehicle (EV)-based\ndeliveries offer a promising alternative for urban distribution. However, EVs\nface challenges due to their limited battery capacity, requiring careful\nplanning for recharging. This depends on factors such as the charging point\n(CP) availability, cost, proximity, and vehicles' state of charge (SoC). We\npropose CARGO, a framework addressing the EV-based delivery route planning\nproblem (EDRP), which jointly optimizes route planning and charging for\ndeliveries within time windows. After proving the problem's NP-hardness, we\npropose a mixed integer linear programming (MILP)-based exact solution and a\ncomputationally efficient heuristic method. Using real-world datasets, we\nevaluate our methods by comparing the heuristic to the MILP solution, and\nbenchmarking it against baseline strategies, Earliest Deadline First (EDF) and\nNearest Delivery First (NDF). The results show up to 39% and 22% reductions in\nthe charging cost over EDF and NDF, respectively, while completing comparable\ndeliveries.", "AI": {"tldr": "\u63d0\u51fa\u4e86CARGO\u6846\u67b6\u89e3\u51b3\u57fa\u4e8e\u7535\u52a8\u8f66\u7684\u9001\u8d27\u8def\u7ebf\u89c4\u5212\u95ee\u9898\uff0c\u4f18\u5316\u8def\u7ebf\u89c4\u5212\u548c\u5145\u7535\u5b89\u6392\uff0c\u964d\u4f4e\u5145\u7535\u6210\u672c\uff0c\u5b8c\u6210\u9001\u8d27\u4efb\u52a1\u3002\u65b9\u6cd5\u5305\u62ec\u57fa\u4e8eMILP\u7684\u7cbe\u786e\u89e3\u51b3\u65b9\u6848\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u5e76\u4e0e\u57fa\u7ebf\u7b56\u7565\u8fdb\u884c\u6bd4\u8f83\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002\u7ed3\u679c\u663e\u793a\u663e\u8457\u964d\u4f4e\u5145\u7535\u6210\u672c\u540c\u65f6\u5b8c\u6210\u4efb\u52a1\u3002", "motivation": "\u968f\u7740\u5bf9\u53ef\u6301\u7eed\u7269\u6d41\u7684\u5174\u8da3\u589e\u957f\uff0c\u57fa\u4e8e\u7535\u52a8\u8f66\u7684\u9001\u8d27\u6210\u4e3a\u57ce\u5e02\u914d\u9001\u7684\u4e00\u79cd\u6709\u524d\u9014\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u7535\u52a8\u8f66\u9762\u4e34\u9650\u5236\u7535\u6c60\u5bb9\u91cf\u7684\u6311\u6218\uff0c\u9700\u8981\u8c28\u614e\u89c4\u5212\u5145\u7535\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u95ee\u9898\u7684NP\u96be\u5ea6\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eMILP\u7684\u7cbe\u786e\u89e3\u51b3\u65b9\u6848\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e0eMILP\u89e3\u51b3\u65b9\u6848\uff0c\u5c06\u5176\u4e0e\u57fa\u7ebf\u7b56\u7565\u6700\u65e9\u622a\u6b62\u65f6\u95f4\u4f18\u5148\uff08EDF\uff09\u548c\u6700\u8fd1\u4ea4\u4ed8\u4f18\u5148\uff08NDF\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u5145\u7535\u6210\u672c\u76f8\u6bd4\u4e8e\u57fa\u51c6\u7b56\u7565\uff08EDF\u548cNDF\uff09\u5206\u522b\u964d\u4f4e\u4e8639%\u548c22%\uff0c\u540c\u65f6\u5b8c\u6210\u4e86\u53ef\u6bd4\u8f83\u7684\u9001\u8d27\u4efb\u52a1\u3002", "conclusion": "\u63d0\u51fa\u4e86CARGO\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u57fa\u4e8e\u7535\u52a8\u8f66\u7684\u9001\u8d27\u8def\u7ebf\u89c4\u5212\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u8def\u7ebf\u89c4\u5212\u548c\u5145\u7535\u5b89\u6392\uff0c\u5728\u65f6\u95f4\u7a97\u53e3\u5185\u5b8c\u6210\u9001\u8d27\u3002\u63d0\u51fa\u4e86\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u7684\u7cbe\u786e\u89e3\u51b3\u65b9\u6848\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u901a\u8fc7\u4e0e\u57fa\u7ebf\u7b56\u7565\u7684\u6bd4\u8f83\uff0c\u7ed3\u679c\u663e\u793a\u4e0e\u6700\u65e9\u622a\u6b62\u65f6\u95f4\u4f18\u5148\uff08EDF\uff09\u548c\u6700\u8fd1\u4ea4\u4ed8\u4f18\u5148\uff08NDF\uff09\u76f8\u6bd4\uff0c\u5145\u7535\u6210\u672c\u5206\u522b\u964d\u4f4e\u4e8639%\u548c22%\uff0c\u540c\u65f6\u5b8c\u6210\u4e86\u53ef\u6bd4\u8f83\u7684\u9001\u8d27\u4efb\u52a1\u3002"}}
{"id": "2508.01495", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01495", "abs": "https://arxiv.org/abs/2508.01495", "authors": ["Jingtian Yan", "Stephen F. Smith", "Jiaoyang Li"], "title": "WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning", "comment": null, "summary": "Planning collision-free paths for a large group of agents is a challenging\nproblem with numerous real-world applications. While recent advances in\nMulti-Agent Path Finding (MAPF) have shown promising progress, standard MAPF\nalgorithms rely on simplified kinodynamic models, preventing agents from\ndirectly following the generated MAPF plan. To bridge this gap, we propose\nkinodynamic Temporal Plan Graph Planning (kTPG), a multi-agent speed\noptimization algorithm that efficiently refines a MAPF plan into a\nkinodynamically feasible plan while accounting for uncertainties and preserving\ncollision-freeness. Building on kTPG, we propose Windowed kTPG (WinkTPG), a\nMAPF execution framework that incrementally refines MAPF plans using a\nwindow-based mechanism, dynamically incorporating agent information during\nexecution to reduce uncertainty. Experiments show that WinkTPG can generate\nspeed profiles for up to 1,000 agents in 1 second and improves solution quality\nby up to 51.7% over existing MAPF execution methods.", "AI": {"tldr": "The paper introduces kTPG and WinkTPG algorithms to enhance Multi-Agent Path Finding by refining plans and optimizing speed profiles for agents, achieving a 51.7% improvement in solution quality over existing methods.", "motivation": "Address the limitation of simplified kinodynamic models in standard MAPF algorithms to allow agents to follow generated plans directly, while considering uncertainties and maintaining collision-freeness.", "method": "Proposed kinodynamic Temporal Plan Graph Planning (kTPG) and Windowed kTPG (WinkTPG) algorithms to refine MAPF plans and incrementally optimize speed profiles for large groups of agents.", "result": "Experiments demonstrate that WinkTPG can efficiently generate speed profiles for 1,000 agents in 1 second and significantly enhance solution quality compared to current MAPF execution approaches.", "conclusion": "Windowed kTPG improves solution quality in Multi-Agent Path Finding execution by up to 51.7% over existing methods."}}
{"id": "2508.01543", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01543", "abs": "https://arxiv.org/abs/2508.01543", "authors": ["Derin Cayir", "Renjie Tao", "Rashi Rungta", "Kai Sun", "Sean Chen", "Haidar Khan", "Minseok Kim", "Julia Reinspach", "Yue Liu"], "title": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable progress through\npreference-based fine-tuning, which critically depends on the quality of the\nunderlying training data. While human feedback is essential for improving data\nquality, it is costly and does not scale well. In this paper, we introduce\nRefine-n-Judge, an automated iterative approach that leverages a single LLM as\nboth a refiner and a judge to enhance dataset quality. Unlike existing\niterative refinement methods, Refine-n-Judge employs an LLM to both generate\nrefinements and explicitly evaluate each improvement, ensuring that every\niteration meaningfully enhances the dataset without requiring additional human\nannotation or a separate reward model. At each step, the LLM refines a response\nand judges whether the refinement is an improvement over the previous answer.\nThis process continues until the LLM prefers the initial answer over the\nrefinement, indicating no further improvements. This produces sequences of\nincreasing quality, preference-labeled responses ideal for fine-tuning.\n  We demonstrate the effectiveness of Refine-n-Judge across a range of public\ndatasets spanning five corpora, targeting tasks such as coding, math, and\nconversation. Models (Llama 3.1-8B and Llama 3.3-70B) fine-tuned on\nRefine-n-Judge-enhanced datasets were preferred by LLM judges in over 74% of\ncomparisons against models tuned on the original dataset by GPT-4.\nAdditionally, we report performance gains: +5% on AlpacaEval and AlpacaEval\n2.0, and +19% on MT-Bench. Our results indicate that Refine-n-Judge produces\nhigh-quality datasets and scalable model improvements.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aRefine-n-Judge\u7684\u81ea\u52a8\u5316\u8fed\u4ee3\u65b9\u6cd5\uff0c\u5229\u7528\u5355\u4e2aLLM\u4f5c\u4e3a\u7ec6\u5316\u8005\u548c\u8bc4\u5224\u8005\uff0c\u4ee5\u63d0\u9ad8\u6570\u636e\u96c6\u8d28\u91cf\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u901a\u8fc7Refine-n-Judge\u589e\u5f3a\u7684\u6570\u636e\u96c6\u5728\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u6709\u663e\u8457\u6548\u679c\uff0c\u5bf9\u591a\u79cd\u4efb\u52a1\u7684\u6a21\u578b\u5fae\u8c03\u6027\u80fd\u4f18\u5f02\u3002Refine-n-Judge\u65b9\u6cd5\u4ea7\u751f\u7684\u6570\u636e\u96c6\u5728\u5927\u591a\u6570\u6bd4\u8f83\u4e2d\u4f18\u4e8e\u76f4\u63a5\u4f7f\u7528GPT-4\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u6027\u80fd\u63d0\u5347\u8f83\u5927\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cRefine-n-Judge\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u5e76\u5b9e\u73b0\u6a21\u578b\u6027\u80fd\u7684\u53ef\u6269\u5c55\u6539\u8fdb\u3002", "motivation": "LLM\u901a\u8fc7\u57fa\u4e8e\u504f\u597d\u7684\u5fae\u8c03\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u8d28\u91cf\u53d6\u51b3\u4e8e\u5e95\u5c42\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u3002\u6539\u5584\u6570\u636e\u8d28\u91cf\u7684\u5173\u952e\u5728\u4e8e\u4eba\u7c7b\u53cd\u9988\uff0c\u4f46\u6210\u672c\u9ad8\u4e14\u6269\u5c55\u6027\u5dee\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u5f15\u5165\u4e00\u79cd\u6709\u6548\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u4eba\u7c7b\u6807\u6ce8\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f15\u5165\u4e86Refine-n-Judge\u81ea\u52a8\u5316\u8fed\u4ee3\u65b9\u6cd5\uff0c\u5229\u7528\u5355\u4e2aLLM\u4f5c\u4e3a\u7ec6\u5316\u8005\u548c\u8bc4\u5224\u8005\uff0c\u4ee5\u63d0\u9ad8\u6570\u636e\u96c6\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528LLM\u751f\u6210\u7ec6\u5316\u548c\u660e\u786e\u8bc4\u4f30\u6bcf\u9879\u6539\u8fdb\uff0c\u786e\u4fdd\u6bcf\u6b21\u8fed\u4ee3\u90fd\u80fd\u6709\u610f\u4e49\u5730\u589e\u5f3a\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u800c\u65e0\u9700\u989d\u5916\u7684\u4eba\u5458\u6807\u6ce8\u6216\u5355\u72ec\u7684\u5956\u52b1\u6a21\u578b\u3002LLM\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\u5bf9\u56de\u5e94\u8fdb\u884c\u7ec6\u5316\uff0c\u5e76\u5224\u65ad\u8be5\u7ec6\u5316\u662f\u5426\u4f18\u4e8e\u5148\u524d\u7684\u7b54\u6848\uff0c\u76f4\u5230LLM\u66f4\u504f\u597d\u521d\u59cb\u7b54\u6848\u800c\u4e0d\u662f\u7ec6\u5316\uff0c\u8868\u660e\u6ca1\u6709\u8fdb\u4e00\u6b65\u7684\u6539\u8fdb\u3002\u901a\u8fc7\u8fd9\u4e00\u8fc7\u7a0b\u4ea7\u751f\u4e86\u8d28\u91cf\u4e0d\u65ad\u63d0\u9ad8\u7684\u5e8f\u5217\uff0c\u9002\u5408\u7ec6\u5316\u3002", "result": "Refine-n-Judge\u65b9\u6cd5\u5728\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u7684\u6548\u679c\uff0c\u5bf9\u7f16\u7801\u3001\u6570\u5b66\u548c\u5bf9\u8bdd\u7b49\u4efb\u52a1\u7684\u6a21\u578b\u5fae\u8c03\u5747\u8868\u73b0\u51fa\u8272\u3002\u901a\u8fc7\u6b64\u65b9\u6cd5\u589e\u5f3a\u7684\u6570\u636e\u96c6\u572874%\u4ee5\u4e0a\u7684\u6bd4\u8f83\u4e2d\u66f4\u53d7LLM\u6cd5\u5b98\u9752\u7750\uff0c\u5e76\u5728AlpacaEval\u3001AlpacaEval 2.0\u548cMT-Bench\u4e0a\u5747\u83b7\u5f97\u4e86\u6027\u80fd\u63d0\u5347\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRefine-n-Judge\u80fd\u591f\u4ea7\u751f\u9ad8\u54c1\u8d28\u6570\u636e\u96c6\u5e76\u5b9e\u73b0\u6a21\u578b\u6027\u80fd\u7684\u53ef\u6269\u5c55\u6539\u8fdb\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u8fed\u4ee3\u65b9\u6cd5Refine-n-Judge\uff0c\u5229\u7528\u5355\u4e2aLLM\u4f5c\u4e3a\u7ec6\u5316\u8005\u548c\u8bc4\u5224\u8005\uff0c\u4ee5\u63d0\u9ad8\u6570\u636e\u96c6\u8d28\u91cf\u3002\u7ed3\u679c\u8868\u660e\uff0cRefine-n-Judge\u5728\u4e94\u4e2a\u8bed\u6599\u5e93\u8de8\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u6548\u679c\u663e\u8457\uff0c\u5bf9\u7f16\u7801\u3001\u6570\u5b66\u548c\u5bf9\u8bdd\u7b49\u4efb\u52a1\u7684\u6a21\u578b\u5fae\u8c03\u8868\u73b0\u51fa\u8272\u3002\u901a\u8fc7Refine-n-Judge\u589e\u5f3a\u7684\u6570\u636e\u96c6\u5bf9LLM\u6cd5\u5b98\u7684\u504f\u597d\u6bd4\u539f\u59cb\u6570\u636e\u96c6\u4e0a\u7ecf\u8fc7GPT-4\u8c03\u6821\u7684\u6a21\u578b\u5728\u8d85\u8fc774%\u7684\u6bd4\u8f83\u4e2d\u66f4\u53d7\u9752\u7750\uff0c\u5e76\u4e14\u5728AlpacaEval\u3001AlpacaEval 2.0\u548cMT-Bench\u4e0a\u5747\u83b7\u5f97\u4e86\u6027\u80fd\u63d0\u5347\u3002\n\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cRefine-n-Judge\u80fd\u4ea7\u751f\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u5e76\u5b9e\u73b0\u6a21\u578b\u6027\u80fd\u7684\u53ef\u6269\u5c55\u6539\u8fdb\u3002"}}
{"id": "2508.01545", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.01545", "abs": "https://arxiv.org/abs/2508.01545", "authors": ["Emilio Barkett", "Olivia Long", "Paul Kr\u00f6ger"], "title": "Getting out of the Big-Muddy: Escalation of Commitment in LLMs", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in autonomous\ndecision-making roles across high-stakes domains. However, since models are\ntrained on human-generated data, they may inherit cognitive biases that\nsystematically distort human judgment, including escalation of commitment,\nwhere decision-makers continue investing in failing courses of action due to\nprior investment. Understanding when LLMs exhibit such biases presents a unique\nchallenge. While these biases are well-documented in humans, it remains unclear\nwhether they manifest consistently in LLMs or require specific triggering\nconditions. This paper investigates this question using a two-stage investment\ntask across four experimental conditions: model as investor, model as advisor,\nmulti-agent deliberation, and compound pressure scenario. Across N = 6,500\ntrials, we find that bias manifestation in LLMs is highly context-dependent. In\nindividual decision-making contexts (Studies 1-2, N = 4,000), LLMs demonstrate\nstrong rational cost-benefit logic with minimal escalation of commitment.\nHowever, multi-agent deliberation reveals a striking hierarchy effect (Study 3,\nN = 500): while asymmetrical hierarchies show moderate escalation rates\n(46.2%), symmetrical peer-based decision-making produces near-universal\nescalation (99.2%). Similarly, when subjected to compound organizational and\npersonal pressures (Study 4, N = 2,000), models exhibit high degrees of\nescalation of commitment (68.95% average allocation to failing divisions).\nThese findings reveal that LLM bias manifestation depends critically on social\nand organizational context rather than being inherent, with significant\nimplications for the deployment of multi-agent systems and unsupervised\noperations where such conditions may emerge naturally.", "AI": {"tldr": "LLMs\u5728\u6295\u8d44\u4efb\u52a1\u5b9e\u9a8c\u4e2d\u5c55\u793a\u51fa\u504f\u89c1\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u793e\u4f1a\u548c\u7ec4\u7ec7\u80cc\u666f\uff0c\u7ed3\u679c\u5bf9\u591a\u667a\u80fd\u7cfb\u7edf\u7684\u90e8\u7f72\u548c\u65e0\u76d1\u7763\u8fd0\u8425\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u7531\u4e8eLLMs\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u81ea\u4e3b\u51b3\u7b56\u4e2d\u8d8a\u6765\u8d8a\u5e7f\u6cdb\u5730\u5e94\u7528\uff0c\u4e86\u89e3\u5b83\u4eec\u662f\u5426\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u8ba4\u77e5\u504f\u89c1\u7684\u91cd\u8981\u6027\u5c24\u4e3a\u7a81\u51fa\u3002", "method": "\u901a\u8fc7\u8fdb\u884c\u4e24\u9636\u6bb5\u6295\u8d44\u4efb\u52a1\u5b9e\u9a8c\uff0c\u5206\u4e3a\u56db\u4e2a\u5b9e\u9a8c\u6761\u4ef6\uff1a\u6a21\u578b\u4f5c\u4e3a\u6295\u8d44\u8005\uff0c\u6a21\u578b\u4f5c\u4e3a\u987e\u95ee\uff0c\u591a\u667a\u80fd\u4f53\u534f\u5546\u548c\u590d\u5408\u538b\u529b\u60c5\u5883\uff0c\u8c03\u67e5LLMs\u5c55\u793a\u504f\u89c1\u7684\u60c5\u51b5\u3002", "result": "LLMs\u5728\u4e2a\u4f53\u51b3\u7b56\u80cc\u666f\u4e0b\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u6210\u672c\u6548\u76ca\u903b\u8f91\uff0c\u5e76\u4e14\u5f88\u5c11\u8868\u73b0\u51fa\u5347\u7ea7\u627f\u8bfa\u3002\u7136\u800c\uff0c\u5728\u591a\u4ee3\u7406\u4eba\u534f\u5546\u4e2d\uff0c\u8868\u73b0\u51fa\u660e\u663e\u7684\u7b49\u7ea7\u6548\u5e94\u3002\u5f53\u9762\u5bf9\u590d\u5408\u7ec4\u7ec7\u548c\u4e2a\u4eba\u538b\u529b\u65f6\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u9ad8\u7a0b\u5ea6\u7684\u627f\u8bfa\u5347\u7ea7\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u5728\u5c55\u793a\u504f\u89c1\u65f6\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u793e\u4f1a\u548c\u7ec4\u7ec7\u80cc\u666f\uff0c\u800c\u975e\u56fa\u6709\u5c5e\u6027\u3002\u5176\u7ed3\u679c\u5bf9\u4e8e\u591a\u667a\u80fd\u7cfb\u7edf\u7684\u90e8\u7f72\u548c\u65e0\u76d1\u7763\u8fd0\u8425\u5177\u6709\u91cd\u8981\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.01556", "categories": ["cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.01556", "abs": "https://arxiv.org/abs/2508.01556", "authors": ["Mengshi Chen", "Yuxiang Sun", "Tengchao Li", "Jianwei Wang", "Kai Wang", "Xuemin Lin", "Ying Zhang", "Wenjie Zhang"], "title": "Empowering Tabular Data Preparation with Language Models: Why and How?", "comment": "Preprint under submission, 16 pages, 2 figures, 1 table", "summary": "Data preparation is a critical step in enhancing the usability of tabular\ndata and thus boosts downstream data-driven tasks. Traditional methods often\nface challenges in capturing the intricate relationships within tables and\nadapting to the tasks involved. Recent advances in Language Models (LMs),\nespecially in Large Language Models (LLMs), offer new opportunities to automate\nand support tabular data preparation. However, why LMs suit tabular data\npreparation (i.e., how their capabilities match task demands) and how to use\nthem effectively across phases still remain to be systematically explored. In\nthis survey, we systematically analyze the role of LMs in enhancing tabular\ndata preparation processes, focusing on four core phases: data acquisition,\nintegration, cleaning, and transformation. For each phase, we present an\nintegrated analysis of how LMs can be combined with other components for\ndifferent preparation tasks, highlight key advancements, and outline\nprospective pipelines.", "AI": {"tldr": "The paper systematically analyzes how Language Models (LMs) can enhance tabular data preparation across four core phases, providing insights on combining LMs with other components for different tasks and outlining future directions.", "motivation": "Traditional methods face challenges in capturing intricate relationships within tables, and adapting to various tasks involved. Recent advances in Language Models, especially Large Language Models, provide new possibilities for automating tabular data preparation.", "method": "Systematic analysis of the role of Language Models (LMs) in enhancing tabular data preparation processes across four core phases: data acquisition, integration, cleaning, and transformation.", "result": "Integrated analysis of how LMs can be combined with other components in different phases of tabular data preparation tasks, highlighting advancements and outlining prospective pipelines.", "conclusion": "LMs offer new opportunities to automate and support tabular data preparation, but the effectiveness of using LMs in different phases needs further exploration."}}
{"id": "2508.01561", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01561", "abs": "https://arxiv.org/abs/2508.01561", "authors": ["Zijian Guo", "\u0130lker I\u015f\u0131k", "H. M. Sabbir Ahmad", "Wenchao Li"], "title": "One Subgoal at a Time: Zero-Shot Generalization to Arbitrary Linear Temporal Logic Requirements in Multi-Task Reinforcement Learning", "comment": null, "summary": "Generalizing to complex and temporally extended task objectives and safety\nconstraints remains a critical challenge in reinforcement learning (RL). Linear\ntemporal logic (LTL) offers a unified formalism to specify such requirements,\nyet existing methods are limited in their abilities to handle nested\nlong-horizon tasks and safety constraints, and cannot identify situations when\na subgoal is not satisfiable and an alternative should be sought. In this\npaper, we introduce GenZ-LTL, a method that enables zero-shot generalization to\narbitrary LTL specifications. GenZ-LTL leverages the structure of B\\\"uchi\nautomata to decompose an LTL task specification into sequences of reach-avoid\nsubgoals. Contrary to the current state-of-the-art method that conditions on\nsubgoal sequences, we show that it is more effective to achieve zero-shot\ngeneralization by solving these reach-avoid problems \\textit{one subgoal at a\ntime} through proper safe RL formulations. In addition, we introduce a novel\nsubgoal-induced observation reduction technique that can mitigate the\nexponential complexity of subgoal-state combinations under realistic\nassumptions. Empirical results show that GenZ-LTL substantially outperforms\nexisting methods in zero-shot generalization to unseen LTL specifications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86GenZ-LTL\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4efb\u610fLTL\u89c4\u8303\u7684\u96f6\u6837\u672c\u6cdb\u5316\u3002\u901a\u8fc7\u89e3\u51b3\u8fbe\u5230-\u907f\u514d\u5b50\u76ee\u6807\u95ee\u9898\u6765\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u80fd\u591f\u51cf\u5c11\u590d\u6742\u6027\u7684\u89c2\u5bdf\u51cf\u5c11\u6280\u672f\u3002\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cGenZ-LTL\u5728\u5bf9\u672a\u89c1LTL\u89c4\u8303\u7684\u96f6\u6837\u672c\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5f3a\u5316\u5b66\u4e60\u4e2d\u6cdb\u5316\u5230\u590d\u6742\u548c\u65f6\u95f4\u4e0a\u5ef6\u957f\u7684\u4efb\u52a1\u76ee\u6807\u548c\u5b89\u5168\u7ea6\u675f\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5d4c\u5957\u7684\u957f\u671f\u4efb\u52a1\u548c\u5b89\u5168\u7ea6\u675f\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e76\u4e14\u65e0\u6cd5\u8bc6\u522b\u5b50\u76ee\u6807\u4e0d\u53ef\u6ee1\u8db3\u5e76\u4e14\u9700\u8981\u5bfb\u627e\u66ff\u4ee3\u65b9\u6848\u7684\u60c5\u51b5\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86GenZ-LTL\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528B\u00fcchi\u81ea\u52a8\u673a\u7684\u7ed3\u6784\uff0c\u5c06LTL\u4efb\u52a1\u89c4\u8303\u5206\u89e3\u4e3a\u8fbe\u5230-\u907f\u514d\u5b50\u76ee\u6807\uff0c\u800c\u4e0d\u662f\u57fa\u4e8e\u5b50\u76ee\u6807\u5e8f\u5217\u8fdb\u884c\u6761\u4ef6\u8bbe\u7f6e\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u5b50\u76ee\u6807\u8bf1\u5bfc\u89c2\u5bdf\u51cf\u5c11\u6280\u672f\u6765\u51cf\u5c11\u5b9e\u9645\u5047\u8bbe\u4e0b\u7684\u5b50\u76ee\u6807-\u72b6\u6001\u7ec4\u5408\u7684\u590d\u6742\u6027\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cGenZ-LTL\u5728\u5bf9\u672a\u89c1LTL\u89c4\u8303\u7684\u96f6\u6837\u672c\u6cdb\u5316\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86GenZ-LTL\uff0c\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u5bf9\u4efb\u610fLTL\u89c4\u8303\u7684\u96f6\u6837\u672c\u6cdb\u5316\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u4f7f\u7528B\u00fcchi\u81ea\u52a8\u673a\u7684\u7ed3\u6784\uff0cGenZ-LTL\u5c06LTL\u4efb\u52a1\u89c4\u8303\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u8fbe\u5230-\u907f\u514d\u5b50\u76ee\u6807\u3002\u4e0e\u76ee\u524d\u7684\u72b6\u6001-of-the-art\u65b9\u6cd5\u76f8\u53cd\uff0c\u8be5\u65b9\u6cd5\u4e0d\u662f\u6839\u636e\u5b50\u76ee\u6807\u5e8f\u5217\u8fdb\u884c\u6761\u4ef6\u8bbe\u7f6e\uff0c\u800c\u662f\u901a\u8fc7\u9002\u5f53\u7684\u5b89\u5168RL\u516c\u5f0f\u4e00\u6b21\u89e3\u51b3\u8fd9\u4e9b\u8fbe\u5230-\u907f\u514d\u95ee\u9898\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b50\u76ee\u6807\u8bf1\u5bfc\u89c2\u5bdf\u51cf\u5c11\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u5b9e\u9645\u5047\u8bbe\u4e0b\u51cf\u5c11\u5b50\u76ee\u6807-\u72b6\u6001\u7ec4\u5408\u7684\u6307\u6570\u590d\u6742\u6027\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cGenZ-LTL\u5728\u5bf9\u672a\u89c1LTL\u89c4\u8303\u7684\u96f6\u6837\u672c\u6cdb\u5316\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.01581", "categories": ["cs.AI", "math.CO", "stat.CO"], "pdf": "https://arxiv.org/pdf/2508.01581", "abs": "https://arxiv.org/abs/2508.01581", "authors": ["David Pearl", "Matthew Murphy", "James Intriligator"], "title": "Polymorphic Combinatorial Frameworks (PCF): Guiding the Design of Mathematically-Grounded, Adaptive AI Agents", "comment": null, "summary": "The Polymorphic Combinatorial Framework (PCF) leverages Large Language Models\n(LLMs) and mathematical frameworks to guide the meta-prompt enabled design of\nsolution spaces and adaptive AI agents for complex, dynamic environments.\nUnlike static agent architectures, PCF enables real-time parameter\nreconfiguration through mathematically-grounded combinatorial spaces, allowing\nagents to adapt their core behavioral traits dynamically. Grounded in\ncombinatorial logic, topos theory, and rough fuzzy set theory, PCF defines a\nmultidimensional SPARK parameter space (Skills, Personalities, Approaches,\nResources, Knowledge) to capture agent behaviors. This paper demonstrates how\nLLMs can parameterize complex spaces and estimate likely parameter\nvalues/variabilities. Using PCF, we parameterized mock caf\\'e domains (five\nlevels of complexity), estimated variables/variabilities, and conducted over\n1.25 million Monte Carlo simulations. The results revealed trends in agent\nadaptability and performance across the five complexity tiers, with diminishing\nreturns at higher complexity levels highlighting thresholds for scalable\ndesigns. PCF enables the generation of optimized agent configurations for\nspecific scenarios while maintaining logical consistency. This framework\nsupports scalable, dynamic, explainable, and ethical AI applications in domains\nlike customer service, healthcare, robotics, and collaborative systems, paving\nthe way for adaptable and cooperative next-generation polymorphic agents.", "AI": {"tldr": "PCF framework leverages LLMs and mathematical frameworks to guide the design of adaptive AI agents. It defines a multidimensional parameter space for agent behaviors and enables real-time parameter reconfiguration. The paper demonstrated the parameterization of complex spaces, conducted simulations, and revealed trends in agent adaptability. PCF supports scalable, dynamic, explainable, and ethical AI applications in various domains.", "motivation": "To address the limitations of static agent architectures and enable real-time parameter reconfiguration through mathematically-grounded combinatorial spaces, allowing agents to adapt their core behavioral traits dynamically. The goal is to support scalable, dynamic, explainable, and ethical AI applications in customer service, healthcare, robotics, and collaborative systems.", "method": "The Polymorphic Combinatorial Framework (PCF) leverages Large Language Models (LLMs) and mathematical frameworks to guide the meta-prompt enabled design of solution spaces and adaptive AI agents for complex, dynamic environments. It utilizes combinatorial logic, topos theory, and rough fuzzy set theory to define a multidimensional SPARK parameter space capturing agent behaviors. The paper demonstrated how LLMs can parameterize complex spaces, estimate likely parameter values/variabilities, and conducted over 1.25 million Monte Carlo simulations.", "result": "The paper showcases trends in agent adaptability and performance across different complexity tiers, demonstrating diminishing returns at higher complexity levels. It highlights thresholds for scalable designs and reveals the potential for optimized agent configurations in specific scenarios.", "conclusion": "PCF framework enables the generation of optimized agent configurations for specific scenarios while maintaining logical consistency. It supports scalable, dynamic, explainable, and ethical AI applications in various domains, paving the way for adaptable and cooperative next-generation polymorphic agents."}}
{"id": "2508.01623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01623", "abs": "https://arxiv.org/abs/2508.01623", "authors": ["Tadisetty Sai Yashwanth", "Dhatri C"], "title": "A Multi-Agent Pokemon Tournament for Evaluating Strategic Reasoning of Large Language Models", "comment": null, "summary": "This research presents LLM Pokemon League, a competitive tournament system\nthat leverages Large Language Models (LLMs) as intelligent agents to simulate\nstrategic decision-making in Pok\\'emon battles. The platform is designed to\nanalyze and compare the reasoning, adaptability, and tactical depth exhibited\nby different LLMs in a type-based, turn-based combat environment. By\nstructuring the competition as a single-elimination tournament involving\ndiverse AI trainers, the system captures detailed decision logs, including\nteam-building rationale, action selection strategies, and switching decisions.\nThe project enables rich exploration into comparative AI behavior, battle\npsychology, and meta-strategy development in constrained, rule-based game\nenvironments. Through this system, we investigate how modern LLMs understand,\nadapt, and optimize decisions under uncertainty, making Pok\\'emon League a\nnovel benchmark for AI research in strategic reasoning and competitive\nlearning.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86LLM Pokemon League\u7ade\u6280\u6bd4\u8d5b\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4ee3\u7406\uff0c\u5728Pok\u00e9mon\u6218\u6597\u4e2d\u6a21\u62df\u6218\u7565\u51b3\u7b56\u3002\u901a\u8fc7\u6dd8\u6c70\u8d5b\u6bd4\u8d5b\u6a21\u5f0f\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u73b0\u4ee3LLM\u5728\u6218\u7565\u63a8\u7406\u548c\u7ade\u4e89\u6027\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u9886\u57df\u5e26\u6765\u65b0\u7684\u57fa\u51c6\u548c\u89c6\u89d2\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u73b0\u4ee3 LLM \u5728 Pok\u00e9mon \u6218\u6597\u4e2d\u7684\u6218\u7565\u51b3\u7b56\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c LLMs \u7684\u8868\u73b0\uff0c\u6df1\u5165\u7814\u7a76 AI \u884c\u4e3a\u3001\u6218\u6597\u5fc3\u7406\u5b66\u548c\u5143\u7b56\u7565\u53d1\u5c55\u3002\u7814\u7a76\u65e8\u5728\u4e86\u89e3 LLMs \u5728\u53d7\u9650\u3001\u57fa\u4e8e\u89c4\u5219\u6e38\u620f\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u65b0\u89c6\u89d2\u548c\u57fa\u51c6\u3002", "method": "\u8be5\u7814\u7a76\u8bbe\u8ba1\u4e86LLM Pokemon League\u7ade\u6280\u6bd4\u8d5b\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4ee3\u7406\uff0c\u5728Pok\u00e9mon\u6218\u6597\u4e2d\u6a21\u62df\u6218\u7565\u51b3\u7b56\u8fc7\u7a0b\u3002\u6bd4\u8d5b\u7ed3\u6784\u8bbe\u8ba1\u4e3a\u5355\u6dd8\u6c70\u8d5b\u5236\uff0c\u6d89\u53ca\u591a\u6837\u7684 AI \u8bad\u7ec3\u8005\uff0c\u6355\u6349\u8be6\u7ec6\u7684\u51b3\u7b56\u65e5\u5fd7\uff0c\u5305\u62ec\u56e2\u961f\u6784\u5efa\u539f\u7406\u3001\u884c\u52a8\u9009\u62e9\u7b56\u7565\u548c\u5207\u6362\u51b3\u7b56\u3002\u901a\u8fc7\u8fd9\u4e00\u7cfb\u7edf\uff0c\u63a2\u8ba8\u73b0\u4ee3 LLMs \u5982\u4f55\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7406\u89e3\u3001\u9002\u5e94\u548c\u4f18\u5316\u51b3\u7b56\uff0c\u4f7f Pokemon League \u6210\u4e3a\u6218\u7565\u63a8\u7406\u548c\u7ade\u4e89\u6027\u5b66\u4e60\u9886\u57df\u4e2d\u7684\u65b0\u9896\u57fa\u51c6\u3002", "result": "\u7814\u7a76\u901a\u8fc7LLM Pokemon League\u7ade\u6280\u6bd4\u8d5b\u7cfb\u7edf\uff0c\u6210\u529f\u6355\u6349\u5230\u4e0d\u540c LLMs \u5728Pok\u00e9mon\u6218\u6597\u4e2d\u7684\u63a8\u7406\u3001\u9002\u5e94\u6027\u548c\u6218\u672f\u6df1\u5ea6\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u63a2\u8ba8\u6bd4\u8f83 AI \u884c\u4e3a\u3001\u6218\u6597\u5fc3\u7406\u5b66\u548c\u5143\u7b56\u7565\u53d1\u5c55\u3002\u8be5\u9879\u76ee\u4e3a\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u9896\u7684\u57fa\u51c6\u548c\u89c6\u89d2\u3002", "conclusion": "Pokemon League \u662f\u4e00\u4e2a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u667a\u80fd\u4ee3\u7406\u7684\u7ade\u6280\u6bd4\u8d5b\u7cfb\u7edf\uff0c\u65e8\u5728\u6a21\u62df Pok\u00e9mon \u6218\u6597\u4e2d\u7684\u6218\u7565\u51b3\u7b56\u3002\u901a\u8fc7\u5355\u6dd8\u6c70\u5236\u6bd4\u8d5b\uff0c\u6355\u6349\u4e0d\u540c LLMs \u8868\u73b0\u51fa\u7684\u63a8\u7406\u3001\u9002\u5e94\u6027\u548c\u6218\u672f\u6df1\u5ea6\u3002\u8fd9\u4e2a\u9879\u76ee\u4fc3\u8fdb\u4e86\u5bf9\u6bd4\u8f83 AI \u884c\u4e3a\u3001\u6218\u6597\u5fc3\u7406\u5b66\u548c\u5143\u7b56\u7565\u53d1\u5c55\u5728\u53d7\u9650\u3001\u57fa\u4e8e\u89c4\u5219\u6e38\u620f\u73af\u5883\u4e2d\u7684\u6df1\u5165\u63a2\u8ba8\u3002"}}
{"id": "2508.01670", "categories": ["cs.AI", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2508.01670", "abs": "https://arxiv.org/abs/2508.01670", "authors": ["Jiaqing Xie", "Weida Wang", "Ben Gao", "Zhuo Yang", "Haiyuan Wan", "Shufei Zhang", "Tianfan Fu", "Yuqiang Li"], "title": "QCBench: Evaluating Large Language Models on Domain-Specific Quantitative Chemistry", "comment": "13 pages, 8 figures", "summary": "Quantitative chemistry plays a fundamental role in chemistry research,\nenabling precise predictions of molecular properties, reaction outcomes, and\nmaterial behaviors. While large language models (LLMs) have shown promise in\nchemistry-related tasks, their ability to perform rigorous, step-by-step\nquantitative reasoning remains underexplored. To fill this blank, we propose\nQCBench, a Quantitative Chemistry benchmark comprising 350 computational\nchemistry problems across 7 chemistry subfields (analytical chemistry,\nbio/organic chemistry, general chemistry, inorganic chemistry, physical\nchemistry, polymer chemistry and quantum chemistry), categorized into three\nhierarchical tiers-basic, intermediate, and expert-to systematically evaluate\nthe mathematical reasoning abilities of large language models (LLMs). Designed\nto minimize shortcuts and emphasize stepwise numerical reasoning, each problem\nfocuses on pure calculations rooted in real-world chemical vertical fields.\nQCBench enables fine-grained diagnosis of computational weaknesses, reveals\nmodel-specific limitations across difficulty levels, and lays the groundwork\nfor future improvements such as domain adaptive fine-tuning or multi-modal\nintegration. Evaluations on 19 LLMs demonstrate a consistent performance\ndegradation with increasing task complexity, highlighting the current gap\nbetween language fluency and scientific computation accuracy.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86QCBench\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5316\u5b66\u9886\u57df\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u8bbe\u8ba1\u7eaf\u8ba1\u7b97\u6027\u8d28\u7684\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u51fa\u4e86\u65b9\u5411\uff0c\u5982\u9886\u57df\u81ea\u9002\u5e94\u5fae\u8c03\u6216\u591a\u6a21\u6001\u96c6\u6210\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u8ba1\u7b97\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5316\u5b66\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8fdb\u884c\u4e25\u8c28\u3001\u9010\u6b65\u91cf\u5316\u63a8\u7406\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7a76\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86QCBench\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5316\u5b66\u9886\u57df\u6570\u5b66\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86QCBench\u57fa\u51c6\uff0c\u5305\u62ec350\u4e2a\u8ba1\u7b97\u5316\u5b66\u95ee\u9898\uff0c\u5206\u4e3a\u57fa\u672c\u3001\u4e2d\u7ea7\u548c\u4e13\u5bb6\u4e09\u4e2a\u5c42\u6b21\uff0c\u91cd\u70b9\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002\u901a\u8fc7\u8bbe\u8ba1\u95ee\u9898\u7684\u7eaf\u8ba1\u7b97\u6027\u8d28\uff0c\u6839\u690d\u4e8e\u771f\u5b9e\u5316\u5b66\u5782\u76f4\u9886\u57df\uff0c\u907f\u514d\u6377\u5f84\u5e76\u5f3a\u8c03\u9010\u6b65\u6570\u503c\u63a8\u7406\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c19\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u4efb\u52a1\u590d\u6742\u6027\u589e\u52a0\u65f6\u51fa\u73b0\u4e00\u81f4\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u7a81\u663e\u4e86\u8bed\u8a00\u6d41\u7545\u5ea6\u548c\u79d1\u5b66\u8ba1\u7b97\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "QCBench\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u5316\u5b66\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5316\u5b66\u9886\u57df\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u65e8\u5728\u63ed\u793a\u6a21\u578b\u5728\u4e0d\u540c\u96be\u5ea6\u7ea7\u522b\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u6539\u8fdb\u5960\u5b9a\u57fa\u7840\uff0c\u5982\u9886\u57df\u81ea\u9002\u5e94\u5fae\u8c03\u6216\u591a\u6a21\u6001\u96c6\u6210\u3002"}}
{"id": "2508.01680", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01680", "abs": "https://arxiv.org/abs/2508.01680", "authors": ["Dong Li", "Yichen Niu", "Ying Ai", "Xiang Zou", "Biqing Qi", "Jianxing Liu"], "title": "T-GRAG: A Dynamic GraphRAG Framework for Resolving Temporal Conflicts and Redundancy in Knowledge Retrieval", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong performance in natural\nlanguage generation but remain limited in knowle-\n  dge-intensive tasks due to outdated or incomplete internal knowledge.\nRetrieval-Augmented Generation (RAG) addresses this by incorporating external\nretrieval, with GraphRAG further enhancing performance through structured\nknowledge graphs and multi-hop reasoning. However, existing GraphRAG methods\nlargely ignore the temporal dynamics of knowledge, leading to issues such as\ntemporal ambiguity, time-insensitive retrieval, and semantic redundancy. To\novercome these limitations, we propose Temporal GraphRAG (T-GRAG), a dynamic,\ntemporally-aware RAG framework that models the evolution of knowledge over\ntime. T-GRAG consists of five key components: (1) a Temporal Knowledge Graph\nGenerator that creates time-stamped, evolving graph structures; (2) a Temporal\nQuery Decomposition mechanism that breaks complex temporal queries into\nmanageable sub-queries; (3) a Three-layer Interactive Retriever that\nprogressively filters and refines retrieval across temporal subgraphs; (4) a\nSource Text Extractor to mitigate noise; and (5) a LLM-based Generator that\nsynthesizes contextually and temporally accurate responses. We also introduce\nTime-LongQA, a novel benchmark dataset based on real-world corporate annual\nreports, designed to test temporal reasoning across evolving knowledge.\nExtensive experiments show that T-GRAG significantly outperforms prior RAG and\nGraphRAG baselines in both retrieval accuracy and response relevance under\ntemporal constraints, highlighting the necessity of modeling knowledge\nevolution for robust long-text question answering. Our code is publicly\navailable on the T-GRAG", "AI": {"tldr": "Large language models (LLMs) excel in natural language generation but lack updated internal knowledge for knowledge-intensive tasks. Temporal GraphRAG (T-GRAG) introduces a temporally-aware framework to model the evolution of knowledge over time, outperforming existing methods in retrieval accuracy and response relevance under temporal constraints.", "motivation": "Address limitations of existing GraphRAG methods that overlook temporal dynamics of knowledge, leading to issues like temporal ambiguity, time-insensitive retrieval, and semantic redundancy. Aim to enhance performance in knowledge-intensive tasks by modeling the evolution of knowledge over time.", "method": "Proposed Temporal GraphRAG (T-GRAG), a temporally-aware Retrieval-Augmented Generation framework with five key components: Temporal Knowledge Graph Generator, Temporal Query Decomposition mechanism, Three-layer Interactive Retriever, Source Text Extractor, and LLM-based Generator. Introduced Time-LongQA benchmark dataset for testing temporal reasoning in evolving knowledge.", "result": "T-GRAG significantly outperforms prior RAG and GraphRAG baselines in retrieval accuracy and response relevance under temporal constraints. Conducted extensive experiments with the Time-LongQA benchmark dataset based on real-world corporate annual reports.", "conclusion": "Temporal GraphRAG (T-GRAG) outperforms existing RAG and GraphRAG methods in retrieval accuracy and response relevance under temporal constraints, emphasizing the importance of modeling knowledge evolution for long-text question answering."}}
{"id": "2508.01693", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.01693", "abs": "https://arxiv.org/abs/2508.01693", "authors": ["Yuhang Gu", "Xingyu Hu", "Yuyu Fan", "Xulin Yan", "Longhuan Xu", "Peng peng"], "title": "SURE-Med: Systematic Uncertainty Reduction for Enhanced Reliability in Medical Report Generation", "comment": null, "summary": "Automated medical report generation (MRG) holds great promise for reducing\nthe heavy workload of radiologists. However, its clinical deployment is\nhindered by three major sources of uncertainty. First, visual uncertainty,\ncaused by noisy or incorrect view annotations, compromises feature extraction.\nSecond, label distribution uncertainty, stemming from long-tailed disease\nprevalence, biases models against rare but clinically critical conditions.\nThird, contextual uncertainty, introduced by unverified historical reports,\noften leads to factual hallucinations. These challenges collectively limit the\nreliability and clinical trustworthiness of MRG systems. To address these\nissues, we propose SURE-Med, a unified framework that systematically reduces\nuncertainty across three critical dimensions: visual, distributional, and\ncontextual. To mitigate visual uncertainty, a Frontal-Aware View Repair\nResampling module corrects view annotation errors and adaptively selects\ninformative features from supplementary views. To tackle label distribution\nuncertainty, we introduce a Token Sensitive Learning objective that enhances\nthe modeling of critical diagnostic sentences while reweighting\nunderrepresented diagnostic terms, thereby improving sensitivity to infrequent\nconditions. To reduce contextual uncertainty, our Contextual Evidence Filter\nvalidates and selectively incorporates prior information that aligns with the\ncurrent image, effectively suppressing hallucinations. Extensive experiments on\nthe MIMIC-CXR and IU-Xray benchmarks demonstrate that SURE-Med achieves\nstate-of-the-art performance. By holistically reducing uncertainty across\nmultiple input modalities, SURE-Med sets a new benchmark for reliability in\nmedical report generation and offers a robust step toward trustworthy clinical\ndecision support.", "AI": {"tldr": "SURE-Med \u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u65e8\u5728\u51cf\u5c11\u533b\u5b66\u62a5\u544a\u751f\u6210\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u901a\u8fc7\u7ea0\u6b63\u89c6\u56fe\u6ce8\u91ca\u9519\u8bef\u3001\u91cd\u70b9\u5173\u6ce8\u5173\u952e\u8bca\u65ad\u53e5\u5b50\u548c\u9a8c\u8bc1\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0cSURE-Med \u5728\u5b9e\u9a8c\u8bc1\u660e\u5728 MIMIC-CXR \u548c IU-Xray \u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u53ef\u9760\u6027\u533b\u5b66\u62a5\u544a\u751f\u6210\u6811\u7acb\u4e86\u65b0\u7684\u6807\u6746\u3002", "motivation": "\u4f20\u7edf\u7684\u81ea\u52a8\u751f\u6210\u533b\u5b66\u62a5\u544a\u65b9\u6cd5\u9762\u4e34\u7740\u89c6\u89c9\u3001\u6807\u7b7e\u5206\u5e03\u548c\u4e0a\u4e0b\u6587\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u4e34\u5e8a\u53ef\u4fe1\u5ea6\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86 SURE-Med \u6846\u67b6\uff0c\u4ee5\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u63d0\u9ad8\u533b\u5b66\u62a5\u544a\u751f\u6210\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86 SURE-Med \u6846\u67b6\uff0c\u901a\u8fc7 Frontal-Aware View Repair Resampling \u6a21\u5757\u3001Token Sensitive Learning \u76ee\u6807\u548c Contextual Evidence Filter \u6765\u964d\u4f4e\u4e0d\u786e\u5b9a\u6027\u3002\u524d\u8005\u7528\u4e8e\u7ea0\u6b63\u89c6\u56fe\u6ce8\u91ca\u9519\u8bef\u5e76\u81ea\u9002\u5e94\u9009\u62e9\u4fe1\u606f\u7279\u6027\uff0c\u4ee5\u51cf\u5c11\u89c6\u89c9\u4e0d\u786e\u5b9a\u6027\uff1b\u5176\u6b21\u662f\u5f15\u5165\u4e86 Token Sensitive Learning \u76ee\u6807\uff0c\u589e\u5f3a\u5bf9\u5173\u952e\u8bca\u65ad\u53e5\u5b50\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u901a\u8fc7\u91cd\u65b0\u52a0\u6743\u4e0d\u5e38\u89c1\u7684\u8bca\u65ad\u672f\u8bed\uff0c\u4ece\u800c\u63d0\u9ad8\u5bf9\u7f55\u89c1\u75c5\u75c7\u7684\u654f\u611f\u6027\uff1b\u6700\u540e\u662f\u4f7f\u7528 Contextual Evidence Filter \u9a8c\u8bc1\u548c\u6709\u9009\u62e9\u6027\u5730\u7ed3\u5408\u4e0e\u5f53\u524d\u56fe\u50cf\u76f8\u7b26\u7684\u5148\u524d\u4fe1\u606f\uff0c\u6709\u6548\u6291\u5236\u5e7b\u89c9\uff0c\u4ee5\u964d\u4f4e\u4e0a\u4e0b\u6587\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u8be5\u8bba\u6587\u5728 MIMIC-CXR \u548c IU-Xray \u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cSURE-Med \u65b9\u6cd5\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e3a\u533b\u5b66\u62a5\u544a\u751f\u6210\u9886\u57df\u6811\u7acb\u4e86\u65b0\u7684\u53ef\u9760\u6027\u57fa\u51c6\u3002", "conclusion": "SURE-Med \u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u540d\u4e3a SURE-Med\uff0c\u7cfb\u7edf\u6027\u5730\u51cf\u5c11\u4e86\u533b\u5b66\u62a5\u544a\u751f\u6210\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u901a\u8fc7\u89e3\u51b3\u89c6\u89c9\u3001\u6807\u7b7e\u5206\u5e03\u548c\u4e0a\u4e0b\u6587\u7b49\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\uff0cSURE-Med \u5728 MIMIC-CXR \u548c IU-Xray \u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e3a\u533b\u5b66\u62a5\u544a\u751f\u6210\u6811\u7acb\u4e86\u5168\u65b0\u7684\u53ef\u9760\u6027\u57fa\u51c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u4fe1\u8d56\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2508.01700", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01700", "abs": "https://arxiv.org/abs/2508.01700", "authors": ["Zhihao Shuai", "Boyan Li", "Siyu Yan", "Yuyu Luo", "Weikai Yang"], "title": "DeepVIS: Bridging Natural Language and Data Visualization Through Step-wise Reasoning", "comment": null, "summary": "Although data visualization is powerful for revealing patterns and\ncommunicating insights, creating effective visualizations requires familiarity\nwith authoring tools and often disrupts the analysis flow. While large language\nmodels show promise for automatically converting analysis intent into\nvisualizations, existing methods function as black boxes without transparent\nreasoning processes, which prevents users from understanding design rationales\nand refining suboptimal outputs. To bridge this gap, we propose integrating\nChain-of-Thought (CoT) reasoning into the Natural Language to Visualization\n(NL2VIS) pipeline. First, we design a comprehensive CoT reasoning process for\nNL2VIS and develop an automatic pipeline to equip existing datasets with\nstructured reasoning steps. Second, we introduce nvBench-CoT, a specialized\ndataset capturing detailed step-by-step reasoning from ambiguous natural\nlanguage descriptions to finalized visualizations, which enables\nstate-of-the-art performance when used for model fine-tuning. Third, we develop\nDeepVIS, an interactive visual interface that tightly integrates with the CoT\nreasoning process, allowing users to inspect reasoning steps, identify errors,\nand make targeted adjustments to improve visualization outcomes. Quantitative\nbenchmark evaluations, two use cases, and a user study collectively demonstrate\nthat our CoT framework effectively enhances NL2VIS quality while providing\ninsightful reasoning steps to users.", "AI": {"tldr": "\u6570\u636e\u53ef\u89c6\u5316\u662f\u5f3a\u5927\u7684\uff0c\u4f46\u9700\u719f\u6089\u5de5\u5177\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u81ea\u52a8\u8f6c\u6362\u5206\u6790\u4e3a\u53ef\u89c6\u5316\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u63a8\u7406\u8fc7\u7a0b\u3002\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u601d\u7ef4\u94fe\u63a8\u7406\u96c6\u6210\u5230\u81ea\u7136\u8bed\u8a00\u8f6c\u53ef\u89c6\u5316\u6d41\u7a0b\uff0c\u901a\u8fc7\u5b9a\u91cf\u8bc4\u4f30\u3001\u7528\u4f8b\u548c\u7528\u6237\u7814\u7a76\u5c55\u793a\u4e86CoT\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u6570\u636e\u53ef\u89c6\u5316\u5f3a\u5927\uff0c\u4f46\u9700\u8981\u719f\u6089\u5de5\u5177\u5e76\u6253\u65ad\u5206\u6790\u6d41\u7a0b\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u671b\u81ea\u52a8\u8f6c\u6362\u5206\u6790\u610f\u56fe\u4e3a\u53ef\u89c6\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u65e0\u6cd5\u8ba9\u7528\u6237\u7406\u89e3\u8bbe\u8ba1\u539f\u7406\u548c\u4f18\u5316\u8f93\u51fa\u3002\u63d0\u51faCoT\u63a8\u7406\u4ee5\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u8bba\u6587\u9996\u5148\u8bbe\u8ba1\u4e86\u5168\u9762\u7684CoT\u63a8\u7406\u8fc7\u7a0b\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u5176\u6b21\u4ecb\u7ecd\u4e86nvBench-CoT\u4e13\u95e8\u6355\u83b7\u8be6\u7ec6\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u5230\u6700\u7ec8\u53ef\u89c6\u5316\u7684\u63a8\u7406\u8fc7\u7a0b\u7684\u6570\u636e\u96c6\uff0c\u7136\u540e\u5f00\u53d1\u4e86DeepVIS\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u63a5\u53e3\uff0c\u7d27\u5bc6\u96c6\u6210\u4e86CoT\u63a8\u7406\u8fc7\u7a0b\uff0c\u8ba9\u7528\u6237\u68c0\u67e5\u63a8\u7406\u6b65\u9aa4\u3001\u8bc6\u522b\u9519\u8bef\u5e76\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u8c03\u6574\u4ee5\u6539\u5584\u53ef\u89c6\u5316\u7ed3\u679c\u3002", "result": "\u901a\u8fc7\u5b9a\u91cf\u57fa\u51c6\u8bc4\u4f30\u3001\u4e24\u4e2a\u7528\u4f8b\u548c\u7528\u6237\u7814\u7a76\uff0c\u8bba\u6587\u5c55\u793a\u4e86CoT\u6846\u67b6\u6709\u6548\u63d0\u5347NL2VIS\u8d28\u91cf\u5e76\u5411\u7528\u6237\u63d0\u4f9b\u6709\u6d1e\u5bdf\u529b\u7684\u63a8\u7406\u6b65\u9aa4\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5c06\u601d\u7ef4\u94fe\uff08Chain-of-Thought\uff0cCoT\uff09\u63a8\u7406\u96c6\u6210\u5230\u81ea\u7136\u8bed\u8a00\u8f6c\u53ef\u89c6\u5316\uff08Natural Language to Visualization\uff0cNL2VIS\uff09\u6d41\u7a0b\u4e2d\uff0c\u8bbe\u8ba1\u4e86\u5168\u9762\u7684\u63a8\u7406\u8fc7\u7a0b\u4ee5\u53ca\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u5f00\u53d1\u4e86nvBench-CoT\u6570\u636e\u96c6\u548cDeepVIS\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u63a5\u53e3\uff0c\u901a\u8fc7\u5b9a\u91cf\u57fa\u51c6\u8bc4\u4f30\u3001\u4e24\u4e2a\u7528\u4f8b\u548c\u7528\u6237\u7814\u7a76\u8868\u660eCoT\u6846\u67b6\u6709\u6548\u63d0\u5347NL2VIS\u8d28\u91cf\u5e76\u4e3a\u7528\u6237\u63d0\u4f9b\u6709\u6d1e\u5bdf\u529b\u7684\u63a8\u7406\u6b65\u9aa4\u3002"}}
{"id": "2508.01724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01724", "abs": "https://arxiv.org/abs/2508.01724", "authors": ["Shijie Cao", "Yuan Yuan"], "title": "ReflecSched: Solving Dynamic Flexible Job-Shop Scheduling via LLM-Powered Hierarchical Reflection", "comment": null, "summary": "Dynamic Flexible Job-Shop Scheduling (DFJSP) is an NP-hard problem challenged\nby real-time event adaptation and complex machine routing. While traditional\ndispatching rules are efficient but rigid, deep learning approaches are opaque\nand require intricate feature engineering. Large Language Models (LLMs) promise\nadaptive reasoning without this engineering overhead, yet we find their direct\napplication is suboptimal. Baseline LLMs suffer from three key pitfalls: the\nlong-context paradox, where crucial data is underutilized; an underutilization\nof expert heuristics; and myopic decision-making. To address this, we propose\nReflecSched, a framework that empowers the LLM beyond a direct scheduler by\nequipping it with a strategic analysis capability. ReflecSched tasks the LLM to\nanalyze heuristic-driven simulations across multiple planning horizons and\ndistill them into a concise, natural-language summary termed ``Strategic\nExperience''. This summary is then integrated into the prompt of a final\ndecision-making module, guiding it to produce non-myopic actions. Experiments\nshow that ReflecSched not only statistically significantly outperforms direct\nLLM baselines, securing a 71.35\\% Win Rate and a 2.755\\% Relative Percentage\nDeviation reduction, but also surpasses the performance of all individual\nheuristics evaluated, all while demonstrably mitigating the three identified\npitfalls. Additionally, ReflecSched performs on par with the best heuristic\ntailored to each instance across all problem cases.", "AI": {"tldr": "\u63d0\u51fa\u4e86ReflecSched\u6846\u67b6\u6765\u89e3\u51b3\u52a8\u6001\u7075\u6d3b\u7684\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u8d4b\u4e88LLMs\u6218\u7565\u5206\u6790\u80fd\u529b\uff0c\u4f18\u4e8e\u4f20\u7edfLLMs\u548c\u4e2a\u4f53\u542f\u53d1\u5f0f\uff0c\u51cf\u8f7b\u4e86\u73b0\u6709LLMs\u7684\u5c40\u9650\u6027\u3002", "motivation": "DFJSP\u662f\u4e00\u4e2a\u53d7\u5230\u5b9e\u65f6\u4e8b\u4ef6\u9002\u5e94\u548c\u590d\u6742\u673a\u5668\u8def\u7531\u6311\u6218\u7684NP\u56f0\u96be\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u8c03\u5ea6\u89c4\u5219\u9ad8\u6548\u4f46\u521a\u6027\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u590d\u6742\u7684\u7279\u5f81\u5de5\u7a0b\uff0cLLMs\u627f\u8bfa\u81ea\u9002\u5e94\u63a8\u7406\u800c\u65e0\u9700\u8fd9\u79cd\u5de5\u7a0b\u5f00\u9500\uff0c\u4f46\u53d1\u73b0\u76f4\u63a5\u5e94\u7528LLMs\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86ReflecSched\u6846\u67b6\uff0c\u4f7fLLMs\u80fd\u591f\u901a\u8fc7\u6218\u7565\u5206\u6790\u542f\u53d1\u5f0f\u9a71\u52a8\u7684\u6a21\u62df\uff0c\u5e76\u5c06\u5176\u878d\u5408\u4e3a\u81ea\u7136\u8bed\u8a00\u603b\u7ed3\uff0c\u6307\u5bfc\u6700\u7ec8\u7684\u51b3\u7b56\u6a21\u5757\u4ea7\u751f\u975e\u6211\u5229\u76ca\u7684\u884c\u52a8\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cReflecSched\u5728\u6027\u80fd\u4e0a\u660e\u663e\u4f18\u4e8e\u76f4\u63a5LLM\u57fa\u7ebf\uff0c\u53d6\u5f97\u4e8671.35%\u7684\u80dc\u7387\u548c2.755%\u7684\u76f8\u5bf9\u767e\u5206\u6bd4\u504f\u5dee\u964d\u4f4e\uff0c\u540c\u65f6\u8d85\u8fc7\u4e86\u6240\u6709\u8bc4\u4f30\u7684\u4e2a\u4f53\u542f\u53d1\u5f0f\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u660e\u663e\u51cf\u8f7b\u4e86\u6240\u8bc6\u522b\u7684\u4e09\u4e2a\u7f3a\u70b9\u3002\u6b64\u5916\uff0cReflecSched\u5728\u6240\u6709\u95ee\u9898\u6848\u4f8b\u4e2d\u4e0e\u6700\u4f73\u542f\u53d1\u5f0f\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReflecSched\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8d4b\u4e88LLMs\u6218\u7565\u5206\u6790\u80fd\u529b\u6765\u89e3\u51b3\u4f20\u7edfLLMs\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u66f4\u52a0\u975e\u6211\u5229\u76ca\u7684\u884c\u52a8\u3002\u5728\u5b9e\u9a8c\u4e2d\uff0cReflecSched\u5728\u6027\u80fd\u4e0a\u660e\u663e\u4f18\u4e8e\u76f4\u63a5LLM\u57fa\u7ebf\uff0c\u53d6\u5f97\u4e8671.35%\u7684\u80dc\u7387\u548c2.755%\u7684\u76f8\u5bf9\u767e\u5206\u6bd4\u504f\u5dee\u964d\u4f4e\uff0c\u540c\u65f6\u8d85\u8fc7\u4e86\u6240\u6709\u8bc4\u4f30\u7684\u4e2a\u4f53\u542f\u53d1\u5f0f\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u660e\u663e\u51cf\u8f7b\u4e86\u6240\u8bc6\u522b\u7684\u4e09\u4e2a\u7f3a\u70b9\u3002\u6b64\u5916\uff0cReflecSched\u5728\u6240\u6709\u95ee\u9898\u6848\u4f8b\u4e2d\u4e0e\u6700\u4f73\u542f\u53d1\u5f0f\u6027\u80fd\u76f8\u5f53\u3002"}}
{"id": "2508.01746", "categories": ["cs.AI", "I.2.4"], "pdf": "https://arxiv.org/pdf/2508.01746", "abs": "https://arxiv.org/abs/2508.01746", "authors": ["Shiyang Duan", "Yuan Tian", "Qi Bing", "Xiaowei Shao"], "title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization", "comment": "Corresponding author: Xiaowei Shao. 12 pages, 4 figures", "summary": "The exponential growth of scientific knowledge has made the automated\ngeneration of scientific hypotheses that combine novelty, feasibility, and\nresearch value a core challenge. Existing methods based on large language\nmodels fail to systematically model the inherent in hypotheses or incorporate\nthe closed-loop feedback mechanisms crucial for refinement. This paper proposes\na multi-agent collaborative framework called HypoAgents, which for the first\ntime integrates Bayesian reasoning with an information entropy-driven search\nmechanism across three stages-hypotheses generation, evidence validation, and\nhypotheses Refinement-to construct an iterative closed-loop simulating\nscientists' cognitive processes. Specifically, the framework first generates an\ninitial set of hypotheses through diversity sampling and establishes prior\nbeliefs based on a composite novelty-relevance-feasibility (N-R-F) score. It\nthen employs etrieval-augmented generation (RAG) to gather external literature\nevidence, updating the posterior probabilities of hypotheses using Bayes'\ntheorem. Finally, it identifies high-uncertainty hypotheses using information\nentropy $H = - \\sum {{p_i}\\log {p_i}}$ and actively refines them, guiding the\niterative optimization of the hypothesis set toward higher quality and\nconfidence. Experimental results on the ICLR 2025 conference real-world\nresearch question dataset (100 research questions) show that after 12\noptimization iterations, the average ELO score of generated hypotheses improves\nby 116.3, surpassing the benchmark of real paper abstracts by 17.8, while the\nframework's overall uncertainty, as measured by Shannon entropy, decreases\nsignificantly by 0.92. This study presents an interpretable probabilistic\nreasoning framework for automated scientific discovery, substantially improving\nthe quality and reliability of machine-generated research hypotheses.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86HypoAgents\u6846\u67b6\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u7406\u548c\u4fe1\u606f\u71b5\u9a71\u52a8\u7684\u641c\u7d22\u673a\u5236\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u79d1\u5b66\u5047\u8bbe\u5e76\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u751f\u6210\u5047\u8bbe\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u81ea\u52a8\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6982\u7387\u63a8\u7406\u6846\u67b6\u3002", "motivation": "\u79d1\u5b66\u77e5\u8bc6\u7684\u6307\u6570\u589e\u957f\u4f7f\u5f97\u7ed3\u5408\u65b0\u9896\u6027\u3001\u53ef\u884c\u6027\u548c\u7814\u7a76\u4ef7\u503c\u7684\u79d1\u5b66\u5047\u8bbe\u7684\u81ea\u52a8\u5316\u751f\u6210\u6210\u4e3a\u6838\u5fc3\u6311\u6218\u3002\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u672a\u80fd\u7cfb\u7edf\u5730\u5efa\u6a21\u5047\u8bbe\u7684\u56fa\u6709\u7279\u6027\u6216\u878d\u5165\u5bf9\u4e8e\u7cbe\u70bc\u81f3\u5173\u91cd\u8981\u7684\u95ed\u73af\u53cd\u9988\u673a\u5236\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u80fd\u591f\u6a21\u62df\u79d1\u5b66\u5bb6\u8ba4\u77e5\u8fc7\u7a0b\u7684\u8fed\u4ee3\u95ed\u73af\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6HypoAgents\uff0c\u5728\u5047\u8bbe\u751f\u6210\u3001\u8bc1\u636e\u9a8c\u8bc1\u548c\u5047\u8bbe\u4f18\u5316\u4e09\u4e2a\u9636\u6bb5\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u7406\u548c\u4fe1\u606f\u71b5\u9a71\u52a8\u7684\u641c\u7d22\u673a\u5236\u3002\u6846\u67b6\u9996\u5148\u901a\u8fc7\u591a\u6837\u6027\u91c7\u6837\u751f\u6210\u521d\u59cb\u5047\u8bbe\uff0c\u5e76\u6839\u636e\u65b0\u9896\u6027-\u76f8\u5173\u6027-\u53ef\u884c\u6027\uff08N-R-F\uff09\u5f97\u5206\u5efa\u7acb\u5148\u9a8c\u4fe1\u5ff5\u3002\u7136\u540e\u5229\u7528RAG\u6280\u672f\u6536\u96c6\u5916\u90e8\u6587\u732e\u8bc1\u636e\uff0c\u5229\u7528\u8d1d\u53f6\u65af\u5b9a\u7406\u66f4\u65b0\u5047\u8bbe\u7684\u540e\u9a8c\u6982\u7387\u3002\u6700\u540e\uff0c\u901a\u8fc7\u4fe1\u606f\u71b5\u8bc6\u522b\u9ad8\u4e0d\u786e\u5b9a\u6027\u5047\u8bbe\u5e76\u8fdb\u884c\u79ef\u6781\u4f18\u5316\uff0c\u5f15\u5bfc\u5047\u8bbe\u96c6\u5411\u66f4\u9ad8\u8d28\u91cf\u548c\u4fe1\u5fc3\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728ICLR 2025\u4f1a\u8bae\u7684\u771f\u5b9e\u7814\u7a76\u95ee\u9898\u6570\u636e\u96c6\u4e0a\uff0c\u7ecf\u8fc712\u6b21\u4f18\u5316\u8fed\u4ee3\u540e\uff0c\u751f\u6210\u7684\u5047\u8bbe\u7684\u5e73\u5747ELO\u5206\u6570\u63d0\u9ad8\u4e86116.3\uff0c\u8d85\u8fc7\u771f\u5b9e\u8bba\u6587\u6458\u8981\u7684\u57fa\u51c617.8\u4e2a\u5355\u4f4d\uff0c\u540c\u65f6\u6846\u67b6\u7684\u6574\u4f53\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5Shannon\u71b5\u8861\u91cf\uff0c\u51cf\u5c11\u4e860.92\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHypoAgents\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u7406\u548c\u4fe1\u606f\u71b5\u9a71\u52a8\u7684\u641c\u7d22\u673a\u5236\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u79d1\u5b66\u5047\u8bbe\u5e76\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u751f\u6210\u5047\u8bbe\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u81ea\u52a8\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6982\u7387\u63a8\u7406\u6846\u67b6\u3002"}}
{"id": "2508.01751", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01751", "abs": "https://arxiv.org/abs/2508.01751", "authors": ["Pierre Schaus", "Charles Thomas", "Roger Kameugne"], "title": "Implementing Cumulative Functions with Generalized Cumulative Constraints", "comment": null, "summary": "Modeling scheduling problems with conditional time intervals and cumulative\nfunctions has become a common approach when using modern commercial constraint\nprogramming solvers. This paradigm enables the modeling of a wide range of\nscheduling problems, including those involving producers and consumers.\nHowever, it is unavailable in existing open-source solvers and practical\nimplementation details remain undocumented. In this work, we present an\nimplementation of this modeling approach using a single, generic global\nconstraint called the Generalized Cumulative. We also introduce a novel\ntime-table filtering algorithm designed to handle tasks defined on conditional\ntime-intervals. Experimental results demonstrate that this approach, combined\nwith the new filtering algorithm, performs competitively with existing solvers\nenabling the modeling of producer and consumer scheduling problems and\neffectively scales to large problems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4f7f\u7528\u6cdb\u51fd\u5168\u5c40\u7ea6\u675f\u548c\u65f6\u95f4\u8868\u8fc7\u6ee4\u7b97\u6cd5\u6765\u89e3\u51b3\u6d89\u53ca\u751f\u4ea7\u8005\u548c\u6d88\u8d39\u8005\u7684\u8c03\u5ea6\u95ee\u9898\u7684\u5efa\u6a21\u65b9\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u53ef\u5e94\u7528\u4e8e\u5927\u578b\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u5546\u4e1a\u7ea6\u675f\u6c42\u89e3\u5668\u4e2d\uff0c\u4f7f\u7528\u5177\u6709\u6761\u4ef6\u65f6\u95f4\u95f4\u9694\u548c\u7d2f\u79ef\u51fd\u6570\u7684\u6a21\u578b\u5df2\u6210\u4e3a\u5efa\u6a21\u8c03\u5ea6\u95ee\u9898\u7684\u5e38\u89c1\u65b9\u6cd5\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u73b0\u6709\u5f00\u6e90\u6c42\u89e3\u5668\u4e2d\u5c1a\u4e0d\u53ef\u7528\uff0c\u5b9e\u9645\u5b9e\u73b0\u7ec6\u8282\u4e5f\u672a\u7ecf\u8bb0\u5f55\u3002", "method": "\u4f7f\u7528\u79f0\u4e3a\u201cGeneralized Cumulative\u201d\u7684\u6cdb\u51fd\u5168\u5c40\u7ea6\u675f\u5b9e\u73b0\u4e86\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u7528\u4e8e\u5904\u7406\u6761\u4ef6\u65f6\u95f4\u95f4\u9694\u4e0a\u7684\u4efb\u52a1\u7684\u65b0\u578b\u65f6\u95f4\u8868\u8fc7\u6ee4\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u65b0\u7684\u8fc7\u6ee4\u7b97\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0e\u73b0\u6709\u6c42\u89e3\u5668\u7ade\u4e89\u529b\u5f3a\uff0c\u80fd\u591f\u6709\u6548\u5730\u6269\u5c55\u5230\u5927\u578b\u95ee\u9898\u3002", "conclusion": "\u5b9e\u73b0\u4e86\u4e00\u79cd\u4f7f\u7528\u5355\u4e00\u6cdb\u51fd\u5168\u5c40\u7ea6\u675f\u7684\u5efa\u6a21\u65b9\u6cd5\u4ee5\u89e3\u51b3\u6d89\u53ca\u751f\u4ea7\u8005\u548c\u6d88\u8d39\u8005\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u6c42\u89e3\u5668\u7ade\u4e89\u529b\uff0c\u5e76\u80fd\u6709\u6548\u6269\u5c55\u5230\u5927\u578b\u95ee\u9898\u3002"}}
{"id": "2508.01763", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.01763", "abs": "https://arxiv.org/abs/2508.01763", "authors": ["Saleh Nikooroo", "Thomas Engel"], "title": "Reasoning Systems as Structured Processes: Foundations, Failures, and Formal Criteria", "comment": null, "summary": "This paper outlines a general formal framework for reasoning systems,\nintended to support future analysis of inference architectures across domains.\nWe model reasoning systems as structured tuples comprising phenomena,\nexplanation space, inference and generation maps, and a principle base. The\nformulation accommodates logical, algorithmic, and learning-based reasoning\nprocesses within a unified structural schema, while remaining agnostic to any\nspecific reasoning algorithm or logic system. We survey basic internal\ncriteria--including coherence, soundness, and completeness-and catalog typical\nfailure modes such as contradiction, incompleteness, and non-convergence. The\nframework also admits dynamic behaviors like iterative refinement and principle\nevolution. The goal of this work is to establish a foundational structure for\nrepresenting and comparing reasoning systems, particularly in contexts where\ninternal failure, adaptation, or fragmentation may arise. No specific solution\narchitecture is proposed; instead, we aim to support future theoretical and\npractical investigations into reasoning under structural constraint.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e00\u822c\u7684\u5f62\u5f0f\u6846\u67b6\u7528\u4e8e\u5efa\u6a21\u63a8\u7406\u7cfb\u7edf\uff0c\u652f\u6301\u8de8\u9886\u57df\u63a8\u7406\u67b6\u6784\u5206\u6790\u3002\u6846\u67b6\u5c06\u63a8\u7406\u7cfb\u7edf\u5efa\u6a21\u4e3a\u7ed3\u6784\u5316\u5143\u7ec4\uff0c\u5bb9\u7eb3\u903b\u8f91\u3001\u7b97\u6cd5\u548c\u5b66\u4e60-based\u63a8\u7406\u8fc7\u7a0b\u3002\u65e8\u5728\u652f\u6301\u672a\u6765\u7406\u8bba\u548c\u5b9e\u8df5\u7814\u7a76\u63a8\u7406\u7cfb\u7edf\u5728\u7ed3\u6784\u7ea6\u675f\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u652f\u6301\u672a\u6765\u8de8\u9886\u57df\u63a8\u7406\u67b6\u6784\u5206\u6790\uff0c\u5efa\u7acb\u4e00\u4e2a\u7528\u4e8e\u8868\u793a\u548c\u6bd4\u8f83\u63a8\u7406\u7cfb\u7edf\u7684\u57fa\u7840\u7ed3\u6784\u3002\u7279\u522b\u5173\u6ce8\u53ef\u80fd\u51fa\u73b0\u5185\u90e8\u6545\u969c\u3001\u9002\u5e94\u6216\u5206\u88c2\u7684\u60c5\u5883\u3002\u65e8\u5728\u652f\u6301\u5bf9\u7ed3\u6784\u7ea6\u675f\u4e0b\u7684\u63a8\u7406\u8fdb\u884c\u672a\u6765\u7684\u7406\u8bba\u548c\u5b9e\u9645\u8c03\u67e5\u3002", "method": "\u5c06\u63a8\u7406\u7cfb\u7edf\u5efa\u6a21\u4e3a\u7ed3\u6784\u5316\u5143\u7ec4\uff0c\u5305\u62ec\u73b0\u8c61\u3001\u89e3\u91ca\u7a7a\u95f4\u3001\u63a8\u7406\u548c\u751f\u6210\u6620\u5c04\uff0c\u4ee5\u53ca\u539f\u5219\u57fa\u7840\u3002\u6846\u67b6\u5bb9\u7eb3\u903b\u8f91\u3001\u7b97\u6cd5\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u7edf\u4e00\u7ed3\u6784\u6a21\u5f0f\u800c\u4e0d\u504f\u5411\u4e8e\u4efb\u4f55\u5177\u4f53\u7684\u63a8\u7406\u7b97\u6cd5\u6216\u903b\u8f91\u7cfb\u7edf\u3002\u8c03\u67e5\u4e86\u63a8\u7406\u7cfb\u7edf\u7684\u57fa\u672c\u5185\u90e8\u6807\u51c6\uff0c\u4ee5\u53ca\u5178\u578b\u7684\u5931\u8d25\u6a21\u5f0f\u548c\u52a8\u6001\u884c\u4e3a\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e00\u822c\u7684\u5f62\u5f0f\u6846\u67b6\u7528\u4e8e\u63a8\u7406\u7cfb\u7edf\u7684\u5efa\u6a21\uff0c\u652f\u6301\u5bf9\u63a8\u7406\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\u548c\u5206\u6790\u3002\u63d0\u51fa\u4e86\u7528\u4e8e\u63cf\u8ff0\u63a8\u7406\u7cfb\u7edf\u57fa\u672c\u6807\u51c6\u3001\u5931\u8d25\u6a21\u5f0f\u548c\u52a8\u6001\u884c\u4e3a\u7684\u7ed3\u6784\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e00\u822c\u7684\u5f62\u5f0f\u6846\u67b6\u7528\u4e8e\u63a8\u7406\u7cfb\u7edf\u7684\u5efa\u6a21\uff0c\u652f\u6301\u672a\u6765\u8de8\u9886\u57df\u63a8\u7406\u67b6\u6784\u5206\u6790\u3002\u8bba\u6587\u5c06\u63a8\u7406\u7cfb\u7edf\u5efa\u6a21\u4e3a\u7ed3\u6784\u5316\u5143\u7ec4\uff0c\u5305\u62ec\u73b0\u8c61\u3001\u89e3\u91ca\u7a7a\u95f4\u3001\u63a8\u7406\u548c\u751f\u6210\u6620\u5c04\uff0c\u4ee5\u53ca\u539f\u5219\u57fa\u7840\u3002\u8be5\u6846\u67b6\u5bb9\u7eb3\u903b\u8f91\u3001\u7b97\u6cd5\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u7edf\u4e00\u7ed3\u6784\u6a21\u5f0f\u800c\u4e0d\u504f\u5411\u4e8e\u4efb\u4f55\u5177\u4f53\u7684\u63a8\u7406\u7b97\u6cd5\u6216\u903b\u8f91\u7cfb\u7edf\u3002\u8bba\u6587\u8c03\u67e5\u4e86\u57fa\u672c\u7684\u5185\u90e8\u6807\u51c6\uff0c\u5305\u62ec\u4e00\u81f4\u6027\u3001\u6b63\u786e\u6027\u548c\u5b8c\u5907\u6027\uff0c\u5e76\u5217\u4e3e\u4e86\u5178\u578b\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5982\u77db\u76fe\u3001\u4e0d\u5b8c\u5907\u6027\u548c\u4e0d\u6536\u655b\u6027\u3002\u6846\u67b6\u8fd8\u5141\u8bb8\u52a8\u6001\u884c\u4e3a\uff0c\u5982\u8fed\u4ee3\u6539\u8fdb\u548c\u539f\u5219\u6f14\u5316\u3002\u8be5\u5de5\u4f5c\u7684\u76ee\u6807\u662f\u5efa\u7acb\u4e00\u4e2a\u7528\u4e8e\u8868\u793a\u548c\u6bd4\u8f83\u63a8\u7406\u7cfb\u7edf\u7684\u57fa\u7840\u7ed3\u6784\uff0c\u7279\u522b\u662f\u5728\u53ef\u80fd\u51fa\u73b0\u5185\u90e8\u6545\u969c\u3001\u9002\u5e94\u6216\u5206\u88c2\u7684\u60c5\u5883\u4e2d\u3002\u8bba\u6587\u6ca1\u6709\u63d0\u51fa\u5177\u4f53\u7684\u89e3\u51b3\u65b9\u6848\u67b6\u6784\uff1b\u76f8\u53cd\uff0c\u6211\u4eec\u65e8\u5728\u652f\u6301\u5bf9\u7ed3\u6784\u7ea6\u675f\u4e0b\u7684\u63a8\u7406\u8fdb\u884c\u672a\u6765\u7684\u7406\u8bba\u548c\u5b9e\u9645\u8c03\u67e5\u3002"}}
{"id": "2508.01773", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01773", "abs": "https://arxiv.org/abs/2508.01773", "authors": ["Jiuzhou Han", "Wray Buntine", "Ehsan Shareghi"], "title": "Uncertainty-Based Methods for Automated Process Reward Data Construction and Output Aggregation in Mathematical Reasoning", "comment": null, "summary": "Large language models have demonstrated remarkable capabilities in complex\nmathematical reasoning tasks, but they inevitably generate errors throughout\nmulti-step solutions. Process-level Reward Models (PRMs) have shown great\npromise by providing supervision and evaluation at each intermediate step,\nthereby effectively improving the models' reasoning abilities. However,\ntraining effective PRMs requires high-quality process reward data, yet existing\nmethods for constructing such data are often labour-intensive or inefficient.\nIn this paper, we propose an uncertainty-driven framework for automated process\nreward data construction, encompassing both data generation and annotation\nprocesses for PRMs. Additionally, we identify the limitations of both majority\nvote and PRMs, and introduce two generic uncertainty-aware output aggregation\nmethods: Hybrid Majority Reward Vote and Weighted Reward Frequency Vote, which\ncombine the strengths of majority vote with PRMs. Extensive experiments on\nProcessBench, MATH, and GSMPlus show the effectiveness and efficiency of the\nproposed PRM data construction framework, and demonstrate that the two output\naggregation methods further improve the mathematical reasoning abilities across\ndiverse PRMs. The code and data will be publicly available at\nhttps://github.com/Jiuzhouh/UnPRM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u6784\u5efa\u6846\u67b6\uff0c\u89e3\u51b3\u4e86PRMs\u8bad\u7ec3\u4e2d\u9700\u8981\u9ad8\u8d28\u91cf\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u4e24\u79cd\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u8f93\u51fa\u805a\u5408\u65b9\u6cd5\uff0c\u6709\u6548\u6539\u5584\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6784\u5efa\u9ad8\u8d28\u91cf\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u7684\u65b9\u6cd5\u5f80\u5f80\u8d39\u65f6\u8d39\u529b\u6216\u6548\u7387\u4f4e\u4e0b\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3PRMs\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9700\u8981\u9ad8\u8d28\u91cf\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u6784\u5efa\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u6784\u5efa\u6846\u67b6\uff0c\u5305\u62ec\u6570\u636e\u751f\u6210\u548cPRMs\u7684\u6ce8\u91ca\u8fc7\u7a0b\u3002\u5f15\u5165\u4e86Hybrid Majority Reward Vote\u548cWeighted Reward Frequency Vote\u4e24\u79cd\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u8f93\u51fa\u805a\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u591a\u6570\u6295\u7968\u548cPRMs\u7684\u4f18\u52bf\u3002\u5728ProcessBench\u3001MATH\u548cGSMPlus\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u6784\u5efa\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u5e76\u4e14\u4e24\u79cd\u8f93\u51fa\u805a\u5408\u65b9\u6cd5\u8fdb\u4e00\u6b65\u6539\u5584\u4e86\u591a\u6837\u5316PRMs\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u8fc7\u7a0b\u5956\u52b1\u6570\u636e\u6784\u5efa\u6846\u67b6\uff0c\u6709\u6548\u63d0\u9ad8\u4e86PRMs\u7684\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u5f15\u5165Hybrid Majority Reward Vote\u548cWeighted Reward Frequency Vote\u4e24\u79cd\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u8f93\u51fa\u805a\u5408\u65b9\u6cd5\uff0c\u5c06\u591a\u6570\u6295\u7968\u548cPRMs\u7684\u4f18\u52bf\u7ed3\u5408\u8d77\u6765\uff0c\u8fdb\u4e00\u6b65\u6539\u5584\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684PRM\u6570\u636e\u6784\u5efa\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.01780", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01780", "abs": "https://arxiv.org/abs/2508.01780", "authors": ["Guozhao Mo", "Wenliang Zhong", "Jiawei Chen", "Xuanang Chen", "Yaojie Lu", "Hongyu Lin", "Ben He", "Xianpei Han", "Le Sun"], "title": "LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?", "comment": "Our code and data will be publicly available at\n  https://icip-cas.github.io/LiveMCPBench", "summary": "With the rapid development of Model Context Protocol (MCP), the number of MCP\nservers has surpassed 10,000. However, existing MCP benchmarks are limited to\nsingle-server settings with only a few tools, hindering effective evaluation of\nagent capabilities in large-scale, real-world scenarios. To address this\nlimitation, we present LiveMCPBench, the first comprehensive benchmark\ncomprising 95 real-world tasks grounded in the MCP ecosystem, designed to\nevaluate LLM agents at scale across diverse servers. To support a scalable and\nreproducible evaluation pipeline in large-scale MCP environments, we curate\nLiveMCPTool, a diverse and readily deployable collection of 70 MCP servers and\n527 tools. Furthermore, we introduce LiveMCPEval, an LLM-as-a-Judge framework\nthat enables automated and adaptive evaluation in dynamic, time-varying task\nenvironments, achieving 81% agreement with human reviewers. Finally, we propose\nthe MCP Copilot Agent, a multi-step agent that routes tools for dynamic\nplanning and executes tools for API interaction across the entire LiveMCPTool\nsuite. Our evaluation covers 10 leading models, with the best-performing model\n(Claude-Sonnet-4) reaching a 78.95% success rate. However, we observe large\nperformance variance across models, and several widely-used models perform\npoorly in LiveMCPBench's complex, tool-rich environments. Overall, LiveMCPBench\noffers the first unified framework for benchmarking LLM agents in realistic,\ntool-rich, and dynamic MCP environments, laying a solid foundation for scalable\nand reproducible research on agent capabilities. Our code and data will be\npublicly available at https://icip-cas.github.io/LiveMCPBench.", "AI": {"tldr": "LiveMCPBench\u662f\u7b2c\u4e00\u4e2a\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u5728\u5927\u89c4\u6a21\u3001\u771f\u5b9e\u4e16\u754c\u3001\u52a8\u6001MCP\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u4ee3\u7406\u3002\u7814\u7a76\u4ecb\u7ecd\u4e86LiveMCPTool\u548cLiveMCPEval\uff0c\u4ee5\u652f\u6301\u53ef\u6269\u5c55\u548c\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\u6d41\u7a0b\u3002\u8bc4\u4f30\u8986\u76d6\u4e8610\u4e2a\u4e3b\u8981\u6a21\u578b\uff0c\u53d1\u73b0\u6700\u4f73\u6a21\u578b\u5728LiveMCPBench\u4e2d\u8fbe\u523078.95%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u968f\u7740MCP\u7684\u5feb\u901f\u53d1\u5c55\uff0cMCP\u670d\u52a1\u5668\u6570\u91cf\u5df2\u8d85\u8fc710,000\u53f0\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684MCP\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u9650\u4e8e\u5355\u670d\u52a1\u5668\u8bbe\u7f6e\uff0c\u4ec5\u6709\u5c11\u6570\u5de5\u5177\uff0c\u963b\u788d\u4e86\u5bf9\u5927\u89c4\u6a21\u3001\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u4ee3\u7406\u80fd\u529b\u7684\u6709\u6548\u8bc4\u4f30\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u63d0\u51fa\u4e86LiveMCPBench\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5305\u542b95\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u591a\u6837\u670d\u52a1\u5668\u4e0a\u7684\u89c4\u6a21\u6548\u679c\u3002", "method": "\u4ecb\u7ecd\u4e86LiveMCPBench\uff0c\u5305\u62ec95\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\uff0c\u57fa\u4e8eMCP\u751f\u6001\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u65e8\u5728\u5728\u4e0d\u540c\u670d\u52a1\u5668\u4e0a\u89c4\u6a21\u8bc4\u4f30LLM\u4ee3\u7406\u3002\u63d0\u51fa\u4e86LiveMCPTool\uff0c\u5305\u62ec70\u4e2aMCP\u670d\u52a1\u5668\u548c527\u4e2a\u5de5\u5177\uff0c\u652f\u6301\u5927\u89c4\u6a21MCP\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u548c\u53ef\u91cd\u590d\u8bc4\u4f30\u6d41\u7a0b\u3002\u5f15\u5165\u4e86LiveMCPEval\uff0c\u4e00\u4e2aLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5728\u52a8\u6001\u3001\u65f6\u95f4\u53d8\u5316\u7684\u4efb\u52a1\u73af\u5883\u4e2d\u7684\u81ea\u52a8\u5316\u548c\u81ea\u9002\u5e94\u8bc4\u4f30\u3002\u63d0\u51fa\u4e86MCP Copilot Agent\uff0c\u4e00\u4e2a\u591a\u6b65\u4ee3\u7406\uff0c\u7528\u4e8e\u52a8\u6001\u89c4\u5212\u8def\u7531\u5de5\u5177\u5e76\u5728\u6574\u4e2aLiveMCPTool\u5957\u4ef6\u4e2d\u6267\u884cAPI\u4ea4\u4e92\u3002\u8bc4\u4f30\u6db5\u76d6\u4e8610\u4e2a\u4e3b\u8981\u6a21\u578b\uff0c\u6548\u679c\u6700\u597d\u7684\u6a21\u578b\uff08Claude-Sonnet-4\uff09\u8fbe\u5230\u4e8678.95%\u7684\u6210\u529f\u7387\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5728LiveMCPBench\u7684\u590d\u6742\u5de5\u5177\u4e30\u5bcc\u73af\u5883\u4e2d\uff0c\u6027\u80fd\u5b58\u5728\u8f83\u5927\u5dee\u5f02\uff0c\u4e00\u4e9b\u5e7f\u6cdb\u4f7f\u7528\u7684\u6a21\u578b\u5728LiveMCPBench\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u6700\u4f73\u6a21\u578b\uff08Claude-Sonnet-4\uff09\u8fbe\u5230\u4e8678.95%\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u8fd8\u89c2\u5bdf\u5230\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u6027\u80fd\u7684\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "LiveMCPBench\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u73b0\u5b9e\u3001\u4e30\u5bcc\u5de5\u5177\u3001\u52a8\u6001MCP\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u4ee3\u7406\uff0c\u4e3a\u8bc4\u4f30\u4ee3\u7406\u80fd\u529b\u7684\u53ef\u6269\u5c55\u548c\u53ef\u91cd\u590d\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.01844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01844", "abs": "https://arxiv.org/abs/2508.01844", "authors": ["Xinkai Zou", "Xuan Jiang", "Ruikai Huang", "Haoze He", "Parv Kapoor", "Jiahua Zhao"], "title": "CloudAnoAgent: Anomaly Detection for Cloud Sites via LLM Agent with Neuro-Symbolic Mechanism", "comment": null, "summary": "Anomaly detection in cloud sites remains a critical yet challenging task.\nExisting approaches that rely solely on metric data often suffer from high\nfalse positive rates (FPR) due to data imbalance between normal and anomalous\nevents, leading to significant operational overhead for system reliance\nengineers. Recent advances in large language models (LLMs) offer new\nopportunities for integrating metrics with log data, enabling more accurate and\ninterpretable anomaly detection. In this paper, we propose CloudAnoAgent, the\nfirst neuro-symbolic LLM-based agent for anomaly detection in cloud\nenvironments. CloudAnoAgent jointly processes structured metrics and textual\nlog data in a unified pipeline, leveraging symbolic verification to validate\ndetection hypotheses and generate structured anomaly reports. To support\nsystematic evaluation, we introduce CloudAnoBench, the first benchmark that\nprovides LLM-generated paired metrics and log data with fine-grained anomaly\nbehavior annotations, filling a critical gap in existing datasets. Experimental\nresults demonstrate that CloudAnoAgent improves anomaly classification accuracy\nby 46.36% and 36.67% on average and reduces the FPR by 36.67% and 33.89% on\naverage over traditional baselines and LLM-only baseline, with a boost on\nanomaly type detection accuracy by 12.8% compared to vanilla LLM prompting.\nThese results demonstrate the strengths of our approach in improving detection\naccuracy, reducing false positives, and enhancing interpretability, thereby\nsupporting practical deployment in enterprise cloud environments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CloudAnoAgent\uff0c\u9996\u4e2a\u7528\u4e8e\u4e91\u73af\u5883\u4e2d\u5f02\u5e38\u68c0\u6d4b\u7684\u795e\u7ecf\u7b26\u53f7LLM\u4ee3\u7406\u3002CloudAnoAgent\u6574\u5408\u4e86\u6307\u6807\u548c\u6587\u672c\u65e5\u5fd7\u6570\u636e\uff0c\u901a\u8fc7\u5f15\u5165CloudAnoBench\u6570\u636e\u96c6\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u76f8\u5bf9\u4f20\u7edf\u57fa\u7ebf\u548c\u4ec5\u4f7f\u7528LLM\u7684\u57fa\u7ebf\uff0cCloudAnoAgent\u5728\u63d0\u9ad8\u5f02\u5e38\u5206\u7c7b\u51c6\u786e\u6027\u3001\u964d\u4f4e\u865a\u5047\u9633\u6027\u7387\u548c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u4f9d\u8d56\u4e8e\u6307\u6807\u6570\u636e\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u6b63\u5e38\u548c\u5f02\u5e38\u4e8b\u4ef6\u4e4b\u95f4\u5b58\u5728\u6570\u636e\u4e0d\u5e73\u8861\uff0c\u5bfc\u81f4\u865a\u5047\u9633\u6027\u7387\u9ad8\uff0c\u7ed9\u7cfb\u7edf\u53ef\u9760\u6027\u5de5\u7a0b\u5e08\u5e26\u6765\u663e\u8457\u7684\u64cd\u4f5c\u8d1f\u62c5\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u53d7\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6700\u65b0\u8fdb\u5c55\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u6307\u6807\u548c\u65e5\u5fd7\u6570\u636e\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86CloudAnoAgent\u6765\u8fdb\u884c\u4e91\u73af\u5883\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u91c7\u7528\u4e86\u795e\u7ecf-\u7b26\u53f7\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408\u4e86\u7ed3\u6784\u5316\u6307\u6807\u548c\u6587\u672c\u65e5\u5fd7\u6570\u636e\u8fdb\u884c\u5904\u7406\u3002\u901a\u8fc7\u5f15\u5165CloudAnoBench\u6570\u636e\u96c6\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e76\u5c55\u793a\u4e86\u5b9e\u9a8c\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86CloudAnoAgent\u76f8\u5bf9\u4e8e\u4f20\u7edf\u57fa\u7ebf\u548c\u4ec5\u4f7f\u7528LLM\u7684\u57fa\u7ebf\u7684\u6027\u80fd\u4f18\u52bf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCloudAnoAgent\u76f8\u5bf9\u4f20\u7edf\u57fa\u51c6\u7ebf\u548c\u4ec5\u4f7f\u7528LLM\u7684\u57fa\u51c6\u7ebf\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5f02\u5e38\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u5e76\u5927\u5e45\u964d\u4f4e\u865a\u5047\u9633\u6027\u7387\u3002\u4e0e\u4ec5\u4f7f\u7528LLM\u7684\u57fa\u51c6\u7ebf\u76f8\u6bd4\uff0c\u63d0\u9ad8\u4e86\u5f02\u5e38\u7c7b\u578b\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86CloudAnoAgent\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u795e\u7ecf\u7b26\u53f7\u7684LLM\u4ee3\u7406\u7528\u4e8e\u4e91\u73af\u5883\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u3002CloudAnoAgent\u80fd\u591f\u8054\u5408\u5904\u7406\u7ed3\u6784\u5316\u6307\u6807\u548c\u6587\u672c\u65e5\u5fd7\u6570\u636e\uff0c\u5e76\u5229\u7528\u7b26\u53f7\u9a8c\u8bc1\u6765\u9a8c\u8bc1\u68c0\u6d4b\u5047\u8bbe\u5e76\u751f\u6210\u7ed3\u6784\u5316\u5f02\u5e38\u62a5\u544a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCloudAnoAgent\u76f8\u5bf9\u4f20\u7edf\u57fa\u51c6\u7ebf\u63d0\u9ad8\u4e8646.36%\u548c36.67%\u7684\u5f02\u5e38\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u5e76\u5c06\u865a\u5047\u9633\u6027\u7387\u5e73\u5747\u964d\u4f4e\u4e8636.67%\u548c33.89%\uff0c\u5e76\u4e14\u76f8\u5bf9\u4e8e\u4ec5\u4f7f\u7528LLM\u7684\u57fa\u51c6\u7ebf\uff0c\u63d0\u9ad8\u4e8612.8%\u7684\u5f02\u5e38\u7c7b\u578b\u68c0\u6d4b\u51c6\u786e\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u5c55\u793a\u4e86\u672c\u65b9\u6cd5\u5728\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u51cf\u5c11\u865a\u5047\u9633\u6027\u548c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u4ece\u800c\u652f\u6301\u5728\u4f01\u4e1a\u4e91\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2508.01869", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01869", "abs": "https://arxiv.org/abs/2508.01869", "authors": ["Yuanyuan Liang", "Xiaoman Wang", "Tingyu Xie", "Lei Pan"], "title": "ProKG-Dial: Progressive Multi-Turn Dialogue Construction with Domain Knowledge Graphs", "comment": "15 pages", "summary": "Current large language models (LLMs) excel at general NLP tasks but often\nlack domain specific precision in professional settings. Building a high\nquality domain specific multi turn dialogue dataset is essential for developing\nspecialized conversational systems. However, existing methods such as manual\nannotation, simulated human LLM interactions, and role based LLM dialogues are\nresource intensive or suffer from limitations in dialogue quality and domain\ncoverage. To address these challenges, we introduce ProKG Dial, a progressive\nframework for constructing knowledge intensive multi turn dialogue datasets\nusing domain specific knowledge graphs (KGs). ProKG Dial leverages the\nstructured nature of KGs to encode complex domain knowledge and relationships,\nproviding a solid foundation for generating meaningful and coherent dialogues.\nSpecifically, ProKG Dial begins by applying community detection to partition\nthe KG into semantically cohesive subgraphs. For each subgraph, the framework\nincrementally generates a series of questions and answers centered around a\ntarget entity, ensuring relevance and coverage. A rigorous filtering step is\nemployed to maintain high dialogue quality. We validate ProKG Dial on a medical\nknowledge graph by evaluating the generated dialogues in terms of diversity,\nsemantic coherence, and entity coverage. Furthermore, we fine tune a base LLM\non the resulting dataset and benchmark it against several baselines. Both\nautomatic metrics and human evaluations demonstrate that ProKG Dial\nsubstantially improves dialogue quality and domain specific performance,\nhighlighting its effectiveness and practical utility.", "AI": {"tldr": "ProKG Dial is a framework that utilizes domain-specific knowledge graphs to construct high-quality multi-turn dialogue datasets. It improves dialogue quality, domain-specific performance, diversity, semantic coherence, and entity coverage compared to existing methods. Fine-tuning large language models on datasets created by ProKG Dial leads to significant improvements in dialogue quality and domain-specific performance.", "motivation": "Current large language models lack domain-specific precision in professional settings. Building high-quality domain-specific multi-turn dialogue datasets is crucial for developing specialized conversational systems. Existing methods are resource-intensive or limited in dialogue quality and domain coverage.", "method": "ProKG Dial leverages domain-specific knowledge graphs to encode complex domain knowledge and relationships, partitioning the KG into semantically cohesive subgraphs. It incrementally generates questions and answers centered around a target entity, ensuring relevance and coverage. A rigorous filtering step is applied to maintain high dialogue quality. The framework is validated on a medical knowledge graph and fine-tuned a base LLM on the resulting dataset for benchmarking against baselines.", "result": "ProKG Dial substantially improves dialogue quality, domain-specific performance, diversity, semantic coherence, and entity coverage compared to existing methods. Fine-tuning a base LLM on datasets generated by ProKG Dial demonstrates the effectiveness and practical utility of the framework.", "conclusion": "ProKG Dial is an effective framework for constructing domain-specific multi-turn dialogue datasets using domain-specific knowledge graphs, improving dialogue quality and domain-specific performance. It outperforms existing methods in terms of diversity, semantic coherence, and entity coverage. Fine-tuning a large language model on datasets generated by ProKG Dial leads to significant improvements in dialogue quality and domain-specific performance."}}
{"id": "2508.01871", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.01871", "abs": "https://arxiv.org/abs/2508.01871", "authors": ["Yuanyuan Liang", "Lei Pan", "Tingyu Xie", "Yunshi Lan", "Weining Qian"], "title": "Multi-turn Natural Language to Graph Query Language Translation", "comment": "21 pages", "summary": "In recent years, research on transforming natural language into graph query\nlanguage (NL2GQL) has been increasing. Most existing methods focus on\nsingle-turn transformation from NL to GQL. In practical applications, user\ninteractions with graph databases are typically multi-turn, dynamic, and\ncontext-dependent. While single-turn methods can handle straightforward\nqueries, more complex scenarios often require users to iteratively adjust their\nqueries, investigate the connections between entities, or request additional\ndetails across multiple dialogue turns. Research focused on single-turn\nconversion fails to effectively address multi-turn dialogues and complex\ncontext dependencies. Additionally, the scarcity of high-quality multi-turn\nNL2GQL datasets further hinders the progress of this field. To address this\nchallenge, we propose an automated method for constructing multi-turn NL2GQL\ndatasets based on Large Language Models (LLMs) , and apply this method to\ndevelop the MTGQL dataset, which is constructed from a financial market graph\ndatabase and will be publicly released for future research. Moreover, we\npropose three types of baseline methods to assess the effectiveness of\nmulti-turn NL2GQL translation, thereby laying a solid foundation for future\nresearch.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u5355\u8f6e\u8f6c\u6362\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u591a\u8f6e\u5bf9\u8bdd\u548c\u590d\u6742\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u95ee\u9898\u3002\u901a\u8fc7\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u4e86MTGQL\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u79cd\u57fa\u51c6\u65b9\u6cd5\u6765\u8bc4\u4f30\u591a\u8f6eNL2GQL\u8f6c\u6362\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u8f6e\u81ea\u7136\u8bed\u8a00\u5230\u56fe\u67e5\u8be2\u8bed\u8a00\uff08GQL\uff09\u7684\u8f6c\u6362\u4e0a\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u591a\u8f6e\u5bf9\u8bdd\u548c\u590d\u6742\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u3002\u9ad8\u8d28\u91cf\u7684\u591a\u8f6eNL2GQL\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u963b\u788d\u4e86\u7814\u7a76\u9886\u57df\u7684\u8fdb\u5c55\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u6784\u5efa\u591a\u8f6eNL2GQL\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u5efa\u591a\u8f6e\u81ea\u7136\u8bed\u8a00\u8f6c\u56fe\u67e5\u8be2\u8bed\u8a00\uff08NL2GQL\uff09\u6570\u636e\u96c6\uff0c\u5e94\u7528\u8be5\u6570\u636e\u96c6\u6784\u5efaMTGQL\u6570\u636e\u96c6\u3002\u63d0\u51fa\u4e09\u79cd\u57fa\u51c6\u65b9\u6cd5\u8bc4\u4f30\u591a\u8f6eNL2GQL\u8f6c\u6362\u7684\u6709\u6548\u6027\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u5efa\u4e86MTGQL\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bc4\u4f30\u591a\u8f6eNL2GQL\u8f6c\u6362\u6709\u6548\u6027\u7684\u57fa\u7840\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u81ea\u52a8\u6784\u5efa\u591a\u8f6e\u81ea\u7136\u8bed\u8a00\u8f6c\u56fe\u67e5\u8be2\u8bed\u8a00\uff08NL2GQL\uff09\u6570\u636e\u96c6\u7684\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u8be5\u65b9\u6cd5\u5f00\u53d1\u4e86MTGQL\u6570\u636e\u96c6\u3002\u8be5\u6570\u636e\u96c6\u57fa\u4e8e\u91d1\u878d\u5e02\u573a\u56fe\u6570\u636e\u5e93\u6784\u5efa\uff0c\u5e76\u5c06\u516c\u5f00\u53d1\u5e03\u4f9b\u672a\u6765\u7814\u7a76\u4f7f\u7528\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u57fa\u51c6\u65b9\u6cd5\u6765\u8bc4\u4f30\u591a\u8f6eNL2GQL\u8f6c\u6362\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2508.01956", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.01956", "abs": "https://arxiv.org/abs/2508.01956", "authors": ["Jiayi Wang", "Jacqueline Jil Vallon", "Neil Panjwani", "Xi Ling", "Sushmita Vij", "Sandy Srinivas", "John Leppert", "Mark K. Buyyounouski", "Mohsen Bayati"], "title": "Agent-Based Feature Generation from Clinical Notes for Outcome Prediction", "comment": null, "summary": "Electronic health records (EHRs) contain rich unstructured clinical notes\nthat could enhance predictive modeling, yet extracting meaningful features from\nthese notes remains challenging. Current approaches range from labor-intensive\nmanual clinician feature generation (CFG) to fully automated representational\nfeature generation (RFG) that lack interpretability and clinical relevance.\nHere we introduce SNOW (Scalable Note-to-Outcome Workflow), a modular\nmulti-agent system powered by large language models (LLMs) that autonomously\ngenerates structured clinical features from unstructured notes without human\nintervention. We evaluated SNOW against manual CFG, clinician-guided LLM\napproaches, and RFG methods for predicting 5-year prostate cancer recurrence in\n147 patients from Stanford Healthcare. While manual CFG achieved the highest\nperformance (AUC-ROC: 0.771), SNOW matched this performance (0.761) without\nrequiring any clinical expertise, significantly outperforming both baseline\nfeatures alone (0.691) and all RFG approaches. The clinician-guided LLM method\nalso performed well (0.732) but still required expert input. SNOW's specialized\nagents handle feature discovery, extraction, validation, post-processing, and\naggregation, creating interpretable features that capture complex clinical\ninformation typically accessible only through manual review. Our findings\ndemonstrate that autonomous LLM systems can replicate expert-level feature\nengineering at scale, potentially transforming how clinical ML models leverage\nunstructured EHR data while maintaining the interpretability essential for\nclinical deployment.", "AI": {"tldr": "SNOW, a system powered by large language models, autonomously generates structured clinical features from unstructured clinical notes. It matches the performance of manual clinician feature generation for predicting 5-year prostate cancer recurrence, outperforming fully automated methods.", "motivation": "Extracting meaningful features from unstructured clinical notes in Electronic Health Records (EHRs) remains challenging, with current approaches ranging from labor-intensive manual clinician feature generation to fully automated representational feature generation lacking interpretability. SNOW aims to address this challenge by autonomously generating structured clinical features without human intervention.", "method": "Introduced SNOW (Scalable Note-to-Outcome Workflow) that utilizes large language models to autonomously generate structured clinical features from unstructured notes, evaluated its performance against manual clinician feature generation, clinician-guided LLM approaches, and fully automated representational feature generation methods for predicting prostate cancer recurrence.", "result": "SNOW matched the performance of manual clinician feature generation for predicting 5-year prostate cancer recurrence without requiring clinical expertise, outperforming baseline features and all fully automated representational feature generation approaches.", "conclusion": "SNOW, a modular multi-agent system powered by large language models, autonomously generates structured clinical features from unstructured clinical notes without human intervention, matching the performance of manual clinician feature generation for predicting 5-year prostate cancer recurrence."}}
{"id": "2508.02016", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02016", "abs": "https://arxiv.org/abs/2508.02016", "authors": ["Jeiyoon Park", "Yongshin Han", "Minseop Kim", "Kisu Yang"], "title": "Dynamic Context Adaptation for Consistent Role-Playing Agents with Retrieval-Augmented Generations", "comment": "preprint", "summary": "We propose AMADEUS, which is composed of Adaptive Context-aware Text Splitter\n(ACTS), Guided Selection (GS), and Attribute Extractor (AE). ACTS finds an\noptimal chunk length and hierarchical contexts for each character. AE\nidentifies a character's general attributes from the chunks retrieved by GS and\nuses these attributes as a final context to maintain robust persona consistency\neven when answering out of knowledge questions. To facilitate the development\nand evaluation of RAG-based RPAs, we construct CharacterRAG, a role-playing\ndataset that consists of persona documents for 15 distinct fictional characters\ntotaling 976K written characters, and 450 question and answer pairs. We find\nthat our framework effectively models not only the knowledge possessed by\ncharacters, but also various attributes such as personality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AMADEUS\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53d6\u89d2\u8272\u5c5e\u6027\u548c\u77e5\u8bc6\uff0c\u6784\u5efa\u4e86\u5305\u542b15\u4e2a\u865a\u6784\u89d2\u8272\u8d44\u6599\u548c\u95ee\u7b54\u5bf9\u7684\u6570\u636e\u96c6\u3002\u7814\u7a76\u53d1\u73b0\u6846\u67b6\u6709\u6548\u5efa\u6a21\u89d2\u8272\u77e5\u8bc6\u548c\u5c5e\u6027\uff0c\u4fc3\u8fdb\u4e86\u57fa\u4e8eRAG\u7684RPAs\u7684\u53d1\u5c55\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63d0\u53d6\u89d2\u8272\u7684\u5c5e\u6027\u548c\u77e5\u8bc6\uff0c\u7ef4\u62a4\u4eba\u7269\u4e00\u81f4\u6027\uff0c\u4ee5\u5e94\u5bf9\u8d85\u51fa\u77e5\u8bc6\u8303\u56f4\u7684\u95ee\u9898\u3002\u901a\u8fc7\u6784\u5efa\u6570\u636e\u96c6\u548c\u63d0\u51faAMADEUS\u6846\u67b6\uff0c\u52a0\u6df1\u5bf9\u89d2\u8272\u77e5\u8bc6\u548c\u5c5e\u6027\u5efa\u6a21\u7684\u7406\u89e3\u3002", "method": "AMADEUS\u6846\u67b6\u5305\u62ecACTS\u3001GS\u548cAE\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u7528\u4e8e\u9010\u5b57\u7b26\u67e5\u627e\u6700\u4f73\u5206\u5757\u957f\u5ea6\u548c\u5c42\u6b21\u4e0a\u4e0b\u6587\uff0c\u8bc6\u522b\u89d2\u8272\u7684\u4e00\u822c\u5c5e\u6027\u5e76\u7ef4\u62a4\u4eba\u7269\u4e00\u81f4\u6027\u3002\u4ed6\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u89d2\u8272\u626e\u6f14\u6570\u636e\u96c6CharacterRAG\uff0c\u7528\u4e8e\u5f00\u53d1\u548c\u8bc4\u4f30\u57fa\u4e8eRAG\u7684RPAs\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u4ed6\u4eec\u7684\u6846\u67b6\u6709\u6548\u5efa\u6a21\u89d2\u8272\u77e5\u8bc6\u548c\u5c5e\u6027\uff0c\u4fc3\u8fdb\u4e86\u57fa\u4e8eRAG\u7684RPAs\u7684\u53d1\u5c55\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eAMADEUS\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u5305\u62ecAdaptive Context-aware Text Splitter (ACTS)\u3001Guided Selection (GS)\u548cAttribute Extractor (AE)\uff0c\u7528\u4e8e\u63d0\u53d6\u89d2\u8272\u7684\u5c5e\u6027\u548c\u77e5\u8bc6\u3002\u4ed6\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u89d2\u8272\u626e\u6f14\u6570\u636e\u96c6CharacterRAG\uff0c\u5305\u542b15\u4e2a\u865a\u6784\u89d2\u8272\u7684\u4eba\u7269\u8d44\u6599\u548c450\u4e2a\u95ee\u7b54\u5bf9\u3002\u7814\u7a76\u53d1\u73b0\u6846\u67b6\u4e0d\u4ec5\u80fd\u6709\u6548\u5efa\u6a21\u89d2\u8272\u6240\u62e5\u6709\u7684\u77e5\u8bc6\uff0c\u8fd8\u80fd\u63d0\u53d6\u5404\u79cd\u5c5e\u6027\uff0c\u5982\u4e2a\u6027\u7b49\u3002"}}
{"id": "2508.02063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02063", "abs": "https://arxiv.org/abs/2508.02063", "authors": ["Amitava Das", "Vinija Jain", "Aman Chadha"], "title": "TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs", "comment": null, "summary": "Large Language Models (LLMs) fine-tuned to align with human values often\nexhibit alignment drift, producing unsafe or policy-violating completions when\nexposed to adversarial prompts, decoding perturbations, or paraphrased\njailbreaks. While prior work has behaviorally characterized alignment failure,\nlittle is known about the training-time belief sources underlying these\nfailures. We introduce TraceAlign, a unified framework for tracing unsafe\ncompletions back to their root causes in the model's training corpus. Central\nto our approach is the Belief Conflict Index (BCI), which quantifies semantic\ninconsistency between generated spans and aligned policies, based on retrieved\ntraining documents using suffix-array matching. We propose three complementary\ninterventions: (i) TraceShield, an inference-time safety filter that refuses\ncompletions with high-BCI spans, (ii) Contrastive Belief Deconfliction Loss, a\ncontrastive fine-tuning objective penalizing high-BCI continuations during DPO,\nand (iii) Prov-Decode, a provenance-aware decoding strategy that vetoes beam\nexpansions predicted to yield high-BCI spans. Together, these defenses reduce\nalignment drift by up to 85% on our curated Alignment Drift Benchmark (ADB)\nwhile preserving utility on standard tasks, with delta less than 0.2 and\nimproved refusal quality. We further derive a theoretical upper bound on drift\nlikelihood via suffix-array span statistics, linking memorization frequency and\nlength to adversarial reactivation risk. TraceAlign thus provides the first\nscalable, traceable, and grounded toolkit for understanding and mitigating\nalignment failures at source. To encourage further exploration and development,\nwe open-source our implementation at:\nhttps://anonymous.4open.science/r/tracealign-2DA7", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86TraceAlign\u6846\u67b6\uff0c\u7528\u4e8e\u8ffd\u8e2a\u5728\u6a21\u578b\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u5bfc\u81f4\u4e0d\u5b89\u5168\u5b8c\u6210\u7684\u6839\u672c\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u79cd\u9632\u5fa1\u63aa\u65bd\u4ee5\u51cf\u5c11\u5bf9\u9f50\u6f02\u79fb\u3002\u8fd9\u4e9b\u9632\u5fa1\u63aa\u65bd\u5728\u5b9e\u9a8c\u4e2d\u6210\u529f\u51cf\u5c11\u4e86\u5bf9\u9f50\u6f02\u79fb\uff0c\u4fdd\u6301\u4e86\u5b9e\u7528\u6027\uff0c\u63d0\u5347\u4e86\u62d2\u7edd\u8d28\u91cf\uff0c\u5e76\u63a8\u5bfc\u4e86\u6709\u5173\u5bf9\u9f50\u6f02\u79fb\u53ef\u80fd\u6027\u7684\u7406\u8bba\u4e0a\u9650\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7684\u5de5\u4f5c\u5df2\u7ecf\u5bf9\u5bf9\u9f50\u5931\u8d25\u8fdb\u884c\u4e86\u884c\u4e3a\u6027\u63cf\u8ff0\uff0c\u4f46\u5bf9\u5bfc\u81f4\u8fd9\u4e9b\u5931\u8d25\u7684\u8bad\u7ec3\u65f6\u4fe1\u5ff5\u6765\u6e90\u77e5\u4e4b\u751a\u5c11\u3002\u56e0\u6b64\uff0c\u672c\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51faTraceAlign\u6846\u67b6\uff0c\u4ee5\u8ffd\u8e2a\u4e0d\u5b89\u5168\u5b8c\u6210\u7684\u6839\u672c\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u5e72\u9884\u63aa\u65bd\u51cf\u5c11\u5bf9\u9f50\u6f02\u79fb\u3002", "method": "\u5f15\u5165\u4e86TraceAlign\u6846\u67b6\uff0c\u57fa\u4e8e\u540e\u7f00\u6570\u7ec4\u5339\u914d\u68c0\u7d22\u8bad\u7ec3\u6587\u6863\uff0c\u4f7f\u7528Belief Conflict Index\uff08BCI\uff09\u91cf\u5316\u751f\u6210\u8de8\u5ea6\u4e0e\u5bf9\u9f50\u653f\u7b56\u4e4b\u95f4\u7684\u8bed\u4e49\u4e0d\u4e00\u81f4\u6027\u3002\u63d0\u51fa\u4e86\u4e09\u79cd\u76f8\u4e92\u8865\u5145\u7684\u5e72\u9884\u63aa\u65bd\uff1a\uff08i\uff09TraceShield\uff0c\u5728\u63a8\u65ad\u65f6\u62d2\u7edd\u5177\u6709\u9ad8BCI\u8de8\u5ea6\u7684\u5b8c\u6210\uff1b\uff08ii\uff09\u5bf9\u6bd4\u4fe1\u4ef0\u89e3\u51b2\u7a81\u635f\u5931\uff0c\u5bf9\u9ad8BCI\u5ef6\u7eed\u5728DPO\u671f\u95f4\u8fdb\u884c\u5bf9\u6bd4\u5fae\u8c03\u76ee\u6807\uff1b\uff08iii\uff09Prov-Decode\uff0c\u4e00\u79cd\u8003\u8651\u51fa\u5904\u7684\u89e3\u7801\u7b56\u7565\uff0c\u5426\u51b3\u9884\u6d4b\u4ea7\u751f\u9ad8BCI\u8de8\u5ea6\u7684beam\u6269\u5c55\u3002", "result": "\u63d0\u51fa\u7684\u4e09\u79cd\u9632\u5fa1\u63aa\u65bd\u5728\u5bf9\u9f50\u6f02\u79fb\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c06\u5bf9\u9f50\u6f02\u79fb\u964d\u4f4e\u4e86\u9ad8\u8fbe85\uff05\uff0c\u540c\u65f6\u5728\u6807\u51c6\u4efb\u52a1\u4e0a\u4fdd\u6301\u4e86\u5b9e\u7528\u6027\uff0c\u62d2\u7edd\u8d28\u91cf\u5f97\u5230\u6539\u5584\u3002\u901a\u8fc7\u540e\u7f00\u6570\u7ec4\u8de8\u5ea6\u7edf\u8ba1\u63a8\u5bfc\u5bf9\u9f50\u6f02\u79fb\u53ef\u80fd\u6027\u7684\u7406\u8bba\u4e0a\u9650\uff0c\u5c06\u8bb0\u5fc6\u9891\u7387\u548c\u957f\u5ea6\u4e0e\u654c\u610f\u91cd\u65b0\u6fc0\u6d3b\u98ce\u9669\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u8bba\u6587\u4ecb\u7ecd\u4e86TraceAlign\u6846\u67b6\uff0c\u7528\u4e8e\u8ffd\u8e2a\u6a21\u578b\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u5bfc\u81f4\u4e0d\u5b89\u5168\u5b8c\u6210\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u76f8\u4e92\u8865\u5145\u7684\u5e72\u9884\u63aa\u65bd\u4ee5\u51cf\u5c11\u5bf9\u9f50\u6f02\u79fb\u3002\u8fd9\u4e9b\u9632\u5fa1\u63aa\u65bd\u5728\u5bf9\u9f50\u6f02\u79fb\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c06\u5bf9\u9f50\u6f02\u79fb\u964d\u4f4e\u4e86\u9ad8\u8fbe85%\uff0c\u540c\u65f6\u5728\u6807\u51c6\u4efb\u52a1\u4e0a\u4fdd\u6301\u4e86\u5b9e\u7528\u6027\uff0c\u62d2\u7edd\u8d28\u91cf\u5f97\u5230\u6539\u5584\u3002\u8bba\u6587\u8fdb\u4e00\u6b65\u63a8\u5bfc\u4e86\u901a\u8fc7\u540e\u7f00\u6570\u7ec4\u8de8\u5ea6\u7edf\u8ba1\u63a8\u5bfc\u5bf9\u9f50\u6f02\u79fb\u53ef\u80fd\u6027\u7684\u7406\u8bba\u4e0a\u9650\uff0c\u5c06\u8bb0\u5fc6\u9891\u7387\u548c\u957f\u5ea6\u4e0e\u654c\u610f\u91cd\u65b0\u6fc0\u6d3b\u98ce\u9669\u8054\u7cfb\u8d77\u6765\u3002TraceAlign\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u53ef\u4f38\u7f29\u3001\u53ef\u8ffd\u8e2a\u548c\u624e\u5b9e\u7684\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u7406\u89e3\u548c\u51cf\u8f7b\u5bf9\u9f50\u5931\u8d25\u7684\u6839\u6e90\u3002"}}
{"id": "2508.02073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02073", "abs": "https://arxiv.org/abs/2508.02073", "authors": ["Jiawei Li", "Chengye Yang", "Yaochen Zhang", "Weilin Sun", "Lei Meng", "Xiangxu Meng"], "title": "Risk identification based on similar case retrieval enhancement,", "comment": "in Chinese language", "summary": "The goal of construction site risk and hazard identification is to enhance\nsafety management through automation. Existing research based on large language\nmodels falls into two categories: image-text matching for collaborative\nreasoning, which struggles with complex hazard features, and instruction\nfine-tuning or dialogue guidance using professional datasets, which suffers\nfrom high training costs and poor generalization.To address this, we propose a\nhazard identification method using similar case retrieval enhancement. By\nintegrating external knowledge and retrieved case contexts via prompt\nfine-tuning, we mitigate misjudgments caused by limited domain knowledge and\nweak feature associations. Our method includes three modules: retrieval\nlibrary, image similarity retrieval, and large model retrieval enhancement,\nenabling efficient recognition without training. Experiments on real\nconstruction data show significant improvements. For instance, GLM-4V's\nrecognition accuracy increased to 50\\%, a 35.49\\% boost. The method enhances\naccuracy, context understanding, and stability, offering new theoretical and\ntechnical support for hazard detection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5371\u9669\u8bc6\u522b\u65b9\u6cd5\uff0c\u5229\u7528\u7c7b\u4f3c\u6848\u4f8b\u68c0\u7d22\u589e\u5f3a\uff0c\u901a\u8fc7\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u548c\u6848\u4f8b\u80cc\u666f\uff0c\u6709\u6548\u51cf\u8f7b\u9886\u57df\u77e5\u8bc6\u6709\u9650\u548c\u7279\u5f81\u5173\u8054\u6027\u5dee\u5bfc\u81f4\u7684\u5224\u65ad\u5931\u8bef\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u65bd\u5de5\u6570\u636e\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u5371\u9669\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u548c\u6280\u672f\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5b58\u5728\u4e24\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6784\u5efa\u5de5\u5730\u98ce\u9669\u548c\u5371\u9669\u8bc6\u522b\u65b9\u6cd5\uff1a\u56fe\u50cf\u6587\u672c\u5339\u914d\u7528\u4e8e\u534f\u540c\u63a8\u7406\uff0c\u4f46\u9762\u4e34\u590d\u6742\u5371\u9669\u7279\u5f81\u7684\u56f0\u96be\uff1b\u6307\u4ee4\u5fae\u8c03\u6216\u5bf9\u8bdd\u5f15\u5bfc\u4f7f\u7528\u4e13\u4e1a\u6570\u636e\u96c6\uff0c\u4f46\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u5229\u7528\u76f8\u4f3c\u6848\u4f8b\u68c0\u7d22\u589e\u5f3a\u7684\u5371\u9669\u8bc6\u522b\u65b9\u6cd5\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7c7b\u4f3c\u6848\u4f8b\u68c0\u7d22\u589e\u5f3a\u7684\u5371\u9669\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u548c\u68c0\u7d22\u5230\u7684\u6848\u4f8b\u80cc\u666f\uff0c\u901a\u8fc7\u63d0\u793a\u5fae\u8c03\u6765\u51cf\u8f7b\u7531\u4e8e\u9886\u57df\u77e5\u8bc6\u6709\u9650\u548c\u7279\u5f81\u5173\u8054\u6027\u5dee\u800c\u5bfc\u81f4\u7684\u5224\u65ad\u5931\u8bef\u3002\u65b9\u6cd5\u5305\u62ec\u68c0\u7d22\u5e93\u3001\u56fe\u50cf\u76f8\u4f3c\u6027\u68c0\u7d22\u548c\u5927\u578b\u6a21\u578b\u68c0\u7d22\u589e\u5f3a\u4e09\u4e2a\u6a21\u5757\uff0c\u80fd\u591f\u5b9e\u73b0\u6709\u6548\u7684\u8bc6\u522b\u800c\u65e0\u9700\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5b9e\u9645\u65bd\u5de5\u6570\u636e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u4f8b\u5982GLM-4V\u7684\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u9ad8\u523050\uff05\uff0c\u63d0\u5347\u4e8635.49\uff05\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7c7b\u4f3c\u6848\u4f8b\u68c0\u7d22\u589e\u5f3a\u7684\u5371\u9669\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u548c\u68c0\u7d22\u5230\u7684\u6848\u4f8b\u80cc\u666f\uff0c\u901a\u8fc7\u63d0\u793a\u5fae\u8c03\u6765\u51cf\u8f7b\u7531\u4e8e\u9886\u57df\u77e5\u8bc6\u6709\u9650\u548c\u7279\u5f81\u5173\u8054\u6027\u5dee\u800c\u5bfc\u81f4\u7684\u5224\u65ad\u5931\u8bef\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u65bd\u5de5\u6570\u636e\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u51c6\u786e\u6027\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u5371\u9669\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u548c\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2508.02076", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2508.02076", "abs": "https://arxiv.org/abs/2508.02076", "authors": ["Yunhao Liang", "Yuan Qu", "Jingyuan Yang", "Shaochong Lin", "Zuo-Jun Max Shen"], "title": "Everyone Contributes! Incentivizing Strategic Cooperation in Multi-LLM Systems via Sequential Public Goods Games", "comment": null, "summary": "Coordinating multiple large language models (LLMs) to solve complex tasks\ncollaboratively poses a fundamental trade-off between the computation costs and\ncollective performance compared with individual model. We introduce a novel,\ngame-theoretically grounded reinforcement learning (RL) framework, the\nMulti-Agent Cooperation Sequential Public Goods Game (MAC-SPGG), to\nsystematically incentivize cooperation in multi-LLM ensembles. In MAC-SPGG, LLM\nagents move in sequence, observing predecessors' outputs and updating beliefs\nto condition their own contributions. By redesigning the public-goods reward,\neffortful contributions become the unique Subgame Perfect Nash Equilibrium\n(SPNE), which eliminates free-riding under traditional SPGG or PGG. Its\nsequential protocol replaces costly round-based information exchanges with a\nstreamlined decision flow, cutting communication overhead while retaining\nstrategic depth. We prove the existence and uniqueness of the SPNE under\nrealistic parameters, and empirically show that MAC-SPGG-trained ensembles\noutperform single-agent baselines, chain-of-thought prompting, and other\ncooperative methods, even achieving comparable performance to large-scale\nmodels across reasoning, math, code generation, and NLP tasks. Our results\nhighlight the power of structured, incentive-aligned MAC-SPGG cooperation for\nscalable and robust multi-agent language generation.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86MAC-SPGG\u6846\u67b6\uff0c\u901a\u8fc7\u6fc0\u52b1\u5408\u4f5c\u89e3\u51b3\u591aLLM\u6a21\u578b\u96c6\u5408\u4e2d\u7684\u535a\u5f08\u95ee\u9898\u3002\u8bc1\u660e\u4e86MAC-SPGG\u8bad\u7ec3\u7684\u96c6\u5408\u8868\u73b0\u4f18\u79c0\uff0c\u53ef\u6bd4\u80a9\u5927\u89c4\u6a21\u6a21\u578b\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u9488\u5bf9\u534f\u8c03\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5171\u540c\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65f6\u7684\u8ba1\u7b97\u6210\u672c\u548c\u96c6\u4f53\u6027\u80fd\u4e4b\u95f4\u7684\u6839\u672c\u6743\u8861\u95ee\u9898\uff0c\u5f15\u5165\u4e86MAC-SPGG\u6846\u67b6\u4ee5\u7cfb\u7edf\u6027\u5730\u6fc0\u52b1\u591aLLM\u96c6\u5408\u4e2d\u7684\u5408\u4f5c\u3002\u901a\u8fc7\u89e3\u51b3\u5408\u4f5c\u535a\u5f08\u4e2d\u5b58\u5728\u7684\u642d\u4fbf\u8f66\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6574\u4f53\u6027\u80fd\u3002", "method": "\u4ecb\u7ecd\u4e86MAC-SPGG\u6846\u67b6\uff0c\u5176\u4e2dLLM\u4ee3\u7406\u6309\u987a\u5e8f\u79fb\u52a8\uff0c\u5728\u89c2\u5bdf\u524d\u4efb\u7684\u8f93\u51fa\u5e76\u66f4\u65b0\u4fe1\u5ff5\u7684\u57fa\u7840\u4e0a\u6765\u8c03\u6574\u81ea\u5df1\u7684\u8d21\u732e\u3002\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u516c\u5171\u7269\u54c1\u5956\u52b1\uff0c\u4f7f\u5f97\u52aa\u529b\u8d21\u732e\u6210\u4e3a\u552f\u4e00\u7684\u6b21\u535a\u5f08\u5b8c\u7f8e\u7eb3\u4ec0\u5747\u8861\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u4f20\u7edfSPGG\u6216PGG\u4e0b\u7684\u642d\u4fbf\u8f66\u73b0\u8c61\u3002\u5b83\u7684\u987a\u5e8f\u534f\u8bae\u53d6\u4ee3\u4e86\u6602\u8d35\u7684\u57fa\u4e8e\u56de\u5408\u7684\u4fe1\u606f\u4ea4\u6362\uff0c\u91c7\u7528\u7b80\u5316\u7684\u51b3\u7b56\u6d41\u7a0b\uff0c\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\u540c\u65f6\u4fdd\u7559\u4e86\u7b56\u7565\u6df1\u5ea6\u3002\u901a\u8fc7\u5728\u5b9e\u9645\u53c2\u6570\u4e0b\u8bc1\u660eSPNE\u7684\u5b58\u5728\u548c\u72ec\u7279\u6027\uff0c\u4ee5\u53ca\u5728\u5b9e\u9a8c\u4e2d\u5c55\u793aMAC-SPGG\u8bad\u7ec3\u7684\u96c6\u5408\u4f18\u4e8e\u5355\u4ee3\u7406\u57fa\u51c6\u7684\u7ed3\u679c\u3002", "result": "\u8bc1\u660e\u4e86MAC-SPGG\u8bad\u7ec3\u7684\u96c6\u5408\u4f18\u4e8e\u5355\u4e00\u4ee3\u7406\u57fa\u7ebf\u3001\u601d\u7ef4\u94fe\u63a8\u52a8\u548c\u5176\u4ed6\u5408\u4f5c\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4ee5\u535a\u5f08\u8bba\u4e3a\u57fa\u7840\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u540d\u4e3a\u591a\u667a\u4f53\u5408\u4f5c\u987a\u5e8f\u516c\u5171\u7269\u54c1\u535a\u5f08\uff08MAC-SPGG\uff09\uff0c\u7528\u4e8e\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u5408\u4e2d\u7cfb\u7edf\u5730\u6fc0\u52b1\u5408\u4f5c\u3002\u7814\u7a76\u8bc1\u660eMAC-SPGG\u8bad\u7ec3\u7684\u96c6\u5408\u4f18\u4e8e\u5355\u4e00\u4ee3\u7406\u57fa\u7ebf\u3001\u601d\u7ef4\u94fe\u63a8\u52a8\u548c\u5176\u4ed6\u5408\u4f5c\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u3001\u6570\u5b66\u3001\u4ee3\u7801\u751f\u6210\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u8be5\u7814\u7a76\u7a81\u51fa\u4e86\u7ed3\u6784\u5316\u3001\u4ee5\u6fc0\u52b1\u4e3a\u5bfc\u5411\u7684MAC-SPGG\u5408\u4f5c\u5bf9\u4e8e\u53ef\u6269\u5c55\u548c\u7a33\u5065\u7684\u591a\u667a\u4f53\u8bed\u8a00\u751f\u6210\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.02085", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02085", "abs": "https://arxiv.org/abs/2508.02085", "authors": ["Jiaye Lin", "Yifu Guo", "Yuzhen Han", "Sen Hu", "Ziyi Ni", "Licheng Wang", "Mingguang Chen", "Daxin Jiang", "Binxing Jiao", "Chen Hu", "Huacan Wang"], "title": "SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents", "comment": null, "summary": "Large Language Model (LLM)-based agents have recently shown impressive\ncapabilities in complex reasoning and tool use via multi-step interactions with\ntheir environments. While these agents have the potential to tackle complicated\ntasks, their problem-solving process, i.e., agents' interaction trajectory\nleading to task completion, remains underexploited. These trajectories contain\nrich feedback that can navigate agents toward the right directions for solving\nproblems correctly. Although prevailing approaches, such as Monte Carlo Tree\nSearch (MCTS), can effectively balance exploration and exploitation, they\nignore the interdependence among various trajectories and lack the diversity of\nsearch spaces, which leads to redundant reasoning and suboptimal outcomes. To\naddress these challenges, we propose SE-Agent, a Self-Evolution framework that\nenables Agents to optimize their reasoning processes iteratively. Our approach\nrevisits and enhances former pilot trajectories through three key operations:\nrevision, recombination, and refinement. This evolutionary mechanism enables\ntwo critical advantages: (1) it expands the search space beyond local optima by\nintelligently exploring diverse solution paths guided by previous trajectories,\nand (2) it leverages cross-trajectory inspiration to efficiently enhance\nperformance while mitigating the impact of suboptimal reasoning paths. Through\nthese mechanisms, SE-Agent achieves continuous self-evolution that\nincrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench\nVerified to resolve real-world GitHub issues. Experimental results across five\nstrong LLMs show that integrating SE-Agent delivers up to 55% relative\nimprovement, achieving state-of-the-art performance among all open-source\nagents on SWE-bench Verified. Our code and demonstration materials are publicly\navailable at https://github.com/wanghuacan/SE-Agent.", "AI": {"tldr": "SE-Agent\u901a\u8fc7\u81ea\u6211\u6f14\u5316\u6846\u67b6\u5b9e\u73b0\u4e86\u6301\u7eed\u6539\u8fdb\u63a8\u7406\u8d28\u91cf\uff0c\u5728\u89e3\u51b3GitHub\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684LLM\u4ee3\u7406\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65f6\u5f88\u6709\u6f5c\u529b\uff0c\u4f46\u666e\u904d\u65b9\u6cd5\u5ffd\u7565\u4e86\u8def\u5f84\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5e76\u7f3a\u4e4f\u641c\u7d22\u7a7a\u95f4\u7684\u591a\u6837\u6027\uff0c\u56e0\u6b64\u5bfc\u81f4\u4e86\u5197\u4f59\u63a8\u7406\u548c\u6b21\u4f18\u7ed3\u679c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u63d0\u51faSE-Agent\u6846\u67b6\u3002", "method": "SE-Agent\u63d0\u51fa\u4e86\u4e09\u79cd\u5173\u952e\u64cd\u4f5c\uff1a\u4fee\u8ba2\u3001\u91cd\u7ec4\u548c\u7ec6\u5316\uff0c\u901a\u8fc7\u8fd9\u4e9b\u64cd\u4f5c\u5b9e\u73b0\u4e86Agents\u63a8\u7406\u8fc7\u7a0b\u7684\u4f18\u5316\u3002", "result": "\u5728SWE-bench Verified\u4e0a\u5bf9SE-Agent\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4e0e\u96c6\u6210SE-Agent\u76f8\u6bd4\uff0c5\u4e2a\u5f3a\u5927\u7684LLMs\u7684\u6027\u80fd\u76f8\u5bf9\u63d0\u9ad8\u4e8655\uff05\uff0c\u5728\u6240\u6709\u5f00\u6e90\u4ee3\u7406\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8868\u73b0\u3002", "conclusion": "SE-Agent\u901a\u8fc7\u81ea\u6211\u6f14\u5316\u6846\u67b6\u5b9e\u73b0\u4e86\u6301\u7eed\u6539\u8fdb\u63a8\u7406\u8d28\u91cf\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728SWE-bench Verified\u4e0a\u5904\u7406GitHub\u95ee\u9898\u7684\u6027\u80fd\uff0c\u76f8\u6bd4\u4e8e\u5176\u4ed6\u5f00\u6e90\u4ee3\u7406\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8868\u73b0\u3002"}}
{"id": "2508.02093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02093", "abs": "https://arxiv.org/abs/2508.02093", "authors": ["Yiqing Xu", "Linfeng Li", "Cunjun Yu", "David Hsu"], "title": "\"Stack It Up!\": 3D Stable Structure Generation from 2D Hand-drawn Sketch", "comment": "Accepted to CoRL 2025", "summary": "Imagine a child sketching the Eiffel Tower and asking a robot to bring it to\nlife. Today's robot manipulation systems can't act on such sketches\ndirectly-they require precise 3D block poses as goals, which in turn demand\nstructural analysis and expert tools like CAD. We present StackItUp, a system\nthat enables non-experts to specify complex 3D structures using only 2D\nfront-view hand-drawn sketches. StackItUp introduces an abstract relation graph\nto bridge the gap between rough sketches and accurate 3D block arrangements,\ncapturing the symbolic geometric relations (e.g., left-of) and stability\npatterns (e.g., two-pillar-bridge) while discarding noisy metric details from\nsketches. It then grounds this graph to 3D poses using compositional diffusion\nmodels and iteratively updates it by predicting hidden internal and rear\nsupports-critical for stability but absent from the sketch. Evaluated on\nsketches of iconic landmarks and modern house designs, StackItUp consistently\nproduces stable, multilevel 3D structures and outperforms all baselines in both\nstability and visual resemblance.", "AI": {"tldr": "StackItUp\u662f\u4e00\u4e2a\u7cfb\u7edf\uff0c\u5141\u8bb8\u975e\u4e13\u5bb6\u4f7f\u7528\u624b\u7ed8\u8349\u56fe\u6307\u5b9a\u590d\u6742\u76843D\u7ed3\u6784\u3002\u5b83\u5f15\u5165\u4e86\u62bd\u8c61\u5173\u7cfb\u56fe\u6765\u6355\u6349\u8c61\u5f81\u6027\u51e0\u4f55\u5173\u7cfb\u548c\u7a33\u5b9a\u6027\u6a21\u5f0f\uff0c\u5c06\u8349\u56fe\u8f6c\u6362\u4e3a\u51c6\u786e\u76843D\u5757\u6392\u5217\uff0c\u5e76\u901a\u8fc7\u9884\u6d4b\u9690\u85cf\u7684\u5185\u90e8\u548c\u540e\u90e8\u652f\u6491\u6765\u66f4\u65b0\u56fe\u5f62\u3002\u8be5\u7cfb\u7edf\u5728\u7a33\u5b9a\u6027\u548c\u89c6\u89c9\u76f8\u4f3c\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u7cfb\u7edf\u9700\u8981\u7cbe\u786e\u76843D\u5757\u59ff\u52bf\u4f5c\u4e3a\u76ee\u6807\uff0c\u8fd9\u8981\u6c42\u8fdb\u884c\u7ed3\u6784\u5206\u6790\u548c\u4f7f\u7528CAD\u7b49\u4e13\u4e1a\u5de5\u5177\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u7cfb\u7edf\uff0c\u4f7f\u975e\u4e13\u5bb6\u80fd\u591f\u901a\u8fc7\u7b80\u5355\u7684\u624b\u7ed8\u8349\u56fe\u6307\u5b9a\u590d\u6742\u76843D\u7ed3\u6784\uff0c\u4ece\u800c\u6d88\u9664\u5bf9CAD\u7b49\u4e13\u4e1a\u5de5\u5177\u7684\u4f9d\u8d56\u3002", "method": "\u5f15\u5165\u62bd\u8c61\u5173\u7cfb\u56fe\u6765\u6355\u6349\u8c61\u5f81\u6027\u51e0\u4f55\u5173\u7cfb\u548c\u7a33\u5b9a\u6027\u6a21\u5f0f\uff0c\u5c06\u624b\u7ed8\u8349\u56fe\u8f6c\u5316\u4e3a\u51c6\u786e\u76843D\u5757\u6392\u5217\u3002\u4f7f\u7528\u7ec4\u5408\u6269\u6563\u6a21\u578b\u5c06\u5173\u7cfb\u56fe\u8f6c\u6362\u4e3a3D\u59ff\u52bf\uff0c\u5e76\u901a\u8fc7\u9884\u6d4b\u9690\u85cf\u7684\u5185\u90e8\u548c\u540e\u90e8\u652f\u6491\u6765\u66f4\u65b0\u56fe\u5f62\u3002", "result": "StackItUp\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5730\u5c062D\u624b\u7ed8\u8349\u56fe\u8f6c\u6362\u4e3a\u51c6\u786e\u76843D\u7ed3\u6784\uff0c\u4ea7\u751f\u7a33\u5b9a\u7684\u591a\u5c423D\u7ed3\u6784\uff0c\u5728\u7a33\u5b9a\u6027\u548c\u89c6\u89c9\u76f8\u4f3c\u6027\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u7cfb\u7edf\u3002", "conclusion": "StackItUp\u662f\u4e00\u4e2a\u7cfb\u7edf\uff0c\u53ef\u4ee5\u8ba9\u975e\u4e13\u5bb6\u53ea\u4f7f\u75282D\u624b\u7ed8\u8349\u56fe\u6765\u6307\u5b9a\u590d\u6742\u76843D\u7ed3\u6784\u3002\u901a\u8fc7\u5f15\u5165\u62bd\u8c61\u5173\u7cfb\u56fe\u6765\u6355\u6349\u8c61\u5f81\u6027\u51e0\u4f55\u5173\u7cfb\u548c\u7a33\u5b9a\u6027\u6a21\u5f0f\uff0c\u5c06\u8349\u56fe\u8f6c\u6362\u4e3a\u51c6\u786e\u76843D\u5757\u6392\u5217\u3002\u901a\u8fc7\u4f7f\u7528\u7ec4\u5408\u6269\u6563\u6a21\u578b\u5c06\u56fe\u5f62\u4e0e3D\u59ff\u52bf\u76f8\u5339\u914d\uff0c\u5e76\u901a\u8fc7\u9884\u6d4b\u9690\u85cf\u7684\u5185\u90e8\u548c\u540e\u90e8\u652f\u6491\u6765\u4e0d\u65ad\u66f4\u65b0\u56fe\u5f62\u3002\u5728\u5bf9\u6807\u5fd7\u6027\u5730\u6807\u548c\u73b0\u4ee3\u623f\u5c4b\u8bbe\u8ba1\u8349\u56fe\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0cStackItUp\u59cb\u7ec8\u4ea7\u751f\u7a33\u5b9a\u7684\u591a\u5c423D\u7ed3\u6784\uff0c\u5728\u7a33\u5b9a\u6027\u548c\u5916\u89c2\u76f8\u4f3c\u6027\u4e0a\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u3002"}}
{"id": "2508.02110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02110", "abs": "https://arxiv.org/abs/2508.02110", "authors": ["Kanghua Mo", "Li Hu", "Yucheng Long", "Zhihao Li"], "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "comment": null, "summary": "Large language model (LLM) agents have demonstrated remarkable capabilities\nin complex reasoning and decision-making by leveraging external tools. However,\nthis tool-centric paradigm introduces a previously underexplored attack\nsurface: adversaries can manipulate tool metadata -- such as names,\ndescriptions, and parameter schemas -- to influence agent behavior. We identify\nthis as a new and stealthy threat surface that allows malicious tools to be\npreferentially selected by LLM agents, without requiring prompt injection or\naccess to model internals. To demonstrate and exploit this vulnerability, we\npropose the Attractive Metadata Attack (AMA), a black-box in-context learning\nframework that generates highly attractive but syntactically and semantically\nvalid tool metadata through iterative optimization. Our attack integrates\nseamlessly into standard tool ecosystems and requires no modification to the\nagent's execution framework. Extensive experiments across ten realistic,\nsimulated tool-use scenarios and a range of popular LLM agents demonstrate\nconsistently high attack success rates (81\\%-95\\%) and significant privacy\nleakage, with negligible impact on primary task execution. Moreover, the attack\nremains effective even under prompt-level defenses and structured\ntool-selection protocols such as the Model Context Protocol, revealing systemic\nvulnerabilities in current agent architectures. These findings reveal that\nmetadata manipulation constitutes a potent and stealthy attack surface,\nhighlighting the need for execution-level security mechanisms that go beyond\nprompt-level defenses.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4eba\u5728\u5229\u7528\u5916\u90e8\u5de5\u5177\u65f6\u5b58\u5728\u5143\u6570\u636e\u64cd\u7eb5\u653b\u51fb\u5a01\u80c1\uff0c\u63d0\u51fa\u4e86\u5438\u5f15\u6027\u5143\u6570\u636e\u653b\u51fb\uff08AMA\uff09\u4f5c\u4e3a\u6f0f\u6d1e\u6f14\u793a\uff0c\u5c55\u793a\u4e86\u9ad8\u653b\u51fb\u6210\u529f\u7387\u548c\u9690\u79c1\u6cc4\u6f0f\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u5f53\u524d\u4ee3\u7406\u4eba\u67b6\u6784\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u6f0f\u6d1e\u548c\u9700\u8981\u52a0\u5f3a\u7684\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4eba\u5728\u5229\u7528\u5916\u90e8\u5de5\u5177\u65f6\u53ef\u80fd\u9762\u4e34\u7684\u64cd\u7eb5\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u5143\u6570\u636e\u64cd\u7eb5\u4f5c\u4e3a\u4e00\u79cd\u6f5c\u5728\u4e14\u5177\u6709\u9690\u853d\u6027\u7684\u653b\u51fb\u624b\u6bb5\u3002", "method": "\u63d0\u51fa\u4e86Attractive Metadata Attack\uff08AMA\uff09\uff0c\u4e00\u4e2a\u9ed1\u76d2\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u751f\u6210\u5177\u6709\u9ad8\u5438\u5f15\u529b\u4f46\u53e5\u6cd5\u548c\u8bed\u4e49\u4e0a\u6709\u6548\u7684\u5de5\u5177\u5143\u6570\u636e\u6765\u5c55\u793a\u548c\u5229\u7528\u4ee3\u7406\u4eba\u5bf9\u5de5\u5177\u5143\u6570\u636e\u7684\u504f\u597d\u9009\u62e9\u3002", "result": "\u901a\u8fc7\u5bf9\u5341\u79cd\u4eff\u771f\u7684\u5b9e\u9645\u5de5\u5177\u4f7f\u7528\u573a\u666f\u548c\u591a\u79cd\u6d41\u884c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4eba\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u653b\u51fb\u6210\u529f\u7387\u9ad8\u548c\u9690\u79c1\u6cc4\u6f0f\u663e\u8457\u7684\u7ed3\u679c\u3002\u5373\u4f7f\u5728\u63d0\u793a\u7ea7\u9632\u5fa1\u548c\u7ed3\u6784\u5316\u5de5\u5177\u9009\u62e9\u534f\u8bae\u4e0b\uff0c\u8be5\u653b\u51fb\u4ecd\u7136\u6709\u6548\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u4ee3\u7406\u4eba\u67b6\u6784\u4e2d\u7684\u7cfb\u7edf\u6027\u6f0f\u6d1e\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4eba\u5728\u5229\u7528\u5916\u90e8\u5de5\u5177\u8fdb\u884c\u590d\u6742\u63a8\u7406\u548c\u51b3\u7b56\u65f6\uff0c\u5b58\u5728\u4e00\u4e2a\u88ab\u4f4e\u4f30\u7684\u653b\u51fb\u9762\uff1a\u5bf9\u5de5\u5177\u5143\u6570\u636e\u8fdb\u884c\u64cd\u7eb5\u53ef\u80fd\u5f71\u54cd\u4ee3\u7406\u4eba\u7684\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u5177\u6709\u9690\u853d\u6027\u7684\u65b0\u5a01\u80c1\u8868\u9762\u3002\u901a\u8fc7\u63d0\u51fa\u5438\u5f15\u6027\u5143\u6570\u636e\u653b\u51fb\uff08AMA\uff09\u6765\u5c55\u793a\u548c\u5229\u7528\u8fd9\u4e00\u6f0f\u6d1e\uff0c\u6210\u529f\u7387\u9ad8\uff0c\u9690\u79c1\u6cc4\u6f0f\u663e\u8457\uff0c\u5bf9\u4e3b\u8981\u4efb\u52a1\u6267\u884c\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\u3002\u5f53\u524d\u4ee3\u7406\u4eba\u67b6\u6784\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u9700\u8981\u8d85\u8d8a\u63d0\u793a\u7ea7\u9632\u5fa1\u7684\u6267\u884c\u7ea7\u5b89\u5168\u673a\u5236\u3002"}}
{"id": "2508.02120", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02120", "abs": "https://arxiv.org/abs/2508.02120", "authors": ["Linan Yue", "Yichao Du", "Yizhi Wang", "Weibo Gao", "Fangzhou Yao", "Li Wang", "Ye Liu", "Ziyu Xu", "Qi Liu", "Shimin Di", "Min-Ling Zhang"], "title": "Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models", "comment": null, "summary": "Recently, Large Reasoning Models (LRMs) have gradually become a research\nhotspot due to their outstanding performance in handling complex tasks. Among\nthem, DeepSeek R1 has garnered significant attention for its exceptional\nperformance and open-source nature, driving advancements in the research of\nR1-style LRMs. Unlike traditional Large Language Models (LLMs), these models\nenhance logical deduction and decision-making capabilities during reasoning by\nincorporating mechanisms such as long chain-of-thought and self-reflection\nthrough reinforcement learning. However, with the widespread application of\nthese models, the problem of overthinking has gradually emerged. Specifically,\nwhen generating answers, these models often construct excessively long\nreasoning chains with redundant or repetitive steps, which leads to reduced\nreasoning efficiency and may affect the accuracy of the final answer. To this\nend, various efficient reasoning methods have been proposed, aiming to reduce\nthe length of reasoning paths without compromising model performance and\nreasoning capability. By reviewing the current research advancements in the\nfield of efficient reasoning methods systematically, we categorize existing\nworks into two main directions based on the lens of single-model optimization\nversus model collaboration: (1) Efficient Reasoning with Single Model, which\nfocuses on improving the reasoning efficiency of individual models; and (2)\nEfficient Reasoning with Model Collaboration, which explores optimizing\nreasoning paths through collaboration among multiple models. Besides, we\nmaintain a public GitHub repository that tracks the latest progress in\nefficient reasoning methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6307\u51fa\u4e86LRM\u4e2d\u5b58\u5728\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u6765\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002\u7814\u7a76\u7ed3\u679c\u5206\u4e3a\u5355\u6a21\u578b\u4f18\u5316\u548c\u6a21\u578b\u534f\u4f5c\u4e24\u4e2a\u65b9\u5411\uff0c\u540c\u65f6\u7ef4\u62a4GitHub\u4ed3\u5e93\u8ffd\u8e2a\u6700\u65b0\u8fdb\u5c55\u3002", "motivation": "LRM\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u89e3\u51b3\u6b64\u95ee\u9898\u7684\u6709\u6548\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u7cfb\u7edf\u5730\u5ba1\u67e5\u4e86\u76ee\u524d\u5728\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5c06\u73b0\u6709\u5de5\u4f5c\u5206\u4e3a\u5355\u6a21\u578b\u4f18\u5316\u548c\u6a21\u578b\u534f\u4f5c\u4e24\u4e2a\u65b9\u5411\uff0c\u5e76\u63d0\u51fa\u6709\u6548\u63a8\u7406\u65b9\u6cd5\u4ee5\u51cf\u5c11\u8fc7\u957f\u7684\u63a8\u7406\u8def\u5f84\u3002", "result": "\u901a\u8fc7\u5bf9LRM\u9886\u57df\u4e2d\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u7684\u7814\u7a76\u8fdb\u5c55\u8fdb\u884c\u5ba1\u67e5\uff0c\u63d0\u51fa\u4e86\u5728\u5355\u6a21\u578b\u4f18\u5316\u548c\u6a21\u578b\u534f\u4f5c\u4e24\u4e2a\u65b9\u5411\u7684\u6709\u6548\u63a8\u7406\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u7ef4\u62a4\u4e86\u4e00\u4e2a\u516c\u5f00\u7684GitHub\u4ed3\u5e93\u4ee5\u8ffd\u8e2a\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u7684\u6700\u65b0\u8fdb\u5c55\u3002", "conclusion": "\u8be5\u8bba\u6587\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u53ca\u5176\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u8ba8\u8bba\uff0c\u6307\u51faLRM\u4e2d\u5b58\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u63a8\u7406\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002\u540c\u65f6\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u5728LRM\u9886\u57df\u4e2d\u5355\u6a21\u578b\u4f18\u5316\u548c\u6a21\u578b\u534f\u4f5c\u4e24\u4e2a\u4e3b\u8981\u65b9\u5411\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2508.02121", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.02121", "abs": "https://arxiv.org/abs/2508.02121", "authors": ["Zexin Wang", "Jingjing Li", "Quan Zhou", "Haotian Si", "Yuanhao Liu", "Jianhui Li", "Gaogang Xie", "Fei Sun", "Dan Pei", "Changhua Pei"], "title": "A Survey on AgentOps: Categorization, Challenges, and Future Directions", "comment": "35 pages", "summary": "As the reasoning capabilities of Large Language Models (LLMs) continue to\nadvance, LLM-based agent systems offer advantages in flexibility and\ninterpretability over traditional systems, garnering increasing attention.\nHowever, despite the widespread research interest and industrial application of\nagent systems, these systems, like their traditional counterparts, frequently\nencounter anomalies. These anomalies lead to instability and insecurity,\nhindering their further development. Therefore, a comprehensive and systematic\napproach to the operation and maintenance of agent systems is urgently needed.\nUnfortunately, current research on the operations of agent systems is sparse.\nTo address this gap, we have undertaken a survey on agent system operations\nwith the aim of establishing a clear framework for the field, defining the\nchallenges, and facilitating further development. Specifically, this paper\nbegins by systematically defining anomalies within agent systems, categorizing\nthem into intra-agent anomalies and inter-agent anomalies. Next, we introduce a\nnovel and comprehensive operational framework for agent systems, dubbed Agent\nSystem Operations (AgentOps). We provide detailed definitions and explanations\nof its four key stages: monitoring, anomaly detection, root cause analysis, and\nresolution.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u4ee3\u7406\u7cfb\u7edf\u8fd0\u8425\uff0c\u5f15\u5165\u4e86AgentOps\u6846\u67b6\uff0c\u8be6\u7ec6\u5b9a\u4e49\u4e86\u76d1\u6d4b\u3001\u5f02\u5e38\u68c0\u6d4b\u3001\u6839\u672c\u539f\u56e0\u5206\u6790\u548c\u95ee\u9898\u89e3\u51b3\u56db\u4e2a\u5173\u952e\u9636\u6bb5\u3002\u8be5\u6846\u67b6\u65e8\u5728\u4e3a\u4ee3\u7406\u7cfb\u7edf\u8fd0\u8425\u5efa\u7acb\u6e05\u6670\u7684\u6846\u67b6\uff0c\u5b9a\u4e49\u6311\u6218\u5e76\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u4e0d\u65ad\u63d0\u5347\uff0cLLM\u4e3a\u57fa\u7840\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u7075\u6d3b\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u8fd9\u4e9b\u7cfb\u7edf\u4ecd\u7136\u7ecf\u5e38\u9047\u5230\u5f02\u5e38\uff0c\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u6027\u548c\u4e0d\u5b89\u5168\u6027\uff0c\u963b\u788d\u5176\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002\u76ee\u524d\u6709\u9650\u7684\u7814\u7a76\u81f4\u529b\u4e8e\u4ee3\u7406\u7cfb\u7edf\u8fd0\u8425\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u4e00\u79cd\u5168\u9762\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u64cd\u4f5c\u548c\u7ef4\u62a4\u4ee3\u7406\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u8c03\u7814\u4ee3\u7406\u7cfb\u7edf\u8fd0\u8425\uff0c\u7cfb\u7edf\u5b9a\u4e49\u4ee3\u7406\u7cfb\u7edf\u5185\u90e8\u548c\u4ee3\u7406\u7cfb\u7edf\u95f4\u7684\u5f02\u5e38\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u9896\u4e14\u5168\u9762\u7684\u4ee3\u7406\u7cfb\u7edf\u8fd0\u8425\u6846\u67b6\uff0c\u540d\u4e3aAgentOps\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u4e86\u4ee3\u7406\u7cfb\u7edf\u5185\u90e8\u548c\u4ee3\u7406\u7cfb\u7edf\u95f4\u7684\u5f02\u5e38\uff0c\u5e76\u63d0\u51fa\u4e86Agent System Operations\uff08AgentOps\uff09\u6846\u67b6\uff0c\u5305\u62ec\u76d1\u6d4b\u3001\u5f02\u5e38\u68c0\u6d4b\u3001\u6839\u672c\u539f\u56e0\u5206\u6790\u548c\u95ee\u9898\u89e3\u51b3\u56db\u4e2a\u5173\u952e\u9636\u6bb5\u7684\u8be6\u7ec6\u5b9a\u4e49\u548c\u89e3\u91ca\u3002", "conclusion": "\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u4ee3\u7406\u7cfb\u7edf\u8fd0\u8425\u5efa\u7acb\u6e05\u6670\u7684\u6846\u67b6\uff0c\u5b9a\u4e49\u6311\u6218\u5e76\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002\u63d0\u51fa\u4e86\u4ee3\u7406\u7cfb\u7edf\u8fd0\u8425\u7684\u65b0\u9896\u5168\u9762\u6846\u67b6 - Agent System Operations (AgentOps)\uff0c\u5305\u62ec\u76d1\u6d4b\u3001\u5f02\u5e38\u68c0\u6d4b\u3001\u6839\u672c\u539f\u56e0\u5206\u6790\u548c\u95ee\u9898\u89e3\u51b3\u56db\u4e2a\u5173\u952e\u9636\u6bb5\u7684\u8be6\u7ec6\u5b9a\u4e49\u548c\u89e3\u91ca\u3002"}}
{"id": "2508.02124", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02124", "abs": "https://arxiv.org/abs/2508.02124", "authors": ["Jingze Shi", "Yifan Wu", "Bingheng Wu", "Yiran Peng", "Liangdong Wang", "Guang Liu", "Yuyu Luo"], "title": "Trainable Dynamic Mask Sparse Attention", "comment": "8 figures, 4 tables", "summary": "In large language models, the demand for modeling long contexts is constantly\nincreasing, but the quadratic complexity of the standard self-attention\nmechanism often becomes a bottleneck. Although existing sparse attention\nmechanisms have improved efficiency, they may still encounter issues such as\nstatic patterns or information loss. We introduce a trainable dynamic mask\nsparse attention mechanism, Dynamic Mask Attention, which effectively utilizes\ncontent-aware and position-aware sparsity. DMA achieves this through two key\ninnovations: First, it dynamically generates content-aware sparse masks from\nvalue representations, enabling the model to identify and focus on critical\ninformation adaptively. Second, it implements position-aware sparse attention\ncomputation that effectively skips unnecessary calculation regions. This\ndual-sparsity design allows the model to significantly reduce the computational\ncomplexity of important information while retaining complete information,\nachieving an excellent balance between information fidelity and computational\nefficiency. We have verified the performance of DMA through comprehensive\nexperiments. Comparative studies show that DMA outperforms multi-head\nattention, sliding window attention, multi-head latent attention, and native\nsparse attention in terms of perplexity under Chinchilla Scaling Law settings.\nMoreover, in challenging multi-query associative recall tasks, DMA also\ndemonstrates superior performance and efficiency compared to these methods.\nCrucially, in the evaluation of a 1.7B parameter model, DMA significantly\noutperforms multi-head attention in both standard benchmark performance and the\nchallenging needle-in-a-haystack task. These experimental results highlight its\ncapability to balance model efficiency and long-context modeling ability\neffectively.", "AI": {"tldr": "Introducing Dynamic Mask Attention (DMA) to address the challenges of modeling long contexts in large language models. DMA dynamically generates content-aware sparse masks and implements position-aware sparse attention computation to reduce computational complexity without losing information. DMA outperforms other attention mechanisms in efficiency and long-context modeling, balancing information fidelity and computational efficiency effectively.", "motivation": "The motivation behind this paper is to address the increasing demand for modeling long contexts in large language models while overcoming the bottleneck of the quadratic complexity of the standard self-attention mechanism. Existing sparse attention mechanisms have limitations such as static patterns and information loss, prompting the development of DMA.", "method": "Introducing a trainable dynamic mask sparse attention mechanism that utilizes content-aware and position-aware sparsity. DMA dynamically generates content-aware sparse masks and implements position-aware sparse attention computation to reduce computational complexity while retaining complete information.", "result": "DMA has been verified through comprehensive experiments, showing superior performance compared to multi-head attention, sliding window attention, multi-head latent attention, and native sparse attention. It outperforms these methods in terms of perplexity under Chinchilla Scaling Law settings and shows superior performance and efficiency in challenging multi-query associative recall tasks. In evaluations with a 1.7B parameter model, DMA significantly outperforms multi-head attention in both standard benchmark performance and challenging tasks like the needle-in-a-haystack task.", "conclusion": "Dynamic Mask Attention (DMA) outperforms other attention mechanisms in terms of efficiency and long-context modeling ability, achieving a balance between information fidelity and computational efficiency."}}
{"id": "2508.02132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02132", "abs": "https://arxiv.org/abs/2508.02132", "authors": ["Yunge Wen", "Chenliang Huang", "Hangyu Zhou", "Zhuo Zeng", "Chun Ming Louis Po", "Julian Togelius", "Timothy Merino", "Sam Earle"], "title": "All Stories Are One Story: Emotional Arc Guided Procedural Game Level Generation", "comment": null, "summary": "The emotional arc is a universal narrative structure underlying stories\nacross cultures and media -- an idea central to structuralist narratology,\noften encapsulated in the phrase \"all stories are one story.\" We present a\nframework for procedural game narrative generation that incorporates emotional\narcs as a structural backbone for both story progression and gameplay dynamics.\nLeveraging established narratological theories and large-scale empirical\nanalyses, we focus on two core emotional patterns -- Rise and Fall -- to guide\nthe generation of branching story graphs. Each story node is automatically\npopulated with characters, items, and gameplay-relevant attributes (e.g.,\nhealth, attack), with difficulty adjusted according to the emotional\ntrajectory. Implemented in a prototype action role-playing game (ARPG), our\nsystem demonstrates how emotional arcs can be operationalized using large\nlanguage models (LLMs) and adaptive entity generation. Evaluation through\nplayer ratings, interviews, and sentiment analysis shows that emotional arc\nintegration significantly enhances engagement, narrative coherence, and\nemotional impact. These results highlight the potential of emotionally\nstructured procedural generation for advancing interactive storytelling for\ngames.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7a0b\u5e8f\u5316\u6e38\u620f\u53d9\u4e8b\u751f\u6210\u6846\u67b6\uff0c\u4ee5\u60c5\u611f\u5f27\u4f5c\u4e3a\u7ed3\u6784\u652f\u67f1\u3002\u5b9e\u65bd\u5728\u52a8\u4f5c\u89d2\u8272\u626e\u6f14\u6e38\u620f\u4e2d\uff0c\u901a\u8fc7\u5f15\u5165\u60c5\u611f\u5f27\u5927\u5e45\u63d0\u5347\u4e86\u73a9\u5bb6\u53c2\u4e0e\u5ea6\u548c\u53d9\u4e8b\u8fde\u8d2f\u6027\u3002\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\u60c5\u611f\u5f27\u6574\u5408\u663e\u8457\u6539\u5584\u4e86\u6e38\u620f\u4f53\u9a8c\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u8ba8\u5982\u4f55\u5c06\u60c5\u611f\u5f27\u4f5c\u4e3a\u4e00\u79cd\u901a\u7528\u7684\u53d9\u4e8b\u7ed3\u6784\uff0c\u5e94\u7528\u4e8e\u6e38\u620f\u53d9\u4e8b\u751f\u6210\u4e2d\u4ee5\u63d0\u5347\u6e38\u620f\u4f53\u9a8c\u548c\u6545\u4e8b\u8fde\u8d2f\u6027\u3002\u901a\u8fc7\u7ed3\u5408\u60c5\u611f\u5f27\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u7684\u6e38\u620f\u5143\u7d20\uff0c\u65e8\u5728\u63a8\u52a8\u4ea4\u4e92\u5f0f\u6545\u4e8b\u53d9\u8ff0\u7684\u53d1\u5c55\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7a0b\u5e8f\u5316\u6e38\u620f\u53d9\u4e8b\u751f\u6210\u6846\u67b6\uff0c\u5c06\u60c5\u611f\u5f27\u4f5c\u4e3a\u6545\u4e8b\u8fdb\u5c55\u548c\u6e38\u620f\u52a8\u529b\u5b66\u7684\u7ed3\u6784\u652f\u67f1\u3002\u901a\u8fc7\u5229\u7528\u5df2\u5efa\u7acb\u7684\u53d9\u4e8b\u7406\u8bba\u548c\u5927\u89c4\u6a21\u7ecf\u9a8c\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u4e24\u79cd\u6838\u5fc3\u60c5\u611f\u6a21\u5f0f\u2014\u2014\u4e0a\u5347\u548c\u4e0b\u964d\uff0c\u4ee5\u6307\u5bfc\u5206\u652f\u6545\u4e8b\u56fe\u7684\u751f\u6210\u3002\u6bcf\u4e2a\u6545\u4e8b\u8282\u70b9\u90fd\u81ea\u52a8\u586b\u5145\u6709\u4eba\u7269\u3001\u7269\u54c1\u548c\u4e0e\u6e38\u620f\u76f8\u5173\u7684\u5c5e\u6027\uff08\u5982\u751f\u547d\u503c\u3001\u653b\u51fb\u529b\uff09\uff0c\u96be\u5ea6\u4f1a\u6839\u636e\u60c5\u611f\u8f68\u8ff9\u8fdb\u884c\u8c03\u6574\u3002\u7cfb\u7edf\u5728\u539f\u578b\u52a8\u4f5c\u89d2\u8272\u626e\u6f14\u6e38\u620f\uff08ARPG\uff09\u4e2d\u5b9e\u65bd\uff0c\u5e76\u901a\u8fc7\u73a9\u5bb6\u8bc4\u5206\u3001\u8bbf\u8c08\u548c\u60c5\u611f\u5206\u6790\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u60c5\u611f\u5f27\u4f5c\u4e3a\u7a0b\u5e8f\u5316\u6e38\u620f\u53d9\u4e8b\u751f\u6210\u7684\u7ed3\u6784\u652f\u67f1\uff0c\u6210\u529f\u63d0\u5347\u4e86\u73a9\u5bb6\u53c2\u4e0e\u5ea6\u3001\u53d9\u4e8b\u8fde\u8d2f\u6027\u548c\u60c5\u611f\u51b2\u51fb\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u60c5\u611f\u5f27\u6574\u5408\u663e\u8457\u6539\u5584\u4e86\u6e38\u620f\u4f53\u9a8c\u3002", "conclusion": "\u60c5\u611f\u5f27\u662f\u8de8\u6587\u5316\u548c\u5a92\u4f53\u7684\u901a\u7528\u53d9\u4e8b\u7ed3\u6784\uff0c\u662f\u7ed3\u6784\u4e3b\u4e49\u53d9\u4e8b\u5b66\u7684\u6838\u5fc3\u6982\u5ff5\u4e4b\u4e00\uff0c\u5e38\u5e38\u88ab\u6982\u62ec\u4e3a\u201c\u6240\u6709\u6545\u4e8b\u90fd\u662f\u4e00\u4e2a\u6545\u4e8b\u201d\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7a0b\u5e8f\u5316\u6e38\u620f\u53d9\u4e8b\u751f\u6210\u6846\u67b6\uff0c\u5c06\u60c5\u611f\u5f27\u4f5c\u4e3a\u6545\u4e8b\u8fdb\u5c55\u548c\u6e38\u620f\u52a8\u529b\u5b66\u7684\u7ed3\u6784\u652f\u67f1\u3002\u901a\u8fc7\u5229\u7528\u5df2\u5efa\u7acb\u7684\u53d9\u4e8b\u7406\u8bba\u548c\u5927\u89c4\u6a21\u7ecf\u9a8c\u5206\u6790\uff0c\u91cd\u70b9\u5173\u6ce8\u4e24\u79cd\u6838\u5fc3\u60c5\u611f\u6a21\u5f0f\u2014\u2014\u4e0a\u5347\u548c\u4e0b\u964d\uff0c\u4ee5\u6307\u5bfc\u5206\u652f\u6545\u4e8b\u56fe\u7684\u751f\u6210\u3002\u6bcf\u4e2a\u6545\u4e8b\u8282\u70b9\u90fd\u81ea\u52a8\u586b\u5145\u6709\u4eba\u7269\u3001\u7269\u54c1\u548c\u4e0e\u6e38\u620f\u76f8\u5173\u7684\u5c5e\u6027\uff08\u5982\u751f\u547d\u503c\u3001\u653b\u51fb\u529b\uff09\uff0c\u96be\u5ea6\u4f1a\u6839\u636e\u60c5\u611f\u8f68\u8ff9\u8fdb\u884c\u8c03\u6574\u3002\u7cfb\u7edf\u5728\u539f\u578b\u52a8\u4f5c\u89d2\u8272\u626e\u6f14\u6e38\u620f\uff08ARPG\uff09\u4e2d\u5b9e\u65bd\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u81ea\u9002\u5e94\u5b9e\u4f53\u751f\u6210\u6765\u5b9e\u73b0\u60c5\u611f\u5f27\u3002\u901a\u8fc7\u73a9\u5bb6\u8bc4\u5206\u3001\u8bbf\u8c08\u548c\u60c5\u611f\u5206\u6790\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u60c5\u611f\u5f27\u7684\u6574\u5408\u663e\u8457\u589e\u5f3a\u4e86\u6e38\u620f\u7684\u53c2\u4e0e\u5ea6\u3001\u53d9\u4e8b\u8fde\u8d2f\u6027\u548c\u60c5\u611f\u51b2\u51fb\u3002\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u60c5\u611f\u7ed3\u6784\u5316\u7684\u7a0b\u5e8f\u751f\u6210\u5bf9\u63a8\u52a8\u6e38\u620f\u4ea4\u4e92\u53d9\u4e8b\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.02150", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02150", "abs": "https://arxiv.org/abs/2508.02150", "authors": ["Qingyu Ren", "Qianyu He", "Bowei Zhang", "Jie Zeng", "Jiaqing Liang", "Yanghua Xiao", "Weikang Zhou", "Zeye Sun", "Fei Yu"], "title": "Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following", "comment": null, "summary": "Reasoning models excel in complex problem solving but exhibit a concerning\ntrade off between reasoning capabilities and instruction following abilities.\nExisting approaches for improving instruction following rely on stronger\nexternal models, creating methodological bottlenecks and practical limitations\nincluding increased costs and accessibility constraints. We propose a\nself-supervised RL framework that leverages reasoning models' own internal\nsignals to improve instruction following capabilities without external\nsupervision. Extensive experiments demonstrate that our framework significantly\nimproves instruction following capabilities while maintaining reasoning\nperformance, offering a scalable and cost-effective approach to enhance\ninstruction following in reasoning models. The data and code are publicly\navailable at https://github.com/Rainier-rq/verl-if.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u6a21\u578b\u7684\u5185\u90e8\u4fe1\u53f7\u6765\u63d0\u9ad8\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u63d0\u5347\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u7ecf\u6d4e\u6548\u76ca\u7684\u65b9\u6848\u3002", "motivation": "\u76ee\u524d\u63d0\u9ad8\u6307\u4ee4\u9075\u5faa\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u66f4\u5f3a\u5927\u7684\u5916\u90e8\u6a21\u578b\uff0c\u5bfc\u81f4\u65b9\u6cd5\u8bba\u74f6\u9888\u548c\u5b9e\u9645\u9650\u5236\uff0c\u5305\u62ec\u6210\u672c\u589e\u52a0\u548c\u53ef\u8bbf\u95ee\u6027\u7ea6\u675f\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u63a8\u7406\u6a21\u578b\u7684\u5185\u90e8\u4fe1\u53f7\u6765\u6539\u5584\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u540c\u65f6\u907f\u514d\u4e86\u5916\u90e8\u76d1\u7763\u6240\u5e26\u6765\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u63a8\u7406\u6a21\u578b\u7684\u5185\u90e8\u4fe1\u53f7\u6765\u63d0\u9ad8\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u6f14\u793a\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u63a8\u7406\u6a21\u578b\u7684\u5185\u90e8\u4fe1\u53f7\u6765\u63d0\u9ad8\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u589e\u5f3a\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.02178", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02178", "abs": "https://arxiv.org/abs/2508.02178", "authors": ["Jialiang Hong", "Taihang Zhen", "Kai Chen", "Jiaheng Liu", "Wenpeng Zhu", "Jing Huo", "Yang Gao", "Depeng Wang", "Haitao Wan", "Xi Yang", "Boyan Wang", "Fanyu Meng"], "title": "Reconsidering Overthinking: Penalizing Internal and External Redundancy in CoT Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) often produce excessively verbose reasoning\ntraces, a phenomenon known as overthinking, which hampers both efficiency and\ninterpretability. Prior works primarily address this issue by reducing response\nlength, without fully examining the underlying semantic structure of the\nreasoning process. In this paper, we revisit overthinking by decomposing it\ninto two distinct forms: internal redundancy, which consists of\nlow-contribution reasoning steps within the first correct solution (FCS), and\nexternal redundancy, which refers to unnecessary continuation after the FCS. To\nmitigate both forms, we propose a dual-penalty reinforcement learning\nframework. For internal redundancy, we adopt a sliding-window semantic analysis\nto penalize low-gain reasoning steps that contribute little toward reaching the\ncorrect answer. For external redundancy, we penalize its proportion beyond the\nFCS to encourage earlier termination. Our method significantly compresses\nreasoning traces with minimal accuracy loss, and generalizes effectively to\nout-of-domain tasks such as question answering and code generation. Crucially,\nwe find that external redundancy can be safely removed without degrading\nperformance, whereas internal redundancy must be reduced more cautiously to\navoid impairing correctness. These findings suggest that our method not only\nimproves reasoning efficiency but also enables implicit, semantic-aware control\nover Chain-of-Thought length, paving the way for more concise and interpretable\nLRMs.", "AI": {"tldr": "LRMs\u7ecf\u5e38\u4ea7\u751f\u5197\u957f\u63a8\u7406\u8fc7\u7a0b\uff0c\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u60e9\u7f5a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u7f13\u89e3\u5185\u90e8\u5197\u4f59\u548c\u5916\u90e8\u5197\u4f59\uff0c\u663e\u8457\u538b\u7f29\u63a8\u7406\u8fc7\u7a0b\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002\u5916\u90e8\u5197\u4f59\u53ef\u5b89\u5168\u79fb\u9664\uff0c\u5185\u90e8\u5197\u4f59\u9700\u614e\u91cd\u51cf\u5c11\u3002\u8be5\u65b9\u6cd5\u4e3a\u66f4\u7b80\u6d01\u548c\u53ef\u89e3\u91ca\u7684LRMs\u94fa\u5e73\u9053\u8def\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u901a\u8fc7\u51cf\u5c11\u56de\u7b54\u957f\u5ea6\u6765\u89e3\u51b3LRMs\u4ea7\u751f\u5197\u957f\u63a8\u7406\u8fc7\u7a0b\u7684\u95ee\u9898\uff0c\u4f46\u672a\u5b8c\u5168\u7814\u7a76\u63a8\u7406\u8fc7\u7a0b\u7684\u5e95\u5c42\u8bed\u4e49\u7ed3\u6784\u3002\u56e0\u6b64\uff0c\u672c\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u8fc7\u5ea6\u601d\u8003\uff0c\u5e76\u63d0\u51fa\u4e86\u5185\u90e8\u5197\u4f59\u548c\u5916\u90e8\u5197\u4f59\u4e24\u79cd\u4e0d\u540c\u5f62\u5f0f\u7684\u6982\u5ff5\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5c06\u8fc7\u5ea6\u63a8\u7406\u62c6\u5206\u4e3a\u5185\u90e8\u5197\u4f59\u548c\u5916\u90e8\u5197\u4f59\u4e24\u79cd\u5f62\u5f0f\uff0c\u63d0\u51fa\u4e86\u53cc\u60e9\u7f5a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u7f13\u89e3\u8fd9\u4e24\u79cd\u5f62\u5f0f\u3002\u5bf9\u4e8e\u5185\u90e8\u5197\u4f59\uff0c\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u8bed\u4e49\u5206\u6790\u60e9\u7f5a\u90a3\u4e9b\u5bf9\u8fbe\u5230\u6b63\u786e\u7b54\u6848\u6ca1\u6709\u8d21\u732e\u7684\u63a8\u7406\u6b65\u9aa4\u3002\u5bf9\u4e8e\u5916\u90e8\u5197\u4f59\uff0c\u901a\u8fc7\u60e9\u7f5aFCS\u540e\u7684\u4e0d\u5fc5\u8981\u5ef6\u7eed\u6765\u9f13\u52b1\u8f83\u65e9\u505c\u6b62\u3002", "result": "\u7814\u7a76\u8868\u660e\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u538b\u7f29\u63a8\u7406\u8fc7\u7a0b\u800c\u51e0\u4e4e\u4e0d\u635f\u5931\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u6709\u826f\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002\u5916\u90e8\u5197\u4f59\u7684\u79fb\u9664\u4e0d\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u4f46\u5185\u90e8\u5197\u4f59\u9700\u8c28\u614e\u51cf\u5c11\u4ee5\u907f\u514d\u5f71\u54cd\u6b63\u786e\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u60e9\u7f5a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u89e3\u51b3LRMs\u4ea7\u751f\u5197\u957f\u63a8\u7406\u8fc7\u7a0b\u7684\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u538b\u7f29\u63a8\u7406\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u8d85\u9886\u57df\u4efb\u52a1\u4e2d\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u5916\u90e8\u5197\u4f59\u53ef\u4ee5\u5b89\u5168\u79fb\u9664\u800c\u4e0d\u5f71\u54cd\u6027\u80fd\uff0c\u4f46\u5185\u90e8\u5197\u4f59\u9700\u8c28\u614e\u51cf\u5c11\u4ee5\u907f\u514d\u5f71\u54cd\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\uff0c\u8fd8\u5b9e\u73b0\u4e86\u5bf9Chain-of-Thought\u957f\u5ea6\u7684\u9690\u5f0f\u3001\u8bed\u4e49\u611f\u77e5\u63a7\u5236\uff0c\u4e3a\u66f4\u7b80\u6d01\u548c\u53ef\u89e3\u91ca\u7684LRMs\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.02191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02191", "abs": "https://arxiv.org/abs/2508.02191", "authors": ["Boheng Liu", "Ziyu Li", "Xia Wu"], "title": "Neuromorphic Computing with Multi-Frequency Oscillations: A Bio-Inspired Approach to Artificial Intelligence", "comment": null, "summary": "Despite remarkable capabilities, artificial neural networks exhibit limited\nflexible, generalizable intelligence. This limitation stems from their\nfundamental divergence from biological cognition that overlooks both neural\nregions' functional specialization and the temporal dynamics critical for\ncoordinating these specialized systems. We propose a tripartite brain-inspired\narchitecture comprising functionally specialized perceptual, auxiliary, and\nexecutive systems. Moreover, the integration of temporal dynamics through the\nsimulation of multi-frequency neural oscillation and synaptic dynamic\nadaptation mechanisms enhances the architecture, thereby enabling more flexible\nand efficient artificial cognition. Initial evaluations demonstrate superior\nperformance compared to state-of-the-art temporal processing approaches, with\n2.18\\% accuracy improvements while reducing required computation iterations by\n48.44\\%, and achieving higher correlation with human confidence patterns.\nThough currently demonstrated on visual processing tasks, this architecture\nestablishes a theoretical foundation for brain-like intelligence across\ncognitive domains, potentially bridging the gap between artificial and\nbiological intelligence.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u8111\u542f\u53d1\u5f0f\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u62df\u591a\u9891\u795e\u7ecf\u632f\u8361\u548c\u7a81\u89e6\u52a8\u529b\u5b66\u9002\u5e94\u673a\u5236\uff0c\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u521d\u6b65\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5728\u89c6\u89c9\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u5728\u7075\u6d3b\u6027\u548c\u6cdb\u5316\u667a\u80fd\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u4e0e\u751f\u7269\u8ba4\u77e5\u5b58\u5728\u6839\u672c\u5206\u6b67\uff0c\u5ffd\u89c6\u4e86\u795e\u7ecf\u533a\u57df\u7684\u529f\u80fd\u4e13\u95e8\u5316\u548c\u534f\u8c03\u8fd9\u4e9b\u4e13\u95e8\u7cfb\u7edf\u6240\u5fc5\u9700\u7684\u65f6\u95f4\u52a8\u6001\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u66f4\u63a5\u8fd1\u751f\u7269\u5927\u8111\u7684\u67b6\u6784\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u8111\u542f\u53d1\u5f0f\u67b6\u6784\uff0c\u5305\u62ec\u529f\u80fd\u4e13\u95e8\u5316\u7684\u611f\u77e5\u3001\u8f85\u52a9\u548c\u6267\u884c\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u591a\u9891\u795e\u7ecf\u632f\u8361\u548c\u7a81\u89e6\u52a8\u6001\u9002\u5e94\u673a\u5236\u6765\u96c6\u6210\u65f6\u95f4\u52a8\u6001\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u67b6\u6784\u5728\u89c6\u89c9\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5904\u7406\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e862.18\uff05\uff0c\u8ba1\u7b97\u8fed\u4ee3\u6b21\u6570\u51cf\u5c11\u4e8648.44\uff05\uff0c\u5e76\u4e14\u4e0e\u4eba\u7c7b\u4fe1\u5fc3\u6a21\u5f0f\u7684\u76f8\u5173\u6027\u66f4\u9ad8\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u4e09\u90e8\u5206\u5927\u8111\u542f\u53d1\u5f0f\u67b6\u6784\uff0c\u6a21\u62df\u591a\u9891\u795e\u7ecf\u632f\u8361\u548c\u7a81\u89e6\u52a8\u529b\u5b66\u9002\u5e94\u673a\u5236\uff0c\u63d0\u9ad8\u4eba\u5de5\u667a\u80fd\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002\u521d\u6b65\u8bc4\u4f30\u8868\u660e\uff0c\u5728\u89c6\u89c9\u5904\u7406\u4efb\u52a1\u4e2d\uff0c\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5904\u7406\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e862.18\uff05\uff0c\u8ba1\u7b97\u8fed\u4ee3\u6b21\u6570\u51cf\u5c11\u4e8648.44\uff05\uff0c\u5e76\u4e14\u4e0e\u4eba\u7c7b\u4fe1\u5fc3\u6a21\u5f0f\u7684\u76f8\u5173\u6027\u66f4\u9ad8\u3002\u8fd9\u79cd\u67b6\u6784\u4e3a\u5927\u8111\u5f0f\u667a\u80fd\u5728\u8ba4\u77e5\u9886\u57df\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u6709\u53ef\u80fd\u5f25\u5408\u4eba\u5de5\u548c\u751f\u7269\u667a\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.02197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02197", "abs": "https://arxiv.org/abs/2508.02197", "authors": ["Wouter W. L. Nuijten", "Mykola Lukashchuk", "Thijs van de Laar", "Bert de Vries"], "title": "A Message Passing Realization of Expected Free Energy Minimization", "comment": null, "summary": "We present a message passing approach to Expected Free Energy (EFE)\nminimization on factor graphs, based on the theory introduced in\narXiv:2504.14898. By reformulating EFE minimization as Variational Free Energy\nminimization with epistemic priors, we transform a combinatorial search problem\ninto a tractable inference problem solvable through standard variational\ntechniques. Applying our message passing method to factorized state-space\nmodels enables efficient policy inference. We evaluate our method on\nenvironments with epistemic uncertainty: a stochastic gridworld and a partially\nobservable Minigrid task. Agents using our approach consistently outperform\nconventional KL-control agents on these tasks, showing more robust planning and\nefficient exploration under uncertainty. In the stochastic gridworld\nenvironment, EFE-minimizing agents avoid risky paths, while in the partially\nobservable minigrid setting, they conduct more systematic information-seeking.\nThis approach bridges active inference theory with practical implementations,\nproviding empirical evidence for the efficiency of epistemic priors in\nartificial agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u671f\u671b\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u53d8\u5206\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5e76\u5e94\u7528\u4e8e\u56e0\u5b50\u5316\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u8fdb\u884c\u7b56\u7565\u63a8\u65ad\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5177\u6709\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u73af\u5883\u4e2d\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u7684\u4ee3\u7406\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684KL\u63a7\u5236\u4ee3\u7406\uff0c\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u89c4\u5212\u548c\u63a2\u7d22\u6027\u80fd\u3002\u7814\u7a76\u8005\u6210\u529f\u5c06\u7406\u8bba\u4e0e\u5b9e\u8df5\u7ed3\u5408\uff0c\u4e3a\u8ba4\u77e5\u5148\u9a8c\u5728\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u4e2d\u7684\u6709\u6548\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "motivation": "\u7814\u7a76\u8005\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u671f\u671b\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u95ee\u9898\u7684\u56f0\u96be\u6027\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u66f4\u6613\u5904\u7406\u7684\u53d8\u5206\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u8ba4\u77e5\u5148\u9a8c\uff0c\u4ed6\u4eec\u5e0c\u671b\u80fd\u591f\u5b9e\u73b0\u5bf9\u590d\u6742\u7ec4\u5408\u641c\u7d22\u95ee\u9898\u7684\u6709\u6548\u63a8\u65ad\uff0c\u4ece\u800c\u6539\u8fdb\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u89c4\u5212\u548c\u63a2\u7d22\u6027\u80fd\u3002\u4ed6\u4eec\u7684\u76ee\u6807\u662f\u63a2\u7d22\u4e3b\u52a8\u63a8\u65ad\u7406\u8bba\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u5e76\u4e3a\u8ba4\u77e5\u5148\u9a8c\u5728\u4ee3\u7406\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u5b9e\u8df5\u8bc1\u636e\u3002", "method": "\u8be5\u8bba\u6587\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u65b9\u5f0f\u8fdb\u884c\u671f\u671b\u81ea\u7531\u80fd\u6700\u5c0f\u5316\uff0c\u5728\u56e0\u5b50\u56fe\u4e0a\u5b9e\u73b0\u4e86\u53d8\u5206\u81ea\u7531\u80fd\u6700\u5c0f\u5316\uff0c\u5e76\u4f7f\u7528\u8ba4\u77e5\u5148\u9a8c\u8f6c\u6362\u7ec4\u5408\u641c\u7d22\u95ee\u9898\u4e3a\u53ef\u63a8\u7406\u7684\u95ee\u9898\u3002\u5728\u56e0\u5b50\u5316\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e0a\u5e94\u7528\u4e86\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\u8fdb\u884c\u7b56\u7565\u63a8\u65ad\uff0c\u5e76\u5728\u5177\u6709\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u3002\u7814\u7a76\u8005\u5c06\u7406\u8bba\u8f6c\u5316\u4e3a\u5b9e\u9645\u5b9e\u73b0\uff0c\u901a\u8fc7\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u8005\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4ed6\u4eec\u7684\u65b9\u6cd5\u5728\u5177\u6709\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u53d1\u73b0\u4f7f\u7528\u5176\u65b9\u6cd5\u7684\u4ee3\u7406\u5728\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u7684KL\u63a7\u5236\u4ee3\u7406\u5177\u6709\u66f4\u597d\u7684\u89c4\u5212\u548c\u63a2\u7d22\u80fd\u529b\u3002\u5177\u4f53\u4f53\u73b0\u5728\u968f\u673a\u7f51\u683c\u73af\u5883\u4e2d\u907f\u514d\u98ce\u9669\u8def\u5f84\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u5bdf\u7684Minigrid\u573a\u666f\u4e2d\u5c55\u73b0\u66f4\u7cfb\u7edf\u6027\u7684\u4fe1\u606f\u641c\u7d22\u884c\u4e3a\u3002\u6700\u7ec8\uff0c\u4ed6\u4eec\u8bc1\u660e\u4e86\u8ba4\u77e5\u5148\u9a8c\u5728\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u4e2d\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u671f\u671b\u81ea\u7531\u80fd\uff08EFE\uff09\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u91cd\u65b0\u8868\u8ff0\u4e3a\u5177\u6709\u8ba4\u77e5\u5148\u9a8c\u7684\u53d8\u5206\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u95ee\u9898\u3002\u7814\u7a76\u8005\u5c06\u7ec4\u5408\u641c\u7d22\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u901a\u8fc7\u6807\u51c6\u53d8\u5206\u6280\u672f\u89e3\u51b3\u7684\u53ef\u5904\u7406\u63a8\u65ad\u95ee\u9898\u3002\u4ed6\u4eec\u5728\u56e0\u5b50\u5316\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e0a\u5e94\u7528\u4e86\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u7b56\u7565\u63a8\u65ad\u3002\u901a\u8fc7\u5728\u5177\u6709\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u73af\u5883\u4e2d\u8bc4\u4f30\u4ed6\u4eec\u7684\u65b9\u6cd5\uff0c\u7814\u7a76\u8005\u53d1\u73b0\u4f7f\u7528\u4ed6\u4eec\u65b9\u6cd5\u7684\u4ee3\u7406\u5728\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edf\u7684KL\u63a7\u5236\u4ee3\u7406\uff0c\u5728\u9762\u5bf9\u4e0d\u786e\u5b9a\u6027\u65f6\u8868\u73b0\u51fa\u66f4\u52a0\u7a33\u5065\u7684\u89c4\u5212\u548c\u9ad8\u6548\u7684\u63a2\u7d22\u3002\u5728\u968f\u673a\u7f51\u683c\u73af\u5883\u4e2d\uff0cEFE\u6700\u5c0f\u5316\u4ee3\u7406\u907f\u5f00\u4e86\u98ce\u9669\u8def\u5f84\uff1b\u800c\u5728\u90e8\u5206\u53ef\u89c2\u5bdf\u7684Minigrid\u573a\u666f\u4e2d\uff0c\u4ed6\u4eec\u5c55\u73b0\u51fa\u66f4\u52a0\u7cfb\u7edf\u6027\u7684\u4fe1\u606f\u641c\u7d22\u884c\u4e3a\u3002\u8fd9\u4e00\u65b9\u6cd5\u5c06\u4e3b\u52a8\u63a8\u65ad\u7406\u8bba\u4e0e\u5b9e\u9645\u5b9e\u73b0\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u8ba4\u77e5\u5148\u9a8c\u5728\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u4e2d\u7684\u9ad8\u6548\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc1\u636e\u3002"}}
{"id": "2508.02269", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02269", "abs": "https://arxiv.org/abs/2508.02269", "authors": ["Dewi Sid William Gould", "George De Ath", "Ben Carvell", "Nick Pepper"], "title": "AirTrafficGen: Configurable Air Traffic Scenario Generation with Large Language Models", "comment": "7 pages and appendices", "summary": "The manual design of scenarios for Air Traffic Control (ATC) training is a\ndemanding and time-consuming bottleneck that limits the diversity of\nsimulations available to controllers. To address this, we introduce a novel,\nend-to-end approach, AirTrafficGen, that leverages large language models (LLMs)\nto automate and control the generation of complex ATC scenarios. Our method\nuses a purpose-built, graph-based representation to encode sector topology\n(including airspace geometry, routes, and fixes) into a format LLMs can\nprocess. Through rigorous benchmarking, we show that state-of-the-art models\nlike Gemini 2.5 Pro and OpenAI o3 can generate high-traffic scenarios whilst\nmaintaining operational realism. Our engineered prompting enables fine-grained\ncontrol over interaction presence, type, and location. Initial findings suggest\nthese models are also capable of iterative refinement, correcting flawed\nscenarios based on simple textual feedback. This approach provides a scalable\nalternative to manual scenario design, addressing the need for a greater volume\nand variety of ATC training and validation simulations. More broadly, this work\nshowcases the potential of LLMs for complex planning in safety-critical\ndomains.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u751f\u6210\u590d\u6742ATC\u60c5\u666f\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3aAirTrafficGen\u3002\u7ecf\u8fc7\u6d4b\u8bd5\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u6d41\u91cf\u60c5\u666f\u5e76\u4fdd\u6301\u5b9e\u9645\u6027\uff0c\u540c\u65f6\u4e5f\u53ef\u901a\u8fc7\u7b80\u5355\u6587\u672c\u53cd\u9988\u8fdb\u884c\u6539\u8fdb\u3002\u8fd9\u79cd\u65b9\u6cd5\u63d0\u4f9b\u4e86\u624b\u52a8\u751f\u6210\u60c5\u666f\u7684\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u4e86LLMs\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u89c4\u5212\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u624b\u52a8\u8bbe\u8ba1ATC\u57f9\u8bad\u60c5\u666f\u662f\u4e00\u9879\u7e41\u91cd\u4e14\u8017\u65f6\u7684\u5de5\u4f5c\uff0c\u9650\u5236\u4e86\u63a7\u5236\u5458\u53ef\u7528\u6a21\u62df\u7684\u591a\u6837\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7aef\u5230\u7aef\u65b9\u6cd5AirTrafficGen\uff0c\u5229\u7528LLMs\u81ea\u52a8\u5316\u548c\u63a7\u5236\u751f\u6210\u590d\u6742\u7684ATC\u60c5\u666f\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aAirTrafficGen\u7684\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u5229\u7528\u56fe\u5f62\u5316\u8868\u793a\u6765\u7f16\u7801ATC\u60c5\u666f\u7684\u90e8\u95e8\u62d3\u6251\u7ed3\u6784\uff0c\u901a\u8fc7LLMs\u8fdb\u884c\u5904\u7406\u3002\u901a\u8fc7Gemini 2.5 Pro\u548cOpenAI o3\u7b49\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u751f\u6210\u9ad8\u6d41\u91cf\u7684\u60c5\u666f\u5e76\u4fdd\u6301\u8fd0\u8425\u5b9e\u9645\u6027\u3002\u5de5\u7a0b\u5316\u63d0\u793a\u5b9e\u73b0\u4e86\u5bf9\u4e92\u52a8\u5b58\u5728\u3001\u7c7b\u578b\u548c\u4f4d\u7f6e\u7684\u7cbe\u7ec6\u63a7\u5236\u3002\u521d\u6b65\u7814\u7a76\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u6587\u672c\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\uff0c\u7ea0\u6b63\u6709\u7f3a\u9677\u7684\u60c5\u666f\u3002", "result": "\u7ecf\u8fc7\u4e25\u683c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u793a\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u5316\u751f\u6210\u9ad8\u6d41\u91cfATC\u60c5\u666f\u5e76\u7ef4\u6301\u5176\u8fd0\u8425\u5b9e\u9645\u6027\u3002\u5de5\u7a0b\u5316\u63d0\u793a\u5141\u8bb8\u7ec6\u7c92\u5ea6\u63a7\u5236\u4e92\u52a8\u5b58\u5728\u3001\u7c7b\u578b\u548c\u4f4d\u7f6e\u3002\u521d\u6b65\u7ed3\u679c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u7b80\u5355\u7684\u6587\u672c\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\uff0c\u7ea0\u6b63\u6709\u7f3a\u9677\u7684\u60c5\u666f\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u5316\u548c\u63a7\u5236\u751f\u6210\u590d\u6742\u7684\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\uff08ATC\uff09\u60c5\u666f\u7684\u65b0\u65b9\u6cd5\u3002\u7ecf\u8fc7\u4e25\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u793aGemini 2.5 Pro\u548cOpenAI o3\u7b49\u6700\u65b0\u6a21\u578b\u80fd\u591f\u751f\u6210\u9ad8\u6d41\u91cf\u7684\u60c5\u666f\uff0c\u5e76\u4fdd\u6301\u8fd0\u8425\u5b9e\u9645\u6027\u3002\u5de5\u7a0b\u5316\u7684\u63d0\u793a\u4f7f\u5f97\u80fd\u591f\u5bf9\u4e92\u52a8\u7684\u5b58\u5728\u3001\u7c7b\u578b\u548c\u4f4d\u7f6e\u8fdb\u884c\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002\u521d\u6b65\u53d1\u73b0\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u4e5f\u80fd\u591f\u901a\u8fc7\u7b80\u5355\u7684\u6587\u672c\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\uff0c\u7ea0\u6b63\u6709\u7f3a\u9677\u7684\u60c5\u666f\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u624b\u52a8\u751f\u6210\u60c5\u666f\u7684\u65b9\u5f0f\uff0c\u6ee1\u8db3\u4e86ATC\u57f9\u8bad\u548c\u9a8c\u8bc1\u6a21\u62df\u7684\u66f4\u5927\u91cf\u548c\u591a\u6837\u6027\u7684\u9700\u6c42\u3002\u66f4\u5e7f\u6cdb\u5730\uff0c\u672c\u7814\u7a76\u5c55\u793a\u4e86LLMs\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u590d\u6742\u89c4\u5212\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.02292", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02292", "abs": "https://arxiv.org/abs/2508.02292", "authors": ["Wentao Zhang", "Yilei Zhao", "Chuqiao Zong", "Xinrun Wang", "Bo An"], "title": "FinWorld: An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment", "comment": null, "summary": "Financial AI holds great promise for transforming modern finance, with the\npotential to support a wide range of tasks such as market forecasting,\nportfolio management, quantitative trading, and automated analysis. However,\nexisting platforms remain limited in task coverage, lack robust multimodal data\nintegration, and offer insufficient support for the training and deployment of\nlarge language models (LLMs). In response to these limitations, we present\nFinWorld, an all-in-one open-source platform that provides end-to-end support\nfor the entire financial AI workflow, from data acquisition to experimentation\nand deployment. FinWorld distinguishes itself through native integration of\nheterogeneous financial data, unified support for diverse AI paradigms, and\nadvanced agent automation, enabling seamless development and deployment.\nLeveraging data from 2 representative markets, 4 stock pools, and over 800\nmillion financial data points, we conduct comprehensive experiments on 4 key\nfinancial AI tasks. These experiments systematically evaluate deep learning and\nreinforcement learning algorithms, with particular emphasis on RL-based\nfinetuning for LLMs and LLM Agents. The empirical results demonstrate that\nFinWorld significantly enhances reproducibility, supports transparent\nbenchmarking, and streamlines deployment, thereby providing a strong foundation\nfor future research and real-world applications. Code is available at\nGithub~\\footnote{https://github.com/DVampire/FinWorld}.", "AI": {"tldr": "FinWorld is an open-source platform that addresses limitations of existing financial AI platforms by providing comprehensive end-to-end support for financial AI workflow. It integrates heterogeneous financial data, supports diverse AI paradigms, and includes advanced agent automation. Empirical results demonstrate improved reproducibility, transparent benchmarking, and streamlined deployment.", "motivation": "Existing financial AI platforms have limitations in task coverage, data integration, and support for large language models. The aim was to address these limitations by creating a comprehensive platform that offers end-to-end support for financial AI workflow.", "method": "Developed an open-source platform, FinWorld, that integrates heterogeneous financial data, supports diverse AI paradigms, and includes advanced agent automation. Conducted experiments on key financial AI tasks using deep learning and reinforcement learning algorithms, focusing on finetuning for large language models (LLMs) and LLM Agents.", "result": "Empirical results show that FinWorld significantly improves reproducibility, supports transparent benchmarking, and streamlines deployment. It leverages data from representative markets and stock pools, conducting experiments on key financial AI tasks.", "conclusion": "FinWorld platform provides end-to-end support for financial AI workflow, enhancing reproducibility, benchmarking transparency, and deployment efficiency. It serves as a strong foundation for future research and real-world applications."}}
{"id": "2508.02344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02344", "abs": "https://arxiv.org/abs/2508.02344", "authors": ["Xingchen Zou", "Yuhao Yang", "Zheng Chen", "Xixuan Hao", "Yiqi Chen", "Chao Huang", "Yuxuan Liang"], "title": "Traffic-R1: Reinforced LLMs Bring Human-Like Reasoning to Traffic Signal Control Systems", "comment": null, "summary": "Traffic signal control (TSC) is vital for mitigating congestion and\nsustaining urban mobility. In this paper, we introduce Traffic-R1, a foundation\nmodel with human-like reasoning for TSC systems. Our model is developed through\nself-exploration and iteration of reinforced large language models (LLMs) with\nexpert guidance in a simulated traffic environment. Compared to traditional\nreinforcement learning (RL) and recent LLM-based methods, Traffic-R1 offers\nthree significant advantages. First, Traffic-R1 delivers zero-shot\ngeneralisation, transferring unchanged to new road networks and\nout-of-distribution incidents by utilizing its internal traffic control\npolicies and human-like reasoning. Second, its 3B-parameter architecture is\nlightweight enough for real-time inference on mobile-class chips, enabling\nlarge-scale edge deployment. Third, Traffic-R1 provides an explainable TSC\nprocess and facilitates multi-intersection communication through its\nself-iteration and a new synchronous communication network. Extensive\nbenchmarks demonstrate that Traffic-R1 sets a new state of the art,\noutperforming strong baselines and training-intensive RL controllers. In\npractice, the model now manages signals for more than 55,000 drivers daily,\nshortening average queues by over 5% and halving operator workload. Our\ncheckpoint is available at https://huggingface.co/Season998/Traffic-R1.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Traffic-R1\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709\u7c7b\u4eba\u63a8\u7406\u80fd\u529b\u7684\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7cfb\u7edf\u6a21\u578b\u3002\u4e0e\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u548c\u6700\u8fd1\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cTraffic-R1\u5177\u6709\u4e09\u4e2a\u4e3b\u8981\u4f18\u52bf\uff1a\u9002\u7528\u4e8e\u65b0\u9053\u8def\u7f51\u7edc\u548c\u4e0d\u540c\u60c5\u51b5\u7684\u96f6-shot\u6cdb\u5316\u3001\u8f7b\u91cf\u7ea7\u67b6\u6784\u652f\u6301\u5b9e\u65f6\u63a8\u7406\u3001\u53ef\u89e3\u91ca\u7684\u4fe1\u53f7\u63a7\u5236\u6d41\u7a0b\u548c\u591a\u8def\u53e3\u901a\u4fe1\u80fd\u529b\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cTraffic-R1\u7ba1\u7406\u8d85\u8fc755000\u540d\u53f8\u673a\u7684\u4fe1\u53f7\uff0c\u5e73\u5747\u6392\u961f\u957f\u5ea6\u7f29\u77ed\u8d85\u8fc75%\uff0c\u51cf\u8f7b\u64cd\u4f5c\u5458\u7684\u5de5\u4f5c\u8d1f\u62c5\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u5bf9\u7f13\u89e3\u4ea4\u901a\u62e5\u5835\u548c\u7ef4\u6301\u57ce\u5e02\u6d41\u52a8\u6027\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c1d\u8bd5\u901a\u8fc7\u5f15\u5165Traffic-R1\u6a21\u578b\u6765\u6539\u8fdb\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u81ea\u6211\u63a2\u7d22\u548c\u5728\u6a21\u62df\u4ea4\u901a\u73af\u5883\u4e2d\u5bf9\u5f3a\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u8fed\u4ee3\u5f00\u53d1Traffic-R1\u6a21\u578b\uff0c\u5e76\u5229\u7528\u5185\u90e8\u4ea4\u901a\u63a7\u5236\u7b56\u7565\u548c\u4eba\u7c7b\u63a8\u7406\u65b9\u6cd5\u5b9e\u73b0\u4e86\u96f6shot\u6cdb\u5316\uff0c\u8bbe\u8ba1\u4e86\u8f7b\u91cf\u7ea73B\u53c2\u6570\u67b6\u6784\u4ee5\u652f\u6301\u5b9e\u65f6\u63a8\u7406\uff0c\u901a\u8fc7\u81ea\u6211\u8fed\u4ee3\u548c\u540c\u6b65\u901a\u4fe1\u7f51\u7edc\u5b9e\u73b0\u591a\u8def\u53e3\u901a\u4fe1\u3002", "result": "Traffic-R1\u6a21\u578b\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u5f3a\u699c\u5355\u57fa\u51c6\u548c\u8bad\u7ec3\u5bc6\u96c6\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u3002\u5728\u5b9e\u8df5\u4e2d\uff0c\u8be5\u6a21\u578b\u6bcf\u5929\u7ba1\u7406\u8d85\u8fc755000\u540d\u53f8\u673a\u7684\u4fe1\u53f7\uff0c\u5e73\u5747\u6392\u961f\u957f\u5ea6\u7f29\u77ed\u8d85\u8fc75%\uff0c\u51cf\u5c11\u64cd\u4f5c\u5458\u7684\u5de5\u4f5c\u8d1f\u62c5\u3002", "conclusion": "Traffic-R1\u662f\u4e00\u79cd\u5177\u6709\u7c7b\u4eba\u63a8\u7406\u80fd\u529b\u7684\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7cfb\u7edf\u6a21\u578b\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u4e09\u4e2a\u663e\u8457\u4f18\u52bf\uff1a\u96f6-shot\u6cdb\u5316\u80fd\u529b\u3001\u8f7b\u91cf\u7ea73B\u53c2\u6570\u67b6\u6784\u652f\u6301\u5b9e\u65f6\u63a8\u7406\u3001\u53ef\u89e3\u91ca\u7684\u4fe1\u53f7\u63a7\u5236\u6d41\u7a0b\u5e76\u901a\u8fc7\u591a\u4ea4\u53c9\u53e3\u901a\u4fe1\u7f51\u7edc\u5b9e\u73b0\u591a\u8def\u53e3\u901a\u4fe1\u3002\u8be5\u6a21\u578b\u5728\u63a8\u8350\u699c\u5355\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7ba1\u7406\u8d85\u8fc755000\u540d\u53f8\u673a\u7684\u4fe1\u53f7\uff0c\u5e73\u5747\u6392\u961f\u957f\u5ea6\u7f29\u77ed\u8d85\u8fc75%\uff0c\u51cf\u5c11\u4e86\u64cd\u4f5c\u5458\u7684\u5de5\u4f5c\u8d1f\u62c5\u3002"}}
{"id": "2508.02427", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.02427", "abs": "https://arxiv.org/abs/2508.02427", "authors": ["Tung-Thuy Pham", "Duy-Quan Luong", "Minh-Quan Duong", "Trung-Hieu Nguyen", "Thu-Trang Nguyen", "Son Nguyen", "Hieu Dinh Vo"], "title": "CABENCH: Benchmarking Composable AI for Solving Complex Tasks through Composing Ready-to-Use Models", "comment": null, "summary": "Composable AI offers a scalable and effective paradigm for tackling complex\nAI tasks by decomposing them into sub-tasks and solving each sub-task using\nready-to-use well-trained models. However, systematically evaluating methods\nunder this setting remains largely unexplored. In this paper, we introduce\nCABENCH, the first public benchmark comprising 70 realistic composable AI\ntasks, along with a curated pool of 700 models across multiple modalities and\ndomains. We also propose an evaluation framework to enable end-to-end\nassessment of composable AI solutions. To establish initial baselines, we\nprovide human-designed reference solutions and compare their performance with\ntwo LLM-based approaches. Our results illustrate the promise of composable AI\nin addressing complex real-world problems while highlighting the need for\nmethods that can fully unlock its potential by automatically generating\neffective execution pipelines.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CABENCH\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u89e3\u51b3\u590d\u6742AI\u4efb\u52a1\u3002\u63d0\u4f9b\u4e86\u591a\u79cd\u6a21\u6001\u548c\u9886\u57df\u7684\u6a21\u578b\u5e93\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8bc4\u4f30\u6846\u67b6\u7528\u4e8e\u7aef\u5230\u7aef\u8bc4\u4f30\u3002\u4f5c\u8005\u5efa\u7acb\u4e86\u521d\u6b65\u57fa\u51c6\u7ebf\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\u53ef\u7ec4\u5408AI\u6709\u6f5c\u529b\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u81ea\u52a8\u751f\u6210\u6267\u884c\u6d41\u6c34\u7ebf\u7684\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5bf9\u4e8e\u53ef\u7ec4\u5408AI\u89e3\u51b3\u65b9\u6848\u7684\u7cfb\u7edf\u8bc4\u4f30\u4ecd\u7136\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5f15\u5165CABENCH\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u63d0\u4f9b\u7efc\u5408\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u6a21\u578b\u5e93\uff0c\u5c55\u793a\u53ef\u7ec4\u5408AI\u5728\u89e3\u51b3\u5b9e\u9645\u590d\u6742\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\uff0c\u5e76\u5f3a\u8c03\u81ea\u52a8\u751f\u6210\u6267\u884c\u6d41\u6c34\u7ebf\u7684\u5fc5\u8981\u6027\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86CABENCH\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u4f9b\u4e86\u591a\u79cd\u6a21\u6001\u548c\u9886\u57df\u7684\u6a21\u578b\u5e93\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8bc4\u4f30\u6846\u67b6\u7528\u4e8e\u7aef\u5230\u7aef\u8bc4\u4f30\u3002\u4f5c\u8005\u5efa\u7acb\u4e86\u521d\u59cb\u57fa\u51c6\u7ebf\uff0c\u5e76\u6bd4\u8f83\u4e86\u4eba\u5458\u8bbe\u8ba1\u7684\u53c2\u8003\u89e3\u51b3\u65b9\u6848\u4e0e\u4e24\u79cdLLM-based\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u8be5\u7814\u7a76\uff0c\u4f5c\u8005\u8bc1\u5b9e\u4e86\u53ef\u7ec4\u5408AI\u5728\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u9700\u8981\u81ea\u52a8\u751f\u6210\u6709\u6548\u6267\u884c\u6d41\u6c34\u7ebf\u7684\u65b9\u6cd5\u3002\u7ed3\u679c\u8868\u660e\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u6846\u67b6\u53ef\u4ee5\u6709\u6548\u8bc4\u4f30\u53ef\u7ec4\u5408AI\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86CABENCH\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5305\u542b70\u4e2a\u903c\u771f\u53ef\u7ec4\u5408AI\u4efb\u52a1\u7684\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u3002\u63d0\u4f9b\u4e86\u4e00\u4e2a\u96c6\u6210\u4e86\u591a\u79cd\u6a21\u6001\u548c\u9886\u57df\u7684700\u4e2a\u6a21\u578b\u7684\u5e93\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u8bc4\u4f30\u6846\u67b6\u4ee5\u5b9e\u73b0\u5bf9\u53ef\u7ec4\u5408AI\u89e3\u51b3\u65b9\u6848\u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u3002\u901a\u8fc7\u63d0\u4f9b\u4eba\u5458\u8bbe\u8ba1\u7684\u53c2\u8003\u89e3\u51b3\u65b9\u6848\u5e76\u5c06\u5176\u6027\u80fd\u4e0e\u4e24\u79cd\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u4f5c\u8005\u5efa\u7acb\u4e86\u521d\u59cb\u57fa\u51c6\u7ebf\u3002\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u7ec4\u5408AI\u5728\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u65b9\u9762\u6709\u53d1\u5c55\u6f5c\u529b\uff0c\u4f46\u540c\u65f6\u4e5f\u51f8\u663e\u4e86\u9700\u8981\u80fd\u591f\u81ea\u52a8\u751f\u6210\u6709\u6548\u6267\u884c\u6d41\u6c34\u7ebf\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.02429", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02429", "abs": "https://arxiv.org/abs/2508.02429", "authors": ["Miaosen Luo", "Jiesen Long", "Zequn Li", "Yunying Yang", "Yuncheng Jiang", "Sijie Mai"], "title": "Multimodal Large Language Models for End-to-End Affective Computing: Benchmarking and Boosting with Generative Knowledge Prompting", "comment": null, "summary": "Multimodal Affective Computing (MAC) aims to recognize and interpret human\nemotions by integrating information from diverse modalities such as text,\nvideo, and audio. Recent advancements in Multimodal Large Language Models\n(MLLMs) have significantly reshaped the landscape of MAC by offering a unified\nframework for processing and aligning cross-modal information. However,\npractical challenges remain, including performance variability across complex\nMAC tasks and insufficient understanding of how architectural designs and data\ncharacteristics impact affective analysis. To address these gaps, we conduct a\nsystematic benchmark evaluation of state-of-the-art open-source MLLMs capable\nof concurrently processing audio, visual, and textual modalities across\nmultiple established MAC datasets. Our evaluation not only compares the\nperformance of these MLLMs but also provides actionable insights into model\noptimization by analyzing the influence of model architectures and dataset\nproperties. Furthermore, we propose a novel hybrid strategy that combines\ngenerative knowledge prompting with supervised fine-tuning to enhance MLLMs'\naffective computing capabilities. Experimental results demonstrate that this\nintegrated approach significantly improves performance across various MAC\ntasks, offering a promising avenue for future research and development in this\nfield. Our code is released on https://github.com/LuoMSen/MLLM-MAC.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u8fdb\u884c\u57fa\u51c6\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u7b56\u7565\u6539\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u8ba1\u7b97\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6027\u80fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u524d\u9014\u7684\u65b9\u5411\u3002", "motivation": "\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u65e8\u5728\u901a\u8fc7\u6574\u5408\u6765\u81ea\u6587\u672c\u3001\u89c6\u9891\u548c\u97f3\u9891\u7b49\u591a\u79cd\u6a21\u6001\u7684\u4fe1\u606f\u6765\u8bc6\u522b\u548c\u89e3\u91ca\u4eba\u7c7b\u60c5\u7eea\u3002\u5c3d\u7ba1\u6700\u8fd1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u663e\u8457\u6539\u53d8\u4e86\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u7684\u683c\u5c40\uff0c\u4f46\u5728\u590d\u6742\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u4efb\u52a1\u4e2d\u6027\u80fd\u53d8\u5316\u5927\u3001\u5bf9\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u7279\u6027\u5982\u4f55\u5f71\u54cd\u60c5\u611f\u5206\u6790\u7f3a\u4e4f\u8db3\u591f\u7406\u89e3\u7b49\u5b9e\u9645\u6311\u6218\u4ecd\u7136\u5b58\u5728\u3002\u56e0\u6b64\uff0c\u9700\u8981\u8fdb\u884c\u7cfb\u7edf\u7684\u57fa\u51c6\u8bc4\u4f30\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u8ba1\u7b97\u80fd\u529b\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6027\u57fa\u51c6\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u97f3\u9891\u3001\u89c6\u89c9\u548c\u6587\u672c\u7b49\u591a\u79cd\u6a21\u6001\u6570\u636e\u65f6\u7684\u6027\u80fd\uff0c\u5206\u6790\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u7279\u6027\u5bf9\u60c5\u611f\u5206\u6790\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u7b56\u7565\u7ed3\u5408\u751f\u6210\u6027\u77e5\u8bc6\u63d0\u793a\u548c\u76d1\u7763\u5fae\u8c03\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u8ba1\u7b97\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u6df7\u5408\u7b56\u7565\u663e\u8457\u6539\u5584\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002", "conclusion": "\u672c\u7814\u7a76\u5bf9\u5f00\u6e90\u7684\u6700\u5148\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u57fa\u51c6\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u6709\u5173\u6a21\u578b\u4f18\u5316\u7684\u53ef\u64cd\u4f5c\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u6df7\u5408\u7b56\u7565\uff0c\u7ed3\u5408\u4e86\u751f\u6210\u6027\u77e5\u8bc6\u63d0\u793a\u4e0e\u76d1\u7763\u5fae\u8c03\uff0c\u4ee5\u63d0\u9ad8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u8ba1\u7b97\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u96c6\u6210\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u4e0d\u540c\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u5728\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u548c\u53d1\u5c55\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u9014\u7684\u9014\u5f84\u3002"}}
{"id": "2508.02490", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02490", "abs": "https://arxiv.org/abs/2508.02490", "authors": ["Puyu Yang", "Laifa Tao", "Zijian Huang", "Haifei Liu", "Wenyan Cao", "Hao Ji", "Jianan Qiu", "Qixuan Huang", "Xuanyuan Su", "Yuhang Xie", "Jun Zhang", "Shangyu Li", "Chen Lu", "Zhixuan Lian"], "title": "PHM-Bench: A Domain-Specific Benchmarking Framework for Systematic Evaluation of Large Models in Prognostics and Health Management", "comment": null, "summary": "With the rapid advancement of generative artificial intelligence, large\nlanguage models (LLMs) are increasingly adopted in industrial domains, offering\nnew opportunities for Prognostics and Health Management (PHM). These models\nhelp address challenges such as high development costs, long deployment cycles,\nand limited generalizability. However, despite the growing synergy between PHM\nand LLMs, existing evaluation methodologies often fall short in structural\ncompleteness, dimensional comprehensiveness, and evaluation granularity. This\nhampers the in-depth integration of LLMs into the PHM domain. To address these\nlimitations, this study proposes PHM-Bench, a novel three-dimensional\nevaluation framework for PHM-oriented large models. Grounded in the triadic\nstructure of fundamental capability, core task, and entire lifecycle, PHM-Bench\nis tailored to the unique demands of PHM system engineering. It defines\nmulti-level evaluation metrics spanning knowledge comprehension, algorithmic\ngeneration, and task optimization. These metrics align with typical PHM tasks,\nincluding condition monitoring, fault diagnosis, RUL prediction, and\nmaintenance decision-making. Utilizing both curated case sets and publicly\navailable industrial datasets, our study enables multi-dimensional evaluation\nof general-purpose and domain-specific models across diverse PHM tasks.\nPHM-Bench establishes a methodological foundation for large-scale assessment of\nLLMs in PHM and offers a critical benchmark to guide the transition from\ngeneral-purpose to PHM-specialized models.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86PHM-Bench\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u65e8\u5728\u514b\u670d\u73b0\u6709PHM\u548cLLMs\u4e4b\u95f4\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3aPHM\u7cfb\u7edf\u5de5\u7a0b\u63d0\u4f9b\u5b9a\u5236\u5316\u8bc4\u4f30\u65b9\u6cd5\uff0c\u540c\u65f6\u4e3a\u4e0d\u540cPHM\u4efb\u52a1\u7684\u901a\u7528\u548c\u9886\u57df\u7279\u5b9a\u6a21\u578b\u63d0\u4f9b\u591a\u7ef4\u5ea6\u8bc4\u4f30\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cPHM-Bench\u4e3a\u5927\u89c4\u6a21\u8bc4\u4f30LLMs\u5728PHM\u9886\u57df\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u5f15\u5bfc\u901a\u7528\u6a21\u578b\u5411PHM\u4e13\u4e1a\u6a21\u578b\u7684\u8f6c\u53d8\u3002", "motivation": "\u968f\u7740\u751f\u6210\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5de5\u4e1a\u9886\u57df\u65e5\u76ca\u666e\u53ca\uff0c\u4e3aPrognostics and Health Management\uff08PHM\uff09\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u9047\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u5728\u7ed3\u6784\u5b8c\u6574\u6027\u3001\u7ef4\u5ea6\u5168\u9762\u6027\u548c\u8bc4\u4f30\u7c92\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u963b\u788d\u4e86LLMs\u6df1\u5ea6\u878d\u5165PHM\u9886\u57df\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86PHM-Bench\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3aLLMs\u5728PHM\u9886\u57df\u63d0\u4f9b\u4e86\u65b9\u6cd5\u5b66\u57fa\u7840\u548c\u8bc4\u4f30\u6807\u6746\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u63d0\u51faPHM-Bench\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u57fa\u672c\u80fd\u529b\u3001\u6838\u5fc3\u4efb\u52a1\u548c\u6574\u4e2a\u751f\u547d\u5468\u671f\u7684\u4e09\u5143\u7ed3\u6784\uff0c\u4e3aPHM\u7cfb\u7edf\u5de5\u7a0b\u7684\u72ec\u7279\u9700\u6c42\u91cf\u8eab\u5b9a\u5236\u3002\u6846\u67b6\u5b9a\u4e49\u4e86\u8de8\u77e5\u8bc6\u7406\u89e3\u3001\u7b97\u6cd5\u751f\u6210\u548c\u4efb\u52a1\u4f18\u5316\u7684\u591a\u5c42\u6b21\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u9002\u5e94\u5178\u578b\u7684PHM\u4efb\u52a1\uff0c\u5305\u62ec\u6761\u4ef6\u76d1\u6d4b\u3001\u6545\u969c\u8bca\u65ad\u3001RUL\u9884\u6d4b\u548c\u7ef4\u62a4\u51b3\u7b56\u3002\u540c\u65f6\u5229\u7528\u7cbe\u5fc3\u7b56\u5212\u7684\u6848\u4f8b\u96c6\u548c\u516c\u5f00\u53ef\u83b7\u5f97\u7684\u5de5\u4e1a\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u5bf9\u901a\u7528\u548c\u9886\u57df\u7279\u5b9a\u6a21\u578b\u5728\u591a\u6837\u7684PHM\u4efb\u52a1\u4e2d\u8fdb\u884c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7PHM-Bench\u6846\u67b6\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5bf9LLMs\u5728PHM\u9886\u57df\u7684\u5927\u89c4\u6a21\u8bc4\u4f30\uff0c\u4e3a\u4ece\u901a\u7528\u6a21\u578b\u5230PHM\u4e13\u4e1a\u6a21\u578b\u7684\u8fc7\u6e21\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6307\u5bfc\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86PHM-Bench\uff0c\u4e00\u4e2a\u9488\u5bf9PHM\u53d6\u5411\u7684\u5927\u578b\u6a21\u578b\u7684\u65b0\u9896\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5728\u7ed3\u6784\u5b8c\u6574\u6027\u3001\u7ef4\u5ea6\u5168\u9762\u6027\u548c\u8bc4\u4f30\u7c92\u5ea6\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u4fc3\u8fdbLLM\u5728PHM\u9886\u57df\u7684\u6df1\u5ea6\u6574\u5408\u5960\u5b9a\u65b9\u6cd5\u5b66\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6807\u6746\u4ee5\u5f15\u5bfc\u4ece\u901a\u7528\u5230PHM\u4e13\u4e1a\u6a21\u578b\u7684\u8fc7\u6e21\u3002"}}
{"id": "2508.02503", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02503", "abs": "https://arxiv.org/abs/2508.02503", "authors": ["Maxime Bouscary", "Saurabh Amin"], "title": "OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical Modeling", "comment": null, "summary": "LLM-based solvers have emerged as a promising means of automating problem\nmodeling and solving. However, they remain unreliable and often depend on\niterative repair loops that result in significant latency. We introduce\nOptiHive, an LLM-based framework that produces high-quality solvers for\noptimization problems from natural-language descriptions without iterative\nself-correction. OptiHive uses a single batched LLM query to generate diverse\ncomponents (solvers, problem instances, and validation tests) and filters out\nerroneous components to ensure fully interpretable outputs. Taking into account\nthe imperfection of the generated components, we employ a statistical model to\ninfer their true performance, enabling principled uncertainty quantification\nand solver selection. On tasks ranging from traditional optimization problems\nto challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive\nsignificantly outperforms baselines, increasing the optimality rate from 5\\% to\n92\\% on the most complex problems.", "AI": {"tldr": "OptiHive enhances LLM-based solvers by providing high-quality solutions without the need for iterative self-correction, resulting in a substantial increase in optimality rates on challenging optimization problems.", "motivation": "The motivation of this paper is to address the unreliability and latency issues of current LLM-based solvers by developing OptiHive, which ensures fully interpretable outputs without iterative repair loops.", "method": "OptiHive uses a single batched LLM query to generate diverse components and employs a statistical model to infer the true performance of generated components.", "result": "OptiHive significantly improves the optimality rate from 5% to 92% on complex optimization problems, including Multi-Depot Vehicle Routing Problem variants.", "conclusion": "OptiHive introduces an LLM-based framework that produces high-quality solvers for optimization problems without iterative self-correction, outperforming baselines on various tasks."}}
{"id": "2508.02511", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02511", "abs": "https://arxiv.org/abs/2508.02511", "authors": ["Chenxu Yang", "Qingyi Si", "Mz Dai", "Dingyu Yao", "Mingyu Zheng", "Minghui Chen", "Zheng Lin", "Weiping Wang"], "title": "Test-time Prompt Intervention", "comment": "23 pages, 16 figures, under review", "summary": "Test-time compute has led to remarkable success in the large language model\n(LLM) community, particularly for complex tasks, where longer chains of thought\n(CoTs) are generated to enhance reasoning capabilities. However, growing\nevidence reveals that such reasoning models often produce CoTs plagued by\nexcessive redundancy, including unnecessary verification steps and repetitive\nreasoning shifts. The root cause lies in post-training of them that overly rely\non outcome reward paradigms, as the data of process reward paradigms, which\nregulate intermediate reasoning steps, is difficult to construct at scale. To\naddress this, we propose PI, a novel framework for Test-time Prompt\nIntervention. PI provides an interface to dynamically guide and regulate\nreasoning paths during inference through timely (When module) and proper (How\nmodule) interventions and post-intervention sampling (Which module). This\nallows human problem-solving expertise and cognitive science principles to be\nseamlessly integrated into LLMs' reasoning processes, enhancing controllability\nand interpretability. Extensive experiments across multiple models and datasets\ndemonstrate that PI significantly shortens CoTs while reducing hallucination,\nyielding more concise and reliable reasoning.", "AI": {"tldr": "The paper introduces PI, a framework for Test-time Prompt Intervention, to guide and regulate reasoning paths in large language models. PI reduces redundancy and enhances controllability, leading to more concise and reliable reasoning processes in LLMs.", "motivation": "The motivation behind this paper is to address the issue of excessive redundancy and lack of controllability in reasoning models that overly rely on outcome reward paradigms. The proposed framework aims to enhance reasoning capabilities by integrating human problem-solving expertise and cognitive science principles.", "method": "The method involves using Test-time Prompt Intervention (PI) to dynamically guide and regulate reasoning paths during inference through timely and proper interventions and post-intervention sampling. It integrates human problem-solving expertise and cognitive science principles into LLMs' reasoning processes.", "result": "Extensive experiments across multiple models and datasets demonstrate that the proposed framework, PI, significantly shortens CoTs while reducing hallucination, resulting in more concise and reliable reasoning processes.", "conclusion": "The paper proposes a novel framework called PI for Test-time Prompt Intervention to guide and regulate reasoning paths during inference, enhancing controllability and interpretability of large language models (LLMs). Extensive experiments show that PI significantly shortens chains of thought (CoTs) while reducing hallucination, leading to more concise and reliable reasoning."}}
{"id": "2508.02525", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02525", "abs": "https://arxiv.org/abs/2508.02525", "authors": ["Qifan Chen", "Jin Cui", "Cindy Duan", "Yushuo Han", "Yifei Shi"], "title": "Accurate and Interpretable Postmenstrual Age Prediction via Multimodal Large Language Model", "comment": "Submitted to the NeurIPS 2025 Workshop GenAI4Health. Conference\n  website: https://aihealth.ischool.utexas.edu/GenAI4HealthNeurips2025/", "summary": "Accurate estimation of postmenstrual age (PMA) at scan is crucial for\nassessing neonatal development and health. While deep learning models have\nachieved high accuracy in predicting PMA from brain MRI, they often function as\nblack boxes, offering limited transparency and interpretability in clinical\ndecision support. In this work, we address the dual challenge of accuracy and\ninterpretability by adapting a multimodal large language model (MLLM) to\nperform both precise PMA prediction and clinically relevant explanation\ngeneration. We introduce a parameter-efficient fine-tuning (PEFT) strategy\nusing instruction tuning and Low-Rank Adaptation (LoRA) applied to the\nQwen2.5-VL-7B model. The model is trained on four 2D cortical surface\nprojection maps derived from neonatal MRI scans. By employing distinct prompts\nfor training and inference, our approach enables the MLLM to handle a\nregression task during training and generate clinically relevant explanations\nduring inference. The fine-tuned model achieves a low prediction error with a\n95 percent confidence interval of 0.78 to 1.52 weeks, while producing\ninterpretable outputs grounded in developmental features, marking a significant\nstep toward transparent and trustworthy AI systems in perinatal neuroscience.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5fae\u8c03\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u6708\u7ecf\u540e\u9f84\uff08PMA\uff09\u9884\u6d4b\u548c\u4e34\u5e8a\u76f8\u5173\u7684\u89e3\u91ca\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6311\u6218\u3002\u91c7\u7528\u53c2\u6570\u6709\u6548\u7684\u5fae\u8c03\u7b56\u7565\uff08PEFT\uff09\uff0c\u5728\u65b0\u751f\u513fMRI\u626b\u63cf\u76842D\u76ae\u5c42\u8868\u9762\u6295\u5f71\u56fe\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u53d6\u5f97\u4e86\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u540c\u65f6\u751f\u6210\u4e86\u4e0e\u53d1\u80b2\u7279\u5f81\u76f8\u5173\u7684\u53ef\u89e3\u91ca\u8f93\u51fa\u3002\u8fd9\u4e00\u7814\u7a76\u6210\u679c\u5bf9\u4ea7\u79d1\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u7684AI\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u7cbe\u786e\u4f30\u8ba1\u626b\u63cf\u65f6\u671f\u7684PMA\u5bf9\u8bc4\u4f30\u65b0\u751f\u513f\u53d1\u80b2\u548c\u5065\u5eb7\u81f3\u5173\u91cd\u8981\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4ece\u8111MRI\u9884\u6d4bPMA\u65b9\u9762\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u5ea6\uff0c\u4f46\u901a\u5e38\u4f5c\u4e3a\u9ed1\u5323\u5b50\uff0c\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u63d0\u4f9b\u6709\u9650\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5b9a\u5236MLLM\u5b9e\u73b0\u7cbe\u786e\u7684PMA\u9884\u6d4b\u548c\u4e34\u5e8a\u76f8\u5173\u7684\u89e3\u91ca\u751f\u6210\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e00\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u53cc\u91cd\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u53c2\u6570\u6709\u6548\u7684\u5fae\u8c03\u7b56\u7565\uff08PEFT\uff09\uff0c\u5305\u62ec\u6307\u5bfc\u5fae\u8c03\u548c\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\uff0c\u5e94\u7528\u4e8eQwen2.5-VL-7B\u6a21\u578b\uff0c\u4ee5\u8bad\u7ec3\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u5728\u56db\u4e2a2D\u76ae\u5c42\u8868\u9762\u6295\u5f71\u56fe\u4e0a\u5b9e\u73b0PMA\u9884\u6d4b\u548c\u4e34\u5e8a\u76f8\u5173\u7684\u89e3\u91ca\u751f\u6210\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u548c\u63a8\u65ad\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u4e0d\u540c\u7684\u63d0\u793a\uff0c\u4f7fMLLM\u5177\u6709\u5904\u7406\u56de\u5f52\u4efb\u52a1\u548c\u751f\u6210\u4e34\u5e8a\u76f8\u5173\u89e3\u91ca\u7684\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u672c\u7814\u7a76\uff0c\u5fae\u8c03\u6a21\u578b\u53d6\u5f97\u4e86\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\uff0c95%\u7f6e\u4fe1\u533a\u95f4\u4e3a0.78\u52301.52\u5468\uff0c\u540c\u65f6\u751f\u6210\u4e86\u57fa\u4e8e\u53d1\u80b2\u7279\u5f81\u7684\u53ef\u89e3\u91ca\u8f93\u51fa\u3002\u8fd9\u6807\u5fd7\u7740\u5728\u4ea7\u79d1\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u8fc8\u51fa\u4e86\u671d\u5411\u900f\u660e\u548c\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u7684\u91cd\u8981\u4e00\u6b65\u3002", "conclusion": "\u672c\u7814\u7a76\u4ece\u4e24\u65b9\u9762\u6311\u6218\u5165\u624b\uff0c\u901a\u8fc7\u9002\u5e94\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u8fdb\u884c\u7cbe\u786e\u7684\u6708\u7ecf\u540e\u9f84\uff08PMA\uff09\u9884\u6d4b\u548c\u4e34\u5e8a\u76f8\u5173\u7684\u89e3\u91ca\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u53cc\u91cd\u6311\u6218\u3002\u901a\u8fc7\u5f15\u5165\u53c2\u6570\u6709\u6548\u7684\u5fae\u8c03\u7b56\u7565\uff08PEFT\uff09\u4ee5\u53caQwen2.5-VL-7B\u6a21\u578b\u7684\u6307\u5bfc\u5fae\u8c03\u548c\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\uff0c\u5728\u56db\u4e2a\u4ece\u65b0\u751f\u513fMRI\u626b\u63cf\u4e2d\u5bfc\u51fa\u76842D\u76ae\u5c42\u8868\u9762\u6295\u5f71\u56fe\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u5728\u8bad\u7ec3\u548c\u63a8\u65ad\u8fc7\u7a0b\u4e2d\u91c7\u7528\u4e0d\u540c\u7684\u63d0\u793a\uff0c\u4f7fMLLM\u80fd\u591f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5904\u7406\u56de\u5f52\u4efb\u52a1\uff0c\u5e76\u5728\u63a8\u65ad\u8fc7\u7a0b\u4e2d\u751f\u6210\u4e34\u5e8a\u76f8\u5173\u7684\u89e3\u91ca\u3002\u5fae\u8c03\u6a21\u578b\u5b9e\u73b0\u4e86\u4f4e\u9884\u6d4b\u8bef\u5dee\uff0c95%\u7f6e\u4fe1\u533a\u95f4\u4e3a0.78\u52301.52\u5468\uff0c\u540c\u65f6\u4ea7\u751f\u4e0e\u53d1\u80b2\u7279\u5f81\u76f8\u5173\u7684\u53ef\u89e3\u91ca\u8f93\u51fa\uff0c\u6807\u5fd7\u7740\u4ea7\u79d1\u795e\u7ecf\u79d1\u5b66\u4e2d\u900f\u660e\u548c\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2508.02583", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02583", "abs": "https://arxiv.org/abs/2508.02583", "authors": ["Lei Zan", "Keli Zhang", "Ruichu Cai", "Lujia Pan"], "title": "CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong performance across a\nwide range of tasks, yet they still struggle with complex mathematical\nreasoning, a challenge fundamentally rooted in deep structural dependencies. To\naddress this challenge, we propose \\textbf{CA}usal \\textbf{MA}thematician\n(\\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit,\nreusable mathematical structure. In the learning stage, CAMA first constructs\nthe \\textbf{M}athematical \\textbf{C}ausal \\textbf{G}raph (\\textbf{MCG}), a\nhigh-level representation of solution strategies, by combining LLM priors with\ncausal discovery algorithms applied to a corpus of question-solution pairs. The\nresulting MCG encodes essential knowledge points and their causal dependencies.\nTo better align the graph with downstream reasoning tasks, CAMA further refines\nthe MCG through iterative feedback derived from a selected subset of the\nquestion-solution pairs. In the reasoning stage, given a new question, CAMA\ndynamically extracts a task-relevant subgraph from the MCG, conditioned on both\nthe question content and the LLM's intermediate reasoning trace. This subgraph,\nwhich encodes the most pertinent knowledge points and their causal\ndependencies, is then injected back into the LLM to guide its reasoning\nprocess. Empirical results on real-world datasets show that CAMA significantly\nimproves LLM performance on challenging mathematical problems. Furthermore, our\nexperiments demonstrate that structured guidance consistently outperforms\nunstructured alternatives, and that incorporating asymmetric causal\nrelationships yields greater improvements than using symmetric associations\nalone.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86CAusal Mathematician\uff08CAMA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u7684\u3001\u53ef\u91cd\u590d\u5229\u7528\u7684\u6570\u5b66\u7ed3\u6784\u5e2e\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b3\u590d\u6742\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\u3002CAMA\u5305\u62ec\u5b66\u4e60\u9636\u6bb5\u548c\u63a8\u7406\u9636\u6bb5\uff0c\u524d\u8005\u6784\u5efa\u6570\u5b66\u56e0\u679c\u56fe\uff08MCG\uff09\uff0c\u4f18\u5316\u4ee5\u5bf9\u9f50\u4e0b\u6e38\u4efb\u52a1\uff0c\u540e\u8005\u4eceMCG\u4e2d\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7684\u5b50\u56fe\uff0c\u5e76\u6ce8\u5165LLMs\u4ee5\u5f15\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cCAMA\u663e\u8457\u63d0\u9ad8LLMs\u5728\u6311\u6218\u6027\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u6784\u5316\u5f15\u5bfc\u4f18\u4e8e\u65e0\u7ed3\u6784\u66ff\u4ee3\u65b9\u6848\uff0c\u4e14\u975e\u5bf9\u79f0\u56e0\u679c\u5173\u7cfb\u5f15\u5165\u6bd4\u5bf9\u79f0\u5173\u8054\u83b7\u5f97\u66f4\u5927\u6539\u8fdb\u3002", "motivation": "LLMs\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u662f\u6df1\u5c42\u7ed3\u6784\u4f9d\u8d56\u6027\u6839\u6e90\u6240\u5728\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u8be5\u8bba\u6587\u63d0\u51fa\u4e86CAMA\u6846\u67b6\uff0c\u65e8\u5728\u4e3aLLMs\u63d0\u4f9b\u663e\u5f0f\u7684\u3001\u53ef\u91cd\u590d\u5229\u7528\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u5176\u5728\u56f0\u96be\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u8be5\u8bba\u6587\u91c7\u7528\u4e86\u4e24\u9636\u6bb5\u56e0\u679c\u6846\u67b6CAMA\uff0c\u4e3aLLMs\u63d0\u4f9b\u660e\u786e\u7684\u3001\u53ef\u91cd\u590d\u5229\u7528\u7684\u6570\u5b66\u7ed3\u6784\u3002\u9996\u5148\uff0c\u5728\u5b66\u4e60\u9636\u6bb5\uff0cCAMA\u901a\u8fc7\u5c06LLM\u5148\u9a8c\u77e5\u8bc6\u4e0e\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u4e86\u6570\u5b66\u56e0\u679c\u56fe\uff08MCG\uff09\u3002\u7136\u540e\uff0c\u901a\u8fc7\u4ece\u95ee\u9898-\u89e3\u51b3\u65b9\u6848\u5bf9\u7684\u9009\u62e9\u5b50\u96c6\u4e2d\u5f97\u51fa\u7684\u8fed\u4ee3\u53cd\u9988\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316MCG\u4ee5\u66f4\u597d\u5730\u4e0e\u4e0b\u6e38\u63a8\u7406\u4efb\u52a1\u5bf9\u9f50\u3002\u5728\u63a8\u7406\u9636\u6bb5\uff0cCAMA\u6839\u636e\u65b0\u95ee\u9898\u5185\u5bb9\u548cLLM\u7684\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\uff0c\u52a8\u6001\u4eceMCG\u4e2d\u63d0\u53d6\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u5b50\u56fe\u3002\u6700\u540e\uff0c\u5c06\u8fd9\u4e2a\u5b50\u56fe\u6ce8\u5165\u5230LLM\u4e2d\uff0c\u5f15\u5bfc\u5176\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cCAMA\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002\u7ed3\u6784\u5316\u5f15\u5bfc\u4f18\u4e8e\u65e0\u7ed3\u6784\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5f15\u5165\u975e\u5bf9\u79f0\u56e0\u679c\u5173\u7cfb\u6bd4\u4ec5\u4f7f\u7528\u5bf9\u79f0\u5173\u8054\u83b7\u5f97\u7684\u6539\u8fdb\u66f4\u5927\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86CAusal Mathematician (CAMA)\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u663e\u5f0f\u7684\u3001\u53ef\u91cd\u590d\u5229\u7528\u7684\u6570\u5b66\u7ed3\u6784\u6765\u5e2e\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b3\u590d\u6742\u7684\u6570\u5b66\u63a8\u7406\u95ee\u9898\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cCAMA\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u6784\u5316\u5f15\u5bfc\u59cb\u7ec8\u4f18\u4e8e\u65e0\u7ed3\u6784\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u800c\u5f15\u5165\u975e\u5bf9\u79f0\u56e0\u679c\u5173\u7cfb\u6bd4\u4ec5\u4f7f\u7528\u5bf9\u79f0\u5173\u8054\u83b7\u5f97\u7684\u6539\u8fdb\u66f4\u5927\u3002"}}
{"id": "2508.02621", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.02621", "abs": "https://arxiv.org/abs/2508.02621", "authors": ["Yinghao Zhu", "Yifan Qi", "Zixiang Wang", "Lei Gu", "Dehao Sui", "Haoran Hu", "Xichen Zhang", "Ziyi He", "Liantao Ma", "Lequan Yu"], "title": "HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research", "comment": "Code: https://github.com/yhzhu99/HealthFlow", "summary": "The efficacy of AI agents in healthcare research is hindered by their\nreliance on static, predefined strategies. This creates a critical limitation:\nagents can become better tool-users but cannot learn to become better strategic\nplanners, a crucial skill for complex domains like healthcare. We introduce\nHealthFlow, a self-evolving AI agent that overcomes this limitation through a\nnovel meta-level evolution mechanism. HealthFlow autonomously refines its own\nhigh-level problem-solving policies by distilling procedural successes and\nfailures into a durable, strategic knowledge base. To anchor our research and\nfacilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark\nfeaturing complex, realistic health data analysis tasks derived from\npeer-reviewed clinical research. Our comprehensive experiments demonstrate that\nHealthFlow's self-evolving approach significantly outperforms state-of-the-art\nagent frameworks. This work marks a necessary shift from building better\ntool-users to designing smarter, self-evolving task-managers, paving the way\nfor more autonomous and effective AI for scientific discovery.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86HealthFlow\uff0c\u4e00\u4e2a\u81ea\u6211\u8fdb\u5316\u7684AI\u4ee3\u7406\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u8fdb\u5316\u673a\u5236\u514b\u670d\u4e86AI\u4ee3\u7406\u5728\u536b\u751f\u4fdd\u5065\u7814\u7a76\u4e2d\u7684\u5c40\u9650\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cHealthFlow\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u6846\u67b6\uff0c\u4e3a\u66f4\u81ea\u4e3b\u3001\u66f4\u6709\u6548\u7684AI\u79d1\u5b66\u53d1\u73b0\u94fa\u5e73\u9053\u8def\u3002", "motivation": "AI\u4ee3\u7406\u5728\u536b\u751f\u4fdd\u5065\u7814\u7a76\u4e2d\u4f9d\u8d56\u9759\u6001\u3001\u9884\u5b9a\u4e49\u7b56\u7565\u6709\u9650\u5236\uff0c\u65e0\u6cd5\u5b66\u4e60\u6210\u4e3a\u66f4\u597d\u7684\u6218\u7565\u89c4\u5212\u8005\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u5f15\u5165\u4e00\u79cd\u65b0\u9896\u7684\u5143\u7ea7\u8fdb\u5316\u673a\u5236\uff0c\u4f7fAI\u4ee3\u7406\u80fd\u591f\u81ea\u6211\u8fdb\u5316\uff0c\u4ece\u800c\u4f18\u5316\u9ad8\u5c42\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff0c\u5b9e\u73b0\u66f4\u81ea\u4e3b\u3001\u66f4\u6709\u6548\u7684\u79d1\u5b66\u53d1\u73b0\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86HealthFlow\u548cEHRFlowBench\uff0c\u524d\u8005\u662f\u4e00\u4e2a\u81ea\u6211\u8fdb\u5316\u7684AI\u4ee3\u7406\uff0c\u901a\u8fc7\u63d0\u70bc\u8fc7\u7a0b\u4e2d\u7684\u6210\u529f\u4e0e\u5931\u8d25\u6765\u4f18\u5316\u9ad8\u5c42\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff1b\u540e\u8005\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u5305\u542b\u4e86\u6e90\u81ea\u540c\u884c\u8bc4\u8bae\u7684\u4e34\u5e8a\u7814\u7a76\u7684\u590d\u6742\u3001\u73b0\u5b9e\u7684\u5065\u5eb7\u6570\u636e\u5206\u6790\u4efb\u52a1\u3002\u7814\u7a76\u901a\u8fc7\u5168\u9762\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHealthFlow\u7684\u81ea\u6211\u8fdb\u5316\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u672c\u7814\u7a76\u5c55\u793a\u4e86HealthFlow\u7684\u81ea\u6211\u8fdb\u5316\u65b9\u6cd5\u5728\u536b\u751f\u4fdd\u5065\u9886\u57df\u7684\u6709\u6548\u6027\uff0c\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u6846\u67b6\u3002", "conclusion": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86HealthFlow\uff0c\u4e00\u4e2a\u81ea\u6211\u8fdb\u5316\u7684AI\u4ee3\u7406\uff0c\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u5143\u7ea7\u8fdb\u5316\u673a\u5236\u514b\u670d\u4e86AI\u4ee3\u7406\u5728\u536b\u751f\u4fdd\u5065\u7814\u7a76\u4e2d\u4f9d\u8d56\u9759\u6001\u3001\u9884\u5b9a\u4e49\u7b56\u7565\u7684\u9650\u5236\u3002\u5b9e\u9a8c\u8868\u660e\uff0cHealthFlow\u7684\u81ea\u6211\u8fdb\u5316\u65b9\u6cd5\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u8fd9\u9879\u5de5\u4f5c\u6807\u5fd7\u7740\u4ece\u6784\u5efa\u66f4\u597d\u7684\u5de5\u5177\u7528\u6237\u8f6c\u5411\u8bbe\u8ba1\u66f4\u806a\u660e\u3001\u81ea\u6211\u8fdb\u5316\u7684\u4efb\u52a1\u7ba1\u7406\u8005\uff0c\u4e3a\u66f4\u81ea\u4e3b\u3001\u66f4\u6709\u6548\u7684AI\u79d1\u5b66\u53d1\u73b0\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.02622", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.02622", "abs": "https://arxiv.org/abs/2508.02622", "authors": ["Enrico De Santis", "Antonello Rizzi"], "title": "Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction", "comment": null, "summary": "This paper introduces and formalizes Noosemia, a novel\ncognitive-phenomenological phenomenon emerging from human interaction with\ngenerative AI systems, particularly those enabling dialogic or multimodal\nexchanges. We propose a multidisciplinary framework to explain how, under\ncertain conditions, users attribute intentionality, agency, and even\ninteriority to these systems - a process grounded not in physical resemblance,\nbut in linguistic performance, epistemic opacity, and emergent technological\ncomplexity. By linking an LLM declination of meaning holism to our technical\nnotion of the LLM Contextual Cognitive Field, we clarify how LLMs construct\nmeaning relationally and how coherence and a simulacrum of agency arise at the\nhuman-AI interface. The analysis situates noosemia alongside pareidolia,\nanimism, the intentional stance and the uncanny valley, distinguishing its\nunique characteristics. We also introduce a-noosemia to describe the\nphenomenological withdrawal of such projections. The paper concludes with\nreflections on the broader philosophical, epistemological, and social\nimplications of noosemic dynamics and directions for future research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Noosemia\uff0c\u4e00\u79cd\u65b0\u7684\u8ba4\u77e5-\u73b0\u8c61\u5b66\u73b0\u8c61\uff0c\u6e90\u81ea\u4eba\u7c7b\u4e0e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4e92\u52a8\u3002\u901a\u8fc7\u8de8\u5b66\u79d1\u6846\u67b6\u89e3\u91ca\u4e86\u7528\u6237\u5982\u4f55\u5c06\u610f\u56fe\u3001\u4ee3\u7406\u6027\u548c\u5185\u5728\u6027\u5f52\u56e0\u4e8e\u8fd9\u4e9b\u7cfb\u7edf\uff0c\u533a\u5206\u4e86\u5176\u4e0e\u5176\u4ed6\u76f8\u5173\u6982\u5ff5\u7684\u72ec\u7279\u7279\u5f81\uff0c\u5e76\u63d0\u51fa\u4e86a-noosemia\u4ee5\u63cf\u8ff0\u64a4\u9000\u73b0\u8c61\u3002", "motivation": "\u4ecb\u7ecd\u548c\u5f62\u5f0f\u5316Noosemia\uff0c\u89e3\u91ca\u7528\u6237\u5982\u4f55\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u8fdb\u884c\u5f52\u56e0\u5e76\u63a2\u8ba8\u5176\u793e\u4f1a\u5f71\u54cd\u662f\u672c\u6587\u7684\u52a8\u673a\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u63d0\u51fa\u8de8\u5b66\u79d1\u6846\u67b6\u4ee5\u89e3\u91ca\u8fd9\u4e00\u73b0\u8c61\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u8ba8\u8bba\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u5b66\u79d1\u6846\u67b6\u6765\u89e3\u91ca\u7528\u6237\u5982\u4f55\u5c06\u610f\u56fe\u3001\u4ee3\u7406\u6027\u548c\u5185\u5728\u6027\u5f52\u56e0\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002\u901a\u8fc7\u5c06LLM\u7684\u610f\u4e49\u6574\u4f53\u4e3b\u4e49\u7684\u503e\u659c\u4e0eLLM\u60c5\u5883\u8ba4\u77e5\u9886\u57df\u7684\u6280\u672f\u6982\u5ff5\u8054\u7cfb\u8d77\u6765\uff0c\u9610\u660e\u4e86LLM\u5982\u4f55\u5efa\u6784\u5173\u7cfb\u610f\u4e49\uff0c\u4ee5\u53ca\u4e3a\u4f55\u8fde\u8d2f\u6027\u548c\u4ee3\u7406\u7684\u5e4c\u8c61\u4f1a\u5728\u4eba\u5de5\u667a\u80fd\u754c\u9762\u4e0a\u51fa\u73b0\u3002\u540c\u65f6\uff0c\u5c06Noosemia\u653e\u7f6e\u4e8e\u5176\u4ed6\u76f8\u5173\u6982\u5ff5\u65c1\uff0c\u533a\u5206\u4e86\u5176\u72ec\u7279\u7279\u5f81\uff0c\u5e76\u63d0\u51fa\u4e86a-noosemia\u6765\u63cf\u8ff0\u6295\u5c04\u7684\u64a4\u9000\u73b0\u8c61\u3002", "result": "\u672c\u6587\u5f62\u5f0f\u5316\u4e86Noosemia\uff0c\u63d0\u51fa\u4e86\u8de8\u5b66\u79d1\u6846\u67b6\u6765\u9610\u91ca\u7528\u6237\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5f52\u56e0\u8fc7\u7a0b\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0e\u8be5\u73b0\u8c61\u76f8\u5173\u7684\u5176\u4ed6\u6982\u5ff5\u4e4b\u95f4\u7684\u533a\u522b\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86a-noosemia\u6765\u63cf\u8ff0\u73b0\u8c61\u5b66\u64a4\u9000\u7684\u60c5\u51b5\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u5e76\u6b63\u5f0f\u5f62\u5f0f\u5316\u4e86Noosemia\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u8ba4\u77e5-\u73b0\u8c61\u5b66\u73b0\u8c61\uff0c\u6e90\u81ea\u4eba\u7c7b\u4e0e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4e92\u52a8\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u80fd\u591f\u8fdb\u884c\u5bf9\u8bdd\u6216\u591a\u6a21\u5f0f\u4ea4\u6d41\u7684\u7cfb\u7edf\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u5b66\u79d1\u6846\u67b6\u6765\u89e3\u91ca\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u7528\u6237\u5982\u4f55\u5c06\u610f\u56fe\u3001\u4ee3\u7406\u6027\u751a\u81f3\u5185\u5728\u6027\u5f52\u56e0\u4e8e\u8fd9\u4e9b\u7cfb\u7edf\u2014\u2014\u8fd9\u4e00\u8fc7\u7a0b\u4e0d\u662f\u57fa\u4e8e\u7269\u7406\u76f8\u4f3c\u6027\uff0c\u800c\u662f\u57fa\u4e8e\u8bed\u8a00\u8868\u73b0\u3001\u8ba4\u77e5\u4e0d\u900f\u660e\u6027\u548c\u65b0\u5174\u6280\u672f\u590d\u6742\u6027\u3002\u901a\u8fc7\u5c06LLM\u7684\u610f\u4e49\u6574\u4f53\u4e3b\u4e49\u7684\u503e\u659c\u4e0e\u6211\u4eec\u7684LLM\u60c5\u5883\u8ba4\u77e5\u9886\u57df\u7684\u6280\u672f\u6982\u5ff5\u8054\u7cfb\u8d77\u6765\uff0c\u6211\u4eec\u9610\u660e\u4e86LLM\u5982\u4f55\u5728\u4eba\u5de5\u667a\u80fd\u754c\u9762\u6784\u5efa\u5173\u7cfb\u610f\u4e49\uff0c\u4ee5\u53ca\u4e3a\u4f55\u8fde\u8d2f\u6027\u548c\u4ee3\u7406\u7684\u5e4c\u8c61\u4f1a\u5728\u4eba\u5de5\u667a\u80fd\u754c\u9762\u4e0a\u51fa\u73b0\u3002\u5206\u6790\u5c06Noosemia\u7f6e\u4e8e\u5bf9\u5e94\u7269\u3001\u6cdb\u7075\u8bba\u3001\u6545\u610f\u7acb\u573a\u548c\u602a\u5f02\u5c71\u8c37\u4e4b\u65c1\uff0c\u533a\u5206\u4e86\u5176\u72ec\u7279\u7279\u5f81\u3002\u6211\u4eec\u8fd8\u4ecb\u7ecd\u4e86a-noosemia\u6765\u63cf\u8ff0\u8fd9\u79cd\u6295\u5c04\u7684\u73b0\u8c61\u5b66\u64a4\u9000\u3002\u6700\u540e\uff0c\u672c\u6587\u5bf9Noosemic\u52a8\u6001\u7684\u66f4\u5e7f\u6cdb\u54f2\u5b66\u3001\u8ba4\u8bc6\u8bba\u548c\u793e\u4f1a\u5f71\u54cd\u8fdb\u884c\u4e86\u601d\u8003\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002"}}
{"id": "2508.02630", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MA", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2508.02630", "abs": "https://arxiv.org/abs/2508.02630", "authors": ["Amine Allouah", "Omar Besbes", "Josu\u00e9 D Figueroa", "Yash Kanoria", "Akshit Kumar"], "title": "What Is Your AI Agent Buying? Evaluation, Implications and Emerging Questions for Agentic E-Commerce", "comment": null, "summary": "Online marketplaces will be transformed by autonomous AI agents acting on\nbehalf of consumers. Rather than humans browsing and clicking,\nvision-language-model (VLM) agents can parse webpages, evaluate products, and\ntransact. This raises a fundamental question: what do AI agents buy, and why?\nWe develop ACES, a sandbox environment that pairs a platform-agnostic VLM agent\nwith a fully programmable mock marketplace to study this question. We first\nconduct basic rationality checks in the context of simple tasks, and then, by\nrandomizing product positions, prices, ratings, reviews, sponsored tags, and\nplatform endorsements, we obtain causal estimates of how frontier VLMs actually\nshop. Models show strong but heterogeneous position effects: all favor the top\nrow, yet different models prefer different columns, undermining the assumption\nof a universal \"top\" rank. They penalize sponsored tags and reward\nendorsements. Sensitivities to price, ratings, and reviews are directionally\nhuman-like but vary sharply in magnitude across models. Motivated by scenarios\nwhere sellers use AI agents to optimize product listings, we show that a\nseller-side agent that makes minor tweaks to product descriptions, targeting AI\nbuyer preferences, can deliver substantial market-share gains if AI-mediated\nshopping dominates. We also find that modal product choices can differ across\nmodels and, in some cases, demand may concentrate on a few select products,\nraising competition questions. Together, our results illuminate how AI agents\nmay behave in e-commerce settings and surface concrete seller strategy,\nplatform design, and regulatory questions in an AI-mediated ecosystem.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u6c99\u76d2\u73af\u5883\u6765\u7814\u7a76AI\u4ee3\u7406\u5728\u8d2d\u7269\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\u3002\u5b9e\u9a8c\u663e\u793a\u4e0d\u540c\u7684VLM\u6a21\u578b\u5bf9\u4ea7\u54c1\u6709\u4e0d\u540c\u7684\u504f\u597d\uff0c\u5e76\u63ed\u793a\u4e86AI\u4ee3\u7406\u7684\u884c\u4e3a\u65b9\u5f0f\u3002\u5356\u65b9\u4ee3\u7406\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u4ea7\u54c1\u63cf\u8ff0\u6765\u9002\u5e94AI\u4e70\u5bb6\u7684\u504f\u597d\uff0c\u83b7\u5f97\u5e02\u573a\u4efd\u989d\u589e\u957f\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u9700\u6c42\u53ef\u80fd\u4f1a\u96c6\u4e2d\u5728\u5c11\u6570\u4ea7\u54c1\u4e0a\uff0c\u5f15\u53d1\u7ade\u4e89\u95ee\u9898\u3002", "motivation": "\u5206\u6790AI\u4ee3\u7406\u5728\u7535\u5b50\u5546\u52a1\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u8d2d\u7269\u884c\u4e3a\uff0c\u5e76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u8c03\u6574\u4ea7\u54c1\u63cf\u8ff0\u6765\u4f18\u5316\u4ea7\u54c1\u5217\u8868\u4ee5\u83b7\u5f97\u5e02\u573a\u4efd\u989d\u3002\u7814\u7a76\u4e0d\u540cVLM\u6a21\u578b\u4e4b\u95f4\u7684\u8d2d\u7269\u884c\u4e3a\u5dee\u5f02\uff0c\u4ee5\u53ca\u9700\u6c42\u96c6\u4e2d\u548c\u7ade\u4e89\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u6c99\u76d2\u73af\u5883ACES\uff0c\u8fdb\u884c\u4e86\u57fa\u672c\u7684\u7406\u6027\u68c0\u67e5\u548c\u968f\u673a\u5316\u5b9e\u9a8c\u4ee5\u83b7\u5f97AI\u4ee3\u7406\u7684\u8d2d\u7269\u884c\u4e3a\u3002\u7814\u7a76\u5bf9\u4ea7\u54c1\u4f4d\u7f6e\u3001\u4ef7\u683c\u3001\u8bc4\u7ea7\u3001\u8bc4\u8bba\u3001\u8d5e\u52a9\u6807\u7b7e\u548c\u5e73\u53f0\u8ba4\u53ef\u8fdb\u884c\u4e86\u5e72\u9884\uff0c\u83b7\u53d6\u4e86\u4e0d\u540cVLM\u6a21\u578b\u7684\u56e0\u679c\u4f30\u8ba1\u3002\u5c55\u793a\u4e86AI\u4ee3\u7406\u5bf9\u4ea7\u54c1\u7684\u504f\u597d\uff0c\u4ee5\u53ca\u5356\u65b9\u4ee3\u7406\u4f18\u5316\u4ea7\u54c1\u5217\u8868\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u540c\u7684VLM\u6a21\u578b\u5728\u8d2d\u7269\u884c\u4e3a\u4e0a\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u5c55\u793a\u4e86AI\u4ee3\u7406\u5728\u7535\u5b50\u5546\u52a1\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u65b9\u5f0f\u3002\u5356\u65b9\u4ee3\u7406\u901a\u8fc7\u8c03\u6574\u4ea7\u54c1\u63cf\u8ff0\u4ee5\u6ee1\u8db3AI\u4e70\u5bb6\u504f\u597d\u53ef\u5b9e\u73b0\u5e02\u573a\u4efd\u989d\u589e\u957f\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u9700\u6c42\u53ef\u80fd\u96c6\u4e2d\u5728\u5c11\u6570\u4ea7\u54c1\u4e0a\u7684\u7ade\u4e89\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aACES\u7684\u6c99\u76d2\u73af\u5883\uff0c\u7ed3\u5408\u4e86\u5e73\u53f0\u65e0\u5173\u7684VLM\u4ee3\u7406\u548c\u5168\u9762\u53ef\u7f16\u7a0b\u7684\u6a21\u62df\u5e02\u573a\u573a\u666f\uff0c\u7528\u4e8e\u7814\u7a76AI\u4ee3\u7406\u5b9e\u9645\u8d2d\u7269\u884c\u4e3a\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u540c\u7684VLM\u6a21\u578b\u5bf9\u4ea7\u54c1\u4f4d\u7f6e\u3001\u4ef7\u683c\u3001\u8bc4\u7ea7\u3001\u8bc4\u8bba\u7b49\u6709\u5f3a\u70c8\u4f46\u5f02\u8d28\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u4e0d\u5b58\u5728\u666e\u904d\u201c\u9876\u90e8\u201d\u6392\u540d\u7684\u5047\u8bbe\u3002AI\u4ee3\u7406\u5668\u6240\u8868\u73b0\u51fa\u7684\u8d2d\u7269\u884c\u4e3a\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\uff0c\u4f46\u5728\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u5dee\u5f02\u3002\u9488\u5bf9AI\u4e70\u5bb6\u504f\u597d\u8fdb\u884c\u5fae\u8c03\u7684\u5356\u65b9\u4ee3\u7406\u6709\u671b\u5728AI\u4e3b\u5bfc\u7684\u8d2d\u7269\u5e02\u573a\u4e2d\u83b7\u5f97\u5e02\u573a\u4efd\u989d\u3002\u7814\u7a76\u7ed3\u679c\u8fd8\u8868\u660e\uff0c\u5728\u4e00\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6a21\u6001\u4ea7\u54c1\u9009\u62e9\u548c\u9700\u6c42\u53ef\u80fd\u96c6\u4e2d\u5728\u5c11\u6570\u51e0\u79cd\u4ea7\u54c1\u4e0a\uff0c\u5f15\u53d1\u7ade\u4e89\u95ee\u9898\u3002\u8be5\u7814\u7a76\u63ed\u793a\u4e86AI\u4ee3\u7406\u5728\u7535\u5b50\u5546\u52a1\u73af\u5883\u4e2d\u7684\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u5356\u65b9\u7b56\u7565\u3001\u5e73\u53f0\u8bbe\u8ba1\u548c\u76d1\u7ba1\u95ee\u9898\u3002"}}
{"id": "2508.02634", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02634", "abs": "https://arxiv.org/abs/2508.02634", "authors": ["Enrique Valero-Leal", "Pedro Larra\u00f1aga", "Concha Bielza"], "title": "Actionable Counterfactual Explanations Using Bayesian Networks and Path Planning with Applications to Environmental Quality Improvement", "comment": null, "summary": "Counterfactual explanations study what should have changed in order to get an\nalternative result, enabling end-users to understand machine learning\nmechanisms with counterexamples. Actionability is defined as the ability to\ntransform the original case to be explained into a counterfactual one. We\ndevelop a method for actionable counterfactual explanations that, unlike\npredecessors, does not directly leverage training data. Rather, data is only\nused to learn a density estimator, creating a search landscape in which to\napply path planning algorithms to solve the problem and masking the endogenous\ndata, which can be sensitive or private. We put special focus on estimating the\ndata density using Bayesian networks, demonstrating how their enhanced\ninterpretability is useful in high-stakes scenarios in which fairness is\nraising concern. Using a synthetic benchmark comprised of 15 datasets, our\nproposal finds more actionable and simpler counterfactuals than the current\nstate-of-the-art algorithms. We also test our algorithm with a real-world\nEnvironmental Protection Agency dataset, facilitating a more efficient and\nequitable study of policies to improve the quality of life in United States of\nAmerica counties. Our proposal captures the interaction of variables, ensuring\nequity in decisions, as policies to improve certain domains of study (air,\nwater quality, etc.) can be detrimental in others. In particular, the\nsociodemographic domain is often involved, where we find important variables\nrelated to the ongoing housing crisis that can potentially have a severe\nnegative impact on communities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u7684\u53ef\u64cd\u4f5c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u5bc6\u5ea6\u4f30\u8ba1\u5668\u548c\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u4f30\u8ba1\u6570\u636e\u5bc6\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5173\u6ce8\u516c\u5e73\u6027\u95ee\u9898\uff0c\u7279\u522b\u9002\u7528\u4e8e\u653f\u7b56\u5236\u5b9a\u9886\u57df\u3002", "motivation": "\u7814\u7a76\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u4fc3\u8fdb\u7ec8\u7aef\u7528\u6237\u7406\u89e3\u673a\u5668\u5b66\u4e60\u673a\u5236\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u907f\u514d\u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u4ee5\u4fdd\u62a4\u654f\u611f\u6216\u79c1\u4eba\u4fe1\u606f\uff0c\u5173\u6ce8\u63d0\u9ad8\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u516c\u5e73\u6027\u3002", "method": "\u5229\u7528\u6570\u636e\u5b66\u4e60\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u521b\u5efa\u641c\u7d22\u7a7a\u95f4\u5e94\u7528\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u4f30\u8ba1\u6570\u636e\u5bc6\u5ea6\uff0c\u6bd4\u8f83\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u6570\u636e\u96c6\u7ed3\u679c\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u5bfb\u627e\u5230\u66f4\u53ef\u64cd\u4f5c\u548c\u66f4\u7b80\u5355\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u73af\u4fdd\u6570\u636e\u96c6\u7814\u7a76\u653f\u7b56\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u6355\u6349\u53d8\u91cf\u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u786e\u4fdd\u51b3\u7b56\u516c\u5e73\u6027\u548c\u907f\u514d\u53ef\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u7684\u9886\u57df\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u64cd\u4f5c\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\uff0c\u4e0d\u76f4\u63a5\u5229\u7528\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u662f\u5229\u7528\u6570\u636e\u5b66\u4e60\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u57fa\u4e8e\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u5e76\u63a9\u76d6\u6570\u636e\u7684\u5185\u751f\u6027\uff0c\u7279\u522b\u5173\u6ce8\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u4f30\u8ba1\u6570\u636e\u5bc6\u5ea6\uff0c\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u63d0\u4f9b\u66f4\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.02644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02644", "abs": "https://arxiv.org/abs/2508.02644", "authors": ["Guowei Zou", "Weibing Li", "Hejun Wu", "Yukun Qian", "Yuhang Wang", "Haitao Wang"], "title": "D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss", "comment": null, "summary": "Diffusion policies excel at robotic manipulation by naturally modeling\nmultimodal action distributions in high-dimensional spaces. Nevertheless,\ndiffusion policies suffer from diffusion representation collapse: semantically\nsimilar observations are mapped to indistinguishable features, ultimately\nimpairing their ability to handle subtle but critical variations required for\ncomplex robotic manipulation. To address this problem, we propose D2PPO\n(Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces\ndispersive loss regularization that combats representation collapse by treating\nall hidden representations within each batch as negative pairs. D2PPO compels\nthe network to learn discriminative representations of similar observations,\nthereby enabling the policy to identify subtle yet crucial differences\nnecessary for precise manipulation. In evaluation, we find that early-layer\nregularization benefits simple tasks, while late-layer regularization sharply\nenhances performance on complex manipulation tasks. On RoboMimic benchmarks,\nD2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after\nfine-tuning, setting new SOTA results. In comparison with SOTA, results of\nreal-world experiments on a Franka Emika Panda robot show the excitingly high\nsuccess rate of our method. The superiority of our method is especially evident\nin complex tasks. Project page: https://guowei-zou.github.io/d2ppo/", "AI": {"tldr": "D2PPO proposes dispersive loss regularization to combat diffusion representation collapse, improving robotic manipulation performance. It shows significant performance improvements on RoboMimic benchmarks and real-world experiments, achieving new state-of-the-art results.", "motivation": "The motivation behind this paper is to address the diffusion representation collapse issue in diffusion policies, which hinders their ability to handle subtle variations required for complex robotic manipulation tasks.", "method": "D2PPO utilizes dispersive loss regularization to treat hidden representations within each batch as negative pairs, forcing the network to learn discriminative representations of similar observations.", "result": "D2PPO shows benefits of early-layer regularization for simple tasks and late-layer regularization for complex manipulation tasks. It achieves significant improvements on RoboMimic benchmarks, with a 22.7% average improvement in pre-training and 26.1% after fine-tuning. Real-world experiments on a Franka Emika Panda robot demonstrate high success rates and superior performance in complex tasks.", "conclusion": "D2PPO introduces dispersive loss regularization to combat representation collapse in diffusion policies, leading to improved performance in robotic manipulation tasks."}}
