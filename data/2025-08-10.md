<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 33]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 该论文提出了基于大型语言模型的智能系统，结合了轴承振动分析和多智能体生成方法，以序列化数据为自然语言进行处理，实现了高准确度的少样本异常检测。实验验证表明系统在轴承振动数据集上表现出有效的异常检测和内容相关的维护指导。该研究将LLMs应用于工业维护，提供了可扩展的预测性维护框架。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于工业机械维护需要及时干预以预防灾难性故障并优化运营效率。作者试图利用大型语言模型（LLM）构建智能系统，为工业维护提供更精准的预测性维护方案。

Method: 研究建立在之前的数字数据分析框架基础上，将轴承振动数据序列化成自然语言以进行LLM处理，实现高准确度的少样本异常检测。论文采用多智能体生成的方法结合轴承振动频率分析，通过处理维护手册和进行网络搜索，生成结构化的维护建议。

Result: 研究在轴承振动数据集上进行实验验证，展示了有效的异常检测和内容相关的维护指导。论文得出结论称系统成功弥合了条件监测和可操作维护规划之间的差距。

Conclusion: 该论文提出了基于大型语言模型（LLM）的智能系统，用于工业机械维护，不仅扩展了传统的异常检测范围，还提供了可操作的维护建议。论文结论强调了该系统成功地将条件监测与可操作的维护规划相结合，为工业从业者提供智能决策支持。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [2] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow is a method that automatically generates agentic workflows for geospatial tasks, improving success rates by 6.8% and reducing token usage by up to fourfold compared to existing approaches.


<details>
  <summary>Details</summary>
Motivation: Unlike prior work that focuses on reasoning decomposition and leaves API selection implicit, GeoFlow aims to improve agentic success and reduce token usage in geospatial tasks.

Method: GeoFlow automatically generates agentic workflows for geospatial tasks, providing each agent with detailed tool-calling objectives to guide geospatial API invocation at runtime.

Result: GeoFlow method outperforms state-of-the-art approaches by increasing agentic success and reducing token usage in geospatial tasks.

Conclusion: GeoFlow method increases agentic success by 6.8% and reduces token usage by up to fourfold across major LLM families compared to state-of-the-art approaches.

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [3] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 提出了基于对抗性棋盘游戏的大型语言模型评估框架，使用 Elo 评分系统和性能循环图进行综合性能评估，实验结果显示大型语言模型在对抗性环境中表现较好，但在技能发挥方面存在一定的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在现有基准方法中存在数据依赖性的局限，为了弥补这一缺陷，提出了基于对抗性棋盘游戏的评估框架。

Method: 提出了对抗性基准框架，通过棋盘游戏比赛评估大型语言模型的综合性能，使用 Elo 评分系统和性能循环图对技术能力进行量化评估，并通过积极情绪分数评估心理适应性。采用循环赛制进行评估，进行系统比较。

Result: 实验结果显示，大部分大型语言模型对获胜和失败持乐观态度，表现出较高的适应性，但在技能发挥过程中存在不稳定性。

Conclusion: 大型语言模型在对抗性棋盘游戏中表现出较高的适应性，但在技能发挥方面存在一定的不稳定性，需要进一步探讨和解释。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [4] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 本研究比较了三种实现AWebGIS的方法，发现基于精调的小语言模型（SLM）在客户端执行的策略效果最佳，具有较高的准确性和较低的服务器负载。


<details>
  <summary>Details</summary>
Motivation: 自主的基于网络的地理信息系统（AWebGIS）旨在通过自然语言输入执行地理空间操作，提供直观、智能和无需使用手的交互。然而，大多数现有解决方案依赖于基于云的大型语言模型（LLM），这些模型需要持续的互联网访问，由于集中的服务器处理引起用户的隐私和扩展性问题。

Method: 该研究比较了三种实现AWebGIS的方法：(1)使用基于云的大型语言模型（例如Cohere）的全自动在线方法；(2)使用传统机器学习分类器（如支持向量机和随机森林）的半自动离线方法；(3)基于精调的小语言模型（SLM），特别是在客户端Web浏览器中执行的T5-small模型的全自主离线方法。

Result: 第三种方法利用SLM取得了最高的准确性，准确匹配度为0.93，Levenshtein相似度为0.99，ROUGE-1和ROUGE-L得分均为0.98。

Conclusion: 客户端执行策略降低了后端服务器的负载，为AWebGIS解决方案提供了可行性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [5] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 本研究发现在非理想情况下，强化学习微调虽然提升了基线推理能力，在实际情景中性能显著下降，揭示了大型模型推理能力的重要局限性。提出了一种特定情景的补救方法，但现有方法未能完全解决推理缺陷。强调评估模型在非理想情况下的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型的推理评估通常在理想化的设置下进行，忽视了在现实非理想情况下的性能。本研究确定了三种具有实际相关性的代表性非理想情景：摘要推理、细粒度噪声抑制和情境过滤。引入了一个新的研究方向，根据脑科学发现，人类推理在不完美输入下仍然可靠。

Method: 本研究通过使用代表性的策略梯度算法对三个大型语言模型（LLMs）和一种最先进的大型视觉-语言模型（LVLM）进行强化学习微调，然后在八个公共数据集上测试它们的性能。

Result: 研究结果显示，强化学习微调虽然提升了在理想情况下基线推理能力，但在三种非理想情况下性能显著下降，揭示了先进推理能力的关键局限。

Conclusion: 本研究发现虽然强化学习微调提升了在理想情况下的基线推理能力，但在三种非理想情况下性能显著下降，暴露了先进推理能力的关键局限性。虽然提出了一种特定情景的补救方法，但研究结果表明当前方法在很大程度上未解决这些推理缺陷。该工作强调大型模型的推理能力往往被夸大，并强调了在非理想情况下评估模型的重要性。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [6] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: 本研究介绍了HealthFlow，一种自我演化的AI代理，通过自主完善高层问题解决策略，克服了静态、预定义策略的限制。实验结果显示HealthFlow显著优于当前最先进的代理框架，为AI在科学领域的更自主和有效应用铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在卫生保健研究中面临静态、预定义策略的局限，难以提高策略规划能力。为了克服这一限制，需要引入一种新的自我演化机制，以提高AI代理在复杂领域如卫生保健中的决策能力。

Method: 介绍了HealthFlow，一种自我演化的AI代理，通过元级演化机制克服了AI代理依赖静态、预定义策略的限制。引入了EHRFlowBench，一个新基准测试，展示了HealthFlow的自我演化方法优于当前最先进的代理框架。

Result: 实验表明HealthFlow在卫生保健数据分析任务中表现显著优于当前最先进的代理框架。

Conclusion: 介绍了HealthFlow，一种自我演化的AI代理，在卫生保健领域研究中克服了AI代理依赖静态、预定义策略的局限，能够自主完善其高层问题解决策略。研究引入了EHRFlowBench，一个新的基准测试，提供了从同行评审的临床研究中提取的复杂、现实的健康数据分析任务。通过全面实验表明，HealthFlow的自我演化方法明显优于最先进的代理框架，将AI的发展从构建更好的工具用户转变为设计更智能、自我演化的任务管理者，为科学发现提供更自主和有效的AI铺平了道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [7] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 本文提出了Docking Game框架和Loop Self-Play算法，通过模拟蛋白-配体相互作用的博弈过程来提高配体对接的性能。实验证明，在准确预测结合方式方面相较于先前方法有约10%的改进。


<details>
  <summary>Details</summary>
Motivation: 目前的多任务学习模型在配体对接方面表现不佳，主要由于配体和蛋白质的结构复杂性不同。为了解决这一问题，作者提出了一种能够促进模型适应和优化的新框架和算法。

Method: 使用基于博弈论的Docking Game框架和Loop Self-Play算法来解决多任务学习模型在配体对接方面的性能问题。通过两层循环训练配体对接模块和蛋白口袋对接模块，使其相互适应和优化。

Result: 通过实验证明，LoopPlay相较于先前最先进的方法在准确预测结合方式方面有约10%的改进。

Conclusion: 这篇论文提出了一种基于博弈论的新框架，命名为Docking Game，用于解决当前多任务学习模型在配体对接方面表现不佳的问题。他们开发了Loop Self-Play算法来训练配体对接模块和蛋白口袋对接模块，实现了互相适应和优化。实验证明，LoopPlay相较于先前最先进的方法在准确预测结合方式方面有约10%的改进，有望提高药物发现中分子对接的准确性。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [8] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: This paper explores the use of large language models (LLMs) for spatial data integration, finding that LLMs show promise in improving integration tasks when provided with relevant features. They can effectively correct errors using a review-and-refine method, positioning LLMs as a flexible alternative to traditional rule-based methods.


<details>
  <summary>Details</summary>
Motivation: Traditional rule-based integration methods have limitations in covering all edge cases, while machine learning approaches require extensive data collection and labeling. LLMs are investigated as a potential solution to address these challenges and enhance spatial data integration.

Method: The study explores the application of large language models (LLMs) for integrating large, heterogeneous, and noisy urban spatial datasets. It investigates how LLMs reason about environmental spatial relationships and evaluates their performance in spatial data integration tasks.

Result: LLMs exhibit spatial reasoning capabilities but may struggle with connecting macro-scale environmental features with computational geometry tasks. However, with relevant features and a review-and-refine approach, LLMs can generate high-performing results in spatial data integration tasks.

Conclusion: LLMs are a promising alternative to traditional rule-based integration methods in spatial data integration, showing high performance when provided with relevant features and utilizing a review-and-refine approach effectively to correct errors.

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [9] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 该论文提出了CogniWeb框架，将快速直觉处理与深思熟虑的推理能力相结合，实现了在Web导航领域的竞争性能力和高效性。


<details>
  <summary>Details</summary>
Motivation: 当前构建自主Web代理的方法主要集中在离线模仿学习和在线探索，但很少有效整合这两种范式。受到人类认知的双过程理论启发，提出了快速和缓慢认知过程的分解，以弥合离线直觉反应行为学习和在线规划能力获取之间的鸿沟。

Method: 通过将人类认知的双过程理论应用于设计，将Web代理方法论分解为快速系统1和缓慢系统2认知过程，并在CogniWeb框架中实现这一分解。

Result: CogniWeb在WebArena上的评估显示，它取得了竞争性的性能（43.96%成功率），同时在令牌使用上显著提高了效率（减少了75%的使用量）。

Conclusion: 该论文提出了一种新的CogniWeb框架，结合了快速直觉处理和深思熟虑的推理能力，实现了在Web导航领域竞争性能力和高效性。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [10] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 近期多模态大型语言模型的进展显著改进了医学人工智能，使其能够统一理解视觉和文本信息。该研究提出了MedMKEB，这是第一个旨在评估医学多模态大型语言模型中知识编辑的全面基准。通过实验发现现有方法在医学知识编辑方面存在限制，需要专门编辑策略的发展。


<details>
  <summary>Details</summary>
Motivation: 随着医学知识不断发展，需要实现医学智能的高效更新过时或不正确信息的能力，而无需从头开始重新训练。虽然文本知识编辑得到广泛研究，但缺乏涉及图像和文本多模态的医学知识编辑的系统基准。因此，为了填补这一空白，研究提出了MedMKEB基准。

Method: 研究建立了MedMKEB基准，包括高质量医学视觉问答数据集和精心设计的编辑任务，如反事实校正、语义泛化、知识迁移和对抗鲁棒性。通过人类专家验证确保基准的准确性和可靠性。进行了广泛的单一编辑和顺序编辑实验，展示了现有知识编辑方法在医学领域的局限性，并强调了开发专门编辑策略的必要性。

Result: 通过实验表明，在医学领域现有的知识编辑方法存在局限性，需要开发专门的编辑策略。建立的MedMKEB基准将促进可信赖和高效的医学知识编辑算法的发展。

Conclusion: 该研究提出了MedMKEB，这是第一个旨在评估医学多模态大型语言模型中知识编辑的可靠性、普遍性、局限性、可移植性和鲁棒性的全面基准。研究表明现有的知识编辑方法在医学领域存在局限性，需要开发专门的编辑策略。MedMKEB将作为一个标准基准，促进可信赖和高效的医学知识编辑算法的发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [11] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: 模拟电路门尺寸设计是一项耗时且经验驱动的任务。本文提出了EasySize，这是一种轻量级门尺寸框架，基于finetuned Qwen3-8B模型，具有普适性跨越不同技术节点和设计规格。EasySize在不同技术节点上表现出色，未经额外训练即可优于其他框架，可以显著简化和加速模拟电路设计过程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI取得进展，但为模拟电路开发开发通用、快速和稳定的门尺寸方法仍然具有重大挑战性。现有方法结合大型语言模型（LLMs）和启发式搜索技术以增强通用性，但往往依赖于大型模型尺寸，缺乏跨不同技术节点的可移植性。为了克服这些限制，本文提出了EasySize，这是第一个基于finetuned Qwen3-8B模型的轻量级门尺寸框架，可跨越工艺节点、设计规格和电路拓扑，具有普适性。

Method: EasySize利用Qwen3-8B模型进行finetuned，通过构建任务特定损失函数实现高效启发式搜索。未经额外定向训练，在不同技术节点上优于AutoCkt等尺寸化框架。

Result: EasySize在不同技术节点上表现出色，未经额外训练即可优于AutoCkt等框架。可显著减少门尺寸设计中对人类专业知识和计算资源的依赖。

Conclusion: EasySize是基于finetuned Qwen3-8B模型的轻量级门尺寸框架，具有普遍适用性，能跨越不同工艺节点、设计规格和电路拓扑。它通过利用性能指标的可达性动态构建任务特定损失函数，实现全局差分进化（DE）和局部粒子群优化（PSO）的高效启发式搜索。EasySize在350纳米节点数据的基础上实现了强大的性能，在180纳米、45纳米和22纳米技术节点上，没有额外的定向训练，仍能优于AutoCkt等常用的基于强化学习的尺寸化框架。我们认为EasySize可以显著减少门尺寸设计中对人类专业知识和计算资源的依赖，从而加速和简化模拟电路设计过程。EasySize将在以后开源。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [12] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 本研究探讨了AI在高等教育中的作用，通过对比实验发现使用苏格拉底教学助手可以显著提升学生的思维能力。研究提出了模块化、教学对齐的代理人星座概念，并分析了对高等教育机构和学生的系统影响。


<details>
  <summary>Details</summary>
Motivation: AI在高等教育中日益普及，如何结合AI技术和教学实践是当前研究的关键。本研究从实验中探讨了苏格拉底教学助手与AI聊天机器人的互动效果，旨在证明AI教学助手对学生思维能力的促进作用，并为教育领域提供新的教学模式。

Method: 在德国进行了控制性实验，比较了65名预备教师学生与苏格拉底教学助手和未经指导的AI聊天机器人的互动。研究采用建构主义理论，通过结构化对话引导学生研究问题的发展。提出了适应性的提供和使用模型，以便学生从这些代理人那里获取教学内容。对高等教育机构和学生的系统级影响进行了审查，包括资金需求、教职角色的变化、课程设置、能力和评估实践的改变。通过比较成本效益分析突出了这种系统的可扩展性。

Result: 通过研究发现，使用苏格拉底教学助手的学生报告了对批判性、独立性和反思性思维的显著支持，表明对话式AI可以激发元认知参与。同时，提出了模块化、教学对齐的代理人星座(Orchestrated MAS)的概念，以支持不同学习轨迹。

Conclusion: AI教学助手可以显著提升学生批判性、独立性和反思性思维能力，证明对话AI可以刺激元认知参与，挑战由生成式AI使用导致的去技能化近期说法。研究为更广泛的教学变革提供了概念验证，提出了通过不同角色和协调互动支持多样学习轨迹的教育者策划的模块化、教学对齐的代理人星座(Orchestrated MAS)。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [13] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 本文使用了异构图神经网络模型，针对包含不完整事件的追踪，返回缺失事件的全部属性。结果表明，该方法在重建所有不同事件属性方面表现优异，具有更全面的优势。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于解决在现实世界事件日志中获取数据的挑战，以及事件记录中出现的信息缺失问题。提出了利用图神经网络模型的新方法，以更自然地表示复杂的多模态序列，从而更具表现力和语义丰富性。

Method: 本文采用了异构图神经网络模型，针对包含不完整事件的追踪，返回缺失事件的全部属性。通过评估在两个合成日志和四个真实事件日志上对不同类型缺失值的工作进行了对比。

Result: 评估结果显示，提出的方法在重建所有不同事件属性方面表现出很好的性能，并比现有方法具有更全面的优势。

Conclusion: 本文聚焦在开发一种异构图神经网络模型，用于在包含不完整事件的追踪中返回缺失事件的全部属性。与现有模型无关的方法不同，提出的方法在重建所有不同事件属性方面表现出很好的性能。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [14] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon is a Query-Aware Dynamic RAG System that improves reasoning performance in Knowledge-Intensive VQA tasks by supporting multimodal, multi-turn, and multi-hop reasoning, outperforming baselines significantly on various tasks.


<details>
  <summary>Details</summary>
Motivation: Existing RAG methods lack the ability to address complex queries that require multi-hop reasoning or up-to-date factual knowledge, prompting the need for a more sophisticated approach like QA-Dragon.

Method: Introduces a domain router for domain-specific reasoning, a search router for optimal retrieval strategies, and orchestrates text and image search agents in a hybrid setup.

Result: QA-Dragon achieves substantial improvements in answer accuracy and knowledge overlap scores compared to baselines, showcasing its effectiveness in enhancing reasoning performance.

Conclusion: QA-Dragon, a Query-Aware Dynamic RAG System, enhances reasoning performance in Knowledge-Intensive VQA tasks by supporting multimodal, multi-turn, and multi-hop reasoning, outperforming baselines by significant margins on different tasks.

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [15] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 在大规模维护组织中，提出了结合RDF图数据库和LLMs的框架，用于处理自然语言查询，通过计划编排架构提供透明推理，提高通信效率和保持系统的信任。


<details>
  <summary>Details</summary>
Motivation: 在大规模维护组织中，识别领域专家并管理跨复杂实体关系的通信存在挑战，传统通信方法无法有效解决信息过载和响应时间长的问题。

Method: 结合RDF图数据库和LLMs处理自然语言查询，采用计划编排架构提供透明推理，使通信所有者能够制定直观查询，改善整个组织的通信效率。

Result: 提出的框架能够精确定位受众，提供可解释的查询结果，从而提高通信效率，保持系统的信任。

Conclusion: 提出了一种将RDF图数据库与LLMs结合的新框架，用于处理自然语言查询以精确定位受众，同时通过计划编排架构提供透明推理。该解决方案使通信所有者能够制定直观查询，结合设备、制造商、维护工程师和设施等概念，提供可解释的结果，保持系统的信任并提高整个组织的通信效率。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [16] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 该论文介绍了一个将决策树符号推理和大型语言模型结合的混合架构，实现了可解释推理和推理任务中的良好表现。系统在不同基准测试中展现出较高的准确性，表现优异，并在临床决策支持和科学发现等应用中展现潜力。


<details>
  <summary>Details</summary>
Motivation: 论文动机在于开发一个融合符号推理和神经网络模型的混合架构，以应对推理任务中的挑战。

Method: 将决策树符号推理与大型语言模型（LLMs）结合，构建统一的推理系统。通过在不同基准测试中取得良好表现来验证系统的有效性。

Result: 该系统在推理基准测试中表现出色，分别在ProofWriter、GSM8k和ARC基准测试中取得了较高的结果。同时，在临床决策支持和科学发现等应用中展示了系统的潜力和优势。

Conclusion: 该论文介绍了一个融合决策树符号推理和大型语言模型（LLMs）生成能力的混合架构。通过协调的多智能体框架，该设计将决策树和随机森林嵌入到统一的推理系统中。树状模块实现可解释的规则推理和因果逻辑，而LLM智能体处理推理、概括和交互规划。中央协调器维护信念状态的一致性，介导智能体和外部工具之间的通信，实现对结构化和非结构化输入的推理。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [17] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 本文提出了对人工智能中的"agent"一词进行重新定义的框架，明确了系统被视为agent的最低要求，并提出了具体建议以促进该领域的发展。


<details>
  <summary>Details</summary>
Motivation: 人工智能领域中"agent"一词的多重解释产生了研究沟通、系统评估和再现性、政策制定等方面的重大挑战，本文旨在解决这一模糊性，并提出了具体的建议，以促进该领域的发展。

Method: 通过历史分析和当代使用模式，提出了对"agent"一词进行重新定义的框架，明确了系统被视为agent的最低要求，并沿着多维谱系对系统进行表征。

Result: 提出了对"agent"一词重新定义的框架，明确了系统被视为agent的最低要求，并提供了具体建议以促进人工智能领域的发展。

Conclusion: 本文主张对人工智能中的"agent"一词进行重新定义，提出了一种框架，以明确定义系统被视为agent的最低要求，并沿着环境互动、学习和适应能力、自治性、目标复杂性和时间连贯性的多维谱系对系统进行表征。该方法为系统描述提供了精确的词汇，同时保留了这一术语在历史上曾具有多重含义的特点。在检查潜在的反对意见和实施挑战后，本文提供了对该领域未来发展的具体建议，包括术语标准化和框架采用的建议。该提议的方法为改善研究清晰度和可重复性提供了实用工具，同时支持更有效的政策制定。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [18] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: 研究通过NomicLaw模拟了LLMs在协作立法中的行为表现，揭示了它们在法律制定中的潜在社会推理和说服能力。实验结果显示LLMs可以自发形成联盟、影响决策结果，并为未来AI系统在法律环境中进行谈判、协调和立法提供了见解。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在处理文本方面取得了显著进展，但在开放式、多代理设置中尤其是包括对法律和伦理困境的讨论的理解仍然有限。本研究旨在填补这一领域的研究空白，探讨LLMs在法律制定中的行为表现和社交推理能力。

Method: NomicLaw是一个结构化的多代理模拟，LLMs通过提议规则、理由和同行提议上投票来参与协作立法。通过量化和定性方法来测量信任、互惠以及代理如何使用战略语言的能力。实验涉及同质和异质LLM组，以展示代理如何形成联盟、背叛信任以及调整言辞来影响决策。

Result: 研究揭示了LLMs在协作立法中的行为表现，包括信任、互惠、和战略语言的使用。实验结果表明LLMs可以自发形成联盟、背叛信任，并通过言辞影响决策结果。

Conclusion: 研究发现在开放式、多代理设置中，LLMs参与协作立法，在提议规则、理由和同行提议上投票。通过量化测量信任和互惠，定性评估代理如何使用战略语言来证明提议并影响结果。实验表明同质和异质LLM组如何自发形成联盟、背叛信任，并调整言辞以塑造集体决策。研究突显了十种开源LLMs的潜在社会推理和说服能力，并为设计未来AI系统提供了见解，使其能够在法律环境中自主进行谈判、协调和起草立法。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [19] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 本文研究了描述逻辑中处理'纯'最小模型的问题。发现在EL中概念可满足性在最小模型中是不可判定的。通过在TBox上施加无环条件，恢复了问题的可判定性，并与逐点割舍方法建立了联系。还对DL-Lite家族进行调查，发现了DL-Lite核心的正面结果和DL-Lite角的ExpSpace难题结果。


<details>
  <summary>Details</summary>
Motivation: 在描述逻辑中，处理最小模型问题一直是许多知识表示技术的核心。然而，在'DLs'中，对于'纯'最小模型的概念可满足性的理解仍然有限。本研究旨在解决这一问题，并对流行的DLs进行分析，以获得有关最小模型的负面结果，并尝试恢复可判定性。

Method: 本文研究了在描述逻辑中处理'纯'最小模型的问题，通过在TBox上施加无环条件，恢复了问题的可判定性，并与逐点割舍方法建立了联系。此外，对DL-Lite家族进行了调查，并发现DL-Lite核心的正面结果，以及DL-Lite角的ExpSpace难题结果。

Result: 研究发现，在EL中，概念可满足性在最小模型中是不可判定的。对于DL-Lite核心和DL-Lite角，得到了相应的复杂性结果。

Conclusion: 在流行的描述逻辑中，以'纯'最小模型为代表的概念可满足性在最小模型中是不可判定的，在EL中已经具有不可判定的性质。但通过在TBox上施加无环条件，可以将最坏情况的复杂度降低到双指数时间，并与最近研究的逐点割舍方法建立联系。我们还在数据复杂度上得出了一些结果。此外，在DL-Lite系列中，DL-Lite核心已知具有正面结果，但扩展版本DL-Lite角已被证明是ExpSpace难题。

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [20] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM method enhances multimodal models' performance on complex reasoning tasks by providing detailed feedback at sub-question levels, leading to top performance on public benchmarks and STEM-Bench, showcasing the effectiveness of structured, verifiable rewards in training.


<details>
  <summary>Details</summary>
Motivation: Existing Vision-Language Models struggle with complex, multi-question reasoning tasks requiring nuanced, partial credit scoring, which traditional reward mechanisms fail to provide. Partial correctness is crucial for effective learning in such tasks.

Method: Introducing StructVRM method aligning multimodal reasoning with Structured and Verifiable Reward Models, utilizing a model-based verifier for fine-grained feedback and scoring based on semantic and mathematical equivalence.

Result: The trained model, Seed-StructVRM, achieves state-of-the-art performance on six out of twelve public multimodal benchmarks and a newly curated high-difficulty STEM-Bench. Extensive experiments demonstrate the effectiveness of StructVRM in enhancing multimodal models' capabilities in real-world reasoning domains.

Conclusion: StructVRM method improves multimodal models' performance on complex reasoning tasks by providing fine-grained, sub-question-level feedback, leading to state-of-the-art results on public benchmarks and high-difficulty STEM-Bench.

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [21] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 该研究提出了一种基于实时数据驱动的智能交通系统预测性维护解决方案，实验结果表明方法在铁路预测性维护领域取得了高准确率和F值，证实了方法的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于在智能交通系统中提供实时数据驱动的预测性维护解决方案。在铁路预测性维护中，准确的故障预测对于最大限度地提高服务可用性至关重要。

Method: 该方法实现了一种处理流程，包括样本预处理、增量分类和结果解释。具有两个主要亮点：专用样本预处理模块和可解释性模块。实验使用了葡萄牙波尔图地铁操作员的MetroPT数据集。

Result: 实验结果显示，拟议方法在铁路预测性维护领域取得了高准确率和F值。方法在类别不平衡和噪声存在的情况下仍保持高性能，并有效反映决策过程。

Conclusion: 该研究提出了一种基于实时数据驱动的智能交通系统预测性维护解决方案，通过在线处理流程实现了样本预处理、机器学习模型的增量分类以及结果解释。实验结果表明，在铁路预测性维护领域取得了高准确率和F值，证实了方法的有效性和实用性。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [22] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: The paper introduces DeepPHY, a benchmark framework, to assess VLMs' understanding and reasoning of physical principles in complex environments. It shows that even advanced VLMs face challenges in accurately controlling predictive actions in simulated scenarios.


<details>
  <summary>Details</summary>
Motivation: To address the struggle of VLMs in attention to detail, precise action planning, and understanding physical principles in complex environments. Real-world evaluations of VLMs are costly, leading to the need for a benchmark framework like DeepPHY to assess VLMs' capabilities in simulated environments.

Method: Introducing DeepPHY, a benchmark framework that systematically evaluates VLMs' understanding and reasoning about fundamental physical principles through challenging simulated environments. The framework integrates multiple physical reasoning environments of varying difficulty levels and incorporates fine-grained evaluation metrics.

Result: The evaluation shows that even advanced VLMs have difficulty in translating physical knowledge into precise predictive control in challenging simulated environments.

Conclusion: VLMs struggle with attention to detail and precise action planning in complex, dynamic environments, leading to subpar performance. The evaluation of these capabilities in real-world scenarios is costly. The paper introduces DeepPHY, a benchmark framework to evaluate VLMs' understanding of physical principles in challenging simulated environments. Even state-of-the-art VLMs face difficulties in translating descriptive physical knowledge into precise predictive control in these environments.

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [23] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 大规模语言模型在有机合成反应中展现出巨大潜力，通过结合其他技术可以加速发现过程，支持更环保的数据驱动化学。倡导开放和民主化获取技术的社区倡议，旨在实现人工智能和自动化驱动的分子创新。


<details>
  <summary>Details</summary>
Motivation: 探讨大规模语言模型如何从概念工具变为实际实验室合作伙伴，指出其优势和限制，包括偏见数据集、不透明推理以及需要预防意外危险的安全措施。

Method: 将大规模语言模型与图神经网络、量子计算和实时光谱学相结合，缩短发现周期并支持更绿色、数据驱动的化学。

Result: 倡导包括开放基准测试、联邦学习和可解释界面在内的社区倡议，旨在民主化获取技术的同时保持人类始终掌控。

Conclusion: 大规模语言模型开始改变化学家规划和进行有机合成反应的方式，通过在数百万报告的转化反应上进行训练，这些基于文本的模型可以提出合成路线、预测反应结果，甚至指导执行实验的机器人无需人类监督。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [24] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 该论文探讨了AI系统面临的地理差异性对齐挑战，强调全球文化和政治环境的影响。在对齐措施中需考虑地理文化差异，提出了对齐敏感性评估的方法和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: AI对于全球用户的地理现实表达方式以及对舆论的影响日益增加，然而现有的对齐措施往往无法充分考虑地理差异性所带来的挑战。为了更好地适应各种文化和政治环境，需要关注地理差异对AI系统对齐的影响。

Method: 本文回顾了地理研究问题，提出未来研究课题，并概述了评估对齐敏感性的方法。

Result: 本文主要论述了AI系统对齐领域中的地理差异性问题，提出了未来研究方向和评估方法。

Conclusion: 该论文就AI系统的地理差异性对齐问题进行了讨论，指出了在不同地区由于文化规范、政治现实和法律法规的不同而产生的挑战。论文强调了AI系统在表达意见、代表地理现实方面的全球影响，并强调了对于时空感知的对齐需求。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [25] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 本研究介绍了Bench-2-CoP框架，填补了基准标准与监管之间的评估缺口，强调了对系统风险评估的迫切需求。发现现有评估工具狭隘，未能覆盖新监管框架下的功能性能力。


<details>
  <summary>Details</summary>
Motivation: 由于快速发展的通用人工智能（GPAI）模型，需要强大的评估框架，尤其是在欧盟AI法案和相关实践准则之类的新兴监管法规下。现有的AI评估实践主要依赖于已建立的基准，但这些工具并未设计用于衡量新监管框架关注的系统性风险。

Method: 引入了Bench-2-CoP框架，使用验证的LLM-as-judge分析，将广泛使用的基准中的194,955个问题与欧盟AI法案对模型能力和倾向性的分类进行映射。

Result: 发现现有评估生态系统主要关注少量行为倾向，而忽略了关键的功能性能力，如规避人类监督、自我复制和自主AI发展。这导致对系统风险的评估差距几乎为零。

Conclusion: 研究揭示了AI评估框架的狭隘性，强调了对系统风险评估的紧迫需要。它表明现有评估工具未能覆盖新的监管要求下关注的功能性能力，提出了Bench-2-CoP框架来填补标准和监管之间的差距。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [26] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: ERC领域面临数据稀缺和偏见来源的挑战，本文提出使用小型、资源高效的LLM合成ERC数据集。通过生成新数据集并对现有ERC基准数据集进行评估，证明了该方法在提高ERC分类器模型性能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: ERC数据稀缺，现有数据集存在偏见来源和软标签固有主观性的挑战。LLM在许多情感任务中展示了质量，但训练成本高昂，应用于ERC任务（特别是数据生成）仍受限制。

Method: 使用小型、资源高效、通用的LLM合成ERC数据集，生成六个新型数据集，其中两个专门针对每个基准进行优化。评估这些数据集的效用：(1) 为ERC分类补充现有数据集，(2) 分析ERC中标签不平衡的影响。

Result: 提出一种方法使用小型、资源高效、通用的LLM合成ERC数据集，为三个最广泛使用的ERC基准数据集增加多样化数据，生成六个新数据集，并表明训练于这些数据集上的ERC分类器模型具有强大的稳健性和性能改进。

Conclusion: 实验结果表明，使用生成的数据集训练的ERC分类器模型表现出很强的稳健性，在现有ERC基准数据集上始终实现显著的性能改进。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [27] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: 该论文提出了InfiAlign框架，结合监督微调和直接偏好优化，在大型语言模型上取得了显著的性能提升。通过自动筛选高质量对齐数据，减少了数据需求，且具有泛化能力。应用于数学推理任务中获得了额外改进，模型检查点可在指定链接上获取。


<details>
  <summary>Details</summary>
Motivation: 现有的对大型语言模型（LLMs）进行后训练的方法在数据和计算成本方面消耗巨大。为了改善模型的泛化能力和推理能力，本研究旨在提出一种更为高效的后训练框架，以解决现有方法中启发式或任务特定策略限制可扩展性的问题。通过在推理数据集中自动筛选高质量对齐数据，实现了在减少数据需求的同时获得显著性能提升，并且能够应用于新的数据源。

Method: 论文通过引入InfiAlign框架，将监督微调与直接偏好优化相结合，并设计了一个强大的数据选择管道，从开源推理数据集中自动筛选出高质量对齐数据，并在Qwen2.5-Math-7B-Base模型上进行实证实验。实验结果表明，该框架在推理能力上取得了显著性能提升，并减少了数据需求。同时，在数学推理任务中应用DPO获得了显著的改进。

Result: InfiAlign框架在对齐LLMs方面取得了显著性能提升，实现了与DeepSeek-R1-Distill-Qwen-7B相当的性能，仅使用约12%的训练数据，并在AIME 24/25基准测试上平均改进了3.89%。通过应用DPO，在数学推理任务中获得了显著的收益。是一种实用解决方案，使大型推理模型能以可扩展且高效的方式对齐。

Conclusion: 该论文介绍了一种名为InfiAlign的可扩展且样本高效的后训练框架，结合了监督微调（SFT）和直接偏好优化（DPO）以增强大型语言模型（LLMs）的推理能力。实验结果表明，InfiAlign在对齐LLMs方面取得了显著的性能提升，同时大幅减少了数据需求，并可扩展到新数据源上。通过在Qwen2.5-Math-7B-Base模型上应用SFT模型，其在仅使用约12%的训练数据的情况下，实现了与DeepSeek-R1-Distill-Qwen-7B相当的性能，且在各种推理任务中表现出了强大的泛化能力。该框架还通过应用DPO获得了额外的改进，尤其在数学推理任务中表现出显著收益。在AIME 24/25基准测试上，模型平均改进了3.89%。研究结果突显了将合理的数据选择与全阶段后训练相结合的有效性，为在可扩展且数据高效的方式上对齐大型推理模型提供了实用解决方案。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [28] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL is a framework that enhances structured knowledge graph reasoning by integrating LLM-guided exploration and path filtering. It improves accuracy and F1 scores significantly on three knowledge graph question-answering datasets.


<details>
  <summary>Details</summary>
Motivation: Existing RAG approaches struggle with handling structured knowledge like knowledge graphs, while current graph retrieval methods face challenges in capturing holistic graph structures and maintaining precision control. To address these limitations, GRAIL was developed to improve graph retrieval reasoning performance by dynamically selecting optimal actions in large-scale graphs.

Method: The proposed GRAIL framework integrates LLM-guided random exploration and path filtering to establish a data synthesis pipeline. It employs a two-stage training process to learn a policy for optimal reasoning actions. The precision-conciseness balance in graph retrieval is decoupled into fine-grained process-supervised rewards to enhance data efficiency and training stability.

Result: Extensive experiments demonstrate that GRAIL outperforms existing methods with an average accuracy improvement of 21.01% and F1 improvement of 22.43% on knowledge graph question-answering datasets.

Conclusion: GRAIL, a Graph-Retrieval Augmented Interactive Learning framework, improves reasoning performance on structured knowledge graphs by integrating LLM-guided random exploration and path filtering in a two-stage training process. It achieves significant accuracy and F1 improvements on three knowledge graph question-answering datasets.

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [29] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 该论文提出了一个通用的、模块化的框架来评估代理完成任务的能力，通过将任务分解成子任务，并利用可用信息验证每一步骤来模拟人类式评估。他们验证了该框架在Magentic-One Actor Agent上，在两个基准测试上相较于基于GPT-4o的LLM-as-a-Judge基础有更高的一致性准确度。


<details>
  <summary>Details</summary>
Motivation: 在当前基于基础模型的代理广泛应用的背景下，需要一个强大的评估框架。现有方法往往只关注最终输出，忽略了推动代理决策的逐步推理。现有的代理评估系统通常局限于狭窄的领域，无法应用于多领域。因此，为填补这一空白，作者提出了一个通用、模块化的框架。

Method: 作者提出的框架将任务分解成子任务，利用可用信息验证每一步骤，最终聚合各模块的输出来评估任务完成情况。他们通过在两个基准测试上验证Magentic-One Actor Agent来证明框架的有效性。

Result: 作者的评估框架在两个基准测试上表现出更高的一致性准确度，证明了其在代理评估方面的潜力。

Conclusion: 该论文提出了一个通用的、模块化的框架来评估代理完成任务的能力，通过将任务分解成子任务，并利用可用信息验证每一步骤来模拟人类式评估。他们在Magentic-One Actor Agent上进行了验证，结果显示该框架在两个基准测试（GAIA和BigCodeBench）上较GPT-4o基础的LLM-as-a-Judge基准具有更高的一致性准确度。因此，该框架展现了潜在的通用评估潜力。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [30] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: 这项研究开发了LORI工具，利用RoBERTa和LLAMA等大型语言模型，通过自然语言处理技术识别推荐信中的领导属性。最新的RoBERTa模型在测试中表现出色，准确性和一致性高。将LORI工具整合到研究生招生流程中，有助于简化流程，自动化评估，并全面了解申请者的能力。


<details>
  <summary>Details</summary>
Motivation: 推荐信是了解申请者能力和经验的重要途径，但审查这些文本密集型材料耗时费力。为支持招生委员会提供学生专业成长的反馈，引入LORI工具应对这一挑战，并在STEM领域领导能力日益重要的背景下，将其融入研究生招生流程，准确评估申请者的领导潜力。

Method: 使用自然语言处理和RoBERTa、LLAMA等大型语言模型，开发了LORI工具，着重识别推荐信中的团队合作、沟通和创新等领导属性。RoBERTa模型的加权F1分数达到91.6%，精确度为92.4%，召回率为91.6%，在测试数据中表现一致性强。

Result: 最新的RoBERTa模型在测试数据中取得显著成果，展现了对领导技能的准确评估能力，为STEM领域的招生流程带来了重要价值。

Conclusion: 将人工智能工具LORI应用于在线硕士申请者的推荐信评估，可有效识别领导力技能，帮助招生委员会更准确评估申请者的领导潜力。该方法不仅简化了招生流程，还自动化并确保了对候选人能力的全面评估。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [31] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate is a novel multi-view agent debate framework that enhances multimodal harmful content detection. It outperforms existing models and baselines, showing promise in improving reliable social intent detection in safety-critical online contexts.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of identifying harmful social media content due to cross-modal contradictions, rapid cultural shifts, and subtle pragmatic cues. The authors aim to improve accuracy and efficiency in detecting harmful intent like sarcasm, hate speech, or misinformation in a complex multimodal environment.

Method: The paper proposes MV-Debate, a framework with four debate agents: surface analyst, deep reasoner, modality contrast, and social contextualist. These agents analyze content from diverse interpretive perspectives through iterative debate and reflection, refining responses for accuracy and efficiency.

Result: Experiments on three benchmark datasets demonstrate that MV-Debate outperforms strong single-model and existing multi-agent debate baselines significantly, highlighting its effectiveness in enhancing social intent detection.

Conclusion: MV-Debate is a multi-view agent debate framework that improves multimodal harmful content detection significantly over existing models and baselines, showing promise in advancing reliable social intent detection in safety-critical online contexts.

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [32] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 本文提出使用主动推理（AIF）作为替换外部奖励信号的方法，以内在驱动力最小化自由能，实现自主学习的AI代理。将大型语言模型与AIF框架结合，能够使代理在学习过程中保持对人类价值观的一致性。这种综合方法为AI系统的自主发展提供了有前景的途径。


<details>
  <summary>Details</summary>
Motivation: AI系统在依赖越来越多的人力工作团队设计奖励的情况下，面临着可伸缩性挑战，这可能阻碍向着真正自主智能的进展。本文的动机在于寻找一种方法，可以使代理能够从自动生成的数据中学习，而不需要持续人类奖励工程。

Method: 提出了使用主动推理（AIF）来替换外部奖励信号，以最小化自由能作为内在驱动力的方法，从而使代理能够自动平衡探索和开发，并通过贝叶斯目标进行决策。同时将大型语言模型与AIF框架相结合，创建能够有效学习并与人类价值观保持一致的代理。

Result: 通过借助AIF框架和内在驱动力最小化自由能的方法，可以使代理能够在探索和开发之间平衡，学习效率更高，并与人类价值观保持一致。这种综合方法为发展自主学习的AI系统提供了一条有前景的道路。

Conclusion: 本文认为主动推理（AIF）为发展自主学习的人工智能（AI）代理提供了关键基础。通过将外部奖励信号替换为最小化自由能的内在驱动力，AIF有望弥合当代AI系统的	extbf{基于地面的代理差距}，从而使代理能够自然地在探索和开发之间平衡，并通过统一的贝叶斯目标进行有效学习。通过将大型语言模型作为生成世界模型，与AIF的原则性决策框架相结合，我们可以创建能够有效学习经验并与人类价值观保持一致的代理。这种综合为AI系统提供了一条引人注目的道路，可以在遵守计算和物理约束的同时自主发展。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [33] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 本研究介绍了LearnerAgent，基于大型语言模型的多代理框架。发现深度学习者在认知增长方面表现更好，浅层学习者的知识缺陷能被有效诊断。不同学习者的行为和认知模式与其心理素质密切相关。模拟实验显示LearnerAgent与真实场景相符，提供对LLM行为更具洞察力的发现。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法难以捕捉学习动态、跟踪学习进展并提供解释性，研究的动机在于引入一种新的框架和方法来模拟逼真的教学环境，并研究不同学习者类型的行为和认知特征。

Method: 介绍了LearnerAgent框架，并利用该框架进行了模拟实验。构建了具有心理学基础个人特质的学习者类型，进行了周知识获取、月战略选择、定期测试和同龄人互动等动态学习过程的跟踪。通过纵向分析和“陷阱问题”测试等手段揭示了不同学习者类型的认知特点。

Result: 通过实验发现深度学习者获得持续认知增长，浅层学习者的知识缺陷能被有效诊断，不同学习者的行为和认知模式与其个人特质相关，基础LLM的默认配置为“勤奋但脆弱的浅层学习者”。模拟实验表明LearnerAgent与真实场景相符。

Conclusion: 研究引入了LearnerAgent，一个基于大型语言模型的多代理框架，用于模拟逼真的教学环境。发现深度学习者在认知增长方面表现更好，浅层学习者的知识缺陷能被有效诊断。不同学习者的行为和认知模式与其心理素质密切相关。总体学习者尽管认知受限但具有高自我效能感。研究指出基本LLM的默认配置为“勤奋但脆弱的浅层学习者”，缺乏真正的普适理解。模拟实验显示LearnerAgent与真实场景相符，对LLM行为提供更具洞察力的发现。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>
