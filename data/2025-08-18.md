<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

TL;DR: 本文针对一阶ASPIC+实例提出了智能基础过程，通过将其转换为Datalog程序并查询引擎，实现了有效的基础和推理过程。通过简化处理避免无影响规则的基础，最终展示了可扩展的实验评估结果。


<details>
  <summary>Details</summary>
Motivation: 现有的推理规则仅支持命题规则，因此需要对一阶实例进行基础步骤。基础可能导致输入理论大小指数增长，需要智能程序处理。目前ASPIC+缺乏专门解决方案，因此提出智能基础过程来解决这一问题。

Method: 提出了智能基础过程，将一阶ASPIC+实例转换为Datalog程序，并查询Datalog引擎以获取基础替代，执行规则和相反命题的基础。此外，提出了针对ASPIC+形式化特定简化，避免对推理过程没有影响的规则进行基础。进行了经验评估以展示可扩展性。

Result: 通过智能基础过程的提出，成功保持了基础规模的可控性，确保了推理过程的正确性。对ASPIC+形式化进行了特定简化，避免了基础对推理过程没有影响的规则。通过原型实现的经验评估展示了可扩展性。

Conclusion: 提出了智能基础过程，保持了基础的规模可控，同时确保了推理过程的正确性。通过将一阶ASPIC+实例转换为Datalog程序，并查询Datalog引擎以获取基础替代，执行规则和相反命题的基础。此外，提出了针对ASPIC+形式化特定简化，避免对推理过程没有影响的规则进行基础。通过对一个原型实现进行经验评估，展示了可扩展性。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [2] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

TL;DR: 本研究介绍了一种多代理算法救济框架，通过容量加权二部匹配问题来优化社会福利。研究提出了三层优化框架，用于最大程度降低福利差距并平衡成本。实验结果显示该框架能够实现接近最优的社会福利，在系统设置中变动较小。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单个人（寻求者）和单个模型（提供者）情况，而实际应用往往涉及多方利益相关者。针对多方互动、竞争有限资源的实际系统环境，个体福利的优化忽视了真实系统的多代理性质。因此，为了解决这一问题，本研究旨在引入一个考虑多方救济寻求者和救济提供者的新框架。

Method: 研究引入了一个三层优化框架，包括基本的容量匹配、最佳容量重新分配以减少福利差距，以及具有成本感知的优化平衡福利最大化与容量调整成本。通过建模多对多互动为容量加权二部匹配问题，优化边权重以实现社会福利最大化，同时量化个体福利与集体可行结果之间的福利差距。

Result: 实验验证表明，该框架在合成和真实数据集上能够实现接近最优的社会福利，并且可以实现在系统设置中最小程度的修改。

Conclusion: 本研究提出了一个针对多方算法救济的新框架，通过解决多个救济寻求者和救济提供者之间的对应关系，优化社会福利。实验验证表明，该框架能够在系统设置方面进行最小修改，实现接近最优的社会福利。研究将算法救济从个体建议扩展到系统级设计，为提高社会福利提供了可行途径。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [3] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

TL;DR: 本研究提出了一种数据驱动的逆优化器和PPO框架结合的自动化治疗计划方法，在临床规划时间内生成高质量的治疗计划。结果显示，该方法比传统方法提高了效果和效率，并在各种参数设置下表现出更好的效果。


<details>
  <summary>Details</summary>
Motivation: 头颈部癌症的质子PBS治疗规划涉及众多冲突目标，需要人类规划者在规划过程中平衡和满足多个临床目标，这需要耗费大量的精力。虽然已经付出大量努力自动调整目标参数，但逆优化仍然依赖于理论驱动的方法。因此，本研究的动机是提出一种数据驱动的逆优化器和PPO框架的整合，以实现自动在临床可接受的规划时间内生成高质量的治疗计划。

Method: 本文提出了一种数据驱动的逆优化器，结合了PPO框架进行自动化治疗计划。优化器采用L2O方法，通过学习特定任务数据分布来预测更新步骤。作者还将用于长序列处理的技术整合到基于Transformer的L2O框架中，以解决现有L2O方法的可扩展性问题。PPO框架作为外部循环虚拟规划器，通过策略网络自主调整目标参数，并使用剂量预测器初始化目标参数。内部循环的L2O逆优化器基于PPO策略网络细化的目标计算可交付的MU值。

Result: 本研究共收集了97例患者数据，在与L-BFGSB方法比较时，作者的L2O逆优化器分别提高了22.97%的效果和36.41%的效率。作者的框架生成的计划在平均2.55小时内展示出改善或相当的器官风险器官限制效果，以及针对处方剂量水平、目标体积数量、射线角度等不同因素的优越靶区覆盖。

Conclusion: 本研究提出了基于数据驱动逆优化的方法，结合了PPO框架进行自动化治疗计划，能够在临床可接受的规划时间内生成高质量的计划。与传统方法相比，该方法在效果和效率上分别提高了22.97%和36.41%，并且在各种参数设定下都表现出更好的器官风险器官剂量限制效果和更优的靶区覆盖。

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [4] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

TL;DR: 本研究通过使用抽象双极集合框架详细研究了ABA中的强可容性和弱可容性，引入了相应的语义，并探讨了它们在非平坦情况下的应用。研究发现强和弱可容性在维持模块化属性方面具有良好性质，但也存在一些问题，作者提出了部分解决方案。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于拓展对ABA中可容性概念的探讨，特别关注了强可容性和弱可容性这两种替代概念。作者希望通过引入新的语义和研究ABA中的强可容性，进一步完善对非平坦ABA框架的理解。此外，将弱可容性语义扩展到非平坦情况，有助于提供更全面的分析。

Method: 该研究使用抽象双极集合为基础的论证框架作为形式化工具，详细研究了强可容性和弱可容性的概念，并引入了相应的语义。研究还对ABA中强可容性的性质进行了调查，扩展了弱可容性语义在非平坦ABA中的应用。此外，作者比较了强和弱可容性语义与标准可容性语义的不足之处，并探讨了解决方法。

Result: 研究结果表明，强和弱可容性在非平坦ABA中保持中心的模块化属性，但也存在一些与标准可容性相同的缺陷。研究者提出了一些解决这些问题的方案，为进一步研究提供了启示。

Conclusion: 在这项工作中，我们扩展了对基于假设的论证（ABA）中可容性概念的研究。我们研究了抽象论证中两种备受关注的替代标准可容性概念，即强可容性和弱可容性，并针对一般的（有时称为非平坦的）ABA引入了相应的首选、完全和基础语义。我们使用抽象双极集合为基础的论证框架（BSAFs）作为形式化工具，因为它们简洁地捕捉了假设之间的关系，并且足够表达一般非平坦的ABA框架。尽管最近已经研究了对于假设不能被推导的ABA受限片段的弱可容性，但目前为止还没有对ABA进行强可容性的研究。我们引入了ABA的强可容性，并研究了其良好性质。此外，我们扩展了对于平坦ABA片段的弱可容性的最新研究，将其应用于非平坦案例。我们展示了在经典、强和弱可容性下，中心的模块化属性得以保持。同时，我们还展示了在非平坦ABA中的强和弱可容性语义与标准可容性语义存在一些缺陷，并讨论了解决这些问题的方法。

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [5] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

TL;DR: LRMs excel in problem-solving but fall short in proactively asking for information. The study introduces a new dataset, evaluates LRMs' performance, uncovers overthinking and hallucination behaviors, and discusses the potential of supervised fine-tuning for enhancing LRMs' ability to ask for information.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks only assess LRMs on well-defined problems, overlooking the need for genuine intelligence that includes the ability to ask for information. The paper aims to bridge this gap by introducing a new dataset with diverse incomplete problems.

Method: The paper proposes a new dataset with incomplete problems to evaluate LRMs' ability to proactively ask for information. Systematic evaluation is conducted to reveal LRMs' shortcomings in this aspect and explore behaviors like overthinking and hallucination.

Result: LRMs are found to be lacking in proactively seeking information. The study uncovers the behaviors of overthinking and hallucination in LRMs, emphasizing the importance of supervised fine-tuning for improving this capability.

Conclusion: LRMs demonstrated remarkable problem-solving abilities in mathematics but lack the capability to ask for information proactively. The study highlights the behaviors of overthinking and hallucination in LRMs and sheds light on the challenges and potential of supervised fine-tuning in improving this ability.

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [6] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

TL;DR: Traditional KG embedding methods focus on static graphs, while real-world KGs are dynamically evolving. The paper introduces SAGE, a scale-aware framework for continual KG embedding, which dynamically updates embedding dimensions and balances learned knowledge with new facts. SAGE outperforms existing methods in experiments, demonstrating the significance of adaptive embedding dimensions in CKGE.


<details>
  <summary>Details</summary>
Motivation: Real-world knowledge graphs (KGs) are dynamically evolving with constant additions of entities, relations, and facts. Existing CKGE methods lack consideration of varying scales of updates and systematic evaluation throughout the update process. The motivation is to address the dynamic nature of KGs and provide a scale-aware approach for efficient and effective continual updating of KG embeddings.

Method: The paper proposes SAGE, which determines embedding dimensions based on update scales and expands the embedding space accordingly. It utilizes the Dynamic Distillation mechanism to balance the preservation of learned knowledge and the incorporation of new facts.

Result: Extensive experiments on seven benchmarks demonstrate that SAGE consistently outperforms existing baselines, showing improvements in MRR, H@1, and H@10. Comparison with methods using fixed embedding dimensions highlights the optimal performance of SAGE, emphasizing the importance of adaptive embedding dimensions in CKGE.

Conclusion: SAGE, a scale-aware gradual evolution framework for continual knowledge graph embedding (CKGE), outperforms existing baselines with significant improvements in Mean Reciprocal Rank (MRR), H@1, and H@10. The proposed method demonstrates the importance of adaptive embedding dimensions in CKGE by dynamically updating KG embeddings to accommodate new facts while maintaining learned knowledge.

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [7] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

TL;DR: 本文提出CRAFT-GUI框架，结合了GRPO框架和设计的奖励函数，针对GUI交互环境中RL方法的局限性进行了优化。实验证明该方法在公共和内部在线基准上均取得显著改善，验证了将强化学习与课程学习相结合的有效性。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于解决Reinforcement Learning (RL) 方法在GUI交互环境中的局限性，包括忽视不同GUI任务之间的难度变化和将任务特定细微差别折叠为单一粗糙奖励的问题。

Method: 本文采用了基于Group Relative Policy Optimization (GRPO)的课程学习框架CRAFT-GUI，设计了一个融合简单规则信号和模型评估的奖励函数，以实现更加精细的策略优化。

Result: 实验证明，CRAFT-GUI方法在公共基准和内部在线基准上的表现均较先前最先进方法提升，分别提高了5.6%和10.3%，验证了将强化学习与课程学习相结合在GUI交互任务中的有效性。

Conclusion: 本文提出了CRAFT-GUI，一个基于Group Relative Policy Optimization (GRPO)的课程学习框架，旨在解决Reinforcement Learning (RL) 方法在GUI交互环境中的局限性。通过考虑不同轨迹的难度变化，设计了一个结合简单基于规则的信号和模型评估的奖励函数，提供更丰富和细致的反馈。实验证明，CRAFT-GUI相较于先前的最先进方法在公共基准Android Control上提升了5.6%，在内部在线基准上提升了10.3%，在GUI交互任务中，将强化学习与课程学习相结合能够取得显著改善。

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [8] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

TL;DR: 本文介绍了AIM-Bench基准测试，用于评估LLM代理在不确定供应链管理情境中的决策行为。研究结果显示不同的LLM存在决策偏差，类似于人类。研究还发现认知反思和信息共享等策略有助于缓解这些偏差，强调了在库存决策情景中部署LLM时需要考虑潜在偏见。希望这些发现能为减轻人类决策偏见、开发供应链的人为中心决策支持系统铺平道路。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLM代理在不确定情境下做出库存决策的能力以及代理的决策偏见仍未被深入探讨，为了解决这一差距，本研究提出了AIM-Bench，以评估LLM代理在不确定供应链管理情境中的决策行为。

Method: 引入了AIM-Bench基准测试，通过一系列多样化的库存补货实验评估LLM代理的决策行为。研究探索并试图缓解决策偏见，包括认知反思和信息共享等策略。

Result: 研究结果揭示了不同LLM通常表现出类似于人类的不同程度的决策偏差。研究还发现了一些策略，如认知反思和信息共享，有助于缓解决策偏见。

Conclusion: 本文介绍了 AIM-Bench，这是一个用于评估LLM代理在不确定供应链管理情境中的决策行为的新型基准测试。研究结果显示，不同的LLM通常表现出各不相同的决策偏差，类似于人类所观察到的。此外，研究还探讨了缓解拉向中心效应和牛鞭效应的策略，即认知反思和信息共享的实施。这些发现强调了在部署LLM进行库存决策情景时，需要认真考虑潜在偏见的必要性。希望这些见解将为减轻人类决策偏见以及为供应链开发以人为中心的决策支持系统铺平道路。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [9] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

TL;DR: 通过Inclusion Arena实时排行榜，利用人类反馈对模型进行排名，以加速LLMs和MLLMs的发展。采用Bradley-Terry模型与两项关键创新，确保评估反映实际使用场景，提高评分稳定性，并减少恶意操纵的风险。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试和排行榜依赖于静态数据集或众包通用提示，未能充分反映在现实应用中的表现，因此提出Inclusion Arena填补这一关键差距。

Method: 使用Bradley-Terry模型并结合两项关键创新：(1) Placement Matches，用于快速估计新整合模型的初始评分，(2) Proximity Sampling，一种智能比较策略，优先考虑具有相似能力的模型之间的比较，以最大化信息获取并增强评分稳定性。

Result: Inclusion Arena产生可靠和稳定的排名，比一般众包数据集具有更高的数据传递性，并显著减少恶意操纵的风险。

Conclusion: 提出Inclusion Arena，一个实时排行榜，通过直接从AI应用程序收集的人类反馈对模型进行排名，确保评估反映实际使用场景，旨在加速LLMs和MLLMs的发展。

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [10] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

TL;DR: 本文介绍了在随机领域中很少被使用的概率性地标，在MDPs中有效利用地标以提高UCT算法性能的研究。实验结果表明，合理选择的地标可以显著改善UCT的性能，并且贪婪地标实现与最终目标实现之间需要平衡。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于经典规划中的地标条件在随机领域中很少被应用，因此作者希望探讨在概率性规划中如何利用地标来改善性能。

Method: 本文形式化了概率性地标并调整了UCT算法以利用它们作为子目标来分解MDPs。关键在于在贪婪地标实现和最终目标实现之间取得平衡。

Result: 在基准领域的实验结果表明，精心选择的地标可以显著改善UCT在在线概率规划中的性能，同时贪婪地标实现与长期目标实现之间的平衡因问题而异。

Conclusion: 本文介绍了在经典规划中起到重要作用的地标条件，在随机领域中很少被使用。作者形式化了概率性地标并调整了UCT算法以利用它们作为子目标来分解MDPs。研究结果表明，精心选择的地标可以显著改善UCT在在线概率规划中的性能，而贪婪与长期目标实现之间的平衡因问题而异。研究结果暗示，地标可以为解决MDPs的任意时间算法提供有益指导。

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [11] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

TL;DR: 研究提出一种新颖的LLM辅助规划器，结合问题分解和两种LLM使用范式，有效解决大规模规划问题。实验结果显示LLM4Predict比LLM4Inspire效果更显著。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于针对大规模规划问题中由于对象和操作增加而导致的状态空间爆炸挑战，以及前人工作忽视LLMs与领域特定知识整合的问题。

Method: 在本研究中，作者提出了将LLMs与领域特定知识相结合的新方法，通过问题分解和两种LLM使用范式（LLM4Inspire和LLM4Predict）来辅助大规模规划问题的解决。

Result: 实验结果显示，提出的LLM辅助规划器能有效定位可行解，并在搜索空间剪枝方面取得显著成效。LLM4Predict相对于LLM4Inspire在融入领域特定知识方面表现更好。

Conclusion: 本研究提出了一种新颖的LLM辅助规划器，结合问题分解方法，能有效处理大规模规划问题。实证验证表明，将领域特定知识融入LLM中对规划效果有显著提升，比起提供一般知识的LLM4Inspire，侧重于使用领域特定知识的LLM4Predict在搜索空间剪枝方面表现更为突出。

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>
