<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 研究探讨了建筑归纳偏好如何影响LLM在指导对话中的认知行为，引入符号支持机制和短期记忆模式以促进自适应结构化推理。通过评估五种系统变体的模型输出，结果显示完整系统优于基准变体，去除记忆或符号结构会降低认知行为。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探究建筑归纳偏好如何影响LLM在指导对话中的认知行为，并设计支持机制以促进结构化推理。

Method: 通过控制消融五种系统变体，通过专家设计的评分表评估模型输出，涵盖了支持、响应性、符号推理和对话记忆等方面。利用与认知相关的评分表对LLM进行评估，从而在早期实验中跨系统变体进行可扩展、系统化的比较。

Result: 在LLM的评估框架中，初步结果表明，完整系统始终优于基准变体，去除记忆或符号结构会降低关键认知行为。

Conclusion: 研究表明，在指导对话中，建筑归纳偏好会影响大型语言模型的认知行为。引入符号支持机制和短期记忆模式有助于促进Socratic辅导中的自适应结构化推理。实验结果显示，完整系统始终优于基准变体，去除记忆或符号结构会降低关键认知行为。建筑支撑可以可靠地塑造LLM中新出现的教学策略。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [2] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 本文评估了两种GraphRAG系统在阿尔茨海默病相关问题上的质量和可追溯性，为研究人员提供了实验界面，以测试标准RAG和GraphRAG的性能。


<details>
  <summary>Details</summary>
Motivation: 过去两年，基于大型语言模型（LLM）的聊天机器人如ChatGPT已经通过实现多样化任务完成和问答能力在各个领域引起了革新。GraphRAG作为改善聊天机器人可靠性的一种有前途的方法，在科学研究中的应用受到了关注。然而，目前对GraphRAG在需要专业知识的特定领域（如阿尔茨海默病等生物医学领域）上的研究还很有限。

Method: 研究构建了包含50篇论文和70个专家问题相关于阿尔茨海默病的数据库，构建了GraphRAG知识库，并使用GPT-4o作为LLM来回答查询，比较了GraphRAG生成的响应质量与标准GPT-4o模型的响应质量。同时讨论和评估了几种检索增强生成（RAG）和GraphRAG系统的可追溯性。

Result: 通过评估两种GraphRAG系统的质量和可追溯性，为研究人员提供了测试标准RAG和GraphRAG性能的界面。

Conclusion: 本文评估了两种流行的GraphRAG系统的质量和可追溯性，提供了适用于研究人员测试标准RAG和GraphRAG性能的易于使用的界面。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [3] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI is an innovative AI platform that leverages advanced AI techniques like Generative AI to manage and integrate diverse data sources in product engineering, providing dynamic and context-aware responses to user queries, thereby enhancing user engagement in the digital ecosystem.


<details>
  <summary>Details</summary>
Motivation: MultiFluxAI aims to tackle the difficulties in managing and integrating disparate data sources in product engineering across various application domains. It also focuses on improving user engagement in the digital ecosystem by addressing both current and new service-related queries.

Method: The platform leverages advanced AI techniques, including Generative AI, vectorization, and agentic orchestration, to provide dynamic and context-aware responses to complex user queries.

Result: The platform successfully provides dynamic and context-aware responses to complex user queries, enhancing user engagement in the digital ecosystem.

Conclusion: MultiFluxAI is an innovative AI platform that addresses challenges in managing and integrating diverse data sources in product engineering across different domains, enhancing user engagement in the digital ecosystem through advanced AI techniques like Generative AI and agentic orchestration.

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [4] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: 本文提出了LINKO框架，利用大型语言模型和两大轴知识传播，在多个本体图中增强医学概念表示学习。通过实验验证了LINKO相对于基线模型的优越性能，特别在数据稀缺和罕见疾病预测方面表现出更强的健壮性。


<details>
  <summary>Details</summary>
Motivation: 现有文献主要集中在将领域知识从单个本体系统或多个本体系统（例如疾病、药物和程序）孤立地整合到统一的学习结构中。因此，概念表示学习通常局限于本体内关系，忽略了跨本体连接的重要性。本文的动机在于解决这一问题，提出一种能够同时利用多个本体图的综合本体学习框架，以增强医学概念表示学习。

Method: 利用LINKO框架，首先利用大型语言模型提供图检索增强初始化，然后通过两大轴进行知识传播：（1）在层次本体级别上进行本体内垂直传播，（2）在每个层次内并行进行本体间水平传播。通过在两个公共数据集上进行广泛实验，验证了LINKO相对于当前最先进基线模型的优越性能。

Result: 通过实验验证，LINKO相对于现有基线模型表现出更好的性能，特别在数据稀缺和罕见疾病预测方面表现出更强的健壮性。

Conclusion: 提出了一种名为LINKO的大型语言模型增强综合本体学习框架，通过同时利用多个本体图，在跨异构本体系统内实现双轴知识传播，以增强医学概念表示学习。实验证明LINKO相对于最先进的基线模型具有更优越的性能表现，同时作为一种插件编码器，与现有的电子健康记录预测模型兼容，在数据稀缺和罕见疾病预测等场景中展示出增强的健壮性。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [5] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: The TiG framework enables Large Language Models to learn procedural knowledge through interaction with game environments, improving transparency and interpretability in complex tasks with lower data and computational requirements compared to traditional RL methods.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of converting static knowledge of LLMs into dynamic decision-making in interactive settings, aiming to enhance transparency and interpretability in complex tasks.

Method: Introducing the Think in Games (TiG) framework to empower LLMs in developing procedural understanding through direct interaction with game environments. Reformulating RL-based decision-making as a language modeling task, where LLMs generate language-guided policies refined iteratively through online reinforcement learning based on feedback.

Result: TiG framework shows that LLMs can successfully acquire procedural knowledge through game interactions with reduced data and computational resources, providing natural language explanations for decisions.

Conclusion: TiG framework successfully bridges the gap between declarative and procedural knowledge, achieving competitive performance with lower data and computational requirements compared to traditional RL methods.

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [6] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: 研究引入了AHELM基准，综合评估ALM的性能，涵盖多个重要方面。Gemini 2.5 Pro在多个方面表现优异但在ASR任务中存在群体不公平。基线系统也在AHELM上取得不错成绩。提供透明度，并将不断更新新的数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 现有ALM评估受到标准基准缺乏的限制，大多数基准只测量一两个能力，并忽略公平性或安全性等评估方面。现有模型间比较困难，因为独立评估测试了有限数量的模型，并使用不同的提示方法和推理参数。引入AHELM基准以解决这些问题，从综合性能角度评估ALM的表现。

Method: 引入了AHELM基准，从综合的角度评估ALM的性能，包括10个重要方面：音频感知、知识、推理、情感检测、偏见、公平性、多语言性、稳健性、毒性和安全性。标准化提示、推理参数和评估指标，确保在模型间进行公平比较。测试了14个ALM和3个额外的基线系统，在多项重要指标中Gemini 2.5 Pro表现最好，但存在群体不公平现象。基线系统在AHELM上表现良好。

Result: Gemini 2.5 Pro在5个方面排名第一，但在ASR任务中存在群体不公平。基线系统表现良好，在AHELM上排名第五。提供透明度，所有原始提示、模型生成和输出都可在网站https://crfm.stanford.edu/helm/audio/v1.0.0 上获得。AHELM将不断更新新的数据集和模型。

Conclusion: 引入了AHELM基准，旨在综合评估ALM在多个重要方面的性能。研究发现Gemini 2.5 Pro在五个方面排名第一，但在ASR任务中存在群体不公平。基线系统表现良好，在AHELM上排名第五。提供透明度，所有原始提示、模型生成和输出都可在网站https://crfm.stanford.edu/helm/audio/v1.0.0 上获得。AHELM是一个动态基准，将不断添加新的数据集和模型。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [7] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文提出了一个七层模型的人工智能计算架构，分析了人工智能的机遇和挑战，以及大规模语言模型的演化过程。对每一层进行了发展轨迹和关键技术的描述，讨论了人工智能计算中的问题和影响，以及经济问题。对未来人工智能发展进行了预测。


<details>
  <summary>Details</summary>
Motivation: 将人工智能发展的机遇和挑战，以及计算架构等方面进行结构化分析，探讨技术和经济问题的影响，预测未来发展轨迹。

Method: 通过提出七层模型的人工智能计算架构，分析了人工智能的机遇和挑战，以及大规模语言模型的演化过程。讨论了每个层次的发展轨迹、关键技术，以及人工智能计算中的问题和影响。

Result: 提出了七层模型的人工智能计算架构，并阐述了人工智能发展中的关键问题和未来趋势。提供了对未来人工智能发展轨迹的预测。

Conclusion: 该文章旨在分析人工智能的机遇和挑战，提出了一个包括七个层次的人工智能计算架构模型，解释了大规模语言模型的三阶段演变如何演化为这种架构。对于每一层，描述了发展轨迹和关键技术。讨论了人工智能计算问题，规模扩展和规模化策略对计算架构的影响，以及不同的LLMs发展路径等。此外，文章还分析了人工智能发展中的经济问题，提供了对未来人工智能发展轨迹的预测。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [8] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN is a tool that simplifies modeling and simulating urban traffic scenarios with pedestrians, cyclists, and autonomous vehicles. It integrates AJAN and CARLA frameworks, providing a visual interface for scenario creation and maintenance. SPARQL Behavior Tree is used for decision-making in dynamic simulations, making CARJAN a novel approach for intelligent agent-based scenario generation in CARLA.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is the challenge of user-friendly modeling and simulation of urban traffic scenarios with different types of agents. The need for an integrated approach for generating and simulating virtual traffic scenarios in CARLA led to the development of CARJAN. It aims to provide a solution for interactive and intelligent agent-based scenario creation in urban traffic settings.

Method: The paper introduces CARJAN, a tool for semi-automated generation and simulation of urban traffic scenarios. It is based on the multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN includes a visual user interface for modeling traffic scenarios, storage, and maintenance. It leverages SPARQL Behavior Tree for decision-making and agent interactions in dynamic scenario simulations in CARLA.

Result: The result of this paper is the development of CARJAN, a tool that enables the semi-automated generation and simulation of urban traffic scenarios involving pedestrians, cyclists, and autonomous vehicles. CARJAN integrates AJAN and CARLA frameworks, offering a visual interface for scenario layout creation and maintenance. It utilizes SPARQL Behavior Tree for decision-making and agent interactions in dynamic simulations, presenting a novel approach for intelligent agent-based scenario generation in CARLA.

Conclusion: CARJAN is a novel tool that facilitates user-friendly modeling and virtual simulation of urban traffic scenarios involving pedestrians, cyclists, and autonomous vehicles. It integrates AJAN and CARLA frameworks, offering a visual interface for scenario layout creation and maintenance. It utilizes SPARQL Behavior Tree for decision-making and agent interactions in dynamic simulations, presenting an innovative approach for intelligent agent-based scenario generation in CARLA.

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [9] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文研究了知识管理中的遗忘操作，提出了五种认知遗忘类型并使用 Spohn 的排名函数实例化了这些操作。通过评估具体的操作，揭示了它们之间的差异和共性。


<details>
  <summary>Details</summary>
Motivation: 作者在文献中提到，已有的遗忘操作主要依赖于传统逻辑，本文针对具有更丰富语义结构的认知状态进行研究，提出了更加全面的认知遗忘理论。

Method: 本文从认知角度研究遗忘操作，将遗忘 operations 提升到认知水平，探讨了五种一般类型的认知遗忘，并使用 Spohn 的排名函数实例化这些遗忘操作。

Result: 提出了五种认知遗忘类型并实例化了七种具体的遗忘操作；通过评估所有具体的遗忘操作，突出了它们之间的差异和共性。

Conclusion: 本文探讨了知识管理中的遗忘操作，介绍了变量消除和收缩两种主要的遗忘方法，重点在于在认知状态中进行遗忘操作并提出了五种认知遗忘类型，评估了遗忘操作的公理，并对具体的遗忘操作进行了评估，突出了遗忘操作符之间的差异和共性。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [10] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 论文讨论了从随机状态-动作迹线中学习滑块拼图的提升STRIPS模型的问题。提出了一个名为SYNTH的学习算法，用于构建每个动作的前置条件表达式序列，确保STRIPS+模型的正确性和完整性，并在从现有STRIPS域衍生的状态-动作迹线上测试了其可扩展性。


<details>
  <summary>Details</summary>
Motivation: 本文考虑从随机状态-动作迹线中学习滑块拼图的提升STRIPS模型的问题，挑战在于状态不是完整的STRIPS状态，动作也不是完整的STRIPS动作。现有方法大多假设迹线中的动作是完整的STRIPS动作或领域谓词是可观察的。作者引入了更“现实”的设置STRIPS+，以更贴近实际情况，提出了解决学习问题的方法。

Method: 论文提出了一个名为SYNTH的学习算法，用于构建每个动作的前置条件表达式序列，以解决STRIPS+模型的学习问题。

Result: 介绍了STRIPS+变种和SYNTH学习算法，确保了算法的正确性和完整性，并在实际状态-动作迹线上测试了算法的可扩展性。

Conclusion: 该论文引入了一个名为STRIPS+的变种，以解决从状态-动作迹线中学习STRIPS+模型的问题。提出了一个名为SYNTH的学习算法，用于构建每个动作的前置条件表达式序列，确保STRIPS+模型的正确性和完整性，并在从现有STRIPS域衍生的STRIPS+模型中获得的状态-动作迹线上测试了其可扩展性。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [11] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: 该论文介绍了MMSearch-Plus，一个包含311个多模态理解任务的基准测试。他们提供了模型-无关代理框架，并评估了多个大型多模态语言模型；最强代理达到36.0%的准确率。研究还包括边界框生成、裁剪图像搜索和错误分析。


<details>
  <summary>Details</summary>
Motivation: 本论文的动机在于，现有的多模态浏览基准往往可以通过浅层固定工作流程解决，而无法很好地应对细粒度视觉推理、来源验证和长期规划等真正的多模态挑战。因此，他们提出了一个新的基准测试MMSearch-Plus，旨在对多模态理解进行更全面的评估。

Method: 该论文介绍了MMSearch-Plus基准测试的构建过程以及他们提出的Spatial-Temporal Extrapolation方法。他们提供了一个模型-无关的代理框架，评估了多个封闭和开放式的大型多模态语言模型，并对结果进行了分析。

Result: 他们的最强代理在不进行搜索时实现了15.1%的准确率，在推演搜索的情况下提高到了36.0%的准确率。另外，一个强大的开源模型在没有搜索的情况下准确率为0.0%，经过20轮搜索后提高到6.9%。此外，他们还评估了边界框生成和裁剪图像搜索，并进行了错误分析。

Conclusion: 该论文提出了MMSearch-Plus，一个包含311个需要多模态理解的任务的基准测试。他们介绍了一个模型-无关的代理框架，并评估了一系列封闭和开放式的大型多模态语言模型。在他们的框架下，最强代理（o3）在不进行搜索时达到了15.1%的准确率，在推演搜索的情况下达到了36.0%的准确率。此外，他们还评估了边界框生成和裁剪图像搜索，并进行了错误分析，揭示了在来源验证、基于部分的推理和长期规划方面的失败。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [12] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 本研究提出了一种基于Z数的模糊推理系统，用于评估智慧的多维特征和确定性意识，结果显示其与已建立的量表有显著相关性，支持了收敛和发散效度。研究采用了模糊推理系统，结合Z数，实验对象进行了文化中立的道德困境任务，将他们的口头反应映射到智慧的五个组成部分上，通过基于21条规则的结合得分，通过高斯核密度估计调整成员函数。传统的推理模型受限于二元思维，无法很好地表达智慧中的灰色部分和自我反省的谦卑。证明性研究表明，该系统产生了与已建立量表有显著相关性的双属性智慧表示，同时与不相关特征几乎无关，支持了收敛和发散效度。


<details>
  <summary>Details</summary>
Motivation: 传统的推理模型受限于二元思维，无法很好地表达智慧中的灰色部分和自我反省的谦卑。本研究旨在提出一种计算框架，考虑到多维度和确定性，以改进心理学科学，并实现人文智能。

Method: 研究采用了模糊推理系统，结合Z数，实验对象进行了文化中立的道德困境任务，将他们的口头反应映射到智慧的五个组成部分上，通过基于21条规则的结合得分，通过高斯核密度估计调整成员函数。

Result: 证明性研究表明，该系统产生了与已建立量表有显著相关性的双属性智慧表示，同时与不相关特征几乎无关，支持了收敛和发散效度。

Conclusion: 本研究提出了一种基于Z数的模糊推理系统，用于评估智慧的多维特征和确定性意识，结果显示其与已建立的量表有显著相关性，支持了收敛和发散效度。

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [13] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种新型解释范式，基于反事实场景解释计划的预期特性。研究发现生成反事实场景的代价通常与计算计划本身的代价相当，展示了该提议的实际可行性。


<details>
  <summary>Details</summary>
Motivation: 通过讨论计划和期望特性之间的最小修改，本文旨在解决自动规划中现有解释方法的局限性，即无法捕捉问题的高级特性。

Method: 本文提出了两种定性实例化的反事实场景，基于对必须满足预期特性的计划的显式量化。然后，从不同类型的变化允许在$P$上时，表征了生成这种反事实场景的计算复杂度。

Result: 研究结果表明，生成反事实场景通常只需与计算$P$的计划一样昂贵，从而证明了提议的实用性。

Conclusion: 本文提出了一种基于反事实场景的新型解释范式，用于解释自动规划中计划的预期特性。研究表明生成反事实场景通常只有计算计划本身的代价高，并展示了该提议的实际可行性，为在该领域构建实用算法提供了框架。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [14] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI is a GenAI framework that simplifies process mining in healthcare by integrating Python and R libraries with Large Language Models for automated interpretation and report generation. It addresses unfamiliarity with process mining outputs, demonstrating robust technical performance and the ability to generate reports through automated LLM analysis. Evaluation with five LLMs showed distinct strengths of different models, with Claude Sonnet-4 and Gemini 2.5-Pro achieving the highest consistency scores.


<details>
  <summary>Details</summary>
Motivation: The paper addressed the barriers in applying process mining in healthcare such as technical complexity, lack of standardized approaches, and limited training resources. The motivation was to simplify process mining applications in healthcare and epidemiology by providing a comprehensive framework that integrates Python and R libraries with LLMs. The aim was to improve accessibility, translate technical analyses into understandable outputs, and make process mining results more accessible to clinicians, data scientists, and researchers.

Method: The paper introduced HealthProcessAI, a GenAI framework that wraps around existing Python and R libraries (PM4PY and bupaR) to simplify process mining in healthcare. It integrated multiple Large Language Models (LLMs) for automated process map interpretation and report generation. The validation was done using sepsis progression data and comparison of five LLM models through the OpenRouter platform. The framework successfully processed sepsis data in proof-of-concept scenarios, demonstrating technical performance and report generation capabilities through automated LLM analysis. Evaluation with five independent LLMs showed distinct strengths of different models, with Claude Sonnet-4 and Gemini 2.5-Pro achieving the highest consistency scores when evaluated by automated LLM assessors.

Result: The framework successfully processed sepsis data, demonstrating robust technical performance and the capability to generate reports through automated LLM analysis. Evaluation with five LLMs revealed distinct strengths of different models, with Claude Sonnet-4 and Gemini 2.5-Pro achieving the highest consistency scores. By integrating LLMs for automated interpretation and report generation, the framework addressed unfamiliarity with process mining outputs, making them accessible to a diverse range of users and representing a methodological advance in translating complex results into actionable insights for healthcare.

Conclusion: HealthProcessAI is a GenAI framework that simplifies process mining applications in healthcare by integrating Python and R libraries with Large Language Models for automated process map interpretation and report generation. The framework has been validated using sepsis progression data, showcasing robust technical performance and the ability to generate reports through automated LLM analysis. It addresses the unfamiliarity with process mining outputs, making them accessible to a diverse range of users like clinicians, data scientists, and researchers, thus representing a methodological advance in translating complex results into actionable insights for healthcare.

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [15] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 本论文提出了一种新的框架，用于发现自动泛化跨领域的地标。他们基于已解决的实例学习泛化地标，扩展了领域的谓词，捕获了重复性，并构建了泛化地标图用于解决新问题实例。研究结果表明，这些泛化地标对于同一领域中的大型实例也是有效的，尤其对于识别重复循环的启发式性能提升明显。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于传统地标提取算法在某些规划问题中存在不足之处，因此提出了一种能够泛化地标并捕获重复性的新框架。他们希望通过学习这些泛化地标来解决同一领域的问题，以提高启发式的性能。

Method: 论文的方法是基于一组已解决的实例学习泛化地标，利用独立于特定问题对象的状态函数来扩展领域的谓词，并适用于所有相似对象，从而捕获了重复性。基于这些函数，构建了一个定向的泛化地标图，定义了地标的进展，包括重复子计划的循环可能性。他们展示了如何在启发式中使用这个图来解决同一领域的新问题实例。

Result: 论文结果表明，从少量小实例学习到的泛化地标图也适用于同一领域中的大型实例。当识别到表示重复的循环时，启示式性能明显提高。泛化地标能捕获对自动规划器有用的领域信息，并且可以从少量计划中发现。

Conclusion: 这篇论文提出了一种新的框架，用于发现能够自动泛化跨领域的地标。通过一组已解决的实例学习这些泛化的地标，描述了规划问题中的中间目标，在传统地标提取算法无法胜任的情况下发挥作用。研究结果表明，从少量小实例学习到的泛化地标图也适用于同一领域中的大型实例。当识别到表示重复的循环时，启示式性能明显提高。泛化地标捕获了可解释且对自动规划器有用的领域信息，这些信息可以从同一领域的少量计划中发现。

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [16] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 本文介绍了确定性去中心化POMDP领域（Det-Dec-POMDP）和迭代确定性POMDP规划（IDPP）求解器，用于解决当前Dec-POMDP求解器无法高效解决的大规模问题。


<details>
  <summary>Details</summary>
Motivation: 关注高级多智能体规划问题，如多机器人导航和路径规划，使用确定性动作和观测进行建模。针对这些领域，介绍了Det-Dec-POMDP类型的POMDP子类。

Method: 提出了迭代确定性POMDP规划（IDPP）方法，在联合均衡搜索策略框架的基础上进行优化，能有效处理大规模Det-Dec-POMDP问题。

Result: 引入了Det-Dec-POMDP领域和IDPP求解器，能有效处理大规模Det-Dec-POMDP问题。

Conclusion: 介绍了确定性去中心化POMDP（Det-Dec-POMDP）领域，提出了迭代确定性POMDP规划（IDPP）求解器，用于处理当前Dec-POMDP求解器无法高效解决的大规模Det-Dec-POMDP问题。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>


### [17] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 该论文提出了一个综合框架，结合了传统网络优化模型和大型语言模型，用于提供供应链规划的交互式、可解释和角色感知的决策支持。通过生成自然语言摘要、情境可视化和定制化关键绩效指标，弥合了运营研究结果和业务利益相关者理解之间的差距。系统通过案例研究展示了其改善规划结果的效果，并计划未来整合更多技术以提升系统能力。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于提供一个综合的决策支持框架，以改善供应链规划过程中的可解释性、交互性和角色感知。通过整合语言模型和优化模型，弥合运营研究结果与业务利益相关者理解之间的差距。

Method: 综合传统网络优化模型和大型语言模型，提出核心优化模型解决多期多物品的战术库存重新分配问题。技术架构整合了人工智能代理、RESTful API 和动态用户界面，实现实时交互、配置更新和基于模拟的洞察力。通过案例研究展示系统的效果，并提出未来的扩展计划。

Result: 通过整合了语言模型和优化模型的框架，成功实现了供应链规划中的决策支持系统，并在案例研究中展示了系统的优势，包括防止库存缺货、降低成本和保持服务水平。未来的扩展计划将进一步增强系统的可解释性和实时决策制定能力。

Conclusion: 该论文提出了一个综合框架，将传统网络优化模型与大型语言模型相结合，为供应链规划提供交互式、可解释和角色感知的决策支持。通过生成自然语言摘要、情境可视化和定制化关键绩效指标，提出的系统弥合了复杂的运营研究结果和业务利益相关者的理解之间的差距。核心优化模型涉及使用混合整数形式的多期多物品的配送中心网络的战术库存重新分配。技术架构整合了人工智能代理、RESTful API 和动态用户界面，以支持实时交互、配置更新和基于模拟的洞察力。案例研究展示了该系统如何通过防止缺货、降低成本和保持服务水平来改善规划结果。未来的扩展包括整合私人LLMs、迁移学习、强化学习和贝叶斯神经网络，以增强可解释性、适应性和实时决策制定。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


### [18] [A-MHA*: Anytime Multi-Heuristic A*](https://arxiv.org/abs/2508.21637)
*Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev*

Main category: cs.AI

TL;DR: 本文介绍了MHA*算法的扩展版本A-MHA*，通过在MHA*框架中应用ARA*算法的概念，使MHA*具有任意时间特性。A-MHA*通过快速找到可行的次优解，并持续改进，解决了原始算法一次性执行的限制。实验结果表明，A-MHA*在路径规划和拼图领域取得了良好的性能表现。


<details>
  <summary>Details</summary>
Motivation: 设计良好的启发式函数对图搜索非常重要，然而，设计启发式函数要求充分的领域知识。本文旨在解决MHA*算法在一次性执行中无法持续改进解决方案的问题，通过将MHA*扩展为任意时间版本的A-MHA*算法，能够快速找到并不断改进次优解。

Method: 本文通过扩展MHA*算法为任意时间版本的A-MHA*算法，解决了原始MHA*算法在一次性执行中无法持续改进解决方案的问题。灵感来源于ARA*算法的概念，在MHA*框架中成功应用，并证明保留了原始子优和完整性保证。

Result: A-MHA*算法成功扩展了MHA*算法为任意时间版本，解决了原始算法的局限性，并在路径规划和拼图领域表现出良好的性能。

Conclusion: 本文提出了A-MHA*算法，将MHA*算法扩展为任意时间版本，能够快速找到一个可行的次优解，并在时间耗尽前持续改进。通过在MHA*框架中精确应用ARA*算法的概念，保留了原始的次优和完整性保证，并增强了MHA*的任意时间性能。在3-D路径规划领域和滑动平铺拼图中进行了A-MHA*性能测试，并与MHA*和其他任意时间算法进行了比较。

Abstract: Designing good heuristic functions for graph search requires adequate domain
knowledge. It is often easy to design heuristics that perform well and
correlate with the underlying true cost-to-go values in certain parts of the
search space but these may not be admissible throughout the domain thereby
affecting the optimality guarantees of the search. Bounded suboptimal search
using several such partially good but inadmissible heuristics was developed in
Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible
heuristics to potentially generate a faster suboptimal solution, the original
version does not improve the solution over time. It is a one shot algorithm
that requires careful setting of inflation factors to obtain a desired one time
solution. In this work, we tackle this issue by extending MHA* to an anytime
version that finds a feasible suboptimal solution quickly and continually
improves it until time runs out. Our work is inspired from the Anytime
Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*
concepts in the MHA* framework preserves the original suboptimal and
completeness guarantees and enhances MHA* to perform in an anytime fashion.
Furthermore, we report the performance of A-MHA* in 3-D path planning domain
and sliding tiles puzzle and compare against MHA* and other anytime algorithms.

</details>


### [19] [Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI](https://arxiv.org/abs/2508.21648)
*Farhad Abtahi,Mehdi Astaraki,Fernando Seoane*

Main category: cs.AI

TL;DR: 该论文提出了MEDLEY框架，通过协调多个AI模型并保留它们多样化的输出，展示了如何在医学领域中结构多样性可以增强医学推理。该框架将AI的不完美视为一种资源，为开发值得信赖的医学AI系统开辟了新的道路。作者开发了一个概念验证演示项目，显示了如何在合成案例中同时保留共识和少数意见，使诊断不确定性和潜在偏见透明化。


<details>
  <summary>Details</summary>
Motivation: 传统观念认为医学人工智能中的偏见是一个需要消除的缺陷。然而，人类推理固有地包含由教育、文化和经验塑造的偏见，表明这些偏见的存在可能是不可避免的，也可能具有价值。基于这一观点，作者提出了MEDLEY框架，试图将AI模型的多样化输出视为有价值的内容，并在临床监督下展示AI不完美之处可以被重新解释为一种资源。

Method: 作者提出了一个名为MEDLEY的概念框架，通过协调多个人工智能模型并保留它们多样化的输出，在医学诊断中展示了结构多样性如何增强医学推理。作者还开发了一个概念验证演示项目，使用超过30个大型语言模型创建了一个最小可行产品，使合成案例中的共识和少数意见都得以保留，从而使诊断不确定性和潜在偏见对临床监督透明。

Result: 作者开发了一个名为MEDLEY的概念框架，并展示了如何通过结构多样性增强医学推理。他们还在超过30个大型语言模型上开发了一个概念验证演示项目，创建了一个最小可行产品，展示了如何在合成案例中同时保留共识和少数意见，从而使诊断不确定性和潜在偏见透明化。虽然尚未成为经过验证的临床工具，但演示表明结构多样性如何能够在临床人员监督下增强医学推理。

Conclusion: 该论文提出了一个名为MEDLEY的概念框架，旨在将多个人工智能模型协调起来，保留它们多样化的输出，而不是将它们合并为共识。通过将模型特定的偏见视为潜在的优势，并将幻觉视为临时假设以供临床人员验证，MEDLEY在医学诊断中展示了结构多样性如何增强医学推理。该框架开创了一种新的范式，将AI的不完美视为一种资源，为开发值得信赖的医学人工智能系统开辟了新的监管、道德和创新路径。

Abstract: Bias in medical artificial intelligence is conventionally viewed as a defect
requiring elimination. However, human reasoning inherently incorporates biases
shaped by education, culture, and experience, suggesting their presence may be
inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble
Diagnostic system with Leveraged diversitY), a conceptual framework that
orchestrates multiple AI models while preserving their diverse outputs rather
than collapsing them into a consensus. Unlike traditional approaches that
suppress disagreement, MEDLEY documents model-specific biases as potential
strengths and treats hallucinations as provisional hypotheses for clinician
verification. A proof-of-concept demonstrator was developed using over 30 large
language models, creating a minimum viable product that preserved both
consensus and minority views in synthetic cases, making diagnostic uncertainty
and latent biases transparent for clinical oversight. While not yet a validated
clinical tool, the demonstration illustrates how structured diversity can
enhance medical reasoning under clinician supervision. By reframing AI
imperfection as a resource, MEDLEY offers a paradigm shift that opens new
regulatory, ethical, and innovation pathways for developing trustworthy medical
AI systems.

</details>


### [20] [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](https://arxiv.org/abs/2508.21720)
*Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim*

Main category: cs.AI

TL;DR: 该论文提出了PosterForest框架，用于自动生成科学海报。通过多智能体协作策略和引入层次化中间表示Poster Tree，实现了文档结构和视觉-文本关系的联合编码。实验结果显示，该方法在生成科学海报方面表现优异，质量接近专家设计的标准，且拥有更好的信息保留、结构清晰度和用户偏好。


<details>
  <summary>Details</summary>
Motivation: 之前的方法主要忽略了科学文档的层次结构和文本 - 视觉元素的语义集成，为了解决这些挑战，本论文提出了PosterForest框架。通过改进框架，旨在实现更好的科学海报生成效果。

Method: 引入Poster Tree层次化中间表示，采用多智能体协作策略，包括内容总结和布局规划，实现了文档结构和视觉-文本关系的联合编码。通过智能体之间的迭代协调和相互反馈，实现了逻辑一致性、内容忠实度和视觉连贯性的联合优化。

Result: 通过实验验证，证明该方法在生成科学海报方面优于现有基准，实现了接近专家设计标准的质量，并提供了更优质的信息保留、结构清晰度和用户偏好。

Conclusion: 该论文提出了一种新颖的无需训练的框架，名为PosterForest，用于自动生成科学海报。通过引入层次化的中间表示Poster Tree，同时编码文档结构和视觉 - 文本关系，以解决科学文档的层次结构和文本 - 视觉元素集成的挑战。采用多智能体协作策略，涉及内容总结和布局规划的智能体相互协调，相互提供反馈。该方法实现了逻辑一致性、内容忠实度和视觉连贯性的联合优化。在多个学术领域进行了广泛实验，证明该方法在定性和定量评估中优于现有基准。生成的海报在信息保留、结构清晰度和用户偏好等方面接近专家设计的标准并提供了更优质的结果。

Abstract: We present a novel training-free framework, \textit{PosterForest}, for
automated scientific poster generation. Unlike prior approaches, which largely
neglect the hierarchical structure of scientific documents and the semantic
integration of textual and visual elements, our method addresses both
challenges directly. We introduce the \textit{Poster Tree}, a hierarchical
intermediate representation that jointly encodes document structure and
visual-textual relationships at multiple levels. Our framework employs a
multi-agent collaboration strategy, where agents specializing in content
summarization and layout planning iteratively coordinate and provide mutual
feedback. This approach enables the joint optimization of logical consistency,
content fidelity, and visual coherence. Extensive experiments on multiple
academic domains show that our method outperforms existing baselines in both
qualitative and quantitative evaluations. The resulting posters achieve quality
closest to expert-designed ground truth and deliver superior information
preservation, structural clarity, and user preference.

</details>


### [21] [Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem](https://arxiv.org/abs/2508.21730)
*Fabrizio Fagiolo,Nicolo' Vescera*

Main category: cs.AI

TL;DR: 该论文提出了一种变分算法用于解决旅行推销员问题，结合紧凑的排列编码和优化-冻结-重用策略，在40个对称实例上进行了实验，结果显示方法具有良好的泛化能力。冻结电路拓扑可以显著降低时间成本，但在7座城市的情况下存在可扩展性限制。


<details>
  <summary>Details</summary>
Motivation: 在传统旅行推销员问题的解决中，通常需要昂贵的结构研究和测试。本研究旨在提出一种有效降低量子比特需求、提高泛化能力并降低时间成本的新方法，以便在NISQ硬件上立即实施。

Method: 采用变分算法结合紧凑的排列编码和优化-冻结-重用策略，通过模拟退火优化电路拓扑，然后在新实例上重复使用冻结的电路拓扑，只重新优化电路参数。

Result: 在40个随机生成的对称实例上进行实验，对于4座城市的情况，所得的电路拓扑实现了100%的平均最佳路径采样概率，5座城市的成功率为90%，6座城市的成功率为80%。但是对于7座城市，成功率明显下降至约20%，揭示了所提方法的可扩展性限制。研究结果显示了对中等规模问题具有稳健的泛化能力，并展示了冻结电路拓扑如何显著减少解决方案的时间。

Conclusion: 该论文提出了一种用于解决旅行推销员问题的变分算法。通过采用一种紧凑的排列编码和优化-冻结-重用策略，将电路拓扑首先在训练实例上通过模拟退火进行优化，然后在新实例上“冻结”并重复使用，这有效降低了量子比特需求。研究结果表明，该方法对于中等规模问题具有良好的泛化能力，冻结电路拓扑可以显著降低解决方案的时间，而不会降低解决方案质量。另外，论文还探讨了可扩展性限制、参数的“热启动”初始化对结果的影响，以及将方法扩展至更复杂问题的展望。

Abstract: In this paper we present a variational algorithm for the Traveling Salesman
Problem (TSP) that combines (i) a compact encoding of permutations, which
reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:
where the circuit topology (``Ansatz'') is first optimized on a training
instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel
instances, limited to a rapid re-optimization of only the circuit parameters.
This pipeline eliminates costly structural research in testing, making the
procedure immediately implementable on NISQ hardware.
  On a set of $40$ randomly generated symmetric instances that span $4 - 7$
cities, the resulting Ansatz achieves an average optimal trip sampling
probability of $100\%$ for 4 city cases, $90\%$ for 5 city cases and $80\%$ for
6 city cases. With 7 cities the success rate drops markedly to an average of
$\sim 20\%$, revealing the onset of scalability limitations of the proposed
method.
  The results show robust generalization ability for moderate problem sizes and
indicate how freezing the Ansatz can dramatically reduce time-to-solution
without degrading solution quality. The paper also discusses scalability
limitations, the impact of ``warm-start'' initialization of parameters, and
prospects for extension to more complex problems, such as Vehicle Routing and
Job-Shop Scheduling.

</details>


### [22] [Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions](https://arxiv.org/abs/2508.21742)
*Timothée Loranchet,Charles K. Assaad*

Main category: cs.AI

TL;DR: 研究了在时间序列分析中使用总结性因果图进行因果推断的方法。提出了一种能够保证在微观层面对时间变量边缘定向的条件，并强调了专家知识在改善观测时间序列数据的因果推断中的重要性。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析中理解时间变量之间因果关系是一个核心挑战，尤其是当完整的因果结构未知时。即使无法完全指定完整的因果结构，专家通常也能成功提供一个称为总结性因果图的高级抽象，捕捉了不同时间序列之间的主要因果关系，同时省略了微观层面的细节。

Method: 介绍了一种能够保证在微观层面对时间变量边缘定向的条件，利用了在总结性因果图中编码的背景知识，并假设可以访问一个忠实且与真实未知图相关的分布。

Result: 为在复杂时间系统中利用总结性因果图进行因果发现提供了理论上的保证，在宏观层面存在循环或双向边缘的情况下仍能实现边缘定向。

Conclusion: 提供了一种在微观层面保证时间变量之间边缘定向的条件，即使在宏观层面存在循环或双向边缘的情况下也能实现。这些发现为在复杂时间系统中利用总结性因果图进行因果发现提供了实用指导，并强调了将专家知识纳入观测时间序列数据的因果推断中的价值。

Abstract: Understanding causal relations between temporal variables is a central
challenge in time series analysis, particularly when the full causal structure
is unknown. Even when the full causal structure cannot be fully specified,
experts often succeed in providing a high-level abstraction of the causal
graph, known as a summary causal graph, which captures the main causal
relations between different time series while abstracting away micro-level
details. In this work, we present conditions that guarantee the orientability
of micro-level edges between temporal variables given the background knowledge
encoded in a summary causal graph and assuming having access to a faithful and
causally sufficient distribution with respect to the true unknown graph. Our
results provide theoretical guarantees for edge orientation at the micro-level,
even in the presence of cycles or bidirected edges at the macro-level. These
findings offer practical guidance for leveraging SCGs to inform causal
discovery in complex temporal systems and highlight the value of incorporating
expert knowledge to improve causal inference from observational time series
data.

</details>


### [23] [Tree-Guided Diffusion Planner](https://arxiv.org/abs/2508.21800)
*Hyeonseong Jeon,Cheolhong Min,Jaesik Park*

Main category: cs.AI

TL;DR: 本文提出了一种树引导扩散规划器（TDP），用于解决多目标控制问题，在真实场景中表现优异，具有零样本泛化能力，比现有方法性能更好。


<details>
  <summary>Details</summary>
Motivation: 现有的梯度引导方法在真实场景中的有效性受到限制，需要特定任务的训练或价值评估器，影响了测试时的灵活性和零样本泛化能力。为解决这一问题，提出了TDP框架以提高规划性能。

Method: 将测试时规划作为一棵树搜索问题来解决，通过一种双层采样过程平衡探索和开发，在训练时通过无需任务特定训练或价值评估器的粒子引导产生多样化的父轨迹，然后通过快速有条件去噪精细调整子轨迹。利用预训练模型和测试时奖励信号，在扩展的解决空间中利用梯度信息。

Result: 在迷宫黄金捡取、机械臂方块操作和AntMaze多目标探索任务中，TDP表现出优于现有方法的性能。

Conclusion: 提出了一种树引导扩散规划器（TDP），用于解决多目标控制问题，能够在非凸目标、非可微分约束和多重奖励结构等真实场景中高效工作，实现了零样本泛化。在迷宫黄金捡取、机械臂方块操作和AntMaze多目标探索任务中，TDP表现出优于现有方法的性能。

Abstract: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.

</details>


### [24] [Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture](https://arxiv.org/abs/2508.21803)
*Yeawon Lee,Xiaoyang Wang,Christopher C. Yang*

Main category: cs.AI

TL;DR: 本文介绍了一种协作多智能体系统（MAS），模拟临床会诊团队来提高临床文本识别准确性。在评估中，MAS相对于单一代理基线展示了在识别特定临床问题方面的改进。系统通过层次化、迭代式辩论有效展现了冲突证据，但有时可能受到群体思维的影响。


<details>
  <summary>Details</summary>
Motivation: 临床文本的准确解释对患者护理至关重要，但这些笔记的复杂性使自动化变得具有挑战性。传统的单一模型方法可能无法满足高风险临床任务所需的鲁棒性。因此，本文提出了MAS系统以填补这一空白。

Method: 本文介绍了一个协作多智能体系统（MAS），模拟临床会诊团队来解决临床文本自动识别的挑战。系统通过分析SOAP笔记中的主观（S）和客观（O）部分，模拟将原始数据合成评估的诊断推理过程。系统通过主管代理（Manager agent）指挥一组动态指定的专家代理团队进行层次化、迭代式辩论来达成共识。

Result: 在评估中，MAS相对于单一代理基线展示了在识别充血性心力衰竭、急性肾损伤和败血症方面的持续改进。代理团队有效展现了冲突证据并通过辩论达成共识，但有时容易受到群体思维的影响。

Conclusion: 本文提出了一种协作多智能体系统（MAS），模拟临床会诊团队以提高临床文本识别准确性。通过对420个MIMIC-III病例笔记的实验评估，MAS在识别充血性心力衰竭、急性肾损伤和败血症方面表现出明显改进。系统有效地展现了冲突证据，并通过层次化、迭代式辩论达成共识。然而，有时容易受到群体思维影响。该系统模拟了临床团队的推理过程，为更准确、更稳健、更可解释的临床决策支持工具提供了有希望的路径。

Abstract: Accurate interpretation of clinical narratives is critical for patient care,
but the complexity of these notes makes automation challenging. While Large
Language Models (LLMs) show promise, single-model approaches can lack the
robustness required for high-stakes clinical tasks. We introduce a
collaborative multi-agent system (MAS) that models a clinical consultation team
to address this gap. The system is tasked with identifying clinical problems by
analyzing only the Subjective (S) and Objective (O) sections of SOAP notes,
simulating the diagnostic reasoning process of synthesizing raw data into an
assessment. A Manager agent orchestrates a dynamically assigned team of
specialist agents who engage in a hierarchical, iterative debate to reach a
consensus. We evaluated our MAS against a single-agent baseline on a curated
dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration
demonstrated consistently improved performance in identifying congestive heart
failure, acute kidney injury, and sepsis. Qualitative analysis of the agent
debates reveals that this structure effectively surfaces and weighs conflicting
evidence, though it can occasionally be susceptible to groupthink. By modeling
a clinical team's reasoning process, our system offers a promising path toward
more accurate, robust, and interpretable clinical decision support tools.

</details>
