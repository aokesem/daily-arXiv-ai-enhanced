{"id": "2507.08001", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.08001", "abs": "https://arxiv.org/abs/2507.08001", "authors": ["Shengyi Xie"], "title": "Human Creativity and AI", "comment": null, "summary": "With the advancement of science and technology, the philosophy of creativity\nhas undergone significant reinterpretation. This paper investigates\ncontemporary research in the fields of psychology, cognitive neuroscience, and\nthe philosophy of creativity, particularly in the context of the development of\nartificial intelligence (AI) techniques. It aims to address the central\nquestion: Can AI exhibit creativity? The paper reviews the historical\nperspectives on the philosophy of creativity and explores the influence of\npsychological advancements on the study of creativity. Furthermore, it analyzes\nvarious definitions of creativity and examines the responses of naturalism and\ncognitive neuroscience to the concept of creativity.", "AI": {"tldr": "This paper explores whether AI can exhibit creativity by analyzing historical views on creativity, psychological advancements' impact, different definitions of creativity, and responses from naturalism and cognitive neuroscience.", "motivation": "With the evolution of science and technology, the understanding of creativity has evolved significantly. This paper aims to investigate how AI can demonstrate creativity by delving into research in psychology, cognitive neuroscience, and the philosophy of creativity.", "method": "The paper reviews historical perspectives on the philosophy of creativity, analyzes psychological advancements' influence on the study of creativity, examines various definitions of creativity, and explores the responses of naturalism and cognitive neuroscience to the concept of creativity.", "result": "The paper provides insights into the possibility of AI exhibiting creativity and offers a comprehensive analysis of the interactions between AI techniques and the study of creativity from various perspectives.", "conclusion": "AI has the potential to exhibit creativity, and this paper explores the intersection of AI techniques with psychology, cognitive neuroscience, and the philosophy of creativity to address this question."}}
{"id": "2507.08046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08046", "abs": "https://arxiv.org/abs/2507.08046", "authors": ["Sishi Xiong", "Dakai Wang", "Yu Zhao", "Jie Zhang", "Changzai Pan", "Haowei He", "Xiangyu Li", "Wenhan Chang", "Zhongjiang He", "Shuangyong Song", "Yongxiang Li"], "title": "TableReasoner: Advancing Table Reasoning Framework with Large Language Models", "comment": null, "summary": "The paper presents our system developed for table question answering (TQA).\nTQA tasks face challenges due to the characteristics of real-world tabular\ndata, such as large size, incomplete column semantics, and entity ambiguity. To\naddress these issues, we propose a large language model (LLM)-powered and\nprogramming-based table reasoning framework, named TableReasoner. It models a\ntable using the schema that combines structural and semantic representations,\nenabling holistic understanding and efficient processing of large tables. We\ndesign a multi-step schema linking plan to derive a focused table schema that\nretains only query-relevant information, eliminating ambiguity and alleviating\nhallucinations. This focused table schema provides precise and sufficient table\ndetails for query refinement and programming. Furthermore, we integrate the\nreasoning workflow into an iterative thinking architecture, allowing\nincremental cycles of thinking, reasoning and reflection. Our system achieves\nfirst place in both subtasks of SemEval-2025 Task 8.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86TableReasoner\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7a0b\uff0c\u7528\u4e8e\u89e3\u51b3\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6311\u6218\u3002\u901a\u8fc7\u6a21\u5f0f\u5316\u8868\u683c\u5efa\u6a21\u548c\u8fed\u4ee3\u601d\u7ef4\u67b6\u6784\uff0c\u7cfb\u7edf\u5728SemEval-2025 Task 8\u7684\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u7b2c\u4e00\u540d\u7684\u6210\u7ee9\u3002", "motivation": "\u89e3\u51b3\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u9762\u4e34\u7684\u6311\u6218\uff0c\u5982\u5927\u578b\u6570\u636e\u3001\u4e0d\u5b8c\u6574\u7684\u5217\u8bed\u4e49\u548c\u5b9e\u4f53\u7684\u6b67\u4e49\u3002\u901a\u8fc7\u7efc\u5408\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7a0b\uff0c\u8bbe\u8ba1\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5927\u8868\u683c\u5e76\u6d88\u9664\u6b67\u4e49\u7684TableReasoner\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7a0b\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u4e86TableReasoner\u6846\u67b6\uff0c\u5e76\u5b9e\u73b0\u4e86\u7ed3\u6784\u548c\u8bed\u4e49\u8868\u793a\u7684\u6a21\u5f0f\u5316\u8868\u683c\u5efa\u6a21\u3002\u901a\u8fc7\u591a\u6b65\u9aa4\u7684\u6a21\u5f0f\u94fe\u63a5\u8ba1\u5212\u63d0\u53d6\u5173\u6ce8\u7279\u5b9a\u67e5\u8be2\u7684\u8868\u683c\u6a21\u5f0f\uff0c\u96c6\u6210\u63a8\u7406\u5de5\u4f5c\u6d41\u5230\u8fed\u4ee3\u601d\u7ef4\u67b6\u6784\u4e2d\u3002", "result": "\u8be5\u7cfb\u7edf\u5728SemEval-2025 Task 8\u7684\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\uff0c\u8868\u660e\u6240\u63d0\u51fa\u7684TableReasoner\u6846\u67b6\u5728\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7a0b\u7684\u8868\u683c\u63a8\u7406\u6846\u67b6TableReasoner\uff0c\u7528\u4e8e\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u3002\u901a\u8fc7\u7ed3\u6784\u548c\u8bed\u4e49\u8868\u793a\u76f8\u7ed3\u5408\u7684\u6a21\u5f0f\u5efa\u6a21\u8868\u683c\uff0c\u5b9e\u73b0\u5bf9\u5927\u8868\u683c\u7684\u6574\u4f53\u7406\u89e3\u548c\u9ad8\u6548\u5904\u7406\u3002\u8bbe\u8ba1\u4e86\u591a\u6b65\u9aa4\u7684\u6a21\u5f0f\u94fe\u63a5\u8ba1\u5212\uff0c\u63d0\u53d6\u5173\u6ce8\u7279\u5b9a\u67e5\u8be2\u7684\u8868\u683c\u6a21\u5f0f\uff0c\u6d88\u9664\u6b67\u4e49\u548c\u51cf\u8f7b\u9519\u89c9\u3002\u901a\u8fc7\u5c06\u63a8\u7406\u5de5\u4f5c\u6d41\u96c6\u6210\u5230\u8fed\u4ee3\u601d\u7ef4\u67b6\u6784\u4e2d\uff0c\u5141\u8bb8\u601d\u8003\u3001\u63a8\u7406\u548c\u53cd\u601d\u7684\u589e\u91cf\u5faa\u73af\u3002\u8be5\u7cfb\u7edf\u5728SemEval-2025 Task 8\u7684\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u53d6\u5f97\u7b2c\u4e00\u540d\u7684\u6210\u7ee9\u3002"}}
{"id": "2507.08207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08207", "abs": "https://arxiv.org/abs/2507.08207", "authors": ["Zhengye Han", "Quanyan Zhu"], "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in critical\napplications, the challenge of jailbreaking, where adversaries manipulate the\nmodels to bypass safety mechanisms, has become a significant concern. This\npaper presents a dynamic Stackelberg game framework to model the interactions\nbetween attackers and defenders in the context of LLM jailbreaking. The\nframework treats the prompt-response dynamics as a sequential extensive-form\ngame, where the defender, as the leader, commits to a strategy while\nanticipating the attacker's optimal responses. We propose a novel agentic AI\nsolution, the \"Purple Agent,\" which integrates adversarial exploration and\ndefensive strategies using Rapidly-exploring Random Trees (RRT). The Purple\nAgent actively simulates potential attack trajectories and intervenes\nproactively to prevent harmful outputs. This approach offers a principled\nmethod for analyzing adversarial dynamics and provides a foundation for\nmitigating the risk of jailbreaking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21LLM jailbreaking\u7684\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u4e92\u52a8\u3002\u8bbe\u8ba1\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u7d2b\u8272\u7279\u5de5\u201d\u7684AI\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7RRT\u7ed3\u5408\u654c\u5bf9\u63a2\u7d22\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u6709\u6548\u9884\u9632\u6076\u610f\u8f93\u51fa\uff0c\u4e3a\u5206\u6790\u5bf9\u6297\u52a8\u6001\u548c\u964d\u4f4e\u8d8a\u72f1\u98ce\u9669\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u8d8a\u6765\u8d8a\u591a\uff0c\u8d8a\u72f1\u6311\u6218\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\u6709\u5fc5\u8981\u5efa\u7acb\u4e00\u4e2a\u6a21\u578b\u6765\u5206\u6790\u548c\u9884\u9632\u5bf9\u6297\u52a8\u6001\uff0c\u51cf\u8f7bLLM\u88ab\u653b\u51fb\u7684\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u52a8\u6001Stackelberg\u535a\u5f08\u6846\u67b6\u5efa\u6a21LLM jailbreaking\u7684\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u4e92\u52a8\uff0c\u8bbe\u8ba1\u4e86\u201c\u7d2b\u8272\u7279\u5de5\u201dAI\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528Rapidly-exploring Random Trees\uff08RRT\uff09\u7ed3\u5408\u654c\u5bf9\u63a2\u7d22\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u4e3b\u52a8\u6a21\u62df\u6f5c\u5728\u653b\u51fb\u8def\u5f84\u5e76\u91c7\u53d6\u9884\u9632\u63aa\u65bd\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5206\u6790LLM\u8d8a\u72f1\u653b\u51fb\u7684\u65b0\u9896\u65b9\u6cd5\uff0c\u901a\u8fc7\u201c\u7d2b\u8272\u7279\u5de5\u201dAI\u89e3\u51b3\u65b9\u6848\u6709\u6548\u9884\u9632\u6076\u610f\u8f93\u51fa\uff0c\u5e76\u4e3a\u964d\u4f4e\u8d8a\u72f1\u98ce\u9669\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21LLM\u8d8a\u72f1\u653b\u51fb\u4e2d\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u4e4b\u95f4\u7684\u4e92\u52a8\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u578bAI\u89e3\u51b3\u65b9\u6848\u201c\u7d2b\u8272\u7279\u5de5\u201d\uff0c\u7ed3\u5408\u654c\u5bf9\u63a2\u7d22\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u6709\u6548\u5730\u9884\u9632\u6076\u610f\u8f93\u51fa\uff0c\u4e3a\u5206\u6790\u5bf9\u6297\u52a8\u6001\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4ece\u800c\u51cf\u8f7b\u8d8a\u72f1\u98ce\u9669\u3002"}}
{"id": "2507.08208", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.08208", "abs": "https://arxiv.org/abs/2507.08208", "authors": ["Quanyan Zhu"], "title": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions", "comment": null, "summary": "We introduce the LLM-Nash framework, a game-theoretic model where agents\nselect reasoning prompts to guide decision-making via Large Language Models\n(LLMs). Unlike classical games that assume utility-maximizing agents with full\nrationality, this framework captures bounded rationality by modeling the\nreasoning process explicitly. Equilibrium is defined over the prompt space,\nwith actions emerging as the behavioral output of LLM inference. This approach\nenables the study of cognitive constraints, mindset expressiveness, and\nepistemic learning. Through illustrative examples, we show how reasoning\nequilibria can diverge from classical Nash outcomes, offering a new foundation\nfor strategic interaction in LLM-enabled systems.", "AI": {"tldr": "The paper introduces the LLM-Nash framework, a game-theoretic model that explores how agents' choice of reasoning prompts in Large Language Models can affect decision-making. It addresses bounded rationality, models reasoning explicitly, and shows divergent outcomes from classical Nash equilibria through examples, offering insights into strategic interactions in LLM-enabled systems.", "motivation": "Addressing the limitations of traditional game models by considering bounded rationality and explicitly modeling reasoning processes in LLMs.", "method": "Proposing a game-theoretic model where agents choose reasoning prompts to influence decision-making in Large Language Models (LLMs) to study cognitive constraints, mindset expressiveness, and epistemic learning.", "result": "Demonstrating through examples how reasoning equilibria in the LLM-Nash framework can differ from classical Nash outcomes, providing a new basis for analyzing strategic interactions in systems utilizing LLMs.", "conclusion": "Introducing the LLM-Nash framework that incorporates bounded rationality and explicit modeling of the reasoning process, leading to divergent outcomes from classical Nash equilibria."}}
{"id": "2507.08210", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08210", "abs": "https://arxiv.org/abs/2507.08210", "authors": ["Fryderyk Mantiuk", "Hanqi Zhou", "Charley M. Wu"], "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration", "comment": null, "summary": "What drives an agent to explore the world while also maintaining control over\nthe environment? From a child at play to scientists in the lab, intelligent\nagents must balance curiosity (the drive to seek knowledge) with competence\n(the drive to master and control the environment). Bridging cognitive theories\nof intrinsic motivation with reinforcement learning, we ask how evolving\ninternal representations mediate the trade-off between curiosity (novelty or\ninformation gain) and competence (empowerment). We compare two model-based\nagents using handcrafted state abstractions (Tabular) or learning an internal\nworld model (Dreamer). The Tabular agent shows curiosity and competence guide\nexploration in distinct patterns, while prioritizing both improves exploration.\nThe Dreamer agent reveals a two-way interaction between exploration and\nrepresentation learning, mirroring the developmental co-evolution of curiosity\nand competence. Our findings formalize adaptive exploration as a balance\nbetween pursuing the unknown and the controllable, offering insights for\ncognitive theories and efficient reinforcement learning.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u667a\u80fdAgent\u5728\u63a2\u7d22\u548c\u63a7\u5236\u73af\u5883\u65f6\u5982\u4f55\u5e73\u8861\u597d\u5947\u5fc3\u548c\u80fd\u529b\uff0c\u7814\u7a76\u4e86\u5185\u90e8\u8868\u5f81\u5bf9\u63a2\u7d22\u4e2d\u597d\u5947\u5fc3\u548c\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e86\u4f7f\u7528\u4e0d\u540c\u65b9\u6cd5\u7684Agent\uff0c\u5e76\u53d1\u73b0\u4e86\u63a2\u7d22\u4e0e\u8868\u793a\u5b66\u4e60\u4e4b\u95f4\u7684\u53cc\u5411\u4e92\u52a8\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u8ba4\u77e5\u7406\u8bba\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u542f\u793a\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u5c06\u8ba4\u77e5\u5185\u5728\u52a8\u673a\u7406\u8bba\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u7814\u7a76\u5185\u90e8\u8868\u5f81\u5982\u4f55\u8c03\u8282\u597d\u5947\u5fc3\u548c\u80fd\u529b\u7684\u5e73\u8861\uff0c\u4ece\u800c\u5f62\u5f0f\u5316\u9002\u5e94\u6027\u63a2\u7d22\u4e3a\u8ffd\u6c42\u672a\u77e5\u548c\u53ef\u63a7\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "method": "\u8bba\u6587\u6bd4\u8f83\u4e86\u4f7f\u7528\u624b\u5de5\u72b6\u6001\u62bd\u8c61\uff08Tabular\uff09\u548c\u5b66\u4e60\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff08Dreamer\uff09\u7684\u4e24\u79cd\u57fa\u4e8e\u6a21\u578b\u7684Agent\u3002Tabular Agent\u663e\u793a\u597d\u5947\u5fc3\u548c\u80fd\u529b\u5728\u4e0d\u540c\u6a21\u5f0f\u4e0b\u5f15\u5bfc\u63a2\u7d22\uff0c\u800c\u540c\u65f6\u4f18\u5148\u8003\u8651\u4e8c\u8005\u53ef\u6539\u5584\u63a2\u7d22\u3002Dreamer Agent\u63ed\u793a\u4e86\u63a2\u7d22\u548c\u8868\u793a\u5b66\u4e60\u4e4b\u95f4\u7684\u53cc\u5411\u4e92\u52a8\u3002", "result": "\u8bba\u6587\u7684\u7814\u7a76\u7ed3\u679c\u4e3a\u8ba4\u77e5\u7406\u8bba\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u6d1e\u89c1\uff0c\u5e76\u9610\u660e\u4e86\u63a2\u7d22\u7684\u5e73\u8861\u673a\u5236\u3002", "conclusion": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u667a\u80fdAgent\u5728\u63a2\u7d22\u4e16\u754c\u7684\u540c\u65f6\u4fdd\u6301\u5bf9\u73af\u5883\u7684\u63a7\u5236\uff0c\u7814\u7a76\u4e86\u597d\u5947\u5fc3\u4e0e\u80fd\u529b\u4e4b\u95f4\u7684\u5e73\u8861\u5173\u7cfb\uff0c\u4ee5\u53ca\u5185\u90e8\u8868\u5f81\u5982\u4f55\u5f71\u54cd\u597d\u5947\u5fc3\u548c\u80fd\u529b\u7684\u6743\u8861\u3002\u7814\u7a76\u53d1\u73b0\u4f7f\u7528\u5185\u90e8\u4e16\u754c\u6a21\u578b\u7684Agent\u8868\u73b0\u51fa\u63a2\u7d22\u548c\u8868\u793a\u5b66\u4e60\u4e4b\u95f4\u7684\u53cc\u5411\u4e92\u52a8\uff0c\u53cd\u6620\u4e86\u597d\u5947\u5fc3\u548c\u80fd\u529b\u7684\u53d1\u5c55\u5171\u540c\u6f14\u5316\u3002"}}
{"id": "2507.08216", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08216", "abs": "https://arxiv.org/abs/2507.08216", "authors": ["Rodrigo Castellano Ontiveros", "Francesco Giannini", "Marco Gori", "Giuseppe Marra", "Michelangelo Diligenti"], "title": "Grounding Methods for Neural-Symbolic AI", "comment": null, "summary": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to\nprocess the input entities, while relying on a reasoner based on First-Order\nLogic to represent and process more complex relationships among the entities. A\nfundamental role for these methods is played by the process of logic grounding,\nwhich determines the relevant substitutions for the logic rules using a\n(sub)set of entities. Some NeSy methods use an exhaustive derivation of all\npossible substitutions, preserving the full expressive power of the logic\nknowledge. This leads to a combinatorial explosion in the number of ground\nformulas to consider and, therefore, strongly limits their scalability. Other\nmethods rely on heuristic-based selective derivations, which are generally more\ncomputationally efficient, but lack a justification and provide no guarantees\nof preserving the information provided to and returned by the reasoner. Taking\ninspiration from multi-hop symbolic reasoning, this paper proposes a\nparametrized family of grounding methods generalizing classic Backward\nChaining. Different selections within this family allow us to obtain commonly\nemployed grounding methods as special cases, and to control the trade-off\nbetween expressiveness and scalability of the reasoner. The experimental\nresults show that the selection of the grounding criterion is often as\nimportant as the NeSy method itself.", "AI": {"tldr": "\u672c\u6587\u63a2\u8a0e\u4e86Neural-Symbolic\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684grounding\u554f\u984c\uff0c\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684parametrized grounding\u65b9\u6cd5\u5bb6\u65cf\uff0c\u901a\u904e\u4e0d\u540c\u9078\u64c7\u53ef\u4ee5\u63a7\u5236\u63a8\u7406\u5668\u7684\u8868\u9054\u80fd\u529b\u548c\u53ef\u64f4\u5c55\u6027\u4e4b\u9593\u7684\u5e73\u8861\u3002\u5be6\u9a57\u7d50\u679c\u5f37\u8abf\u4e86grounding\u6a19\u6e96\u7684\u9078\u64c7\u5c0d\u65bcNeSy\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73fe\u6709\u7684Neural-Symbolic\u65b9\u6cd5\u4e2d\uff0c\u5b58\u5728\u4e00\u4e9bgrounding\u65b9\u6cd5\u6703\u5c0e\u81f4\u63a8\u7406\u6a39\u7684\u7d44\u5408\u7206\u70b8\uff0c\u56b4\u91cd\u9650\u5236\u4e86\u5176\u53ef\u64f4\u5c55\u6027\u3002\u672c\u6587\u9748\u611f\u4f86\u6e90\u65bc\u591a\u8df3\u7b26\u865f\u63a8\u7406\uff0c\u63d0\u51fa\u4e00\u500b\u65b0\u7684grounding\u65b9\u6cd5\u5bb6\u65cf\uff0c\u4ee5\u89e3\u6c7a\u8868\u9054\u80fd\u529b\u548c\u53ef\u64f4\u5c55\u6027\u4e4b\u9593\u7684\u6298\u8877\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u53c3\u6578\u5316\u7684grounding\u65b9\u6cd5\u5bb6\u65cf\uff0c\u901a\u904e\u5c0d\u9019\u500b\u5bb6\u65cf\u4e2d\u4e0d\u540c\u9078\u64c7\u7684\u4f7f\u7528\uff0c\u53ef\u4ee5\u63a7\u5236\u63a8\u7406\u5668\u7684\u8868\u9054\u80fd\u529b\u548c\u53ef\u64f4\u5c55\u6027\u4e4b\u9593\u7684\u5e73\u8861\u3002", "result": "\u901a\u904e\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cgrounding\u6a19\u6e96\u7684\u9078\u64c7\u5c0d\u65bcNeSy\u65b9\u6cd5\u7684\u6548\u679c\u540c\u6a23\u91cd\u8981\u3002", "conclusion": "\u9019\u7bc7\u8ad6\u6587\u63d0\u51fa\u4e00\u500b\u53c3\u6578\u5316\u7684grounding\u65b9\u6cd5\u5bb6\u65cf\uff0c\u53ef\u4ee5\u6cdb\u5316\u7d93\u5178\u7684Backward Chaining\u65b9\u6cd5\uff0c\u901a\u904e\u4e0d\u540c\u7684\u9078\u64c7\u5728\u9019\u500b\u5bb6\u65cf\u4e2d\u53ef\u4ee5\u7372\u5f97\u5e38\u7528\u7684grounding\u65b9\u6cd5\uff0c\u4e26\u4e14\u63a7\u5236\u63a8\u7406\u5668\u7684\u8868\u9054\u80fd\u529b\u548c\u53ef\u64f4\u5c55\u6027\u4e4b\u9593\u7684\u6298\u8877\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cgrounding\u6a19\u6e96\u7684\u9078\u64c7\u901a\u5e38\u8207NeSy\u65b9\u6cd5\u672c\u8eab\u540c\u7b49\u91cd\u8981\u3002"}}
{"id": "2507.08217", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08217", "abs": "https://arxiv.org/abs/2507.08217", "authors": ["Atit Pokharel", "Ratun Rahman", "Thomas Morris", "Dinh C. Nguyen"], "title": "Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach", "comment": "This paper was presented at BEAM with CVPR 2025", "summary": "Quantum federated learning (QFL) has been recently introduced to enable a\ndistributed privacy-preserving quantum machine learning (QML) model training\nacross quantum processors (clients). Despite recent research efforts, existing\nQFL frameworks predominantly focus on unimodal systems, limiting their\napplicability to real-world tasks that often naturally involve multiple\nmodalities. To fill this significant gap, we present for the first time a novel\nmultimodal approach specifically tailored for the QFL setting with the\nintermediate fusion using quantum entanglement. Furthermore, to address a major\nbottleneck in multimodal QFL, where the absence of certain modalities during\ntraining can degrade model performance, we introduce a Missing Modality\nAgnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring\nstable training without corrupted states. Simulation results demonstrate that\nthe proposed multimodal QFL method with MMA yields an improvement in accuracy\nof 6.84% in independent and identically distributed (IID) and 7.25% in non-IID\ndata distributions compared to the state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9QFL\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\u548c\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u6a21\u6001\u65b9\u6cd5\u53caMissing Modality Agnostic\uff08MMA\uff09\u673a\u5236\uff0c\u901a\u8fc7\u91cf\u5b50\u7ea0\u7f20\u5b9e\u73b0\u4e2d\u95f4\u878d\u5408\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001QFL\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u5ea6\u3002\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728IID\u548c\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u51c6\u786e\u5ea6\u63d0\u5347\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709QFL\u6846\u67b6\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u6a21\u6001\u7cfb\u7edf\u4e0a\uff0c\u5bf9\u4e8e\u73b0\u5b9e\u4efb\u52a1\u4e2d\u6d89\u53ca\u591a\u79cd\u6a21\u6001\u7684\u5e94\u7528\u6709\u9650\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u91cd\u8981\u7a7a\u767d\u3002\u901a\u8fc7\u65b0\u9896\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u548cMMA\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001QFL\u4e2d\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002", "method": "\u9488\u5bf9QFL\u8bbe\u7f6e\uff0c\u5f15\u5165\u4e86\u591a\u6a21\u6001\u65b9\u6cd5\u548cMMA\u673a\u5236\u3002\u4f7f\u7528\u91cf\u5b50\u7ea0\u7f20\u5b9e\u73b0\u4e2d\u95f4\u878d\u5408\uff0c\u9694\u79bb\u672a\u8bad\u7ec3\u7684\u91cf\u5b50\u7535\u8def\u4ee5\u786e\u4fdd\u8bad\u7ec3\u8fc7\u7a0b\u7a33\u5b9a\u3002\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u8bc1\u660e\u4e86\u63d0\u51fa\u7684\u591a\u6a21\u6001QFL\u65b9\u6cd5\u7ed3\u5408MMA\u673a\u5236\u5728IID\u548c\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u5206\u522b\u63d0\u9ad8\u4e866.84%\u548c7.25%\u7684\u51c6\u786e\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\uff08QFL\uff09\u7684\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50\u7ea0\u7f20\u8fdb\u884c\u4e2d\u95f4\u878d\u5408\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u5ea6\u3002\u5f15\u5165\u4e86Missing Modality Agnostic\uff08MMA\uff09\u673a\u5236\uff0c\u786e\u4fdd\u5728\u591a\u6a21\u6001QFL\u4e2d\u8bad\u7ec3\u8fc7\u7a0b\u7a33\u5b9a\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728IID\u548c\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\uff0c\u63d0\u51fa\u7684\u591a\u6a21\u6001QFL\u65b9\u6cd5\u7ed3\u5408MMA\u53ef\u4ee5\u4f7f\u51c6\u786e\u5ea6\u5206\u522b\u63d0\u9ad8\u4e866.84%\u548c7.25%\u3002"}}
{"id": "2507.08249", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.08249", "abs": "https://arxiv.org/abs/2507.08249", "authors": ["Bill Marino", "Ari Juels"], "title": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm", "comment": null, "summary": "There is growing interest in giving AI agents access to cryptocurrencies as\nwell as to the smart contracts that transact them. But doing so, this position\npaper argues, could lead to formidable new vectors of AI harm. To support this\nargument, we first examine the unique properties of cryptocurrencies and smart\ncontracts that could lead to these new vectors of harm. Next, we describe each\nof these new vectors of harm in detail. Finally, we conclude with a call for\nmore technical research aimed at preventing and mitigating these harms and,\nthereby making it safer to endow AI agents with cryptocurrencies and smart\ncontracts.", "AI": {"tldr": "\u672c\u6587\u5bf9\u7ed9\u4e88AI\u4ee3\u7406\u8bbf\u95ee\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u53ef\u80fd\u5e26\u6765\u7684\u65b0\u98ce\u9669\u8fdb\u884c\u4e86\u63a2\u8ba8\uff0c\u63cf\u8ff0\u4e86\u8fd9\u4e9b\u65b0\u98ce\u9669\u5e76\u547c\u5401\u52a0\u5f3a\u6280\u672f\u7814\u7a76\u4ee5\u964d\u4f4e\u98ce\u9669\u3002", "motivation": "\u63a2\u8ba8\u7ed9\u4e88AI\u4ee3\u7406\u8bbf\u95ee\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u7684\u589e\u957f\u5174\u8da3\uff0c\u63d0\u51fa\u8fd9\u53ef\u80fd\u5bfc\u81f4\u65b0\u7684AI\u4f24\u5bb3\u6e20\u9053\u3002\u9488\u5bf9\u8fd9\u4e00\u89c2\u70b9\uff0c\u547c\u5401\u52a0\u5f3a\u5bf9\u6f5c\u5728\u98ce\u9669\u7684\u7814\u7a76\u3002", "method": "\u9996\u5148\u7814\u7a76\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u7684\u72ec\u7279\u5c5e\u6027\uff0c\u63a2\u8ba8\u53ef\u80fd\u5bfc\u81f4\u65b0\u98ce\u9669\u7684\u56e0\u7d20\uff0c\u7136\u540e\u8be6\u7ec6\u63cf\u8ff0\u8fd9\u4e9b\u65b0\u98ce\u9669\uff0c\u5e76\u547c\u5401\u8fdb\u884c\u66f4\u591a\u6280\u672f\u7814\u7a76\u4ee5\u9884\u9632\u548c\u51cf\u8f7b\u8fd9\u4e9b\u98ce\u9669\u3002", "result": "\u901a\u8fc7\u5206\u6790\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u7684\u7279\u6027\uff0c\u5e76\u63cf\u8ff0\u65b0\u7684\u98ce\u9669\u6e20\u9053\uff0c\u52a0\u5f3a\u4e86\u5bf9AI\u4ee3\u7406\u4e0e\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u6f5c\u5728\u98ce\u9669\u7684\u8ba4\u8bc6\u3002", "conclusion": "\u547c\u5401\u8fdb\u884c\u66f4\u591a\u7684\u6280\u672f\u7814\u7a76\uff0c\u4ee5\u9632\u6b62\u548c\u51cf\u8f7bAI\u4ee3\u7406\u4e0e\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u4ea7\u751f\u98ce\u9669\uff0c\u4ece\u800c\u4f7fAI\u4ee3\u7406\u5177\u6709\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u66f4\u52a0\u5b89\u5168\u3002"}}
{"id": "2507.08264", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08264", "abs": "https://arxiv.org/abs/2507.08264", "authors": ["Abhinav Sood", "Kazjon Grace", "Stephen Wan", "Cecile Paris"], "title": "Abductive Computational Systems: Creative Abduction and Future Directions", "comment": "Published in the 16th International Conference on Computational\n  Creativity, ICCC25. Accepted Paper in\n  https://computationalcreativity.net/iccc25/wp-content/uploads/papers/iccc25-sood2025abductive.pdf", "summary": "Abductive reasoning, reasoning for inferring explanations for observations,\nis often mentioned in scientific, design-related and artistic contexts, but its\nunderstanding varies across these domains. This paper reviews how abductive\nreasoning is discussed in epistemology, science and design, and then analyses\nhow various computational systems use abductive reasoning. Our analysis shows\nthat neither theoretical accounts nor computational implementations of\nabductive reasoning adequately address generating creative hypotheses.\nTheoretical frameworks do not provide a straightforward model for generating\ncreative abductive hypotheses, computational systems largely implement\nsyllogistic forms of abductive reasoning. We break down abductive computational\nsystems into components and conclude by identifying specific directions for\nfuture research that could advance the state of creative abductive reasoning in\ncomputational systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u7efc\u8ff0\u4e86Abductive Reasoning\u5728\u8ba4\u8bc6\u8bba\u3001\u79d1\u5b66\u548c\u8bbe\u8ba1\u9886\u57df\u7684\u8ba8\u8bba\u60c5\u51b5\uff0c\u5206\u6790\u4e86\u8ba1\u7b97\u7cfb\u7edf\u5e94\u7528Abductive Reasoning\u7684\u65b9\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u7684\u7406\u8bba\u6846\u67b6\u548c\u8ba1\u7b97\u7cfb\u7edf\u5e76\u672a\u6709\u6548\u89e3\u51b3\u751f\u6210\u521b\u9020\u6027\u5047\u8bbe\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3Abductive Reasoning\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u7406\u89e3\u7684\u5dee\u5f02\u95ee\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u7406\u8bba\u6846\u67b6\u548c\u8ba1\u7b97\u7cfb\u7edf\u5728\u751f\u6210\u521b\u9020\u6027\u5047\u8bbe\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u7814\u7a76\u65e8\u5728\u4fc3\u8fdb\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u521b\u9020\u6027Abductive Reasoning\u7684\u53d1\u5c55\u3002", "method": "\u8be5\u8bba\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u5206\u6790\u7814\u7a76\u4e86Abductive Reasoning\u5728\u8ba4\u8bc6\u8bba\u3001\u79d1\u5b66\u548c\u8bbe\u8ba1\u9886\u57df\u7684\u8ba8\u8bba\u72b6\u51b5\uff0c\u5e76\u8c03\u67e5\u4e86\u8ba1\u7b97\u7cfb\u7edf\u5982\u4f55\u5e94\u7528Abductive Reasoning\u3002\u7814\u7a76\u91c7\u7528\u5206\u6790\u65b9\u6cd5\uff0c\u5bf9\u73b0\u6709\u7684\u7406\u8bba\u6846\u67b6\u548c\u8ba1\u7b97\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\uff0c\u6307\u51fa\u5b83\u4eec\u5728\u751f\u6210\u521b\u9020\u6027\u5047\u8bbe\u65b9\u9762\u5b58\u5728\u7684\u4e0d\u8db3\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u7684Abductive Reasoning\u7406\u8bba\u6846\u67b6\u548c\u8ba1\u7b97\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u521b\u9020\u6027\u5047\u8bbe\u751f\u6210\u7684\u6709\u6548\u65b9\u6cd5\u3002\u7406\u8bba\u6846\u67b6\u4e0d\u80fd\u76f4\u63a5\u652f\u6301\u521b\u9020\u6027Abductive\u5047\u8bbe\u7684\u751f\u6210\uff0c\u800c\u8ba1\u7b97\u7cfb\u7edf\u4e3b\u8981\u91c7\u7528\u6f14\u7ece\u5f62\u5f0f\u7684Abductive Reasoning\u3002\u901a\u8fc7\u5bf9\u8ba1\u7b97\u7cfb\u7edf\u8fdb\u884c\u62c6\u89e3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5177\u4f53\u65b9\u5411\u3002", "conclusion": "\u8be5\u8bba\u6587\u603b\u7ed3\u4e86\u76ee\u524d\u5173\u4e8eAbductive Reasoning\u5728\u4e0d\u540c\u9886\u57df\uff08\u8ba4\u8bc6\u8bba\u3001\u79d1\u5b66\u548c\u8bbe\u8ba1\uff09\u7684\u8ba8\u8bba\u60c5\u51b5\uff0c\u5e76\u5206\u6790\u4e86\u5404\u79cd\u8ba1\u7b97\u7cfb\u7edf\u5982\u4f55\u4f7f\u7528Abductive Reasoning\u3002\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u6709\u7684\u7406\u8bba\u6846\u67b6\u548c\u8ba1\u7b97\u7cfb\u7edf\u5bf9\u4e8e\u751f\u6210\u521b\u9020\u6027\u5047\u8bbe\u5e76\u4e0d\u8db3\u591f\u3002\u7406\u8bba\u6846\u67b6\u6ca1\u6709\u63d0\u4f9b\u76f4\u63a5\u7684\u751f\u6210\u521b\u9020\u6027Abductive\u5047\u8bbe\u7684\u6a21\u578b\uff0c\u8ba1\u7b97\u7cfb\u7edf\u4e3b\u8981\u5b9e\u73b0\u4e86\u6f14\u7ece\u5f62\u5f0f\u7684Abductive Reasoning\u3002\u7814\u7a76\u5c06Abductive\u8ba1\u7b97\u7cfb\u7edf\u5206\u89e3\u4e3a\u4e0d\u540c\u7ec4\u4ef6\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u7684\u5177\u4f53\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u521b\u9020\u6027Abductive Reasoning\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.08270", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.08270", "abs": "https://arxiv.org/abs/2507.08270", "authors": ["Zeyang Sha", "Hanling Tian", "Zhuoer Xu", "Shiwen Cui", "Changhua Meng", "Weiqiang Wang"], "title": "Agent Safety Alignment via Reinforcement Learning", "comment": null, "summary": "The emergence of autonomous Large Language Model (LLM) agents capable of tool\nusage has introduced new safety risks that go beyond traditional conversational\nmisuse. These agents, empowered to execute external functions, are vulnerable\nto both user-initiated threats (e.g., adversarial prompts) and tool-initiated\nthreats (e.g., malicious outputs from compromised tools). In this paper, we\npropose the first unified safety-alignment framework for tool-using agents,\nenabling models to handle both channels of threat via structured reasoning and\nsandboxed reinforcement learning. We introduce a tri-modal taxonomy, including\nbenign, malicious, and sensitive for both user prompts and tool responses, and\ndefine a policy-driven decision model. Our framework employs a custom-designed\nsandbox environment that simulates real-world tool execution and allows\nfine-grained reward shaping. Through extensive evaluations on public and\nself-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we\ndemonstrate that our safety-aligned agents significantly improve resistance to\nsecurity threats while preserving strong utility on benign tasks. Our results\nshow that safety and effectiveness can be jointly optimized, laying the\ngroundwork for trustworthy deployment of autonomous LLM agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u7684\u7edf\u4e00\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u4e09\u6a21\u6001\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u8bbe\u8ba1\u7684\u6c99\u76d2\u73af\u5883\u6a21\u62df\u5b9e\u9645\u5de5\u5177\u6267\u884c\uff0c\u5c55\u793a\u4e86\u5b89\u5168\u5bf9\u9f50\u4ee3\u7406\u5728\u5b89\u5168\u5a01\u80c1\u62b5\u6297\u80fd\u529b\u65b9\u9762\u7684\u663e\u8457\u6539\u8fdb\u3002\u7ed3\u679c\u8868\u660e\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\u53ef\u4ee5\u540c\u65f6\u5f97\u5230\u4f18\u5316\uff0c\u4e3a\u81ea\u4e3bLLM\u4ee3\u7406\u7684\u53ef\u4fe1\u90e8\u7f72\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u81ea\u4e3b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u51fa\u73b0\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u8d85\u8d8a\u4f20\u7edf\u5bf9\u8bdd\u8bef\u7528\u7684\u8003\u8651\u3002\u73b0\u6709\u4ee3\u7406\u53ef\u4ee5\u6267\u884c\u5916\u90e8\u529f\u80fd\uff0c\u56e0\u6b64\u5bb9\u6613\u53d7\u5230\u7528\u6237\u53d1\u8d77\u7684\u5a01\u80c1\u548c\u5de5\u5177\u53d1\u8d77\u7684\u5a01\u80c1\u7684\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u5e94\u5bf9\u8fd9\u79cd\u65b0\u578b\u5a01\u80c1\uff0c\u63d0\u51fa\u7edf\u4e00\u7684\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u4ee5\u4fdd\u8bc1\u6a21\u578b\u5728\u9762\u5bf9\u5a01\u80c1\u65f6\u80fd\u591f\u505a\u51fa\u6b63\u786e\u7684\u51b3\u7b56\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u81ea\u5b9a\u4e49\u8bbe\u8ba1\u7684\u6c99\u76d2\u73af\u5883\u6a21\u62df\u5b9e\u9645\u5de5\u5177\u6267\u884c\uff0c\u5141\u8bb8\u7cbe\u7ec6\u5316\u5956\u52b1\u5851\u9020\u3002\u5f15\u5165\u4e86\u4e09\u6a21\u6001\u5206\u7c7b\u6cd5\uff0c\u5305\u62ec\u826f\u6027\u3001\u6076\u610f\u548c\u654f\u611f\uff0c\u4e3a\u7528\u6237\u63d0\u793a\u548c\u5de5\u5177\u54cd\u5e94\u8fdb\u884c\u5b9a\u4e49\uff0c\u5efa\u7acb\u57fa\u4e8e\u7b56\u7565\u7684\u51b3\u7b56\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5b89\u5168\u5bf9\u9f50\u4ee3\u7406\u5728\u5b89\u5168\u5a01\u80c1\u62b5\u6297\u80fd\u529b\u65b9\u9762\u7684\u663e\u8457\u6539\u8fdb\uff0c\u540c\u65f6\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u6548\u7528\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\u53ef\u4ee5\u540c\u65f6\u5f97\u5230\u4f18\u5316\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u7684\u7edf\u4e00\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u5229\u7528\u7ed3\u6784\u5316\u63a8\u7406\u548c\u6c99\u7bb1\u5f3a\u5316\u5b66\u4e60\u5e2e\u52a9\u6a21\u578b\u5904\u7406\u7528\u6237\u53d1\u8d77\u7684\u5a01\u80c1\u548c\u5de5\u5177\u53d1\u8d77\u7684\u5a01\u80c1\u3002\u901a\u8fc7\u5728\u516c\u5171\u548c\u81ea\u5efa\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5b89\u5168\u5bf9\u9f50\u4ee3\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u62b5\u6297\u5b89\u5168\u5a01\u80c1\u7684\u80fd\u529b\uff0c\u540c\u65f6\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u4fdd\u6301\u5f3a\u5927\u7684\u6548\u7528\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\u53ef\u4ee5\u540c\u65f6\u4f18\u5316\uff0c\u4e3a\u81ea\u4e3bLLM\u4ee3\u7406\u7684\u53ef\u4fe1\u90e8\u7f72\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.08306", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.08306", "abs": "https://arxiv.org/abs/2507.08306", "authors": ["Inclusion AI", ":", "Fudong Wang", "Jiajia Liu", "Jingdong Chen", "Jun Zhou", "Kaixiang Ji", "Lixiang Ru", "Qingpei Guo", "Ruobing Zheng", "Tianqi Li", "Yi Yuan", "Yifan Mao", "Yuting Xiao", "Ziping Ma"], "title": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "comment": "31pages, 14 figures", "summary": "Recent advancements in Multimodal Large Language Models (MLLMs), particularly\nthrough Reinforcement Learning with Verifiable Rewards (RLVR), have\nsignificantly enhanced their reasoning abilities. However, a critical gap\npersists: these models struggle with dynamic spatial interactions, a capability\nessential for real-world applications. To bridge this gap, we introduce\nM2-Reasoning-7B, a model designed to excel in both general and spatial\nreasoning. Our approach integrates two key innovations: (1) a novel data\npipeline that generates 294.2K high-quality data samples (168K for cold-start\nfine-tuning and 126.2K for RLVR), which feature logically coherent reasoning\ntrajectories and have undergone comprehensive assessment; and (2) a dynamic\nmulti-task training strategy with step-wise optimization to mitigate conflicts\nbetween data, and task-specific rewards for delivering tailored incentive\nsignals. This combination of curated data and advanced training allows\nM2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks,\nshowcasing superior performance in both general and spatial reasoning domains.", "AI": {"tldr": "Recent advancements in Multimodal Large Language Models have led to the development of M2-Reasoning-7B, which excels in general and spatial reasoning. The model integrates innovative data pipeline and dynamic multi-task training strategy to enhance reasoning abilities across 8 benchmarks, setting a new state-of-the-art in both domains.", "motivation": "Existing Multimodal Large Language Models struggle with dynamic spatial interactions, crucial for real-world applications. The goal is to enhance reasoning abilities in both general and spatial domains.", "method": "Integrates a novel data pipeline to generate high-quality data samples for cold-start fine-tuning and RLVR, and implements a dynamic multi-task training strategy with step-wise optimization to address conflicts between data and provide task-specific rewards for tailored incentive signals.", "result": "The model M2-Reasoning-7B outperforms previous models, achieving state-of-the-art results in 8 benchmarks for general and spatial reasoning.", "conclusion": "M2-Reasoning-7B sets a new state-of-the-art across 8 benchmarks, demonstrating superior performance in both general and spatial reasoning domains."}}
{"id": "2507.08392", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.08392", "abs": "https://arxiv.org/abs/2507.08392", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "title": "Multi-Agent LLMs as Ethics Advocates in AI-Based Systems", "comment": null, "summary": "Incorporating ethics into the requirement elicitation process is essential\nfor creating ethically aligned systems. Although eliciting manual ethics\nrequirements is effective, it requires diverse input from multiple\nstakeholders, which can be challenging due to time and resource constraints.\nMoreover, it is often given a low priority in the requirements elicitation\nprocess. This study proposes a framework for generating ethics requirements\ndrafts by introducing an ethics advocate agent in a multi-agent LLM setting.\nThis agent critiques and provides input on ethical issues based on the system\ndescription. The proposed framework is evaluated through two case studies from\ndifferent contexts, demonstrating that it captures the majority of ethics\nrequirements identified by researchers during 30-minute interviews and\nintroduces several additional relevant requirements. However, it also\nhighlights reliability issues in generating ethics requirements, emphasizing\nthe need for human feedback in this sensitive domain. We believe this work can\nfacilitate the broader adoption of ethics in the requirements engineering\nprocess, ultimately leading to more ethically aligned products.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u9053\u5fb7\u5021\u5bfc\u8005\u4ee3\u7406\u5728\u591a\u667a\u80fd\u4f53LLM\u8bbe\u7f6e\u4e2d\uff0c\u5bf9\u7cfb\u7edf\u63cf\u8ff0\u7684\u9053\u5fb7\u95ee\u9898\u8fdb\u884c\u6279\u5224\u548c\u63d0\u4f9b\u610f\u89c1\uff0c\u751f\u6210\u9053\u5fb7\u8981\u6c42\u8349\u6848\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u53d1\u73b0\u5176\u6709\u6548\u6355\u6349\u4e86\u5927\u90e8\u5206\u7814\u7a76\u4eba\u5458\u5728\u77ed\u65f6\u95f4\u5185\u8bc6\u522b\u7684\u9053\u5fb7\u8981\u6c42\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e9b\u5176\u4ed6\u76f8\u5173\u8981\u6c42\u3002\u7136\u800c\uff0c\u4e5f\u6307\u51fa\u4e86\u5728\u751f\u6210\u9053\u5fb7\u8981\u6c42\u65b9\u9762\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u5728\u8fd9\u4e00\u654f\u611f\u9886\u57df\u4e2d\u9700\u8981\u4eba\u7c7b\u53cd\u9988\u7684\u5fc5\u8981\u6027\u3002\u7814\u7a76\u8ba4\u4e3a\u8fd9\u9879\u5de5\u4f5c\u53ef\u4ee5\u4fc3\u8fdb\u9053\u5fb7\u5728\u9700\u6c42\u5de5\u7a0b\u8fc7\u7a0b\u4e2d\u7684\u66f4\u5e7f\u6cdb\u91c7\u7528\uff0c\u6700\u7ec8\u5bfc\u81f4\u66f4\u7b26\u5408\u9053\u5fb7\u7684\u4ea7\u54c1\u3002", "motivation": "\u5c06\u9053\u5fb7\u7eb3\u5165\u9700\u6c42\u5f15\u51fa\u8fc7\u7a0b\u5bf9\u4e8e\u521b\u5efa\u7b26\u5408\u9053\u5fb7\u7684\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u7684\u624b\u52a8\u9053\u5fb7\u8981\u6c42\u5f15\u51fa\u867d\u7136\u6709\u6548\uff0c\u4f46\u9700\u8981\u6765\u81ea\u591a\u4e2a\u5229\u76ca\u76f8\u5173\u8005\u7684\u591a\u6837\u5316\u8f93\u5165\uff0c\u7531\u4e8e\u65f6\u95f4\u548c\u8d44\u6e90\u9650\u5236\u53ef\u80fd\u5b58\u5728\u6311\u6218\u3002\u6b64\u5916\uff0c\u5728\u9700\u6c42\u5f15\u51fa\u8fc7\u7a0b\u4e2d\u901a\u5e38\u5c06\u5176\u4f18\u5148\u7ea7\u964d\u4f4e\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u9053\u5fb7\u5021\u5bfc\u8005\u4ee3\u7406\u5728\u591a\u667a\u80fd\u4f53LLM\u8bbe\u7f6e\u4e2d\uff0c\u5bf9\u7cfb\u7edf\u63cf\u8ff0\u7684\u9053\u5fb7\u95ee\u9898\u8fdb\u884c\u6279\u5224\u548c\u63d0\u4f9b\u610f\u89c1\uff0c\u751f\u6210\u9053\u5fb7\u8981\u6c42\u8349\u6848\u3002\u901a\u8fc7\u4e24\u4e2a\u4e0d\u540c\u80cc\u666f\u7684\u6848\u4f8b\u7814\u7a76\u5bf9\u63d0\u51fa\u7684\u6846\u67b6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u63d0\u51fa\u7684\u6846\u67b6\uff0c\u53d1\u73b0\u5176\u6355\u6349\u4e86\u5927\u90e8\u5206\u7814\u7a76\u4eba\u5458\u572830\u5206\u949f\u8bbf\u8c08\u4e2d\u8bc6\u522b\u7684\u9053\u5fb7\u8981\u6c42\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e9b\u5176\u4ed6\u76f8\u5173\u8981\u6c42\u3002\u7136\u800c\uff0c\u4e5f\u7a81\u51fa\u4e86\u5728\u751f\u6210\u9053\u5fb7\u8981\u6c42\u65b9\u9762\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u5728\u8fd9\u4e00\u654f\u611f\u9886\u57df\u4e2d\u9700\u8981\u4eba\u7c7b\u53cd\u9988\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u591a\u667a\u80fd\u4f53LLM\u73af\u5883\u4e2d\u5f15\u5165\u9053\u5fb7\u5021\u5bfc\u8005\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9053\u5fb7\u8981\u6c42\u8349\u6848\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4e24\u4e2a\u4e0d\u540c\u80cc\u666f\u7684\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u572830\u5206\u949f\u8bbf\u8c08\u4e2d\u8bc6\u522b\u7684\u5927\u90e8\u5206\u9053\u5fb7\u8981\u6c42\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e9b\u5176\u4ed6\u76f8\u5173\u8981\u6c42\u3002\u7136\u800c\uff0c\u5b83\u4e5f\u5f3a\u8c03\u4e86\u5728\u751f\u6210\u9053\u5fb7\u8981\u6c42\u65f6\u5b58\u5728\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u5728\u8fd9\u4e00\u654f\u611f\u9886\u57df\u9700\u8981\u4eba\u7c7b\u53cd\u9988\u7684\u5fc5\u8981\u6027\u3002\u7814\u7a76\u8ba4\u4e3a\u8fd9\u9879\u5de5\u4f5c\u53ef\u4ee5\u4fc3\u8fdb\u9053\u5fb7\u5728\u9700\u6c42\u5de5\u7a0b\u8fc7\u7a0b\u4e2d\u7684\u66f4\u5e7f\u6cdb\u91c7\u7528\uff0c\u6700\u7ec8\u5bfc\u81f4\u66f4\u7b26\u5408\u9053\u5fb7\u7684\u4ea7\u54c1\u3002"}}
{"id": "2507.08454", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 03B05", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2507.08454", "abs": "https://arxiv.org/abs/2507.08454", "authors": ["Tobias Geibinger", "Reijo Jaakkola", "Antti Kuusisto", "Xinghan Liu", "Miikka Vilander"], "title": "Why this and not that? A Logic-based Framework for Contrastive Explanations", "comment": "20 pages, accepted to JELIA 2025", "summary": "We define several canonical problems related to contrastive explanations,\neach answering a question of the form ''Why P but not Q?''. The problems\ncompute causes for both P and Q, explicitly comparing their differences. We\ninvestigate the basic properties of our definitions in the setting of\npropositional logic. We show, inter alia, that our framework captures a\ncardinality-minimal version of existing contrastive explanations in the\nliterature. Furthermore, we provide an extensive analysis of the computational\ncomplexities of the problems. We also implement the problems for CNF-formulas\nusing answer set programming and present several examples demonstrating how\nthey work in practice.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5bf9\u6bd4\u89e3\u91ca\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u6bd4\u5982\u201c\u4e3a\u4ec0\u4e48\u662fP\u800c\u4e0d\u662fQ\uff1f\u201d\u5229\u7528\u547d\u9898\u903b\u8f91\u6846\u67b6\u5b9a\u4e49\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5176\u57fa\u672c\u5c5e\u6027\u548c\u8ba1\u7b97\u590d\u6742\u6027\u5206\u6790\u3002\u901a\u8fc7\u7b54\u6848\u96c6\u7f16\u7a0b\u5b9e\u73b0\u4e86\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5448\u73b0\u4e86\u5b9e\u9645\u793a\u4f8b\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u6d89\u53ca\u5bf9\u6bd4\u89e3\u91ca\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u65b9\u6cd5\u548c\u5b9e\u73b0\u8fd9\u4e9b\u95ee\u9898\u7684\u65b9\u5f0f\u3002\u901a\u8fc7\u6bd4\u8f83P\u548cQ\u7684\u539f\u56e0\uff0c\u63a2\u7d22\u4e86\u5bf9\u6bd4\u89e3\u91ca\u7684\u65b0\u89c6\u89d2\u3002", "method": "\u7814\u7a76\u4e86\u5bf9\u6bd4\u89e3\u91ca\u7684\u51e0\u4e2a\u7ecf\u5178\u95ee\u9898\uff0c\u5e76\u5728\u547d\u9898\u903b\u8f91\u6846\u67b6\u4e0b\u5b9a\u4e49\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002\u5c55\u793a\u4e86\u8ba1\u7b97\u5bf9\u95ee\u9898\u7684\u57fa\u672c\u5c5e\u6027\u548c\u8ba1\u7b97\u590d\u6742\u6027\u8fdb\u884c\u4e86\u5206\u6790\u3002\u901a\u8fc7\u7b54\u6848\u96c6\u7f16\u7a0b\u5b9e\u73b0\u4e86\u5bf9\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5448\u73b0\u4e86\u5b9e\u9645\u793a\u4f8b\u3002", "result": "\u901a\u8fc7\u547d\u9898\u903b\u8f91\u7684\u5b9a\u4e49\uff0c\u8bba\u6587\u63d0\u4f9b\u4e86\u5bf9\u6bd4\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u6355\u6349\u73b0\u6709\u5bf9\u6bd4\u89e3\u91ca\u7248\u672c\u7684\u80fd\u529b\u4ee5\u53ca\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u5206\u6790\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u7b54\u6848\u96c6\u7f16\u7a0b\u5b9e\u73b0\u4e86\u5bf9\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u8be5\u8bba\u6587\u5b9a\u4e49\u4e86\u51e0\u4e2a\u6d89\u53ca\u5bf9\u6bd4\u89e3\u91ca\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u56de\u7b54\u4e86\u201c\u4e3a\u4ec0\u4e48\u662fP\u800c\u4e0d\u662fQ\uff1f\u201d\u8fd9\u79cd\u5f62\u5f0f\u7684\u95ee\u9898\u3002\u4ed6\u4eec\u8ba1\u7b97\u4e86P\u548cQ\u7684\u539f\u56e0\uff0c\u5e76\u660e\u786e\u6bd4\u8f83\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u5728\u547d\u9898\u903b\u8f91\u8bbe\u7f6e\u4e0b\u7814\u7a76\u4e86\u5b9a\u4e49\u7684\u57fa\u672c\u5c5e\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u6355\u6349\u5230\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u5b58\u5728\u7684\u5bf9\u6bd4\u89e3\u91ca\u7684\u57fa\u6570\u6700\u5c0f\u7248\u672c\u3002\u6b64\u5916\uff0c\u5bf9\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5206\u6790\u3002\u8fd8\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\u4e3aCNF\u516c\u5f0f\u5b9e\u73b0\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u51e0\u4e2a\u793a\u4f8b\u6765\u6f14\u793a\u5b83\u4eec\u5728\u5b9e\u8df5\u4e2d\u7684\u8fd0\u4f5c\u3002"}}
{"id": "2507.08501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08501", "abs": "https://arxiv.org/abs/2507.08501", "authors": ["Keying Yang", "Hao Wang", "Kai Yang"], "title": "From Language to Logic: A Bi-Level Framework for Structured Reasoning", "comment": null, "summary": "Structured reasoning over natural language inputs remains a core challenge in\nartificial intelligence, as it requires bridging the gap between unstructured\nlinguistic expressions and formal logical representations. In this paper, we\npropose a novel \\textbf{bi-level framework} that maps language to logic through\na two-stage process: high-level task abstraction and low-level logic\ngeneration. At the upper level, a large language model (LLM) parses natural\nlanguage queries into intermediate structured representations specifying the\nproblem type, objectives, decision variables, and symbolic constraints. At the\nlower level, the LLM uses these representations to generate symbolic workflows\nor executable reasoning programs for accurate and interpretable decision\nmaking. The framework supports modular reasoning, enforces explicit\nconstraints, and generalizes across domains such as mathematical problem\nsolving, question answering, and logical inference. We further optimize the\nframework with an end-to-end {bi-level} optimization approach that jointly\nrefines both the high-level abstraction and low-level logic generation stages.\nExperiments on multiple realistic reasoning benchmarks demonstrate that our\napproach significantly outperforms existing baselines in accuracy, with\naccuracy gains reaching as high as 40\\%. Moreover, the bi-level design enhances\ntransparency and error traceability, offering a promising step toward\ntrustworthy and systematic reasoning with LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u7ea7\u4efb\u52a1\u62bd\u8c61\u548c\u4f4e\u7ea7\u903b\u8f91\u751f\u6210\u5c06\u81ea\u7136\u8bed\u8a00\u6620\u5c04\u5230\u903b\u8f91\u8868\u793a\u3002\u4f7f\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\u4f18\u5316\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u73b0\u5b9e\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7cbe\u5ea6\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u7cbe\u5ea6\u63d0\u9ad8\u8fbe\u523040%\u3002\u53cc\u5c42\u8bbe\u8ba1\u589e\u5f3a\u4e86\u900f\u660e\u6027\u548c\u9519\u8bef\u53ef\u8ffd\u6eaf\u6027\uff0c\u4e3a\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53ef\u4fe1\u8d56\u548c\u7cfb\u7edf\u63a8\u7406\u8fc8\u51fa\u4e86\u6709\u76ca\u7684\u4e00\u6b65\u3002", "motivation": "\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u4e2d\uff0c\u7ed3\u6784\u5316\u63a8\u7406\u4ecd\u7136\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u4e0e\u5f62\u5f0f\u903b\u8f91\u8868\u793a\u4e4b\u95f4\u7684\u6865\u6881\u3002\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u63d0\u51fa\u4e00\u79cd\u6846\u67b6\uff0c\u4ee5\u66f4\u597d\u5730\u5c06\u81ea\u7136\u8bed\u8a00\u6620\u5c04\u5230\u903b\u8f91\u8868\u793a\uff0c\u652f\u6301\u591a\u9886\u57df\u63a8\u7406\uff0c\u5e76\u5728\u7cbe\u5ea6\u3001\u900f\u660e\u6027\u548c\u9519\u8bef\u8ffd\u6eaf\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u5c42\u6846\u67b6\uff0c\u5305\u62ec\u9ad8\u7ea7\u4efb\u52a1\u62bd\u8c61\u548c\u4f4e\u7ea7\u903b\u8f91\u751f\u6210\u9636\u6bb5\uff0c\u901a\u8fc7\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5e76\u751f\u6210\u7ed3\u6784\u5316\u8868\u793a\uff0c\u8fdb\u800c\u751f\u6210\u7b26\u53f7\u5de5\u4f5c\u6d41\u6216\u53ef\u6267\u884c\u63a8\u7406\u7a0b\u5e8f\u3002\u4f18\u5316\u6846\u67b6\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u5b8c\u5584\u9ad8\u7ea7\u62bd\u8c61\u548c\u4f4e\u7ea7\u903b\u8f91\u751f\u6210\u9636\u6bb5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5728\u591a\u4e2a\u73b0\u5b9e\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u7cbe\u5ea6\u65b9\u9762\u5927\u5e45\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\uff0c\u7cbe\u5ea6\u63d0\u9ad8\u8fbe\u523040%\u3002\u53cc\u5c42\u8bbe\u8ba1\u589e\u5f3a\u4e86\u900f\u660e\u6027\u548c\u9519\u8bef\u53ef\u8ffd\u6eaf\u6027\uff0c\u4e3a\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53ef\u4fe1\u8d56\u548c\u7cfb\u7edf\u63a8\u7406\u8fc8\u51fa\u4e86\u6709\u76ca\u7684\u4e00\u6b65\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u5c42\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u7ea7\u4efb\u52a1\u62bd\u8c61\u548c\u4f4e\u7ea7\u903b\u8f91\u751f\u6210\u5c06\u81ea\u7136\u8bed\u8a00\u6620\u5c04\u5230\u903b\u8f91\u8868\u793a\uff0c\u652f\u6301\u6a21\u5757\u5316\u63a8\u7406\uff0c\u5f3a\u5236\u663e\u5f0f\u7ea6\u675f\uff0c\u5e76\u5728\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u3001\u95ee\u7b54\u548c\u903b\u8f91\u63a8\u7406\u7b49\u9886\u57df\u5177\u6709\u6cdb\u5316\u80fd\u529b\u3002\u4f7f\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\u4f18\u5316\u6846\u67b6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u591a\u4e2a\u73b0\u5b9e\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7cbe\u5ea6\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u7cbe\u5ea6\u63d0\u9ad8\u8fbe\u523040%\u3002\u53cc\u5c42\u8bbe\u8ba1\u589e\u5f3a\u4e86\u900f\u660e\u6027\u548c\u9519\u8bef\u53ef\u8ffd\u6eaf\u6027\uff0c\u4e3a\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53ef\u4fe1\u8d56\u548c\u7cfb\u7edf\u63a8\u7406\u8fc8\u51fa\u4e86\u6709\u76ca\u7684\u4e00\u6b65\u3002"}}
{"id": "2507.08529", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.08529", "abs": "https://arxiv.org/abs/2507.08529", "authors": ["Mingda Zhang", "Na Zhao", "Jianglong Qin", "Guoyu Ye", "Ruixiang Tang"], "title": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "comment": "10 pages,3 figures", "summary": "Despite advances from medical large language models in healthcare,\nrare-disease diagnosis remains hampered by insufficient\nknowledge-representation depth, limited concept understanding, and constrained\nclinical reasoning. We propose a framework that couples multi-granularity\nsparse activation of medical concepts with a hierarchical knowledge graph. Four\ncomplementary matching algorithms, diversity control, and a five-level fallback\nstrategy enable precise concept activation, while a three-layer knowledge graph\n(taxonomy, clinical features, instances) provides structured, up-to-date\ncontext. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09,\nROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89\napproaching the 0.90 clinical threshold. Expert evaluation confirms\nimprovements in information quality, reasoning, and professional expression,\nsuggesting our approach shortens the \"diagnostic odyssey\" for rare-disease\npatients.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\uff0c\u8026\u5408\u591a\u7c92\u5ea6\u7a00\u758f\u6fc0\u6d3b\u533b\u5b66\u6982\u5ff5\u548c\u5206\u5c42\u77e5\u8bc6\u56fe\uff0c\u901a\u8fc7\u591a\u79cd\u7b97\u6cd5\u5b9e\u73b0\u7cbe\u786e\u6982\u5ff5\u6fc0\u6d3b\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u7f55\u89c1\u75be\u75c5\u8bca\u65ad\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u4e13\u5bb6\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u4fe1\u606f\u8d28\u91cf\u548c\u63a8\u7406\u80fd\u529b\u7684\u6539\u8fdb\uff0c\u6709\u52a9\u4e8e\u7f29\u77ed\u7f55\u89c1\u75be\u75c5\u60a3\u8005\u7684\u8bca\u65ad\u65f6\u95f4\u3002", "motivation": "\u533b\u7597\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u4fdd\u5065\u9886\u57df\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u7f55\u89c1\u75be\u75c5\u8bca\u65ad\u4ecd\u53d7\u5230\u77e5\u8bc6\u8868\u793a\u6df1\u5ea6\u4e0d\u8db3\u3001\u6982\u5ff5\u7406\u89e3\u6709\u9650\u548c\u4e34\u5e8a\u63a8\u7406\u53d7\u9650\u7684\u5f71\u54cd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u672c\u7814\u7a76\u7684\u65b9\u6cd5\u3002", "method": "\u8026\u5408\u591a\u7c92\u5ea6\u7a00\u758f\u6fc0\u6d3b\u533b\u5b66\u6982\u5ff5\u548c\u5206\u5c42\u77e5\u8bc6\u56fe\u7684\u6846\u67b6\uff0c\u56db\u79cd\u5339\u914d\u7b97\u6cd5\u3001\u591a\u6837\u6027\u63a7\u5236\u548c\u4e94\u7ea7\u5907\u7528\u7b56\u7565\u5b9e\u73b0\u7cbe\u786e\u6982\u5ff5\u6fc0\u6d3b\u3002\u4e09\u5c42\u77e5\u8bc6\u56fe\uff08\u5206\u7c7b\u3001\u4e34\u5e8a\u7279\u5f81\u3001\u5b9e\u4f8b\uff09\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u6700\u65b0\u7684\u4e0a\u4e0b\u6587\u3002", "result": "\u5728BioASQ\u7f55\u89c1\u75be\u75c5QA\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53d6\u5f97\u4e86\u53ef\u89c2\u7684\u63d0\u5347\uff0c\u5305\u62ecBLEU\u589e\u76ca\u4e3a0.09\uff0cROUGE\u589e\u76ca\u4e3a0.05\uff0c\u51c6\u786e\u5ea6\u589e\u76ca\u4e3a0.12\uff0c\u4e14\u51c6\u786e\u5ea6\u63a5\u8fd1\u4e34\u5e8a\u9608\u503c\u3002\u4e13\u5bb6\u8bc4\u4f30\u786e\u8ba4\u4e86\u4fe1\u606f\u8d28\u91cf\u3001\u63a8\u7406\u548c\u4e13\u4e1a\u8868\u8fbe\u7b49\u65b9\u9762\u7684\u6539\u8fdb\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8026\u5408\u591a\u7c92\u5ea6\u7a00\u758f\u6fc0\u6d3b\u533b\u5b66\u6982\u5ff5\u548c\u5206\u5c42\u77e5\u8bc6\u56fe\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u79cd\u4e92\u8865\u7684\u5339\u914d\u7b97\u6cd5\u3001\u591a\u6837\u6027\u63a7\u5236\u548c\u4e94\u7ea7\u5907\u7528\u7b56\u7565\u5b9e\u73b0\u7cbe\u786e\u6982\u5ff5\u6fc0\u6d3b\u3002\u4e09\u5c42\u77e5\u8bc6\u56fe\uff08\u5206\u7c7b\u3001\u4e34\u5e8a\u7279\u5f81\u3001\u5b9e\u4f8b\uff09\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u6700\u65b0\u7684\u4e0a\u4e0b\u6587\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728BioASQ\u7f55\u89c1\u75be\u75c5QA\u6570\u636e\u96c6\u4e0a\uff0cBLEU\u589e\u76ca\u4e3a0.09\uff0cROUGE\u589e\u76ca\u4e3a0.05\uff0c\u51c6\u786e\u5ea6\u589e\u76ca\u4e3a0.12\uff0c\u51c6\u786e\u5ea6\u8fbe\u52300.89\uff0c\u63a5\u8fd10.90\u7684\u4e34\u5e8a\u9608\u503c\u3002\u4e13\u5bb6\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u4fe1\u606f\u8d28\u91cf\u3001\u63a8\u7406\u548c\u4e13\u4e1a\u8868\u8fbe\u65b9\u9762\u7684\u6539\u8fdb\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u7f29\u77ed\u4e86\u7f55\u89c1\u75be\u75c5\u60a3\u8005\u7684\u201c\u8bca\u65ad\u5965\u5fb7\u8d5b\u201d\u3002"}}
{"id": "2507.08575", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.08575", "abs": "https://arxiv.org/abs/2507.08575", "authors": ["Kalana Wijegunarathna", "Kristin Stock", "Christopher B. Jones"], "title": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing", "comment": null, "summary": "Millions of biological sample records collected in the last few centuries\narchived in natural history collections are un-georeferenced. Georeferencing\ncomplex locality descriptions associated with these collection samples is a\nhighly labour-intensive task collection agencies struggle with. None of the\nexisting automated methods exploit maps that are an essential tool for\ngeoreferencing complex relations. We present preliminary experiments and\nresults of a novel method that exploits multi-modal capabilities of recent\nLarge Multi-Modal Models (LMM). This method enables the model to visually\ncontextualize spatial relations it reads in the locality description. We use a\ngrid-based approach to adapt these auto-regressive models for this task in a\nzero-shot setting. Our experiments conducted on a small manually annotated\ndataset show impressive results for our approach ($\\sim$1 km Average distance\nerror) compared to uni-modal georeferencing with Large Language Models and\nexisting georeferencing tools. The paper also discusses the findings of the\nexperiments in light of an LMM's ability to comprehend fine-grained maps.\nMotivated by these results, a practical framework is proposed to integrate this\nmethod into a georeferencing workflow.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b(LMM)\u8fdb\u884c\u5730\u7406\u53c2\u8003\u7684\u65b0\u65b9\u6cd5\u3002\u91c7\u7528\u4e86\u57fa\u4e8e\u7f51\u683c\u7684\u81ea\u9002\u5e94\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u5b9a\u4e0b\u53d6\u5f97\u4e86\u4ee4\u4eba\u77a9\u76ee\u7684\u6210\u679c($\tilda1$ km\u5e73\u5747\u8ddd\u79bb\u8bef\u5dee)\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u8d8a\u4e8e\u4f20\u7edf\u7684\u5355\u6a21\u6001\u5730\u7406\u53c2\u8003\u65b9\u6cd5\u548c\u73b0\u6709\u5de5\u5177\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86\u5c06\u8be5\u65b9\u6cd5\u6574\u5408\u5230\u5730\u7406\u53c2\u8003\u5de5\u4f5c\u6d41\u7a0b\u7684\u5b9e\u7528\u6846\u67b6\u3002", "motivation": "\u8bba\u6587\u6307\u51fa\u81ea\u7136\u5386\u53f2\u6536\u85cf\u4e2d\u7684\u51e0\u767e\u4e07\u4e2a\u751f\u7269\u6837\u672c\u8bb0\u5f55\u672a\u8fdb\u884c\u5730\u7406\u7f16\u7801\uff0c\u5730\u7406\u7f16\u7801\u4e0e\u6837\u672c\u91c7\u96c6\u76f8\u5173\u7684\u590d\u6742\u5730\u70b9\u63cf\u8ff0\u662f\u6536\u96c6\u673a\u6784\u96be\u4ee5\u5904\u7406\u7684\u52b3\u52a8\u5bc6\u96c6\u4efb\u52a1\u3002\u73b0\u6709\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u672a\u5229\u7528\u5730\u56fe\u4f5c\u4e3a\u5730\u7406\u7f16\u7801\u590d\u6742\u5173\u7cfb\u7684\u57fa\u672c\u5de5\u5177\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u53d7\u5230\u8fd9\u4e00\u6311\u6218\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u5229\u7528\u6700\u8fd1\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u591a\u6a21\u6001\u80fd\u529b\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86\u57fa\u4e8e\u7f51\u683c\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u81ea\u56de\u5f52\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bbe\u5b9a\u4e0b\u8fdb\u884c\u81ea\u9002\u5e94\uff0c\u4ee5\u5b9e\u73b0\u5730\u7406\u53c2\u8003\u590d\u6742\u5730\u70b9\u63cf\u8ff0\u7684\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u5730\u7406\u53c2\u8003\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e73\u5747\u8ddd\u79bb\u8bef\u5dee\u7ea6\u4e3a1\u516c\u91cc\u3002\u76f8\u6bd4\u4e8e\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u73b0\u6709\u5730\u7406\u53c2\u8003\u5de5\u5177\u8fdb\u884c\u5355\u6a21\u6001\u5730\u7406\u53c2\u8003\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u8d8a\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6700\u8fd1\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b(LMM)\u7684\u591a\u6a21\u6001\u80fd\u529b\uff0c\u5b9e\u73b0\u5bf9\u590d\u6742\u5730\u70b9\u63cf\u8ff0\u7684\u81ea\u52a8\u5730\u7406\u53c2\u8003\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u5730\u7406\u53c2\u8003\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\uff0c\u4e0e\u5355\u6a21\u6001\u5730\u7406\u53c2\u8003\u65b9\u6cd5\u548c\u73b0\u6709\u5730\u7406\u53c2\u8003\u5de5\u5177\u76f8\u6bd4\u8868\u73b0\u51fa\u8272\u3002\u8bba\u6587\u8fd8\u8ba8\u8bba\u4e86\u5b9e\u9a8c\u7ed3\u679c\uff0c\u5e76\u63d0\u51fa\u4e86\u5c06\u8be5\u65b9\u6cd5\u878d\u5165\u5730\u7406\u53c2\u8003\u5de5\u4f5c\u6d41\u7a0b\u7684\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2507.08603", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.08603", "abs": "https://arxiv.org/abs/2507.08603", "authors": ["Yonghua Hei", "Yibo Yan", "Shuliang Liu", "Huiyu Zhou", "Linfeng Zhang", "Xuming Hu"], "title": "Unlocking Speech Instruction Data Potential with Query Rewriting", "comment": "ACL 2025 Findings", "summary": "End-to-end Large Speech Language Models~(\\textbf{LSLMs}) demonstrate strong\npotential in response latency and speech comprehension capabilities, showcasing\ngeneral intelligence across speech understanding tasks. However, the ability to\nfollow speech instructions has not been fully realized due to the lack of\ndatasets and heavily biased training tasks. Leveraging the rich ASR datasets,\nprevious approaches have used Large Language Models~(\\textbf{LLMs}) to continue\nthe linguistic information of speech to construct speech instruction datasets.\nYet, due to the gap between LLM-generated results and real human responses, the\ncontinuation methods further amplify these shortcomings. Given the high costs\nof collecting and annotating speech instruction datasets by humans, using\nspeech synthesis to construct large-scale speech instruction datasets has\nbecome a balanced and robust alternative. Although modern\nText-To-Speech~(\\textbf{TTS}) models have achieved near-human-level synthesis\nquality, it is challenging to appropriately convert out-of-distribution text\ninstruction to speech due to the limitations of the training data distribution\nin TTS models. To address this issue, we propose a query rewriting framework\nwith multi-LLM knowledge fusion, employing multiple agents to annotate and\nvalidate the synthesized speech, making it possible to construct high-quality\nspeech instruction datasets without relying on human annotation. Experiments\nshow that this method can transform text instructions into distributions more\nsuitable for TTS models for speech synthesis through zero-shot rewriting,\nincreasing data usability from 72\\% to 93\\%. It also demonstrates unique\nadvantages in rewriting tasks that require complex knowledge and\ncontext-related abilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u67e5\u8be2\u91cd\u5199\u6846\u67b6\u548c\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u878d\u5408\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u5c06\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e3a\u66f4\u9002\u5408\u8bed\u97f3\u5408\u6210\u7684\u5206\u5e03\uff0c\u63d0\u9ad8\u6570\u636e\u53ef\u7528\u6027\u5e76\u5c55\u73b0\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u4ee3\u6587\u672c\u8f6c\u8bed\u97f3(TTS)\u6a21\u578b\u5df2\u7ecf\u5b9e\u73b0\u4e86\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u5408\u6210\u8d28\u91cf\uff0c\u4f46\u7531\u4e8eTTS\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u7684\u9650\u5236\uff0c\u5c06\u5206\u5e03\u5916\u6587\u672c\u6307\u4ee4\u9002\u5f53\u8f6c\u6362\u4e3a\u8bed\u97f3\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002\u901a\u8fc7\u4eba\u5de5\u5408\u6210\u8bed\u97f3\u6307\u4ee4\u6570\u636e\u96c6\u7684\u9ad8\u6210\u672c\uff0c\u63d0\u51fa\u4f7f\u7528\u8bed\u97f3\u5408\u6210\u6784\u5efa\u5927\u89c4\u6a21\u8bed\u97f3\u6307\u4ee4\u6570\u636e\u96c6\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u67e5\u8be2\u91cd\u5199\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u77e5\u8bc6\u878d\u5408\uff0c\u4f7f\u7528\u591a\u4e2a\u4ee3\u7406\u8fdb\u884c\u6ce8\u91ca\u548c\u9a8c\u8bc1\u5408\u6210\u8bed\u97f3\uff0c\u4ee5\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u8bed\u97f3\u6307\u4ee4\u6570\u636e\u96c6\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u901a\u8fc7\u96f6\u6837\u672c\u91cd\u5199\uff0c\u5c06\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e3a\u66f4\u9002\u5408\u7528\u4e8e\u8bed\u97f3\u5408\u6210\u7684\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u96f6\u6837\u672c\u91cd\u5199\uff0c\u5c06\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e3a\u66f4\u9002\u5408\u7528\u4e8e\u8bed\u97f3\u5408\u6210\u7684\u5206\u5e03\uff0c\u5c06\u6570\u636e\u53ef\u7528\u6027\u4ece72%\u63d0\u9ad8\u523093%\u3002\u5728\u9700\u8981\u590d\u6742\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u80fd\u529b\u7684\u91cd\u5199\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u72ec\u7279\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u67e5\u8be2\u91cd\u5199\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u77e5\u8bc6\u878d\u5408\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u91cd\u5199\uff0c\u5c06\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e3a\u66f4\u9002\u5408\u7528\u4e8e\u8bed\u97f3\u5408\u6210\u7684\u5206\u5e03\uff0c\u4ece\u800c\u5c06\u6570\u636e\u53ef\u7528\u6027\u4ece72%\u63d0\u9ad8\u523093%\uff0c\u5728\u590d\u6742\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u80fd\u529b\u65b9\u9762\u5177\u6709\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2507.08619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08619", "abs": "https://arxiv.org/abs/2507.08619", "authors": ["Soheyl Massoudi", "Mark Fuge"], "title": "Agentic Large Language Models for Conceptual Systems Engineering and Design", "comment": "32 pages, 3 figures", "summary": "Early-stage engineering design involves complex, iterative reasoning, yet\nexisting large language model (LLM) workflows struggle to maintain task\ncontinuity and generate executable models. We evaluate whether a structured\nmulti-agent system (MAS) can more effectively manage requirements extraction,\nfunctional decomposition, and simulator code generation than a simpler\ntwo-agent system (2AS). The target application is a solar-powered water\nfiltration system as described in a cahier des charges. We introduce the\nDesign-State Graph (DSG), a JSON-serializable representation that bundles\nrequirements, physical embodiments, and Python-based physics models into graph\nnodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS\ncollapses the process to a Generator-Reflector loop. Both systems run a total\nof 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1\n70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON\nvalidity, requirement coverage, embodiment presence, code compatibility,\nworkflow completion, runtime, and graph size. Across all runs, both MAS and 2AS\nmaintained perfect JSON integrity and embodiment tagging. Requirement coverage\nremained minimal (less than 20\\%). Code compatibility peaked at 100\\% under\nspecific 2AS settings but averaged below 50\\% for MAS. Only the\nreasoning-distilled model reliably flagged workflow completion. Powered by\nDeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes)\nwhereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced\ndesign detail. Reasoning-distilled LLM improved completion rates, yet low\nrequirements and fidelity gaps in coding persisted.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u548c\u53cc\u4ee3\u7406\u7cfb\u7edf\u5728\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u7684\u6548\u679c\u3002\u591a\u4ee3\u7406\u7cfb\u7edf\u63d0\u9ad8\u4e86\u8bbe\u8ba1\u7ec6\u8282\u548c\u4efb\u52a1\u7ba1\u7406\uff0c\u4f46\u7f16\u7801\u517c\u5bb9\u6027\u8f83\u5dee\u3002\u6df1\u5ea6\u63a8\u7406\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u4f46\u9700\u6c42\u548c\u7f16\u7801\u65b9\u9762\u5b58\u5728\u5dee\u8ddd\u3002", "motivation": "\u9488\u5bf9\u65e9\u671f\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u7684\u590d\u6742\u8fed\u4ee3\u63a8\u7406\u8fc7\u7a0b\uff0c\u5c1d\u8bd5\u89e3\u51b3\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u6d41\u5728\u4efb\u52a1\u8fde\u7eed\u6027\u548c\u53ef\u6267\u884c\u6a21\u578b\u751f\u6210\u65b9\u9762\u7684\u56f0\u96be\u3002", "method": "\u5f15\u5165\u4e86Design-State Graph (DSG)\uff0c\u5229\u7528\u4e5d\u79cd\u89d2\u8272\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u8fed\u4ee3\u6784\u5efa\u548c\u5b8c\u5584DSG\uff0c\u4e0e2AS\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\u3002\u8fd0\u884c\u4e8660\u4e2a\u5b9e\u9a8c\uff0c\u5bf9\u591a\u79cd\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u5982JSON\u6709\u6548\u6027\u3001\u9700\u6c42\u8986\u76d6\u3001\u4ee3\u7801\u517c\u5bb9\u6027\u3001\u5de5\u4f5c\u6d41\u7a0b\u5b8c\u6210\u7387\u7b49\u3002", "result": "\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u8bbe\u8ba1\u7ec6\u8282\u548c\u4efb\u52a1\u7ba1\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u7f16\u7801\u517c\u5bb9\u6027\u4e0a\u8868\u73b0\u4e0d\u5982\u53cc\u4ee3\u7406\u7cfb\u7edf\u3002\u6df1\u5ea6\u63a8\u7406\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u4f46\u5b58\u5728\u9700\u6c42\u548c\u7f16\u7801\u5fe0\u5b9e\u5ea6\u65b9\u9762\u7684\u5dee\u8ddd\u3002", "conclusion": "\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u7ba1\u7406\u9700\u6c42\u63d0\u53d6\u3001\u529f\u80fd\u5206\u89e3\u548c\u6a21\u62df\u5668\u4ee3\u7801\u751f\u6210\u65b9\u9762\u6bd4\u7b80\u5355\u7684\u53cc\u4ee3\u7406\u7cfb\u7edf\u66f4\u6709\u6548\u3002\u591a\u4ee3\u7406\u7cfb\u7edf\u63d0\u9ad8\u4e86\u8bbe\u8ba1\u7ec6\u8282\uff0c\u4f46\u5bf9\u7f16\u7801\u65b9\u9762\u8981\u6c42\u8f83\u4f4e\u3002\u6df1\u5ea6\u63a8\u7406\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u9ad8\u4e86\u5b8c\u6210\u7387\uff0c\u4f46\u5728\u7f16\u7801\u65b9\u9762\u5b58\u5728\u9700\u6c42\u548c\u5fe0\u5b9e\u5ea6\u5dee\u8ddd\u3002"}}
{"id": "2507.08649", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08649", "abs": "https://arxiv.org/abs/2507.08649", "authors": ["Xingguang Ji", "Yahui Liu", "Qi Wang", "Jingyuan Zhang", "Yang Yue", "Rui Shi", "Chenxi Sun", "Fuzheng Zhang", "Guorui Zhou", "Kun Gai"], "title": "Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning", "comment": "23 pages, 13 figures", "summary": "We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that\ncan produce formal theorem proofs in Lean 4, with verifier-integrated Long\nChain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we\ncontinual to choose to posttrain existing strong prover models for further\nperformance improvement. In our V2 version, we mainly upgrade the Reinforcement\nLearning (RL) with feedback provided by the Lean 4 verifier. Crucially,\nverifier feedback, such as indicating success or detailing specific errors,\nallows the LLM to become ``self-aware'' of the correctness of its own reasoning\nprocess and learn to reflexively correct errors. Leanabell-Prover-V2 directly\noptimizes LLM reasoning trajectories with multi-turn verifier interactions,\ntogether with feedback token masking for stable RL training and a simple reward\nstrategy. Experiments show that Leanabell-Prover-V2 improves performance by\n3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with\nDeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data\nand models are available at:\nhttps://github.com/Leanabell-LM/Leanabell-Prover-V2.", "AI": {"tldr": "Leanabell-Prover-V2\u662f\u4e00\u4e2a7B\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e0eLean 4\u9a8c\u8bc1\u5668\u7684\u53cd\u9988\u7ed3\u5408\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u751f\u6210\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728MiniF2F\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u5b83\u901a\u8fc7\u4e0d\u540c\u8bc1\u660e\u6a21\u578b\u5206\u522b\u63d0\u9ad8\u4e863.2%\u548c2.0%\u7684\u6027\u80fd\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u901a\u8fc7Leanabell-Prover-V2\u63d0\u9ad8LLM\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u80fd\u591f\u81ea\u6211\u610f\u8bc6\u5730\u7ea0\u6b63\u9519\u8bef\u5e76\u751f\u6210\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\u3002", "method": "Leanabell-Prover-V2\u901a\u8fc7\u5347\u7ea7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7ed3\u5408Lean 4\u9a8c\u8bc1\u5668\u7684\u53cd\u9988\u6765\u751f\u6210\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\u3002\u5b83\u76f4\u63a5\u4f18\u5316LLM\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5b9e\u73b0\u591a\u8f6e\u9a8c\u8bc1\u5668\u4ea4\u4e92\uff0c\u91c7\u7528\u53cd\u9988\u4ee4\u724c\u63a9\u76d6\u8fdb\u884c\u7a33\u5b9a\u7684RL\u8bad\u7ec3\u5e76\u91c7\u7528\u7b80\u5355\u7684\u5956\u52b1\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLeanabell-Prover-V2\u5728MiniF2F\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u901a\u8fc7Kimina-Prover-Preview-Distill-7B\u548cDeepSeek-Prover-V2-7B\u63d0\u9ad8\u4e863.2%\u548c2.0%\uff0c\u5c55\u793a\u4e86\u5176\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "Leanabell-Prover-V2 \u662f\u4e00\u4e2a7B\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u4ee5\u5728Lean 4\u4e2d\u751f\u6210\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\uff0c\u5177\u6709\u9a8c\u8bc1\u5668\u96c6\u6210\u7684Long Chain-of-Thoughts\uff08CoT\uff09\u3002\u901a\u8fc7\u5f3a\u8c03Leanabell-Prover-V1\u7684\u5148\u524d\u5de5\u4f5c\uff0c\u6211\u4eec\u9009\u62e9\u8fdb\u4e00\u6b65\u540e\u8bad\u7ec3\u73b0\u6709\u5f3a\u5927\u7684\u8bc1\u660e\u6a21\u578b\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002\u5728V2\u7248\u672c\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u901a\u8fc7Lean 4\u9a8c\u8bc1\u5668\u63d0\u4f9b\u7684\u53cd\u9988\u6765\u5347\u7ea7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u3002\u5173\u952e\u7684\u662f\uff0c\u9a8c\u8bc1\u5668\u7684\u53cd\u9988\uff0c\u4f8b\u5982\u6307\u793a\u6210\u529f\u6216\u8be6\u7ec6\u8bf4\u660e\u7279\u5b9a\u9519\u8bef\uff0c\u4f7fLLM\u80fd\u591f\u201c\u81ea\u6211\u610f\u8bc6\u201d\u5730\u4e86\u89e3\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u6b63\u786e\u6027\uff0c\u5e76\u5b66\u4f1a\u81ea\u6211\u4fee\u6b63\u9519\u8bef\u3002Leanabell-Prover-V2\u76f4\u63a5\u4f18\u5316LLM\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5177\u6709\u591a\u8f6e\u9a8c\u8bc1\u5668\u4ea4\u4e92\u4ee5\u53ca\u53cd\u9988\u4ee4\u724c\u63a9\u76d6\u4ee5\u8fdb\u884c\u7a33\u5b9a\u7684RL\u8bad\u7ec3\u548c\u7b80\u5355\u7684\u5956\u52b1\u7b56\u7565\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cLeanabell-Prover-V2\u5728MiniF2F\u6d4b\u8bd5\u96c6\u4e0a\u901a\u8fc7Kimina-Prover-Preview-Distill-7B\u63d0\u9ad8\u4e863.2%\uff08pass@128\uff09\uff0c\u901a\u8fc7DeepSeek-Prover-V2-7B\u63d0\u9ad8\u4e862.0%\uff08pass@128\uff09\u3002"}}
{"id": "2507.08664", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08664", "abs": "https://arxiv.org/abs/2507.08664", "authors": ["Haoran Sun", "Shaoning Zeng"], "title": "Introspection of Thought Helps AI Agents", "comment": null, "summary": "AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to\nperform interpretation and inference in text and image tasks without\npost-training, where LLMs and MLLMs play the most critical role and determine\nthe initial ability and limitations of AI Agents. Usually, AI Agents utilize\nsophisticated prompt engineering and external reasoning framework to obtain a\npromising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought\nand Image-of-Thought. However, they are still constrained by the inherent\nlimitations of LLM in understanding natural language, and the iterative\nreasoning process will generate a large amount of inference cost. To this end,\nwe propose a novel AI Agent Reasoning Framework with Introspection of Thought\n(INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute\nprogrammatic dialogue reasoning processes following the code in prompt.\nTherefore, self-denial and reflection occur within LLM instead of outside LLM,\nwhich can reduce token cost effectively. Through our experiments on six\nbenchmarks for three different tasks, the effectiveness of INoT is verified,\nwith an average improvement of 7.95\\% in performance, exceeding the baselines.\nFurthermore, the token cost of INoT is lower on average than the best\nperforming method at baseline by 58.3\\%. In addition, we demonstrate the\nversatility of INoT in image interpretation and inference through verification\nexperiments.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aINoT\u7684\u65b0\u7684AI Agent\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u8bbe\u8ba1\u65b0\u7684LLM-Read\u4ee3\u7801\uff0c\u4f7fLLM\u6267\u884c\u7a0b\u5e8f\u5316\u5bf9\u8bdd\u63a8\u7406\u8fc7\u7a0b\u3002\u5728\u516d\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u5b9e\u4e86INoT\u7684\u6709\u6548\u6027\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u9ad8\u4e867.95\fp\u5e76\u8d85\u8fc7\u4e86\u57fa\u7ebf\uff0c\u540c\u65f6\u6807\u8bb0\u6210\u672c\u4f4e\u4e8e\u57fa\u7ebf\u4e0a\u6700\u4f73\u65b9\u6cd5\u768458.3\fp\u3002\u8fd8\u8bc1\u660e\u4e86INoT\u5728\u56fe\u50cf\u89e3\u91ca\u548c\u63a8\u7406\u4e2d\u7684\u591a\u529f\u80fd\u6027\u3002", "motivation": "AI Agents\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u591a\u6a21\u5f0fLLMs\uff08MLLMs\uff09\u6267\u884c\u6587\u672c\u548c\u56fe\u50cf\u4efb\u52a1\u4e2d\u7684\u89e3\u91ca\u548c\u63a8\u7406\uff0c\u4f46\u53d7\u9650\u4e8eLLM\u5728\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u65b9\u9762\u7684\u56fa\u6709\u9650\u5236\u4ee5\u53ca\u8fed\u4ee3\u63a8\u7406\u8fc7\u7a0b\u53ef\u80fd\u5e26\u6765\u7684\u5927\u91cf\u63a8\u7406\u6210\u672c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7684AI Agent\u63a8\u7406\u6846\u67b6\uff0cINoT\uff0c\u5176\u4e2d\u5305\u62ecLLM-Read\u4ee3\u7801\uff0c\u4ee5\u6267\u884c\u7a0b\u5e8f\u5316\u5bf9\u8bdd\u63a8\u7406\u8fc7\u7a0b\u3002\u901a\u8fc7\u5b9e\u9a8c\u5728\u516d\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u9a8c\u8bc1\u4e86INoT\u7684\u6709\u6548\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u56fe\u50cf\u89e3\u91ca\u548c\u63a8\u7406\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u63d0\u51fa\u7684INoT\u6846\u67b6\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u4e86\u5176\u5728\u6539\u5584AI Agent\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u964d\u4f4e\u4e86\u6807\u8bb0\u6210\u672c\u3002\u6b64\u5916\uff0cINoT\u8fd8\u5c55\u793a\u4e86\u5728\u56fe\u50cf\u89e3\u91ca\u548c\u63a8\u7406\u4e2d\u7684\u591a\u529f\u80fd\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684AI Agent\u63a8\u7406\u6846\u67b6\uff0c\u540d\u4e3a\u201c\u601d\u7ef4\u5185\u7701\uff08INoT\uff09\u201d\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u8bbe\u8ba1\u65b0\u7684LLM-Read\u4ee3\u7801\uff0c\u5b9e\u73b0LLM\u6267\u884c\u7a0b\u5e8f\u5316\u5bf9\u8bdd\u63a8\u7406\u8fc7\u7a0b\u3002\u901a\u8fc7\u5728\u516d\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86INoT\u7684\u6709\u6548\u6027\uff0c\u5728\u6027\u80fd\u65b9\u9762\u5e73\u5747\u63d0\u9ad8\u4e867.95\fp\uff0c\u5e76\u8d85\u8fc7\u4e86\u57fa\u7ebf\u3002\u6b64\u5916\uff0cINoT\u7684\u6807\u8bb0\u6210\u672c\u5e73\u5747\u4f4e\u4e8e\u57fa\u7ebf\u4e0a\u6700\u4f73\u6027\u80fd\u65b9\u6cd5\u768458.3\fp\u3002\u901a\u8fc7\u9a8c\u8bc1\u5b9e\u9a8c\u5c55\u793a\u4e86INoT\u5728\u56fe\u50cf\u89e3\u91ca\u548c\u63a8\u7406\u4e2d\u7684\u591a\u529f\u80fd\u6027\u3002"}}
{"id": "2507.08705", "categories": ["cs.AI", "I.2.5; I.2.1; I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2507.08705", "abs": "https://arxiv.org/abs/2507.08705", "authors": ["Philip Osborne", "Danilo S. Carvalho", "Andr\u00e9 Freitas"], "title": "elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings", "comment": "6 pages, 1 figure, 3 tables, 11 Appendix pages, submitted to EMNLP\n  2025 Call for System Demonstrations", "summary": "We present elsciRL, an open-source Python library to facilitate the\napplication of language solutions on reinforcement learning problems. We\ndemonstrate the potential of our software by extending the Language Adapter\nwith Self-Completing Instruction framework defined in (Osborne, 2024) with the\nuse of LLMs. Our approach can be re-applied to new applications with minimal\nsetup requirements. We provide a novel GUI that allows a user to provide text\ninput for an LLM to generate instructions which it can then self-complete.\nEmpirical results indicate that these instructions \\textit{can} improve a\nreinforcement learning agent's performance. Therefore, we present this work to\naccelerate the evaluation of language solutions on reward based environments to\nenable new opportunities for scientific discovery.", "AI": {"tldr": "elsciRL\u662f\u4e00\u4e2aPython\u5e93\uff0c\u7528\u4e8e\u5728\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u4e0a\u5e94\u7528\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u3002\u4ed6\u4eec\u6269\u5c55\u4e86Language Adapter with Self-Completing Instruction\u6846\u67b6\uff0c\u7ed3\u5408LLMs\uff0c\u5e76\u63d0\u4f9b\u65b0\u7684GUI\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u751f\u6210\u7684\u6307\u4ee4\u53ef\u4ee5\u6539\u5584\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u8be5\u5de5\u4f5c\u65e8\u5728\u52a0\u901f\u8bc4\u4f30\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u7684\u5e94\u7528\u3002", "motivation": "\u52a0\u901f\u8bc4\u4f30\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u5728\u5956\u52b1\u9a71\u52a8\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u4e3a\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u65b0\u673a\u4f1a\u3002", "method": "\u6269\u5c55\u4e86Language Adapter with Self-Completing Instruction\u6846\u67b6\uff0c\u7ed3\u5408LLMs\uff0c\u5e76\u63d0\u4f9b\u65b0\u9896\u7684GUI\u8fdb\u884c\u6587\u672c\u8f93\u5165\uff0c\u751f\u6210\u6307\u4ee4\u5e76\u81ea\u6211\u5b8c\u6210\uff0c\u4ee5\u6539\u5584\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u751f\u6210\u7684\u6307\u4ee4\u53ef\u4ee5\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6027\u80fd\u3002", "conclusion": "\u4ecb\u7ecd\u4e86elsciRL\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684Python\u5e93\uff0c\u7528\u4e8e\u5728\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u4e0a\u5e94\u7528\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u5c06Language Adapter with Self-Completing Instruction\u6846\u67b6\u4e0eLLMs\u76f8\u7ed3\u5408\uff0c\u5c55\u793a\u4e86\u8f6f\u4ef6\u7684\u6f5c\u529b\u3002\u4ed6\u4eec\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684GUI\uff0c\u5141\u8bb8\u7528\u6237\u63d0\u4f9b\u6587\u672c\u8f93\u5165\uff0c\u4ee5\u751f\u6210\u6307\u4ee4\u5e76\u8fdb\u884c\u81ea\u6211\u5b8c\u6210\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u6307\u4ee4\u53ef\u4ee5\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6027\u80fd\u3002\u8be5\u5de5\u4f5c\u65e8\u5728\u52a0\u901f\u8bc4\u4f30\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u5728\u57fa\u4e8e\u5956\u52b1\u7684\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u4ece\u800c\u4e3a\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u65b0\u673a\u4f1a\u3002"}}
{"id": "2507.08715", "categories": ["cs.AI", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.08715", "abs": "https://arxiv.org/abs/2507.08715", "authors": ["Paul Saves", "Jasper Bussemaker", "R\u00e9mi Lafage", "Thierry Lefebvre", "Nathalie Bartoli", "Youssef Diouane", "Joseph Morlier"], "title": "System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility", "comment": null, "summary": "For developing innovative systems architectures, modeling and optimization\ntechniques have been central to frame the architecting process and define the\noptimization and modeling problems. In this context, for system-of-systems the\nuse of efficient dedicated approaches (often physics-based simulations) is\nhighly recommended to reduce the computational complexity of the targeted\napplications. However, exploring novel architectures using such dedicated\napproaches might pose challenges for optimization algorithms, including\nincreased evaluation costs and potential failures. To address these challenges,\nsurrogate-based optimization algorithms, such as Bayesian optimization\nutilizing Gaussian process models have emerged.", "AI": {"tldr": "The paper discusses the importance of modeling and optimization techniques in developing innovative systems architectures, particularly for system-of-systems. It highlights the use of dedicated approaches like physics-based simulations and the emergence of surrogate-based optimization algorithms, such as Bayesian optimization with Gaussian process models, to tackle challenges in exploring novel architectures.", "motivation": "The motivation of the paper is to reduce the computational complexity of targeted applications when exploring novel architectures. It aims to overcome challenges faced by optimization algorithms, including increased evaluation costs and potential failures.", "method": "The paper focuses on modeling and optimization techniques for developing innovative systems architectures. It emphasizes the use of efficient dedicated approaches, such as physics-based simulations, for system-of-systems.", "result": "The use of surrogate-based optimization algorithms, particularly Bayesian optimization with Gaussian process models, has shown promise in addressing the challenges associated with exploring novel architectures for system-of-systems.", "conclusion": "Surrogate-based optimization algorithms, such as Bayesian optimization using Gaussian process models, have emerged to address challenges in exploring novel architectures with dedicated approaches for system-of-systems."}}
