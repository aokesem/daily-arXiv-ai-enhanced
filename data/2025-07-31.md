<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [When Truthful Representations Flip Under Deceptive Instructions?](https://arxiv.org/abs/2507.22149)
*Xianxuan Long,Yao Fu,Runchao Li,Mu Sheng,Haotian Yu,Xiaotian Han,Pan Li*

Main category: cs.AI

TL;DR: 研究探讨大型语言模型在接受欺骗和真实指令时内部表示的变化情况。发现欺骗性指令导致内部表示发生显著转变，与真实/中性指令有显著不同。研究利用线性探针和稀疏自编码器显示了这种变化，重点在早期到中期层。特定SAE特征和可视化确认了真实和欺骗表示的差异。研究结果揭示了欺骗行为的特征和层级迹象，为检测和控制大型语言模型中的欺骗性行为提供重要见解。


<details>
  <summary>Details</summary>
Motivation: 目前对大型语言模型内部表示在接受欺骗性指令和真实指令时的变化缺乏深入理解，本研究旨在填补这一知识空白。通过研究内部表示的转变情况，可以为检测和控制大型语言模型中的欺骗性行为提供新的视角和方法。

Method: 通过线性探针分析Llama-3.1-8B-Instruct和Gemma-2-9B-Instruct在事实验证任务中的内部表示，发现模型的真/假输出可通过线性探针在所有条件下进行预测。利用稀疏自编码器（SAEs）展示了欺骗指令相对于真实/中性指令引发的显著表示转变，集中在早期到中期层，并且即使在复杂数据集上也是可检测的。研究还使用有针对性的可视化确定了对欺骗指令高度敏感的SAE特征，并确认了不同的真实/欺骗表示子空间。

Result: 研究发现欺骗性指令引发了内部表示的显著转变，与真实/中性指令相比具有显著不同，集中在早期到中期层。通过特定的SAE特征和有针对性的可视化，确认了真实和欺骗表示子空间的差异。最终揭示了教导不诚实行为的特征和层级迹象，为检测和控制大型语言模型中的欺骗性行为提供重要见解。

Conclusion: 研究通过分析内部表示探讨了大型语言模型在接受欺骗性指令和真实指令时的变化情况，发现欺骗指令会引起内部表示发生显著转变，而真实指令和中性指令的表示相似。研究还确定了对欺骗指令高度敏感的SAE特征，并通过有针对性的可视化确认了真实和欺骗表示子空间的差异。最终，通过层级和特征级别的相关性揭示了教导不诚实行为的特征和层级迹象，为检测和控制大型语言模型中的欺骗性行为提供洞察。

Abstract: Large language models (LLMs) tend to follow maliciously crafted instructions
to generate deceptive responses, posing safety challenges. How deceptive
instructions alter the internal representations of LLM compared to truthful
ones remains poorly understood beyond output analysis. To bridge this gap, we
investigate when and how these representations ``flip'', such as from truthful
to deceptive, under deceptive versus truthful/neutral instructions. Analyzing
the internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct
on a factual verification task, we find the model's instructed True/False
output is predictable via linear probes across all conditions based on the
internal representation. Further, we use Sparse Autoencoders (SAEs) to show
that the Deceptive instructions induce significant representational shifts
compared to Truthful/Neutral representations (which are similar), concentrated
in early-to-mid layers and detectable even on complex datasets. We also
identify specific SAE features highly sensitive to deceptive instruction and
use targeted visualizations to confirm distinct truthful/deceptive
representational subspaces. % Our analysis pinpoints layer-wise and
feature-level correlates of instructed dishonesty, offering insights for LLM
detection and control. Our findings expose feature- and layer-level signatures
of deception, offering new insights for detecting and mitigating instructed
dishonesty in LLMs.

</details>


### [2] [Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence](https://arxiv.org/abs/2507.22197)
*Matthieu Queloz*

Main category: cs.AI

TL;DR: 本文讨论了对人工智能的期望不仅限于可解释性，还应包括更广泛的思维系统性。作者提出了思维系统性的框架，澄清了系统性与连接主义之间的关系，并强调了历史上对思维系统性的严格要求。论文通过引入多种理解和理由成功解决了系统性挑战，为确定 AI 模型需要多系统性以及何时需要系统性提供了指导。


<details>
  <summary>Details</summary>
Motivation: 长期以来，连接主义引发的“系统性挑战”给对思维系统性的丰富概念造成困扰。本文旨在澄清系统性与连接主义之间的关系，探讨思维体系的严格要求，并将这种理念应用于人工智能模型。

Method: 本文提出了对思维系统性的四种理解，以消除系统性与连接主义之间的紧张关系。作者识别出五种系统化的理由，并将其应用于人工智能，强调了“严格系统性挑战”。作者提出系统化需求本身必须受到系统化理由的规范，从而得到对思想系统化需求的动态理解，告诉我们AI模型需要多系统化以及何时需要系统化。

Result: 通过引入四种思维系统性的理解和五种系统化的理由，本文成功消除了系统性与连接主义之间的紧张关系，并确立了对人工智能模型系统性的要求。作者提供了对系统性概念的动态理解，为确定 AI 模型需要多系统化以及何时需要系统化提供了指导。

Conclusion: 本文主张可解释性仅是塑造我们对人工智能期望的更广泛理想的一个方面。作者提出了对思维系统性的概念框架，以消除系统性与连接主义之间的紧张关系，并表明历史上塑造我们对什么构成理性、权威和科学思维的观念更加严格。作者认为我们必须查看系统化的理由，并探讨其在多大程度上适用于人工智能模型，以确定我们是否有理由将AI模型置于这种系统性理想之下。

Abstract: This paper argues that explainability is only one facet of a broader ideal
that shapes our expectations towards artificial intelligence (AI).
Fundamentally, the issue is to what extent AI exhibits systematicity--not
merely in being sensitive to how thoughts are composed of recombinable
constituents, but in striving towards an integrated body of thought that is
consistent, coherent, comprehensive, and parsimoniously principled. This richer
conception of systematicity has been obscured by the long shadow of the
"systematicity challenge" to connectionism, according to which network
architectures are fundamentally at odds with what Fodor and colleagues termed
"the systematicity of thought." I offer a conceptual framework for thinking
about "the systematicity of thought" that distinguishes four senses of the
phrase. I use these distinctions to defuse the perceived tension between
systematicity and connectionism and show that the conception of systematicity
that historically shaped our sense of what makes thought rational,
authoritative, and scientific is more demanding than the Fodorian notion. To
determine whether we have reason to hold AI models to this ideal of
systematicity, I then argue, we must look to the rationales for systematization
and explore to what extent they transfer to AI models. I identify five such
rationales and apply them to AI. This brings into view the "hard systematicity
challenge." However, the demand for systematization itself needs to be
regulated by the rationales for systematization. This yields a dynamic
understanding of the need to systematize thought, which tells us how systematic
we need AI models to be and when.

</details>


### [3] [CoEx -- Co-evolving World-model and Exploration](https://arxiv.org/abs/2507.22281)
*Minsoo Kim,Seung-won Hwang*

Main category: cs.AI

TL;DR: 本论文介绍了一种名为CoEx的分层代理架构，通过层次化状态抽象实现了LLM规划与动态更新的世界模型相互演化。CoEx利用LLM推理编排动态计划，持续将子目标经验结合到神经符号信念状态中。实验证明，CoEx在规划和探索方面表现优异，优于现有代理范式。


<details>
  <summary>Details</summary>
Motivation: 现代LLM代理的规划依赖于在预训练期间获取的LLM作为内部世界模型，然而现有的代理设计未能有效地将新观察结果纳入世界模型的动态更新中。LLM静态内部世界模型的依赖逐渐倾向于与世界真实状态不一致，导致产生分歧和错误计划。因此，本研究旨在解决这一问题，提出了CoEx架构以改善代理的规划能力。

Method: 引入了一种分层代理架构CoEx，通过层次化状态抽象的方式，实现LLM规划与动态更新的世界模型相互演化，采用LLM推理编排动态计划并持续将子目标经验结合到神经符号信念状态中。在ALFWorld、PDDL和Jericho等复杂任务中评估了该代理的性能。

Result: 实验结果显示，CoEx在规划和探索方面优于现有代理范式，表现出在丰富环境和复杂任务中的良好性能。

Conclusion: 这篇论文介绍了一种分层代理架构CoEx，其中层次化状态抽象允许LLM规划与动态更新的世界模型相互演化。通过使用LLM推理编排由子目标组成的动态计划，CoEx在丰富环境和复杂任务中规划并与世界互动，并且其学习机制不断将这些子目标经验结合到神经符号信念状态中。实验结果表明，CoEx在规划和探索方面优于现有的代理范式。

Abstract: Planning in modern LLM agents relies on the utilization of LLM as an internal
world model, acquired during pretraining. However, existing agent designs fail
to effectively assimilate new observations into dynamic updates of the world
model. This reliance on the LLM's static internal world model is progressively
prone to misalignment with the underlying true state of the world, leading to
the generation of divergent and erroneous plans. We introduce a hierarchical
agent architecture, CoEx, in which hierarchical state abstraction allows LLM
planning to co-evolve with a dynamically updated model of the world. CoEx plans
and interacts with the world by using LLM reasoning to orchestrate dynamic
plans consisting of subgoals, and its learning mechanism continuously
incorporates these subgoal experiences into a persistent world model in the
form of a neurosymbolic belief state, comprising textual inferences and
code-based symbolic memory. We evaluate our agent across a diverse set of agent
scenarios involving rich environments and complex tasks including ALFWorld,
PDDL, and Jericho. Our experiments show that CoEx outperforms existing agent
paradigms in planning and exploration.

</details>


### [4] [An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem](https://arxiv.org/abs/2507.22326)
*Qun Ma,Xiao Xue,Ming Zhang,Yifan Shen,Zihan Zhao*

Main category: cs.AI

TL;DR: 本论文讨论了Metaverse服务生态系统中代理面临的挑战，提出了一个解决方案：可解释的情感对齐框架。该框架通过整合事实因素，实现了更好的关系事实对齐能力。通过离线到线下食品配送场景的模拟实验验证了框架的有效性，获得了更真实的社会建构。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的兴起，代理在Metaverse服务生态系统中扮演关键角色，但现有代理在虚拟世界服务与现实世界服务之间存在挑战。因此，本论文旨在解决这些问题，提出一个新框架以加强现有代理的关系事实对齐能力。

Method: 该论文提出了一个解决现有LLM基于代理在Metaverse服务生态系统中挑战的解决方案，即可解释的情感对齐框架。通过将事实因素整合到LLM基于代理的决策循环中，系统地展示了如何为这些代理实现更多关系事实对齐。

Result: 通过模拟实验评估，证明了提出的可解释的情感对齐框架在Metaverse服务生态系统中的有效性。实验结果表明该框架能够实现更真实的社会建构。

Conclusion: 该论文提出了一个可解释的情感对齐框架，用于解决在Metaverse服务生态系统中存在的现有LLM 基于代理面临的挑战，以实现更好的关系事实对齐。通过离线到线下的食品配送场景的模拟实验评估了该框架的有效性，获得了更加真实的社会建构。

Abstract: Metaverse service is a product of the convergence between Metaverse and
service systems, designed to address service-related challenges concerning
digital avatars, digital twins, and digital natives within Metaverse. With the
rise of large language models (LLMs), agents now play a pivotal role in
Metaverse service ecosystem, serving dual functions: as digital avatars
representing users in the virtual realm and as service assistants (or NPCs)
providing personalized support. However, during the modeling of Metaverse
service ecosystems, existing LLM-based agents face significant challenges in
bridging virtual-world services with real-world services, particularly
regarding issues such as character data fusion, character knowledge
association, and ethical safety concerns. This paper proposes an explainable
emotion alignment framework for LLM-based agents in Metaverse Service
Ecosystem. It aims to integrate factual factors into the decision-making loop
of LLM-based agents, systematically demonstrating how to achieve more
relational fact alignment for these agents. Finally, a simulation experiment in
the Offline-to-Offline food delivery scenario is conducted to evaluate the
effectiveness of this framework, obtaining more realistic social emergence.

</details>


### [5] [Magentic-UI: Towards Human-in-the-loop Agentic Systems](https://arxiv.org/abs/2507.22358)
*Hussein Mozannar,Gagan Bansal,Cheng Tan,Adam Fourney,Victor Dibia,Jingya Chen,Jack Gerrits,Tyler Payne,Matheus Kunzler Maldaner,Madeleine Grunde-McLaughlin,Eric Zhu,Griffin Bassman,Jacob Alber,Peter Chang,Ricky Loynd,Friederike Niedtner,Ece Kamar,Maya Murad,Rafah Hosn,Saleema Amershi*

Main category: cs.AI

TL;DR: 研究表明人类参与的智能系统为提高安全性和效率在人工智能与人类协作中提供了有前途的路径。Magentic-UI是一种开源网络界面，支持多种互动机制，通过Model Context Protocol可以扩展各种工具，有潜力推进安全和高效的人-智能合作。


<details>
  <summary>Details</summary>
Motivation: 人工智能代理尽管具备使用外部工具自主完成复杂、多步骤任务的能力，但在大多数领域仍无法达到人类水平，且可能存在安全风险和对抗性操纵的问题。因此，研究呼吁通过人类参与的智能系统来解锁从不完美系统中提升生产力的潜力。

Method: 研究建议人类参与的智能系统是一种有前途的方法，结合人类监督和控制与人工智能的效率，从而提升不完美系统的生产力。引入了Magentic-UI，基于灵活的多代理体系结构，支持网络浏览、代码执行和文件操作，并通过Model Context Protocol（MCP）可以扩展各种工具。此外，Magentic-UI提供六种互动机制，包括共同规划、共同任务、多任务、动作保护和长期记忆，以促进有效、成本低廉的人类参与。

Result: Magentic-UI通过评估表现出自主任务完成、互动能力、与真实用户的定性研究以及定向安全评估等方面的潜力，有望推进安全和高效的人-智能协作。

Conclusion: 人类参与的智能系统为提高安全性和效率在人工智能与人类协作中提供了有前途的路径。研究介绍了Magentic-UI，一种开源网络界面，旨在开发和研究人类与智能代理的互动。通过四个维度的评估，研究表明Magentic-UI有潜力推进安全和高效的人-智能合作。

Abstract: AI agents powered by large language models are increasingly capable of
autonomously completing complex, multi-step tasks using external tools. Yet,
they still fall short of human-level performance in most domains including
computer use, software development, and research. Their growing autonomy and
ability to interact with the outside world, also introduces safety and security
risks including potentially misaligned actions and adversarial manipulation. We
argue that human-in-the-loop agentic systems offer a promising path forward,
combining human oversight and control with AI efficiency to unlock productivity
from imperfect systems. We introduce Magentic-UI, an open-source web interface
for developing and studying human-agent interaction. Built on a flexible
multi-agent architecture, Magentic-UI supports web browsing, code execution,
and file manipulation, and can be extended with diverse tools via Model Context
Protocol (MCP). Moreover, Magentic-UI presents six interaction mechanisms for
enabling effective, low-cost human involvement: co-planning, co-tasking,
multi-tasking, action guards, and long-term memory. We evaluate Magentic-UI
across four dimensions: autonomous task completion on agentic benchmarks,
simulated user testing of its interaction capabilities, qualitative studies
with real users, and targeted safety assessments. Our findings highlight
Magentic-UI's potential to advance safe and efficient human-agent
collaboration.

</details>


### [6] [LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models](https://arxiv.org/abs/2507.22359)
*Qianhong Guo,Wei Xie,Xiaofang Cai,Enze Wang,Shuoyoucheng Ma,Kai Chen,Xiaofeng Wang,Baosheng Wang*

Main category: cs.AI

TL;DR: 本研究提出了一种新的基准无关评估范式LLM-Crowdsourced，通过LLMs自动生成问题、独立回答和相互评估来评估LLMs性能。实验证明该方法在区分LLM性能方面具有优势，并揭示了一些传统方法难以发现的新发现。通过对八种主流LLMs进行实验验证，证明了提出方法在区分LLM性能方面的优势。


<details>
  <summary>Details</summary>
Motivation: LLMs在各种任务中展现出卓越的能力，但评估这些能力仍然是一项具有挑战性的任务，现有评估方法存在诸如数据污染、黑盒操作和主观偏好等问题，难以全面评估LLMs的真实能力。因此，为解决这些挑战，本研究的动机在于提出一种新的、基准无关的评估范式。

Method: 提出了LLM-Crowdsourced评估范式，该方法整合了动态、透明、客观和专业四个关键评估标准，通过与现有方法不同，利用LLMs自动生成问题来进行评估。

Result: 通过在数学和编程领域对八种主流LLMs进行实验验证，证明了提出方法在区分LLM性能方面的优势。研究还揭示了一些新发现，包括Gemini在问题设计能力上表现最佳，部分LLMs存在“基于记忆的回答”现象，以及LLM评估结果的高一致性。

Conclusion: 本研究提出了一种新的基准无关评估范式LLM-Crowdsourced，通过利用LLMs生成问题、独立回答问题以及相互评估来评估LLMs的性能。实验证明该方法在区分LLM性能方面具有优势，并揭示了一些传统方法难以发现的新发现，包括Gemini在原创和专业问题设计能力上优势明显，部分LLMs表现出“基于记忆的回答”，LLM评估结果具有高一致性（健壮性）。

Abstract: Although large language models (LLMs) demonstrate remarkable capabilities
across various tasks, evaluating their capabilities remains a challenging task.
Existing evaluation methods suffer from issues such as data contamination,
black-box operation, and subjective preference. These issues make it difficult
to evaluate the LLMs' true capabilities comprehensively. To tackle these
challenges, we propose a novel benchmark-free evaluation paradigm,
LLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently,
and evaluate mutually. This method integrates four key evaluation criteria:
dynamic, transparent, objective, and professional, which existing evaluation
methods cannot satisfy simultaneously. Experiments on eight mainstream LLMs
across mathematics and programming verify the advantages of our method in
distinguishing LLM performance. Furthermore, our study reveals several novel
findings that are difficult for traditional methods to detect, including but
not limited to: (1) Gemini demonstrates the highest original and professional
question-design capabilities among others; (2) Some LLMs exhibit
''memorization-based answering'' by misrecognizing questions as familiar ones
with a similar structure; (3) LLM evaluation results demonstrate high
consistency (robustness).

</details>


### [7] [Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making](https://arxiv.org/abs/2507.22365)
*ZhaoBin Li,Mark Steyvers*

Main category: cs.AI

TL;DR: 研究探讨了AI在决策中的作用，强调了元认知敏感性的重要性。实验证实了AI元认知敏感性对人类决策表现的影响，提出优化AI准确性和元认知敏感性以实现更好决策结果的重要性。


<details>
  <summary>Details</summary>
Motivation: AI在决策中的作用日益重要，但通常只评估其准确性，忽略了元认知敏感性的重要性。因此，研究旨在探讨并确定AI元认知敏感性对决策准确性的影响，并为实际决策提供更多洞察。

Method: 介绍了一个理论框架来评估AI的预测准确性和元认知敏感性共同影响。进行了实验验证元认知敏感性对于人类决策表现的影响。

Result: 研究发现具有较低预测准确性但更高元认知敏感性的AI能提升人类决策整体准确性。实验结果证实更高的AI元认知敏感性可以改善人类决策表现。

Conclusion: 人类决策依赖于人工智能输入，AI的准确性和置信度可靠性对决策质量产生影响。研究强调AI元认知敏感性的作用，介绍了一个评估AI预测准确性和元认知敏感性共同影响的理论框架。研究确定了在混合决策情境中，具有较低预测准确性但较高元认知敏感性的AI可以提升人类决策的整体准确性的条件。最后，行为实验证实更高的AI元认知敏感性可以提升人类决策表现。这些发现强调了评估AI辅助的重要性不仅仅是准确性，还包括元认知敏感性，并且优化两者以实现更优决策结果。

Abstract: In settings where human decision-making relies on AI input, both the
predictive accuracy of the AI system and the reliability of its confidence
estimates influence decision quality. We highlight the role of AI metacognitive
sensitivity -- its ability to assign confidence scores that accurately
distinguish correct from incorrect predictions -- and introduce a theoretical
framework for assessing the joint impact of AI's predictive accuracy and
metacognitive sensitivity in hybrid decision-making settings. Our analysis
identifies conditions under which an AI with lower predictive accuracy but
higher metacognitive sensitivity can enhance the overall accuracy of human
decision making. Finally, a behavioral experiment confirms that greater AI
metacognitive sensitivity improves human decision performance. Together, these
findings underscore the importance of evaluating AI assistance not only by
accuracy but also by metacognitive sensitivity, and of optimizing both to
achieve superior decision outcomes.

</details>


### [8] [On the Definition of Intelligence](https://arxiv.org/abs/2507.22423)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本文提出了{	extepsilon}-类别智能作为评估智能的标准，该标准可跨越不同智能行为范式，提供了正式框架、实证协议概要以及对评估、安全性和泛化的讨论。


<details>
  <summary>Details</summary>
Motivation: 为了研发人工智能通用智能 (AGI)，需要将智能本质以种族不可知的形式进行捕捉，并足够通用以涵盖智能行为的多种范式，包括强化学习、生成模型、分类、类比推理和目标导向决策。

Method: 提出了一个基于采样保真度的智能评估标准，形式化为{	extepsilon}-类别智能，通过选择可区分生成样本和原始样本的鉴别器，来定义智能。

Result: 提出了{	extepsilon}-类别智能作为智能的评估标准，并介绍了正式框架、实证协议概要以及对评估、安全性和泛化的讨论。

Conclusion: 提出了在超越不同智能行为范式的基础上捕捉智能本质的广义标准，即基于采样保真度的{	extepsilon}-类别智能，该标准可用于评估、安全性和泛化方面的研究。

Abstract: To engineer AGI, we should first capture the essence of intelligence in a
species-agnostic form that can be evaluated, while being sufficiently general
to encompass diverse paradigms of intelligent behavior, including reinforcement
learning, generative models, classification, analogical reasoning, and
goal-directed decision-making. We propose a general criterion based on sample
fidelity: intelligence is the ability, given sample(s) from a category, to
generate sample(s) from the same category. We formalise this intuition as
{\epsilon}-category intelligence: it is {\epsilon}-intelligent with respect to
a category if no chosen admissible distinguisher can separate generated from
original samples beyond tolerance {\epsilon}. We present the formal framework,
outline empirical protocols, and discuss implications for evaluation, safety,
and generalization.

</details>


### [9] [Cross-Border Legal Adaptation of Autonomous Vehicle Design based on Logic and Non-monotonic Reasoning](https://arxiv.org/abs/2507.22432)
*Zhe Yu,Yiwei Lu,Burkhard Schafer,Zhe Lin*

Main category: cs.AI

TL;DR: 本文研究了自动驾驶车辆在跨国背景下的法律合规挑战，以设计师的视角提供支持性的法律推理。引入了基于论证理论的逻辑和自然数偏序集来帮助设计者更灵活地调整设计解决方案，从中可以更好理解法律对决策的影响。


<details>
  <summary>Details</summary>
Motivation: 针对自动驾驶车辆在跨国背景下的法律合规挑战，以设计师视角提供支持性的法律推理，使设计者更灵活地适应不同国家的法律要求，并更清晰地了解法律对其设计决策的影响，有助于更好地解决自动驾驶车辆应用中的法律问题。

Method: 基于论证理论，引入一种逻辑来表示基于论证的实践（规范性）推理的基本属性，结合自然数的偏序集来表达优先级。通过对法律文本的案例分析，展示推理系统如何帮助设计师适应跨国应用中的设计解决方案，并理解决策的法律影响。

Result: 通过提供一种基于论证理论的推理系统，设计者可以更好地调整自动驾驶车辆的设计解决方案，从而更好地适应跨国应用，并更易于理解法律决策的影响。

Conclusion: 该论文主要关注自动驾驶车辆在跨国背景下的法律合规挑战，以设计师的视角提供支持性的法律推理。通过论证理论，引入一种逻辑来表示基于论证的实践（规范性）推理的基本属性，结合自然数的偏序集来表达优先级。最后，通过对法律文本的案例分析，展示了我们提供的推理系统如何帮助设计师在自动驾驶车辆的跨境应用中更灵活地调整其设计解决方案，并更容易理解其决策的法律影响。

Abstract: This paper focuses on the legal compliance challenges of autonomous vehicles
in a transnational context. We choose the perspective of designers and try to
provide supporting legal reasoning in the design process. Based on
argumentation theory, we introduce a logic to represent the basic properties of
argument-based practical (normative) reasoning, combined with partial order
sets of natural numbers to express priority. Finally, through case analysis of
legal texts, we show how the reasoning system we provide can help designers to
adapt their design solutions more flexibly in the cross-border application of
autonomous vehicles and to more easily understand the legal implications of
their decisions.

</details>


### [10] [Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool](https://arxiv.org/abs/2507.22440)
*Yiya Diao,Changhe Li,Sanyou Zeng,Xinye Cai,Wenjian Luo,Shengxiang Yang,Carlos A. Coello Coello*

Main category: cs.AI

TL;DR: 本文提出了高效的NBN计算方法，解决了时间消耗问题，并在OneMax问题和TSP中发现了新特征。TSP问题的挑战包括崎岖性、多模性和欺骗性，现有算法有局限性。


<details>
  <summary>Details</summary>
Motivation: NBN方法在连续优化问题中保留多个景观特征，但计算耗时，并扩展到组合优化问题具有挑战性但非常重要。作者的动机在于分析算法行为，解决NBN时间消耗的问题，并在OneMax问题和TSP中进行新颖发现。

Method: 本文通过简单的理论推导表明，NBN网络实质上作为算法的最大概率转移网络。作者提出了具有对数线性时间复杂度的高效NBN计算方法，以解决时间消耗的问题。

Result: 通过应用高效的NBN算法，作者发现OneMax的适应性景观表现中性、崎岖和多态特征，同时指出TSP问题的主要挑战。现有算法如EAX和LKH在处理TSP问题的多模性和欺骗性方面存在局限性。

Conclusion: 本文提出了一种高效的最近改进网络(NBN)计算方法，解决了时间消耗的问题，并在OneMax问题和旅行商问题(TSP)中取得了几项突出发现。作者指出TSP问题的主要挑战在于崎岖性、多模性和欺骗性，现有算法在处理这些挑战时存在局限性。

Abstract: The Nearest-Better Network (NBN) is a powerful method to visualize sampled
data for continuous optimization problems while preserving multiple landscape
features. However, the calculation of NBN is very time-consuming, and the
extension of the method to combinatorial optimization problems is challenging
but very important for analyzing the algorithm's behavior. This paper provides
a straightforward theoretical derivation showing that the NBN network
essentially functions as the maximum probability transition network for
algorithms. This paper also presents an efficient NBN computation method with
logarithmic linear time complexity to address the time-consuming issue. By
applying this efficient NBN algorithm to the OneMax problem and the Traveling
Salesman Problem (TSP), we have made several remarkable discoveries for the
first time: The fitness landscape of OneMax exhibits neutrality, ruggedness,
and modality features. The primary challenges of TSP problems are ruggedness,
modality, and deception. Two state-of-the-art TSP algorithms (i.e., EAX and
LKH) have limitations when addressing challenges related to modality and
deception, respectively. LKH, based on local search operators, fails when there
are deceptive solutions near global optima. EAX, which is based on a single
population, can efficiently maintain diversity. However, when multiple
attraction basins exist, EAX retains individuals within multiple basins
simultaneously, reducing inter-basin interaction efficiency and leading to
algorithm's stagnation.

</details>


### [11] [Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic Matching Approach](https://arxiv.org/abs/2507.22504)
*Hongyan Cheng,Chengzhang Yu,Yanshu Shi,Chiyue Wang,Cong Liu,Zhanpeng Jin*

Main category: cs.AI

TL;DR: 研究提出了一种多智能体互动智能系统，用于医疗分诊，解决了当前基于AI的分诊系统中存在的医疗专业化不足、异构的医疗机构结构以及细节导向问诊低效的三个基本挑战。实验结果显示，系统在一级和二级科室分类准确率方面表现良好。该系统采用了专门化智能体和结构化的机制，为医疗分诊提供了具有可扩展性和适应性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究动机是由于后疫情时期对医疗需求的激增，以及关键护理人员短缺给急诊科分诊系统带来了前所未有的压力，迫切需要创新的基于AI的解决方案。

Method: 通过构建包括9个一级科室和62个二级科室的现实案例在内的详尽的中文医疗分诊数据集，并利用大型语言模型进行系统数据填充，解决了现实世界数据中不完整医疗记录的普遍问题。研究采用了三种专门化智能体 - RecipientAgent，InquirerAgent和DepartmentAgent，通过结构化的询问机制和部门特定的指导规则协作，将患者症状转化为准确的科室推荐。

Result: 实验结果表明，该多智能体系统在实际表现上取得了很高的准确率，证明了其有效性和可行性。

Conclusion: 研究提出了一种多智能体互动智能系统，用于医疗分诊，解决了当前基于AI的分诊系统中存在的医疗专业化不足、异构的医疗机构结构以及细节导向问诊低效的三个基本挑战。实验结果显示，该系统在四轮患者互动后，在一级科室分类方面达到了89.2%的准确率，在二级科室分类方面达到了73.9%的准确率。系统的指导机制基于模式匹配，能够有效适应不同医院配置，同时保持高分诊准确性。该工作为部署能够适应医疗机构组织异质性并确保临床决策的可扩展AI辅助分诊系统提供了一个框架。

Abstract: The post-pandemic surge in healthcare demand, coupled with critical nursing
shortages, has placed unprecedented pressure on emergency department triage
systems, necessitating innovative AI-driven solutions. We present a multi-agent
interactive intelligent system for medical triage that addresses three
fundamental challenges in current AI-based triage systems: insufficient medical
specialization leading to hallucination-induced misclassifications,
heterogeneous department structures across healthcare institutions, and
inefficient detail-oriented questioning that impedes rapid triage decisions.
Our system employs three specialized agents - RecipientAgent, InquirerAgent,
and DepartmentAgent - that collaborate through structured inquiry mechanisms
and department-specific guidance rules to transform unstructured patient
symptoms into accurate department recommendations. To ensure robust evaluation,
we constructed a comprehensive Chinese medical triage dataset from a medical
website, comprising 3,360 real-world cases spanning 9 primary departments and
62 secondary departments. Through systematic data imputation using large
language models, we address the prevalent issue of incomplete medical records
in real-world data. Experimental results demonstrate that our multi-agent
system achieves 89.2% accuracy in primary department classification and 73.9%
accuracy in secondary department classification after four rounds of patient
interaction. The system's pattern-matching-based guidance mechanisms enable
efficient adaptation to diverse hospital configurations while maintaining high
triage accuracy. Our work provides a scalable framework for deploying
AI-assisted triage systems that can accommodate the organizational
heterogeneity of healthcare institutions while ensuring clinically sound
decision-making.

</details>


### [12] [MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines](https://arxiv.org/abs/2507.22606)
*Yaolun Zhang,Xiaogeng Liu,Chaowei Xiao*

Main category: cs.AI

TL;DR: 本文提出了 MetaAgent 框架，使用有限状态机自动生成多智能体系统，并通过优化算法改进。实验证明，该框架优于其他自动生成方法，性能可与人类设计的系统媲美。框架解决了现有自动设计方法的限制，包括工具集成不足、依赖外部数据和通信结构僵化等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人类设计的多智能体框架通常限于少量预定义场景，自动设计方法存在各种限制，如工具集成不足、依赖外部训练数据和通信结构过于僵化。因此，本研究旨在解决这些问题，提出一种能够自动生成多智能体系统的框架。

Method: 提出了 MetaAgent 框架，基于有限状态机自动生成多智能体系统，并通过优化算法进行改进。进行了基于文本和实际任务的实验证明框架效果。

Result: 实验结果显示，MetaAgent 框架生成的多智能体系统表现优异，超越其他自动生成方法，同时性能可与人类设计的多智能体系统媲美。

Conclusion: 新提出的 MetaAgent 框架基于有限状态机，能够自动生成多智能体系统，并通过优化算法进行改进。实验结果表明，生成的多智能体系统优于其他自动生成方法，并能够达到与人类设计的多智能体系统相媲美的性能。

Abstract: Large Language Models (LLMs) have demonstrated the ability to solve a wide
range of practical tasks within multi-agent systems. However, existing
human-designed multi-agent frameworks are typically limited to a small set of
pre-defined scenarios, while current automated design methods suffer from
several limitations, such as the lack of tool integration, dependence on
external training data, and rigid communication structures. In this paper, we
propose MetaAgent, a finite state machine based framework that can
automatically generate a multi-agent system. Given a task description,
MetaAgent will design a multi-agent system and polish it through an
optimization algorithm. When the multi-agent system is deployed, the finite
state machine will control the agent's actions and the state transitions. To
evaluate our framework, we conduct experiments on both text-based tasks and
practical tasks. The results indicate that the generated multi-agent system
surpasses other auto-designed methods and can achieve a comparable performance
with the human-designed multi-agent system, which is optimized for those
specific tasks.

</details>


### [13] [Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting](https://arxiv.org/abs/2507.22619)
*Sebastian Monka,Irlan Grangel-González,Stefan Schmid,Lavdim Halilaj,Marc Rickart,Oliver Rudolph,Rui Dias*

Main category: cs.AI

TL;DR: 使用LLMs作为中介评估多种策略，帮助从KG中检索信息，重点关注制造领域。比较从KG传递相关上下文给LLM的方法，并分析其在将实际问题转换为SPARQL查询方面的熟练程度。研究发现，提供KG模式的充分上下文可以显著提高LLMs生成正确和完整查询的性能。上下文感知的提示技术帮助LLMs专注于本体的相关部分，并减少幻觉的风险。


<details>
  <summary>Details</summary>
Motivation: Address the challenge of translating natural language queries into SPARQL format to bridge the gap between user-friendly interfaces and the sophisticated architecture of KGs. Enhance LLMs' understanding of domain-specific KGs to improve query accuracy.

Method: Evaluate multiple strategies using LLMs as mediators to facilitate information retrieval from KGs, focusing on the manufacturing domain. Compare approaches for feeding relevant context from KG to LLM and analyze proficiency in transforming real-world questions into SPARQL queries.

Result: Findings indicate that LLMs perform better in generating correct and complete queries when provided with the adequate context of the KG schema. Context-aware prompting techniques aid LLMs in focusing on relevant ontology parts and reduce the risk of hallucination.

Conclusion: LLMs can significantly improve query generation from KGs by providing adequate context, reducing the risk of hallucination, and enhancing performance in manufacturing settings.

Abstract: Knowledge graphs (KGs) have transformed data management within the
manufacturing industry, offering effective means for integrating disparate data
sources through shared and structured conceptual schemas. However, harnessing
the power of KGs can be daunting for non-experts, as it often requires
formulating complex SPARQL queries to retrieve specific information. With the
advent of Large Language Models (LLMs), there is a growing potential to
automatically translate natural language queries into the SPARQL format, thus
bridging the gap between user-friendly interfaces and the sophisticated
architecture of KGs. The challenge remains in adequately informing LLMs about
the relevant context and structure of domain-specific KGs, e.g., in
manufacturing, to improve the accuracy of generated queries. In this paper, we
evaluate multiple strategies that use LLMs as mediators to facilitate
information retrieval from KGs. We focus on the manufacturing domain,
particularly on the Bosch Line Information System KG and the I40 Core
Information Model. In our evaluation, we compare various approaches for feeding
relevant context from the KG to the LLM and analyze their proficiency in
transforming real-world questions into SPARQL queries. Our findings show that
LLMs can significantly improve their performance on generating correct and
complete queries when provided only the adequate context of the KG schema. Such
context-aware prompting techniques help LLMs to focus on the relevant parts of
the ontology and reduce the risk of hallucination. We anticipate that the
proposed techniques help LLMs to democratize access to complex data
repositories and empower informed decision-making in manufacturing settings.

</details>


### [14] [ASP-FZN: A Translation-based Constraint Answer Set Solver](https://arxiv.org/abs/2507.22774)
*Thomas Eiter,Tobias Geibinger,Tobias Kaminski,Nysret Musliu,Johannes Oetsch*

Main category: cs.AI

TL;DR: Asp-fzn is a solver for CASP that extends ASP with linear constraints, translating programs into FlatZinc. It competes well with state-of-the-art ASP solvers and outperforms clingcon on some CASP benchmarks, demonstrating promising performance in both ASP and CASP problems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance ASP by incorporating linear constraints through the asp-fzn solver and provide a solver-independent approach by translating CASP programs into FlatZinc. The aim is to demonstrate competitive performance and compare it with the renowned CASP solver clingcon.

Method: The paper presents the solver asp-fzn that extends ASP with linear constraints by translating CASP programs into the FlatZinc language. The solver supports a rich language of linear constraints, including common global constraints, and is evaluated on benchmarks from past ASP competitions as well as CASP problems from the literature.

Result: The evaluation shows that asp-fzn is competitive with state-of-the-art ASP solvers on benchmarks from past competitions and even outperforms clingcon on some CASP benchmarks. The performance of asp-fzn is promising and highlights its effectiveness in enhancing ASP with linear constraints.

Conclusion: Asp-fzn, a solver for Constraint Answer Set Programming (CASP), demonstrates competitive performance with state-of-the-art ASP solvers on various benchmarks and outperforms clingcon on some CASP benchmarks.

Abstract: We present the solver asp-fzn for Constraint Answer Set Programming (CASP),
which extends ASP with linear constraints. Our approach is based on translating
CASP programs into the solver-independent FlatZinc language that supports
several Constraint Programming and Integer Programming backend solvers. Our
solver supports a rich language of linear constraints, including some common
global constraints. As for evaluation, we show that asp-fzn is competitive with
state-of-the-art ASP solvers on benchmarks taken from past ASP competitions.
Furthermore, we evaluate it on several CASP problems from the literature and
compare its performance with clingcon, which is a prominent CASP solver that
supports most of the asp-fzn language. The performance of asp-fzn is very
promising as it is already competitive on plain ASP and even outperforms
clingcon on some CASP benchmarks.

</details>


### [15] [Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies](https://arxiv.org/abs/2507.22782)
*Hugo Garrido-Lestache,Jeremy Kedziora*

Main category: cs.AI

TL;DR: TAAC is a reinforcement learning algorithm that enhances multi-agent collaboration through dynamic communication and efficient management of joint-action spaces. It outperforms benchmark algorithms in multi-agent environments, showing superior performance and enhanced collaboration across multiple metrics.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance multi-agent collaboration in cooperative environments by enabling dynamic inter-agent communication and efficient management of joint-action spaces while ensuring a high degree of collaboration.

Method: TAAC employs a Centralized Training/Centralized Execution scheme with multi-headed attention mechanisms in both the actor and critic. It also introduces a penalized loss function to encourage diverse yet complementary roles among agents.

Result: TAAC outperforms benchmark algorithms in various metrics such as win rates, goal differentials, Elo ratings, inter-agent connectivity, spatial distributions, and tactical interactions like ball possession swaps.

Conclusion: TAAC shows superior performance and enhanced collaboration compared to benchmark algorithms in multi-agent environments.

Abstract: This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement
learning algorithm designed to enhance multi-agent collaboration in cooperative
environments. TAAC employs a Centralized Training/Centralized Execution scheme
incorporating multi-headed attention mechanisms in both the actor and critic.
This design facilitates dynamic, inter-agent communication, allowing agents to
explicitly query teammates, thereby efficiently managing the exponential growth
of joint-action spaces while ensuring a high degree of collaboration. We
further introduce a penalized loss function which promotes diverse yet
complementary roles among agents. We evaluate TAAC in a simulated soccer
environment against benchmark algorithms representing other multi-agent
paradigms, including Proximal Policy Optimization and Multi-Agent
Actor-Attention-Critic. We find that TAAC exhibits superior performance and
enhanced collaborative behaviors across a variety of metrics (win rates, goal
differentials, Elo ratings, inter-agent connectivity, balanced spatial
distributions, and frequent tactical interactions such as ball possession
swaps).

</details>


### [16] [The Incomplete Bridge: How AI Research (Mis)Engages with Psychology](https://arxiv.org/abs/2507.22847)
*Han Jiang,Pengda Wang,Xiaoyuan Yi,Xing Xie,Ziang Xiao*

Main category: cs.AI

TL;DR: 该研究分析了在2023年至2025年间在顶尖人工智能会议上发表的1,006篇LLM相关论文及其引用的2,544篇心理学论文，探讨了人工智能与心理学之间的跨学科融合。研究辨明了跨学科整合的关键模式，找到了心理学中引用最频繁的领域，并提供了对心理学理论/框架实施和解释方式的分析。研究结果强调了仍未充分探索的领域，识别了常见的误用类型，并提出了更有效整合的建议。总体而言，该研究为人工智能与心理学之间的跨学科合作提供了深入见解，并为推动人工智能系统的发展提供了指导。


<details>
  <summary>Details</summary>
Motivation: 社会科学积累了丰富的理论和方法，可以用于探索人类心智和行为，为设计和理解人工智能系统提供宝贵见解。本研究聚焦心理学作为突出案例，通过分析在2023年至2025年间在顶尖人工智能会议上发表的1,006篇LLM相关论文及其引用的2,544篇心理学论文，探讨了人工智能与心理学领域之间的跨学科协同关系。

Method: 分析了在2023年至2025年间在顶尖人工智能会议上发表的1,006篇LLM相关论文及其引用的2,544篇心理学论文。通过对这些论文的研究，确定了跨学科整合的关键模式，找到了心理学领域中被引用最频繁的领域，并强调仍未被充分探索的领域。进一步研究了心理学理论/框架的操作化和解释方式，确定了常见的误用类型，并提出了更有效整合的指导。

Result: 辨明了跨学科整合的关键模式，找到了心理学中引用最频繁的领域，强调了仍未充分探索的领域，并提供了对心理学理论/框架实施和解释方式的分析，识别了常见的误用类型，并提出了更有效整合的指导。研究为人工智能与心理学之间的跨学科合作提供了全面的地图，促进了更深入的合作并推动了人工智能系统的发展。

Conclusion: 该研究探讨了人工智能与心理学之间的跨学科融合，识别了重要的跨学科整合模式、心理学领域的主要引用以及尚未充分开发的领域。还分析了心理学理论/框架的实施和解释方式，识别了常见的误用类型，并提供建议以更有效地融合两个领域。研究提供了人工智能与心理学之间跨学科参与的全面图景，促进了更深入的合作并推动了人工智能系统的发展。

Abstract: Social sciences have accumulated a rich body of theories and methodologies
for investigating the human mind and behaviors, while offering valuable
insights into the design and understanding of Artificial Intelligence (AI)
systems. Focusing on psychology as a prominent case, this study explores the
interdisciplinary synergy between AI and the field by analyzing 1,006
LLM-related papers published in premier AI venues between 2023 and 2025, along
with the 2,544 psychology publications they cite. Through our analysis, we
identify key patterns of interdisciplinary integration, locate the psychology
domains most frequently referenced, and highlight areas that remain
underexplored. We further examine how psychology theories/frameworks are
operationalized and interpreted, identify common types of misapplication, and
offer guidance for more effective incorporation. Our work provides a
comprehensive map of interdisciplinary engagement between AI and psychology,
thereby facilitating deeper collaboration and advancing AI systems.

</details>


### [17] [Automatically discovering heuristics in a complex SAT solver with large language models](https://arxiv.org/abs/2507.22876)
*Yiwen Sun,Furong Ye,Zhihan Chen,Ke Wei,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoModSAT optimizes complex SAT solvers using Large Language Models (LLMs), addressing challenges in solver development, prompt optimization, and search strategy design. It outperforms state-of-the-art solvers, showcasing significant improvements in handling complex problem instances.


<details>
  <summary>Details</summary>
Motivation: Existing automatic configuration frameworks for SAT solvers have limitations in performance gains. The paper aims to enhance optimization of SAT solvers in real-world settings by leveraging Large Language Models (LLMs) and innovative techniques.

Method: Introduces a novel paradigm using Large Language Models (LLMs) to optimize SAT solvers, develops AutoModSAT tool. Addresses three challenges: LLM-friendly solver development, automatic prompt optimization, and efficient search strategy design. Conducts extensive experiments across various datasets to validate performance improvements.

Result: AutoModSAT achieves 50% performance improvement over baseline solver, 30% superiority against state-of-the-art solvers, and 20% speedup compared to parameter-tuned alternatives of the state-of-the-art solvers.

Conclusion: AutoModSAT achieves significant performance improvements in optimizing complex SAT solvers, surpassing state-of-the-art solvers and demonstrating enhanced capabilities in handling complex problem instances.

Abstract: Satisfiability problem (SAT) is a cornerstone of computational complexity
with broad industrial applications, and it remains challenging to optimize
modern SAT solvers in real-world settings due to their intricate architectures.
While automatic configuration frameworks have been developed, they rely on
manually constrained search spaces and yield limited performance gains. This
work introduces a novel paradigm which effectively optimizes complex SAT
solvers via Large Language Models (LLMs), and a tool called AutoModSAT is
developed. Three fundamental challenges are addressed in order to achieve
superior performance: (1) LLM-friendly solver: Systematic guidelines are
proposed for developing a modularized solver to meet LLMs' compatibility,
emphasizing code simplification, information share and bug reduction; (2)
Automatic prompt optimization: An unsupervised automatic prompt optimization
method is introduced to advance the diversity of LLMs' output; (3) Efficient
search strategy: We design a presearch strategy and an EA evolutionary
algorithm for the final efficient and effective discovery of heuristics.
Extensive experiments across a wide range of datasets demonstrate that
AutoModSAT achieves 50% performance improvement over the baseline solver and
achieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover,
AutoModSAT attains a 20% speedup on average compared to parameter-tuned
alternatives of the SOTA solvers, showcasing the enhanced capability in
handling complex problem instances. This work bridges the gap between AI-driven
heuristics discovery and mission-critical system optimization, and provides
both methodological advancements and empirically validated results for
next-generation complex solver development.

</details>
