<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 21]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
*Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis*

Main category: cs.AI

TL;DR: 本研究使用符号回归（SR）模型三维不可压缩流在矩形通道中的速度和压力场，从数值模拟数据中导出符号方程，将SR与Answer Set Programming（ASP）框架结合，确保生成的符号表达准确可信。研究突出了SR简化复杂流动行为并提高数据驱动模型可靠性的能力，表明知识表示方法有助于保持模型与领域原则一致。


<details>
  <summary>Details</summary>
Motivation: 由于在流体力学中理解潜在流动物理与准确预测同等重要，本研究受此启发，将SR应用于建模基本的三维不可压缩流，关注（轴向）速度和压力场。

Method: 应用符号回归（SR）模型三维不可压缩流在矩形通道中的速度和压力场，采用PySR库从数值模拟数据中导出简洁的符号方程，结合Answer Set Programming（ASP）框架，确保SR生成的符号表达不仅在统计上准确，而且在物理上可信，符合特定领域原则。

Result: 研究通过SR模拟了研究中观察到的流体流动中的抛物线速度剖面和压降，与文献中的分析解完全吻合。提出的混合SR/ASP框架强调了SR的简化复杂流动行为和知识表示方法提高数据驱动SR模型可靠性和与领域原则一致性的重要性。

Conclusion: 本研究强调了符号回归（SR）在揭示复杂物理系统中可解释数学关系方面的能力，以及与Answer Set Programming（ASP）框架相结合的潜力。研究结果展示了从三维不可压缩流数值模拟数据中推导出的简洁符号方程，符合流体动力学的关键特征。将SR与ASP结合的创新方法确保了SR生成的符号表达不仅在统计上准确，而且在物理上可信，符合特定领域原则。研究突出了两个主要贡献：SR将复杂流动行为简化为简洁可解释的方程；知识表示方法有助于提高数据驱动的SR模型与领域原则的可靠性和一致性。通过研究3D通道流的见解，为将这种混合方法整合到效率框架中铺平了道路，其中可解释的预测和实时数据分析至关重要。

Abstract: Unlike conventional Machine-Learning (ML) approaches, often criticized as
"black boxes", Symbolic Regression (SR) stands out as a powerful tool for
revealing interpretable mathematical relationships in complex physical systems,
requiring no a priori assumptions about models' structures. Motivated by the
recognition that, in fluid mechanics, an understanding of the underlying flow
physics is as crucial as accurate prediction, this study applies SR to model a
fundamental three-dimensional (3D) incompressible flow in a rectangular
channel, focusing on the (axial) velocity and pressure fields under laminar
conditions. By employing the PySR library, compact symbolic equations were
derived directly from numerical simulation data, revealing key characteristics
of the flow dynamics. These equations not only approximate the parabolic
velocity profile and pressure drop observed in the studied fluid flow, but also
perfectly coincide with analytical solutions from the literature. Furthermore,
we propose an innovative approach that integrates SR with the
knowledge-representation framework of Answer Set Programming (ASP), combining
the generative power of SR with the declarative reasoning strengths of ASP. The
proposed hybrid SR/ASP framework ensures that the SR-generated symbolic
expressions are not only statistically accurate, but also physically plausible,
adhering to domain-specific principles. Overall, the study highlights two key
contributions: SR's ability to simplify complex flow behaviours into concise,
interpretable equations, and the potential of knowledge-representation
approaches to improve the reliability and alignment of data-driven SR models
with domain principles. Insights from the examined 3D channel flow pave the way
for integrating such hybrid approaches into efficient frameworks, [...] where
explainable predictions and real-time data analysis are crucial.

</details>


### [2] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
*SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam*

Main category: cs.AI

TL;DR: Recent advancements focus on automating data analysis insight generation but lack structured reasoning processes. I2I-STRADA addresses this by modeling cognitive steps. It outperforms prior systems in planning coherence and insight alignment, showing the significance of structured cognitive workflows in data analysis.


<details>
  <summary>Details</summary>
Motivation: Recent advances in agentic systems emphasize automation of insight generation but overlook the structured reasoning process underlying analytical thinking. Real-world data analysis requires a consistent cognitive workflow which I2I-STRADA aims to address.

Method: Introducing I2I-STRADA, an agentic architecture designed to formalize the reasoning process in data analysis through modular sub-tasks reflecting cognitive steps.

Result: Evaluations on benchmarks show that I2I-STRADA performs better in planning coherence and insight alignment compared to previous systems.

Conclusion: I2I-STRADA outperforms prior systems in planning coherence and insight alignment, highlighting the importance of structured cognitive workflows in agent design for data analysis.

Abstract: Recent advances in agentic systems for data analysis have emphasized
automation of insight generation through multi-agent frameworks, and
orchestration layers. While these systems effectively manage tasks like query
translation, data transformation, and visualization, they often overlook the
structured reasoning process underlying analytical thinking. Reasoning large
language models (LLMs) used for multi-step problem solving are trained as
general-purpose problem solvers. As a result, their reasoning or thinking steps
do not adhere to fixed processes for specific tasks. Real-world data analysis
requires a consistent cognitive workflow: interpreting vague goals, grounding
them in contextual knowledge, constructing abstract plans, and adapting
execution based on intermediate outcomes. We introduce I2I-STRADA
(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an
agentic architecture designed to formalize this reasoning process. I2I-STRADA
focuses on modeling how analysis unfolds via modular sub-tasks that reflect the
cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench
benchmarks show that I2I-STRADA outperforms prior systems in planning coherence
and insight alignment, highlighting the importance of structured cognitive
workflows in agent design for data analysis.

</details>


### [3] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
*Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang*

Main category: cs.AI

TL;DR: SmartAPS is a conversational system using a tool-augmented LLM to provide natural language interactions for operations planners, addressing the accessibility issues of traditional advanced planning systems and offering a cost-effective solution for supply chain planners to manage operations effectively.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to make advanced planning systems more accessible to supply chain planners by reducing the costs associated with customization and maintenance, which often make such systems prohibitively expensive for many customers. SmartAPS aims to provide a more user-friendly and cost-effective solution for operations planners to manage their operations effectively.

Method: The paper presents SmartAPS, a conversational system integrated with a tool-augmented large language model (LLM) to provide intuitive natural language interactions for operations planners. The system aims to address accessibility issues faced by supply chain planners using advanced planning systems.

Result: The result is the development of SmartAPS, a conversational system that enables operations planners to interact with an intuitive natural language chat interface for querying information, performing counterfactual reasoning, receiving recommendations, and conducting scenario analysis. The system aims to enhance the management of operations for supply chain planners.

Conclusion: SmartAPS is a conversational system built on a tool-augmented LLM to make advanced planning systems more accessible to supply chain planners, enabling intuitive natural language interactions for querying information, reasoning, recommendations, and scenario analysis.

Abstract: Large language models (LLMs) present intriguing opportunities to enhance user
interaction with traditional algorithms and tools in real-world applications.
An advanced planning system (APS) is a sophisticated software that leverages
optimization to help operations planners create, interpret, and modify an
operational plan. While highly beneficial, many customers are priced out of
using an APS due to the ongoing costs of consultants responsible for
customization and maintenance. To address the need for a more accessible APS
expressed by supply chain planners, we present SmartAPS, a conversational
system built on a tool-augmented LLM. Our system provides operations planners
with an intuitive natural language chat interface, allowing them to query
information, perform counterfactual reasoning, receive recommendations, and
execute scenario analysis to better manage their operation. A short video
demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw

</details>


### [4] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
*Dario Della Monica,Angelo Montanari,Pietro Sala*

Main category: cs.AI

TL;DR: 该论文研究了定性基于时间轴的规划模型，发现可以将其子集直接映射到确定性有限自动机的非空问题，从而简化了合成策略的步骤。


<details>
  <summary>Details</summary>
Motivation: 鉴于目前使用非确定性自动机合成规划策略时需要昂贵的确定化步骤，本文旨在找出一个直接映射到确定性有限自动机的子集，以解决此问题。

Method: 通过识别适合确定性有限自动机非空问题的定性基于时间轴规划的子集，解决了合成规划策略时需要昂贵的确定化步骤的问题。

Result: 该论文确定了一组Allen关系的最大子集，适用于确定性的时间轴规划模型，从而简化了合成策略的过程。

Conclusion: 该论文确定了定性基于时间轴的规划模型的一个子集，可以直接映射到确定性有限自动机的非空问题，从而可以合成策略。

Abstract: Qualitative timeline-based planning models domains as sets of independent,
but
  interacting, components whose behaviors over time, the timelines, are
governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronization rules.
  Its plan-existence problem has been shown to be PSPACE-complete; in
  particular, PSPACE-membership has been proved via reduction to the
  nonemptiness problem for nondeterministic finite automata.
  However, nondeterministic automata cannot be directly used to synthesize
  planning strategies as a costly determinization step is needed.
  In this paper, we identify a fragment of qualitative timeline-based planning
  whose plan-existence problem can be directly mapped into the nonemptiness
  problem of deterministic finite automata, which can then
  synthesize strategies.
  In addition, we identify a maximal subset of Allen's relations that fits into
  such a deterministic fragment.

</details>


### [5] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
*Yusen Peng,Shuhua Mao*

Main category: cs.AI

TL;DR: 本文探讨了如何让人工智能实现真正的创造力，提出了E.A.R.T.H.框架，通过五个阶段的生成管道将模型生成的错误转化为创造性资产。在Refine阶段，创造力得分提高了52.5%，最终输出得分达到2.010，提升了70.4%。人类评估显示60%的输出得分>=4.0，比喻口号表现优于直接口号。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨如何让人工智能超越模仿，朝向真正的创造力。借鉴认知科学和生成建模，提出了E.A.R.T.H.框架，旨在将模型生成的错误转化为创意资产。

Method: 使用LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和稳定扩散等工具，采用基于新颖性、惊喜和相关性的复合奖励函数。通过结构化提示、语义评分和人在环评估操作化“创意潜在隐藏在失败中”的假设。

Result: 在Refine阶段，创造力得分提高了52.5%，最终输出达到2.010，提升了70.4%。经过人类评估，60%的输出得分>=4.0，比喻口号表现优异。

Conclusion: 该论文提出了E.A.R.T.H.框架，通过五个阶段的生成管道，将模型生成的错误转化为创造性资产。在Refine阶段，创造力得分提高了52.5%，终稿达到2.010，提升了70.4%。在人类评估中，60%的输出得分达到4.0以上，比喻口号优于直接口号。结果表明，以错误为中心、以反馈驱动的生成方式可以增强创造力，为自我进化、与人类对齐的创造性AI提供了可扩展的路径。

Abstract: How can AI move beyond imitation toward genuine creativity? This paper
proposes the E.A.R.T.H. framework, a five-stage generative pipeline that
transforms model-generated errors into creative assets through Error
generation, Amplification, Refine selection, Transform, and Harness feedback.
Drawing on cognitive science and generative modeling, we posit that "creative
potential hides in failure" and operationalize this via structured prompts,
semantic scoring, and human-in-the-loop evaluation. Implemented using
LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the
pipeline employs a composite reward function based on novelty, surprise, and
relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to
1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%
improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a
4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment
(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs
scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones
(3.99). Feedback highlights stylistic precision and emotional resonance. These
results demonstrate that error-centered, feedback-driven generation enhances
creativity, offering a scalable path toward self-evolving, human-aligned
creative AI.

</details>


### [6] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
*Victoria R. Li,Johnathan Sun,Martin Wattenberg*

Main category: cs.AI

TL;DR: 本研究通过实验发现，人工智能系统如GPT 4.1和Claude 3.5可以从可视化中受益，特别是在处理复杂数据集时。图表内容对模型性能具有重要影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨图表和图形对人工智能系统是否有用，通过实验验证可视化对视觉-语言模型的影响。通过对比基准模型，探究图表内容对模型性能的影响。

Method: 研究采用了一系列实验，利用两种商业视觉-语言模型：GPT 4.1和Claude 3.5，在三个代表性的分析任务中进行比较。实验设置包括提供空白图表、图表和不匹配数据的比较，以研究图表对模型表现的影响。

Result: 研究结果表明，当原始数据辅以散点图时，视觉-语言模型可以更准确地描述合成数据集，特别是在数据集复杂性增加时。相比于提供空白图表和包含不匹配数据的图表，图表内容是提升性能的关键因素。

Conclusion: 该研究的结论是人工智能系统可以从可视化中受益，通过实验发现当原始数据辅以散点图时，商用GPT 4.1和Claude 3.5的视觉-语言模型能更准确地描述合成数据集，特别是在数据集复杂性增加时。两个基准模型的对比表明改进的性能归因于图表的内容。

Abstract: Charts and graphs help people analyze data, but can they also be useful to AI
systems? To investigate this question, we perform a series of experiments with
two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three
representative analysis tasks, the two systems describe synthetic datasets more
precisely and accurately when raw data is accompanied by a scatterplot,
especially as datasets grow in complexity. Comparison with two baselines --
providing a blank chart and a chart with mismatched data -- shows that the
improved performance is due to the content of the charts. Our results are
initial evidence that AI systems, like humans, can benefit from visualization.

</details>


### [7] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
*Yueheng Li,Guangming Xie,Zongqing Lu*

Main category: cs.AI

TL;DR: MAGPO is a new framework for decentralized multi-agent learning that integrates centralized guidance with decentralized execution, outperforming CTDE baselines and matching or surpassing fully centralized approaches. The framework offers a practical solution with theoretical guarantees of policy improvement.


<details>
  <summary>Details</summary>
Motivation: Existing CTDE methods underutilize centralized training and lack theoretical guarantees. The motivation is to better leverage centralized training in cooperative Multi-Agent Reinforcement Learning by aligning centralized guidance with decentralized policies.

Method: Proposed Multi-Agent Guided Policy Optimization (MAGPO) framework integrates centralized guidance with decentralized execution using an auto-regressive joint policy. The framework ensures scalable, coordinated exploration and deployability under partial observability.

Result: Theoretical guarantees of monotonic policy improvement are provided, and empirical evaluation on 43 tasks across 6 diverse environments shows that MAGPO consistently outperforms CTDE baselines.

Conclusion: MAGPO outperforms strong CTDE baselines and matches or surpasses fully centralized approaches in decentralized multi-agent learning, providing a principled and practical solution with theoretical guarantees of monotonic policy improvement.

Abstract: Due to practical constraints such as partial observability and limited
communication, Centralized Training with Decentralized Execution (CTDE) has
become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning
(MARL). However, existing CTDE methods often underutilize centralized training
or lack theoretical guarantees. We propose Multi-Agent Guided Policy
Optimization (MAGPO), a novel framework that better leverages centralized
training by integrating centralized guidance with decentralized execution.
MAGPO uses an auto-regressive joint policy for scalable, coordinated
exploration and explicitly aligns it with decentralized policies to ensure
deployability under partial observability. We provide theoretical guarantees of
monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across
6 diverse environments. Results show that MAGPO consistently outperforms strong
CTDE baselines and matches or surpasses fully centralized approaches, offering
a principled and practical solution for decentralized multi-agent learning. Our
code and experimental data can be found in https://github.com/liyheng/MAGPO.

</details>


### [8] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
*Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu*

Main category: cs.AI

TL;DR: 本论文介绍了ASI-Arch，这是人工超智能在神经结构发现领域的首次示范，使人工智能能够进行自身的架构创新。通过自主实验，他们发现了106个创新的最先进的线性注意力架构，超越了人工设计的基准。建立了科学发现的经验规律，展示了架构突破可以在计算上扩展，从而加速研究进展。提供了自主研究能力和设计模式的深入分析，为自我加速的人工智能系统奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统展示出指数级的能力提升，但人工智能研究本身的步伐仍受人类认知容量的线性限制，造成愈发严重的发展瓶颈。本论文旨在突破这一基本约束，使人工智能能够进行自身的架构创新，从而实现研究进展从人类限制的过程转变为计算可扩展的过程。

Method: 引入 ASI-Arch，一种完全自主的系统，能让人工智能进行自身的架构创新。与传统的神经结构搜索（NAS）不同，ASI-Arch能在体系结构发现领域进行端到端的科学研究，自主提出新奇的架构概念，将其实现为可执行代码，并通过严格的实验和历史经验验证其性能。ASI-Arch进行了1773个自主实验，耗时20000个GPU小时，最终发现了106个创新的最先进的线性注意力架构。

Result: ASI-Arch成果包括发现106个创新的最先进的线性注意力架构，建立了科学发现的经验规律。他们提供了对自主性研究能力和新兴设计模式的全面分析，为自我加速的人工智能系统建立了蓝图。

Conclusion: 该论文展示了 ASI-Arch，这是第一个展示人工超智能用于人工智能研究（ASI4AI）的示范，突破了人类认知容量对人工智能研究的线性限制。他们提出了自动进行创新的范式转变，从自动优化到自动创新。通过 ASI-Arch，他们发现了106个创新的最先进（SOTA）线性注意力结构，这些结构系统地超越了人工设计的基准，并揭示了以前未知的架构创新路径。他们还建立了第一个科学发现的经验规律，展示了架构突破可以在计算上扩展，将研究进展从受人类限制的过程转变为可以扩展计算的过程。

Abstract: While AI systems demonstrate exponentially improving capabilities, the pace
of AI research itself remains linearly bounded by human cognitive capacity,
creating an increasingly severe development bottleneck. We present ASI-Arch,
the first demonstration of Artificial Superintelligence for AI research
(ASI4AI) in the critical domain of neural architecture discovery--a fully
autonomous system that shatters this fundamental constraint by enabling AI to
conduct its own architectural innovation. Moving beyond traditional Neural
Architecture Search (NAS), which is fundamentally limited to exploring
human-defined spaces, we introduce a paradigm shift from automated optimization
to automated innovation. ASI-Arch can conduct end-to-end scientific research in
the domain of architecture discovery, autonomously hypothesizing novel
architectural concepts, implementing them as executable code, training and
empirically validating their performance through rigorous experimentation and
past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000
GPU hours, culminating in the discovery of 106 innovative, state-of-the-art
(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed
unexpected strategic insights invisible to human players, our AI-discovered
architectures demonstrate emergent design principles that systematically
surpass human-designed baselines and illuminate previously unknown pathways for
architectural innovation. Crucially, we establish the first empirical scaling
law for scientific discovery itself--demonstrating that architectural
breakthroughs can be scaled computationally, transforming research progress
from a human-limited to a computation-scalable process. We provide
comprehensive analysis of the emergent design patterns and autonomous research
capabilities that enabled these breakthroughs, establishing a blueprint for
self-accelerating AI systems.

</details>


### [9] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
*Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha*

Main category: cs.AI

TL;DR: 本研究提出了Agentic AI框架，在医疗保健中构建和部署机器学习解决方案仍然昂贵且需要大量人力劳动。该框架通过自动化整个临床数据流程，处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐。系统在老年医学、姑息护理和结肠镜成像数据集上进行了评估，展示了框架的有效性和适用性。通过减少重复专家干预，提供了在临床环境中操作AI的可扩展、成本效益的途径。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健中构建和部署机器学习解决方案的成本高、需要大量人力并受到数据隐私约束，本研究旨在通过自动化临床数据流程的Agentic AI框架减少专家干预，为在临床环境中实现AI提供成本效益的可扩展途径。

Method: 介绍了Agentic AI框架，使用一系列模块化的任务特定代理处理医疗保健中的机器学习解决方案，包括自动化数据摄入、特征提取、模型选择和预处理推荐等过程。 在公开可用的老年医学、姑息护理和结肠镜成像数据集上进行了评估。

Result: 系统在老年医学、姑息护理和结肠镜成像等领域的数据集上进行了评估，展示了自动化数据处理流程的有效性和适用性。通过减少重复专家干预，提供了在临床环境中操作AI的可扩展、成本效益的途径。

Conclusion: 提出了一种Agentic AI框架，在医疗保健中构建和部署机器学习解决方案仍然昂贵且需要大量人力劳动，该框架通过一系列模块化的任务特定代理自动化整个临床数据流程，从数据摄入到推断，以处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐，无需手动干预。

Abstract: Building and deploying machine learning solutions in healthcare remains
expensive and labor-intensive due to fragmented preprocessing workflows, model
compatibility issues, and stringent data privacy constraints. In this work, we
introduce an Agentic AI framework that automates the entire clinical data
pipeline, from ingestion to inference, through a system of modular,
task-specific agents. These agents handle both structured and unstructured
data, enabling automatic feature selection, model selection, and preprocessing
recommendation without manual intervention. We evaluate the system on publicly
available datasets from geriatrics, palliative care, and colonoscopy imaging.
For example, in the case of structured data (anxiety data) and unstructured
data (colonoscopy polyps data), the pipeline begins with file-type detection by
the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring
privacy compliance, where we first identify the data type and then anonymize
it. The Feature Extraction Agent identifies features using an embedding-based
approach for tabular data, extracting all column names, and a multi-stage
MedGemma-based approach for image data, which infers modality and disease name.
These features guide the Model-Data Feature Matcher Agent in selecting the
best-fit model from a curated repository. The Preprocessing Recommender Agent
and Preprocessing Implementor Agent then apply tailored preprocessing based on
data type and model requirements. Finally, the ``Model Inference Agent" runs
the selected model on the uploaded data and generates interpretable outputs
using tools like SHAP, LIME, and DETR attention maps. By automating these
high-friction stages of the ML lifecycle, the proposed framework reduces the
need for repeated expert intervention, offering a scalable, cost-efficient
pathway for operationalizing AI in clinical environments.

</details>


### [10] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
*Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black*

Main category: cs.AI

TL;DR: 本研究利用自然语言处理和主动学习技术快速开发分类器，旨在从急诊科病历中检测疫苗安全问题，结合数据增强和评估技术以提高模型性能。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫苗的快速发展展示了全球社区应对传染病的能力。然而，由于临床试验中数据收集时间有限且早期广泛实施，因此对事后许可监测系统的需求增加。急诊科初步评估备注中包含专家提供的简明重要患者信息，可以显著有助于及时监测疫苗安全信号。

Method: 本研究采用自然语言处理技术和主动学习方法，结合数据增强和评估技术，用于快速开发分类器。

Result: 通过本研究结合自然语言处理和主动学习技术，成功开发了从急诊科病历中检测潜在疫苗安全问题的分类器，为增强疫苗安全监测提供了有力工具。

Conclusion: 本研究旨在利用自然语言处理技术和主动学习快速开发一个分类器，用于从急诊科病历中检测潜在的疫苗安全问题。主动学习、数据增强和评估技术的结合将用于创建用于增强疫苗安全监测的分类器。

Abstract: The rapid development of COVID-19 vaccines has showcased the global
communitys ability to combat infectious diseases. However, the need for
post-licensure surveillance systems has grown due to the limited window for
safety data collection in clinical trials and early widespread implementation.
This study aims to employ Natural Language Processing techniques and Active
Learning to rapidly develop a classifier that detects potential vaccine safety
issues from emergency department notes. ED triage notes, containing expert,
succinct vital patient information at the point of entry to health systems, can
significantly contribute to timely vaccine safety signal surveillance. While
keyword-based classification can be effective, it may yield false positives and
demand extensive keyword modifications. This is exacerbated by the infrequency
of vaccination-related ED presentations and their similarity to other reasons
for ED visits. NLP offers a more accurate and efficient alternative, albeit
requiring annotated data, which is often scarce in the medical field. Active
learning optimizes the annotation process and the quality of annotated data,
which can result in faster model implementation and improved model performance.
This work combines active learning, data augmentation, and active learning and
evaluation techniques to create a classifier that is used to enhance vaccine
safety surveillance from ED triage notes.

</details>


### [11] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
*Moritz Schönherr,Carsten Lutz*

Main category: cs.AI

TL;DR: 本文研究了使用均值作为聚合函数的图神经网络（GNNs）的表达能力，发现在非均匀设置下与比率模态逻辑的表达能力相同，在统一设置下相对于MSO表达能力与无交替模态逻辑相同。


<details>
  <summary>Details</summary>
Motivation: 研究动机是了解使用均值作为聚合函数的图神经网络在不同设置下的表达能力，揭示其与各种逻辑形式之间的关系。

Method: 研究方法包括对非均匀设置和统一设置下的图神经网络（GNNs）的表达能力进行分析和比较。通过证明在不同设置下GNNs与不同逻辑形式的表达能力等价来得出结论。

Result: 通过研究发现，在非均匀设置下，均值GNNs与比率模态逻辑具有相同的表达能力，而在统一设置下，相对于MSO，均值GNNs的表达能力与无交替模态逻辑相同。因此，在不同设置下，均值GNNs的表达能力各不相同。

Conclusion: 本文研究了使用均值作为聚合函数的图神经网络（GNNs）的表达能力。在非均匀设置下，表明这样的GNNs与比率模态逻辑具有完全相同的表达能力，后者具有表达操作符，表明至少某个顶点的继承者比例满足指定属性。均值GNNs的非均匀表达能力因此高于最大聚合的GNNs，但低于和聚合的GNNs。在统一设置下，相对于MSO，其表达能力与无交替模态逻辑完全相同，前提是组合函数连续且分类函数为阈值。相对于MSO在统一设置下，均值GNNs的表达能力严格低于和GNNs和最大GNNs。当其中任何假设被放弃时，表达能力将增加。

Abstract: We study the expressive power of graph neural networks (GNNs) with mean as
the aggregation function. In the non-uniform setting, we show that such GNNs
have exactly the same expressive power as ratio modal logic, which has modal
operators expressing that at least a certain ratio of the successors of a
vertex satisfies a specified property. The non-uniform expressive power of mean
GNNs is thus higher than that of GNNs with max aggregation, but lower than for
sum aggregation--the latter are characterized by modal logic and graded modal
logic, respectively. In the uniform setting, we show that the expressive power
relative to MSO is exactly that of alternation-free modal logic, under the
natural assumptions that combination functions are continuous and
classification functions are thresholds. This implies that, relative to MSO and
in the uniform setting, mean GNNs are strictly less expressive than sum GNNs
and max GNNs. When any of the assumptions is dropped, the expressive power
increases.

</details>


### [12] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
*Mutian Yang,Jiandong Gao,Ji Wu*

Main category: cs.AI

TL;DR: 该论文提出了认知归因框架以理解LLMs中知识和推理的贡献。实验结果显示推理调整对不同领域有影响，参数缩放可以改善知识和推理，知识主要存在于网络较低层，而推理则存在于更高层。


<details>
  <summary>Details</summary>
Motivation: 基于双系统认知理论，作者提出了认知归因框架，以帮助理解并区分LLMs中知识和推理的贡献。该研究动机在于提高模型分析、可解释性和发展过程中对LLMs能力的认识。

Method: 文章提出了认知归因框架，通过在两种认知模式下对LLMs进行答案生成，来量化知识和推理的贡献。将LLMs分为两个不同但互补的阶段：知识检索和推理调整。在三个数据集中使用该架构对15个LLMs进行了实验。分析表明，推理调整对领域特异性有影响，并且参数缩放可以改善知识和推理。

Result: 实验结果显示推理调整对领域特异性有影响，参数缩放改善了知识和推理，知识主要存在于网络较低层，推理则存在于更高层。

Conclusion: 该论文提出了一个认知归因框架，通过分离知识和推理的贡献，可以更好地理解大型语言模型（LLMs）的工作机制。研究结果显示推理调整对领域特异性有影响，对推理密集型领域有益，但可能对知识密集型领域有害。参数缩放对知识和推理都有改进，其中知识的改进更为显著。知识主要存在于网络较低层，而推理则位于更高层。这一框架不仅从“分解”的角度有助于理解LLMs，还为现有研究提供了新的见解。

Abstract: While large language models (LLMs) leverage both knowledge and reasoning
during inference, the capacity to distinguish between them plays a pivotal role
in model analysis, interpretability, and development. Inspired by dual-system
cognitive theory, we propose a cognition attribution framework to decouple the
contribution of knowledge and reasoning. In particular, the cognition of LLMs
is decomposed into two distinct yet complementary phases: knowledge retrieval
(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs
are prompted to generate answers under two different cognitive modes, fast
thinking and slow thinking, respectively. The performance under different
cognitive modes is analyzed to quantify the contribution of knowledge and
reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results
reveal: (1) reasoning adjustment is domain-specific, benefiting
reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and
potentially imparing knowledge-intensive domains. (2) Parameter scaling
improves both knowledge and reasoning, with knowledge improvements being more
pronounced. Additionally, parameter scaling make LLMs reasoning significantly
more prudent, while moderately more intelligent. (3) Knowledge primarily
resides in lower network layers, while reasoning operates in higher layers. Our
framework not only helps understand LLMs from a "decoupling" perspective, but
also provides new insights into existing research, including scaling laws,
hierarchical knowledge editing, and limitations of small-model reasoning.

</details>


### [13] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
*Felicidad Aguado,Pedro Cabalar,Brais Muñiz,Gilberto Pérez,Concepción Vidal*

Main category: cs.AI

TL;DR: 本文比较了ASP中四种析取的语义方法，发现三种方法提供了一个通用的方法，能够覆盖稳定模型，并比第四种方法更强大。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探讨ASP中不遵循模型最小原则的不同析取语义，以及它们与稳定模型之间的关系。

Method: 本文比较了Cabalar和Muñiz的合理模型和Doherty与Szalas的强力支持模型等四种非最小模型的析取方法。其中，Forks、合理模型和对DI语义的合理放宽在不同定义下实际上是一种通用方法。

Result: 研究发现Forks、合理模型和一种合理松弛的DI语义在某种程度上是相同的方法，能够提供稳定模型的超集。同时，它们比强力支持模型方法更强大。

Conclusion: 本文比较了四种不遵循模型最小原则的逻辑编程（ASP）中析取的语义，发现其中三种方法实际上是一种通用的方法，提供了一个稳定模型的超集，比另一种方法更强大。

Abstract: In this paper, we compare four different semantics for disjunction in Answer
Set Programming that, unlike stable models, do not adhere to the principle of
model minimality. Two of these approaches, Cabalar and Mu\~niz' \emph{Justified
Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly
provide an alternative non-minimal semantics for disjunction. The other two,
Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference}
(DI) semantics, actually introduce a new disjunction connective, but are
compared here as if they constituted new semantics for the standard disjunction
operator. We are able to prove that three of these approaches (Forks, Justified
Models and a reasonable relaxation of the DI semantics) actually coincide,
constituting a common single approach under different definitions. Moreover,
this common semantics always provides a superset of the stable models of a
program (in fact, modulo any context) and is strictly stronger than the fourth
approach (Strongly Supported Models), that actually treats disjunctions as in
classical logic.

</details>


### [14] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
*Antonino Rotolo,Beatrice Ferrigno,Jose Miguel Angel Garcia Godinez,Claudio Novelli,Giovanni Sartor*

Main category: cs.AI

TL;DR: 本章引入了一个概念性框架，用于定性评估人工智能的风险，特别是在欧盟人工智能法案的背景下，强调了概念均衡和可废除推理等方法的重要性。研究结果表明通过这种整合方法取得了重要进展，为人工智能风险评估提供了哲学基础，强调了未来工作的发展方向。


<details>
  <summary>Details</summary>
Motivation: 本章旨在引入一个概念性框架，用于解决人工智能风险评估中的法律合规性和基本权利保护的复杂性。作者强调了分析人工智能部署场景和识别潜在风险对基本权利影响的重要性。该研究的动机在于为人工智能风险分析提供哲学基础，从而支持负责任的人工智能治理。

Method: 该研究采用整合概念均衡和可废除推理的方法来处理人工智能风险评估。作者强调了对人工智能部署场景的分析以及识别潜在法律违规行为和基本权利的多层影响的重要性。通过在哲学上建立人工智能风险分析的逻辑依据，作者考虑了人工智能部署场景与基本权利之间互动的基本构建模块，并将概念均衡和有关权利情境性提升或降级的论证纳入可废除推理。作者计划未来发展一个形式化模型和有效算法，以支持负责任的人工智能治理。

Result: 研究结果表明，通过整合概念均衡和可废除推理，作者在人工智能风险评估领域取得了重要进展。他们为人工智能风险评估提供了哲学基础，考虑了人工智能部署场景与基本权利之间互动的基本构建模块，同时强调未来工作计划发展形式化模型和算法以进一步支持负责任的人工智能治理。

Conclusion: 该章节引入了一个概念性框架，用于定性评估人工智能的风险，特别是在欧盟人工智能法案的背景下。该框架通过整合概念均衡和可废除推理来应对法律合规性和基本权利保护的复杂性。概念均衡利用比例分析来解决竞争权利之间的冲突，而可废除推理则适应法律决策的动态性质。作者强调了对人工智能部署场景的分析的必要性，以及识别潜在法律违规行为和对基本权利的多层影响。基于这一分析，作者为人工智能风险分析提供了哲学基础，特别是考虑了概念上把握人工智能部署场景与基本权利之间互动的基本构建模块，将概念均衡和关于权利情境性提升或降级的论证纳入可废除推理。这种分层方法允许更具操作性的评估高风险人工智能系统和通用人工智能（GPAI）系统，强调了后者的更广泛适用性。未来工作旨在发展一个形式化模型和有效算法，以增强人工智能风险评估，将理论见解与实际应用相结合，支持负责任的人工智能治理。

Abstract: This chapter introduces a conceptual framework for qualitative risk
assessment of AI, particularly in the context of the EU AI Act. The framework
addresses the complexities of legal compliance and fundamental rights
protection by itegrating definitional balancing and defeasible reasoning.
Definitional balancing employs proportionality analysis to resolve conflicts
between competing rights, while defeasible reasoning accommodates the dynamic
nature of legal decision-making. Our approach stresses the need for an analysis
of AI deployment scenarios and for identifying potential legal violations and
multi-layered impacts on fundamental rights. On the basis of this analysis, we
provide philosophical foundations for a logical account of AI risk analysis. In
particular, we consider the basic building blocks for conceptually grasping the
interaction between AI deployment scenarios and fundamental rights,
incorporating in defeasible reasoning definitional balancing and arguments
about the contextual promotion or demotion of rights. This layered approach
allows for more operative models of assessment of both high-risk AI systems and
General Purpose AI (GPAI) systems, emphasizing the broader applicability of the
latter. Future work aims to develop a formal model and effective algorithms to
enhance AI risk assessment, bridging theoretical insights with practical
applications to support responsible AI governance.

</details>


### [15] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
*Peter Baumgartner,Lachlan McGinness*

Main category: cs.AI

TL;DR: 研究提出了一种结合多种技术的自动评分物理考试方法，包括使用计算机代数系统、SMT求解器和术语重写系统。通过大型语言模型对学生答案进行纠错和重写，然后应用自动推理技术评估答案正确性。系统在澳大利亚物理奥林匹克竞赛的真实考试数据上取得了良好表现。


<details>
  <summary>Details</summary>
Motivation: 解决物理考试自动评分问题是一项具有挑战性的任务，研究针对此问题提出了一种结合多种技术的方法。提高评分的准确性和效率，使评分更具客观性和可靠性。

Method: 使用计算机代数系统，SMT求解器和术语重写系统结合处理评分问题；引入大型语言模型解释和修正学生答案中的错误，并重新编写为机器可读格式；应用自动推理技术评估学生解决方案的正确性；考虑了两种自动定理证明方法：SMT求解和针对物理问题的术语重写系统；描述了术语重写系统的开发过程以及终止和可互换性属性。

Result: 在真实的物理考试答案数据集上对系统进行了评估，展示了系统在处理物理学问题中的潜力。

Conclusion: 研究提出了一种自动评分物理考试的方法。使用计算机代数系统，SMT求解器和术语重写系统结合的方式处理评分问题。引入大型语言模型来解释和纠正学生答案中的错误，并以机器可读格式重新编写。通过自动推理技术对学生解决方案的正确性进行评估。考虑了两种自动定理证明方法：现成的SMT求解和针对涉及三角函数表达式的物理问题定制的术语重写系统。在论文中详细描述了术语重写系统的开发过程以及终止和可互换性属性。在2023年澳大利亚物理奥林匹克竞赛的1500多份真实学生考试答案上对系统进行了评估。

Abstract: We present our method for automatically marking Physics exams. The marking
problem consists in assessing typed student answers for correctness with
respect to a ground truth solution. This is a challenging problem that we seek
to tackle using a combination of a computer algebra system, an SMT solver and a
term rewriting system. A Large Language Model is used to interpret and remove
errors from student responses and rewrite these in a machine readable format.
Once formalized and language-aligned, the next step then consists in applying
automated reasoning techniques for assessing student solution correctness. We
consider two methods of automated theorem proving: off-the-shelf SMT solving
and term rewriting systems tailored for physics problems involving
trigonometric expressions. The development of the term rewrite system and
establishing termination and confluence properties was not trivial, and we
describe it in some detail in the paper. We evaluate our system on a rich pool
of over 1500 real-world student exam responses from the 2023 Australian Physics
Olympiad.

</details>


### [16] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
*Zhuang Qiang Bok,Watson Wei Khong Chua*

Main category: cs.AI

TL;DR: ConDiFi is a benchmark assessing divergent and convergent thinking in LLMs for financial tasks. Models like DeepSeek-R1 and Cohere Command R+ excel, while GPT-4o lags in Novelty and Actionability. ConDiFi provides a new perspective for evaluating reasoning capabilities in finance.


<details>
  <summary>Details</summary>
Motivation: Current reasoning benchmarks for LLMs focus on factual accuracy or step-by-step logic, neglecting the need for creative and plausible future generation in finance. Professionals in finance require both optimal decisions and creativity under uncertainty.

Method: Introducing ConDiFi benchmark with 607 macro-financial prompts for divergent reasoning and 990 multi-hop adversarial MCQs for convergent reasoning. Evaluation of 14 models using the benchmark to uncover performance variations.

Result: Evaluation of leading models using ConDiFi benchmark reveals differences in performance. Models like DeepSeek-R1 and Cohere Command R+ outperform GPT-4o in generating actionable insights. ConDiFi offers a new perspective to assess reasoning capabilities in the deployment of LLMs in finance.

Conclusion: ConDiFi introduces a benchmark that evaluates divergent and convergent thinking in LLMs for financial tasks, revealing differences in model performance. Models like DeepSeek-R1 and Cohere Command R+ excel in generating actionable insights for investment decisions, while GPT-4o lags behind in Novelty and Actionability.

Abstract: Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step
logic. In finance, however, professionals must not only converge on optimal
decisions but also generate creative, plausible futures under uncertainty. We
introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent
thinking in LLMs for financial tasks.
  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990
multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we
evaluated 14 leading models and uncovered striking differences. Despite high
fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models
like DeepSeek-R1 and Cohere Command R+ rank among the top for generating
actionable, insights suitable for investment decisions. ConDiFi provides a new
perspective to assess reasoning capabilities essential to safe and strategic
deployment of LLMs in finance.

</details>


### [17] [Revisiting LLM Reasoning via Information Bottleneck](https://arxiv.org/abs/2507.18391)
*Shiye Lei,Zhihao Cheng,Kai Jia,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文介绍了信息瓶颈（IB）原则，提出了信息瓶颈感知推理优化（IBRO）框架，鼓励推理过程既具有信息量又具备泛化性，有效提升大型语言模型的推理性能，实验证实了IB正则化方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理指导方面往往受启发于直觉，缺乏系统的原则方法。因此，本文旨在填补这一空白，提出基于信息瓶颈原则的推理优化框架，从而加强大型语言模型的推理能力。

Method: 本文基于信息瓶颈原则，提出了IB-aware reasoning optimization（IBRO）框架，引入了轻量级的IB正则化方法，通过引导LLMs生成具有信息量且泛化性强的推理轨迹，从而有效改进推理性能。

Result: 实验证实了IB正则化方法在多个数学推理基准和RL算法上的有效性，取得了一致的LLM推理性能改进。

Conclusion: 本文提出了信息瓶颈优化（IBRO）框架，通过理论特征化大型语言模型的推理过程，鼓励推理轨迹既对最终正确答案具有信息量，又能够泛化到多样的提示。实验证实了IB正则化在多个数学推理基准和RL算法上的有效性，证明在LLM推理性能方面取得了一致改进。

Abstract: Large language models (LLMs) have recently demonstrated remarkable progress
in reasoning capabilities through reinforcement learning with verifiable
rewards (RLVR). By leveraging simple rule-based rewards, RL effectively
incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning
trajectories, progressively guiding them toward correct answers. However,
existing approaches remain largely heuristic and intuition-driven, limiting the
development of principled methodologies. In this paper, we present a
theoretical characterization of LLM reasoning grounded in information
bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO),
a framework that encourages reasoning trajectories to be both informative about
the final correct answer and generalizable across diverse prompts. We derive a
practical token-level surrogate objective and propose an efficient
approximation, resulting in the lightweight IB regularization method. This
technique integrates seamlessly into existing RL-based post-training frameworks
without additional computational overhead, requiring only a one-line code
modification. Empirically, we validate IB regularization across multiple
mathematical reasoning benchmarks and RL algorithms, demonstrating consistent
improvements in LLM reasoning performance.

</details>


### [18] [Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation](https://arxiv.org/abs/2507.18398)
*Kwong Ho Li,Wathsala Karunarathne*

Main category: cs.AI

TL;DR: 本文研究了深度强化学习在呼叫中心中优化呼叫路由的应用。通过比较值迭代和PPO方法，发现PPO方法在减少客户等待时间和员工空闲时间方面表现最佳，尽管需要更长的训练时间。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过深度强化学习优化呼叫中心的呼叫路由，以减少客户等待时间和员工空闲时间。

Method: 比较了基于值迭代和基于PPO的两种优化呼叫路由的方法，使用了理论模型和仿真模型进行评估。

Result: PPO方法在1000个测试集中 consistently 获得最高奖励，并且在客户等待时间和员工空闲时间方面表现出色。

Conclusion: 深度强化学习在呼叫中心中应用的效果良好，PPO方法在最小化客户等待时间和员工空闲时间方面表现最佳。

Abstract: This paper investigates the application of Reinforcement Learning (RL) to
optimise call routing in call centres to minimise client waiting time and staff
idle time. Two methods are compared: a model-based approach using Value
Iteration (VI) under known system dynamics, and a model-free approach using
Proximal Policy Optimisation (PPO) that learns from experience. For the
model-based approach, a theoretical model is used, while a simulation model
combining Discrete Event Simulation (DES) with the OpenAI Gym environment is
developed for model-free learning. Both models frame the problem as a Markov
Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with
Poisson client arrivals and exponentially distributed service and abandonment
times. For policy evaluation, random, VI, and PPO policies are evaluated using
the simulation model. After 1,000 test episodes, PPO consistently achives the
highest rewards, along with the lowest client waiting time and staff idle time,
despite requiring longer training time.

</details>


### [19] [GPU Accelerated Compact-Table Propagation](https://arxiv.org/abs/2507.18413)
*Enrico Santi,Fabio Tardivo,Agostino Dovier,Andrea Formisano*

Main category: cs.AI

TL;DR: 本文介绍了如何利用现代GPU的计算能力增强Compact-Table（CT）算法，用于处理大型表约束。实验验证表明，在现有约束求解器中集成GPU加速的CT算法是可行的。


<details>
  <summary>Details</summary>
Motivation: 现有用于处理大表约束的标准CPU方法在处理数百或数千个有效情况时效果不佳，本文旨在利用现代GPU的计算能力增强Table约束处理方法。

Method: 通过利用现代GPU的计算能力增强Compact-Table（CT）算法，以处理大型表约束。描述了GPU加速的CT算法的设计和实施，以及集成到现有约束求解器中，并进行了一组重要实例的实验验证。

Result: 通过利用现代GPU的计算能力，成功增强了Compact-Table（CT）算法，可以处理大型表约束，并且在实验中得到了验证。

Conclusion: 本文关注特定形式的约束，即所谓的表约束，介绍了如何利用现代GPU的计算能力增强Compact-Table（CT）算法，以处理大型表约束。实验验证表明，在现有约束求解器中集成GPU加速的CT算法是可行的。

Abstract: Constraint Programming developed within Logic Programming in the Eighties;
nowadays all Prolog systems encompass modules capable of handling constraint
programming on finite domains demanding their solution to a constraint solver.
This work focuses on a specific form of constraint, the so-called table
constraint, used to specify conditions on the values of variables as an
enumeration of alternative options. Since every condition on a set of finite
domain variables can be ultimately expressed as a finite set of cases, Table
can, in principle, simulate any other constraint. These characteristics make
Table one of the most studied constraints ever, leading to a series of
increasingly efficient propagation algorithms. Despite this, it is not uncommon
to encounter real-world problems with hundreds or thousands of valid cases that
are simply too many to be handled effectively with standard CPU-based
approaches. In this paper, we deal with the Compact-Table (CT) algorithm, the
state-of-the-art propagation algorithms for Table. We describe how CT can be
enhanced by exploiting the massive computational power offered by modern GPUs
to handle large Table constraints. In particular, we report on the design and
implementation of GPU-accelerated CT, on its integration into an existing
constraint solver, and on an experimental validation performed on a significant
set of instances.

</details>


### [20] [On the Performance of Concept Probing: The Influence of the Data (Extended Version)](https://arxiv.org/abs/2507.18550)
*Manuel de Sousa Ribeiro,Afonso Leote,João Leite*

Main category: cs.AI

TL;DR: 本文关注概念探查在图像分类任务中的应用，研究了训练探查模型所需数据对性能的影响，并提供了两个数据集的概念标签。


<details>
  <summary>Details</summary>
Motivation: 概念探查作为一种帮助解释人工神经网络的方式，因其通常庞大的规模和符号下的特性而备受关注，这使得直接解释变得不可行。先前的研究主要聚焦于被探查的模型或探查模型本身，而忽略了训练这些探查模型所需的数据方面。本文旨在填补这一研究空白。

Method: 通过训练额外的分类器将模型的内部表示映射到人类定义的感兴趣的概念，从而使人类能够窥视人工神经网络的内部。

Result: 研究调查了用于训练探查模型的数据对其性能的影响，同时提供了两个常用数据集的概念标签。

Conclusion: 研究主要集中在被探查的模型或探查模型本身，而对用于训练此类探查模型所需的数据关注较少。本文针对这一问题进行了研究，重点关注图像分类任务中的概念探查，探讨用于训练探查模型的数据对性能的影响，并为两个常用数据集提供概念标签。

Abstract: Concept probing has recently garnered increasing interest as a way to help
interpret artificial neural networks, dealing both with their typically large
size and their subsymbolic nature, which ultimately renders them unfeasible for
direct human interpretation. Concept probing works by training additional
classifiers to map the internal representations of a model into human-defined
concepts of interest, thus allowing humans to peek inside artificial neural
networks. Research on concept probing has mainly focused on the model being
probed or the probing model itself, paying limited attention to the data
required to train such probing models. In this paper, we address this gap.
Focusing on concept probing in the context of image classification tasks, we
investigate the effect of the data used to train probing models on their
performance. We also make available concept labels for two widely used
datasets.

</details>


### [21] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
*Shanghai AI Lab,:,Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu,Chao Yang,Yue Yang,Yang Yao,Yulei Ye,Zhenyun Yin,Yi Yu,Bo Zhang,Qiaosheng Zhang,Jinxuan Zhang,Yexin Zhang,Yinqiang Zheng,Hefeng Zhou,Zhanhui Zhou,Pengyu Zhu,Qingzi Zhu,Yubo Zhu,Bowen Zhou*

Main category: cs.AI

TL;DR: SafeWork-R1, developed using the SafeLadder framework, shows significant safety improvements and outperforms its base model. It achieves state-of-the-art safety performance compared to leading models. The paper introduces additional models highlighting the generalizability of their framework.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations of previous alignment methods by introducing a framework that focuses on safety and capabilities co-evolution. The goal is to develop AI models that are not only high-performing but also safe and reliable.

Method: The paper introduces the SafeLadder framework which incorporates large-scale, safety-oriented reinforcement learning post-training and multi-principled verifiers. It enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, leading to safety improvements. Two distinct inference-time intervention methods and a deliberative search mechanism are implemented to enhance reliability and enforce step-level verification.

Result: SafeWork-R1 demonstrates an average improvement of 46.54% over its base model on safety-related benchmarks without compromising general capabilities. It outperforms leading proprietary models such as GPT-4.1 and Claude Opus 4 in terms of safety performance. Additional models developed under the framework further emphasize the synergy between safety and capability.

Conclusion: SafeWork-R1 is a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It outperforms its base model and achieves state-of-the-art safety performance compared to leading proprietary models. The paper also introduces additional models that highlight the generalizability of their framework.

Abstract: We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that
demonstrates the coevolution of capabilities and safety. It is developed by our
proposed SafeLadder framework, which incorporates large-scale, progressive,
safety-oriented reinforcement learning post-training, supported by a suite of
multi-principled verifiers. Unlike previous alignment methods such as RLHF that
simply learn human preferences, SafeLadder enables SafeWork-R1 to develop
intrinsic safety reasoning and self-reflection abilities, giving rise to safety
`aha' moments. Notably, SafeWork-R1 achieves an average improvement of
$46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks
without compromising general capabilities, and delivers state-of-the-art safety
performance compared to leading proprietary models such as GPT-4.1 and Claude
Opus 4. To further bolster its reliability, we implement two distinct
inference-time intervention methods and a deliberative search mechanism,
enforcing step-level verification. Finally, we further develop
SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and
SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and
capability can co-evolve synergistically, highlighting the generalizability of
our framework in building robust, reliable, and trustworthy general-purpose AI.

</details>
