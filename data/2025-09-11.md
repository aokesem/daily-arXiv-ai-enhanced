<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Learning-Based Planning for Improving Science Return of Earth Observation Satellites](https://arxiv.org/abs/2509.07997)
*Abigail Breitfeld,Alberto Candela,Juan Delfa,Akseli Kangaslahti,Itai Zilberstein,Steve Chien,David Wettergreen*

Main category: cs.AI

TL;DR: 本文介绍了卫星观测卫星中动态定位的重要性，并提出了基于学习的两种动态定位方法：强化学习和模仿学习。研究发现，这些学习方法相较于传统启发式方法表现更好，平均性能提升分别达到10.0％和13.7％。同时，这些学习方法仅需相对少量数据就可进行有效训练。


<details>
  <summary>Details</summary>
Motivation: 卫星观测卫星是收集地球科学信息的强大工具，但也存在一些局限性，如不能轻易偏离轨道轨迹，传感器视野有限，操作传感器需要消耗大量卫星资源。为了优化卫星收集的数据，只包括最重要或最具信息量的测量是至关重要的。因此，动态定位这一新兴概念应运而生。

Method: 本研究展示了两种不同的基于学习的动态定位方法，分别使用强化学习和模仿学习。这些学习方法建立在动态规划解决方案的基础上，用于规划一系列采样位置。通过评估这些方法与现有启发式方法的对比，展示了学习在该应用中的优势。

Result: 动态定位通过学习方法表现出比传统启发式方法更好的性能，模仿学习和强化学习分别表现出10.0％和13.7％的平均性能提升。同时，这两种学习方法在相对较少的数据下也能被有效训练。

Conclusion: 动态定位是一种新兴的概念，利用卫星资源和前瞻仪器的数据智能重新配置和定位主要仪器，提高了收集科学信息的效率。本研究提出了基于强化学习和模仿学习的两种动态定位学习方法，与现有的启发式方法相比，学习方法表现出更好的性能。模仿学习平均比最佳启发式方法表现好10.0％，而强化学习平均比启发式方法表现好13.7％。此外，研究表明，这两种学习方法在相对较少的数据量下也可以有效训练。

Abstract: Earth observing satellites are powerful tools for collecting scientific
information about our planet, however they have limitations: they cannot easily
deviate from their orbital trajectories, their sensors have a limited field of
view, and pointing and operating these sensors can take a large amount of the
spacecraft's resources. It is important for these satellites to optimize the
data they collect and include only the most important or informative
measurements. Dynamic targeting is an emerging concept in which satellite
resources and data from a lookahead instrument are used to intelligently
reconfigure and point a primary instrument. Simulation studies have shown that
dynamic targeting increases the amount of scientific information gathered
versus conventional sampling strategies. In this work, we present two different
learning-based approaches to dynamic targeting, using reinforcement and
imitation learning, respectively. These learning methods build on a dynamic
programming solution to plan a sequence of sampling locations. We evaluate our
approaches against existing heuristic methods for dynamic targeting, showing
the benefits of using learning for this application. Imitation learning
performs on average 10.0\% better than the best heuristic method, while
reinforcement learning performs on average 13.7\% better. We also show that
both learning methods can be trained effectively with relatively small amounts
of data.

</details>


### [2] [EnvX: Agentize Everything with Agentic AI](https://arxiv.org/abs/2509.08088)
*Linyao Chen,Zimian Peng,Yingxuan Yang,Yikun Wang,Wenzheng Tom Tang,Hiroki H. Kobayashi,Weinan Zhang*

Main category: cs.AI

TL;DR: EnvX is a framework that transforms GitHub repositories into intelligent agents using Agentic AI. It automates the process of understanding, initializing, and operationalizing repository functionality, achieving high execution completion and task pass rates. EnvX outperforms existing frameworks and enables multi-repository collaboration, fostering accessibility and collaboration in the open-source ecosystem.


<details>
  <summary>Details</summary>
Motivation: The motivation behind EnvX is to address the manual, error-prone, and disconnected nature of utilizing reusable software components from open-source repositories. Developers face barriers such as navigating documentation, understanding APIs, and writing integration code. EnvX aims to automate these processes and enhance software reuse efficiency.

Method: EnvX utilizes a three-phase process including TODO-guided environment initialization, human-aligned agentic automation, and Agent-to-Agent (A2A) protocol to agentize GitHub repositories. It combines large language model capabilities with structured tool integration to automate code generation and the entire process of understanding, initializing, and operationalizing repository functionality.

Result: EnvX achieves a 74.07% execution completion rate and 51.85% task pass rate on the GitTaskBench benchmark using 18 repositories from various domains. It demonstrates superior performance compared to existing frameworks and enables multi-repository collaboration through the A2A protocol.

Conclusion: EnvX is a framework that leverages Agentic AI to transform GitHub repositories into intelligent agents capable of natural language interaction and inter-agent collaboration, achieving a high execution completion rate and task pass rate, outperforming existing frameworks. It marks a shift towards treating repositories as active agents, fostering greater accessibility and collaboration in the open-source ecosystem.

Abstract: The widespread availability of open-source repositories has led to a vast
collection of reusable software components, yet their utilization remains
manual, error-prone, and disconnected. Developers must navigate documentation,
understand APIs, and write integration code, creating significant barriers to
efficient software reuse. To address this, we present EnvX, a framework that
leverages Agentic AI to agentize GitHub repositories, transforming them into
intelligent, autonomous agents capable of natural language interaction and
inter-agent collaboration. Unlike existing approaches that treat repositories
as static code resources, EnvX reimagines them as active agents through a
three-phase process: (1) TODO-guided environment initialization, which sets up
the necessary dependencies, data, and validation datasets; (2) human-aligned
agentic automation, allowing repository-specific agents to autonomously perform
real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple
agents to collaborate. By combining large language model capabilities with
structured tool integration, EnvX automates not just code generation, but the
entire process of understanding, initializing, and operationalizing repository
functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18
repositories across domains such as image processing, speech recognition,
document analysis, and video manipulation. Our results show that EnvX achieves
a 74.07% execution completion rate and 51.85% task pass rate, outperforming
existing frameworks. Case studies further demonstrate EnvX's ability to enable
multi-repository collaboration via the A2A protocol. This work marks a shift
from treating repositories as passive code resources to intelligent,
interactive agents, fostering greater accessibility and collaboration within
the open-source ecosystem.

</details>


### [3] [Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI](https://arxiv.org/abs/2509.08151)
*Botao Zhu,Jeslyn Wang,Dusit Niyato,Xianbin Wang*

Main category: cs.AI

TL;DR: 为了有效执行复杂的计算任务，提出了2TSD模型，通过师生代理架构实现快速准确的协作者选择，取得了积极的实验结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决采集协作者信任数据、繁琐的评估过程和动态情况变化导致的开销和信任评估降低的挑战。

Method: 建立了师生代理架构，通过在服务器上部署教师代理和设备端学生代理，教师代理负责信任数据收集、信任语义提取和协作者匹配分析，学生代理接收潜在合作者的信任语义以实现快速准确的选择。

Result: 实验结果表明，2TSD模型在减少评估时间、减少设备资源消耗和提高协作者选择准确性方面取得了积极效果。

Conclusion: 提出了一种基于大型AI模型驱动的师生代理架构的任务特定信任语义提炼（2TSD）模型，可以减少协作者评估时间，减少设备资源消耗并提高协作者选择的准确性。

Abstract: Accurate trustworthiness evaluation of potential collaborating devices is
essential for the effective execution of complex computing tasks. This
evaluation process involves collecting diverse trust-related data from
potential collaborators, including historical performance and available
resources, for collaborator selection. However, when each task owner
independently assesses all collaborators' trustworthiness, frequent data
exchange, complex reasoning, and dynamic situation changes can result in
significant overhead and deteriorated trust evaluation. To overcome these
challenges, we propose a task-specific trust semantics distillation (2TSD)
model based on a large AI model (LAM)-driven teacher-student agent
architecture. The teacher agent is deployed on a server with powerful
computational capabilities and an augmented memory module dedicated to
multidimensional trust-related data collection, task-specific trust semantics
extraction, and task-collaborator matching analysis. Upon receiving
task-specific requests from device-side student agents, the teacher agent
transfers the trust semantics of potential collaborators to the student agents,
enabling rapid and accurate collaborator selection. Experimental results
demonstrate that the proposed 2TSD model can reduce collaborator evaluation
time, decrease device resource consumption, and improve the accuracy of
collaborator selection.

</details>


### [4] [Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following](https://arxiv.org/abs/2509.08222)
*Minjong Yoo,Jinwoo Jang,Wei-jin Park,Honguk Woo*

Main category: cs.AI

TL;DR: 研究提出了ExRAP框架，用于解决连续指示任务中的挑战。通过在环境背景记忆中进行查询和任务执行，在多个任务上引入探索整合的方案，改进了任务性能。实验结果显示该方法在体验指示跟随场景中表现优异，胜过其他LLM-based任务规划方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提高大型语言模型（LLMs）在动态、非静态环境中的体验推理能力，解决连续指示任务规划的挑战。通过为多个任务引入探索整合的任务规划方案，以及改进的查询评估方案，旨在提高任务性能和处理效率。

Method: 探索检索增强规划（ExRAP）框架通过在环境背景记忆中进行查询和基于查询结果进行任务执行，解决了连续指示任务中的挑战。为了高效处理多个连续任务，研究采用了探索整合的任务规划方案，并将信息探索融入到基于LLM的规划过程中。同时，结合记忆增强的查询评估和时间一致性改进方案，提高了整体任务性能。实验结果表明，该方法在多种体验指示跟随场景中表现出色，优于其他LLM-based任务规划方法。

Result: 该研究的结果表明，ExRAP框架在各种体验指示跟随场景中表现出鲁棒性，并在目标成功率和执行效率方面优于其他最新的LLM-based任务规划方法。研究还提出了探索整合的任务规划方案和时间一致性改进方案，有效平衡了环境背景记忆的有效性和环境探索负担，提高了整体任务性能。

Conclusion: 该研究提出了一种探索检索增强规划（ExRAP）框架，旨在解决动态、非静态环境中具有连续指示的体验代理的任务。该框架通过有效探索物理环境并建立环境背景记忆，增强了大型语言模型（LLMs）的体验推理能力，从而有效地使任务规划过程落实在时变环境背景中。通过在环境背景记忆上进行查询和基于查询结果进行任务执行，ExRAP将多个连续指示的任务分解为查询，以便有效处理这些连续同时执行的多个任务。为了高效处理这些多个任务，该研究实现了一种探索整合的任务规划方案，将信息探索融入基于LLM的规划过程中。结合记忆增强的查询评估，这一整合方案不仅可以更好地平衡环境背景记忆的有效性和环境探索负担，还可以提高整体任务性能。此外，研究设计了一种用于查询评估的时间一致性改进方案，以解决记忆中知识固有的衰减问题。通过与VirtualHome、ALFRED和CARLA的实验，该方法展现出对抗涉及不同指示规模和类型以及非静态程度的各种体验指示跟随场景的鲁棒性，并在目标成功率和执行效率方面始终优于其他最新的以LLM为基础的任务规划方法。

Abstract: This study presents an Exploratory Retrieval-Augmented Planning (ExRAP)
framework, designed to tackle continual instruction following tasks of embodied
agents in dynamic, non-stationary environments. The framework enhances Large
Language Models' (LLMs) embodied reasoning capabilities by efficiently
exploring the physical environment and establishing the environmental context
memory, thereby effectively grounding the task planning process in time-varying
environment contexts. In ExRAP, given multiple continual instruction following
tasks, each instruction is decomposed into queries on the environmental context
memory and task executions conditioned on the query results. To efficiently
handle these multiple tasks that are performed continuously and simultaneously,
we implement an exploration-integrated task planning scheme by incorporating
the {information-based exploration} into the LLM-based planning process.
Combined with memory-augmented query evaluation, this integrated scheme not
only allows for a better balance between the validity of the environmental
context memory and the load of environment exploration, but also improves
overall task performance. Furthermore, we devise a {temporal consistency
refinement} scheme for query evaluation to address the inherent decay of
knowledge in the memory. Through experiments with VirtualHome, ALFRED, and
CARLA, our approach demonstrates robustness against a variety of embodied
instruction following scenarios involving different instruction scales and
types, and non-stationarity degrees, and it consistently outperforms other
state-of-the-art LLM-based task planning approaches in terms of both goal
success rate and execution efficiency.

</details>


### [5] [Real-world Music Plagiarism Detection With Music Segment Transcription System](https://arxiv.org/abs/2509.08282)
*Seonghyeon Go*

Main category: cs.AI

TL;DR: 本文提出了一种结合各种音乐信息检索技术的音乐抄袭检测系统，取得了有前途的结果，并收集了一个用于音乐相似性研究的数据集。


<details>
  <summary>Details</summary>
Motivation: 随着音乐信息检索技术不断发展，音乐生成和分发变得更加多样和便捷，对音乐知识产权保护的兴趣逐渐增加。

Method: 结合多种音乐信息检索技术，开发了音乐片段转录系统，从音频录音中提取有音乐意义的片段，以检测不同音乐格式的抄袭情况。通过计算基于多种音乐特征的相似性得分，并通过全面的音乐分析进行评估。

Result: 该方法在音乐抄袭检测实验中取得了有前途的结果，同时提出的方法可以在真实世界的音乐场景中应用。

Conclusion: 本文提出了一种结合各种音乐信息检索(MIR)技术的音乐抄袭检测系统，取得了有前途的结果。该方法可应用于现实音乐场景，并收集了一个用于音乐相似性研究的数据集。

Abstract: As a result of continuous advances in Music Information Retrieval (MIR)
technology, generating and distributing music has become more diverse and
accessible. In this context, interest in music intellectual property protection
is increasing to safeguard individual music copyrights. In this work, we
propose a system for detecting music plagiarism by combining various MIR
technologies. We developed a music segment transcription system that extracts
musically meaningful segments from audio recordings to detect plagiarism across
different musical formats. With this system, we compute similarity scores based
on multiple musical features that can be evaluated through comprehensive
musical analysis. Our approach demonstrated promising results in music
plagiarism detection experiments, and the proposed method can be applied to
real-world music scenarios. We also collected a Similar Music Pair (SMP)
dataset for musical similarity research using real-world cases. The dataset are
publicly available.

</details>


### [6] [Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies](https://arxiv.org/abs/2509.08312)
*Binghan Wu,Shoufeng Wang,Yunxin Liu,Ya-Qin Zhang,Joseph Sifakis,Ye Ouyang*

Main category: cs.AI

TL;DR: 该论文实现了AN Agent参考架构，在5G NR子6 GHz频段内展示了次秒级实时控制，比OLLA算法获得了更高的下行吞吐量，并通过MCS优化降低了超可靠服务的BLER，证实了该框架的潜力。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是传统自主性障碍的克服，推动关键的L4启用功能的发展，以实现自配置、自愈合和自优化系统，提供零等待、零触摸和零故障服务。

Method: 通过在功能性认知系统中实施AN Agent参考架构，使用混合知识表示驱动协调的主动-反应式运行时，完成对传统架构理论和操作实践之间的桥梁作用。

Result: 在5G NR的子6 GHz频段内表现出次秒级实时控制，比外环链路自适应（OLLA）算法获得了更高的下行吞吐量，并通过动态调制和编码方案（MCS）优化，将超可靠服务的块错误率（BLER）降低了67%。

Conclusion: 该论文确认了实现Joseph Sifakis的AN Agent参考架构的潜力，通过对射频接入网络（RAN）链路自适应（LA）代理的实证案例研究，证实了这一框架的转型潜力。

Abstract: The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a
strategic inflection point in telecommunications, where networks must transcend
reactive automation to achieve genuine cognitive capabilities--fulfilling TM
Forum's vision of self-configuring, self-healing, and self-optimizing systems
that deliver zero-wait, zero-touch, and zero-fault services. This work bridges
the gap between architectural theory and operational reality by implementing
Joseph Sifakis's AN Agent reference architecture in a functional cognitive
system, deploying coordinated proactive-reactive runtimes driven by hybrid
knowledge representation. Through an empirical case study of a Radio Access
Network (RAN) Link Adaptation (LA) Agent, we validate this framework's
transformative potential: demonstrating sub-10 ms real-time control in 5G NR
sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link
Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for
ultra-reliable services through dynamic Modulation and Coding Scheme (MCS)
optimization. These improvements confirm the architecture's viability in
overcoming traditional autonomy barriers and advancing critical L4-enabling
capabilities toward next-generation objectives.

</details>


### [7] [Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives](https://arxiv.org/abs/2509.08380)
*Prathamesh Vasudeo Naik,Naresh Kumar Dintakurthi,Zhanghao Hu,Yue Wang,Robby Qiu*

Main category: cs.AI

TL;DR: 本文介绍了Co-Investigator AI框架，旨在提高AML工作流中SAR的效率。该框架整合了各种代理人用于规划、检测犯罪类型、收集外部情报和验证合规性。通过协作工作流，使人类调查员能与AI合作，提高合规性和业务专业知识的结合。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在合规关键领域存在风险，本文旨在解决传统方法中产生SAR的高成本低可扩展性等问题。借鉴自动代理人架构的最新进展，促使该研究的动机。

Method: 提出Co-Investigator AI框架，以优化产生SAR的效率和准确性。框架整合了专门的代理人用于规划、犯罪类型检测、外部情报收集和合规验证。采用动态存储管理、AI隐私保护层和实时验证代理人等技术。

Result: Co-Investigator AI在复杂的金融犯罪场景中展示了多样性，突出了其简化SAR起草、将叙述与监管期望保持一致以及让合规团队专注于更高阶分析工作的能力。

Conclusion: 引入Co-Investigator AI框架可显著提高产生可疑交易报告（SAR）的速度和准确性，使得AML工作流更高效。人类调查员与AI协作，在保证合规的前提下提高了业务专业知识的利用。

Abstract: Generating regulatorily compliant Suspicious Activity Report (SAR) remains a
high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows.
While large language models (LLMs) offer promising fluency, they suffer from
factual hallucination, limited crime typology alignment, and poor
explainability -- posing unacceptable risks in compliance-critical domains.
This paper introduces Co-Investigator AI, an agentic framework optimized to
produce Suspicious Activity Reports (SARs) significantly faster and with
greater accuracy than traditional methods. Drawing inspiration from recent
advances in autonomous agent architectures, such as the AI Co-Scientist, our
approach integrates specialized agents for planning, crime type detection,
external intelligence gathering, and compliance validation. The system features
dynamic memory management, an AI-Privacy Guard layer for sensitive data
handling, and a real-time validation agent employing the Agent-as-a-Judge
paradigm to ensure continuous narrative quality assurance. Human investigators
remain firmly in the loop, empowered to review and refine drafts in a
collaborative workflow that blends AI efficiency with domain expertise. We
demonstrate the versatility of Co-Investigator AI across a range of complex
financial crime scenarios, highlighting its ability to streamline SAR drafting,
align narratives with regulatory expectations, and enable compliance teams to
focus on higher-order analytical work. This approach marks the beginning of a
new era in compliance reporting -- bringing the transformative benefits of AI
agents to the core of regulatory processes and paving the way for scalable,
reliable, and transparent SAR generation.

</details>


### [8] [TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making](https://arxiv.org/abs/2509.08500)
*Kechen Jiao,Zhirui Fang,Jiahao Liu,Bei Li,Qifan Wang,Xinyu Liu,Junhao Ruan,Zhongjian Qiao,Yifan Zhu,Yaxin Xu,Jingang Wang,Xiu Li*

Main category: cs.AI

TL;DR: 本论文针对具身人工智能中视觉语言模型的决策制定挑战，提出了TCPO方法。通过实验证明，在ALFWorld环境中，TCPO方法相较于RL4VLM取得了6%的改进，成功缓解了模型退化问题，验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在具身人工智能中的应用面临挑战，现有方法存在模型退化问题和低样本效率。为了解决这些问题，需要一种能够提高决策制定效果的方法。

Method: 本文提出了Thought-Centric Preference Optimization (TCPO)方法，通过引入逐步基于偏好的优化方法，将稀疏奖励信号转换为更丰富的步骤样本对。该方法强调模型中间推理过程的对齐，缓解了模型退化问题。此外，通过整合Action Policy Consistency Constraint (APC)，进一步对模型输出施加了一致性约束。在ALFWorld环境中进行了实验，取得了一定成功，验证了该方法的有效性。

Result: 在ALFWorld环境中的实验表明，TCPO方法相比RL4VLM取得了6%的改进，并成功缓解了模型退化问题。这突显了基于偏好的学习技术和CoT过程相结合的潜力。

Conclusion: 本论文提出了Thought-Centric Preference Optimization (TCPO)来有效进行具身决策制定。在ALFWorld环境中的实验证明了该方法在细化调优后缓解了模型退化问题，平均成功率提高了6%，比RL4VLM有所改进。结果突显了将基于偏好的学习技术与CoT过程相结合，以增强具身智能体中视觉-语言模型的决策能力的潜力。

Abstract: Using effective generalization capabilities of vision language models (VLMs)
in context-specific dynamic tasks for embodied artificial intelligence remains
a significant challenge. Although supervised fine-tuned models can better align
with the real physical world, they still exhibit sluggish responses and
hallucination issues in dynamically changing environments, necessitating
further alignment. Existing post-SFT methods, reliant on reinforcement learning
and chain-of-thought (CoT) approaches, are constrained by sparse rewards and
action-only optimization, resulting in low sample efficiency, poor consistency,
and model degradation. To address these issues, this paper proposes
Thought-Centric Preference Optimization (TCPO) for effective embodied
decision-making. Specifically, TCPO introduces a stepwise preference-based
optimization approach, transforming sparse reward signals into richer step
sample pairs. It emphasizes the alignment of the model's intermediate reasoning
process, mitigating the problem of model degradation. Moreover, by
incorporating Action Policy Consistency Constraint (APC), it further imposes
consistency constraints on the model output. Experiments in the ALFWorld
environment demonstrate an average success rate of 26.67%, achieving a 6%
improvement over RL4VLM and validating the effectiveness of our approach in
mitigating model degradation after fine-tuning. These results highlight the
potential of integrating preference-based learning techniques with CoT
processes to enhance the decision-making capabilities of vision-language models
in embodied agents.

</details>


### [9] [No-Knowledge Alarms for Misaligned LLMs-as-Judges](https://arxiv.org/abs/2509.08593)
*Andrés Corrada-Emmanuel*

Main category: cs.AI

TL;DR: 本研究通过观察LLM法官之间的一致和不一致来评估其评分能力，在整数响应计数空间中应用线性规划问题开发了无知警报系统，用于检测LLM法官评分能力的违规情况。


<details>
  <summary>Details</summary>
Motivation: 对于无法确定专家决策的真实性且不愿全盲信任专家时，需要一种方法来提高对LLM法官评估不确定性的解决方案。

Method: 利用逻辑一致性和线性规划问题在整数响应计数空间中开发无知警报算法，用于检测LLM法官的评分能力是否达到用户指定需求。

Result: 开发了可以检测LLM法官评分能力是否符合用户指定需求的无知警报系统，并能准确识别出不符合要求的评分者。

Conclusion: 利用逻辑一致性评估LLM法官对其他LLM法官的决策能力，通过线性规划问题发展无知警报检测对齐的LLM法官。

Abstract: If we use LLMs as judges to evaluate the complex decisions of other LLMs, who
or what monitors the judges? Infinite monitoring chains are inevitable whenever
we do not know the ground truth of the decisions by experts and we do not want
to trust them. One way to ameliorate our evaluation uncertainty is to exploit
the use of logical consistency between disagreeing experts. By observing how
LLM judges agree and disagree while grading other LLMs, we can compute the only
possible evaluations of their grading ability. For example, if two LLM judges
disagree on which tasks a third one completed correctly, they cannot both be
100\% correct in their judgments. This logic can be formalized as a Linear
Programming problem in the space of integer response counts for any finite
test. We use it here to develop no-knowledge alarms for misaligned LLM judges.
The alarms can detect, with no false positives, that at least one member or
more of an ensemble of judges are violating a user specified grading ability
requirement.

</details>


### [10] [Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference](https://arxiv.org/abs/2509.08682)
*Guoqing Ma,Jia Zhu,Hanghui Guo,Weijie Shi,Jiawei Shen,Jingjiang Liu,Yidan Liang*

Main category: cs.AI

TL;DR: 本研究针对多智能体系统的失败归因问题，提出了基于多粒度因果推断的失败归因框架。通过性能因果反演原则和CDC-MAS算法，实现了智能体级别责任分配和关键失败步骤识别。在Who&When和TRAIL基准测试上取得显著进展，步骤级准确率提升至36.2%，任务成功率平均提升22.4%。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在复杂任务自动化中至关重要，但面临失败归因挑战。现有诊断工具无法准确定位失败根本原因，本研究旨在填补这一关键空白，并通过自动化优化提高任务成功率。

Method: 本研究采用性能因果反演原则和Shapley值结合，以及CDC-MAS因果发现算法，实现了性能依赖模型的准确建模、智能体级别归因和关键失败步骤的鲁棒识别。通过对Who&When和TRAIL基准测试的评估，方法在步骤级精度和任务成功率上均取得了显著提升。

Result: 研究的结果表明，本方法在智能体归因和任务成功率方面取得显著进展，步骤级准确率提升至36.2%，优化建议平均提升任务成功率22.4%。

Conclusion: 本研究提出了面向多智能体系统的首个失败归因框架，通过多粒度因果推断解决了当前诊断工具的不足之处。通过性能因果反演原则和新颖的因果发现算法，实现了准确分配智能体级别责任，并在Who&When和TRAIL基准测试上取得显著进展。通过自动化优化循环生成的有针对性建议实现了任务成功率的提升，为调试复杂智能体交互提供了有效解决方案。

Abstract: Multi-agent systems (MAS) are critical for automating complex tasks, yet
their practical deployment is severely hampered by the challenge of failure
attribution. Current diagnostic tools, which rely on statistical correlations,
are fundamentally inadequate; on challenging benchmarks like Who\&When,
state-of-the-art methods achieve less than 15\% accuracy in locating the
root-cause step of a failure. To address this critical gap, we introduce the
first failure attribution framework for MAS grounded in multi-granularity
causal inference. Our approach makes two key technical contributions: (1) a
performance causal inversion principle, which correctly models performance
dependencies by reversing the data flow in execution logs, combined with
Shapley values to accurately assign agent-level blame; (2) a novel causal
discovery algorithm, CDC-MAS, that robustly identifies critical failure steps
by tackling the non-stationary nature of MAS interaction data. The framework's
attribution results directly fuel an automated optimization loop, generating
targeted suggestions whose efficacy is validated via counterfactual
simulations. Evaluations on the Who\&When and TRAIL benchmarks demonstrate a
significant leap in performance. Our method achieves up to 36.2\% step-level
accuracy. Crucially, the generated optimizations boost overall task success
rates by an average of 22.4\%. This work provides a principled and effective
solution for debugging complex agent interactions, paving the way for more
reliable and interpretable multi-agent systems.

</details>


### [11] [One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases](https://arxiv.org/abs/2509.08705)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 该论文提出了一种新颖的心智理论框架，结合了快速习惯性的基于图的推理系统和较慢的上下文敏感的元适应学习系统，动态平衡直觉和深思熟虑的推理。作者验证了架构在错误信念任务上的有效性，并系统探索了其复制相关认知偏见的能力。实验结果显示模型成功模拟人类自适应行为，并具有强大的泛化能力，阐明了认知偏见背后的认知机制。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于构建一种新颖的心智理论框架，结合了认知科学的双过程理论，旨在实现人工智能系统具备类人化的社会认知和自适应决策能力。作者希望通过将人类认知机制融入到人工智能系统中，拓展AI系统的应用领域，并为理解认知偏见背后的认知机制提供新的视角。

Method: 该论文的方法是基于图卷积网络（GCNs）实现了快速习惯性的基于图的推理系统（系统1），并采用元学习技术驱动了较慢的、上下文敏感的元适应学习系统（系统2），通过学习的上下文门机制动态平衡直觉和深思熟虑的推理。作者验证了架构在经典错误信念任务上的有效性，并通过实验系统地探索了其复制与双过程理论相关的认知偏见。

Result: 论文的实验结果表明，该双过程方法在模拟人类自适应行为方面取得了成功，并具有对未见环境的强大泛化能力。作者的模型能够复制多种与双过程理论相关的认知偏见，展示了其在理解认知机制方面的潜力。

Conclusion: 该论文介绍了一种新颖的心智理论（ToM）框架，结合了认知科学的双过程理论，通过图卷积网络（GCNs）实现了快速习惯性的基于图的推理系统（系统1），并采用元学习技术驱动了较慢的、上下文敏感的元适应学习系统（系统2）。模型通过学习的上下文门机制动态平衡直觉和深思熟虑的推理。通过在经典的错误信念任务上验证我们的架构，并系统地探索其复制与双过程理论相关的标志性认知偏见，包括锚定效应、认知负荷疲劳、框架效应和启动效应。实验结果表明，我们的双过程方法密切模拟了人类的自适应行为，对未知环境具有强大的泛化能力，并阐明了推理偏见背后的认知机制。这项工作连接了人工智能和认知理论，为展现细致、类人化社会认知和自适应决策能力的人工智能系统铺平了道路。

Abstract: We introduce a novel Theory of Mind (ToM) framework inspired by dual-process
theories from cognitive science, integrating a fast, habitual graph-based
reasoning system (System 1), implemented via graph convolutional networks
(GCNs), and a slower, context-sensitive meta-adaptive learning system (System
2), driven by meta-learning techniques. Our model dynamically balances
intuitive and deliberative reasoning through a learned context gate mechanism.
We validate our architecture on canonical false-belief tasks and systematically
explore its capacity to replicate hallmark cognitive biases associated with
dual-process theory, including anchoring, cognitive-load fatigue, framing
effects, and priming effects. Experimental results demonstrate that our
dual-process approach closely mirrors human adaptive behavior, achieves robust
generalization to unseen contexts, and elucidates cognitive mechanisms
underlying reasoning biases. This work bridges artificial intelligence and
cognitive theory, paving the way for AI systems exhibiting nuanced, human-like
social cognition and adaptive decision-making capabilities.

</details>


### [12] [The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems](https://arxiv.org/abs/2509.08713)
*Ziming Luo,Atoosa Kasirzadeh,Nihar B. Shah*

Main category: cs.AI

TL;DR: AI scientist systems have the potential to accelerate scientific discovery, but there are risks in their internal workflow that could compromise research integrity. The paper identifies four failure modes, assesses prominent AI scientist systems, and recommends mandating the submission of trace logs and code for transparency and reproducibility.


<details>
  <summary>Details</summary>
Motivation: The motivation of the paper is to address the lack of scrutiny on the internal workflow of AI scientist systems, highlighting the importance of examining potential flaws that could impact the reliability and trustworthiness of research outputs.

Method: The paper identifies four failure modes in AI scientist systems: inappropriate benchmark selection, data leakage, metric misuse, and post-hoc selection bias. Controlled experiments were designed to isolate each failure mode and assess two open-source AI scientist systems. The evaluation was based on the full automated workflow, enabling effective detection of failures.

Result: The assessment revealed several failures in AI scientist systems, ranging in severity, which can be easily overlooked in practice. Access to trace logs and code from the full automated workflow was shown to be more effective in detecting failures compared to examining the final paper alone.

Conclusion: AI scientist systems have the potential to accelerate scientific discovery, but there are risks in their internal workflow that could compromise research integrity. This paper identifies four potential failure modes in contemporary AI scientist systems and recommends mandating the submission of trace logs and code alongside research papers for transparency and reproducibility.

Abstract: AI scientist systems, capable of autonomously executing the full research
workflow from hypothesis generation and experimentation to paper writing, hold
significant potential for accelerating scientific discovery. However, the
internal workflow of these systems have not been closely examined. This lack of
scrutiny poses a risk of introducing flaws that could undermine the integrity,
reliability, and trustworthiness of their research outputs. In this paper, we
identify four potential failure modes in contemporary AI scientist systems:
inappropriate benchmark selection, data leakage, metric misuse, and post-hoc
selection bias. To examine these risks, we design controlled experiments that
isolate each failure mode while addressing challenges unique to evaluating AI
scientist systems. Our assessment of two prominent open-source AI scientist
systems reveals the presence of several failures, across a spectrum of
severity, which can be easily overlooked in practice. Finally, we demonstrate
that access to trace logs and code from the full automated workflow enables far
more effective detection of such failures than examining the final paper alone.
We thus recommend journals and conferences evaluating AI-generated research to
mandate submission of these artifacts alongside the paper to ensure
transparency, accountability, and reproducibility.

</details>


### [13] [Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making](https://arxiv.org/abs/2509.08785)
*Anup Tuladhar,Araz Minhas,Adam Kirton,Eli Kinney-Lang*

Main category: cs.AI

TL;DR: 该论文介绍了一个实验平台，结合强化学习和语言模型推理，探讨叙事元素如何塑造人工智能决策。通过可配置的网格世界环境，研究了不同叙事框架对奖励为基础学习的影响，为理解强化学习与叙事决策之间的互动提供基础。


<details>
  <summary>Details</summary>
Motivation: AI系统目前能够进行决策和进行叙事推理，但这些能力大多是分开研究的。作者试图通过双系统架构来探讨叙事框架如何影响奖励为基础的学习，以搭建这一研究间的桥梁。

Method: 介绍了一个双系统架构，由强化学习策略和语言模型组成，用于研究叙事框架如何影响奖励为基础的学习。实施了一个可配置的网格世界环境，以便控制测试环境的复杂性、叙事参数以及强化学习与基于叙事决策之间的互动。记录系统捕获了从RL策略值到语言模型推理再到行动选择模式的基本决策指标。

Result: 实验平台介绍了一个具有双系统架构的实验平台，可用于研究叙事框架对奖励为基础的学习的影响，并探索强化学习与叙事决策之间的潜在互动。

Conclusion: 该论文介绍了一个实验平台，通过将强化学习和语言模型推理相结合，探讨叙事元素如何影响人工智能决策。他们的平台旨在通过双系统架构，研究叙事框架如何影响基于奖励的学习。实施了一个可配置的网格世界环境，平台的模块化设计有利于控制环境复杂性、叙事参数以及强化学习与基于叙事的决策之间的互动。通过捕获基本决策指标，为研究不同叙事框架如何影响基于奖励的决策和探索优化式学习与符号推理在人工智能系统中的潜在互动提供了基础。

Abstract: We present a preliminary experimental platform that explores how narrative
elements might shape AI decision-making by combining reinforcement learning
(RL) with language model reasoning. While AI systems can now both make
decisions and engage in narrative reasoning, these capabilities have mostly
been studied separately. Our platform attempts to bridge this gap using a
dual-system architecture to examine how narrative frameworks could influence
reward-based learning. The system comprises a reinforcement learning policy
that suggests actions based on past experience, and a language model that
processes these suggestions through different narrative frameworks to guide
decisions. This setup enables initial experimentation with narrative elements
while maintaining consistent environment and reward structures. We implement
this architecture in a configurable gridworld environment, where agents receive
both policy suggestions and information about their surroundings. The
platform's modular design facilitates controlled testing of environmental
complexity, narrative parameters, and the interaction between reinforcement
learning and narrative-based decisions. Our logging system captures basic
decision metrics, from RL policy values to language model reasoning to action
selection patterns. While preliminary, this implementation provides a
foundation for studying how different narrative frameworks might affect
reward-based decisions and exploring potential interactions between
optimization-based learning and symbolic reasoning in AI systems.

</details>
